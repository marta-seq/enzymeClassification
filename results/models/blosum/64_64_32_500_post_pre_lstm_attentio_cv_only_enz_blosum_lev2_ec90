/home/amsequeira/enzymeClassification/models/blosum/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_blosum_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/blosum/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_blosum_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa2703657c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa2703653a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa270365880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa2703655e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1, -1, -2, ..., -1, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2, -2,  1, ..., -4, -3, -3],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 0, -3, -3, ..., -3, -1,  4],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.90      0.87       911
         1.0       0.92      0.68      0.78        53
         2.0       0.82      0.83      0.82       179
         3.0       0.48      0.40      0.43        25
         4.0       0.58      0.68      0.63       112
         5.0       0.88      0.71      0.78       491
         6.0       0.79      0.81      0.80        64
         7.0       0.50      0.30      0.37        37
         8.0       0.92      0.84      0.88       206
         9.0       0.83      0.77      0.80        71
        10.0       0.91      0.92      0.91       404
        11.0       0.90      0.56      0.69        16
        12.0       0.75      0.79      0.77       378
        13.0       0.68      0.82      0.74       191
        14.0       0.53      0.39      0.45        76
        15.0       0.84      0.74      0.79        66
        16.0       0.85      0.83      0.84       141
        17.0       0.77      0.79      0.78       182
        18.0       1.00      0.75      0.86        12
        19.0       0.92      0.87      0.89        38
        20.0       0.91      0.92      0.92      2162
        21.0       0.95      0.95      0.95       168
        22.0       0.85      0.80      0.82      1470
        23.0       0.90      0.84      0.87      1259
        24.0       0.91      0.88      0.90       956
        25.0       0.92      0.90      0.91       283
        26.0       0.90      0.90      0.90      3919
        27.0       0.93      0.92      0.93       531
        28.0       1.00      0.83      0.91        12
        29.0       0.80      0.83      0.81      2345
        30.0       0.65      0.77      0.71       615
        31.0       0.81      0.66      0.72        32
        32.0       0.80      0.79      0.80      1449
        33.0       0.84      0.83      0.83       893
        34.0       0.90      0.87      0.88      1377
        35.0       0.67      0.55      0.60        22
        36.0       0.77      0.87      0.82       844
        37.0       0.88      0.87      0.88      1142
        38.0       0.88      0.88      0.88       314
        39.0       0.80      0.70      0.74        56
        40.0       0.88      0.77      0.82       154
        41.0       0.96      0.85      0.90        52
        42.0       0.82      0.78      0.80       247
        43.0       0.89      0.83      0.86       198
        44.0       0.92      0.92      0.92       529
        45.0       0.93      0.86      0.90       540
        46.0       0.60      0.45      0.51        20
        47.0       0.64      0.68      0.65        80
        48.0       0.96      0.98      0.97      1466
        49.0       0.88      0.90      0.89       148
        50.0       0.90      0.96      0.93      1453
        51.0       0.40      0.33      0.36        12
        52.0       0.89      0.93      0.91       151
        53.0       0.96      0.96      0.96       903
        54.0       0.92      0.85      0.88       108
        55.0       0.95      0.97      0.96        93
        56.0       1.00      0.88      0.94        33
        57.0       0.85      0.92      0.88        49
        58.0       0.91      0.94      0.92       154

    accuracy                           0.87     29892
   macro avg       0.83      0.79      0.81     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[816   0   4 ...   0   0   0]
 [  0  36   0 ...   0   1   0]
 [  0   0 148 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   1]
 [  0   0   0 ...   0  45   2]
 [  0   0   0 ...   0   5 144]]

===multilabel confusion matrix===

[[[28825   156]
  [   95   816]]

 [[29836     3]
  [   17    36]]

 [[29680    33]
  [   31   148]]

 [[29856    11]
  [   15    10]]

 [[29726    54]
  [   36    76]]

 [[29352    49]
  [  143   348]]

 [[29814    14]
  [   12    52]]

 [[29844    11]
  [   26    11]]

 [[29670    16]
  [   33   173]]

 [[29810    11]
  [   16    55]]

 [[29450    38]
  [   34   370]]

 [[29875     1]
  [    7     9]]

 [[29412   102]
  [   78   300]]

 [[29628    73]
  [   35   156]]

 [[29789    27]
  [   46    30]]

 [[29817     9]
  [   17    49]]

 [[29730    21]
  [   24   117]]

 [[29668    42]
  [   38   144]]

 [[29880     0]
  [    3     9]]

 [[29851     3]
  [    5    33]]

 [[27543   187]
  [  168  1994]]

 [[29716     8]
  [    8   160]]

 [[28206   216]
  [  289  1181]]

 [[28516   117]
  [  205  1054]]

 [[28852    84]
  [  111   845]]

 [[29587    22]
  [   28   255]]

 [[25601   372]
  [  406  3513]]

 [[29324    37]
  [   42   489]]

 [[29880     0]
  [    2    10]]

 [[27061   486]
  [  409  1936]]

 [[29025   252]
  [  142   473]]

 [[29855     5]
  [   11    21]]

 [[28161   282]
  [  299  1150]]

 [[28853   146]
  [  152   741]]

 [[28381   134]
  [  178  1199]]

 [[29864     6]
  [   10    12]]

 [[28832   216]
  [  108   736]]

 [[28619   131]
  [  144   998]]

 [[29541    37]
  [   37   277]]

 [[29826    10]
  [   17    39]]

 [[29722    16]
  [   36   118]]

 [[29838     2]
  [    8    44]]

 [[29602    43]
  [   55   192]]

 [[29673    21]
  [   33   165]]

 [[29321    42]
  [   41   488]]

 [[29316    36]
  [   73   467]]

 [[29866     6]
  [   11     9]]

 [[29781    31]
  [   26    54]]

 [[28362    64]
  [   29  1437]]

 [[29726    18]
  [   15   133]]

 [[28287   152]
  [   53  1400]]

 [[29874     6]
  [    8     4]]

 [[29724    17]
  [   10   141]]

 [[28952    37]
  [   36   867]]

 [[29776     8]
  [   16    92]]

 [[29794     5]
  [    3    90]]

 [[29859     0]
  [    4    29]]

 [[29835     8]
  [    4    45]]

 [[29724    14]
  [   10   144]]]

===scores report===
metrics	scores
Accuracy	0.8679
MCC	0.8609
log_loss	0.6967
f1 score weighted	0.8678
f1 score macro	0.8077
f1 score micro	0.8679
roc_auc ovr	0.9920
roc_auc ovo	0.9899
precision	0.8694
recall	0.8679

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa2703657c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa2703653a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa270365880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa2703655e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1,  2,  0, ..., -3, -2, -2],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-2, -2,  1, ..., -4, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -3, -3, ..., -3, -1,  4],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 4, -1, -2, ..., -3, -2,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -2, -3, ..., -2, -1,  1],
        [-1, -2, -3, ..., -2, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 4, -1, -2, ..., -3, -2,  0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.90      0.89       912
         1.0       0.86      0.72      0.78        53
         2.0       0.89      0.75      0.82       179
         3.0       0.90      0.36      0.51        25
         4.0       0.68      0.61      0.64       112
         5.0       0.74      0.78      0.76       492
         6.0       0.90      0.80      0.85        65
         7.0       0.77      0.63      0.70        38
         8.0       0.84      0.84      0.84       206
         9.0       0.88      0.79      0.83        71
        10.0       0.91      0.87      0.89       405
        11.0       0.62      0.59      0.61        17
        12.0       0.84      0.77      0.80       377
        13.0       0.80      0.78      0.79       191
        14.0       0.45      0.32      0.37        76
        15.0       0.76      0.71      0.73        66
        16.0       0.86      0.78      0.82       140
        17.0       0.79      0.82      0.81       182
        18.0       1.00      1.00      1.00        11
        19.0       0.91      0.84      0.87        37
        20.0       0.93      0.93      0.93      2163
        21.0       0.95      0.92      0.93       169
        22.0       0.81      0.85      0.83      1469
        23.0       0.90      0.86      0.88      1259
        24.0       0.89      0.89      0.89       956
        25.0       0.95      0.86      0.90       282
        26.0       0.87      0.92      0.90      3919
        27.0       0.92      0.90      0.91       531
        28.0       1.00      0.83      0.91        12
        29.0       0.79      0.82      0.81      2346
        30.0       0.70      0.73      0.72       615
        31.0       0.93      0.88      0.90        32
        32.0       0.77      0.81      0.79      1450
        33.0       0.82      0.81      0.82       893
        34.0       0.90      0.89      0.90      1376
        35.0       0.85      0.50      0.63        22
        36.0       0.86      0.84      0.85       843
        37.0       0.90      0.85      0.87      1142
        38.0       0.90      0.89      0.89       314
        39.0       0.74      0.55      0.63        56
        40.0       0.82      0.77      0.80       154
        41.0       0.87      0.90      0.89        52
        42.0       0.81      0.80      0.80       247
        43.0       0.91      0.84      0.87       198
        44.0       0.90      0.88      0.89       529
        45.0       0.91      0.90      0.91       539
        46.0       0.71      0.26      0.38        19
        47.0       0.75      0.76      0.76        80
        48.0       0.97      0.97      0.97      1466
        49.0       0.91      0.86      0.89       148
        50.0       0.95      0.93      0.94      1453
        51.0       0.33      0.25      0.29        12
        52.0       0.90      0.91      0.91       151
        53.0       0.95      0.95      0.95       903
        54.0       0.92      0.85      0.88       108
        55.0       0.95      0.97      0.96        93
        56.0       0.97      0.88      0.92        33
        57.0       0.88      0.94      0.91        49
        58.0       0.93      0.90      0.92       154

    accuracy                           0.87     29892
   macro avg       0.85      0.79      0.81     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[818   0   0 ...   0   0   0]
 [  0  38   0 ...   0   0   0]
 [  1   0 135 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   1]
 [  0   0   0 ...   0  46   3]
 [  0   0   0 ...   0   5 139]]

===multilabel confusion matrix===

[[[28871   109]
  [   94   818]]

 [[29833     6]
  [   15    38]]

 [[29696    17]
  [   44   135]]

 [[29866     1]
  [   16     9]]

 [[29748    32]
  [   44    68]]

 [[29266   134]
  [  110   382]]

 [[29821     6]
  [   13    52]]

 [[29847     7]
  [   14    24]]

 [[29654    32]
  [   33   173]]

 [[29813     8]
  [   15    56]]

 [[29452    35]
  [   52   353]]

 [[29869     6]
  [    7    10]]

 [[29461    54]
  [   87   290]]

 [[29663    38]
  [   42   149]]

 [[29787    29]
  [   52    24]]

 [[29811    15]
  [   19    47]]

 [[29734    18]
  [   31   109]]

 [[29670    40]
  [   32   150]]

 [[29881     0]
  [    0    11]]

 [[29852     3]
  [    6    31]]

 [[27588   141]
  [  158  2005]]

 [[29715     8]
  [   14   155]]

 [[28123   300]
  [  224  1245]]

 [[28507   126]
  [  180  1079]]

 [[28834   102]
  [  106   850]]

 [[29598    12]
  [   40   242]]

 [[25422   551]
  [  295  3624]]

 [[29320    41]
  [   52   479]]

 [[29880     0]
  [    2    10]]

 [[27046   500]
  [  425  1921]]

 [[29088   189]
  [  165   450]]

 [[29858     2]
  [    4    28]]

 [[28101   341]
  [  281  1169]]

 [[28845   154]
  [  168   725]]

 [[28384   132]
  [  150  1226]]

 [[29868     2]
  [   11    11]]

 [[28933   116]
  [  133   710]]

 [[28640   110]
  [  170   972]]

 [[29547    31]
  [   35   279]]

 [[29825    11]
  [   25    31]]

 [[29712    26]
  [   35   119]]

 [[29833     7]
  [    5    47]]

 [[29598    47]
  [   49   198]]

 [[29677    17]
  [   32   166]]

 [[29309    54]
  [   61   468]]

 [[29306    47]
  [   52   487]]

 [[29871     2]
  [   14     5]]

 [[29792    20]
  [   19    61]]

 [[28382    44]
  [   46  1420]]

 [[29731    13]
  [   20   128]]

 [[28370    69]
  [   99  1354]]

 [[29874     6]
  [    9     3]]

 [[29726    15]
  [   13   138]]

 [[28940    49]
  [   46   857]]

 [[29776     8]
  [   16    92]]

 [[29794     5]
  [    3    90]]

 [[29858     1]
  [    4    29]]

 [[29837     6]
  [    3    46]]

 [[29728    10]
  [   15   139]]]

===scores report===
metrics	scores
Accuracy	0.8694
MCC	0.8623
log_loss	0.6915
f1 score weighted	0.8690
f1 score macro	0.8140
f1 score micro	0.8694
roc_auc ovr	0.9918
roc_auc ovo	0.9904
precision	0.8700
recall	0.8694

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa2703657c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa2703653a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa270365880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa2703655e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 0, -2,  0, ..., -2, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2, -2, -2, ...,  2,  7, -1],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-2,  0,  1, ..., -2,  2, -3],
        [ 0, -3, -3, ..., -2, -2, -1],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0, -2,  0, ..., -2, -3, -3],
        [-1, -2, -3, ..., -2, -1,  1],
        [-1, -2, -2, ..., -4, -3, -2]],

       [[ 0, -3, -3, ..., -3, -1,  4],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  5,  0, ..., -3, -2, -3],
        [-2,  0,  6, ..., -4, -2, -3]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.88      0.89       912
         1.0       0.86      0.83      0.84        52
         2.0       0.86      0.81      0.83       179
         3.0       0.50      0.36      0.42        25
         4.0       0.69      0.57      0.62       112
         5.0       0.76      0.77      0.77       492
         6.0       0.89      0.83      0.86        65
         7.0       0.69      0.53      0.60        38
         8.0       0.92      0.84      0.88       205
         9.0       0.87      0.77      0.82        71
        10.0       0.92      0.91      0.91       405
        11.0       0.69      0.65      0.67        17
        12.0       0.78      0.81      0.80       377
        13.0       0.89      0.85      0.87       190
        14.0       0.39      0.24      0.30        76
        15.0       0.85      0.67      0.75        67
        16.0       0.92      0.84      0.88       140
        17.0       0.84      0.79      0.81       183
        18.0       0.92      0.92      0.92        12
        19.0       0.97      0.89      0.93        37
        20.0       0.91      0.92      0.92      2162
        21.0       0.94      0.95      0.95       169
        22.0       0.82      0.85      0.84      1470
        23.0       0.85      0.87      0.86      1259
        24.0       0.91      0.91      0.91       956
        25.0       0.88      0.89      0.89       282
        26.0       0.89      0.92      0.90      3918
        27.0       0.96      0.91      0.93       531
        28.0       1.00      0.85      0.92        13
        29.0       0.81      0.82      0.82      2346
        30.0       0.68      0.68      0.68       615
        31.0       0.90      0.84      0.87        32
        32.0       0.78      0.82      0.80      1450
        33.0       0.84      0.82      0.83       893
        34.0       0.91      0.88      0.90      1376
        35.0       0.60      0.55      0.57        22
        36.0       0.80      0.86      0.83       843
        37.0       0.91      0.89      0.90      1142
        38.0       0.91      0.92      0.92       314
        39.0       0.85      0.51      0.64        55
        40.0       0.91      0.75      0.82       154
        41.0       0.86      0.85      0.85        52
        42.0       0.80      0.81      0.81       247
        43.0       0.89      0.86      0.87       197
        44.0       0.93      0.90      0.92       530
        45.0       0.92      0.88      0.90       540
        46.0       1.00      0.42      0.59        19
        47.0       0.70      0.72      0.71        79
        48.0       0.95      0.98      0.96      1465
        49.0       0.95      0.83      0.88       149
        50.0       0.95      0.93      0.94      1453
        51.0       0.30      0.25      0.27        12
        52.0       0.93      0.89      0.91       152
        53.0       0.96      0.95      0.95       903
        54.0       0.92      0.85      0.88       108
        55.0       0.94      0.88      0.91        93
        56.0       0.97      0.97      0.97        32
        57.0       0.98      0.94      0.96        50
        58.0       0.89      0.95      0.92       154

    accuracy                           0.87     29892
   macro avg       0.85      0.80      0.82     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[798   0   0 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  1   0 145 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  47   3]
 [  0   0   0 ...   0   0 147]]

===multilabel confusion matrix===

[[[28900    80]
  [  114   798]]

 [[29833     7]
  [    9    43]]

 [[29689    24]
  [   34   145]]

 [[29858     9]
  [   16     9]]

 [[29751    29]
  [   48    64]]

 [[29280   120]
  [  111   381]]

 [[29820     7]
  [   11    54]]

 [[29845     9]
  [   18    20]]

 [[29673    14]
  [   33   172]]

 [[29813     8]
  [   16    55]]

 [[29453    34]
  [   36   369]]

 [[29870     5]
  [    6    11]]

 [[29431    84]
  [   71   306]]

 [[29681    21]
  [   28   162]]

 [[29788    28]
  [   58    18]]

 [[29817     8]
  [   22    45]]

 [[29742    10]
  [   23   117]]

 [[29681    28]
  [   39   144]]

 [[29879     1]
  [    1    11]]

 [[29854     1]
  [    4    33]]

 [[27535   195]
  [  163  1999]]

 [[29713    10]
  [    8   161]]

 [[28152   270]
  [  221  1249]]

 [[28443   190]
  [  161  1098]]

 [[28848    88]
  [   89   867]]

 [[29577    33]
  [   31   251]]

 [[25511   463]
  [  322  3596]]

 [[29340    21]
  [   50   481]]

 [[29879     0]
  [    2    11]]

 [[27106   440]
  [  426  1920]]

 [[29083   194]
  [  196   419]]

 [[29857     3]
  [    5    27]]

 [[28104   338]
  [  257  1193]]

 [[28855   144]
  [  158   735]]

 [[28401   115]
  [  160  1216]]

 [[29862     8]
  [   10    12]]

 [[28869   180]
  [  116   727]]

 [[28654    96]
  [  131  1011]]

 [[29551    27]
  [   26   288]]

 [[29832     5]
  [   27    28]]

 [[29726    12]
  [   38   116]]

 [[29833     7]
  [    8    44]]

 [[29594    51]
  [   46   201]]

 [[29673    22]
  [   27   170]]

 [[29327    35]
  [   52   478]]

 [[29309    43]
  [   64   476]]

 [[29873     0]
  [   11     8]]

 [[29789    24]
  [   22    57]]

 [[28347    80]
  [   28  1437]]

 [[29737     6]
  [   26   123]]

 [[28362    77]
  [   99  1354]]

 [[29873     7]
  [    9     3]]

 [[29729    11]
  [   16   136]]

 [[28955    34]
  [   49   854]]

 [[29776     8]
  [   16    92]]

 [[29794     5]
  [   11    82]]

 [[29859     1]
  [    1    31]]

 [[29841     1]
  [    3    47]]

 [[29719    19]
  [    7   147]]]

===scores report===
metrics	scores
Accuracy	0.8732
MCC	0.8663
log_loss	0.6751
f1 score weighted	0.8727
f1 score macro	0.8180
f1 score micro	0.8732
roc_auc ovr	0.9923
roc_auc ovo	0.9904
precision	0.8734
recall	0.8732

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa2703657c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa2703653a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa270365880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa2703655e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [-1, -3, -3, ..., -3, -1,  3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -1,  0, ..., -2, -2,  0],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2,  0,  6, ..., -4, -2, -3],
        [-2,  0,  1, ..., -2,  2, -3],
        [-1, -2, -3, ..., -2, -1,  1]],

       [[ 0, -3, -3, ..., -3, -1,  4],
        [-1,  5,  0, ..., -3, -2, -3],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [-1,  1,  0, ..., -2, -1, -2],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1,  0,  0, ..., -3, -2, -2]],

       [[ 0, -2,  0, ..., -2, -3, -3],
        [-1, -2, -2, ..., -4, -3, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2,  0,  1, ..., -2,  2, -3],
        [ 0, -1,  0, ..., -2, -2,  0],
        [-1, -2, -3, ..., -2, -1,  1]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.86      0.87       912
         1.0       0.90      0.90      0.90        52
         2.0       0.85      0.73      0.78       179
         3.0       0.45      0.42      0.43        24
         4.0       0.65      0.57      0.61       112
         5.0       0.78      0.75      0.76       492
         6.0       0.98      0.72      0.83        64
         7.0       0.76      0.58      0.66        38
         8.0       0.93      0.84      0.88       205
         9.0       0.82      0.80      0.81        70
        10.0       0.89      0.86      0.87       405
        11.0       0.75      0.53      0.62        17
        12.0       0.80      0.80      0.80       378
        13.0       0.82      0.79      0.81       191
        14.0       0.37      0.22      0.28        76
        15.0       0.75      0.73      0.74        67
        16.0       0.82      0.86      0.84       140
        17.0       0.83      0.78      0.80       183
        18.0       1.00      0.92      0.96        12
        19.0       0.97      0.92      0.94        37
        20.0       0.92      0.93      0.93      2162
        21.0       0.96      0.89      0.92       168
        22.0       0.81      0.83      0.82      1470
        23.0       0.85      0.87      0.86      1259
        24.0       0.89      0.90      0.89       955
        25.0       0.92      0.90      0.91       282
        26.0       0.90      0.91      0.90      3918
        27.0       0.96      0.90      0.93       532
        28.0       0.92      0.85      0.88        13
        29.0       0.79      0.84      0.81      2346
        30.0       0.71      0.70      0.70       616
        31.0       0.93      0.78      0.85        32
        32.0       0.78      0.83      0.80      1449
        33.0       0.87      0.81      0.84       893
        34.0       0.84      0.89      0.87      1377
        35.0       0.87      0.59      0.70        22
        36.0       0.87      0.84      0.86       844
        37.0       0.87      0.89      0.88      1142
        38.0       0.95      0.90      0.93       314
        39.0       0.77      0.66      0.71        56
        40.0       0.78      0.74      0.76       153
        41.0       0.96      0.90      0.93        51
        42.0       0.83      0.74      0.78       246
        43.0       0.88      0.87      0.87       197
        44.0       0.92      0.88      0.90       530
        45.0       0.92      0.91      0.92       540
        46.0       0.47      0.40      0.43        20
        47.0       0.67      0.69      0.68        80
        48.0       0.97      0.97      0.97      1465
        49.0       0.92      0.89      0.90       148
        50.0       0.96      0.94      0.95      1453
        51.0       0.60      0.46      0.52        13
        52.0       0.91      0.89      0.90       151
        53.0       0.95      0.95      0.95       904
        54.0       0.90      0.78      0.84       108
        55.0       0.95      0.86      0.90        93
        56.0       0.91      0.97      0.94        33
        57.0       0.90      0.92      0.91        50
        58.0       0.85      0.92      0.88       153

    accuracy                           0.87     29892
   macro avg       0.84      0.80      0.82     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[781   0   0 ...   0   0   0]
 [  0  47   0 ...   0   0   0]
 [  0   0 130 ...   0   0   0]
 ...
 [  0   0   0 ...  32   1   0]
 [  0   0   0 ...   1  46   2]
 [  0   0   0 ...   0   2 140]]

===multilabel confusion matrix===

[[[28875   105]
  [  131   781]]

 [[29835     5]
  [    5    47]]

 [[29690    23]
  [   49   130]]

 [[29856    12]
  [   14    10]]

 [[29746    34]
  [   48    64]]

 [[29294   106]
  [  125   367]]

 [[29827     1]
  [   18    46]]

 [[29847     7]
  [   16    22]]

 [[29673    14]
  [   32   173]]

 [[29810    12]
  [   14    56]]

 [[29442    45]
  [   56   349]]

 [[29872     3]
  [    8     9]]

 [[29440    74]
  [   77   301]]

 [[29668    33]
  [   40   151]]

 [[29787    29]
  [   59    17]]

 [[29809    16]
  [   18    49]]

 [[29725    27]
  [   20   120]]

 [[29679    30]
  [   41   142]]

 [[29880     0]
  [    1    11]]

 [[29854     1]
  [    3    34]]

 [[27562   168]
  [  142  2020]]

 [[29717     7]
  [   18   150]]

 [[28133   289]
  [  243  1227]]

 [[28435   198]
  [  160  1099]]

 [[28830   107]
  [   98   857]]

 [[29587    23]
  [   29   253]]

 [[25588   386]
  [  365  3553]]

 [[29338    22]
  [   53   479]]

 [[29878     1]
  [    2    11]]

 [[27024   522]
  [  382  1964]]

 [[29102   174]
  [  186   430]]

 [[29858     2]
  [    7    25]]

 [[28103   340]
  [  244  1205]]

 [[28887   112]
  [  166   727]]

 [[28280   235]
  [  146  1231]]

 [[29868     2]
  [    9    13]]

 [[28946   102]
  [  137   707]]

 [[28592   158]
  [  129  1013]]

 [[29564    14]
  [   31   283]]

 [[29825    11]
  [   19    37]]

 [[29708    31]
  [   40   113]]

 [[29839     2]
  [    5    46]]

 [[29608    38]
  [   63   183]]

 [[29671    24]
  [   26   171]]

 [[29324    38]
  [   62   468]]

 [[29309    43]
  [   47   493]]

 [[29863     9]
  [   12     8]]

 [[29785    27]
  [   25    55]]

 [[28377    50]
  [   40  1425]]

 [[29733    11]
  [   17   131]]

 [[28380    59]
  [   92  1361]]

 [[29875     4]
  [    7     6]]

 [[29727    14]
  [   16   135]]

 [[28940    48]
  [   46   858]]

 [[29775     9]
  [   24    84]]

 [[29795     4]
  [   13    80]]

 [[29856     3]
  [    1    32]]

 [[29837     5]
  [    4    46]]

 [[29714    25]
  [   13   140]]]

===scores report===
metrics	scores
Accuracy	0.8697
MCC	0.8627
log_loss	0.6727
f1 score weighted	0.8693
f1 score macro	0.8158
f1 score micro	0.8697
roc_auc ovr	0.9922
roc_auc ovo	0.9900
precision	0.8700
recall	0.8697

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa2703657c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa2703653a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa270365880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa2703655e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1, -2, -3, ..., -2, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 0, -1,  0, ..., -2, -2,  0],
        [-2, -2,  1, ..., -4, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -3, -3, ..., -3, -1,  3],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1,  0,  0, ..., -3, -2, -2],
        ...,
        [ 0, -2,  0, ..., -2, -3, -3],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1, -2, -2, ..., -4, -3, -2],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -2, -2, ..., -4, -3, -2],
        [ 0, -2,  0, ..., -2, -3, -3],
        [-2, -2, -2, ...,  2,  7, -1],
        ...,
        [ 0, -2,  0, ..., -2, -3, -3],
        [ 0, -2,  0, ..., -2, -3, -3],
        [-2,  0,  1, ..., -2,  2, -3]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.91      0.88       911
         1.0       0.85      0.74      0.79        53
         2.0       0.89      0.81      0.85       180
         3.0       0.60      0.24      0.34        25
         4.0       0.78      0.56      0.65       111
         5.0       0.76      0.77      0.77       491
         6.0       0.95      0.84      0.89        64
         7.0       0.65      0.46      0.54        37
         8.0       0.90      0.88      0.89       205
         9.0       0.76      0.80      0.78        71
        10.0       0.91      0.88      0.90       404
        11.0       0.86      0.35      0.50        17
        12.0       0.79      0.83      0.81       378
        13.0       0.88      0.75      0.81       191
        14.0       0.39      0.34      0.37        76
        15.0       0.76      0.67      0.71        66
        16.0       0.86      0.81      0.83       140
        17.0       0.82      0.74      0.77       182
        18.0       1.00      1.00      1.00        12
        19.0       0.96      0.68      0.79        37
        20.0       0.92      0.93      0.93      2162
        21.0       0.90      0.92      0.91       168
        22.0       0.82      0.83      0.82      1470
        23.0       0.84      0.86      0.85      1259
        24.0       0.90      0.90      0.90       955
        25.0       0.91      0.91      0.91       283
        26.0       0.88      0.92      0.90      3919
        27.0       0.97      0.90      0.93       532
        28.0       1.00      0.69      0.82        13
        29.0       0.80      0.80      0.80      2345
        30.0       0.69      0.74      0.71       616
        31.0       1.00      0.78      0.88        32
        32.0       0.79      0.81      0.80      1449
        33.0       0.84      0.82      0.83       893
        34.0       0.90      0.89      0.89      1377
        35.0       0.82      0.64      0.72        22
        36.0       0.84      0.87      0.86       844
        37.0       0.92      0.89      0.91      1142
        38.0       0.89      0.89      0.89       314
        39.0       0.77      0.61      0.68        56
        40.0       0.91      0.81      0.86       153
        41.0       0.96      0.85      0.90        52
        42.0       0.82      0.78      0.80       247
        43.0       0.90      0.82      0.86       197
        44.0       0.91      0.90      0.90       529
        45.0       0.94      0.90      0.92       540
        46.0       0.60      0.30      0.40        20
        47.0       0.82      0.76      0.79        80
        48.0       0.97      0.98      0.97      1466
        49.0       0.91      0.89      0.90       148
        50.0       0.94      0.95      0.95      1453
        51.0       0.20      0.08      0.12        12
        52.0       0.91      0.87      0.89       151
        53.0       0.95      0.96      0.96       904
        54.0       0.86      0.81      0.83       108
        55.0       0.94      0.96      0.95        93
        56.0       0.91      0.91      0.91        33
        57.0       0.90      0.92      0.91        50
        58.0       0.91      0.94      0.93       154

    accuracy                           0.87     29892
   macro avg       0.85      0.78      0.81     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[826   0   0 ...   0   0   0]
 [  0  39   0 ...   0   0   0]
 [  0   0 145 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   1]
 [  0   0   0 ...   0  46   2]
 [  0   0   0 ...   1   3 145]]

===multilabel confusion matrix===

[[[28837   144]
  [   85   826]]

 [[29832     7]
  [   14    39]]

 [[29694    18]
  [   35   145]]

 [[29863     4]
  [   19     6]]

 [[29764    17]
  [   49    62]]

 [[29282   119]
  [  113   378]]

 [[29825     3]
  [   10    54]]

 [[29846     9]
  [   20    17]]

 [[29666    21]
  [   24   181]]

 [[29803    18]
  [   14    57]]

 [[29453    35]
  [   47   357]]

 [[29874     1]
  [   11     6]]

 [[29430    84]
  [   64   314]]

 [[29682    19]
  [   47   144]]

 [[29776    40]
  [   50    26]]

 [[29812    14]
  [   22    44]]

 [[29734    18]
  [   27   113]]

 [[29680    30]
  [   48   134]]

 [[29880     0]
  [    0    12]]

 [[29854     1]
  [   12    25]]

 [[27564   166]
  [  152  2010]]

 [[29707    17]
  [   14   154]]

 [[28157   265]
  [  254  1216]]

 [[28433   200]
  [  174  1085]]

 [[28844    93]
  [   97   858]]

 [[29585    24]
  [   26   257]]

 [[25474   499]
  [  325  3594]]

 [[29343    17]
  [   54   478]]

 [[29879     0]
  [    4     9]]

 [[27073   474]
  [  470  1875]]

 [[29069   207]
  [  161   455]]

 [[29860     0]
  [    7    25]]

 [[28140   303]
  [  277  1172]]

 [[28856   143]
  [  159   734]]

 [[28375   140]
  [  156  1221]]

 [[29867     3]
  [    8    14]]

 [[28913   135]
  [  112   732]]

 [[28662    88]
  [  120  1022]]

 [[29544    34]
  [   33   281]]

 [[29826    10]
  [   22    34]]

 [[29726    13]
  [   29   124]]

 [[29838     2]
  [    8    44]]

 [[29603    42]
  [   54   193]]

 [[29677    18]
  [   36   161]]

 [[29318    45]
  [   55   474]]

 [[29320    32]
  [   54   486]]

 [[29868     4]
  [   14     6]]

 [[29799    13]
  [   19    61]]

 [[28374    52]
  [   32  1434]]

 [[29731    13]
  [   17   131]]

 [[28356    83]
  [   76  1377]]

 [[29876     4]
  [   11     1]]

 [[29728    13]
  [   19   132]]

 [[28945    43]
  [   38   866]]

 [[29770    14]
  [   21    87]]

 [[29793     6]
  [    4    89]]

 [[29856     3]
  [    3    30]]

 [[29837     5]
  [    4    46]]

 [[29724    14]
  [    9   145]]]

===scores report===
metrics	scores
Accuracy	0.8716
MCC	0.8646
log_loss	0.6812
f1 score weighted	0.8709
f1 score macro	0.8058
f1 score micro	0.8716
roc_auc ovr	0.9920
roc_auc ovo	0.9901
precision	0.8715
recall	0.8716

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8679245283018868	0.8608919468104932	0.6967341045906708	0.8678111701075463	0.8076504975569496	0.8679245283018869	0.991998874500281	0.989922588801092	0.8693688406159711	0.8679245283018868
1	0.8693630402783353	0.8622546731098631	0.6915099445172868	0.8689933482334776	0.8139697554755887	0.8693630402783353	0.9917922039811122	0.9904189286133145	0.8699659662210084	0.8693630402783353
2	0.8732102234711628	0.8663406494161319	0.675080242173705	0.8726954374932117	0.8179695191441508	0.8732102234711628	0.9923304690253718	0.9904037622611491	0.8733679000078814	0.8732102234711628
3	0.869731031714171	0.8626910096911191	0.6726676953761898	0.8693475282320343	0.8157792503774235	0.869731031714171	0.9921645137274095	0.9899999359378324	0.8700241791761796	0.869731031714171
4	0.8715709888933494	0.864602627994963	0.6811789798964906	0.8708976923328506	0.8057527090226433	0.8715709888933494	0.9920361363302512	0.9901056320542881	0.8715191100914517	0.8715709888933494
mean	0.870359962531781	0.8633561814045141	0.6834341933108685	0.8699490352798241	0.8122243463153511	0.870359962531781	0.9920644395128854	0.9901701695335351	0.8708491992224985	0.870359962531781
std	0.0018390932609236783	0.0019072967509575697	0.009304809106290408	0.0016904609593771049	0.0047221391036913795	0.0018390932609236488	0.00017888464199658857	0.00020537157767195612	0.001445327259432916	0.0018390932609236783

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 70495.1918 secs

