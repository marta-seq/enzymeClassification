/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_700_pre_eliminate_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f47307582e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4730758520>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f47307584c0>]/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_700_pre_eliminate_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8e04798220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8e047983d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8e04798430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8e047984f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.73      0.74      3504
         1.0       0.54      0.91      0.68      3551
         2.0       0.93      0.76      0.84      9748
         3.0       0.81      0.77      0.79      6027
         4.0       0.71      0.80      0.75      2487
         5.0       0.91      0.68      0.78      1550
         6.0       0.95      0.92      0.93      2748
         7.0       0.98      0.88      0.93      1283

    accuracy                           0.80     30898
   macro avg       0.82      0.81      0.80     30898
weighted avg       0.83      0.80      0.80     30898


===confusion_matrix===

[[2558  377  128  361   47   18    8    7]
 [  82 3215   54  113   64    5   12    6]
 [ 373 1143 7456  365  321   26   62    2]
 [ 294  615  207 4655  204   16   31    5]
 [  29  290   62  114 1978   12    2    0]
 [  35  191   29   67  153 1057   18    0]
 [  11  122   41   19   18   20 2517    0]
 [  65    7   30   34   12    5    2 1128]]

===multilabel confusion matrix===

[[[26505   889]
  [  946  2558]]

 [[24602  2745]
  [  336  3215]]

 [[20599   551]
  [ 2292  7456]]

 [[23798  1073]
  [ 1372  4655]]

 [[27592   819]
  [  509  1978]]

 [[29246   102]
  [  493  1057]]

 [[28015   135]
  [  231  2517]]

 [[29595    20]
  [  155  1128]]]

===scores report===
metrics	scores
Accuracy	0.7950
MCC	0.7571
log_loss	0.6145
f1 score weighted	0.8015
f1 score macro	0.8042
f1 score micro	0.7950
roc_auc ovr	0.9692
roc_auc ovo	0.9723
precision	0.8263
recall	0.7950

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8e04798220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8e047983d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8e04798430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8e047984f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.74      0.78      3504
         1.0       0.84      0.88      0.86      3551
         2.0       0.87      0.93      0.90      9748
         3.0       0.90      0.79      0.84      6027
         4.0       0.74      0.90      0.81      2487
         5.0       0.97      0.79      0.87      1550
         6.0       0.97      0.95      0.96      2749
         7.0       0.92      0.97      0.94      1282

    accuracy                           0.87     30898
   macro avg       0.88      0.87      0.87     30898
weighted avg       0.87      0.87      0.87     30898


===confusion_matrix===

[[2576  150  397  233   96    9    3   40]
 [  44 3114  191   75  107    3    4   13]
 [ 156  136 9075  109  222    3   21   26]
 [ 225  167  561 4769  245   11   31   18]
 [  25   43  113   44 2250    8    1    3]
 [  36   51   79   44  110 1217   12    1]
 [   4   22   66   11   24    1 2612    9]
 [  13    8    7    2    4    0    2 1246]]

===multilabel confusion matrix===

[[[26891   503]
  [  928  2576]]

 [[26770   577]
  [  437  3114]]

 [[19736  1414]
  [  673  9075]]

 [[24353   518]
  [ 1258  4769]]

 [[27603   808]
  [  237  2250]]

 [[29313    35]
  [  333  1217]]

 [[28075    74]
  [  137  2612]]

 [[29506   110]
  [   36  1246]]]

===scores report===
metrics	scores
Accuracy	0.8693
MCC	0.8405
log_loss	0.4239
f1 score weighted	0.8686
f1 score macro	0.8711
f1 score micro	0.8693
roc_auc ovr	0.9839
roc_auc ovo	0.9858
precision	0.8734
recall	0.8693

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8e04798220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8e047983d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8e04798430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8e047984f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.77      0.81      3504
         1.0       0.81      0.93      0.86      3551
         2.0       0.91      0.93      0.92      9748
         3.0       0.87      0.86      0.87      6028
         4.0       0.94      0.86      0.90      2486
         5.0       0.95      0.85      0.90      1550
         6.0       0.95      0.97      0.96      2748
         7.0       0.98      0.95      0.97      1282

    accuracy                           0.89     30897
   macro avg       0.91      0.89      0.90     30897
weighted avg       0.89      0.89      0.89     30897


===confusion_matrix===

[[2693  173  288  287   16   19   14   14]
 [  48 3285   99   79   19    4   15    2]
 [ 149  227 9047  226   33   16   48    2]
 [ 191  201  335 5206   36   21   32    6]
 [  38   93  115   87 2129   13   11    0]
 [  39   49   62   41   17 1323   17    2]
 [  14   18   37   16    3    1 2659    0]
 [  14   24    6   11    1    1    1 1224]]

===multilabel confusion matrix===

[[[26900   493]
  [  811  2693]]

 [[26561   785]
  [  266  3285]]

 [[20207   942]
  [  701  9047]]

 [[24122   747]
  [  822  5206]]

 [[28286   125]
  [  357  2129]]

 [[29272    75]
  [  227  1323]]

 [[28011   138]
  [   89  2659]]

 [[29589    26]
  [   58  1224]]]

===scores report===
metrics	scores
Accuracy	0.8922
MCC	0.8681
log_loss	0.3631
f1 score weighted	0.8919
f1 score macro	0.8968
f1 score micro	0.8922
roc_auc ovr	0.9874
roc_auc ovo	0.9889
precision	0.8936
recall	0.8922

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8e04798220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8e047983d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8e04798430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8e047984f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.81      0.80      3503
         1.0       0.84      0.88      0.86      3551
         2.0       0.93      0.90      0.91      9747
         3.0       0.82      0.88      0.85      6028
         4.0       0.89      0.87      0.88      2487
         5.0       0.97      0.79      0.87      1550
         6.0       0.96      0.94      0.95      2748
         7.0       0.93      0.97      0.95      1283

    accuracy                           0.88     30897
   macro avg       0.89      0.88      0.88     30897
weighted avg       0.88      0.88      0.88     30897


===confusion_matrix===

[[2830  106  162  331   33    4    6   31]
 [  87 3135  102  156   35    5   15   16]
 [ 288  198 8761  359   79   14   38   10]
 [ 265  130  218 5290   74    4   27   20]
 [  40   65   99   99 2164    6   10    4]
 [  62   57   55   95   41 1227   10    3]
 [  17   19   38   75    6    3 2584    6]
 [  11   13    5    9    1    0    1 1243]]

===multilabel confusion matrix===

[[[26624   770]
  [  673  2830]]

 [[26758   588]
  [  416  3135]]

 [[20471   679]
  [  986  8761]]

 [[23745  1124]
  [  738  5290]]

 [[28141   269]
  [  323  2164]]

 [[29311    36]
  [  323  1227]]

 [[28042   107]
  [  164  2584]]

 [[29524    90]
  [   40  1243]]]

===scores report===
metrics	scores
Accuracy	0.8814
MCC	0.8553
log_loss	0.3987
f1 score weighted	0.8819
f1 score macro	0.8844
f1 score micro	0.8814
roc_auc ovr	0.9848
roc_auc ovo	0.9866
precision	0.8840
recall	0.8814

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8e04798220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8e047983d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8e04798430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8e047984f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.64      0.72      3504
         1.0       0.64      0.87      0.74      3551
         2.0       0.82      0.90      0.86      9747
         3.0       0.91      0.63      0.75      6027
         4.0       0.68      0.83      0.75      2487
         5.0       0.76      0.81      0.78      1550
         6.0       0.95      0.94      0.95      2748
         7.0       0.98      0.86      0.91      1283

    accuracy                           0.80     30897
   macro avg       0.82      0.81      0.81     30897
weighted avg       0.82      0.80      0.80     30897


===confusion_matrix===

[[2236  372  503  175  130   62   16   10]
 [  35 3082  220   31  102   57   17    7]
 [ 130  419 8735  106  242   64   47    4]
 [ 221  610  796 3822  393  156   27    2]
 [  21  128  182   41 2063   42   10    0]
 [  26   87  109   20   51 1248    9    0]
 [   4   46   69    3   21   18 2586    1]
 [  24   53   68   15   13    0   10 1100]]

===multilabel confusion matrix===

[[[26932   461]
  [ 1268  2236]]

 [[25631  1715]
  [  469  3082]]

 [[19203  1947]
  [ 1012  8735]]

 [[24479   391]
  [ 2205  3822]]

 [[27458   952]
  [  424  2063]]

 [[28948   399]
  [  302  1248]]

 [[28013   136]
  [  162  2586]]

 [[29590    24]
  [  183  1100]]]

===scores report===
metrics	scores
Accuracy	0.8050
MCC	0.7645
log_loss	0.6156
f1 score weighted	0.8036
f1 score macro	0.8064
f1 score micro	0.8050
roc_auc ovr	0.9712
roc_auc ovo	0.9742
precision	0.8210
recall	0.8050

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7950029128098907	0.7571181299803635	0.6144927645132303	0.8014785130935811	0.80415254872211	0.7950029128098907	0.9692039075476535	0.9722661733545536	0.8263356712690891	0.7950029128098907
1	0.8692795650203897	0.8405331694995308	0.4238520518982321	0.8685933625400871	0.8710679379177966	0.8692795650203897	0.9838999665553861	0.9857580650301666	0.8733786983436187	0.8692795650203897
2	0.8921901802764023	0.8681224766596173	0.36311835247604834	0.891892616054304	0.8968410687551197	0.8921901802764023	0.9874071208953711	0.9889317195731161	0.8936447634348306	0.8921901802764023
3	0.8814448004660647	0.8552939768645221	0.39868704310326575	0.8819479546152844	0.8843652713653638	0.8814448004660647	0.9848204840071906	0.986591082233707	0.8840480395218338	0.8814448004660647
4	0.8049972489238437	0.764523913171892	0.6156432068680794	0.8036175520696646	0.8064198286552124	0.8049972489238437	0.9712285226621484	0.9742131695071483	0.8210219209255527	0.8049972489238437
mean	0.8485829414993182	0.8171183332351852	0.4831586837717712	0.8495059996745843	0.8525693310831205	0.8485829414993182	0.9793120003335499	0.9815520419397383	0.8596858186989849	0.8485829414993182
std	0.040448424803269115	0.0468471010472886	0.10941956445102476	0.03905335376259823	0.0394642329668047	0.040448424803269115	0.0075424128019915895	0.006893890095688824	0.030137524810727557	0.040448424803269115

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 92391.8277 secs

