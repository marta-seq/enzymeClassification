/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_900_pre_eliminate_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f95e011b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f95e011b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f95e011b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f95e011b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.75      0.80      3879
         1.0       0.87      0.89      0.88      3710
         2.0       0.90      0.93      0.91     10244
         3.0       0.84      0.89      0.86      6456
         4.0       0.93      0.85      0.89      2541
         5.0       0.95      0.84      0.89      1596
         6.0       0.97      0.95      0.96      3069
         7.0       0.95      0.96      0.95      1320

    accuracy                           0.89     32815
   macro avg       0.91      0.88      0.89     32815
weighted avg       0.89      0.89      0.89     32815


===confusion_matrix===

[[2923   90  340  449   33    9    4   31]
 [  66 3318  126  138   20   11   17   14]
 [ 187  137 9518  305   49   17   24    7]
 [ 177  124  345 5720   37   13   23   17]
 [  43   52  135  124 2162   15   10    0]
 [  33   42   81   54   29 1346   10    1]
 [  14   35   55   29    5    6 2925    0]
 [  26    8    9    9    0    0    0 1268]]

===multilabel confusion matrix===

[[[28390   546]
  [  956  2923]]

 [[28617   488]
  [  392  3318]]

 [[21480  1091]
  [  726  9518]]

 [[25251  1108]
  [  736  5720]]

 [[30101   173]
  [  379  2162]]

 [[31148    71]
  [  250  1346]]

 [[29658    88]
  [  144  2925]]

 [[31425    70]
  [   52  1268]]]

===scores report===
metrics	scores
Accuracy	0.8892
MCC	0.8643
log_loss	0.3621
f1 score weighted	0.8887
f1 score macro	0.8936
f1 score micro	0.8892
roc_auc ovr	0.9866
roc_auc ovo	0.9881
precision	0.8899
recall	0.8892

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f95e011b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f95e011b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f95e011b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f95e011b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 1., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.85      0.75      3878
         1.0       0.93      0.79      0.86      3710
         2.0       0.87      0.91      0.89     10243
         3.0       0.92      0.72      0.81      6457
         4.0       0.90      0.83      0.86      2541
         5.0       0.69      0.89      0.78      1597
         6.0       0.89      0.97      0.93      3068
         7.0       0.99      0.90      0.94      1320

    accuracy                           0.85     32814
   macro avg       0.86      0.86      0.85     32814
weighted avg       0.86      0.85      0.85     32814


===confusion_matrix===

[[3301   27  285  125   21   72   42    5]
 [ 216 2935  256   92   49   66   91    5]
 [ 439   48 9372   99   72  125   85    3]
 [ 761   75  536 4631   80  262  109    3]
 [  87   33  153   40 2116   91   21    0]
 [  42   10   63   18   11 1422   31    0]
 [  19    4   40    4    3   16 2982    0]
 [ 105    9   11    2    1    3    4 1185]]

===multilabel confusion matrix===

[[[27267  1669]
  [  577  3301]]

 [[28898   206]
  [  775  2935]]

 [[21227  1344]
  [  871  9372]]

 [[25977   380]
  [ 1826  4631]]

 [[30036   237]
  [  425  2116]]

 [[30582   635]
  [  175  1422]]

 [[29363   383]
  [   86  2982]]

 [[31478    16]
  [  135  1185]]]

===scores report===
metrics	scores
Accuracy	0.8516
MCC	0.8209
log_loss	0.4749
f1 score weighted	0.8525
f1 score macro	0.8519
f1 score micro	0.8516
roc_auc ovr	0.9814
roc_auc ovo	0.9839
precision	0.8648
recall	0.8516

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f95e011b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f95e011b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f95e011b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f95e011b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.79      0.80      3879
         1.0       0.92      0.87      0.89      3710
         2.0       0.87      0.95      0.91     10243
         3.0       0.90      0.85      0.87      6456
         4.0       0.92      0.84      0.88      2541
         5.0       0.88      0.90      0.89      1597
         6.0       0.98      0.96      0.97      3069
         7.0       0.94      0.96      0.95      1319

    accuracy                           0.89     32814
   macro avg       0.90      0.89      0.90     32814
weighted avg       0.89      0.89      0.89     32814


===confusion_matrix===

[[3075   71  400  220   34   41   10   28]
 [  94 3217  206  117   37   15    6   18]
 [ 208   60 9694  152   49   46   22   12]
 [ 290   76  473 5489   51   48   19   10]
 [  39   32  211   84 2146   22    7    0]
 [  26   16   71   27   16 1430    5    6]
 [  12   13   62   21    2   12 2946    1]
 [  17    7   13   11    0    3    2 1266]]

===multilabel confusion matrix===

[[[28249   686]
  [  804  3075]]

 [[28829   275]
  [  493  3217]]

 [[21135  1436]
  [  549  9694]]

 [[25726   632]
  [  967  5489]]

 [[30084   189]
  [  395  2146]]

 [[31030   187]
  [  167  1430]]

 [[29674    71]
  [  123  2946]]

 [[31420    75]
  [   53  1266]]]

===scores report===
metrics	scores
Accuracy	0.8918
MCC	0.8675
log_loss	0.3625
f1 score weighted	0.8913
f1 score macro	0.8961
f1 score micro	0.8918
roc_auc ovr	0.9880
roc_auc ovo	0.9893
precision	0.8926
recall	0.8918

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f95e011b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f95e011b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f95e011b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f95e011b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.79      0.81      3879
         1.0       0.90      0.86      0.88      3710
         2.0       0.91      0.93      0.92     10243
         3.0       0.85      0.88      0.86      6456
         4.0       0.90      0.87      0.88      2541
         5.0       0.90      0.88      0.89      1597
         6.0       0.96      0.96      0.96      3069
         7.0       0.97      0.95      0.96      1319

    accuracy                           0.89     32814
   macro avg       0.90      0.89      0.90     32814
weighted avg       0.89      0.89      0.89     32814


===confusion_matrix===

[[3076   57  253  373   33   52   11   24]
 [  68 3206  161  169   58   14   27    7]
 [ 221   99 9498  282   77   31   31    4]
 [ 279   84  287 5679   64   29   30    4]
 [  36   54  111   99 2207   21   13    0]
 [  25   23   58   45   24 1411   10    1]
 [   6   17   48   44    1   11 2942    0]
 [  15   10   10   26    0    2    1 1255]]

===multilabel confusion matrix===

[[[28285   650]
  [  803  3076]]

 [[28760   344]
  [  504  3206]]

 [[21643   928]
  [  745  9498]]

 [[25320  1038]
  [  777  5679]]

 [[30016   257]
  [  334  2207]]

 [[31057   160]
  [  186  1411]]

 [[29622   123]
  [  127  2942]]

 [[31455    40]
  [   64  1255]]]

===scores report===
metrics	scores
Accuracy	0.8921
MCC	0.8679
log_loss	0.3604
f1 score weighted	0.8920
f1 score macro	0.8957
f1 score micro	0.8921
roc_auc ovr	0.9876
roc_auc ovo	0.9891
precision	0.8922
recall	0.8921

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f95e011b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f95e011b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f95e011b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f95e011b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.61      0.65      3879
         1.0       0.78      0.33      0.46      3710
         2.0       0.52      0.77      0.62     10243
         3.0       0.48      0.50      0.49      6456
         4.0       0.51      0.52      0.51      2541
         5.0       0.28      0.01      0.01      1596
         6.0       0.90      0.66      0.76      3069
         7.0       0.88      0.83      0.86      1320

    accuracy                           0.58     32814
   macro avg       0.63      0.53      0.55     32814
weighted avg       0.60      0.58      0.57     32814


===confusion_matrix===

[[2371   22  567  850    9    0    8   52]
 [  71 1211 1521  699  184    1   15    8]
 [ 457  134 7926 1121  482    5   79   39]
 [ 360   77 2511 3214  224    3   28   39]
 [  23   41  774  372 1316    2   13    0]
 [  47   37  838  241  340   11   79    3]
 [  18   19  878   81   35   17 2020    1]
 [  37    8  112   71    0    0    0 1092]]

===multilabel confusion matrix===

[[[27922  1013]
  [ 1508  2371]]

 [[28766   338]
  [ 2499  1211]]

 [[15370  7201]
  [ 2317  7926]]

 [[22923  3435]
  [ 3242  3214]]

 [[28999  1274]
  [ 1225  1316]]

 [[31190    28]
  [ 1585    11]]

 [[29523   222]
  [ 1049  2020]]

 [[31352   142]
  [  228  1092]]]

===scores report===
metrics	scores
Accuracy	0.5839
MCC	0.4797
log_loss	1.1615
f1 score weighted	0.5667
f1 score macro	0.5464
f1 score micro	0.5839
roc_auc ovr	0.8561
roc_auc ovo	0.8724
precision	0.6028
recall	0.5839

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8892274874295292	0.8643008687193492	0.3621430012853806	0.8887273136044668	0.893596165678938	0.8892274874295292	0.9866428284465503	0.988148067427108	0.8898599179261694	0.8892274874295292
1	0.8515877369415493	0.8208710404694385	0.4749440736984246	0.8524809417469933	0.8518972403138892	0.8515877369415493	0.9814431402556816	0.9839213575540297	0.8648243803926475	0.8515877369415493
2	0.8917839946364357	0.8675216753397403	0.36252590961180714	0.8913338796006215	0.8960519483429752	0.8917839946364357	0.9880127127370044	0.9893270939290977	0.892600930306457	0.8917839946364357
3	0.8921192174072042	0.867942432635417	0.3604313308376344	0.8919638421592285	0.8956964348997543	0.8921192174072041	0.9876015979764888	0.9891484728979336	0.8922059355053585	0.8921192174072042
4	0.583927591881514	0.47972424450873075	1.1614756674294122	0.5667171766386243	0.5463756303376361	0.583927591881514	0.8561249556343571	0.8723555554060851	0.6028043017764099	0.583927591881514
mean	0.8217292056592465	0.7800720523345352	0.5443039965725317	0.818244630749987	0.8167234839146384	0.8217292056592465	0.9599650470100165	0.9645801094428508	0.8284590931814085	0.8217292056592465
std	0.11988293011107688	0.15121937501931368	0.3116878979097325	0.12663534591348735	0.1362088811571527	0.11988293011107687	0.05197350784929861	0.04615391340579865	0.11330526506158219	0.11988293011107688

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 144379.2879 secs

