/home/amsequeira/enzymeClassification/models/first_model_search_cv/64_64_32_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f638c3d4eb0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f638c3d4ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f638c3d4f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f638c3d4b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.78      0.78      4541
         1.0       0.86      0.86      0.86      3813
         2.0       0.87      0.91      0.89     10869
         3.0       0.84      0.83      0.84      6897
         4.0       0.96      0.80      0.87      2585
         5.0       0.89      0.84      0.86      1617
         6.0       0.96      0.94      0.95      3258
         7.0       0.94      0.95      0.95      1372

    accuracy                           0.87     34952
   macro avg       0.89      0.87      0.87     34952
weighted avg       0.87      0.87      0.87     34952


===confusion_matrix===

[[3540  117  365  421    9   36   10   43]
 [  74 3295  208  171   24   17   15    9]
 [ 423  140 9943  277   17   23   41    5]
 [ 380  133  509 5734   28   53   41   19]
 [  67   88  186  127 2069   35   12    1]
 [  33   42   99   55    9 1365   12    2]
 [  24   17  107   36    2   11 3061    0]
 [  20   14   16   14    0    1    1 1306]]

===multilabel confusion matrix===

[[[29390  1021]
  [ 1001  3540]]

 [[30588   551]
  [  518  3295]]

 [[22593  1490]
  [  926  9943]]

 [[26954  1101]
  [ 1163  5734]]

 [[32278    89]
  [  516  2069]]

 [[33159   176]
  [  252  1365]]

 [[31562   132]
  [  197  3061]]

 [[33501    79]
  [   66  1306]]]

===scores report===
metrics	scores
Accuracy	0.8673
MCC	0.8372
log_loss	0.4168
f1 score weighted	0.8672
f1 score macro	0.8748
f1 score micro	0.8673
roc_auc ovr	0.9814
roc_auc ovo	0.9841
precision	0.8685
recall	0.8673

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f638c3d4eb0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f638c3d4ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f638c3d4f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f638c3d4b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.70      0.74      4541
         1.0       0.77      0.85      0.81      3813
         2.0       0.84      0.88      0.86     10869
         3.0       0.79      0.80      0.80      6897
         4.0       0.94      0.75      0.83      2585
         5.0       0.90      0.77      0.83      1616
         6.0       0.89      0.95      0.92      3258
         7.0       0.94      0.93      0.94      1372

    accuracy                           0.83     34951
   macro avg       0.86      0.83      0.84     34951
weighted avg       0.83      0.83      0.83     34951


===confusion_matrix===

[[3167  162  547  542   21   29   32   41]
 [  74 3237  212  179   35   23   41   12]
 [ 335  291 9557  445   34   35  162   10]
 [ 309  250  624 5540   34   32   92   16]
 [  44  141  243  171 1943   14   29    0]
 [  34   67  137   99    9 1243   27    0]
 [  15   40   74   37    2    4 3086    0]
 [  31   12   16   24    0    4    6 1279]]

===multilabel confusion matrix===

[[[29568   842]
  [ 1374  3167]]

 [[30175   963]
  [  576  3237]]

 [[22229  1853]
  [ 1312  9557]]

 [[26557  1497]
  [ 1357  5540]]

 [[32231   135]
  [  642  1943]]

 [[33194   141]
  [  373  1243]]

 [[31304   389]
  [  172  3086]]

 [[33500    79]
  [   93  1279]]]

===scores report===
metrics	scores
Accuracy	0.8312
MCC	0.7930
log_loss	0.5130
f1 score weighted	0.8303
f1 score macro	0.8397
f1 score micro	0.8312
roc_auc ovr	0.9719
roc_auc ovo	0.9758
precision	0.8330
recall	0.8312

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f638c3d4eb0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f638c3d4ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f638c3d4f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f638c3d4b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 1., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 1., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.77      0.79      4542
         1.0       0.88      0.89      0.88      3814
         2.0       0.90      0.92      0.91     10869
         3.0       0.86      0.84      0.85      6896
         4.0       0.88      0.88      0.88      2584
         5.0       0.89      0.88      0.89      1616
         6.0       0.95      0.96      0.95      3258
         7.0       0.96      0.96      0.96      1372

    accuracy                           0.88     34951
   macro avg       0.89      0.89      0.89     34951
weighted avg       0.88      0.88      0.88     34951


===confusion_matrix===

[[3517   94  335  451   44   49   30   22]
 [  87 3393  143   90   49   21   17   14]
 [ 319  133 9980  250   76   36   71    4]
 [ 346  143  405 5811   97   47   36   11]
 [  29   52  116   86 2280   12    7    2]
 [  39   24   56   44   24 1422    7    0]
 [  12   13   62   27    8    8 3128    0]
 [  22    7    9   13    2    1    1 1317]]

===multilabel confusion matrix===

[[[29555   854]
  [ 1025  3517]]

 [[30671   466]
  [  421  3393]]

 [[22956  1126]
  [  889  9980]]

 [[27094   961]
  [ 1085  5811]]

 [[32067   300]
  [  304  2280]]

 [[33161   174]
  [  194  1422]]

 [[31524   169]
  [  130  3128]]

 [[33526    53]
  [   55  1317]]]

===scores report===
metrics	scores
Accuracy	0.8826
MCC	0.8563
log_loss	0.3977
f1 score weighted	0.8822
f1 score macro	0.8895
f1 score micro	0.8826
roc_auc ovr	0.9847
roc_auc ovo	0.9871
precision	0.8820
recall	0.8826

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f638c3d4eb0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f638c3d4ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f638c3d4f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f638c3d4b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        ...,
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 1., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 1.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.81      0.76      4542
         1.0       0.85      0.86      0.85      3813
         2.0       0.92      0.86      0.89     10868
         3.0       0.76      0.87      0.81      6897
         4.0       0.94      0.83      0.88      2585
         5.0       0.97      0.80      0.87      1616
         6.0       0.99      0.91      0.95      3258
         7.0       0.98      0.95      0.96      1372

    accuracy                           0.86     34951
   macro avg       0.89      0.86      0.87     34951
weighted avg       0.87      0.86      0.86     34951


===confusion_matrix===

[[3657   86  203  552   16    7    2   19]
 [ 132 3263  126  245   26    4    6   11]
 [ 566  220 9365  648   37   17   14    1]
 [ 480  110  238 6021   30    7    9    2]
 [  72   68  117  184 2135    6    3    0]
 [  66   34   71  138   17 1287    3    0]
 [  58   55   68  100    4    2 2971    0]
 [  28    4    8   28    0    0    0 1304]]

===multilabel confusion matrix===

[[[29007  1402]
  [  885  3657]]

 [[30561   577]
  [  550  3263]]

 [[23252   831]
  [ 1503  9365]]

 [[26159  1895]
  [  876  6021]]

 [[32236   130]
  [  450  2135]]

 [[33292    43]
  [  329  1287]]

 [[31656    37]
  [  287  2971]]

 [[33546    33]
  [   68  1304]]]

===scores report===
metrics	scores
Accuracy	0.8584
MCC	0.8277
log_loss	0.4366
f1 score weighted	0.8606
f1 score macro	0.8727
f1 score micro	0.8584
roc_auc ovr	0.9803
roc_auc ovo	0.9834
precision	0.8672
recall	0.8584

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f638c3d4eb0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f638c3d4ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f638c3d4f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f638c3d4b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 1., 0., ..., 0., 0., 0.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       [[0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.77      0.78      4542
         1.0       0.84      0.87      0.86      3813
         2.0       0.89      0.91      0.90     10868
         3.0       0.87      0.80      0.83      6897
         4.0       0.81      0.88      0.85      2585
         5.0       0.87      0.84      0.86      1616
         6.0       0.94      0.96      0.95      3258
         7.0       0.95      0.94      0.94      1372

    accuracy                           0.87     34951
   macro avg       0.87      0.87      0.87     34951
weighted avg       0.87      0.87      0.87     34951


===confusion_matrix===

[[3519  140  394  315   70   46   21   37]
 [  79 3326  154   90  102   26   22   14]
 [ 316  184 9850  285  120   42   59   12]
 [ 434  169  459 5526  173   50   78    8]
 [  34   66   97   78 2275   26    9    0]
 [  35   32   74   53   46 1363   12    1]
 [  16   16   51   19   12    4 3140    0]
 [  37   14   14   16    1    1    2 1287]]

===multilabel confusion matrix===

[[[29458   951]
  [ 1023  3519]]

 [[30517   621]
  [  487  3326]]

 [[22840  1243]
  [ 1018  9850]]

 [[27198   856]
  [ 1371  5526]]

 [[31842   524]
  [  310  2275]]

 [[33140   195]
  [  253  1363]]

 [[31490   203]
  [  118  3140]]

 [[33507    72]
  [   85  1287]]]

===scores report===
metrics	scores
Accuracy	0.8665
MCC	0.8370
log_loss	0.4241
f1 score weighted	0.8661
f1 score macro	0.8707
f1 score micro	0.8665
roc_auc ovr	0.9817
roc_auc ovo	0.9847
precision	0.8665
recall	0.8665

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8672751201647975	0.8371854819380213	0.4168466152642021	0.867168225817111	0.8747995924280586	0.8672751201647975	0.9814417904891358	0.9841130210121626	0.8685478591478611	0.8672751201647975
1	0.8312208520500128	0.7930337841159596	0.5129807634822587	0.8302901494002383	0.8396977714097233	0.8312208520500128	0.9719044514512064	0.9758194750336064	0.8329817180990937	0.8312208520500128
2	0.8826070784813024	0.8563144164653468	0.3976574830909557	0.8821959784285642	0.8894576326535224	0.8826070784813024	0.9847360901598046	0.9870968391172561	0.8819699726380726	0.8826070784813024
3	0.8584303739521044	0.8277047087228854	0.43663638599059773	0.860643077668681	0.872726406757766	0.8584303739521044	0.9802884507728035	0.9833706857903576	0.8671553990586167	0.8584303739521044
4	0.866527424108037	0.8369781324260517	0.4241301265210218	0.8660768797684059	0.8706680294133136	0.866527424108037	0.9817042742152079	0.9846695493682251	0.8665038885855628	0.866527424108037
mean	0.8612121697512508	0.830243304733653	0.4376502748698073	0.8612748622166	0.8694698865324769	0.8612121697512508	0.9800150114176317	0.9830139140643215	0.8634317675058414	0.8612121697512508
std	0.01691136269782205	0.020805035398258995	0.03972586196390381	0.017064206929579776	0.016287019795873492	0.01691136269782205	0.004313556394853116	0.0038080619837754905	0.016250220379778833	0.01691136269782205

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 67904.4688 secs

