/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_term_bilstm_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbef865c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbef865c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbef865c700>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbef865c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.88      0.90      3813
         1.0       0.93      0.93      0.93     10869
         2.0       0.88      0.91      0.89      6897
         3.0       0.86      0.91      0.89      2585
         4.0       0.93      0.88      0.91      1616
         5.0       0.97      0.96      0.96      3258
         6.0       0.97      0.97      0.97      1372

    accuracy                           0.92     30410
   macro avg       0.92      0.92      0.92     30410
weighted avg       0.92      0.92      0.92     30410


===confusion_matrix===

[[ 3337   175   176    74    25    18     8]
 [   96 10124   424   146    34    31    14]
 [   73   388  6242   107    37    40    10]
 [   34    62   111  2357    11     9     1]
 [   24    59    62    29  1430    12     0]
 [   13    58    43    21     5  3117     1]
 [    8    16    15     5     2     0  1326]]

===multilabel confusion matrix===

[[[26349   248]
  [  476  3337]]

 [[18783   758]
  [  745 10124]]

 [[22682   831]
  [  655  6242]]

 [[27443   382]
  [  228  2357]]

 [[28680   114]
  [  186  1430]]

 [[27042   110]
  [  141  3117]]

 [[29004    34]
  [   46  1326]]]

===scores report===
metrics	scores
Accuracy	0.9185
MCC	0.8958
log_loss	0.2904
f1 score weighted	0.9187
f1 score macro	0.9213
f1 score micro	0.9185
roc_auc ovr	0.9910
roc_auc ovo	0.9925
precision	0.9192
recall	0.9185

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbef865c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbef865c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbef865c700>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbef865c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.87      0.87      3813
         1.0       0.89      0.93      0.91     10869
         2.0       0.89      0.83      0.86      6897
         3.0       0.77      0.91      0.83      2585
         4.0       0.94      0.82      0.88      1616
         5.0       0.98      0.92      0.95      3258
         6.0       0.98      0.95      0.96      1372

    accuracy                           0.89     30410
   macro avg       0.90      0.89      0.89     30410
weighted avg       0.90      0.89      0.89     30410


===confusion_matrix===

[[ 3316   195   120   161     6    11     4]
 [  154 10137   356   179    21    17     5]
 [  194   679  5703   242    40    18    21]
 [   53   122    56  2343    10     1     0]
 [   51   103    68    66  1325     3     0]
 [   25   105    64    53     0  3011     0]
 [   36    14    17     1     2     2  1300]]

===multilabel confusion matrix===

[[[26084   513]
  [  497  3316]]

 [[18323  1218]
  [  732 10137]]

 [[22832   681]
  [ 1194  5703]]

 [[27123   702]
  [  242  2343]]

 [[28715    79]
  [  291  1325]]

 [[27100    52]
  [  247  3011]]

 [[29008    30]
  [   72  1300]]]

===scores report===
metrics	scores
Accuracy	0.8923
MCC	0.8623
log_loss	0.3398
f1 score weighted	0.8925
f1 score macro	0.8948
f1 score micro	0.8923
roc_auc ovr	0.9864
roc_auc ovo	0.9883
precision	0.8952
recall	0.8923

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbef865c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbef865c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbef865c700>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbef865c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.90      0.90      3814
         1.0       0.93      0.90      0.92     10869
         2.0       0.83      0.91      0.87      6896
         3.0       0.93      0.86      0.89      2584
         4.0       0.92      0.88      0.90      1617
         5.0       0.96      0.96      0.96      3258
         6.0       0.97      0.95      0.96      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.91      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[3431  121  194   24   17   17   10]
 [ 140 9813  751   55   41   56   13]
 [ 151  326 6287   59   38   25   10]
 [  61  121  157 2213   22    9    1]
 [  29   60   82   16 1419    8    3]
 [  18   38   60    6    3 3132    1]
 [  21   25   19    1    1    0 1305]]

===multilabel confusion matrix===

[[[26176   420]
  [  383  3431]]

 [[18850   691]
  [ 1056  9813]]

 [[22251  1263]
  [  609  6287]]

 [[27665   161]
  [  371  2213]]

 [[28671   122]
  [  198  1419]]

 [[27037   115]
  [  126  3132]]

 [[29000    38]
  [   67  1305]]]

===scores report===
metrics	scores
Accuracy	0.9076
MCC	0.8822
log_loss	0.3108
f1 score weighted	0.9080
f1 score macro	0.9142
f1 score micro	0.9076
roc_auc ovr	0.9888
roc_auc ovo	0.9904
precision	0.9098
recall	0.9076

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbef865c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbef865c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbef865c700>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbef865c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.89      0.90      3813
         1.0       0.94      0.92      0.93     10868
         2.0       0.88      0.91      0.90      6897
         3.0       0.89      0.89      0.89      2585
         4.0       0.87      0.90      0.89      1616
         5.0       0.96      0.95      0.96      3258
         6.0       0.98      0.96      0.97      1372

    accuracy                           0.92     30409
   macro avg       0.92      0.92      0.92     30409
weighted avg       0.92      0.92      0.92     30409


===confusion_matrix===

[[ 3392   134   169    62    30    11    15]
 [  134 10023   463   110    80    55     3]
 [  112   306  6295    90    56    33     5]
 [   40    88   114  2311    27     4     1]
 [   21    40    57    33  1455     9     1]
 [   26    51    52     3    23  3103     0]
 [   18    19    19     1     1     1  1313]]

===multilabel confusion matrix===

[[[26245   351]
  [  421  3392]]

 [[18903   638]
  [  845 10023]]

 [[22638   874]
  [  602  6295]]

 [[27525   299]
  [  274  2311]]

 [[28576   217]
  [  161  1455]]

 [[27038   113]
  [  155  3103]]

 [[29012    25]
  [   59  1313]]]

===scores report===
metrics	scores
Accuracy	0.9172
MCC	0.8943
log_loss	0.2955
f1 score weighted	0.9175
f1 score macro	0.9181
f1 score micro	0.9172
roc_auc ovr	0.9907
roc_auc ovo	0.9921
precision	0.9180
recall	0.9172

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbef865c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbef865c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbef865c700>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbef865c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.92      0.88      3813
         1.0       0.91      0.93      0.92     10868
         2.0       0.93      0.83      0.87      6897
         3.0       0.90      0.88      0.89      2585
         4.0       0.88      0.89      0.89      1616
         5.0       0.92      0.97      0.94      3258
         6.0       0.96      0.95      0.95      1372

    accuracy                           0.90     30409
   macro avg       0.90      0.91      0.91     30409
weighted avg       0.91      0.90      0.90     30409


===confusion_matrix===

[[ 3514   110    87    43    14    33    12]
 [  271 10115   225    80    58    93    26]
 [  244   611  5705   114    83   122    18]
 [   92    95    72  2279    28    17     2]
 [   42    64    32    21  1438    17     2]
 [   26    41    20     5     5  3160     1]
 [   13    28    19     0     2     6  1304]]

===multilabel confusion matrix===

[[[25908   688]
  [  299  3514]]

 [[18592   949]
  [  753 10115]]

 [[23057   455]
  [ 1192  5705]]

 [[27561   263]
  [  306  2279]]

 [[28603   190]
  [  178  1438]]

 [[26863   288]
  [   98  3160]]

 [[28976    61]
  [   68  1304]]]

===scores report===
metrics	scores
Accuracy	0.9048
MCC	0.8789
log_loss	0.3133
f1 score weighted	0.9045
f1 score macro	0.9063
f1 score micro	0.9048
roc_auc ovr	0.9889
roc_auc ovo	0.9910
precision	0.9061
recall	0.9048

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.918546530746465	0.8957537872581312	0.29041246961393297	0.918654463237857	0.9213093072166954	0.918546530746465	0.9910009244661231	0.9924557736633287	0.9192244774457904	0.918546530746465
1	0.8923051627754028	0.8623063880944704	0.339789686290663	0.8925136381239744	0.8948101919790601	0.8923051627754027	0.9864210929659232	0.9883336379236237	0.8952454491205829	0.8923051627754028
2	0.9075961854653075	0.8821505135619434	0.3108070841659914	0.9080405692768245	0.9142228091654132	0.9075961854653075	0.9887763528126732	0.9903752893535364	0.9098309577547881	0.9075961854653075
3	0.9172284521029959	0.8942693532820974	0.29548584497266145	0.9174509853134858	0.9180510418759216	0.9172284521029959	0.9906629576736405	0.9921018266520184	0.9179594671005546	0.9172284521029959
4	0.9048308066690782	0.8788573081980551	0.31329024953224166	0.9044582915231691	0.9062856557213651	0.9048308066690782	0.9888825565579147	0.9909940896378381	0.9060993323728784	0.9048308066690782
mean	0.9081014275518499	0.8826674700789393	0.30995706691509806	0.9082235894950621	0.910935801191691	0.9081014275518499	0.9891487768952549	0.990852123446069	0.909671936758919	0.9081014275518499
std	0.009517110583741656	0.012126117501916335	0.01728135042561978	0.009538988394241351	0.009494206907776175	0.009517110583741693	0.001635422064027536	0.0014644962683769908	0.008727502828337697	0.009517110583741656

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 68755.7723 secs

