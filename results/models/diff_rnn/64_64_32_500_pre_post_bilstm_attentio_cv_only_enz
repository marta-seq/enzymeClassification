/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_post_bilstm_attentio_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7feb8039c5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7feb8039c760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7feb8039c7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7feb8039c580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.84      0.88      3813
         1.0       0.94      0.86      0.90     10869
         2.0       0.79      0.93      0.85      6897
         3.0       0.91      0.85      0.88      2585
         4.0       0.80      0.91      0.85      1616
         5.0       0.95      0.96      0.96      3258
         6.0       0.98      0.95      0.97      1372

    accuracy                           0.89     30410
   macro avg       0.90      0.90      0.90     30410
weighted avg       0.90      0.89      0.89     30410


===confusion_matrix===

[[3217  146  303   37   67   33   10]
 [ 174 9374  995  105  140   75    6]
 [  68  267 6383   58   90   25    6]
 [  42   78  187 2206   56   16    0]
 [  17   32   71   16 1476    3    1]
 [  14   30   70    8   16 3120    0]
 [   7   19   32    4    1    4 1305]]

===multilabel confusion matrix===

[[[26275   322]
  [  596  3217]]

 [[18969   572]
  [ 1495  9374]]

 [[21855  1658]
  [  514  6383]]

 [[27597   228]
  [  379  2206]]

 [[28424   370]
  [  140  1476]]

 [[26996   156]
  [  138  3120]]

 [[29015    23]
  [   67  1305]]]

===scores report===
metrics	scores
Accuracy	0.8905
MCC	0.8619
log_loss	0.3458
f1 score weighted	0.8914
f1 score macro	0.8977
f1 score micro	0.8905
roc_auc ovr	0.9867
roc_auc ovo	0.9896
precision	0.8968
recall	0.8905

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7feb8039c5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7feb8039c760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7feb8039c7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7feb8039c580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.90      0.91      3813
         1.0       0.92      0.94      0.93     10869
         2.0       0.89      0.90      0.90      6897
         3.0       0.94      0.89      0.91      2585
         4.0       0.95      0.90      0.92      1616
         5.0       0.96      0.97      0.96      3258
         6.0       0.98      0.96      0.97      1372

    accuracy                           0.92     30410
   macro avg       0.94      0.92      0.93     30410
weighted avg       0.92      0.92      0.92     30410


===confusion_matrix===

[[ 3425   179   135    24    21    24     5]
 [  101 10241   406    49    14    51     7]
 [  114   425  6215    60    30    44     9]
 [   34   137   101  2293     9    10     1]
 [   32    53    67     6  1450     8     0]
 [   16    51    28     5     1  3155     2]
 [   15    12    21     2     0     1  1321]]

===multilabel confusion matrix===

[[[26285   312]
  [  388  3425]]

 [[18684   857]
  [  628 10241]]

 [[22755   758]
  [  682  6215]]

 [[27679   146]
  [  292  2293]]

 [[28719    75]
  [  166  1450]]

 [[27014   138]
  [  103  3155]]

 [[29014    24]
  [   51  1321]]]

===scores report===
metrics	scores
Accuracy	0.9240
MCC	0.9026
log_loss	0.2675
f1 score weighted	0.9240
f1 score macro	0.9297
f1 score micro	0.9240
roc_auc ovr	0.9918
roc_auc ovo	0.9931
precision	0.9243
recall	0.9240

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7feb8039c5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7feb8039c760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7feb8039c7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7feb8039c580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.87      0.88      3814
         1.0       0.92      0.91      0.91     10869
         2.0       0.82      0.91      0.86      6896
         3.0       0.97      0.79      0.87      2584
         4.0       0.97      0.84      0.90      1617
         5.0       0.95      0.96      0.95      3258
         6.0       0.97      0.96      0.97      1372

    accuracy                           0.90     30410
   macro avg       0.93      0.89      0.91     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[3335  153  276   10    6   23   11]
 [ 167 9874  718   14   10   76   10]
 [ 118  393 6298   16   13   46   12]
 [  81  214  225 2033    9   22    0]
 [  43   80  106   12 1361   13    2]
 [  13   61   49    0    1 3134    0]
 [  26   15   16    1    0    2 1312]]

===multilabel confusion matrix===

[[[26148   448]
  [  479  3335]]

 [[18625   916]
  [  995  9874]]

 [[22124  1390]
  [  598  6298]]

 [[27773    53]
  [  551  2033]]

 [[28754    39]
  [  256  1361]]

 [[26970   182]
  [  124  3134]]

 [[29003    35]
  [   60  1312]]]

===scores report===
metrics	scores
Accuracy	0.8993
MCC	0.8712
log_loss	0.3235
f1 score weighted	0.8995
f1 score macro	0.9064
f1 score micro	0.8993
roc_auc ovr	0.9872
roc_auc ovo	0.9891
precision	0.9031
recall	0.8993

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7feb8039c5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7feb8039c760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7feb8039c7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7feb8039c580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.96      0.79      0.87      3813
         1.0       0.90      0.93      0.92     10868
         2.0       0.82      0.92      0.87      6897
         3.0       0.94      0.86      0.90      2585
         4.0       0.95      0.85      0.90      1616
         5.0       0.97      0.95      0.96      3258
         6.0       0.98      0.95      0.97      1372

    accuracy                           0.90     30409
   macro avg       0.93      0.89      0.91     30409
weighted avg       0.91      0.90      0.90     30409


===confusion_matrix===

[[ 3010   322   387    40    16    28    10]
 [   33 10083   641    46    18    44     3]
 [   42   398  6367    39    20    23     8]
 [   19   145   181  2228    10     2     0]
 [   17   107    83    18  1378    12     1]
 [    6    65    73     4     3  3107     0]
 [    3    38    23     1     1     3  1303]]

===multilabel confusion matrix===

[[[26476   120]
  [  803  3010]]

 [[18466  1075]
  [  785 10083]]

 [[22124  1388]
  [  530  6367]]

 [[27676   148]
  [  357  2228]]

 [[28725    68]
  [  238  1378]]

 [[27039   112]
  [  151  3107]]

 [[29015    22]
  [   69  1303]]]

===scores report===
metrics	scores
Accuracy	0.9035
MCC	0.8765
log_loss	0.3359
f1 score weighted	0.9036
f1 score macro	0.9108
f1 score micro	0.9035
roc_auc ovr	0.9880
roc_auc ovo	0.9897
precision	0.9079
recall	0.9035

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7feb8039c5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7feb8039c760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7feb8039c7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7feb8039c580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.42      0.54      3813
         1.0       1.00      0.10      0.18     10868
         2.0       0.27      1.00      0.42      6897
         3.0       1.00      0.11      0.20      2585
         4.0       0.89      0.05      0.09      1616
         5.0       1.00      0.13      0.24      3258
         6.0       0.98      0.51      0.67      1372

    accuracy                           0.36     30409
   macro avg       0.84      0.33      0.33     30409
weighted avg       0.80      0.36      0.30     30409


===confusion_matrix===

[[1597    1 2209    0    0    1    5]
 [ 160 1047 9651    1    1    0    8]
 [  11    0 6885    0    0    0    1]
 [ 137    1 2151  292    4    0    0]
 [  27    0 1516    0   73    0    0]
 [ 120    0 2700    0    4  434    0]
 [  15    0  653    0    0    0  704]]

===multilabel confusion matrix===

[[[26126   470]
  [ 2216  1597]]

 [[19539     2]
  [ 9821  1047]]

 [[ 4632 18880]
  [   12  6885]]

 [[27823     1]
  [ 2293   292]]

 [[28784     9]
  [ 1543    73]]

 [[27150     1]
  [ 2824   434]]

 [[29023    14]
  [  668   704]]]

===scores report===
metrics	scores
Accuracy	0.3628
MCC	0.3151
log_loss	2.4689
f1 score weighted	0.3039
f1 score macro	0.3340
f1 score micro	0.3628
roc_auc ovr	0.8973
roc_auc ovo	0.8965
precision	0.7974
recall	0.3628

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.890529431108188	0.8619238149275631	0.34579219924989707	0.8914408479344136	0.8976926828307442	0.890529431108188	0.9867334373682	0.9896023755730304	0.8967748369040602	0.890529431108188
1	0.9240381453469253	0.9025612597704018	0.2675473901631364	0.9239913906990068	0.9296516045844125	0.9240381453469253	0.9917903865016378	0.9931293429802716	0.9242804974159258	0.9240381453469253
2	0.8992765537652088	0.8711593593162748	0.3234510733532416	0.8994969793636086	0.9064044859797491	0.8992765537652088	0.9871906167038098	0.9891382924159995	0.9031125513266701	0.8992765537652088
3	0.9035482916241903	0.8765134085640661	0.33592826153296407	0.9036234912857622	0.9108051391099129	0.9035482916241903	0.9879621118900883	0.9896619883483125	0.9078947003294524	0.9035482916241903
4	0.36278733269755664	0.31511721083673	2.468928093725086	0.3039279377588257	0.33401845151016296	0.36278733269755664	0.8973094671840648	0.896466871812811	0.7973585419494512	0.36278733269755664
mean	0.7960359509084138	0.7654550106830073	0.748329403604865	0.7844961294083234	0.7957144728029963	0.7960359509084138	0.9701972039295601	0.971599774226085	0.8858842255851119	0.7960359509084138
std	0.21690342101837692	0.22557298808211312	0.8607257048888491	0.2405237665623775	0.23108442922705463	0.21690342101837692	0.036487539654986245	0.0375936489591952	0.04519060073709073	0.21690342101837692

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 67250.3142 secs

