/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_post_lstm_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a4449c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4a4449c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a4449c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4a4449c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.84      0.85      3813
         1.0       0.84      0.95      0.89     10869
         2.0       0.87      0.82      0.84      6897
         3.0       0.94      0.81      0.87      2585
         4.0       0.98      0.78      0.87      1616
         5.0       0.99      0.93      0.96      3258
         6.0       0.96      0.95      0.95      1372

    accuracy                           0.88     30410
   macro avg       0.92      0.87      0.89     30410
weighted avg       0.89      0.88      0.88     30410


===confusion_matrix===

[[ 3220   359   187    25     6     2    14]
 [  166 10278   363    30     8     6    18]
 [  158   986  5672    38    10    15    18]
 [   83   252   152  2092     3     2     1]
 [   68   154   105    26  1259     4     0]
 [   24   142    61    14     2  3014     1]
 [   16    34    17     1     2     2  1300]]

===multilabel confusion matrix===

[[[26082   515]
  [  593  3220]]

 [[17614  1927]
  [  591 10278]]

 [[22628   885]
  [ 1225  5672]]

 [[27691   134]
  [  493  2092]]

 [[28763    31]
  [  357  1259]]

 [[27121    31]
  [  244  3014]]

 [[28986    52]
  [   72  1300]]]

===scores report===
metrics	scores
Accuracy	0.8824
MCC	0.8489
log_loss	0.3648
f1 score weighted	0.8821
f1 score macro	0.8906
f1 score micro	0.8824
roc_auc ovr	0.9832
roc_auc ovo	0.9856
precision	0.8864
recall	0.8824

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a4449c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4a4449c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a4449c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4a4449c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00      3813
         1.0       0.36      1.00      0.53     10869
         2.0       0.00      0.00      0.00      6897
         3.0       0.00      0.00      0.00      2585
         4.0       0.00      0.00      0.00      1616
         5.0       0.00      0.00      0.00      3258
         6.0       0.00      0.00      0.00      1372

    accuracy                           0.36     30410
   macro avg       0.05      0.14      0.08     30410
weighted avg       0.13      0.36      0.19     30410


===confusion_matrix===

[[    0  3813     0     0     0     0     0]
 [    0 10869     0     0     0     0     0]
 [    0  6897     0     0     0     0     0]
 [    0  2585     0     0     0     0     0]
 [    0  1616     0     0     0     0     0]
 [    0  3258     0     0     0     0     0]
 [    0  1372     0     0     0     0     0]]

===multilabel confusion matrix===

[[[26597     0]
  [ 3813     0]]

 [[    0 19541]
  [    0 10869]]

 [[23513     0]
  [ 6897     0]]

 [[27825     0]
  [ 2585     0]]

 [[28794     0]
  [ 1616     0]]

 [[27152     0]
  [ 3258     0]]

 [[29038     0]
  [ 1372     0]]]

===scores report===
metrics	scores
Accuracy	0.3574
MCC	0.0000
log_loss	1.7092
f1 score weighted	0.1882
f1 score macro	0.0752
f1 score micro	0.3574
roc_auc ovr	0.5000
roc_auc ovo	0.5000
precision	0.1277
recall	0.3574

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a4449c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4a4449c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a4449c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4a4449c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00      3814
         1.0       0.36      1.00      0.53     10869
         2.0       0.00      0.00      0.00      6896
         3.0       0.00      0.00      0.00      2584
         4.0       0.00      0.00      0.00      1617
         5.0       0.00      0.00      0.00      3258
         6.0       0.00      0.00      0.00      1372

    accuracy                           0.36     30410
   macro avg       0.05      0.14      0.08     30410
weighted avg       0.13      0.36      0.19     30410


===confusion_matrix===

[[    0  3814     0     0     0     0     0]
 [    0 10869     0     0     0     0     0]
 [    0  6896     0     0     0     0     0]
 [    0  2584     0     0     0     0     0]
 [    0  1617     0     0     0     0     0]
 [    0  3258     0     0     0     0     0]
 [    0  1372     0     0     0     0     0]]

===multilabel confusion matrix===

[[[26596     0]
  [ 3814     0]]

 [[    0 19541]
  [    0 10869]]

 [[23514     0]
  [ 6896     0]]

 [[27826     0]
  [ 2584     0]]

 [[28793     0]
  [ 1617     0]]

 [[27152     0]
  [ 3258     0]]

 [[29038     0]
  [ 1372     0]]]

===scores report===
metrics	scores
Accuracy	0.3574
MCC	0.0000
log_loss	1.7092
f1 score weighted	0.1882
f1 score macro	0.0752
f1 score micro	0.3574
roc_auc ovr	0.5000
roc_auc ovo	0.5000
precision	0.1277
recall	0.3574

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a4449c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4a4449c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a4449c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4a4449c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.85      0.83      3813
         1.0       0.90      0.86      0.88     10868
         2.0       0.86      0.81      0.83      6897
         3.0       0.79      0.85      0.82      2585
         4.0       0.75      0.82      0.79      1616
         5.0       0.89      0.96      0.92      3258
         6.0       0.89      0.96      0.92      1372

    accuracy                           0.86     30409
   macro avg       0.84      0.87      0.86     30409
weighted avg       0.86      0.86      0.86     30409


===confusion_matrix===

[[3226  150  189  104   29   92   23]
 [ 331 9387  520  237  135  157  101]
 [ 262  590 5588  163  180   86   28]
 [  94  106  107 2186   71   18    3]
 [  47   76   68   59 1332   32    2]
 [  19   57   26    8   28 3118    2]
 [  13   16   21    1    1    6 1314]]

===multilabel confusion matrix===

[[[25830   766]
  [  587  3226]]

 [[18546   995]
  [ 1481  9387]]

 [[22581   931]
  [ 1309  5588]]

 [[27252   572]
  [  399  2186]]

 [[28349   444]
  [  284  1332]]

 [[26760   391]
  [  140  3118]]

 [[28878   159]
  [   58  1314]]]

===scores report===
metrics	scores
Accuracy	0.8600
MCC	0.8225
log_loss	0.4246
f1 score weighted	0.8600
f1 score macro	0.8560
f1 score micro	0.8600
roc_auc ovr	0.9790
roc_auc ovo	0.9825
precision	0.8616
recall	0.8600

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a4449c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4a4449c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a4449c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4a4449c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.67      0.64      0.65      3813
         1.0       0.74      0.83      0.79     10868
         2.0       0.65      0.77      0.70      6897
         3.0       0.72      0.46      0.56      2585
         4.0       1.00      0.00      0.00      1616
         5.0       0.75      0.86      0.80      3258
         6.0       0.94      0.74      0.83      1372

    accuracy                           0.72     30409
   macro avg       0.78      0.61      0.62     30409
weighted avg       0.73      0.72      0.69     30409


===confusion_matrix===

[[2425  593  604   84    0   96   11]
 [ 353 9024 1152   93    0  211   35]
 [ 232 1168 5308   52    0  124   13]
 [ 354  532  385 1185    0  129    0]
 [ 204  435  390  215    1  371    0]
 [  51  203  172   14    0 2818    0]
 [  16  163  157    3    0   22 1011]]

===multilabel confusion matrix===

[[[25386  1210]
  [ 1388  2425]]

 [[16447  3094]
  [ 1844  9024]]

 [[20652  2860]
  [ 1589  5308]]

 [[27363   461]
  [ 1400  1185]]

 [[28793     0]
  [ 1615     1]]

 [[26198   953]
  [  440  2818]]

 [[28978    59]
  [  361  1011]]]

===scores report===
metrics	scores
Accuracy	0.7160
MCC	0.6308
log_loss	0.8183
f1 score weighted	0.6930
f1 score macro	0.6189
f1 score micro	0.7160
roc_auc ovr	0.9251
roc_auc ovo	0.9234
precision	0.7342
recall	0.7160

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8824399868464321	0.8489300918385593	0.3647633435966827	0.8821194386247393	0.8906076860109075	0.8824399868464321	0.9832132078790897	0.9856090144028243	0.8864488051182967	0.8824399868464321
1	0.3574153239066097	0.0	1.7091780330859607	0.18821905354010227	0.07523022775330244	0.3574153239066097	0.5	0.5	0.1277457137632667	0.3574153239066097
2	0.3574153239066097	0.0	1.7092135186220463	0.18821905354010227	0.07523022775330244	0.3574153239066097	0.5	0.5	0.1277457137632667	0.3574153239066097
3	0.8599756650991482	0.8225258227823448	0.42463213555575713	0.8600491354077109	0.8560097374325613	0.8599756650991482	0.9789852157505624	0.9825003021283746	0.8615717800965613	0.8599756650991482
4	0.7159722450590286	0.6308029821656516	0.8183307510445158	0.6930431739071083	0.6188934012013697	0.7159722450590286	0.9251154083497215	0.9234186309078165	0.7342215111653873	0.7159722450590286
mean	0.6346437089635656	0.4604517793573111	1.0052235563809924	0.5623299710039527	0.5031942560302887	0.6346437089635656	0.7774627663958747	0.7783055894878032	0.5475467047813557	0.6346437089635656
std	0.2334536234606341	0.38342254151661653	0.5955431764349673	0.31237986586812777	0.3617348865779783	0.2334536234606341	0.22747176436318636	0.22831381373992116	0.34663514218773767	0.2334536234606341

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 32968.8866 secs

