/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_middle_lstm_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f65d879c1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f65d879c7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f65d879c850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f65d879c610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00      3813
         1.0       0.36      1.00      0.53     10869
         2.0       0.00      0.00      0.00      6897
         3.0       0.00      0.00      0.00      2585
         4.0       0.00      0.00      0.00      1616
         5.0       0.00      0.00      0.00      3258
         6.0       0.00      0.00      0.00      1372

    accuracy                           0.36     30410
   macro avg       0.05      0.14      0.08     30410
weighted avg       0.13      0.36      0.19     30410


===confusion_matrix===

[[    0  3813     0     0     0     0     0]
 [    0 10869     0     0     0     0     0]
 [    0  6897     0     0     0     0     0]
 [    0  2585     0     0     0     0     0]
 [    0  1616     0     0     0     0     0]
 [    0  3258     0     0     0     0     0]
 [    0  1372     0     0     0     0     0]]

===multilabel confusion matrix===

[[[26597     0]
  [ 3813     0]]

 [[    0 19541]
  [    0 10869]]

 [[23513     0]
  [ 6897     0]]

 [[27825     0]
  [ 2585     0]]

 [[28794     0]
  [ 1616     0]]

 [[27152     0]
  [ 3258     0]]

 [[29038     0]
  [ 1372     0]]]

===scores report===
metrics	scores
Accuracy	0.3574
MCC	0.0000
log_loss	1.7092
f1 score weighted	0.1882
f1 score macro	0.0752
f1 score micro	0.3574
roc_auc ovr	0.5000
roc_auc ovo	0.5000
precision	0.1277
recall	0.3574

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f65d879c1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f65d879c7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f65d879c850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f65d879c610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.81      0.81      3813
         1.0       0.85      0.90      0.88     10869
         2.0       0.82      0.83      0.82      6897
         3.0       0.91      0.78      0.84      2585
         4.0       0.92      0.74      0.82      1616
         5.0       0.94      0.93      0.94      3258
         6.0       0.98      0.94      0.96      1372

    accuracy                           0.86     30410
   macro avg       0.89      0.85      0.87     30410
weighted avg       0.86      0.86      0.86     30410


===confusion_matrix===

[[3077  351  256   60   20   42    7]
 [ 247 9823  626   75   38   53    7]
 [ 229  836 5719   38   21   41   13]
 [ 111  252  186 2012   13   10    1]
 [  73  145  141   29 1200   28    0]
 [  34  128   40    6    8 3041    1]
 [  13   31   32    1    0    3 1292]]

===multilabel confusion matrix===

[[[25890   707]
  [  736  3077]]

 [[17798  1743]
  [ 1046  9823]]

 [[22232  1281]
  [ 1178  5719]]

 [[27616   209]
  [  573  2012]]

 [[28694   100]
  [  416  1200]]

 [[26975   177]
  [  217  3041]]

 [[29009    29]
  [   80  1292]]]

===scores report===
metrics	scores
Accuracy	0.8604
MCC	0.8202
log_loss	0.4140
f1 score weighted	0.8600
f1 score macro	0.8668
f1 score micro	0.8604
roc_auc ovr	0.9766
roc_auc ovo	0.9797
precision	0.8622
recall	0.8604

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f65d879c1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f65d879c7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f65d879c850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f65d879c610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00      3814
         1.0       0.38      0.95      0.54     10869
         2.0       0.00      0.00      0.00      6896
         3.0       0.00      0.00      0.00      2584
         4.0       0.00      0.00      0.00      1617
         5.0       0.42      0.35      0.39      3258
         6.0       0.84      0.15      0.25      1372

    accuracy                           0.38     30410
   macro avg       0.23      0.21      0.17     30410
weighted avg       0.22      0.38      0.25     30410


===confusion_matrix===

[[    0  3647     0     0     0   165     2]
 [    0 10349     0     0     0   497    23]
 [    0  6391     0     0     0   491    14]
 [    0  2491     0     0     0    93     0]
 [    0  1393     0     0     0   224     0]
 [    0  2109     0     0     0  1149     0]
 [    0  1080     0     0     0    89   203]]

===multilabel confusion matrix===

[[[26596     0]
  [ 3814     0]]

 [[ 2430 17111]
  [  520 10349]]

 [[23514     0]
  [ 6896     0]]

 [[27826     0]
  [ 2584     0]]

 [[28793     0]
  [ 1617     0]]

 [[25593  1559]
  [ 2109  1149]]

 [[28999    39]
  [ 1169   203]]]

===scores report===
metrics	scores
Accuracy	0.3848
MCC	0.1403
log_loss	1.6114
f1 score weighted	0.2456
f1 score macro	0.1681
f1 score micro	0.3848
roc_auc ovr	0.6074
roc_auc ovo	0.6189
precision	0.2180
recall	0.3848

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f65d879c1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f65d879c7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f65d879c850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f65d879c610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.76      0.84      3813
         1.0       0.85      0.93      0.89     10868
         2.0       0.90      0.75      0.82      6897
         3.0       0.91      0.80      0.85      2585
         4.0       0.72      0.85      0.78      1616
         5.0       0.80      0.97      0.88      3258
         6.0       0.91      0.97      0.94      1372

    accuracy                           0.86     30409
   macro avg       0.86      0.86      0.86     30409
weighted avg       0.86      0.86      0.86     30409


===confusion_matrix===

[[ 2910   424   160    45   108   145    21]
 [   78 10103   220    65   115   236    51]
 [   89  1014  5176    80   194   296    48]
 [   40   226   110  2071    88    49     1]
 [   16   106    57    16  1373    46     2]
 [    7    59    23     4    16  3147     2]
 [    8    21    12     0     3     2  1326]]

===multilabel confusion matrix===

[[[26358   238]
  [  903  2910]]

 [[17691  1850]
  [  765 10103]]

 [[22930   582]
  [ 1721  5176]]

 [[27614   210]
  [  514  2071]]

 [[28269   524]
  [  243  1373]]

 [[26377   774]
  [  111  3147]]

 [[28912   125]
  [   46  1326]]]

===scores report===
metrics	scores
Accuracy	0.8585
MCC	0.8201
log_loss	0.4397
f1 score weighted	0.8570
f1 score macro	0.8555
f1 score micro	0.8585
roc_auc ovr	0.9794
roc_auc ovo	0.9829
precision	0.8647
recall	0.8585

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f65d879c1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f65d879c7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f65d879c850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f65d879c610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.71      0.90      0.79      3813
         1.0       0.85      0.91      0.88     10868
         2.0       0.94      0.66      0.77      6897
         3.0       0.87      0.80      0.83      2585
         4.0       0.86      0.82      0.84      1616
         5.0       0.79      0.97      0.87      3258
         6.0       0.98      0.91      0.95      1372

    accuracy                           0.84     30409
   macro avg       0.86      0.85      0.85     30409
weighted avg       0.86      0.84      0.84     30409


===confusion_matrix===

[[3436  188   39   34   14   95    7]
 [ 448 9854  135   81   57  286    7]
 [ 646 1131 4522  162   97  332    7]
 [ 190  171   54 2060   37   72    1]
 [  61  115   31   27 1319   63    0]
 [  32   38    6    3    7 3172    0]
 [  30   37   23   11    6   13 1252]]

===multilabel confusion matrix===

[[[25189  1407]
  [  377  3436]]

 [[17861  1680]
  [ 1014  9854]]

 [[23224   288]
  [ 2375  4522]]

 [[27506   318]
  [  525  2060]]

 [[28575   218]
  [  297  1319]]

 [[26290   861]
  [   86  3172]]

 [[29015    22]
  [  120  1252]]]

===scores report===
metrics	scores
Accuracy	0.8423
MCC	0.8023
log_loss	0.4934
f1 score weighted	0.8401
f1 score macro	0.8471
f1 score micro	0.8423
roc_auc ovr	0.9775
roc_auc ovo	0.9815
precision	0.8554
recall	0.8423

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.3574153239066097	0.0	1.709178505701205	0.18821905354010227	0.07523022775330244	0.3574153239066097	0.5	0.5	0.1277457137632667	0.3574153239066097
1	0.8603748766853009	0.8201749032729091	0.41396078011196624	0.8600414519796237	0.8668305587801765	0.8603748766853009	0.9765756921998101	0.9796920046273637	0.8622357226727845	0.8603748766853009
2	0.38477474514962184	0.14031987037387317	1.6114397392132898	0.245623374289442	0.16810578846601212	0.38477474514962184	0.607438603545203	0.6189335684013264	0.2180044719166771	0.38477474514962184
3	0.8584958400473544	0.8201371441681261	0.43965835522865415	0.8570272503457249	0.855506632411818	0.8584958400473544	0.9793581277282414	0.9828844731833545	0.8647386749753685	0.8584958400473544
4	0.8423493044822257	0.8023136676570833	0.49339045127425046	0.8401292570212617	0.8470609718331845	0.8423493044822257	0.9774724527315456	0.9814762895050695	0.8553770520899904	0.8423493044822257
mean	0.6606820180542224	0.5165891170943984	0.9335255663058731	0.598208077435231	0.5625468358488988	0.6606820180542224	0.80816897524096	0.812597267143423	0.5856203270836174	0.6606820180542224
std	0.2366880055848931	0.3672566173759778	0.5947733041983602	0.3119220768174505	0.36122667022364113	0.2366880055848931	0.21051888996418222	0.21007674200898335	0.33822548643954004	0.2366880055848931

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 30711.9572 secs

