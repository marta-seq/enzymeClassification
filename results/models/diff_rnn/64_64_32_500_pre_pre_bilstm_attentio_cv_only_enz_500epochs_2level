/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_2level
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb4fe835c10>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb4fe8359a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb4fe835bb0>]/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_2level
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f217434e520>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f217434e790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f217434e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f217434e4f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.93      0.89       911
         1.0       0.95      0.66      0.78        53
         2.0       0.91      0.83      0.87       179
         3.0       0.67      0.40      0.50        25
         4.0       0.72      0.66      0.69       112
         5.0       0.85      0.79      0.82       491
         6.0       0.91      0.81      0.86        64
         7.0       0.88      0.62      0.73        37
         8.0       0.90      0.89      0.89       206
         9.0       0.98      0.89      0.93        71
        10.0       0.94      0.93      0.94       404
        11.0       0.73      0.69      0.71        16
        12.0       0.81      0.83      0.82       378
        13.0       0.85      0.84      0.85       191
        14.0       0.67      0.37      0.47        76
        15.0       0.84      0.82      0.83        66
        16.0       0.92      0.86      0.89       141
        17.0       0.89      0.82      0.85       182
        18.0       0.91      0.83      0.87        12
        19.0       0.89      0.89      0.89        38
        20.0       0.93      0.94      0.94      2162
        21.0       0.95      0.96      0.95       168
        22.0       0.86      0.87      0.86      1470
        23.0       0.90      0.90      0.90      1259
        24.0       0.93      0.92      0.92       956
        25.0       0.95      0.93      0.94       283
        26.0       0.91      0.93      0.92      3919
        27.0       0.96      0.92      0.94       531
        28.0       1.00      0.67      0.80        12
        29.0       0.81      0.83      0.82      2345
        30.0       0.70      0.82      0.76       615
        31.0       0.95      0.66      0.78        32
        32.0       0.82      0.82      0.82      1449
        33.0       0.88      0.87      0.87       893
        34.0       0.93      0.90      0.92      1377
        35.0       1.00      0.68      0.81        22
        36.0       0.86      0.89      0.88       844
        37.0       0.92      0.90      0.91      1142
        38.0       0.96      0.90      0.93       314
        39.0       0.93      0.68      0.78        56
        40.0       0.94      0.81      0.87       154
        41.0       0.96      0.87      0.91        52
        42.0       0.89      0.79      0.84       247
        43.0       0.94      0.84      0.89       198
        44.0       0.92      0.94      0.93       529
        45.0       0.94      0.90      0.92       540
        46.0       0.90      0.45      0.60        20
        47.0       0.84      0.76      0.80        80
        48.0       0.97      0.99      0.98      1466
        49.0       0.96      0.89      0.93       148
        50.0       0.94      0.97      0.95      1453
        51.0       0.75      0.25      0.38        12
        52.0       0.94      0.94      0.94       151
        53.0       0.97      0.96      0.97       903
        54.0       0.94      0.90      0.92       108
        55.0       0.97      0.97      0.97        93
        56.0       1.00      0.94      0.97        33
        57.0       0.88      0.88      0.88        49
        58.0       0.91      0.95      0.93       154

    accuracy                           0.90     29892
   macro avg       0.89      0.82      0.85     29892
weighted avg       0.90      0.90      0.89     29892


===confusion_matrix===

[[850   0   0 ...   0   0   0]
 [  0  35   0 ...   0   0   0]
 [  2   0 148 ...   0   0   0]
 ...
 [  0   0   0 ...  31   1   0]
 [  0   0   0 ...   0  43   5]
 [  0   0   0 ...   0   5 146]]

===multilabel confusion matrix===

[[[28834   147]
  [   61   850]]

 [[29837     2]
  [   18    35]]

 [[29699    14]
  [   31   148]]

 [[29862     5]
  [   15    10]]

 [[29751    29]
  [   38    74]]

 [[29333    68]
  [  105   386]]

 [[29823     5]
  [   12    52]]

 [[29852     3]
  [   14    23]]

 [[29666    20]
  [   23   183]]

 [[29820     1]
  [    8    63]]

 [[29464    24]
  [   28   376]]

 [[29872     4]
  [    5    11]]

 [[29439    75]
  [   66   312]]

 [[29673    28]
  [   30   161]]

 [[29802    14]
  [   48    28]]

 [[29816    10]
  [   12    54]]

 [[29740    11]
  [   20   121]]

 [[29691    19]
  [   32   150]]

 [[29879     1]
  [    2    10]]

 [[29850     4]
  [    4    34]]

 [[27581   149]
  [  120  2042]]

 [[29715     9]
  [    7   161]]

 [[28215   207]
  [  194  1276]]

 [[28507   126]
  [  132  1127]]

 [[28868    68]
  [   76   880]]

 [[29596    13]
  [   20   263]]

 [[25604   369]
  [  292  3627]]

 [[29338    23]
  [   41   490]]

 [[29880     0]
  [    4     8]]

 [[27093   454]
  [  387  1958]]

 [[29059   218]
  [  109   506]]

 [[29859     1]
  [   11    21]]

 [[28179   264]
  [  255  1194]]

 [[28889   110]
  [  116   777]]

 [[28429    86]
  [  143  1234]]

 [[29870     0]
  [    7    15]]

 [[28923   125]
  [   89   755]]

 [[28664    86]
  [  114  1028]]

 [[29565    13]
  [   31   283]]

 [[29833     3]
  [   18    38]]

 [[29730     8]
  [   29   125]]

 [[29838     2]
  [    7    45]]

 [[29622    23]
  [   52   195]]

 [[29683    11]
  [   32   166]]

 [[29321    42]
  [   31   498]]

 [[29323    29]
  [   55   485]]

 [[29871     1]
  [   11     9]]

 [[29800    12]
  [   19    61]]

 [[28388    38]
  [   16  1450]]

 [[29739     5]
  [   16   132]]

 [[28352    87]
  [   48  1405]]

 [[29879     1]
  [    9     3]]

 [[29732     9]
  [    9   142]]

 [[28961    28]
  [   32   871]]

 [[29778     6]
  [   11    97]]

 [[29796     3]
  [    3    90]]

 [[29859     0]
  [    2    31]]

 [[29837     6]
  [    6    43]]

 [[29723    15]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8952
MCC	0.8895
log_loss	0.4900
f1 score weighted	0.8948
f1 score macro	0.8489
f1 score micro	0.8952
roc_auc ovr	0.9946
roc_auc ovo	0.9932
precision	0.8961
recall	0.8952

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f217434e520>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f217434e790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f217434e730>]