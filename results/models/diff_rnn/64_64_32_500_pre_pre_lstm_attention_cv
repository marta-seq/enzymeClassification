/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_lstm_attention_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f075455c460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f075455c6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f075455c640>]/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_lstm_attention_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9b547e0460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9b547e06a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9b547e0640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9b547e0430>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.79      0.75      4541
         1.0       0.80      0.87      0.83      3813
         2.0       0.90      0.85      0.87     10869
         3.0       0.82      0.80      0.81      6897
         4.0       0.83      0.85      0.84      2585
         5.0       0.88      0.81      0.84      1617
         6.0       0.96      0.93      0.95      3258
         7.0       0.82      0.97      0.89      1372

    accuracy                           0.84     34952
   macro avg       0.84      0.86      0.85     34952
weighted avg       0.85      0.84      0.84     34952


===confusion_matrix===

[[3588  126  245  377   47   38    9  111]
 [ 102 3305  130  133   73   21   13   36]
 [ 613  317 9199  420  150   47   42   81]
 [ 538  231  380 5531   98   42   32   45]
 [  51   69  111  119 2195   25   10    5]
 [  70   56   66   62   46 1305    6    6]
 [  33   43   57   57   22    7 3036    3]
 [  18    9    2    8    5    0    0 1330]]

===multilabel confusion matrix===

[[[28986  1425]
  [  953  3588]]

 [[30288   851]
  [  508  3305]]

 [[23092   991]
  [ 1670  9199]]

 [[26879  1176]
  [ 1366  5531]]

 [[31926   441]
  [  390  2195]]

 [[33155   180]
  [  312  1305]]

 [[31582   112]
  [  222  3036]]

 [[33293   287]
  [   42  1330]]]

===scores report===
metrics	scores
Accuracy	0.8437
MCC	0.8103
log_loss	0.4782
f1 score weighted	0.8446
f1 score macro	0.8484
f1 score micro	0.8437
roc_auc ovr	0.9754
roc_auc ovo	0.9798
precision	0.8476
recall	0.8437

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9b547e0460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9b547e06a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9b547e0640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9b547e0430>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.61      0.70      4541
         1.0       0.86      0.80      0.83      3813
         2.0       0.70      0.95      0.81     10869
         3.0       0.84      0.72      0.77      6897
         4.0       0.95      0.75      0.83      2585
         5.0       0.97      0.70      0.82      1616
         6.0       0.99      0.84      0.91      3258
         7.0       0.97      0.92      0.95      1372

    accuracy                           0.81     34951
   macro avg       0.89      0.79      0.83     34951
weighted avg       0.83      0.81      0.81     34951


===confusion_matrix===

[[ 2782    91  1158   443    20    22     3    22]
 [   70  3037   556   117    20     1     3     9]
 [  217    82 10363   189    10     2     3     3]
 [  219   141  1528  4953    43     4     5     4]
 [   43    66   447    95  1927     1     6     0]
 [   47    53   312    48    16  1138     2     0]
 [   13    36   437    21     1     0  2750     0]
 [   33     9    38    20     2     1     0  1269]]

===multilabel confusion matrix===

[[[29768   642]
  [ 1759  2782]]

 [[30660   478]
  [  776  3037]]

 [[19606  4476]
  [  506 10363]]

 [[27121   933]
  [ 1944  4953]]

 [[32254   112]
  [  658  1927]]

 [[33304    31]
  [  478  1138]]

 [[31671    22]
  [  508  2750]]

 [[33541    38]
  [  103  1269]]]

===scores report===
metrics	scores
Accuracy	0.8074
MCC	0.7661
log_loss	0.6127
f1 score weighted	0.8065
f1 score macro	0.8273
f1 score micro	0.8074
roc_auc ovr	0.9702
roc_auc ovo	0.9735
precision	0.8286
recall	0.8074

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9b547e0460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9b547e06a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9b547e0640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9b547e0430>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.69      0.74      4542
         1.0       0.86      0.79      0.82      3814
         2.0       0.79      0.93      0.85     10869
         3.0       0.85      0.75      0.80      6896
         4.0       0.90      0.80      0.85      2584
         5.0       0.95      0.78      0.86      1616
         6.0       0.90      0.95      0.93      3258
         7.0       0.91      0.96      0.93      1372

    accuracy                           0.84     34951
   macro avg       0.87      0.83      0.85     34951
weighted avg       0.84      0.84      0.83     34951


===confusion_matrix===

[[ 3144   130   748   378    33    12    41    56]
 [   69  3022   478   112    44    14    52    23]
 [  279   106 10108   233    56     6    66    15]
 [  361   176   956  5189    67    19   105    23]
 [   52    41   267   111  2070    11    31     1]
 [   61    34   142    56    30  1259    27     7]
 [   14    12   110    21     8     1  3090     2]
 [   26     5    17     7     1     1     3  1312]]

===multilabel confusion matrix===

[[[29547   862]
  [ 1398  3144]]

 [[30633   504]
  [  792  3022]]

 [[21364  2718]
  [  761 10108]]

 [[27137   918]
  [ 1707  5189]]

 [[32128   239]
  [  514  2070]]

 [[33271    64]
  [  357  1259]]

 [[31368   325]
  [  168  3090]]

 [[33452   127]
  [   60  1312]]]

===scores report===
metrics	scores
Accuracy	0.8353
MCC	0.7983
log_loss	0.5032
f1 score weighted	0.8334
f1 score macro	0.8466
f1 score micro	0.8353
roc_auc ovr	0.9746
roc_auc ovo	0.9785
precision	0.8387
recall	0.8353

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9b547e0460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9b547e06a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9b547e0640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9b547e0430>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.80      0.76      4542
         1.0       0.84      0.86      0.85      3813
         2.0       0.92      0.86      0.89     10868
         3.0       0.81      0.84      0.82      6897
         4.0       0.89      0.86      0.87      2585
         5.0       0.93      0.81      0.87      1616
         6.0       0.91      0.95      0.93      3258
         7.0       0.95      0.95      0.95      1372

    accuracy                           0.86     34951
   macro avg       0.87      0.87      0.87     34951
weighted avg       0.86      0.86      0.86     34951


===confusion_matrix===

[[3633  109  241  441   36   18   27   37]
 [  98 3276  134  203   40    9   40   13]
 [ 582  222 9357  456   96   24  126    5]
 [ 498  138  274 5791   63   30   94    9]
 [  62   68   92  135 2212   10    5    1]
 [  61   45   62   83   34 1317   14    0]
 [  39   19   28   52    7    2 3110    1]
 [  31    7    4   18    1    1    1 1309]]

===multilabel confusion matrix===

[[[29038  1371]
  [  909  3633]]

 [[30530   608]
  [  537  3276]]

 [[23248   835]
  [ 1511  9357]]

 [[26666  1388]
  [ 1106  5791]]

 [[32089   277]
  [  373  2212]]

 [[33241    94]
  [  299  1317]]

 [[31386   307]
  [  148  3110]]

 [[33513    66]
  [   63  1309]]]

===scores report===
metrics	scores
Accuracy	0.8585
MCC	0.8278
log_loss	0.4301
f1 score weighted	0.8595
f1 score macro	0.8688
f1 score micro	0.8585
roc_auc ovr	0.9798
roc_auc ovo	0.9832
precision	0.8621
recall	0.8585

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9b547e0460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9b547e06a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9b547e0640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9b547e0430>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.68      0.71      4542
         1.0       0.96      0.63      0.76      3813
         2.0       0.69      0.95      0.80     10868
         3.0       0.87      0.71      0.78      6897
         4.0       0.96      0.71      0.81      2585
         5.0       0.95      0.77      0.85      1616
         6.0       0.97      0.91      0.94      3258
         7.0       0.89      0.95      0.92      1372

    accuracy                           0.80     34951
   macro avg       0.88      0.79      0.82     34951
weighted avg       0.83      0.80      0.80     34951


===confusion_matrix===

[[ 3076    30  1093   239     4    17     6    77]
 [  116  2418  1027   149    31    24    22    26]
 [  278    11 10365   152    14     2    15    31]
 [  455    34  1436  4881    25    13    33    20]
 [   82    20   538    94  1831    10     8     2]
 [   87     5   237    28     3  1247     6     3]
 [   30     6   229    27     1     0  2962     3]
 [   18     1    34    13     0     0     1  1305]]

===multilabel confusion matrix===

[[[29343  1066]
  [ 1466  3076]]

 [[31031   107]
  [ 1395  2418]]

 [[19489  4594]
  [  503 10365]]

 [[27352   702]
  [ 2016  4881]]

 [[32288    78]
  [  754  1831]]

 [[33269    66]
  [  369  1247]]

 [[31602    91]
  [  296  2962]]

 [[33417   162]
  [   67  1305]]]

===scores report===
metrics	scores
Accuracy	0.8036
MCC	0.7621
log_loss	0.5933
f1 score weighted	0.8025
f1 score macro	0.8226
f1 score micro	0.8036
roc_auc ovr	0.9720
roc_auc ovo	0.9757
precision	0.8292
recall	0.8036

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8436999313344015	0.8102646904835907	0.4781765839663978	0.8446024192615639	0.8484207459953982	0.8436999313344015	0.9754465498569435	0.9798494446960504	0.8476241724612158	0.8436999313344015
1	0.8073874853366141	0.766063546346386	0.612724334764056	0.8064626306504055	0.8273453285919243	0.8073874853366141	0.9702426989142089	0.9734635703872901	0.8285511675966194	0.8073874853366141
2	0.8352836828703042	0.7982891049167725	0.5031539424438872	0.833384668135482	0.8465999619193604	0.8352836828703042	0.9746222212604596	0.9784657555314143	0.8386548947063645	0.8352836828703042
3	0.8584875969214043	0.8278274451253981	0.43007043559940134	0.8594551597601955	0.8688449411419601	0.8584875969214043	0.9797645033548943	0.9832303876420336	0.8621190153081544	0.8584875969214043
4	0.8035535463935224	0.762090993169002	0.5933183657541198	0.8024701567334737	0.8225839567863513	0.8035535463935224	0.9720478426930523	0.9756943467039033	0.8291652037221717	0.8035535463935224
mean	0.8296824485712493	0.7929071560082298	0.5234887325055724	0.829275006908224	0.8427589868869989	0.8296824485712493	0.9744247632159115	0.9781407009921385	0.841222890758905	0.8296824485712493
std	0.02115365280423016	0.025376726506605895	0.06932942099714878	0.02191604441700008	0.016564409536062863	0.02115365280423016	0.0032476229881738586	0.0033701802827640825	0.012571232373266803	0.02115365280423016

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 38083.7224 secs

