/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attention_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa3cc25c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa3cc25c1c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa3cc25c760>]/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attention_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f10a6d67b80>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f10a6d679d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f10a6d67be0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa3cc25c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.90      0.87      3813
         1.0       0.96      0.87      0.91     10869
         2.0       0.80      0.93      0.86      6897
         3.0       0.94      0.85      0.89      2585
         4.0       0.94      0.85      0.89      1616
         5.0       0.92      0.96      0.94      3258
         6.0       0.98      0.96      0.97      1372

    accuracy                           0.90     30410
   macro avg       0.91      0.90      0.91     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[3415   76  250   23   19   25    5]
 [ 285 9426  935   53   25  133   12]
 [ 154  195 6398   37   20   82   11]
 [  78   93  182 2196   21   15    0]
 [  36   46  121   12 1380   20    1]
 [  28   24   53    7    3 3143    0]
 [  16    6   27    0    0    2 1321]]

===multilabel confusion matrix===

[[[26000   597]
  [  398  3415]]

 [[19101   440]
  [ 1443  9426]]

 [[21945  1568]
  [  499  6398]]

 [[27693   132]
  [  389  2196]]

 [[28706    88]
  [  236  1380]]

 [[26875   277]
  [  115  3143]]

 [[29009    29]
  [   51  1321]]]

===scores report===
metrics	scores
Accuracy	0.8970
MCC	0.8702
log_loss	0.3374
f1 score weighted	0.8978
f1 score macro	0.9063
f1 score micro	0.8970
roc_auc ovr	0.9879
roc_auc ovo	0.9901
precision	0.9031
recall	0.8970

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa3cc25c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa3cc25c1c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa3cc25c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa3cc25c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.91      0.88      3813
         1.0       0.90      0.94      0.92     10869
         2.0       0.89      0.87      0.88      6897
         3.0       0.96      0.85      0.90      2585
         4.0       0.96      0.87      0.91      1616
         5.0       0.97      0.94      0.96      3258
         6.0       0.97      0.96      0.96      1372

    accuracy                           0.91     30410
   macro avg       0.93      0.91      0.92     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3463   168   144    17     8     7     6]
 [  212 10200   372    32    21    26     6]
 [  213   566  6011    24    20    36    27]
 [   74   165   130  2204     5     5     2]
 [   50    86    67     7  1399     6     1]
 [   44    90    44     2     2  3076     0]
 [   20    21    13     1     1     0  1316]]

===multilabel confusion matrix===

[[[25984   613]
  [  350  3463]]

 [[18445  1096]
  [  669 10200]]

 [[22743   770]
  [  886  6011]]

 [[27742    83]
  [  381  2204]]

 [[28737    57]
  [  217  1399]]

 [[27072    80]
  [  182  3076]]

 [[28996    42]
  [   56  1316]]]

===scores report===
metrics	scores
Accuracy	0.9099
MCC	0.8844
log_loss	0.2961
f1 score weighted	0.9099
f1 score macro	0.9166
f1 score micro	0.9099
roc_auc ovr	0.9891
roc_auc ovo	0.9910
precision	0.9114
recall	0.9099

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa3cc25c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa3cc25c1c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa3cc25c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa3cc25c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.91      0.85      3814
         1.0       0.87      0.95      0.90     10869
         2.0       0.92      0.80      0.86      6896
         3.0       0.97      0.79      0.87      2584
         4.0       0.99      0.69      0.82      1617
         5.0       0.86      0.97      0.91      3258
         6.0       0.98      0.93      0.95      1372

    accuracy                           0.88     30410
   macro avg       0.91      0.86      0.88     30410
weighted avg       0.89      0.88      0.88     30410


===confusion_matrix===

[[ 3461   210    71     9     0    55     8]
 [  201 10285   196    17     1   165     4]
 [  365   820  5532    29     3   138     9]
 [  116   258    99  2034     2    73     2]
 [  116   205    98     4  1117    76     1]
 [   18    47    20     1     0  3172     0]
 [   20    52    20     1     0     4  1275]]

===multilabel confusion matrix===

[[[25760   836]
  [  353  3461]]

 [[17949  1592]
  [  584 10285]]

 [[23010   504]
  [ 1364  5532]]

 [[27765    61]
  [  550  2034]]

 [[28787     6]
  [  500  1117]]

 [[26641   511]
  [   86  3172]]

 [[29014    24]
  [   97  1275]]]

===scores report===
metrics	scores
Accuracy	0.8838
MCC	0.8517
log_loss	0.4073
f1 score weighted	0.8825
f1 score macro	0.8810
f1 score micro	0.8838
roc_auc ovr	0.9855
roc_auc ovo	0.9872
precision	0.8903
recall	0.8838

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa3cc25c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa3cc25c1c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa3cc25c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa3cc25c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.94      0.82      3813
         1.0       0.93      0.91      0.92     10868
         2.0       0.91      0.83      0.87      6897
         3.0       0.93      0.86      0.89      2585
         4.0       0.89      0.87      0.88      1616
         5.0       0.94      0.96      0.95      3258
         6.0       0.97      0.96      0.96      1372

    accuracy                           0.90     30409
   macro avg       0.90      0.90      0.90     30409
weighted avg       0.90      0.90      0.90     30409


===confusion_matrix===

[[3568   96   71   27   19   21   11]
 [ 470 9852  312   74   67   79   14]
 [ 519  445 5712   53   63   92   13]
 [ 147   90   82 2236   18   12    0]
 [  82   74   36   13 1404    6    1]
 [  39   40   23    4    9 3142    1]
 [  20   13   11    6    3    4 1315]]

===multilabel confusion matrix===

[[[25319  1277]
  [  245  3568]]

 [[18783   758]
  [ 1016  9852]]

 [[22977   535]
  [ 1185  5712]]

 [[27647   177]
  [  349  2236]]

 [[28614   179]
  [  212  1404]]

 [[26937   214]
  [  116  3142]]

 [[28997    40]
  [   57  1315]]]

===scores report===
metrics	scores
Accuracy	0.8954
MCC	0.8678
log_loss	0.3346
f1 score weighted	0.8964
f1 score macro	0.8997
f1 score micro	0.8954
roc_auc ovr	0.9880
roc_auc ovo	0.9903
precision	0.9016
recall	0.8954

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa3cc25c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa3cc25c1c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa3cc25c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa3cc25c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.93      0.85      3813
         1.0       0.93      0.89      0.91     10868
         2.0       0.90      0.83      0.87      6897
         3.0       0.85      0.89      0.87      2585
         4.0       0.93      0.88      0.90      1616
         5.0       0.88      0.98      0.93      3258
         6.0       0.98      0.93      0.96      1372

    accuracy                           0.89     30409
   macro avg       0.89      0.90      0.90     30409
weighted avg       0.90      0.89      0.89     30409


===confusion_matrix===

[[3543   95   93   32    7   37    6]
 [ 435 9664  357  176   46  182    8]
 [ 348  436 5753  144   37  171    8]
 [ 105   76   80 2297   12   14    1]
 [  53   44   56   29 1416   18    0]
 [  24   20   17   11    6 3180    0]
 [  50   10   21    3    0    8 1280]]

===multilabel confusion matrix===

[[[25581  1015]
  [  270  3543]]

 [[18860   681]
  [ 1204  9664]]

 [[22888   624]
  [ 1144  5753]]

 [[27429   395]
  [  288  2297]]

 [[28685   108]
  [  200  1416]]

 [[26721   430]
  [   78  3180]]

 [[29014    23]
  [   92  1280]]]

===scores report===
metrics	scores
Accuracy	0.8923
MCC	0.8639
log_loss	0.3441
f1 score weighted	0.8927
f1 score macro	0.8971
f1 score micro	0.8923
roc_auc ovr	0.9875
roc_auc ovo	0.9902
precision	0.8966
recall	0.8923

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8970404472213088	0.8702193150191362	0.3373678753655507	0.8978452103857465	0.9062523892342186	0.8970404472213088	0.9878568795459749	0.9901247911308885	0.9031076340563196	0.8970404472213088
1	0.9098651759289708	0.8843647099465236	0.296073518790853	0.9099431285778912	0.9165792190425824	0.9098651759289708	0.9891119602573277	0.9909537017932256	0.9114341896685204	0.9098651759289708
2	0.8837882275567248	0.8516656445759359	0.40726220707724614	0.8824921616888224	0.8809612657566842	0.8837882275567248	0.9854797654359846	0.9871793945594657	0.8902997076134721	0.8837882275567248
3	0.8954256963398993	0.867808332368718	0.33455717742396845	0.8963661862051602	0.899688901874187	0.8954256963398993	0.9879899978480468	0.990279730926903	0.9015852302663431	0.8954256963398993
4	0.8922687362294057	0.8639069450573598	0.3441270464491575	0.8927048291152677	0.8971378413471095	0.8922687362294057	0.9875141015043396	0.9901758609885677	0.8965595644368246	0.8922687362294057
mean	0.895677656655262	0.8675929893935347	0.34387756502135514	0.8958703031945776	0.9001239234509564	0.895677656655262	0.9875905409183346	0.9897426958798101	0.900597265208296	0.895677656655262
std	0.008440209097270567	0.010540415598857026	0.0358668303866529	0.008845173474137666	0.011701694115600712	0.008440209097270567	0.0011837596909197812	0.0013159851378609481	0.007029362395044307	0.008440209097270567

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 62784.9257 secs

