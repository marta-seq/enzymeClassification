/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_z_lev3_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_z_lev3_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7eff00493ac0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7eff00493be0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7eff00493c40>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7eff00493a30>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [-2,  0,  0,  1,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 2, -4,  0,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [-4, -1, -1,  0,  0],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 2, -1,  1, -1,  0],
        [ 2,  1,  0,  3,  0],
        [-2, -2, -1,  0,  0]],

       [[-4, -1, -1,  0,  0],
        [-4, -1, -1,  0,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 2, -1,  1, -1,  0],
        [ 0, -2,  0,  0,  1]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.62      0.96      0.76       825
         1.0       0.00      0.00      0.00        14
         2.0       0.70      0.68      0.69        31
         3.0       0.00      0.00      0.00        11
         4.0       0.91      0.81      0.86        52
         5.0       0.69      0.78      0.74       176
         6.0       0.69      0.44      0.54       102
         7.0       0.79      0.24      0.37        97
         8.0       1.00      0.21      0.35        14
         9.0       0.37      0.37      0.37        70
        10.0       0.65      0.80      0.72       104
        11.0       0.50      0.06      0.10        18
        12.0       0.00      0.00      0.00        14
        13.0       0.86      0.70      0.77        43
        14.0       0.89      0.50      0.64        34
        15.0       0.94      0.73      0.82        64
        16.0       1.00      0.15      0.27        13
        17.0       1.00      0.37      0.54        19
        18.0       0.81      0.92      0.86        72
        19.0       0.62      0.17      0.26        30
        20.0       0.99      0.97      0.98        94
        21.0       0.80      0.80      0.80        46
        22.0       0.94      0.64      0.76        25
        23.0       0.98      0.90      0.94       345
        24.0       0.76      0.83      0.79        30
        25.0       1.00      0.15      0.26        20
        26.0       0.85      0.72      0.78       167
        27.0       0.92      0.67      0.77        36
        28.0       0.96      0.87      0.91        61
        29.0       1.00      0.76      0.86        63
        30.0       0.00      0.00      0.00        11
        31.0       0.00      0.00      0.00        11
        32.0       0.86      0.30      0.44        40
        33.0       0.96      0.70      0.81        73
        34.0       0.95      1.00      0.97        57
        35.0       1.00      0.87      0.93        15
        36.0       0.50      0.14      0.22        50
        37.0       0.88      0.74      0.80        19
        38.0       1.00      0.66      0.79        29
        39.0       0.87      0.93      0.90       101
        40.0       1.00      0.67      0.80        12
        41.0       1.00      1.00      1.00        14
        42.0       0.69      0.91      0.79        67
        43.0       0.99      0.91      0.95        76
        44.0       1.00      1.00      1.00        11
        45.0       1.00      0.86      0.93        37
        46.0       0.94      0.87      0.90      1613
        47.0       0.85      0.99      0.92       299
        48.0       0.95      0.98      0.96       244
        49.0       0.91      0.95      0.93       168
        50.0       0.86      0.79      0.82      1024
        51.0       0.92      0.69      0.79       353
        52.0       0.85      0.86      0.86        86
        53.0       0.81      0.70      0.75       607
        54.0       0.84      0.91      0.88       543
        55.0       0.92      0.92      0.92        78
        56.0       0.77      0.94      0.85       954
        57.0       0.95      0.84      0.89       247
        58.0       0.87      1.00      0.93        34
        59.0       0.85      0.79      0.82       877
        60.0       1.00      0.84      0.92        77
        61.0       0.68      0.92      0.78       566
        62.0       1.00      0.12      0.22        24
        63.0       0.82      0.65      0.73        55
        64.0       0.99      0.96      0.97       254
        65.0       0.67      0.29      0.40        14
        66.0       0.92      0.96      0.94       456
        67.0       0.96      0.66      0.78        38
        68.0       0.75      0.89      0.81      1189
        69.0       0.78      0.81      0.79       224
        70.0       0.85      0.58      0.69        19
        71.0       0.99      0.94      0.96       358
        72.0       0.67      0.56      0.61        32
        73.0       0.50      0.08      0.13        13
        74.0       0.99      0.94      0.97       127
        75.0       1.00      0.83      0.91        12
        76.0       0.84      0.77      0.80       460
        77.0       0.99      0.78      0.87       103
        78.0       0.70      0.13      0.23        52
        79.0       0.88      0.60      0.71        83
        80.0       0.77      0.41      0.54        80
        81.0       0.58      0.82      0.68        84
        82.0       0.80      0.89      0.84       335
        83.0       0.80      0.17      0.29        23
        84.0       0.90      0.69      0.78       518
        85.0       0.36      0.06      0.10        87
        86.0       0.00      0.00      0.00        13
        87.0       0.64      0.64      0.64       480
        88.0       0.52      0.71      0.60       126
        89.0       0.95      0.80      0.87        25
        90.0       0.83      0.74      0.78       152
        91.0       1.00      0.25      0.40        20
        92.0       1.00      0.21      0.35        28
        93.0       0.91      0.50      0.65        42
        94.0       0.39      0.21      0.27        34
        95.0       0.47      0.28      0.35        99
        96.0       0.81      0.80      0.81       415
        97.0       0.94      0.56      0.70       118
        98.0       0.82      0.62      0.71        99
        99.0       0.68      0.75      0.71       253
       100.0       0.90      0.93      0.92       116
       101.0       0.69      0.78      0.74       423
       102.0       0.79      0.78      0.79        99
       103.0       0.91      0.68      0.78        60
       104.0       0.70      0.82      0.75       266
       105.0       0.94      0.89      0.92        37
       106.0       0.65      0.89      0.75       494
       107.0       0.93      0.93      0.93        14
       108.0       0.89      0.81      0.85       610
       109.0       0.87      0.85      0.86       206
       110.0       0.73      0.50      0.59        22
       111.0       0.87      0.85      0.86       534
       112.0       0.71      0.57      0.63        98
       113.0       0.81      0.56      0.66        86
       114.0       0.95      0.85      0.90       109
       115.0       0.87      0.90      0.89       858
       116.0       0.38      0.66      0.48        61
       117.0       0.90      0.90      0.90       209
       118.0       0.00      0.00      0.00        13
       119.0       0.70      0.74      0.72        65
       120.0       0.95      0.92      0.94       156
       121.0       0.94      0.93      0.93        84
       122.0       1.00      0.49      0.66        55
       123.0       0.47      0.83      0.60       154
       124.0       0.96      0.83      0.89        52
       125.0       0.96      0.89      0.92       147
       126.0       0.82      0.47      0.60        77
       127.0       0.89      0.84      0.86        19
       128.0       0.91      0.81      0.86       198
       129.0       0.95      0.89      0.92       450
       130.0       1.00      0.18      0.31        11
       131.0       0.85      0.40      0.54        43
       132.0       0.93      0.81      0.87        16
       133.0       0.92      0.97      0.94       204
       134.0       0.99      0.95      0.97        76
       135.0       0.58      0.88      0.70       255
       136.0       0.00      0.00      0.00        20
       137.0       0.83      0.77      0.80        13
       138.0       0.83      0.57      0.67        67
       139.0       0.96      0.97      0.97      1464
       140.0       0.92      0.87      0.89       146
       141.0       0.96      0.93      0.94        99
       142.0       0.89      0.90      0.90       455
       143.0       0.86      0.93      0.89        82
       144.0       0.98      0.94      0.96       411
       145.0       0.95      0.93      0.94       406
       146.0       1.00      0.17      0.29        12
       147.0       0.85      0.90      0.88       149
       148.0       0.89      0.96      0.93       703
       149.0       0.99      0.95      0.97       195
       150.0       0.84      0.64      0.72        33
       151.0       0.98      0.71      0.82        68
       152.0       1.00      0.91      0.96        93
       153.0       1.00      0.91      0.95        33
       154.0       0.92      0.92      0.92        49
       155.0       0.79      0.95      0.86       154

    accuracy                           0.83     28656
   macro avg       0.80      0.68      0.71     28656
weighted avg       0.84      0.83      0.82     28656


===confusion_matrix===

[[795   0   0 ...   0   0   0]
 [  3   0   0 ...   0   0   0]
 [  2   0  21 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   2]
 [  0   0   0 ...   0  45   4]
 [  0   0   0 ...   0   2 147]]

===multilabel confusion matrix===

[[[27351   480]
  [   30   795]]

 [[28640     2]
  [   14     0]]

 [[28616     9]
  [   10    21]]

 [[28645     0]
  [   11     0]]

 [[28600     4]
  [   10    42]]

 [[28419    61]
  [   38   138]]

 [[28534    20]
  [   57    45]]

 [[28553     6]
  [   74    23]]

 [[28642     0]
  [   11     3]]

 [[28542    44]
  [   44    26]]

 [[28508    44]
  [   21    83]]

 [[28637     1]
  [   17     1]]

 [[28642     0]
  [   14     0]]

 [[28608     5]
  [   13    30]]

 [[28620     2]
  [   17    17]]

 [[28589     3]
  [   17    47]]

 [[28643     0]
  [   11     2]]

 [[28637     0]
  [   12     7]]

 [[28569    15]
  [    6    66]]

 [[28623     3]
  [   25     5]]

 [[28561     1]
  [    3    91]]

 [[28601     9]
  [    9    37]]

 [[28630     1]
  [    9    16]]

 [[28305     6]
  [   35   310]]

 [[28618     8]
  [    5    25]]

 [[28636     0]
  [   17     3]]

 [[28468    21]
  [   47   120]]

 [[28618     2]
  [   12    24]]

 [[28593     2]
  [    8    53]]

 [[28593     0]
  [   15    48]]

 [[28643     2]
  [   11     0]]

 [[28642     3]
  [   11     0]]

 [[28614     2]
  [   28    12]]

 [[28581     2]
  [   22    51]]

 [[28596     3]
  [    0    57]]

 [[28641     0]
  [    2    13]]

 [[28599     7]
  [   43     7]]

 [[28635     2]
  [    5    14]]

 [[28627     0]
  [   10    19]]

 [[28541    14]
  [    7    94]]

 [[28644     0]
  [    4     8]]

 [[28642     0]
  [    0    14]]

 [[28562    27]
  [    6    61]]

 [[28579     1]
  [    7    69]]

 [[28645     0]
  [    0    11]]

 [[28619     0]
  [    5    32]]

 [[26948    95]
  [  203  1410]]

 [[28306    51]
  [    3   296]]

 [[28400    12]
  [    6   238]]

 [[28473    15]
  [    9   159]]

 [[27498   134]
  [  217   807]]

 [[28283    20]
  [  110   243]]

 [[28557    13]
  [   12    74]]

 [[27949   100]
  [  182   425]]

 [[28022    91]
  [   47   496]]

 [[28572     6]
  [    6    72]]

 [[27438   264]
  [   61   893]]

 [[28398    11]
  [   39   208]]

 [[28617     5]
  [    0    34]]

 [[27657   122]
  [  187   690]]

 [[28579     0]
  [   12    65]]

 [[27849   241]
  [   47   519]]

 [[28632     0]
  [   21     3]]

 [[28593     8]
  [   19    36]]

 [[28399     3]
  [   10   244]]

 [[28640     2]
  [   10     4]]

 [[28160    40]
  [   17   439]]

 [[28617     1]
  [   13    25]]

 [[27119   348]
  [  135  1054]]

 [[28381    51]
  [   43   181]]

 [[28635     2]
  [    8    11]]

 [[28294     4]
  [   22   336]]

 [[28615     9]
  [   14    18]]

 [[28642     1]
  [   12     1]]

 [[28528     1]
  [    7   120]]

 [[28644     0]
  [    2    10]]

 [[28127    69]
  [  106   354]]

 [[28552     1]
  [   23    80]]

 [[28601     3]
  [   45     7]]

 [[28566     7]
  [   33    50]]

 [[28566    10]
  [   47    33]]

 [[28522    50]
  [   15    69]]

 [[28248    73]
  [   37   298]]

 [[28632     1]
  [   19     4]]

 [[28096    42]
  [  160   358]]

 [[28560     9]
  [   82     5]]

 [[28643     0]
  [   13     0]]

 [[28006   170]
  [  174   306]]

 [[28449    81]
  [   37    89]]

 [[28630     1]
  [    5    20]]

 [[28481    23]
  [   39   113]]

 [[28636     0]
  [   15     5]]

 [[28628     0]
  [   22     6]]

 [[28612     2]
  [   21    21]]

 [[28611    11]
  [   27     7]]

 [[28525    32]
  [   71    28]]

 [[28164    77]
  [   81   334]]

 [[28534     4]
  [   52    66]]

 [[28544    13]
  [   38    61]]

 [[28316    87]
  [   64   189]]

 [[28528    12]
  [    8   108]]

 [[28087   146]
  [   92   331]]

 [[28537    20]
  [   22    77]]

 [[28592     4]
  [   19    41]]

 [[28296    94]
  [   49   217]]

 [[28617     2]
  [    4    33]]

 [[27928   234]
  [   53   441]]

 [[28641     1]
  [    1    13]]

 [[27986    60]
  [  113   497]]

 [[28424    26]
  [   30   176]]

 [[28630     4]
  [   11    11]]

 [[28056    66]
  [   79   455]]

 [[28535    23]
  [   42    56]]

 [[28559    11]
  [   38    48]]

 [[28542     5]
  [   16    93]]

 [[27685   113]
  [   86   772]]

 [[28531    64]
  [   21    40]]

 [[28427    20]
  [   21   188]]

 [[28643     0]
  [   13     0]]

 [[28570    21]
  [   17    48]]

 [[28493     7]
  [   12   144]]

 [[28567     5]
  [    6    78]]

 [[28601     0]
  [   28    27]]

 [[28357   145]
  [   26   128]]

 [[28602     2]
  [    9    43]]

 [[28503     6]
  [   16   131]]

 [[28571     8]
  [   41    36]]

 [[28635     2]
  [    3    16]]

 [[28442    16]
  [   38   160]]

 [[28185    21]
  [   50   400]]

 [[28645     0]
  [    9     2]]

 [[28610     3]
  [   26    17]]

 [[28639     1]
  [    3    13]]

 [[28435    17]
  [    7   197]]

 [[28579     1]
  [    4    72]]

 [[28242   159]
  [   31   224]]

 [[28636     0]
  [   20     0]]

 [[28641     2]
  [    3    10]]

 [[28581     8]
  [   29    38]]

 [[27136    56]
  [   46  1418]]

 [[28499    11]
  [   19   127]]

 [[28553     4]
  [    7    92]]

 [[28153    48]
  [   47   408]]

 [[28562    12]
  [    6    76]]

 [[28239     6]
  [   25   386]]

 [[28232    18]
  [   30   376]]

 [[28644     0]
  [   10     2]]

 [[28484    23]
  [   15   134]]

 [[27873    80]
  [   27   676]]

 [[28459     2]
  [   10   185]]

 [[28619     4]
  [   12    21]]

 [[28587     1]
  [   20    48]]

 [[28563     0]
  [    8    85]]

 [[28623     0]
  [    3    30]]

 [[28603     4]
  [    4    45]]

 [[28463    39]
  [    7   147]]]

===scores report===
metrics	scores
Accuracy	0.8302
MCC	0.8269
log_loss	0.7793
f1 score weighted	0.8249
f1 score macro	0.7055
f1 score micro	0.8302
roc_auc ovr	0.9931
roc_auc ovo	0.9901
precision	0.8392
recall	0.8302

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7eff00493ac0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7eff00493be0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7eff00493c40>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7eff00493a30>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [ 2, -1,  1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  1, -2,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2, -2, -1,  0,  0],
        [ 3,  2, -3,  1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 1,  0, -1, -1,  0],
        [ 3,  0,  0,  0,  0],
        [ 3,  0,  0,  0,  0]],

       [[-2, -2, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  0,  1, -2,  0],
        [ 3,  2, -3,  1,  0],
        [ 3,  1,  1, -1,  1]]], dtype=int8), 'y_test': array([56., 56., 56., ..., 98., 51., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.91      0.88       825
         1.0       0.75      0.21      0.33        14
         2.0       0.72      0.68      0.70        31
         3.0       0.00      0.00      0.00        12
         4.0       0.96      0.83      0.89        52
         5.0       0.84      0.81      0.82       176
         6.0       0.83      0.47      0.60       102
         7.0       0.32      0.49      0.39        97
         8.0       0.57      0.57      0.57        14
         9.0       0.57      0.41      0.48        70
        10.0       0.73      0.77      0.75       104
        11.0       0.00      0.00      0.00        18
        12.0       0.30      0.21      0.25        14
        13.0       0.82      0.64      0.72        42
        14.0       0.56      0.68      0.61        34
        15.0       0.70      0.81      0.75        64
        16.0       0.67      0.14      0.24        14
        17.0       0.83      0.53      0.65        19
        18.0       0.86      0.90      0.88        72
        19.0       0.64      0.23      0.33        31
        20.0       0.92      0.95      0.93        94
        21.0       0.62      0.82      0.70        45
        22.0       1.00      0.80      0.89        25
        23.0       0.88      0.97      0.92       346
        24.0       0.93      0.47      0.62        30
        25.0       0.10      0.11      0.10        19
        26.0       0.66      0.72      0.69       167
        27.0       0.93      0.69      0.79        36
        28.0       0.79      0.97      0.87        60
        29.0       0.97      0.60      0.74        62
        30.0       0.50      0.09      0.15        11
        31.0       0.00      0.00      0.00        11
        32.0       0.65      0.50      0.56        40
        33.0       0.68      0.73      0.70        74
        34.0       0.95      0.95      0.95        56
        35.0       0.70      0.88      0.78        16
        36.0       0.25      0.25      0.25        51
        37.0       0.87      0.68      0.76        19
        38.0       0.70      0.66      0.68        29
        39.0       0.79      0.91      0.84       101
        40.0       1.00      0.58      0.74        12
        41.0       1.00      1.00      1.00        13
        42.0       0.67      0.90      0.77        67
        43.0       0.86      0.95      0.90        76
        44.0       1.00      1.00      1.00        12
        45.0       0.87      0.92      0.89        36
        46.0       0.83      0.93      0.88      1613
        47.0       0.97      0.98      0.98       299
        48.0       0.98      0.98      0.98       243
        49.0       0.97      0.89      0.93       169
        50.0       0.75      0.83      0.78      1024
        51.0       0.66      0.77      0.71       352
        52.0       0.92      0.90      0.91        86
        53.0       0.84      0.75      0.79       607
        54.0       0.90      0.90      0.90       543
        55.0       0.97      0.87      0.92        78
        56.0       0.92      0.85      0.88       954
        57.0       0.66      0.93      0.77       247
        58.0       1.00      0.94      0.97        34
        59.0       0.71      0.88      0.79       877
        60.0       0.97      0.77      0.86        77
        61.0       0.77      0.89      0.83       565
        62.0       1.00      0.33      0.50        24
        63.0       0.96      0.44      0.60        55
        64.0       0.96      0.96      0.96       255
        65.0       0.50      0.57      0.53        14
        66.0       0.97      0.90      0.94       457
        67.0       0.94      0.78      0.85        37
        68.0       0.94      0.78      0.85      1189
        69.0       0.93      0.78      0.84       224
        70.0       0.65      0.55      0.59        20
        71.0       0.94      0.95      0.95       358
        72.0       0.82      0.44      0.57        32
        73.0       0.50      0.08      0.13        13
        74.0       0.83      0.95      0.89       128
        75.0       1.00      0.77      0.87        13
        76.0       0.75      0.82      0.79       460
        77.0       0.95      0.84      0.89       104
        78.0       0.54      0.13      0.22        52
        79.0       0.76      0.61      0.68        84
        80.0       0.90      0.44      0.59        80
        81.0       0.96      0.78      0.86        83
        82.0       0.87      0.86      0.87       335
        83.0       0.75      0.25      0.38        24
        84.0       0.91      0.68      0.78       518
        85.0       0.00      0.00      0.00        88
        86.0       1.00      0.23      0.38        13
        87.0       0.48      0.87      0.62       480
        88.0       0.86      0.61      0.71       126
        89.0       1.00      1.00      1.00        25
        90.0       0.80      0.78      0.79       153
        91.0       0.80      0.20      0.32        20
        92.0       0.55      0.41      0.47        27
        93.0       0.83      0.60      0.69        42
        94.0       0.45      0.15      0.22        34
        95.0       0.68      0.39      0.50        99
        96.0       0.77      0.86      0.81       416
        97.0       0.38      0.75      0.50       118
        98.0       0.89      0.74      0.81        99
        99.0       0.80      0.73      0.76       253
       100.0       0.94      0.91      0.93       115
       101.0       0.86      0.78      0.82       423
       102.0       0.92      0.77      0.84        99
       103.0       0.65      0.67      0.66        61
       104.0       0.77      0.88      0.82       266
       105.0       0.85      0.81      0.83        36
       106.0       0.83      0.81      0.82       494
       107.0       1.00      0.43      0.60        14
       108.0       0.98      0.79      0.87       610
       109.0       0.97      0.85      0.91       206
       110.0       0.67      0.64      0.65        22
       111.0       0.97      0.83      0.89       535
       112.0       0.45      0.66      0.53        98
       113.0       0.41      0.63      0.49        86
       114.0       0.73      0.92      0.81       109
       115.0       0.93      0.89      0.91       858
       116.0       0.55      0.59      0.57        61
       117.0       0.99      0.87      0.93       208
       118.0       0.00      0.00      0.00        13
       119.0       0.67      0.69      0.68        65
       120.0       0.95      0.87      0.91       157
       121.0       0.93      0.99      0.96        84
       122.0       0.35      0.51      0.41        55
       123.0       0.92      0.77      0.84       154
       124.0       0.91      0.92      0.91        52
       125.0       0.97      0.90      0.94       147
       126.0       0.74      0.52      0.61        77
       127.0       1.00      0.67      0.80        18
       128.0       0.88      0.85      0.87       197
       129.0       0.86      0.94      0.90       449
       130.0       0.00      0.00      0.00        11
       131.0       0.96      0.58      0.72        43
       132.0       0.79      0.73      0.76        15
       133.0       0.99      0.97      0.98       204
       134.0       0.93      0.99      0.96        76
       135.0       0.66      0.89      0.76       255
       136.0       1.00      0.32      0.48        19
       137.0       1.00      0.92      0.96        13
       138.0       0.48      0.69      0.57        67
       139.0       0.98      0.95      0.97      1463
       140.0       0.95      0.86      0.90       147
       141.0       0.99      0.87      0.92        99
       142.0       0.98      0.85      0.92       455
       143.0       0.89      0.96      0.92        82
       144.0       0.99      0.91      0.95       410
       145.0       0.98      0.93      0.95       406
       146.0       1.00      0.08      0.15        12
       147.0       0.96      0.87      0.91       149
       148.0       0.90      0.97      0.93       702
       149.0       0.99      0.95      0.97       196
       150.0       0.95      0.66      0.78        32
       151.0       0.91      0.86      0.88        69
       152.0       0.90      0.92      0.91        93
       153.0       0.83      0.91      0.87        32
       154.0       0.93      0.78      0.84        49
       155.0       0.85      0.94      0.89       154

    accuracy                           0.84     28655
   macro avg       0.78      0.69      0.71     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[748   0   0 ...   0   0   0]
 [  0   3   0 ...   0   0   0]
 [  1   0  21 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   0]
 [  0   0   0 ...   0  38   9]
 [  0   0   0 ...   1   2 145]]

===multilabel confusion matrix===

[[[27712   118]
  [   77   748]]

 [[28640     1]
  [   11     3]]

 [[28616     8]
  [   10    21]]

 [[28641     2]
  [   12     0]]

 [[28601     2]
  [    9    43]]

 [[28452    27]
  [   34   142]]

 [[28543    10]
  [   54    48]]

 [[28454   104]
  [   49    48]]

 [[28635     6]
  [    6     8]]

 [[28563    22]
  [   41    29]]

 [[28521    30]
  [   24    80]]

 [[28631     6]
  [   18     0]]

 [[28634     7]
  [   11     3]]

 [[28607     6]
  [   15    27]]

 [[28603    18]
  [   11    23]]

 [[28569    22]
  [   12    52]]

 [[28640     1]
  [   12     2]]

 [[28634     2]
  [    9    10]]

 [[28572    11]
  [    7    65]]

 [[28620     4]
  [   24     7]]

 [[28553     8]
  [    5    89]]

 [[28587    23]
  [    8    37]]

 [[28630     0]
  [    5    20]]

 [[28264    45]
  [   10   336]]

 [[28624     1]
  [   16    14]]

 [[28618    18]
  [   17     2]]

 [[28426    62]
  [   47   120]]

 [[28617     2]
  [   11    25]]

 [[28580    15]
  [    2    58]]

 [[28592     1]
  [   25    37]]

 [[28643     1]
  [   10     1]]

 [[28644     0]
  [   11     0]]

 [[28604    11]
  [   20    20]]

 [[28555    26]
  [   20    54]]

 [[28596     3]
  [    3    53]]

 [[28633     6]
  [    2    14]]

 [[28566    38]
  [   38    13]]

 [[28634     2]
  [    6    13]]

 [[28618     8]
  [   10    19]]

 [[28529    25]
  [    9    92]]

 [[28643     0]
  [    5     7]]

 [[28642     0]
  [    0    13]]

 [[28559    29]
  [    7    60]]

 [[28567    12]
  [    4    72]]

 [[28643     0]
  [    0    12]]

 [[28614     5]
  [    3    33]]

 [[26740   302]
  [  118  1495]]

 [[28348     8]
  [    6   293]]

 [[28407     5]
  [    6   237]]

 [[28481     5]
  [   18   151]]

 [[27343   288]
  [  177   847]]

 [[28164   139]
  [   81   271]]

 [[28562     7]
  [    9    77]]

 [[27959    89]
  [  151   456]]

 [[28059    53]
  [   55   488]]

 [[28575     2]
  [   10    68]]

 [[27628    73]
  [  146   808]]

 [[28291   117]
  [   18   229]]

 [[28621     0]
  [    2    32]]

 [[27464   314]
  [  105   772]]

 [[28576     2]
  [   18    59]]

 [[27942   148]
  [   64   501]]

 [[28631     0]
  [   16     8]]

 [[28599     1]
  [   31    24]]

 [[28390    10]
  [   10   245]]

 [[28633     8]
  [    6     8]]

 [[28187    11]
  [   44   413]]

 [[28616     2]
  [    8    29]]

 [[27403    63]
  [  257   932]]

 [[28417    14]
  [   50   174]]

 [[28629     6]
  [    9    11]]

 [[28276    21]
  [   18   340]]

 [[28620     3]
  [   18    14]]

 [[28641     1]
  [   12     1]]

 [[28503    24]
  [    7   121]]

 [[28642     0]
  [    3    10]]

 [[28072   123]
  [   81   379]]

 [[28546     5]
  [   17    87]]

 [[28597     6]
  [   45     7]]

 [[28555    16]
  [   33    51]]

 [[28571     4]
  [   45    35]]

 [[28569     3]
  [   18    65]]

 [[28278    42]
  [   46   289]]

 [[28629     2]
  [   18     6]]

 [[28104    33]
  [  164   354]]

 [[28563     4]
  [   88     0]]

 [[28642     0]
  [   10     3]]

 [[27719   456]
  [   63   417]]

 [[28516    13]
  [   49    77]]

 [[28630     0]
  [    0    25]]

 [[28473    29]
  [   34   119]]

 [[28634     1]
  [   16     4]]

 [[28619     9]
  [   16    11]]

 [[28608     5]
  [   17    25]]

 [[28615     6]
  [   29     5]]

 [[28538    18]
  [   60    39]]

 [[28133   106]
  [   60   356]]

 [[28389   148]
  [   29    89]]

 [[28547     9]
  [   26    73]]

 [[28356    46]
  [   68   185]]

 [[28533     7]
  [   10   105]]

 [[28180    52]
  [   93   330]]

 [[28549     7]
  [   23    76]]

 [[28572    22]
  [   20    41]]

 [[28320    69]
  [   33   233]]

 [[28614     5]
  [    7    29]]

 [[28081    80]
  [   92   402]]

 [[28641     0]
  [    8     6]]

 [[28035    10]
  [  129   481]]

 [[28443     6]
  [   30   176]]

 [[28626     7]
  [    8    14]]

 [[28105    15]
  [   90   445]]

 [[28476    81]
  [   33    65]]

 [[28490    79]
  [   32    54]]

 [[28509    37]
  [    9   100]]

 [[27737    60]
  [   98   760]]

 [[28564    30]
  [   25    36]]

 [[28446     1]
  [   27   181]]

 [[28642     0]
  [   13     0]]

 [[28568    22]
  [   20    45]]

 [[28491     7]
  [   20   137]]

 [[28565     6]
  [    1    83]]

 [[28548    52]
  [   27    28]]

 [[28491    10]
  [   36   118]]

 [[28598     5]
  [    4    48]]

 [[28504     4]
  [   14   133]]

 [[28564    14]
  [   37    40]]

 [[28637     0]
  [    6    12]]

 [[28436    22]
  [   29   168]]

 [[28139    67]
  [   27   422]]

 [[28644     0]
  [   11     0]]

 [[28611     1]
  [   18    25]]

 [[28637     3]
  [    4    11]]

 [[28448     3]
  [    6   198]]

 [[28573     6]
  [    1    75]]

 [[28286   114]
  [   29   226]]

 [[28636     0]
  [   13     6]]

 [[28642     0]
  [    1    12]]

 [[28539    49]
  [   21    46]]

 [[27166    26]
  [   69  1394]]

 [[28501     7]
  [   20   127]]

 [[28555     1]
  [   13    86]]

 [[28194     6]
  [   66   389]]

 [[28563    10]
  [    3    79]]

 [[28241     4]
  [   35   375]]

 [[28241     8]
  [   29   377]]

 [[28643     0]
  [   11     1]]

 [[28500     6]
  [   19   130]]

 [[27877    76]
  [   23   679]]

 [[28457     2]
  [   10   186]]

 [[28622     1]
  [   11    21]]

 [[28580     6]
  [   10    59]]

 [[28552    10]
  [    7    86]]

 [[28617     6]
  [    3    29]]

 [[28603     3]
  [   11    38]]

 [[28475    26]
  [    9   145]]]

===scores report===
metrics	scores
Accuracy	0.8360
MCC	0.8328
log_loss	0.7758
f1 score weighted	0.8352
f1 score macro	0.7131
f1 score micro	0.8360
roc_auc ovr	0.9930
roc_auc ovo	0.9901
precision	0.8490
recall	0.8360

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7eff00493ac0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7eff00493be0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7eff00493c40>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7eff00493a30>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 3,  2, -3,  1,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [-3, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 0, -2, -1, -1,  0],
        [-2,  2,  0,  0, -1],
        [ 2, -1,  1, -1,  0],
        ...,
        [ 3,  0,  0,  0,  0],
        [-4,  1,  1,  0,  0],
        [ 3,  0,  1, -2,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  51.,  96., 109.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.92      0.83       825
         1.0       1.00      0.07      0.13        14
         2.0       0.95      0.62      0.75        32
         3.0       0.00      0.00      0.00        12
         4.0       1.00      0.77      0.87        52
         5.0       0.82      0.82      0.82       176
         6.0       0.71      0.46      0.56       102
         7.0       0.26      0.11      0.16        97
         8.0       0.67      0.14      0.24        14
         9.0       0.70      0.33      0.45        69
        10.0       0.89      0.54      0.67       104
        11.0       0.50      0.06      0.10        18
        12.0       0.00      0.00      0.00        15
        13.0       0.79      0.64      0.71        42
        14.0       1.00      0.38      0.55        34
        15.0       0.76      0.80      0.78        64
        16.0       1.00      0.15      0.27        13
        17.0       0.56      0.47      0.51        19
        18.0       0.91      0.89      0.90        71
        19.0       1.00      0.06      0.12        31
        20.0       0.97      0.96      0.96        94
        21.0       0.74      0.74      0.74        46
        22.0       0.95      0.72      0.82        25
        23.0       1.00      0.85      0.92       346
        24.0       1.00      0.68      0.81        31
        25.0       0.00      0.00      0.00        20
        26.0       0.82      0.61      0.70       167
        27.0       1.00      0.53      0.69        36
        28.0       0.92      0.92      0.92        60
        29.0       0.92      0.77      0.84        62
        30.0       1.00      0.18      0.31        11
        31.0       0.00      0.00      0.00        12
        32.0       0.42      0.47      0.45        40
        33.0       0.89      0.85      0.87        74
        34.0       1.00      0.98      0.99        56
        35.0       0.61      0.88      0.72        16
        36.0       0.42      0.16      0.23        51
        37.0       0.75      0.95      0.84        19
        38.0       1.00      0.62      0.77        29
        39.0       0.97      0.87      0.92       101
        40.0       1.00      0.50      0.67        12
        41.0       1.00      1.00      1.00        13
        42.0       0.92      0.84      0.88        67
        43.0       0.94      0.80      0.87        76
        44.0       0.91      0.91      0.91        11
        45.0       1.00      0.76      0.86        37
        46.0       0.74      0.93      0.82      1613
        47.0       0.98      0.96      0.97       299
        48.0       0.96      0.94      0.95       243
        49.0       0.94      0.93      0.94       169
        50.0       0.71      0.85      0.77      1023
        51.0       0.59      0.77      0.67       352
        52.0       0.93      0.77      0.84        86
        53.0       0.88      0.65      0.75       606
        54.0       0.78      0.87      0.82       543
        55.0       1.00      0.78      0.88        79
        56.0       0.89      0.87      0.88       954
        57.0       0.83      0.90      0.86       247
        58.0       1.00      0.97      0.99        34
        59.0       0.80      0.83      0.81       877
        60.0       0.92      0.78      0.85        77
        61.0       0.92      0.76      0.83       566
        62.0       0.83      0.21      0.33        24
        63.0       1.00      0.42      0.59        55
        64.0       0.93      0.95      0.94       255
        65.0       1.00      0.08      0.14        13
        66.0       0.95      0.95      0.95       457
        67.0       0.83      0.65      0.73        37
        68.0       0.75      0.84      0.80      1189
        69.0       0.74      0.85      0.79       223
        70.0       0.62      0.42      0.50        19
        71.0       0.96      0.94      0.95       357
        72.0       0.94      0.53      0.68        32
        73.0       0.00      0.00      0.00        13
        74.0       0.98      0.95      0.96       128
        75.0       1.00      0.69      0.82        13
        76.0       0.63      0.80      0.71       460
        77.0       0.70      0.79      0.74       104
        78.0       0.77      0.32      0.45        53
        79.0       0.77      0.58      0.66        83
        80.0       0.90      0.48      0.63        79
        81.0       0.86      0.80      0.83        84
        82.0       0.82      0.83      0.82       334
        83.0       0.00      0.00      0.00        24
        84.0       0.83      0.71      0.76       518
        85.0       0.71      0.06      0.11        88
        86.0       1.00      0.15      0.27        13
        87.0       0.54      0.71      0.61       480
        88.0       0.71      0.71      0.71       127
        89.0       0.95      0.88      0.91        24
        90.0       0.91      0.69      0.79       153
        91.0       1.00      0.15      0.26        20
        92.0       1.00      0.33      0.50        27
        93.0       0.97      0.67      0.79        42
        94.0       0.73      0.24      0.36        34
        95.0       0.76      0.41      0.54        99
        96.0       0.79      0.85      0.82       416
        97.0       0.74      0.58      0.65       118
        98.0       0.95      0.71      0.81        99
        99.0       0.82      0.63      0.71       253
       100.0       0.89      0.94      0.91       115
       101.0       0.80      0.74      0.77       423
       102.0       0.83      0.73      0.78        98
       103.0       0.87      0.67      0.75        60
       104.0       0.87      0.78      0.82       265
       105.0       0.91      0.83      0.87        36
       106.0       0.82      0.80      0.81       495
       107.0       1.00      0.29      0.44        14
       108.0       0.83      0.84      0.84       610
       109.0       0.97      0.86      0.91       206
       110.0       0.79      0.68      0.73        22
       111.0       0.53      0.89      0.67       535
       112.0       0.55      0.57      0.56        98
       113.0       0.65      0.41      0.50        86
       114.0       0.84      0.88      0.86       110
       115.0       0.76      0.89      0.82       858
       116.0       0.77      0.39      0.52        61
       117.0       0.98      0.88      0.92       208
       118.0       0.00      0.00      0.00        13
       119.0       0.75      0.59      0.66        66
       120.0       0.99      0.90      0.94       157
       121.0       0.99      0.99      0.99        84
       122.0       0.66      0.53      0.59        55
       123.0       0.70      0.76      0.73       153
       124.0       0.98      0.87      0.92        52
       125.0       0.92      0.91      0.92       147
       126.0       0.68      0.37      0.48        76
       127.0       1.00      0.89      0.94        18
       128.0       0.77      0.85      0.81       197
       129.0       0.81      0.95      0.88       450
       130.0       0.75      0.25      0.38        12
       131.0       1.00      0.60      0.75        42
       132.0       0.93      0.87      0.90        15
       133.0       0.96      0.96      0.96       204
       134.0       0.97      0.91      0.94        76
       135.0       0.86      0.79      0.82       256
       136.0       1.00      0.21      0.35        19
       137.0       1.00      0.69      0.82        13
       138.0       0.74      0.52      0.61        67
       139.0       0.99      0.92      0.95      1464
       140.0       0.95      0.83      0.88       147
       141.0       0.99      0.86      0.92        98
       142.0       0.98      0.91      0.94       455
       143.0       0.92      0.93      0.92        82
       144.0       0.99      0.93      0.96       410
       145.0       0.87      0.93      0.90       406
       146.0       1.00      0.08      0.15        12
       147.0       0.97      0.86      0.91       149
       148.0       0.98      0.92      0.95       702
       149.0       0.97      0.95      0.96       196
       150.0       1.00      0.50      0.67        32
       151.0       0.81      0.87      0.84        69
       152.0       0.86      0.94      0.90        93
       153.0       0.72      0.85      0.78        33
       154.0       0.76      0.90      0.83        50
       155.0       0.90      0.79      0.84       154

    accuracy                           0.82     28655
   macro avg       0.82      0.66      0.70     28655
weighted avg       0.83      0.82      0.81     28655


===confusion_matrix===

[[762   0   0 ...   0   0   0]
 [  2   1   0 ...   0   0   0]
 [  4   0  20 ...   0   0   0]
 ...
 [  0   0   0 ...  28   1   1]
 [  0   0   0 ...   1  45   2]
 [  0   0   0 ...   2   9 122]]

===multilabel confusion matrix===

[[[27578   252]
  [   63   762]]

 [[28641     0]
  [   13     1]]

 [[28622     1]
  [   12    20]]

 [[28643     0]
  [   12     0]]

 [[28603     0]
  [   12    40]]

 [[28448    31]
  [   31   145]]

 [[28534    19]
  [   55    47]]

 [[28526    32]
  [   86    11]]

 [[28640     1]
  [   12     2]]

 [[28576    10]
  [   46    23]]

 [[28544     7]
  [   48    56]]

 [[28636     1]
  [   17     1]]

 [[28640     0]
  [   15     0]]

 [[28606     7]
  [   15    27]]

 [[28621     0]
  [   21    13]]

 [[28575    16]
  [   13    51]]

 [[28642     0]
  [   11     2]]

 [[28629     7]
  [   10     9]]

 [[28578     6]
  [    8    63]]

 [[28624     0]
  [   29     2]]

 [[28558     3]
  [    4    90]]

 [[28597    12]
  [   12    34]]

 [[28629     1]
  [    7    18]]

 [[28309     0]
  [   51   295]]

 [[28624     0]
  [   10    21]]

 [[28634     1]
  [   20     0]]

 [[28466    22]
  [   65   102]]

 [[28619     0]
  [   17    19]]

 [[28590     5]
  [    5    55]]

 [[28589     4]
  [   14    48]]

 [[28644     0]
  [    9     2]]

 [[28643     0]
  [   12     0]]

 [[28589    26]
  [   21    19]]

 [[28573     8]
  [   11    63]]

 [[28599     0]
  [    1    55]]

 [[28630     9]
  [    2    14]]

 [[28593    11]
  [   43     8]]

 [[28630     6]
  [    1    18]]

 [[28626     0]
  [   11    18]]

 [[28551     3]
  [   13    88]]

 [[28643     0]
  [    6     6]]

 [[28642     0]
  [    0    13]]

 [[28583     5]
  [   11    56]]

 [[28575     4]
  [   15    61]]

 [[28643     1]
  [    1    10]]

 [[28618     0]
  [    9    28]]

 [[26502   540]
  [  105  1508]]

 [[28350     6]
  [   11   288]]

 [[28403     9]
  [   14   229]]

 [[28476    10]
  [   11   158]]

 [[27278   354]
  [  156   867]]

 [[28113   190]
  [   82   270]]

 [[28564     5]
  [   20    66]]

 [[27995    54]
  [  212   394]]

 [[27976   136]
  [   68   475]]

 [[28576     0]
  [   17    62]]

 [[27595   106]
  [  121   833]]

 [[28362    46]
  [   25   222]]

 [[28621     0]
  [    1    33]]

 [[27593   185]
  [  149   728]]

 [[28573     5]
  [   17    60]]

 [[28052    37]
  [  136   430]]

 [[28630     1]
  [   19     5]]

 [[28600     0]
  [   32    23]]

 [[28381    19]
  [   12   243]]

 [[28642     0]
  [   12     1]]

 [[28173    25]
  [   23   434]]

 [[28613     5]
  [   13    24]]

 [[27137   329]
  [  185  1004]]

 [[28365    67]
  [   33   190]]

 [[28631     5]
  [   11     8]]

 [[28283    15]
  [   20   337]]

 [[28622     1]
  [   15    17]]

 [[28642     0]
  [   13     0]]

 [[28524     3]
  [    7   121]]

 [[28642     0]
  [    4     9]]

 [[27980   215]
  [   91   369]]

 [[28516    35]
  [   22    82]]

 [[28597     5]
  [   36    17]]

 [[28558    14]
  [   35    48]]

 [[28572     4]
  [   41    38]]

 [[28560    11]
  [   17    67]]

 [[28261    60]
  [   58   276]]

 [[28630     1]
  [   24     0]]

 [[28059    78]
  [  149   369]]

 [[28565     2]
  [   83     5]]

 [[28642     0]
  [   11     2]]

 [[27891   284]
  [  141   339]]

 [[28491    37]
  [   37    90]]

 [[28630     1]
  [    3    21]]

 [[28491    11]
  [   47   106]]

 [[28635     0]
  [   17     3]]

 [[28628     0]
  [   18     9]]

 [[28612     1]
  [   14    28]]

 [[28618     3]
  [   26     8]]

 [[28543    13]
  [   58    41]]

 [[28147    92]
  [   61   355]]

 [[28513    24]
  [   50    68]]

 [[28552     4]
  [   29    70]]

 [[28368    34]
  [   94   159]]

 [[28526    14]
  [    7   108]]

 [[28155    77]
  [  108   315]]

 [[28542    15]
  [   26    72]]

 [[28589     6]
  [   20    40]]

 [[28358    32]
  [   59   206]]

 [[28616     3]
  [    6    30]]

 [[28075    85]
  [   99   396]]

 [[28641     0]
  [   10     4]]

 [[27943   102]
  [   96   514]]

 [[28443     6]
  [   28   178]]

 [[28629     4]
  [    7    15]]

 [[27698   422]
  [   57   478]]

 [[28512    45]
  [   42    56]]

 [[28550    19]
  [   51    35]]

 [[28527    18]
  [   13    97]]

 [[27554   243]
  [   92   766]]

 [[28587     7]
  [   37    24]]

 [[28443     4]
  [   26   182]]

 [[28641     1]
  [   13     0]]

 [[28576    13]
  [   27    39]]

 [[28496     2]
  [   15   142]]

 [[28570     1]
  [    1    83]]

 [[28585    15]
  [   26    29]]

 [[28452    50]
  [   37   116]]

 [[28602     1]
  [    7    45]]

 [[28497    11]
  [   13   134]]

 [[28566    13]
  [   48    28]]

 [[28637     0]
  [    2    16]]

 [[28408    50]
  [   29   168]]

 [[28106    99]
  [   22   428]]

 [[28642     1]
  [    9     3]]

 [[28613     0]
  [   17    25]]

 [[28639     1]
  [    2    13]]

 [[28442     9]
  [    8   196]]

 [[28577     2]
  [    7    69]]

 [[28365    34]
  [   53   203]]

 [[28636     0]
  [   15     4]]

 [[28642     0]
  [    4     9]]

 [[28576    12]
  [   32    35]]

 [[27171    20]
  [  118  1346]]

 [[28501     7]
  [   25   122]]

 [[28556     1]
  [   14    84]]

 [[28192     8]
  [   42   413]]

 [[28566     7]
  [    6    76]]

 [[28240     5]
  [   27   383]]

 [[28194    55]
  [   30   376]]

 [[28643     0]
  [   11     1]]

 [[28502     4]
  [   21   128]]

 [[27937    16]
  [   53   649]]

 [[28453     6]
  [    9   187]]

 [[28623     0]
  [   16    16]]

 [[28572    14]
  [    9    60]]

 [[28548    14]
  [    6    87]]

 [[28611    11]
  [    5    28]]

 [[28591    14]
  [    5    45]]

 [[28487    14]
  [   32   122]]]

===scores report===
metrics	scores
Accuracy	0.8183
MCC	0.8146
log_loss	0.8271
f1 score weighted	0.8127
f1 score macro	0.6955
f1 score micro	0.8183
roc_auc ovr	0.9921
roc_auc ovo	0.9885
precision	0.8284
recall	0.8183

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7eff00493ac0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7eff00493be0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7eff00493c40>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7eff00493a30>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [-4, -1, -1,  0,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-2,  2,  0,  0, -1],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2, -2, -1,  0,  0],
        [-2, -2, -1,  0,  0],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1]],

       [[ 0, -2, -1, -1,  0],
        [ 2,  0, -2,  1,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  1,  1, -1,  1],
        [ 2,  1,  0,  3,  0],
        [-4, -1, -1,  0,  0]],

       [[ 2, -4,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        [-1,  0,  1,  0,  2],
        ...,
        [ 2,  1,  0,  3,  0],
        [ 0, -2, -1, -1,  0],
        [-4, -1, -1,  0,  0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  96.,  46., 108.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.93      0.83       824
         1.0       0.00      0.00      0.00        14
         2.0       0.86      0.75      0.80        32
         3.0       0.00      0.00      0.00        12
         4.0       0.95      0.75      0.84        52
         5.0       0.82      0.77      0.79       175
         6.0       0.69      0.50      0.58       101
         7.0       0.64      0.30      0.41        98
         8.0       0.50      0.21      0.30        14
         9.0       0.64      0.39      0.48        70
        10.0       0.80      0.65      0.72       104
        11.0       0.67      0.11      0.19        18
        12.0       0.80      0.27      0.40        15
        13.0       0.70      0.67      0.68        42
        14.0       0.80      0.35      0.49        34
        15.0       1.00      0.88      0.93        65
        16.0       0.75      0.23      0.35        13
        17.0       1.00      0.16      0.27        19
        18.0       0.97      0.79      0.87        72
        19.0       0.80      0.13      0.23        30
        20.0       0.96      0.97      0.96        94
        21.0       0.64      0.89      0.75        46
        22.0       0.84      0.64      0.73        25
        23.0       0.92      0.96      0.94       345
        24.0       0.74      0.67      0.70        30
        25.0       0.00      0.00      0.00        20
        26.0       0.81      0.66      0.73       168
        27.0       1.00      0.60      0.75        35
        28.0       1.00      0.77      0.87        61
        29.0       0.84      0.65      0.73        63
        30.0       0.75      0.27      0.40        11
        31.0       0.00      0.00      0.00        12
        32.0       0.91      0.25      0.39        40
        33.0       0.91      0.72      0.80        74
        34.0       0.98      0.98      0.98        57
        35.0       0.75      0.75      0.75        16
        36.0       0.28      0.14      0.19        50
        37.0       0.94      0.80      0.86        20
        38.0       0.85      0.59      0.69        29
        39.0       0.94      0.88      0.91       101
        40.0       1.00      0.42      0.59        12
        41.0       1.00      1.00      1.00        14
        42.0       0.88      0.84      0.85        67
        43.0       0.96      0.92      0.94        76
        44.0       1.00      0.73      0.84        11
        45.0       1.00      0.89      0.94        37
        46.0       0.84      0.90      0.87      1613
        47.0       0.97      0.97      0.97       299
        48.0       1.00      0.96      0.98       243
        49.0       0.82      0.96      0.89       168
        50.0       0.79      0.81      0.80      1024
        51.0       0.95      0.61      0.74       353
        52.0       0.92      0.92      0.92        85
        53.0       0.54      0.85      0.66       606
        54.0       0.88      0.90      0.89       543
        55.0       0.93      0.66      0.77        79
        56.0       0.86      0.88      0.87       954
        57.0       0.86      0.89      0.88       247
        58.0       0.97      1.00      0.99        34
        59.0       0.75      0.89      0.81       876
        60.0       1.00      0.83      0.91        76
        61.0       0.84      0.84      0.84       566
        62.0       1.00      0.50      0.67        24
        63.0       0.89      0.62      0.73        55
        64.0       0.96      0.96      0.96       255
        65.0       0.00      0.00      0.00        13
        66.0       0.96      0.94      0.95       457
        67.0       0.95      0.57      0.71        37
        68.0       0.87      0.82      0.84      1189
        69.0       0.91      0.80      0.85       223
        70.0       0.77      0.53      0.62        19
        71.0       0.96      0.92      0.94       357
        72.0       0.87      0.42      0.57        31
        73.0       0.00      0.00      0.00        13
        74.0       0.98      0.95      0.96       128
        75.0       1.00      0.54      0.70        13
        76.0       0.65      0.81      0.72       461
        77.0       0.78      0.80      0.79       104
        78.0       0.50      0.32      0.39        53
        79.0       0.74      0.39      0.51        83
        80.0       0.78      0.44      0.56        79
        81.0       0.93      0.82      0.87        84
        82.0       0.91      0.87      0.89       334
        83.0       1.00      0.25      0.40        24
        84.0       0.47      0.81      0.59       518
        85.0       0.27      0.12      0.17        88
        86.0       1.00      0.25      0.40        12
        87.0       0.58      0.75      0.66       481
        88.0       0.73      0.61      0.66       126
        89.0       0.96      1.00      0.98        24
        90.0       0.85      0.70      0.77       152
        91.0       0.86      0.30      0.44        20
        92.0       0.80      0.15      0.25        27
        93.0       0.74      0.67      0.70        42
        94.0       0.71      0.36      0.48        33
        95.0       0.46      0.53      0.49       100
        96.0       0.90      0.80      0.84       415
        97.0       0.86      0.43      0.58       118
        98.0       0.91      0.78      0.84       100
        99.0       0.95      0.57      0.71       253
       100.0       0.96      0.89      0.92       116
       101.0       0.83      0.77      0.80       423
       102.0       0.88      0.74      0.80        99
       103.0       0.71      0.58      0.64        60
       104.0       0.84      0.77      0.81       265
       105.0       0.94      0.89      0.91        36
       106.0       0.68      0.83      0.75       495
       107.0       1.00      0.80      0.89        15
       108.0       0.85      0.86      0.85       611
       109.0       0.93      0.89      0.91       207
       110.0       0.92      0.50      0.65        22
       111.0       0.64      0.91      0.75       535
       112.0       0.74      0.60      0.66        98
       113.0       0.50      0.44      0.47        87
       114.0       1.00      0.91      0.95       110
       115.0       0.85      0.88      0.86       858
       116.0       0.58      0.43      0.50        60
       117.0       0.95      0.90      0.93       209
       118.0       0.00      0.00      0.00        12
       119.0       0.87      0.70      0.77        66
       120.0       0.99      0.87      0.93       157
       121.0       0.95      0.93      0.94        84
       122.0       0.89      0.60      0.72        55
       123.0       0.85      0.79      0.82       153
       124.0       0.83      0.84      0.83        51
       125.0       0.92      0.89      0.90       146
       126.0       0.57      0.47      0.51        77
       127.0       1.00      0.67      0.80        18
       128.0       0.98      0.80      0.88       197
       129.0       0.91      0.89      0.90       450
       130.0       1.00      0.09      0.17        11
       131.0       0.86      0.57      0.69        42
       132.0       1.00      0.73      0.85        15
       133.0       0.97      0.99      0.98       204
       134.0       1.00      0.97      0.99        76
       135.0       0.91      0.79      0.85       256
       136.0       1.00      0.20      0.33        20
       137.0       1.00      0.92      0.96        13
       138.0       0.97      0.49      0.65        67
       139.0       0.98      0.96      0.97      1464
       140.0       0.96      0.80      0.87       147
       141.0       0.89      0.82      0.85        98
       142.0       0.86      0.91      0.88       455
       143.0       0.88      0.93      0.90        82
       144.0       0.92      0.94      0.93       410
       145.0       0.94      0.93      0.93       406
       146.0       1.00      0.08      0.15        12
       147.0       0.90      0.87      0.89       148
       148.0       0.97      0.93      0.95       702
       149.0       0.97      0.95      0.96       196
       150.0       1.00      0.59      0.75        32
       151.0       0.77      0.86      0.81        69
       152.0       0.98      0.90      0.94        93
       153.0       0.97      0.94      0.95        33
       154.0       0.82      0.80      0.81        50
       155.0       0.85      0.86      0.86       153

    accuracy                           0.83     28655
   macro avg       0.82      0.66      0.71     28655
weighted avg       0.84      0.83      0.82     28655


===confusion_matrix===

[[767   0   0 ...   0   0   0]
 [  2   0   1 ...   0   0   0]
 [  2   0  24 ...   0   0   0]
 ...
 [  0   0   0 ...  31   1   1]
 [  0   0   0 ...   0  40   6]
 [  0   0   0 ...   0   7 132]]

===multilabel confusion matrix===

[[[27569   262]
  [   57   767]]

 [[28641     0]
  [   14     0]]

 [[28619     4]
  [    8    24]]

 [[28643     0]
  [   12     0]]

 [[28601     2]
  [   13    39]]

 [[28451    29]
  [   41   134]]

 [[28532    22]
  [   51    50]]

 [[28541    16]
  [   69    29]]

 [[28638     3]
  [   11     3]]

 [[28570    15]
  [   43    27]]

 [[28534    17]
  [   36    68]]

 [[28636     1]
  [   16     2]]

 [[28639     1]
  [   11     4]]

 [[28601    12]
  [   14    28]]

 [[28618     3]
  [   22    12]]

 [[28590     0]
  [    8    57]]

 [[28641     1]
  [   10     3]]

 [[28636     0]
  [   16     3]]

 [[28581     2]
  [   15    57]]

 [[28624     1]
  [   26     4]]

 [[28557     4]
  [    3    91]]

 [[28586    23]
  [    5    41]]

 [[28627     3]
  [    9    16]]

 [[28280    30]
  [   14   331]]

 [[28618     7]
  [   10    20]]

 [[28634     1]
  [   20     0]]

 [[28461    26]
  [   57   111]]

 [[28620     0]
  [   14    21]]

 [[28594     0]
  [   14    47]]

 [[28584     8]
  [   22    41]]

 [[28643     1]
  [    8     3]]

 [[28642     1]
  [   12     0]]

 [[28614     1]
  [   30    10]]

 [[28576     5]
  [   21    53]]

 [[28597     1]
  [    1    56]]

 [[28635     4]
  [    4    12]]

 [[28587    18]
  [   43     7]]

 [[28634     1]
  [    4    16]]

 [[28623     3]
  [   12    17]]

 [[28548     6]
  [   12    89]]

 [[28643     0]
  [    7     5]]

 [[28641     0]
  [    0    14]]

 [[28580     8]
  [   11    56]]

 [[28576     3]
  [    6    70]]

 [[28644     0]
  [    3     8]]

 [[28618     0]
  [    4    33]]

 [[26766   276]
  [  158  1455]]

 [[28348     8]
  [    8   291]]

 [[28412     0]
  [    9   234]]

 [[28452    35]
  [    6   162]]

 [[27404   227]
  [  193   831]]

 [[28290    12]
  [  139   214]]

 [[28563     7]
  [    7    78]]

 [[27612   437]
  [   89   517]]

 [[28047    65]
  [   52   491]]

 [[28572     4]
  [   27    52]]

 [[27566   135]
  [  114   840]]

 [[28373    35]
  [   26   221]]

 [[28620     1]
  [    0    34]]

 [[27525   254]
  [  100   776]]

 [[28579     0]
  [   13    63]]

 [[28000    89]
  [   92   474]]

 [[28631     0]
  [   12    12]]

 [[28596     4]
  [   21    34]]

 [[28390    10]
  [   10   245]]

 [[28642     0]
  [   13     0]]

 [[28179    19]
  [   26   431]]

 [[28617     1]
  [   16    21]]

 [[27321   145]
  [  216   973]]

 [[28415    17]
  [   45   178]]

 [[28633     3]
  [    9    10]]

 [[28285    13]
  [   29   328]]

 [[28622     2]
  [   18    13]]

 [[28642     0]
  [   13     0]]

 [[28524     3]
  [    6   122]]

 [[28642     0]
  [    6     7]]

 [[27995   199]
  [   87   374]]

 [[28527    24]
  [   21    83]]

 [[28585    17]
  [   36    17]]

 [[28561    11]
  [   51    32]]

 [[28566    10]
  [   44    35]]

 [[28566     5]
  [   15    69]]

 [[28291    30]
  [   45   289]]

 [[28631     0]
  [   18     6]]

 [[27664   473]
  [  100   418]]

 [[28537    30]
  [   77    11]]

 [[28643     0]
  [    9     3]]

 [[27918   256]
  [  121   360]]

 [[28500    29]
  [   49    77]]

 [[28630     1]
  [    0    24]]

 [[28484    19]
  [   46   106]]

 [[28634     1]
  [   14     6]]

 [[28627     1]
  [   23     4]]

 [[28603    10]
  [   14    28]]

 [[28617     5]
  [   21    12]]

 [[28493    62]
  [   47    53]]

 [[28203    37]
  [   85   330]]

 [[28529     8]
  [   67    51]]

 [[28547     8]
  [   22    78]]

 [[28395     7]
  [  110   143]]

 [[28535     4]
  [   13   103]]

 [[28164    68]
  [   99   324]]

 [[28546    10]
  [   26    73]]

 [[28581    14]
  [   25    35]]

 [[28351    39]
  [   60   205]]

 [[28617     2]
  [    4    32]]

 [[27966   194]
  [   84   411]]

 [[28640     0]
  [    3    12]]

 [[27953    91]
  [   87   524]]

 [[28435    13]
  [   23   184]]

 [[28632     1]
  [   11    11]]

 [[27847   273]
  [   50   485]]

 [[28536    21]
  [   39    59]]

 [[28530    38]
  [   49    38]]

 [[28545     0]
  [   10   100]]

 [[27663   134]
  [  106   752]]

 [[28576    19]
  [   34    26]]

 [[28436    10]
  [   20   189]]

 [[28643     0]
  [   12     0]]

 [[28582     7]
  [   20    46]]

 [[28497     1]
  [   21   136]]

 [[28567     4]
  [    6    78]]

 [[28596     4]
  [   22    33]]

 [[28481    21]
  [   32   121]]

 [[28595     9]
  [    8    43]]

 [[28497    12]
  [   16   130]]

 [[28551    27]
  [   41    36]]

 [[28637     0]
  [    6    12]]

 [[28454     4]
  [   40   157]]

 [[28167    38]
  [   48   402]]

 [[28644     0]
  [   10     1]]

 [[28609     4]
  [   18    24]]

 [[28640     0]
  [    4    11]]

 [[28444     7]
  [    3   201]]

 [[28579     0]
  [    2    74]]

 [[28380    19]
  [   54   202]]

 [[28635     0]
  [   16     4]]

 [[28642     0]
  [    1    12]]

 [[28587     1]
  [   34    33]]

 [[27164    27]
  [   60  1404]]

 [[28503     5]
  [   29   118]]

 [[28547    10]
  [   18    80]]

 [[28132    68]
  [   40   415]]

 [[28563    10]
  [    6    76]]

 [[28211    34]
  [   24   386]]

 [[28225    24]
  [   30   376]]

 [[28643     0]
  [   11     1]]

 [[28493    14]
  [   19   129]]

 [[27935    18]
  [   46   656]]

 [[28453     6]
  [    9   187]]

 [[28623     0]
  [   13    19]]

 [[28568    18]
  [   10    59]]

 [[28560     2]
  [    9    84]]

 [[28621     1]
  [    2    31]]

 [[28596     9]
  [   10    40]]

 [[28479    23]
  [   21   132]]]

===scores report===
metrics	scores
Accuracy	0.8273
MCC	0.8238
log_loss	0.7967
f1 score weighted	0.8241
f1 score macro	0.7077
f1 score micro	0.8273
roc_auc ovr	0.9923
roc_auc ovo	0.9887
precision	0.8391
recall	0.8273

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7eff00493ac0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7eff00493be0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7eff00493c40>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7eff00493a30>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-3, -1, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [ 3,  0,  0,  0,  0],
        ...,
        [ 2, -4,  0,  0,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-1,  0,  1,  0,  2],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 2,  1,  0,  3,  0],
        [ 0, -1,  3,  0, -2],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 2, -4,  0,  0,  0],
        [-4, -1, -1,  0,  0],
        [-1,  0,  1,  0,  2]]], dtype=int8), 'y_test': array([ 56.,  56., 115., ...,  96., 109.,  88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.92      0.84       824
         1.0       0.00      0.00      0.00        14
         2.0       1.00      0.59      0.75        32
         3.0       0.00      0.00      0.00        11
         4.0       0.97      0.71      0.82        51
         5.0       0.91      0.70      0.79       176
         6.0       0.64      0.51      0.57       102
         7.0       0.66      0.22      0.33        97
         8.0       0.70      0.50      0.58        14
         9.0       0.67      0.23      0.34        70
        10.0       0.96      0.84      0.90       103
        11.0       0.50      0.11      0.18        18
        12.0       0.00      0.00      0.00        15
        13.0       0.60      0.77      0.67        43
        14.0       0.94      0.44      0.60        34
        15.0       0.93      0.57      0.70        65
        16.0       0.67      0.31      0.42        13
        17.0       0.88      0.37      0.52        19
        18.0       0.98      0.88      0.93        72
        19.0       0.33      0.03      0.06        30
        20.0       0.98      0.99      0.98        94
        21.0       0.91      0.70      0.79        46
        22.0       1.00      0.36      0.53        25
        23.0       0.97      0.91      0.94       345
        24.0       0.95      0.63      0.76        30
        25.0       0.00      0.00      0.00        20
        26.0       0.88      0.67      0.76       168
        27.0       1.00      0.54      0.70        35
        28.0       1.00      0.75      0.86        61
        29.0       0.76      0.79      0.78        63
        30.0       0.00      0.00      0.00        11
        31.0       0.00      0.00      0.00        12
        32.0       0.82      0.23      0.35        40
        33.0       1.00      0.69      0.82        74
        34.0       0.98      1.00      0.99        57
        35.0       1.00      1.00      1.00        15
        36.0       0.40      0.08      0.13        50
        37.0       0.85      0.89      0.87        19
        38.0       1.00      0.48      0.65        29
        39.0       0.92      0.86      0.89       101
        40.0       1.00      0.54      0.70        13
        41.0       1.00      0.86      0.92        14
        42.0       0.81      0.79      0.80        66
        43.0       0.98      0.80      0.88        76
        44.0       1.00      0.91      0.95        11
        45.0       0.97      0.81      0.88        37
        46.0       0.84      0.93      0.88      1612
        47.0       0.88      0.98      0.93       299
        48.0       0.98      0.96      0.97       243
        49.0       0.93      0.87      0.90       168
        50.0       0.65      0.86      0.74      1024
        51.0       0.91      0.61      0.73       353
        52.0       0.95      0.84      0.89        85
        53.0       0.47      0.87      0.61       606
        54.0       0.62      0.92      0.74       543
        55.0       0.91      0.76      0.83        78
        56.0       0.77      0.90      0.83       954
        57.0       0.79      0.90      0.84       247
        58.0       1.00      1.00      1.00        34
        59.0       0.85      0.81      0.83       877
        60.0       1.00      0.78      0.87        76
        61.0       0.85      0.83      0.84       566
        62.0       1.00      0.12      0.22        24
        63.0       0.91      0.56      0.70        55
        64.0       0.99      0.95      0.97       255
        65.0       1.00      0.36      0.53        14
        66.0       1.00      0.91      0.95       457
        67.0       1.00      0.49      0.65        37
        68.0       0.68      0.89      0.77      1189
        69.0       0.87      0.88      0.88       224
        70.0       0.33      0.79      0.46        19
        71.0       0.97      0.95      0.96       357
        72.0       1.00      0.16      0.27        32
        73.0       0.00      0.00      0.00        12
        74.0       0.98      0.94      0.96       127
        75.0       1.00      0.83      0.91        12
        76.0       0.89      0.66      0.76       460
        77.0       0.92      0.82      0.87       103
        78.0       0.73      0.21      0.33        52
        79.0       0.61      0.54      0.57        83
        80.0       0.78      0.31      0.45        80
        81.0       1.00      0.70      0.83        84
        82.0       0.82      0.86      0.84       334
        83.0       1.00      0.09      0.16        23
        84.0       0.89      0.70      0.78       519
        85.0       0.05      0.01      0.02        88
        86.0       0.00      0.00      0.00        12
        87.0       0.65      0.44      0.52       480
        88.0       0.78      0.56      0.65       126
        89.0       1.00      0.92      0.96        25
        90.0       0.90      0.62      0.73       152
        91.0       0.45      0.25      0.32        20
        92.0       1.00      0.25      0.40        28
        93.0       0.81      0.71      0.76        42
        94.0       1.00      0.03      0.06        34
        95.0       0.95      0.20      0.33       100
        96.0       0.74      0.80      0.77       415
        97.0       0.88      0.32      0.47       118
        98.0       0.94      0.77      0.84        99
        99.0       0.81      0.72      0.76       253
       100.0       0.98      0.84      0.91       116
       101.0       0.77      0.73      0.75       423
       102.0       0.87      0.73      0.79        99
       103.0       0.93      0.45      0.61        60
       104.0       0.72      0.84      0.77       265
       105.0       0.79      0.73      0.76        37
       106.0       0.85      0.77      0.81       495
       107.0       1.00      0.67      0.80        15
       108.0       0.79      0.85      0.82       611
       109.0       0.99      0.83      0.90       206
       110.0       0.47      0.36      0.41        22
       111.0       0.61      0.85      0.71       534
       112.0       0.72      0.51      0.60        98
       113.0       0.64      0.55      0.59        87
       114.0       0.96      0.85      0.90       110
       115.0       0.74      0.91      0.82       858
       116.0       0.79      0.49      0.61        61
       117.0       0.91      0.92      0.91       209
       118.0       0.00      0.00      0.00        13
       119.0       0.72      0.72      0.72        65
       120.0       0.96      0.94      0.95       156
       121.0       0.98      0.96      0.97        85
       122.0       0.82      0.48      0.61        56
       123.0       0.91      0.69      0.79       154
       124.0       0.93      0.83      0.88        52
       125.0       0.87      0.90      0.89       146
       126.0       0.78      0.36      0.50        77
       127.0       1.00      0.61      0.76        18
       128.0       0.97      0.62      0.76       198
       129.0       0.91      0.92      0.91       450
       130.0       0.00      0.00      0.00        11
       131.0       0.92      0.56      0.70        43
       132.0       0.93      0.87      0.90        15
       133.0       0.99      0.91      0.95       205
       134.0       0.99      0.95      0.97        77
       135.0       0.91      0.78      0.84       255
       136.0       1.00      0.20      0.33        20
       137.0       1.00      0.83      0.91        12
       138.0       0.83      0.36      0.50        67
       139.0       0.90      0.97      0.93      1464
       140.0       0.96      0.84      0.89       147
       141.0       0.96      0.74      0.84        98
       142.0       0.95      0.92      0.93       455
       143.0       0.96      0.94      0.95        82
       144.0       0.97      0.92      0.95       411
       145.0       0.98      0.89      0.93       405
       146.0       1.00      0.09      0.17        11
       147.0       0.96      0.89      0.92       148
       148.0       0.95      0.96      0.95       702
       149.0       0.98      0.97      0.98       196
       150.0       0.86      0.56      0.68        32
       151.0       0.97      0.81      0.88        69
       152.0       0.93      0.92      0.93        93
       153.0       1.00      0.85      0.92        33
       154.0       0.97      0.66      0.79        50
       155.0       0.80      0.97      0.88       154

    accuracy                           0.81     28655
   macro avg       0.81      0.64      0.68     28655
weighted avg       0.83      0.81      0.81     28655


===confusion_matrix===

[[757   0   0 ...   0   0   0]
 [  0   0   0 ...   0   0   0]
 [  0   0  19 ...   0   0   0]
 ...
 [  0   0   0 ...  28   0   3]
 [  0   0   0 ...   0  33  16]
 [  0   0   0 ...   0   1 149]]

===multilabel confusion matrix===

[[[27609   222]
  [   67   757]]

 [[28641     0]
  [   14     0]]

 [[28623     0]
  [   13    19]]

 [[28644     0]
  [   11     0]]

 [[28603     1]
  [   15    36]]

 [[28467    12]
  [   52   124]]

 [[28524    29]
  [   50    52]]

 [[28547    11]
  [   76    21]]

 [[28638     3]
  [    7     7]]

 [[28577     8]
  [   54    16]]

 [[28548     4]
  [   16    87]]

 [[28635     2]
  [   16     2]]

 [[28640     0]
  [   15     0]]

 [[28590    22]
  [   10    33]]

 [[28620     1]
  [   19    15]]

 [[28587     3]
  [   28    37]]

 [[28640     2]
  [    9     4]]

 [[28635     1]
  [   12     7]]

 [[28582     1]
  [    9    63]]

 [[28623     2]
  [   29     1]]

 [[28559     2]
  [    1    93]]

 [[28606     3]
  [   14    32]]

 [[28630     0]
  [   16     9]]

 [[28300    10]
  [   31   314]]

 [[28624     1]
  [   11    19]]

 [[28635     0]
  [   20     0]]

 [[28472    15]
  [   56   112]]

 [[28620     0]
  [   16    19]]

 [[28594     0]
  [   15    46]]

 [[28576    16]
  [   13    50]]

 [[28644     0]
  [   11     0]]

 [[28642     1]
  [   12     0]]

 [[28613     2]
  [   31     9]]

 [[28581     0]
  [   23    51]]

 [[28597     1]
  [    0    57]]

 [[28640     0]
  [    0    15]]

 [[28599     6]
  [   46     4]]

 [[28633     3]
  [    2    17]]

 [[28626     0]
  [   15    14]]

 [[28546     8]
  [   14    87]]

 [[28642     0]
  [    6     7]]

 [[28641     0]
  [    2    12]]

 [[28577    12]
  [   14    52]]

 [[28578     1]
  [   15    61]]

 [[28644     0]
  [    1    10]]

 [[28617     1]
  [    7    30]]

 [[26749   294]
  [  118  1494]]

 [[28314    42]
  [    5   294]]

 [[28407     5]
  [    9   234]]

 [[28476    11]
  [   22   146]]

 [[27153   478]
  [  143   881]]

 [[28281    21]
  [  136   217]]

 [[28566     4]
  [   14    71]]

 [[27450   599]
  [   81   525]]

 [[27801   311]
  [   42   501]]

 [[28571     6]
  [   19    59]]

 [[27441   260]
  [   93   861]]

 [[28347    61]
  [   24   223]]

 [[28621     0]
  [    0    34]]

 [[27654   124]
  [  166   711]]

 [[28579     0]
  [   17    59]]

 [[28007    82]
  [   98   468]]

 [[28631     0]
  [   21     3]]

 [[28597     3]
  [   24    31]]

 [[28398     2]
  [   12   243]]

 [[28641     0]
  [    9     5]]

 [[28196     2]
  [   41   416]]

 [[28618     0]
  [   19    18]]

 [[26965   501]
  [  127  1062]]

 [[28402    29]
  [   27   197]]

 [[28605    31]
  [    4    15]]

 [[28289     9]
  [   19   338]]

 [[28623     0]
  [   27     5]]

 [[28642     1]
  [   12     0]]

 [[28526     2]
  [    7   120]]

 [[28643     0]
  [    2    10]]

 [[28158    37]
  [  155   305]]

 [[28545     7]
  [   19    84]]

 [[28599     4]
  [   41    11]]

 [[28543    29]
  [   38    45]]

 [[28568     7]
  [   55    25]]

 [[28571     0]
  [   25    59]]

 [[28259    62]
  [   47   287]]

 [[28632     0]
  [   21     2]]

 [[28093    43]
  [  157   362]]

 [[28547    20]
  [   87     1]]

 [[28643     0]
  [   12     0]]

 [[28060   115]
  [  270   210]]

 [[28509    20]
  [   55    71]]

 [[28630     0]
  [    2    23]]

 [[28492    11]
  [   58    94]]

 [[28629     6]
  [   15     5]]

 [[28627     0]
  [   21     7]]

 [[28606     7]
  [   12    30]]

 [[28621     0]
  [   33     1]]

 [[28554     1]
  [   80    20]]

 [[28124   116]
  [   84   331]]

 [[28532     5]
  [   80    38]]

 [[28551     5]
  [   23    76]]

 [[28360    42]
  [   71   182]]

 [[28537     2]
  [   18    98]]

 [[28139    93]
  [  114   309]]

 [[28545    11]
  [   27    72]]

 [[28593     2]
  [   33    27]]

 [[28302    88]
  [   43   222]]

 [[28611     7]
  [   10    27]]

 [[28094    66]
  [  112   383]]

 [[28640     0]
  [    5    10]]

 [[27907   137]
  [   94   517]]

 [[28448     1]
  [   35   171]]

 [[28624     9]
  [   14     8]]

 [[27824   297]
  [   78   456]]

 [[28538    19]
  [   48    50]]

 [[28541    27]
  [   39    48]]

 [[28541     4]
  [   17    93]]

 [[27521   276]
  [   74   784]]

 [[28586     8]
  [   31    30]]

 [[28426    20]
  [   17   192]]

 [[28642     0]
  [   13     0]]

 [[28572    18]
  [   18    47]]

 [[28493     6]
  [    9   147]]

 [[28568     2]
  [    3    82]]

 [[28593     6]
  [   29    27]]

 [[28490    11]
  [   47   107]]

 [[28600     3]
  [    9    43]]

 [[28490    19]
  [   15   131]]

 [[28570     8]
  [   49    28]]

 [[28637     0]
  [    7    11]]

 [[28453     4]
  [   75   123]]

 [[28163    42]
  [   38   412]]

 [[28644     0]
  [   11     0]]

 [[28610     2]
  [   19    24]]

 [[28639     1]
  [    2    13]]

 [[28448     2]
  [   18   187]]

 [[28577     1]
  [    4    73]]

 [[28380    20]
  [   56   199]]

 [[28635     0]
  [   16     4]]

 [[28643     0]
  [    2    10]]

 [[28583     5]
  [   43    24]]

 [[27031   160]
  [   49  1415]]

 [[28503     5]
  [   24   123]]

 [[28554     3]
  [   25    73]]

 [[28179    21]
  [   38   417]]

 [[28570     3]
  [    5    77]]

 [[28233    11]
  [   31   380]]

 [[28243     7]
  [   44   361]]

 [[28644     0]
  [   10     1]]

 [[28502     5]
  [   17   131]]

 [[27914    39]
  [   31   671]]

 [[28455     4]
  [    5   191]]

 [[28620     3]
  [   14    18]]

 [[28584     2]
  [   13    56]]

 [[28556     6]
  [    7    86]]

 [[28622     0]
  [    5    28]]

 [[28604     1]
  [   17    33]]

 [[28464    37]
  [    5   149]]]

===scores report===
metrics	scores
Accuracy	0.8135
MCC	0.8097
log_loss	0.8583
f1 score weighted	0.8057
f1 score macro	0.6832
f1 score micro	0.8135
roc_auc ovr	0.9920
roc_auc ovo	0.9882
precision	0.8272
recall	0.8135

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8302275265214963	0.8268661994711681	0.77934631267298	0.8249283498195419	0.7054616549144016	0.8302275265214963	0.9931407424718267	0.9900526604414311	0.8392126299254834	0.8302275265214963
1	0.8360146571279009	0.8328069401656805	0.7758102796310468	0.8351538925193742	0.7130566502987862	0.8360146571279009	0.9929975669667049	0.9901169489010678	0.8490483521202465	0.8360146571279009
2	0.8183214098761123	0.8145960380067674	0.8270619377940633	0.8127365766378651	0.6955059844303167	0.8183214098761123	0.9921095042848338	0.9885173148311395	0.8284180799017541	0.8183214098761123
3	0.8273250741580876	0.8238397719618447	0.7967217312158142	0.8240647056257919	0.7076507660216437	0.8273250741580876	0.9923399223657777	0.9886582110556406	0.839107618547513	0.8273250741580876
4	0.8134705984993893	0.8096773071042445	0.8582871270685997	0.8057178636610601	0.6832341308045617	0.8134705984993892	0.992047691564831	0.9881984364500562	0.827205618356049	0.8134705984993893
mean	0.8250718532365973	0.821557251341941	0.8074454776765009	0.8205202776527267	0.7009818372939419	0.8250718532365973	0.9925270855307948	0.9891087143358671	0.8365984597702092	0.8250718532365973
std	0.008143224491390365	0.008361123075743548	0.03122507450071593	0.010255088643389762	0.010538600814215917	0.008143224491390396	0.0004554449131855105	0.0008110343516471168	0.008040816718738889	0.008143224491390365

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 81428.2185 secs

