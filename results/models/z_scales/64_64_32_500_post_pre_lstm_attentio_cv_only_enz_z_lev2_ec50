/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_z_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_z_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff16c175a90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff16c175bb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff16c175c10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff16c175a00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [-2,  0,  0,  1,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  1, -2,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 2, -4,  0,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-3, -1, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [ 3,  0,  0,  0,  0],
        ...,
        [ 2, -4,  0,  0,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-1,  0,  1,  0,  2],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.73      0.71       402
         1.0       1.00      0.47      0.64        19
         2.0       0.68      0.57      0.62        82
         3.0       0.60      0.19      0.29        16
         4.0       0.56      0.24      0.34        62
         5.0       0.67      0.52      0.58       277
         6.0       0.83      0.53      0.64        36
         7.0       0.50      0.12      0.19        26
         8.0       0.86      0.43      0.57        72
         9.0       0.53      0.70      0.60        30
        10.0       0.64      0.68      0.66       156
        11.0       0.59      0.38      0.46       168
        12.0       0.65      0.48      0.55        83
        13.0       0.75      0.06      0.11        53
        14.0       0.83      0.16      0.27        31
        15.0       0.79      0.29      0.42        52
        16.0       0.77      0.59      0.67        94
        17.0       0.83      0.81      0.82       885
        18.0       0.72      0.60      0.66        48
        19.0       0.55      0.76      0.64       781
        20.0       0.69      0.73      0.71       591
        21.0       0.83      0.67      0.74       385
        22.0       0.68      0.80      0.73       128
        23.0       0.81      0.75      0.78      1888
        24.0       0.78      0.70      0.74       169
        25.0       0.50      0.70      0.58      1296
        26.0       0.61      0.51      0.56       381
        27.0       0.60      0.21      0.32        14
        28.0       0.59      0.67      0.63       769
        29.0       0.42      0.46      0.44       372
        30.0       0.81      0.71      0.76       631
        31.0       1.00      0.18      0.31        11
        32.0       0.45      0.53      0.49       316
        33.0       0.67      0.58      0.62       405
        34.0       0.59      0.57      0.58        96
        35.0       0.00      0.00      0.00        26
        36.0       0.76      0.40      0.53        65
        37.0       0.85      0.52      0.65        21
        38.0       0.68      0.55      0.61       121
        39.0       0.87      0.71      0.78       114
        40.0       0.79      0.67      0.73       207
        41.0       0.73      0.61      0.66       194
        42.0       0.53      0.45      0.48        47
        43.0       0.92      0.84      0.88       431
        44.0       0.70      0.58      0.63        67
        45.0       0.83      0.74      0.79       488
        46.0       0.76      0.50      0.60        62
        47.0       0.85      0.88      0.86       264
        48.0       0.76      0.63      0.69        49
        49.0       0.68      0.77      0.72        30
        50.0       0.86      0.80      0.83        15
        51.0       0.88      0.33      0.48        21
        52.0       0.62      0.81      0.70        73

    accuracy                           0.68     13120
   macro avg       0.70      0.55      0.59     13120
weighted avg       0.69      0.68      0.68     13120


===confusion_matrix===

[[294   0   0 ...   0   0   0]
 [  0   9   2 ...   0   0   0]
 [  1   0  47 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   2]
 [  0   0   0 ...   0   7  11]
 [  0   0   0 ...   1   0  59]]

===multilabel confusion matrix===

[[[12587   131]
  [  108   294]]

 [[13101     0]
  [   10     9]]

 [[13016    22]
  [   35    47]]

 [[13102     2]
  [   13     3]]

 [[13046    12]
  [   47    15]]

 [[12771    72]
  [  134   143]]

 [[13080     4]
  [   17    19]]

 [[13091     3]
  [   23     3]]

 [[13043     5]
  [   41    31]]

 [[13071    19]
  [    9    21]]

 [[12905    59]
  [   50   106]]

 [[12908    44]
  [  105    63]]

 [[13015    22]
  [   43    40]]

 [[13066     1]
  [   50     3]]

 [[13088     1]
  [   26     5]]

 [[13064     4]
  [   37    15]]

 [[13010    16]
  [   39    55]]

 [[12088   147]
  [  171   714]]

 [[13061    11]
  [   19    29]]

 [[11848   491]
  [  184   597]]

 [[12336   193]
  [  159   432]]

 [[12683    52]
  [  126   259]]

 [[12943    49]
  [   26   102]]

 [[10888   344]
  [  467  1421]]

 [[12917    34]
  [   50   119]]

 [[10907   917]
  [  383   913]]

 [[12615   124]
  [  187   194]]

 [[13104     2]
  [   11     3]]

 [[11990   361]
  [  254   515]]

 [[12507   241]
  [  201   171]]

 [[12381   108]
  [  180   451]]

 [[13109     0]
  [    9     2]]

 [[12595   209]
  [  147   169]]

 [[12597   118]
  [  170   235]]

 [[12985    39]
  [   41    55]]

 [[13093     1]
  [   26     0]]

 [[13047     8]
  [   39    26]]

 [[13097     2]
  [   10    11]]

 [[12968    31]
  [   55    66]]

 [[12994    12]
  [   33    81]]

 [[12877    36]
  [   68   139]]

 [[12881    45]
  [   75   119]]

 [[13054    19]
  [   26    21]]

 [[12657    32]
  [   68   363]]

 [[13036    17]
  [   28    39]]

 [[12560    72]
  [  126   362]]

 [[13048    10]
  [   31    31]]

 [[12814    42]
  [   31   233]]

 [[13061    10]
  [   18    31]]

 [[13079    11]
  [    7    23]]

 [[13103     2]
  [    3    12]]

 [[13098     1]
  [   14     7]]

 [[13011    36]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.6765
MCC	0.6569
log_loss	1.3579
f1 score weighted	0.6758
f1 score macro	0.5855
f1 score micro	0.6765
roc_auc ovr	0.9573
roc_auc ovo	0.9543
precision	0.6945
recall	0.6765

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff16c175a90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff16c175bb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff16c175c10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff16c175a00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 1,  0, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 3,  0,  1, -2,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 2,  0, -2,  1,  0],
        [-2, -2, -1,  0,  0],
        [-4,  1,  1,  0,  0],
        ...,
        [ 2,  1,  0,  3,  0],
        [-1,  0,  1,  0,  2],
        [-4, -1, -1,  0,  0]],

       [[ 3,  1,  1, -1,  1],
        [ 2, -1,  1, -1,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [-4, -1, -1,  0,  0],
        [-2,  2,  0,  0, -1],
        [ 0, -2,  0,  0,  1]],

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  1, -2,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.63      0.73      0.67       402
         1.0       0.82      0.47      0.60        19
         2.0       0.82      0.51      0.63        81
         3.0       0.50      0.06      0.11        16
         4.0       0.45      0.24      0.32        62
         5.0       0.72      0.59      0.65       277
         6.0       0.85      0.81      0.83        36
         7.0       0.80      0.31      0.44        26
         8.0       0.69      0.58      0.63        73
         9.0       0.59      0.34      0.43        29
        10.0       0.70      0.69      0.69       156
        11.0       0.52      0.57      0.55       168
        12.0       0.53      0.58      0.55        83
        13.0       0.27      0.06      0.09        53
        14.0       0.39      0.38      0.38        32
        15.0       0.62      0.50      0.55        52
        16.0       0.72      0.57      0.64        95
        17.0       0.81      0.80      0.80       884
        18.0       0.64      0.71      0.67        48
        19.0       0.57      0.78      0.66       782
        20.0       0.75      0.70      0.73       591
        21.0       0.75      0.73      0.74       385
        22.0       0.77      0.83      0.80       128
        23.0       0.78      0.81      0.79      1888
        24.0       0.85      0.63      0.72       169
        25.0       0.66      0.63      0.64      1295
        26.0       0.62      0.60      0.61       381
        27.0       0.83      0.36      0.50        14
        28.0       0.60      0.67      0.63       769
        29.0       0.53      0.57      0.55       371
        30.0       0.78      0.75      0.76       631
        31.0       0.80      0.36      0.50        11
        32.0       0.44      0.60      0.50       316
        33.0       0.64      0.66      0.65       405
        34.0       0.70      0.53      0.60        96
        35.0       0.00      0.00      0.00        26
        36.0       0.71      0.60      0.65        65
        37.0       1.00      0.68      0.81        22
        38.0       0.74      0.56      0.64       121
        39.0       0.82      0.68      0.74       113
        40.0       0.77      0.70      0.74       208
        41.0       0.72      0.63      0.67       193
        42.0       0.53      0.57      0.55        46
        43.0       0.93      0.91      0.92       431
        44.0       0.69      0.73      0.71        66
        45.0       0.86      0.73      0.79       489
        46.0       0.86      0.81      0.83        62
        47.0       0.81      0.87      0.84       264
        48.0       0.59      0.55      0.57        49
        49.0       0.90      0.87      0.89        31
        50.0       1.00      0.94      0.97        16
        51.0       0.85      0.81      0.83        21
        52.0       0.78      0.86      0.82        73

    accuracy                           0.70     13120
   macro avg       0.69      0.61      0.63     13120
weighted avg       0.71      0.70      0.70     13120


===confusion_matrix===

[[292   0   0 ...   0   0   0]
 [  0   9   0 ...   0   0   0]
 [  1   0  41 ...   0   0   0]
 ...
 [  0   0   0 ...  15   0   1]
 [  0   0   0 ...   0  17   3]
 [  0   0   0 ...   0   2  63]]

===multilabel confusion matrix===

[[[12544   174]
  [  110   292]]

 [[13099     2]
  [   10     9]]

 [[13030     9]
  [   40    41]]

 [[13103     1]
  [   15     1]]

 [[13040    18]
  [   47    15]]

 [[12781    62]
  [  114   163]]

 [[13079     5]
  [    7    29]]

 [[13092     2]
  [   18     8]]

 [[13028    19]
  [   31    42]]

 [[13084     7]
  [   19    10]]

 [[12918    46]
  [   49   107]]

 [[12864    88]
  [   72    96]]

 [[12995    42]
  [   35    48]]

 [[13059     8]
  [   50     3]]

 [[13069    19]
  [   20    12]]

 [[13052    16]
  [   26    26]]

 [[13004    21]
  [   41    54]]

 [[12070   166]
  [  178   706]]

 [[13053    19]
  [   14    34]]

 [[11876   462]
  [  169   613]]

 [[12392   137]
  [  177   414]]

 [[12643    92]
  [  105   280]]

 [[12960    32]
  [   22   106]]

 [[10809   423]
  [  365  1523]]

 [[12933    18]
  [   63   106]]

 [[11412   413]
  [  485   810]]

 [[12602   137]
  [  154   227]]

 [[13105     1]
  [    9     5]]

 [[12004   347]
  [  255   514]]

 [[12561   188]
  [  161   210]]

 [[12359   130]
  [  160   471]]

 [[13108     1]
  [    7     4]]

 [[12559   245]
  [  127   189]]

 [[12564   151]
  [  136   269]]

 [[13002    22]
  [   45    51]]

 [[13088     6]
  [   26     0]]

 [[13039    16]
  [   26    39]]

 [[13098     0]
  [    7    15]]

 [[12975    24]
  [   53    68]]

 [[12990    17]
  [   36    77]]

 [[12869    43]
  [   62   146]]

 [[12880    47]
  [   71   122]]

 [[13051    23]
  [   20    26]]

 [[12658    31]
  [   38   393]]

 [[13032    22]
  [   18    48]]

 [[12575    56]
  [  134   355]]

 [[13050     8]
  [   12    50]]

 [[12801    55]
  [   34   230]]

 [[13052    19]
  [   22    27]]

 [[13086     3]
  [    4    27]]

 [[13104     0]
  [    1    15]]

 [[13096     3]
  [    4    17]]

 [[13029    18]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.7017
MCC	0.6837
log_loss	1.3001
f1 score weighted	0.7005
f1 score macro	0.6338
f1 score micro	0.7017
roc_auc ovr	0.9638
roc_auc ovo	0.9643
precision	0.7080
recall	0.7017

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff16c175a90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff16c175bb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff16c175c10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff16c175a00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 0, -2, -1, -1,  0],
        [-2,  2,  0,  0, -1],
        [ 2, -1,  1, -1,  0],
        ...,
        [ 3,  0,  0,  0,  0],
        [-4,  1,  1,  0,  0],
        [ 3,  0,  1, -2,  0]],

       [[-2, -2, -1,  0,  0],
        [-2, -2, -1,  0,  0],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1]],

       [[ 0, -2, -1, -1,  0],
        [ 2,  0, -2,  1,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  1,  1, -1,  1],
        [ 2,  1,  0,  3,  0],
        [-4, -1, -1,  0,  0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.58      0.78      0.66       401
         1.0       1.00      0.40      0.57        20
         2.0       0.90      0.46      0.61        82
         3.0       0.20      0.06      0.10        16
         4.0       0.59      0.16      0.25        62
         5.0       0.83      0.47      0.60       277
         6.0       0.89      0.69      0.78        36
         7.0       0.60      0.12      0.20        25
         8.0       0.75      0.55      0.63        73
         9.0       0.73      0.55      0.63        29
        10.0       0.78      0.63      0.70       156
        11.0       0.52      0.54      0.53       168
        12.0       0.54      0.45      0.49        83
        13.0       0.25      0.02      0.03        54
        14.0       0.35      0.19      0.25        31
        15.0       0.58      0.28      0.38        53
        16.0       0.79      0.56      0.65        95
        17.0       0.82      0.82      0.82       884
        18.0       0.67      0.60      0.63        47
        19.0       0.74      0.71      0.72       782
        20.0       0.74      0.76      0.75       592
        21.0       0.83      0.68      0.74       385
        22.0       0.82      0.78      0.80       128
        23.0       0.76      0.81      0.79      1887
        24.0       0.79      0.68      0.73       168
        25.0       0.57      0.70      0.63      1295
        26.0       0.58      0.60      0.59       381
        27.0       0.90      0.64      0.75        14
        28.0       0.61      0.62      0.62       768
        29.0       0.56      0.53      0.54       372
        30.0       0.88      0.72      0.79       631
        31.0       1.00      0.10      0.18        10
        32.0       0.41      0.62      0.49       316
        33.0       0.51      0.71      0.59       405
        34.0       0.70      0.59      0.64        96
        35.0       0.00      0.00      0.00        26
        36.0       0.81      0.44      0.57        66
        37.0       0.93      0.64      0.76        22
        38.0       0.60      0.61      0.60       121
        39.0       0.94      0.68      0.79       113
        40.0       0.83      0.67      0.74       208
        41.0       0.69      0.71      0.70       194
        42.0       0.83      0.43      0.57        46
        43.0       0.92      0.86      0.89       431
        44.0       0.86      0.67      0.75        66
        45.0       0.76      0.82      0.79       489
        46.0       0.93      0.66      0.77        62
        47.0       0.83      0.89      0.86       263
        48.0       0.85      0.56      0.67        50
        49.0       0.86      0.61      0.72        31
        50.0       0.78      0.88      0.82        16
        51.0       0.89      0.81      0.85        21
        52.0       0.70      0.88      0.78        73

    accuracy                           0.70     13120
   macro avg       0.71      0.57      0.61     13120
weighted avg       0.71      0.70      0.70     13120


===confusion_matrix===

[[311   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  1   0  38 ...   0   0   0]
 ...
 [  0   0   0 ...  14   0   1]
 [  0   0   0 ...   0  17   3]
 [  0   0   0 ...   0   2  64]]

===multilabel confusion matrix===

[[[12490   229]
  [   90   311]]

 [[13100     0]
  [   12     8]]

 [[13034     4]
  [   44    38]]

 [[13100     4]
  [   15     1]]

 [[13051     7]
  [   52    10]]

 [[12816    27]
  [  148   129]]

 [[13081     3]
  [   11    25]]

 [[13093     2]
  [   22     3]]

 [[13034    13]
  [   33    40]]

 [[13085     6]
  [   13    16]]

 [[12936    28]
  [   57    99]]

 [[12867    85]
  [   77    91]]

 [[13006    31]
  [   46    37]]

 [[13063     3]
  [   53     1]]

 [[13078    11]
  [   25     6]]

 [[13056    11]
  [   38    15]]

 [[13011    14]
  [   42    53]]

 [[12083   153]
  [  163   721]]

 [[13059    14]
  [   19    28]]

 [[12137   201]
  [  224   558]]

 [[12368   160]
  [  141   451]]

 [[12680    55]
  [  125   260]]

 [[12970    22]
  [   28   100]]

 [[10763   470]
  [  359  1528]]

 [[12922    30]
  [   54   114]]

 [[11149   676]
  [  386   909]]

 [[12574   165]
  [  152   229]]

 [[13105     1]
  [    5     9]]

 [[12054   298]
  [  292   476]]

 [[12592   156]
  [  176   196]]

 [[12430    59]
  [  178   453]]

 [[13110     0]
  [    9     1]]

 [[12520   284]
  [  121   195]]

 [[12437   278]
  [  117   288]]

 [[12999    25]
  [   39    57]]

 [[13094     0]
  [   26     0]]

 [[13047     7]
  [   37    29]]

 [[13097     1]
  [    8    14]]

 [[12949    50]
  [   47    74]]

 [[13002     5]
  [   36    77]]

 [[12884    28]
  [   69   139]]

 [[12864    62]
  [   56   138]]

 [[13070     4]
  [   26    20]]

 [[12657    32]
  [   61   370]]

 [[13047     7]
  [   22    44]]

 [[12507   124]
  [   86   403]]

 [[13055     3]
  [   21    41]]

 [[12808    49]
  [   28   235]]

 [[13065     5]
  [   22    28]]

 [[13086     3]
  [   12    19]]

 [[13100     4]
  [    2    14]]

 [[13097     2]
  [    4    17]]

 [[13020    27]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6998
MCC	0.6813
log_loss	1.2613
f1 score weighted	0.6979
f1 score macro	0.6137
f1 score micro	0.6998
roc_auc ovr	0.9641
roc_auc ovo	0.9626
precision	0.7127
recall	0.6998

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff16c175a90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff16c175bb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff16c175c10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff16c175a00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-2, -2, -1,  0,  0],
        [ 2, -4,  0,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 2, -1,  1, -1,  0],
        [ 2,  1,  0,  3,  0],
        [-2, -2, -1,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  0,  0,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-4, -1, -1,  0,  0],
        [-4, -1, -1,  0,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 2, -1,  1, -1,  0],
        [ 0, -2,  0,  0,  1]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.64      0.81      0.71       401
         1.0       0.69      0.45      0.55        20
         2.0       0.82      0.56      0.67        82
         3.0       0.50      0.07      0.12        15
         4.0       0.39      0.19      0.26        62
         5.0       0.68      0.60      0.64       278
         6.0       0.86      0.69      0.77        36
         7.0       0.60      0.24      0.34        25
         8.0       0.73      0.49      0.59        73
         9.0       0.54      0.45      0.49        29
        10.0       0.71      0.63      0.67       156
        11.0       0.52      0.51      0.51       168
        12.0       0.69      0.49      0.58        83
        13.0       0.17      0.06      0.08        54
        14.0       0.45      0.42      0.43        31
        15.0       0.38      0.28      0.33        53
        16.0       0.75      0.65      0.70        95
        17.0       0.85      0.82      0.83       884
        18.0       0.77      0.64      0.70        47
        19.0       0.62      0.71      0.67       781
        20.0       0.62      0.73      0.67       592
        21.0       0.81      0.76      0.78       385
        22.0       0.76      0.81      0.78       129
        23.0       0.77      0.81      0.79      1887
        24.0       0.81      0.73      0.77       168
        25.0       0.62      0.67      0.64      1295
        26.0       0.50      0.57      0.54       381
        27.0       0.57      0.31      0.40        13
        28.0       0.54      0.63      0.58       769
        29.0       0.60      0.49      0.54       372
        30.0       0.80      0.74      0.77       631
        31.0       0.50      0.09      0.15        11
        32.0       0.49      0.51      0.50       316
        33.0       0.64      0.61      0.62       405
        34.0       0.67      0.57      0.61        95
        35.0       0.00      0.00      0.00        25
        36.0       0.60      0.41      0.49        66
        37.0       0.93      0.59      0.72        22
        38.0       0.71      0.56      0.63       121
        39.0       0.86      0.81      0.83       113
        40.0       0.71      0.70      0.71       208
        41.0       0.88      0.66      0.75       194
        42.0       0.77      0.52      0.62        46
        43.0       0.93      0.84      0.88       431
        44.0       0.61      0.71      0.66        66
        45.0       0.86      0.78      0.82       489
        46.0       0.78      0.69      0.74        62
        47.0       0.84      0.93      0.88       263
        48.0       0.70      0.56      0.62        50
        49.0       0.75      0.68      0.71        31
        50.0       0.86      0.75      0.80        16
        51.0       0.94      0.73      0.82        22
        52.0       0.74      0.89      0.81        73

    accuracy                           0.70     13120
   macro avg       0.67      0.58      0.61     13120
weighted avg       0.70      0.70      0.70     13120


===confusion_matrix===

[[326   0   0 ...   0   0   0]
 [  0   9   0 ...   0   0   0]
 [  0   0  46 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   0  16   4]
 [  0   0   0 ...   1   0  65]]

===multilabel confusion matrix===

[[[12534   185]
  [   75   326]]

 [[13096     4]
  [   11     9]]

 [[13028    10]
  [   36    46]]

 [[13104     1]
  [   14     1]]

 [[13039    19]
  [   50    12]]

 [[12763    79]
  [  110   168]]

 [[13080     4]
  [   11    25]]

 [[13091     4]
  [   19     6]]

 [[13034    13]
  [   37    36]]

 [[13080    11]
  [   16    13]]

 [[12923    41]
  [   57    99]]

 [[12872    80]
  [   83    85]]

 [[13019    18]
  [   42    41]]

 [[13051    15]
  [   51     3]]

 [[13073    16]
  [   18    13]]

 [[13043    24]
  [   38    15]]

 [[13004    21]
  [   33    62]]

 [[12110   126]
  [  161   723]]

 [[13064     9]
  [   17    30]]

 [[12004   335]
  [  225   556]]

 [[12268   260]
  [  159   433]]

 [[12667    68]
  [   94   291]]

 [[12957    34]
  [   24   105]]

 [[10770   463]
  [  358  1529]]

 [[12923    29]
  [   45   123]]

 [[11293   532]
  [  428   867]]

 [[12523   216]
  [  162   219]]

 [[13104     3]
  [    9     4]]

 [[11945   406]
  [  286   483]]

 [[12629   119]
  [  191   181]]

 [[12371   118]
  [  162   469]]

 [[13108     1]
  [   10     1]]

 [[12635   169]
  [  154   162]]

 [[12577   138]
  [  159   246]]

 [[12998    27]
  [   41    54]]

 [[13093     2]
  [   25     0]]

 [[13036    18]
  [   39    27]]

 [[13097     1]
  [    9    13]]

 [[12971    28]
  [   53    68]]

 [[12992    15]
  [   22    91]]

 [[12853    59]
  [   62   146]]

 [[12908    18]
  [   66   128]]

 [[13067     7]
  [   22    24]]

 [[12660    29]
  [   69   362]]

 [[13024    30]
  [   19    47]]

 [[12571    60]
  [  110   379]]

 [[13046    12]
  [   19    43]]

 [[12809    48]
  [   19   244]]

 [[13058    12]
  [   22    28]]

 [[13082     7]
  [   10    21]]

 [[13102     2]
  [    4    12]]

 [[13097     1]
  [    6    16]]

 [[13024    23]
  [    8    65]]]

===scores report===
metrics	scores
Accuracy	0.6974
MCC	0.6787
log_loss	1.3253
f1 score weighted	0.6950
f1 score macro	0.6089
f1 score micro	0.6974
roc_auc ovr	0.9627
roc_auc ovo	0.9602
precision	0.7001
recall	0.6974

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff16c175a90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff16c175bb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff16c175c10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff16c175a00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 0, -2, -1, -1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [-3, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 2, -4,  0,  0,  0],
        [-2, -2, -1,  0,  0],
        [ 3,  0,  1, -2,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2, -2, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  0,  1, -2,  0],
        [ 3,  2, -3,  1,  0],
        [ 3,  1,  1, -1,  1]],

       [[ 2, -4,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        [-1,  0,  1,  0,  2],
        ...,
        [ 2,  1,  0,  3,  0],
        [ 0, -2, -1, -1,  0],
        [-4, -1, -1,  0,  0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.59      0.69       402
         1.0       0.91      0.53      0.67        19
         2.0       0.82      0.45      0.58        82
         3.0       0.00      0.00      0.00        16
         4.0       0.59      0.16      0.25        62
         5.0       0.75      0.50      0.60       278
         6.0       1.00      0.67      0.80        36
         7.0       0.60      0.12      0.19        26
         8.0       0.71      0.44      0.54        73
         9.0       0.71      0.50      0.59        30
        10.0       0.84      0.62      0.72       156
        11.0       0.58      0.51      0.55       169
        12.0       0.70      0.40      0.51        83
        13.0       0.00      0.00      0.00        53
        14.0       0.60      0.29      0.39        31
        15.0       0.74      0.33      0.45        52
        16.0       0.81      0.46      0.59        95
        17.0       0.79      0.82      0.80       885
        18.0       0.89      0.50      0.64        48
        19.0       0.60      0.69      0.64       781
        20.0       0.69      0.70      0.70       592
        21.0       0.76      0.70      0.73       384
        22.0       0.69      0.71      0.70       128
        23.0       0.78      0.75      0.77      1887
        24.0       0.55      0.65      0.60       168
        25.0       0.49      0.75      0.59      1295
        26.0       0.67      0.43      0.52       381
        27.0       1.00      0.36      0.53        14
        28.0       0.48      0.72      0.57       769
        29.0       0.79      0.37      0.51       372
        30.0       0.65      0.78      0.71       630
        31.0       0.67      0.18      0.29        11
        32.0       0.68      0.43      0.53       316
        33.0       0.68      0.63      0.65       405
        34.0       0.82      0.61      0.70        95
        35.0       0.00      0.00      0.00        25
        36.0       0.87      0.42      0.56        65
        37.0       1.00      0.59      0.74        22
        38.0       0.91      0.43      0.58       121
        39.0       0.78      0.78      0.78       113
        40.0       0.83      0.69      0.75       208
        41.0       0.66      0.65      0.65       194
        42.0       0.43      0.43      0.43        47
        43.0       0.86      0.87      0.86       431
        44.0       0.69      0.79      0.74        66
        45.0       0.86      0.74      0.80       488
        46.0       0.50      0.76      0.60        63
        47.0       0.79      0.83      0.81       263
        48.0       0.68      0.55      0.61        49
        49.0       0.84      0.53      0.65        30
        50.0       0.81      0.87      0.84        15
        51.0       0.73      0.86      0.79        22
        52.0       0.70      0.81      0.75        73

    accuracy                           0.67     13119
   macro avg       0.69      0.55      0.59     13119
weighted avg       0.70      0.67      0.67     13119


===confusion_matrix===

[[238   0   0 ...   0   0   0]
 [  0  10   0 ...   0   0   0]
 [  0   0  37 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   2]
 [  0   0   0 ...   0  19   3]
 [  0   0   0 ...   0   6  59]]

===multilabel confusion matrix===

[[[12669    48]
  [  164   238]]

 [[13099     1]
  [    9    10]]

 [[13029     8]
  [   45    37]]

 [[13102     1]
  [   16     0]]

 [[13050     7]
  [   52    10]]

 [[12794    47]
  [  139   139]]

 [[13083     0]
  [   12    24]]

 [[13091     2]
  [   23     3]]

 [[13033    13]
  [   41    32]]

 [[13083     6]
  [   15    15]]

 [[12945    18]
  [   59    97]]

 [[12887    63]
  [   82    87]]

 [[13022    14]
  [   50    33]]

 [[13063     3]
  [   53     0]]

 [[13082     6]
  [   22     9]]

 [[13061     6]
  [   35    17]]

 [[13014    10]
  [   51    44]]

 [[12041   193]
  [  160   725]]

 [[13068     3]
  [   24    24]]

 [[11979   359]
  [  239   542]]

 [[12337   190]
  [  175   417]]

 [[12652    83]
  [  117   267]]

 [[12950    41]
  [   37    91]]

 [[10834   398]
  [  463  1424]]

 [[12861    90]
  [   58   110]]

 [[10797  1027]
  [  319   976]]

 [[12658    80]
  [  217   164]]

 [[13105     0]
  [    9     5]]

 [[11747   603]
  [  218   551]]

 [[12711    36]
  [  234   138]]

 [[12226   263]
  [  139   491]]

 [[13107     1]
  [    9     2]]

 [[12739    64]
  [  179   137]]

 [[12592   122]
  [  149   256]]

 [[13011    13]
  [   37    58]]

 [[13077    17]
  [   25     0]]

 [[13050     4]
  [   38    27]]

 [[13097     0]
  [    9    13]]

 [[12993     5]
  [   69    52]]

 [[12981    25]
  [   25    88]]

 [[12881    30]
  [   64   144]]

 [[12859    66]
  [   68   126]]

 [[13046    26]
  [   27    20]]

 [[12628    60]
  [   58   373]]

 [[13030    23]
  [   14    52]]

 [[12574    57]
  [  128   360]]

 [[13008    48]
  [   15    48]]

 [[12797    59]
  [   44   219]]

 [[13057    13]
  [   22    27]]

 [[13086     3]
  [   14    16]]

 [[13101     3]
  [    2    13]]

 [[13090     7]
  [    3    19]]

 [[13021    25]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.6730
MCC	0.6531
log_loss	1.3901
f1 score weighted	0.6698
f1 score macro	0.5897
f1 score micro	0.6730
roc_auc ovr	0.9588
roc_auc ovo	0.9581
precision	0.6965
recall	0.6730

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6765243902439024	0.6568973885134847	1.3579416645651314	0.6757843294380671	0.5854733628117742	0.6765243902439024	0.9573092687926513	0.954258580578678	0.6945456514809893	0.6765243902439024
1	0.7016768292682927	0.6837130347405964	1.3000582340591267	0.7005209908963336	0.6338010660368165	0.7016768292682927	0.9637855160273643	0.9643042660737818	0.7080208228435491	0.7016768292682927
2	0.6998475609756097	0.6813041765534611	1.261334760571934	0.6978924025078115	0.613749958458387	0.6998475609756097	0.9641489444997423	0.9625797482014709	0.712672337536087	0.6998475609756097
3	0.6974085365853658	0.6786804977184662	1.3253464828367836	0.6950386224804249	0.6088803770213695	0.6974085365853658	0.9626875203795638	0.9602484620395395	0.7001434810881837	0.6974085365853658
4	0.6729933683969814	0.653084389866921	1.3900783649742443	0.6697533108388594	0.5897337123204021	0.6729933683969814	0.9587798449150771	0.9581311596712674	0.6964818112326734	0.6729933683969814
mean	0.6896901370940304	0.6707358974785859	1.326951901401444	0.6877979312322993	0.6063276953297498	0.6896901370940304	0.9613422189228797	0.9599044433129474	0.7023728208362965	0.6896901370940304
std	0.012317034667019937	0.01300992958040023	0.04466938931007731	0.012539036330684485	0.017473727299361093	0.012317034667019937	0.002774443818956355	0.0035115337488232285	0.006912575509928962	0.012317034667019937

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 31377.2475 secs

