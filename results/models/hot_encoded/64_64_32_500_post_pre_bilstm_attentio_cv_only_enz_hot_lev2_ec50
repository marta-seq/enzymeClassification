/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_hot_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f09f4134490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f09f4134340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f09f4134820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f09f41347f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.80      0.75       402
         1.0       0.85      0.58      0.69        19
         2.0       0.66      0.57      0.61        82
         3.0       0.00      0.00      0.00        16
         4.0       0.58      0.18      0.27        62
         5.0       0.70      0.48      0.57       277
         6.0       0.75      0.67      0.71        36
         7.0       0.30      0.23      0.26        26
         8.0       0.64      0.60      0.62        72
         9.0       0.58      0.63      0.60        30
        10.0       0.80      0.74      0.77       156
        11.0       0.44      0.45      0.44       168
        12.0       0.84      0.43      0.57        83
        13.0       0.18      0.04      0.06        53
        14.0       0.50      0.26      0.34        31
        15.0       0.56      0.38      0.45        52
        16.0       0.81      0.54      0.65        94
        17.0       0.82      0.83      0.82       885
        18.0       0.71      0.75      0.73        48
        19.0       0.74      0.71      0.72       781
        20.0       0.60      0.81      0.69       591
        21.0       0.47      0.83      0.60       385
        22.0       0.84      0.77      0.80       128
        23.0       0.78      0.81      0.80      1888
        24.0       0.90      0.68      0.77       169
        25.0       0.71      0.61      0.66      1296
        26.0       0.66      0.50      0.57       381
        27.0       0.83      0.36      0.50        14
        28.0       0.67      0.61      0.64       769
        29.0       0.47      0.56      0.51       372
        30.0       0.78      0.77      0.78       631
        31.0       1.00      0.18      0.31        11
        32.0       0.48      0.65      0.55       316
        33.0       0.47      0.68      0.56       405
        34.0       0.51      0.65      0.57        96
        35.0       0.00      0.00      0.00        26
        36.0       0.89      0.38      0.54        65
        37.0       0.73      0.52      0.61        21
        38.0       0.81      0.55      0.66       121
        39.0       0.82      0.62      0.71       114
        40.0       0.70      0.76      0.73       207
        41.0       0.87      0.62      0.73       194
        42.0       0.89      0.36      0.52        47
        43.0       0.96      0.82      0.88       431
        44.0       0.80      0.72      0.76        67
        45.0       0.81      0.81      0.81       488
        46.0       0.89      0.63      0.74        62
        47.0       0.85      0.89      0.87       264
        48.0       0.85      0.67      0.75        49
        49.0       0.74      0.67      0.70        30
        50.0       0.91      0.67      0.77        15
        51.0       0.80      0.57      0.67        21
        52.0       0.69      0.93      0.80        73

    accuracy                           0.70     13120
   macro avg       0.69      0.58      0.61     13120
weighted avg       0.71      0.70      0.70     13120


===confusion_matrix===

[[321   0   1 ...   0   0   0]
 [  0  11   0 ...   0   0   0]
 [  0   0  47 ...   0   0   0]
 ...
 [  0   0   0 ...  10   1   0]
 [  0   0   0 ...   0  12   6]
 [  0   0   0 ...   0   0  68]]

===multilabel confusion matrix===

[[[12581   137]
  [   81   321]]

 [[13099     2]
  [    8    11]]

 [[13014    24]
  [   35    47]]

 [[13104     0]
  [   16     0]]

 [[13050     8]
  [   51    11]]

 [[12786    57]
  [  144   133]]

 [[13076     8]
  [   12    24]]

 [[13080    14]
  [   20     6]]

 [[13024    24]
  [   29    43]]

 [[13076    14]
  [   11    19]]

 [[12935    29]
  [   40   116]]

 [[12854    98]
  [   92    76]]

 [[13030     7]
  [   47    36]]

 [[13058     9]
  [   51     2]]

 [[13081     8]
  [   23     8]]

 [[13052    16]
  [   32    20]]

 [[13014    12]
  [   43    51]]

 [[12070   165]
  [  150   735]]

 [[13057    15]
  [   12    36]]

 [[12145   194]
  [  230   551]]

 [[12214   315]
  [  112   479]]

 [[12373   362]
  [   66   319]]

 [[12974    18]
  [   30    98]]

 [[10809   423]
  [  357  1531]]

 [[12938    13]
  [   54   115]]

 [[11505   319]
  [  503   793]]

 [[12638   101]
  [  189   192]]

 [[13105     1]
  [    9     5]]

 [[12115   236]
  [  299   470]]

 [[12510   238]
  [  162   210]]

 [[12349   140]
  [  142   489]]

 [[13109     0]
  [    9     2]]

 [[12579   225]
  [  111   205]]

 [[12403   312]
  [  128   277]]

 [[12964    60]
  [   34    62]]

 [[13094     0]
  [   26     0]]

 [[13052     3]
  [   40    25]]

 [[13095     4]
  [   10    11]]

 [[12983    16]
  [   54    67]]

 [[12990    16]
  [   43    71]]

 [[12844    69]
  [   49   158]]

 [[12908    18]
  [   73   121]]

 [[13071     2]
  [   30    17]]

 [[12676    13]
  [   79   352]]

 [[13041    12]
  [   19    48]]

 [[12540    92]
  [   91   397]]

 [[13053     5]
  [   23    39]]

 [[12815    41]
  [   28   236]]

 [[13065     6]
  [   16    33]]

 [[13083     7]
  [   10    20]]

 [[13104     1]
  [    5    10]]

 [[13096     3]
  [    9    12]]

 [[13017    30]
  [    5    68]]]

===scores report===
metrics	scores
Accuracy	0.6995
MCC	0.6820
log_loss	1.2298
f1 score weighted	0.6977
f1 score macro	0.6071
f1 score micro	0.6995
roc_auc ovr	0.9663
roc_auc ovo	0.9641
precision	0.7135
recall	0.6995

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f09f4134490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f09f4134340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f09f4134820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f09f41347f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.75      0.74       402
         1.0       0.79      0.58      0.67        19
         2.0       0.65      0.62      0.63        81
         3.0       0.50      0.06      0.11        16
         4.0       0.50      0.27      0.35        62
         5.0       0.76      0.60      0.67       277
         6.0       0.86      0.86      0.86        36
         7.0       0.76      0.50      0.60        26
         8.0       0.79      0.45      0.57        73
         9.0       0.73      0.38      0.50        29
        10.0       0.77      0.72      0.75       156
        11.0       0.57      0.57      0.57       168
        12.0       0.64      0.54      0.59        83
        13.0       0.64      0.13      0.22        53
        14.0       0.68      0.47      0.56        32
        15.0       0.74      0.54      0.62        52
        16.0       0.67      0.65      0.66        95
        17.0       0.87      0.84      0.85       884
        18.0       0.75      0.56      0.64        48
        19.0       0.81      0.73      0.76       782
        20.0       0.74      0.77      0.76       591
        21.0       0.87      0.74      0.80       385
        22.0       0.85      0.87      0.86       128
        23.0       0.80      0.84      0.82      1888
        24.0       0.89      0.69      0.78       169
        25.0       0.66      0.73      0.69      1295
        26.0       0.55      0.72      0.63       381
        27.0       1.00      0.57      0.73        14
        28.0       0.64      0.68      0.66       769
        29.0       0.57      0.63      0.60       371
        30.0       0.80      0.78      0.79       631
        31.0       0.71      0.45      0.56        11
        32.0       0.53      0.67      0.59       316
        33.0       0.62      0.69      0.65       405
        34.0       0.76      0.62      0.69        96
        35.0       0.50      0.12      0.19        26
        36.0       0.73      0.57      0.64        65
        37.0       1.00      0.82      0.90        22
        38.0       0.65      0.60      0.62       121
        39.0       0.82      0.76      0.79       113
        40.0       0.80      0.78      0.79       208
        41.0       0.81      0.71      0.75       193
        42.0       0.79      0.50      0.61        46
        43.0       0.89      0.95      0.92       431
        44.0       0.88      0.70      0.78        66
        45.0       0.87      0.85      0.86       489
        46.0       0.79      0.79      0.79        62
        47.0       0.89      0.89      0.89       264
        48.0       0.93      0.55      0.69        49
        49.0       0.89      0.81      0.85        31
        50.0       1.00      0.94      0.97        16
        51.0       0.86      0.86      0.86        21
        52.0       0.76      0.90      0.82        73

    accuracy                           0.74     13120
   macro avg       0.76      0.65      0.68     13120
weighted avg       0.75      0.74      0.74     13120


===confusion_matrix===

[[303   0   1 ...   0   0   0]
 [  0  11   0 ...   0   0   0]
 [  0   0  50 ...   0   0   0]
 ...
 [  0   0   0 ...  15   0   1]
 [  0   0   0 ...   0  18   3]
 [  0   0   0 ...   0   2  66]]

===multilabel confusion matrix===

[[[12599   119]
  [   99   303]]

 [[13098     3]
  [    8    11]]

 [[13012    27]
  [   31    50]]

 [[13103     1]
  [   15     1]]

 [[13041    17]
  [   45    17]]

 [[12789    54]
  [  110   167]]

 [[13079     5]
  [    5    31]]

 [[13090     4]
  [   13    13]]

 [[13038     9]
  [   40    33]]

 [[13087     4]
  [   18    11]]

 [[12931    33]
  [   43   113]]

 [[12880    72]
  [   73    95]]

 [[13012    25]
  [   38    45]]

 [[13063     4]
  [   46     7]]

 [[13081     7]
  [   17    15]]

 [[13058    10]
  [   24    28]]

 [[12995    30]
  [   33    62]]

 [[12120   116]
  [  139   745]]

 [[13063     9]
  [   21    27]]

 [[12201   137]
  [  213   569]]

 [[12369   160]
  [  135   456]]

 [[12693    42]
  [  101   284]]

 [[12973    19]
  [   17   111]]

 [[10836   396]
  [  309  1579]]

 [[12937    14]
  [   53   116]]

 [[11327   498]
  [  347   948]]

 [[12516   223]
  [  105   276]]

 [[13106     0]
  [    6     8]]

 [[12062   289]
  [  245   524]]

 [[12577   172]
  [  139   232]]

 [[12362   127]
  [  136   495]]

 [[13107     2]
  [    6     5]]

 [[12617   187]
  [  103   213]]

 [[12541   174]
  [  127   278]]

 [[13005    19]
  [   36    60]]

 [[13091     3]
  [   23     3]]

 [[13041    14]
  [   28    37]]

 [[13098     0]
  [    4    18]]

 [[12961    38]
  [   49    72]]

 [[12988    19]
  [   27    86]]

 [[12871    41]
  [   45   163]]

 [[12894    33]
  [   56   137]]

 [[13068     6]
  [   23    23]]

 [[12638    51]
  [   23   408]]

 [[13048     6]
  [   20    46]]

 [[12571    60]
  [   75   414]]

 [[13045    13]
  [   13    49]]

 [[12827    29]
  [   29   235]]

 [[13069     2]
  [   22    27]]

 [[13086     3]
  [    6    25]]

 [[13104     0]
  [    1    15]]

 [[13096     3]
  [    3    18]]

 [[13026    21]
  [    7    66]]]

===scores report===
metrics	scores
Accuracy	0.7447
MCC	0.7290
log_loss	1.0693
f1 score weighted	0.7433
f1 score macro	0.6840
f1 score micro	0.7447
roc_auc ovr	0.9717
roc_auc ovo	0.9695
precision	0.7504
recall	0.7447

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f09f4134490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f09f4134340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f09f4134820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f09f41347f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.62      0.81      0.70       401
         1.0       0.75      0.45      0.56        20
         2.0       0.56      0.49      0.52        82
         3.0       0.67      0.12      0.21        16
         4.0       0.31      0.26      0.28        62
         5.0       0.52      0.58      0.55       277
         6.0       0.79      0.86      0.83        36
         7.0       0.80      0.32      0.46        25
         8.0       0.69      0.48      0.56        73
         9.0       0.52      0.59      0.55        29
        10.0       0.77      0.70      0.73       156
        11.0       0.40      0.49      0.44       168
        12.0       0.39      0.60      0.47        83
        13.0       0.25      0.09      0.14        54
        14.0       0.48      0.32      0.38        31
        15.0       0.52      0.43      0.47        53
        16.0       0.46      0.62      0.53        95
        17.0       0.95      0.69      0.80       884
        18.0       0.82      0.77      0.79        47
        19.0       0.77      0.67      0.72       782
        20.0       0.83      0.71      0.77       592
        21.0       0.86      0.66      0.75       385
        22.0       0.78      0.79      0.78       128
        23.0       0.72      0.82      0.76      1887
        24.0       0.84      0.65      0.73       168
        25.0       0.73      0.58      0.64      1295
        26.0       0.57      0.65      0.61       381
        27.0       0.90      0.64      0.75        14
        28.0       0.66      0.56      0.61       768
        29.0       0.38      0.60      0.46       372
        30.0       0.88      0.64      0.74       631
        31.0       0.00      0.00      0.00        10
        32.0       0.38      0.70      0.49       316
        33.0       0.57      0.69      0.63       405
        34.0       0.66      0.62      0.64        96
        35.0       0.60      0.12      0.19        26
        36.0       0.82      0.55      0.65        66
        37.0       0.92      0.50      0.65        22
        38.0       0.73      0.61      0.66       121
        39.0       0.95      0.76      0.84       113
        40.0       0.83      0.68      0.75       208
        41.0       0.68      0.69      0.69       194
        42.0       0.80      0.43      0.56        46
        43.0       0.91      0.89      0.90       431
        44.0       0.83      0.83      0.83        66
        45.0       0.60      0.86      0.71       489
        46.0       0.70      0.65      0.67        62
        47.0       0.78      0.92      0.84       263
        48.0       0.79      0.68      0.73        50
        49.0       0.64      0.45      0.53        31
        50.0       0.75      0.75      0.75        16
        51.0       0.93      0.62      0.74        21
        52.0       0.71      0.78      0.75        73

    accuracy                           0.69     13120
   macro avg       0.67      0.59      0.61     13120
weighted avg       0.71      0.69      0.69     13120


===confusion_matrix===

[[326   0   0 ...   0   0   0]
 [  0   9   0 ...   0   0   0]
 [  0   0  40 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   1]
 [  0   0   0 ...   0  13   6]
 [  0   1   0 ...   0   0  57]]

===multilabel confusion matrix===

[[[12520   199]
  [   75   326]]

 [[13097     3]
  [   11     9]]

 [[13007    31]
  [   42    40]]

 [[13103     1]
  [   14     2]]

 [[13023    35]
  [   46    16]]

 [[12693   150]
  [  117   160]]

 [[13076     8]
  [    5    31]]

 [[13093     2]
  [   17     8]]

 [[13031    16]
  [   38    35]]

 [[13075    16]
  [   12    17]]

 [[12931    33]
  [   47   109]]

 [[12830   122]
  [   86    82]]

 [[12959    78]
  [   33    50]]

 [[13051    15]
  [   49     5]]

 [[13078    11]
  [   21    10]]

 [[13046    21]
  [   30    23]]

 [[12957    68]
  [   36    59]]

 [[12202    34]
  [  270   614]]

 [[13065     8]
  [   11    36]]

 [[12182   156]
  [  260   522]]

 [[12442    86]
  [  171   421]]

 [[12693    42]
  [  131   254]]

 [[12963    29]
  [   27   101]]

 [[10616   617]
  [  339  1548]]

 [[12932    20]
  [   59   109]]

 [[11543   282]
  [  550   745]]

 [[12551   188]
  [  132   249]]

 [[13105     1]
  [    5     9]]

 [[12129   223]
  [  337   431]]

 [[12383   365]
  [  149   223]]

 [[12435    54]
  [  225   406]]

 [[13103     7]
  [   10     0]]

 [[12439   365]
  [   94   222]]

 [[12502   213]
  [  124   281]]

 [[12993    31]
  [   36    60]]

 [[13092     2]
  [   23     3]]

 [[13046     8]
  [   30    36]]

 [[13097     1]
  [   11    11]]

 [[12971    28]
  [   47    74]]

 [[13002     5]
  [   27    86]]

 [[12883    29]
  [   67   141]]

 [[12863    63]
  [   60   134]]

 [[13069     5]
  [   26    20]]

 [[12650    39]
  [   46   385]]

 [[13043    11]
  [   11    55]]

 [[12353   278]
  [   70   419]]

 [[13041    17]
  [   22    40]]

 [[12787    70]
  [   21   242]]

 [[13061     9]
  [   16    34]]

 [[13081     8]
  [   17    14]]

 [[13100     4]
  [    4    12]]

 [[13098     1]
  [    8    13]]

 [[13024    23]
  [   16    57]]]

===scores report===
metrics	scores
Accuracy	0.6851
MCC	0.6674
log_loss	1.3336
f1 score weighted	0.6883
f1 score macro	0.6136
f1 score micro	0.6851
roc_auc ovr	0.9612
roc_auc ovo	0.9637
precision	0.7127
recall	0.6851

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f09f4134490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f09f4134340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f09f4134820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f09f41347f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.71      0.69      0.70       401
         1.0       0.86      0.30      0.44        20
         2.0       0.79      0.51      0.62        82
         3.0       0.00      0.00      0.00        15
         4.0       0.52      0.21      0.30        62
         5.0       0.65      0.55      0.59       278
         6.0       0.96      0.61      0.75        36
         7.0       0.75      0.12      0.21        25
         8.0       0.35      0.58      0.43        73
         9.0       0.68      0.45      0.54        29
        10.0       0.44      0.76      0.56       156
        11.0       0.54      0.46      0.50       168
        12.0       0.54      0.49      0.52        83
        13.0       0.50      0.02      0.04        54
        14.0       0.52      0.48      0.50        31
        15.0       0.30      0.40      0.34        53
        16.0       0.44      0.58      0.50        95
        17.0       0.65      0.88      0.75       884
        18.0       0.90      0.60      0.72        47
        19.0       0.73      0.65      0.69       781
        20.0       0.85      0.67      0.75       592
        21.0       0.68      0.75      0.72       385
        22.0       0.51      0.81      0.62       129
        23.0       0.79      0.80      0.80      1887
        24.0       0.65      0.73      0.69       168
        25.0       0.80      0.56      0.66      1295
        26.0       0.61      0.60      0.61       381
        27.0       1.00      0.38      0.56        13
        28.0       0.61      0.68      0.64       769
        29.0       0.70      0.39      0.50       372
        30.0       0.77      0.76      0.76       631
        31.0       0.44      0.36      0.40        11
        32.0       0.54      0.53      0.54       316
        33.0       0.53      0.68      0.60       405
        34.0       0.70      0.56      0.62        95
        35.0       0.10      0.04      0.06        25
        36.0       0.96      0.33      0.49        66
        37.0       0.67      0.73      0.70        22
        38.0       0.59      0.58      0.58       121
        39.0       0.79      0.69      0.74       113
        40.0       0.72      0.72      0.72       208
        41.0       0.47      0.80      0.59       194
        42.0       0.61      0.48      0.54        46
        43.0       0.70      0.92      0.79       431
        44.0       0.74      0.70      0.72        66
        45.0       0.80      0.82      0.81       489
        46.0       0.45      0.76      0.56        62
        47.0       0.90      0.89      0.89       263
        48.0       0.76      0.56      0.64        50
        49.0       0.77      0.87      0.82        31
        50.0       1.00      0.69      0.81        16
        51.0       1.00      0.50      0.67        22
        52.0       0.80      0.92      0.85        73

    accuracy                           0.69     13120
   macro avg       0.66      0.58      0.59     13120
weighted avg       0.70      0.69      0.68     13120


===confusion_matrix===

[[276   0   1 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  1   0  42 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   0]
 [  0   0   0 ...   0  11   6]
 [  0   0   0 ...   0   0  67]]

===multilabel confusion matrix===

[[[12605   114]
  [  125   276]]

 [[13099     1]
  [   14     6]]

 [[13027    11]
  [   40    42]]

 [[13101     4]
  [   15     0]]

 [[13046    12]
  [   49    13]]

 [[12758    84]
  [  125   153]]

 [[13083     1]
  [   14    22]]

 [[13094     1]
  [   22     3]]

 [[12968    79]
  [   31    42]]

 [[13085     6]
  [   16    13]]

 [[12813   151]
  [   37   119]]

 [[12885    67]
  [   90    78]]

 [[13002    35]
  [   42    41]]

 [[13065     1]
  [   53     1]]

 [[13075    14]
  [   16    15]]

 [[13018    49]
  [   32    21]]

 [[12955    70]
  [   40    55]]

 [[11824   412]
  [  107   777]]

 [[13070     3]
  [   19    28]]

 [[12154   185]
  [  271   510]]

 [[12460    68]
  [  198   394]]

 [[12599   136]
  [   95   290]]

 [[12889   102]
  [   24   105]]

 [[10839   394]
  [  368  1519]]

 [[12886    66]
  [   45   123]]

 [[11642   183]
  [  575   720]]

 [[12595   144]
  [  153   228]]

 [[13107     0]
  [    8     5]]

 [[12014   337]
  [  246   523]]

 [[12684    64]
  [  226   146]]

 [[12343   146]
  [  151   480]]

 [[13104     5]
  [    7     4]]

 [[12662   142]
  [  148   168]]

 [[12476   239]
  [  131   274]]

 [[13002    23]
  [   42    53]]

 [[13086     9]
  [   24     1]]

 [[13053     1]
  [   44    22]]

 [[13090     8]
  [    6    16]]

 [[12950    49]
  [   51    70]]

 [[12986    21]
  [   35    78]]

 [[12854    58]
  [   58   150]]

 [[12749   177]
  [   39   155]]

 [[13060    14]
  [   24    22]]

 [[12518   171]
  [   34   397]]

 [[13038    16]
  [   20    46]]

 [[12530   101]
  [   89   400]]

 [[13000    58]
  [   15    47]]

 [[12831    26]
  [   30   233]]

 [[13061     9]
  [   22    28]]

 [[13081     8]
  [    4    27]]

 [[13104     0]
  [    5    11]]

 [[13098     0]
  [   11    11]]

 [[13030    17]
  [    6    67]]]

===scores report===
metrics	scores
Accuracy	0.6881
MCC	0.6707
log_loss	1.2896
f1 score weighted	0.6842
f1 score macro	0.5874
f1 score micro	0.6881
roc_auc ovr	0.9653
roc_auc ovo	0.9631
precision	0.7038
recall	0.6881

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f09f4134490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f09f4134340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f09f4134820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f09f41347f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.74      0.74       402
         1.0       0.77      0.53      0.62        19
         2.0       0.69      0.60      0.64        82
         3.0       0.67      0.12      0.21        16
         4.0       0.46      0.27      0.34        62
         5.0       0.65      0.55      0.60       278
         6.0       0.79      0.61      0.69        36
         7.0       0.30      0.31      0.30        26
         8.0       0.84      0.51      0.63        73
         9.0       0.62      0.27      0.37        30
        10.0       0.75      0.71      0.73       156
        11.0       0.58      0.55      0.57       169
        12.0       0.73      0.46      0.56        83
        13.0       0.43      0.06      0.10        53
        14.0       0.75      0.29      0.42        31
        15.0       0.64      0.48      0.55        52
        16.0       0.51      0.63      0.56        95
        17.0       0.88      0.82      0.85       885
        18.0       0.91      0.67      0.77        48
        19.0       0.63      0.75      0.68       781
        20.0       0.88      0.67      0.76       592
        21.0       0.81      0.75      0.78       384
        22.0       0.89      0.70      0.78       128
        23.0       0.79      0.77      0.78      1887
        24.0       0.66      0.70      0.68       168
        25.0       0.59      0.69      0.63      1295
        26.0       0.71      0.50      0.58       381
        27.0       1.00      0.50      0.67        14
        28.0       0.53      0.67      0.59       769
        29.0       0.47      0.65      0.54       372
        30.0       0.56      0.83      0.67       630
        31.0       0.33      0.09      0.14        11
        32.0       0.58      0.53      0.55       316
        33.0       0.77      0.65      0.71       405
        34.0       0.70      0.60      0.64        95
        35.0       0.00      0.00      0.00        25
        36.0       0.93      0.38      0.54        65
        37.0       1.00      0.64      0.78        22
        38.0       0.85      0.55      0.67       121
        39.0       0.72      0.80      0.76       113
        40.0       0.75      0.74      0.74       208
        41.0       0.87      0.68      0.76       194
        42.0       0.80      0.43      0.56        47
        43.0       0.98      0.83      0.90       431
        44.0       0.92      0.83      0.87        66
        45.0       0.78      0.81      0.79       488
        46.0       0.93      0.68      0.79        63
        47.0       0.80      0.84      0.82       263
        48.0       0.89      0.49      0.63        49
        49.0       0.88      0.70      0.78        30
        50.0       0.87      0.87      0.87        15
        51.0       0.94      0.68      0.79        22
        52.0       0.74      0.96      0.83        73

    accuracy                           0.70     13119
   macro avg       0.72      0.59      0.63     13119
weighted avg       0.72      0.70      0.70     13119


===confusion_matrix===

[[299   0   0 ...   0   0   0]
 [  0  10   1 ...   0   0   0]
 [  1   0  49 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  15   6]
 [  0   0   0 ...   0   0  70]]

===multilabel confusion matrix===

[[[12609   108]
  [  103   299]]

 [[13097     3]
  [    9    10]]

 [[13015    22]
  [   33    49]]

 [[13102     1]
  [   14     2]]

 [[13037    20]
  [   45    17]]

 [[12758    83]
  [  125   153]]

 [[13077     6]
  [   14    22]]

 [[13074    19]
  [   18     8]]

 [[13039     7]
  [   36    37]]

 [[13084     5]
  [   22     8]]

 [[12927    36]
  [   46   110]]

 [[12884    66]
  [   76    93]]

 [[13022    14]
  [   45    38]]

 [[13062     4]
  [   50     3]]

 [[13085     3]
  [   22     9]]

 [[13053    14]
  [   27    25]]

 [[12966    58]
  [   35    60]]

 [[12135    99]
  [  163   722]]

 [[13068     3]
  [   16    32]]

 [[11997   341]
  [  199   582]]

 [[12471    56]
  [  193   399]]

 [[12667    68]
  [   97   287]]

 [[12980    11]
  [   39    89]]

 [[10841   391]
  [  426  1461]]

 [[12890    61]
  [   50   118]]

 [[11194   630]
  [  400   895]]

 [[12659    79]
  [  191   190]]

 [[13105     0]
  [    7     7]]

 [[11894   456]
  [  251   518]]

 [[12473   274]
  [  132   240]]

 [[12084   405]
  [  106   524]]

 [[13106     2]
  [   10     1]]

 [[12683   120]
  [  149   167]]

 [[12636    78]
  [  142   263]]

 [[12999    25]
  [   38    57]]

 [[13092     2]
  [   25     0]]

 [[13052     2]
  [   40    25]]

 [[13097     0]
  [    8    14]]

 [[12986    12]
  [   54    67]]

 [[12971    35]
  [   23    90]]

 [[12859    52]
  [   54   154]]

 [[12906    19]
  [   63   131]]

 [[13067     5]
  [   27    20]]

 [[12679     9]
  [   73   358]]

 [[13048     5]
  [   11    55]]

 [[12523   108]
  [   95   393]]

 [[13053     3]
  [   20    43]]

 [[12801    55]
  [   41   222]]

 [[13067     3]
  [   25    24]]

 [[13086     3]
  [    9    21]]

 [[13102     2]
  [    2    13]]

 [[13096     1]
  [    7    15]]

 [[13021    25]
  [    3    70]]]

===scores report===
metrics	scores
Accuracy	0.7020
MCC	0.6840
log_loss	1.1887
f1 score weighted	0.7018
f1 score macro	0.6291
f1 score micro	0.7020
roc_auc ovr	0.9660
roc_auc ovo	0.9649
precision	0.7188
recall	0.7020

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6995426829268293	0.6820021240334722	1.2298253554366463	0.697726173422527	0.6070505455288625	0.6995426829268293	0.9663008376204801	0.964068044167753	0.7134863718585475	0.6995426829268293
1	0.7446646341463414	0.7290091365498871	1.069313163467472	0.743314009140202	0.6839641387284133	0.7446646341463414	0.9717356150472343	0.9694910769816332	0.7503994035583437	0.7446646341463414
2	0.6851371951219513	0.6673937995615885	1.3336253210144753	0.6882995337233113	0.6135979923886888	0.6851371951219513	0.9612080985099827	0.9637143076482306	0.7126593527285038	0.6851371951219513
3	0.688109756097561	0.6706980959452068	1.2896436161516842	0.684179479578455	0.5874481829737771	0.688109756097561	0.9653152006783694	0.9631293842174504	0.7038105823259617	0.688109756097561
4	0.702035216098788	0.6840080916460438	1.188651633680752	0.7017968939477451	0.6291280525476602	0.702035216098788	0.9660454976637487	0.9649434858825896	0.7188262225403929	0.702035216098788
mean	0.7038978968782942	0.6866222495472396	1.2222118179502057	0.7030632179624481	0.6242377824334804	0.7038978968782942	0.966121049903963	0.9650692597795313	0.7198363866023498	0.7038978968782942
std	0.021380335149075974	0.02212753726858177	0.09112877321419886	0.021093960078821104	0.032720737311610265	0.021380335149075974	0.0033570182569075064	0.002287781965909306	0.016023590996167975	0.021380335149075974

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 31945.3410 secs

