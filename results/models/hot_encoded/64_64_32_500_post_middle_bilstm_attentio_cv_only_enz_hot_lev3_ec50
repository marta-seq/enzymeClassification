/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_middle_bilstm_attentio_cv_only_enz_hot_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c707d05b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c707d07f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c707d0850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c707d0640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.61      0.85      0.71       358
         1.0       0.67      0.50      0.57        12
         2.0       0.91      0.53      0.67        19
         3.0       0.60      0.65      0.62        80
         4.0       0.37      0.31      0.34        54
         5.0       0.30      0.10      0.15        58
         6.0       0.39      0.29      0.33        45
         7.0       0.77      0.56      0.65        48
         8.0       0.00      0.00      0.00        11
         9.0       0.82      0.43      0.56        21
        10.0       0.67      0.13      0.22        15
        11.0       0.84      0.58      0.69        36
        12.0       1.00      0.42      0.59        12
        13.0       0.82      0.72      0.77        25
        14.0       0.80      0.21      0.33        19
        15.0       0.93      0.59      0.72        22
        16.0       0.71      0.65      0.68        23
        17.0       0.88      0.89      0.89       119
        18.0       0.74      0.78      0.76        18
        19.0       0.25      0.08      0.12        12
        20.0       0.54      0.51      0.53        90
        21.0       1.00      0.25      0.40        12
        22.0       0.80      0.80      0.80        25
        23.0       0.00      0.00      0.00        12
        24.0       0.56      0.23      0.32        22
        25.0       0.72      0.61      0.66        38
        26.0       1.00      1.00      1.00        17
        27.0       0.24      0.11      0.15        35
        28.0       1.00      0.09      0.17        11
        29.0       0.83      0.67      0.74        36
        30.0       0.71      0.69      0.70        32
        31.0       0.88      0.76      0.82        38
        32.0       0.71      0.85      0.77       747
        33.0       0.93      0.86      0.90        74
        34.0       0.90      0.93      0.92        59
        35.0       0.78      0.83      0.81        48
        36.0       0.70      0.74      0.72       502
        37.0       0.72      0.67      0.70       241
        38.0       0.86      0.55      0.67        33
        39.0       0.68      0.72      0.70       344
        40.0       0.82      0.70      0.75       191
        41.0       0.72      0.56      0.63        32
        42.0       0.73      0.82      0.77       384
        43.0       0.74      0.76      0.75       118
        44.0       0.70      0.75      0.73       436
        45.0       0.78      0.52      0.62        48
        46.0       0.81      0.84      0.83       402
        47.0       0.88      0.41      0.56        17
        48.0       0.79      0.52      0.63        42
        49.0       0.87      0.88      0.88        78
        50.0       0.91      0.90      0.90       172
        51.0       1.00      0.35      0.52        20
        52.0       0.66      0.74      0.70       499
        53.0       0.83      0.71      0.76       100
        54.0       0.50      0.09      0.15        11
        55.0       0.71      0.82      0.76       103
        56.0       0.65      0.61      0.63        18
        57.0       1.00      0.10      0.18        10
        58.0       0.94      0.91      0.93        34
        59.0       0.57      0.69      0.62       231
        60.0       0.97      0.64      0.77        58
        61.0       0.20      0.07      0.10        30
        62.0       0.68      0.48      0.56        48
        63.0       0.43      0.36      0.39        50
        64.0       0.88      0.68      0.77        34
        65.0       0.82      0.79      0.80       155
        66.0       0.80      0.29      0.42        14
        67.0       0.61      0.66      0.63       314
        68.0       0.41      0.19      0.26        63
        69.0       0.56      0.72      0.63       308
        70.0       0.72      0.43      0.54        68
        71.0       0.67      0.55      0.60        66
        72.0       0.00      0.00      0.00        14
        73.0       0.72      0.52      0.60        25
        74.0       0.00      0.00      0.00        18
        75.0       0.30      0.15      0.20        60
        76.0       0.82      0.65      0.73       205
        77.0       0.66      0.35      0.46        77
        78.0       0.72      0.85      0.78        59
        79.0       0.79      0.60      0.68       139
        80.0       0.95      0.86      0.90        42
        81.0       0.41      0.47      0.44       175
        82.0       0.65      0.47      0.54        43
        83.0       0.62      0.58      0.60        26
        84.0       0.64      0.49      0.56       106
        85.0       0.58      0.50      0.54        14
        86.0       0.80      0.77      0.78       242
        87.0       0.82      0.84      0.83       309
        88.0       0.82      0.78      0.80        58
        89.0       0.50      0.18      0.27        11
        90.0       0.58      0.62      0.60       187
        91.0       0.56      0.39      0.46        46
        92.0       0.21      0.12      0.16        40
        93.0       0.50      0.66      0.57        32
        94.0       0.57      0.75      0.65       289
        95.0       0.67      0.06      0.12        31
        96.0       0.88      0.77      0.82        74
        97.0       0.65      0.48      0.55        27
        98.0       0.89      0.65      0.75        37
        99.0       0.92      0.92      0.92        24
       100.0       0.29      0.16      0.21        25
       101.0       0.91      0.49      0.64        65
       102.0       0.85      0.77      0.81        22
       103.0       0.70      0.81      0.75        64
       104.0       0.52      0.33      0.40        40
       105.0       0.85      0.92      0.88        12
       106.0       0.88      0.75      0.81       114
       107.0       0.73      0.87      0.79       161
       108.0       0.67      0.33      0.44        24
       109.0       0.87      0.75      0.80        52
       110.0       0.76      0.87      0.81        15
       111.0       0.75      0.72      0.74       123
       112.0       0.68      0.50      0.58        42
       113.0       0.82      0.95      0.88       430
       114.0       0.75      0.78      0.77        65
       115.0       0.73      0.71      0.72        31
       116.0       0.69      0.83      0.75       173
       117.0       0.88      0.94      0.91        31
       118.0       0.80      0.86      0.83       117
       119.0       0.74      0.90      0.81       136
       120.0       0.73      0.77      0.75        62
       121.0       0.91      0.86      0.88       224
       122.0       0.96      0.63      0.76        35
       123.0       0.81      0.57      0.67        37
       124.0       0.84      0.68      0.75        31
       125.0       0.86      0.80      0.83        15
       126.0       0.73      0.76      0.74        21
       127.0       0.77      0.90      0.83        73

    accuracy                           0.71     12227
   macro avg       0.70      0.58      0.61     12227
weighted avg       0.71      0.71      0.70     12227


===confusion_matrix===

[[304   0   0 ...   0   0   0]
 [  1   6   0 ...   0   0   0]
 [  0   0  10 ...   0   0   0]
 ...
 [  0   0   0 ...  12   1   0]
 [  0   0   0 ...   0  16   4]
 [  0   0   0 ...   1   3  66]]

===multilabel confusion matrix===

[[[11676   193]
  [   54   304]]

 [[12212     3]
  [    6     6]]

 [[12207     1]
  [    9    10]]

 [[12112    35]
  [   28    52]]

 [[12144    29]
  [   37    17]]

 [[12155    14]
  [   52     6]]

 [[12162    20]
  [   32    13]]

 [[12171     8]
  [   21    27]]

 [[12216     0]
  [   11     0]]

 [[12204     2]
  [   12     9]]

 [[12211     1]
  [   13     2]]

 [[12187     4]
  [   15    21]]

 [[12215     0]
  [    7     5]]

 [[12198     4]
  [    7    18]]

 [[12207     1]
  [   15     4]]

 [[12204     1]
  [    9    13]]

 [[12198     6]
  [    8    15]]

 [[12094    14]
  [   13   106]]

 [[12204     5]
  [    4    14]]

 [[12212     3]
  [   11     1]]

 [[12098    39]
  [   44    46]]

 [[12215     0]
  [    9     3]]

 [[12197     5]
  [    5    20]]

 [[12215     0]
  [   12     0]]

 [[12201     4]
  [   17     5]]

 [[12180     9]
  [   15    23]]

 [[12210     0]
  [    0    17]]

 [[12179    13]
  [   31     4]]

 [[12216     0]
  [   10     1]]

 [[12186     5]
  [   12    24]]

 [[12186     9]
  [   10    22]]

 [[12185     4]
  [    9    29]]

 [[11217   263]
  [  112   635]]

 [[12148     5]
  [   10    64]]

 [[12162     6]
  [    4    55]]

 [[12168    11]
  [    8    40]]

 [[11566   159]
  [  133   369]]

 [[11923    63]
  [   79   162]]

 [[12191     3]
  [   15    18]]

 [[11764   119]
  [   95   249]]

 [[12006    30]
  [   58   133]]

 [[12188     7]
  [   14    18]]

 [[11729   114]
  [   71   313]]

 [[12077    32]
  [   28    90]]

 [[11654   137]
  [  110   326]]

 [[12172     7]
  [   23    25]]

 [[11747    78]
  [   64   338]]

 [[12209     1]
  [   10     7]]

 [[12179     6]
  [   20    22]]

 [[12139    10]
  [    9    69]]

 [[12040    15]
  [   18   154]]

 [[12207     0]
  [   13     7]]

 [[11542   186]
  [  130   369]]

 [[12112    15]
  [   29    71]]

 [[12215     1]
  [   10     1]]

 [[12089    35]
  [   19    84]]

 [[12203     6]
  [    7    11]]

 [[12217     0]
  [    9     1]]

 [[12191     2]
  [    3    31]]

 [[11874   122]
  [   72   159]]

 [[12168     1]
  [   21    37]]

 [[12189     8]
  [   28     2]]

 [[12168    11]
  [   25    23]]

 [[12153    24]
  [   32    18]]

 [[12190     3]
  [   11    23]]

 [[12045    27]
  [   33   122]]

 [[12212     1]
  [   10     4]]

 [[11781   132]
  [  108   206]]

 [[12147    17]
  [   51    12]]

 [[11742   177]
  [   85   223]]

 [[12148    11]
  [   39    29]]

 [[12143    18]
  [   30    36]]

 [[12212     1]
  [   14     0]]

 [[12197     5]
  [   12    13]]

 [[12208     1]
  [   18     0]]

 [[12146    21]
  [   51     9]]

 [[11992    30]
  [   71   134]]

 [[12136    14]
  [   50    27]]

 [[12149    19]
  [    9    50]]

 [[12065    23]
  [   55    84]]

 [[12183     2]
  [    6    36]]

 [[11932   120]
  [   93    82]]

 [[12173    11]
  [   23    20]]

 [[12192     9]
  [   11    15]]

 [[12092    29]
  [   54    52]]

 [[12208     5]
  [    7     7]]

 [[11939    46]
  [   56   186]]

 [[11859    59]
  [   48   261]]

 [[12159    10]
  [   13    45]]

 [[12214     2]
  [    9     2]]

 [[11955    85]
  [   71   116]]

 [[12167    14]
  [   28    18]]

 [[12168    19]
  [   35     5]]

 [[12174    21]
  [   11    21]]

 [[11775   163]
  [   73   216]]

 [[12195     1]
  [   29     2]]

 [[12145     8]
  [   17    57]]

 [[12193     7]
  [   14    13]]

 [[12187     3]
  [   13    24]]

 [[12201     2]
  [    2    22]]

 [[12192    10]
  [   21     4]]

 [[12159     3]
  [   33    32]]

 [[12202     3]
  [    5    17]]

 [[12141    22]
  [   12    52]]

 [[12175    12]
  [   27    13]]

 [[12213     2]
  [    1    11]]

 [[12101    12]
  [   29    85]]

 [[12014    52]
  [   21   140]]

 [[12199     4]
  [   16     8]]

 [[12169     6]
  [   13    39]]

 [[12208     4]
  [    2    13]]

 [[12075    29]
  [   34    89]]

 [[12175    10]
  [   21    21]]

 [[11708    89]
  [   23   407]]

 [[12145    17]
  [   14    51]]

 [[12188     8]
  [    9    22]]

 [[11990    64]
  [   30   143]]

 [[12192     4]
  [    2    29]]

 [[12084    26]
  [   16   101]]

 [[12048    43]
  [   14   122]]

 [[12147    18]
  [   14    48]]

 [[11984    19]
  [   32   192]]

 [[12191     1]
  [   13    22]]

 [[12185     5]
  [   16    21]]

 [[12192     4]
  [   10    21]]

 [[12210     2]
  [    3    12]]

 [[12200     6]
  [    5    16]]

 [[12134    20]
  [    7    66]]]

===scores report===
metrics	scores
Accuracy	0.7121
MCC	0.7056
log_loss	1.3077
f1 score weighted	0.7021
f1 score macro	0.6128
f1 score micro	0.7121
roc_auc ovr	0.9790
roc_auc ovo	0.9761
precision	0.7111
recall	0.7121

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c707d05b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c707d07f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c707d0850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c707d0640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.84      0.76       357
         1.0       0.58      0.58      0.58        12
         2.0       0.85      0.58      0.69        19
         3.0       0.46      0.61      0.53        80
         4.0       0.22      0.28      0.25        54
         5.0       0.30      0.17      0.22        58
         6.0       0.43      0.27      0.33        44
         7.0       0.82      0.58      0.68        48
         8.0       0.00      0.00      0.00        11
         9.0       0.87      0.62      0.72        21
        10.0       0.67      0.13      0.22        15
        11.0       0.83      0.67      0.74        36
        12.0       0.00      0.00      0.00        12
        13.0       0.76      0.64      0.70        25
        14.0       0.56      0.25      0.34        20
        15.0       0.74      0.61      0.67        23
        16.0       0.75      0.65      0.70        23
        17.0       0.77      0.83      0.80       119
        18.0       0.33      0.53      0.41        17
        19.0       0.00      0.00      0.00        13
        20.0       0.67      0.37      0.47        90
        21.0       0.67      0.33      0.44        12
        22.0       0.73      0.76      0.75        25
        23.0       1.00      0.08      0.15        12
        24.0       0.67      0.18      0.29        22
        25.0       0.69      0.54      0.61        37
        26.0       0.78      1.00      0.88        18
        27.0       0.13      0.06      0.08        35
        28.0       0.50      0.17      0.25        12
        29.0       0.69      0.49      0.57        37
        30.0       0.58      0.69      0.63        32
        31.0       0.60      0.67      0.63        39
        32.0       0.74      0.84      0.79       746
        33.0       0.86      0.95      0.90        74
        34.0       0.79      0.86      0.83        58
        35.0       0.63      0.77      0.69        48
        36.0       0.79      0.67      0.72       502
        37.0       0.63      0.74      0.68       241
        38.0       0.68      0.76      0.71        33
        39.0       0.59      0.73      0.65       344
        40.0       0.83      0.65      0.73       191
        41.0       0.82      0.58      0.68        31
        42.0       0.78      0.70      0.74       384
        43.0       0.50      0.91      0.64       118
        44.0       0.67      0.72      0.69       436
        45.0       0.71      0.50      0.59        48
        46.0       0.66      0.84      0.74       402
        47.0       0.88      0.41      0.56        17
        48.0       0.68      0.55      0.61        42
        49.0       0.89      0.91      0.90        77
        50.0       0.79      0.84      0.81       172
        51.0       0.94      0.80      0.86        20
        52.0       0.69      0.68      0.69       499
        53.0       0.71      0.61      0.66        99
        54.0       1.00      0.09      0.17        11
        55.0       0.73      0.81      0.77       103
        56.0       0.83      0.28      0.42        18
        57.0       1.00      0.27      0.43        11
        58.0       0.97      0.91      0.94        34
        59.0       0.52      0.66      0.59       231
        60.0       0.89      0.69      0.78        58
        61.0       0.14      0.03      0.05        30
        62.0       0.67      0.38      0.48        48
        63.0       0.34      0.24      0.29        49
        64.0       0.95      0.62      0.75        34
        65.0       0.93      0.70      0.80       154
        66.0       0.43      0.21      0.29        14
        67.0       0.41      0.58      0.48       314
        68.0       0.24      0.11      0.15        63
        69.0       0.42      0.78      0.55       308
        70.0       0.57      0.41      0.47        69
        71.0       0.66      0.44      0.53        66
        72.0       0.00      0.00      0.00        14
        73.0       0.95      0.84      0.89        25
        74.0       0.00      0.00      0.00        18
        75.0       0.10      0.05      0.07        59
        76.0       0.73      0.60      0.65       205
        77.0       0.70      0.30      0.42        77
        78.0       0.77      0.46      0.57        59
        79.0       0.70      0.60      0.64       139
        80.0       0.71      0.78      0.74        41
        81.0       0.38      0.40      0.39       175
        82.0       0.46      0.51      0.48        43
        83.0       0.38      0.23      0.29        26
        84.0       0.47      0.50      0.48       105
        85.0       0.75      0.43      0.55        14
        86.0       0.75      0.66      0.70       242
        87.0       0.86      0.77      0.81       309
        88.0       0.71      0.64      0.67        58
        89.0       0.50      0.18      0.27        11
        90.0       0.58      0.47      0.52       187
        91.0       0.43      0.39      0.41        46
        92.0       0.22      0.05      0.08        40
        93.0       0.67      0.18      0.29        33
        94.0       0.59      0.68      0.63       289
        95.0       0.20      0.03      0.05        32
        96.0       1.00      0.69      0.82        74
        97.0       0.43      0.59      0.50        27
        98.0       0.80      0.54      0.65        37
        99.0       0.91      0.88      0.89        24
       100.0       0.33      0.08      0.12        26
       101.0       0.54      0.45      0.49        65
       102.0       0.83      0.45      0.59        22
       103.0       0.57      0.80      0.67        64
       104.0       0.48      0.28      0.35        40
       105.0       0.79      0.85      0.81        13
       106.0       0.92      0.77      0.84       113
       107.0       0.80      0.80      0.80       162
       108.0       0.29      0.25      0.27        24
       109.0       0.55      0.92      0.69        52
       110.0       0.86      0.80      0.83        15
       111.0       0.92      0.69      0.79       123
       112.0       0.91      0.49      0.63        41
       113.0       0.89      0.90      0.89       430
       114.0       0.80      0.75      0.78        65
       115.0       0.55      0.39      0.45        31
       116.0       0.77      0.73      0.75       173
       117.0       0.88      0.77      0.82        30
       118.0       0.80      0.89      0.84       118
       119.0       0.65      0.88      0.75       136
       120.0       0.75      0.69      0.72        61
       121.0       0.90      0.88      0.89       225
       122.0       0.97      0.97      0.97        35
       123.0       0.80      0.74      0.77        38
       124.0       0.79      0.84      0.81        31
       125.0       1.00      0.69      0.81        16
       126.0       0.75      0.86      0.80        21
       127.0       0.74      0.74      0.74        73

    accuracy                           0.67     12227
   macro avg       0.65      0.55      0.57     12227
weighted avg       0.68      0.67      0.67     12227


===confusion_matrix===

[[301   0   0 ...   0   0   0]
 [  0   7   0 ...   0   0   0]
 [  1   0  11 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   1]
 [  0   0   0 ...   0  18   3]
 [  0   0   0 ...   0   6  54]]

===multilabel confusion matrix===

[[[11733   137]
  [   56   301]]

 [[12210     5]
  [    5     7]]

 [[12206     2]
  [    8    11]]

 [[12090    57]
  [   31    49]]

 [[12120    53]
  [   39    15]]

 [[12146    23]
  [   48    10]]

 [[12167    16]
  [   32    12]]

 [[12173     6]
  [   20    28]]

 [[12215     1]
  [   11     0]]

 [[12204     2]
  [    8    13]]

 [[12211     1]
  [   13     2]]

 [[12186     5]
  [   12    24]]

 [[12214     1]
  [   12     0]]

 [[12197     5]
  [    9    16]]

 [[12203     4]
  [   15     5]]

 [[12199     5]
  [    9    14]]

 [[12199     5]
  [    8    15]]

 [[12078    30]
  [   20    99]]

 [[12192    18]
  [    8     9]]

 [[12210     4]
  [   13     0]]

 [[12121    16]
  [   57    33]]

 [[12213     2]
  [    8     4]]

 [[12195     7]
  [    6    19]]

 [[12215     0]
  [   11     1]]

 [[12203     2]
  [   18     4]]

 [[12181     9]
  [   17    20]]

 [[12204     5]
  [    0    18]]

 [[12179    13]
  [   33     2]]

 [[12213     2]
  [   10     2]]

 [[12182     8]
  [   19    18]]

 [[12179    16]
  [   10    22]]

 [[12171    17]
  [   13    26]]

 [[11255   226]
  [  118   628]]

 [[12142    11]
  [    4    70]]

 [[12156    13]
  [    8    50]]

 [[12157    22]
  [   11    37]]

 [[11638    87]
  [  168   334]]

 [[11882   104]
  [   63   178]]

 [[12182    12]
  [    8    25]]

 [[11708   175]
  [   94   250]]

 [[12011    25]
  [   66   125]]

 [[12192     4]
  [   13    18]]

 [[11768    75]
  [  114   270]]

 [[12001   108]
  [   11   107]]

 [[11632   159]
  [  120   316]]

 [[12169    10]
  [   24    24]]

 [[11654   171]
  [   65   337]]

 [[12209     1]
  [   10     7]]

 [[12174    11]
  [   19    23]]

 [[12141     9]
  [    7    70]]

 [[12016    39]
  [   27   145]]

 [[12206     1]
  [    4    16]]

 [[11579   149]
  [  160   339]]

 [[12104    24]
  [   39    60]]

 [[12216     0]
  [   10     1]]

 [[12094    30]
  [   20    83]]

 [[12208     1]
  [   13     5]]

 [[12216     0]
  [    8     3]]

 [[12192     1]
  [    3    31]]

 [[11857   139]
  [   78   153]]

 [[12164     5]
  [   18    40]]

 [[12191     6]
  [   29     1]]

 [[12170     9]
  [   30    18]]

 [[12155    23]
  [   37    12]]

 [[12192     1]
  [   13    21]]

 [[12065     8]
  [   46   108]]

 [[12209     4]
  [   11     3]]

 [[11655   258]
  [  132   182]]

 [[12142    22]
  [   56     7]]

 [[11587   332]
  [   68   240]]

 [[12137    21]
  [   41    28]]

 [[12146    15]
  [   37    29]]

 [[12211     2]
  [   14     0]]

 [[12201     1]
  [    4    21]]

 [[12209     0]
  [   18     0]]

 [[12142    26]
  [   56     3]]

 [[11976    46]
  [   83   122]]

 [[12140    10]
  [   54    23]]

 [[12160     8]
  [   32    27]]

 [[12052    36]
  [   56    83]]

 [[12173    13]
  [    9    32]]

 [[11938   114]
  [  105    70]]

 [[12158    26]
  [   21    22]]

 [[12191    10]
  [   20     6]]

 [[12063    59]
  [   53    52]]

 [[12211     2]
  [    8     6]]

 [[11933    52]
  [   83   159]]

 [[11878    40]
  [   71   238]]

 [[12154    15]
  [   21    37]]

 [[12214     2]
  [    9     2]]

 [[11977    63]
  [  100    87]]

 [[12157    24]
  [   28    18]]

 [[12180     7]
  [   38     2]]

 [[12191     3]
  [   27     6]]

 [[11803   135]
  [   93   196]]

 [[12191     4]
  [   31     1]]

 [[12153     0]
  [   23    51]]

 [[12179    21]
  [   11    16]]

 [[12185     5]
  [   17    20]]

 [[12201     2]
  [    3    21]]

 [[12197     4]
  [   24     2]]

 [[12137    25]
  [   36    29]]

 [[12203     2]
  [   12    10]]

 [[12125    38]
  [   13    51]]

 [[12175    12]
  [   29    11]]

 [[12211     3]
  [    2    11]]

 [[12106     8]
  [   26    87]]

 [[12033    32]
  [   32   130]]

 [[12188    15]
  [   18     6]]

 [[12135    40]
  [    4    48]]

 [[12210     2]
  [    3    12]]

 [[12097     7]
  [   38    85]]

 [[12184     2]
  [   21    20]]

 [[11751    46]
  [   45   385]]

 [[12150    12]
  [   16    49]]

 [[12186    10]
  [   19    12]]

 [[12017    37]
  [   46   127]]

 [[12194     3]
  [    7    23]]

 [[12082    27]
  [   13   105]]

 [[12026    65]
  [   16   120]]

 [[12152    14]
  [   19    42]]

 [[11981    21]
  [   27   198]]

 [[12191     1]
  [    1    34]]

 [[12182     7]
  [   10    28]]

 [[12189     7]
  [    5    26]]

 [[12211     0]
  [    5    11]]

 [[12200     6]
  [    3    18]]

 [[12135    19]
  [   19    54]]]

===scores report===
metrics	scores
Accuracy	0.6746
MCC	0.6675
log_loss	1.4710
f1 score weighted	0.6664
f1 score macro	0.5705
f1 score micro	0.6746
roc_auc ovr	0.9723
roc_auc ovo	0.9693
precision	0.6824
recall	0.6746

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c707d05b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c707d07f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c707d0850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c707d0640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.55      0.86      0.67       357
         1.0       1.00      0.23      0.38        13
         2.0       0.56      0.26      0.36        19
         3.0       0.70      0.44      0.54        79
         4.0       0.36      0.15      0.21        55
         5.0       0.14      0.07      0.09        59
         6.0       0.22      0.23      0.22        44
         7.0       0.56      0.75      0.64        48
         8.0       0.00      0.00      0.00        10
         9.0       0.55      0.52      0.54        21
        10.0       0.50      0.07      0.12        15
        11.0       0.96      0.75      0.84        36
        12.0       0.33      0.08      0.13        12
        13.0       0.88      0.84      0.86        25
        14.0       0.43      0.15      0.22        20
        15.0       0.78      0.64      0.70        22
        16.0       0.67      0.61      0.64        23
        17.0       0.81      0.81      0.81       118
        18.0       0.86      0.33      0.48        18
        19.0       0.00      0.00      0.00        13
        20.0       0.49      0.25      0.33        89
        21.0       0.33      0.08      0.13        12
        22.0       0.61      0.71      0.65        24
        23.0       0.50      0.08      0.14        12
        24.0       0.00      0.00      0.00        23
        25.0       0.61      0.51      0.56        37
        26.0       0.93      0.76      0.84        17
        27.0       0.28      0.22      0.25        36
        28.0       1.00      0.25      0.40        12
        29.0       0.51      0.70      0.59        37
        30.0       0.57      0.66      0.61        32
        31.0       0.76      0.82      0.79        39
        32.0       0.83      0.83      0.83       746
        33.0       0.79      0.89      0.84        74
        34.0       0.85      0.86      0.85        58
        35.0       0.69      0.71      0.70        48
        36.0       0.71      0.62      0.66       502
        37.0       0.71      0.65      0.68       240
        38.0       0.85      0.52      0.64        33
        39.0       0.58      0.75      0.66       344
        40.0       0.91      0.72      0.80       191
        41.0       0.63      0.39      0.48        31
        42.0       0.68      0.76      0.71       384
        43.0       0.54      0.93      0.69       117
        44.0       0.73      0.70      0.72       436
        45.0       0.63      0.49      0.55        49
        46.0       0.81      0.84      0.82       402
        47.0       1.00      0.12      0.21        17
        48.0       0.68      0.31      0.43        42
        49.0       0.95      0.82      0.88        77
        50.0       0.82      0.91      0.87       172
        51.0       1.00      0.32      0.48        19
        52.0       0.60      0.65      0.62       499
        53.0       0.86      0.65      0.74        99
        54.0       0.00      0.00      0.00        11
        55.0       0.79      0.80      0.79       103
        56.0       0.71      0.28      0.40        18
        57.0       0.00      0.00      0.00        11
        58.0       0.89      0.94      0.92        35
        59.0       0.66      0.53      0.59       231
        60.0       0.89      0.72      0.80        57
        61.0       0.00      0.00      0.00        29
        62.0       0.75      0.38      0.50        48
        63.0       0.31      0.33      0.32        49
        64.0       0.91      0.59      0.71        34
        65.0       0.71      0.73      0.72       155
        66.0       0.27      0.21      0.24        14
        67.0       0.76      0.52      0.62       315
        68.0       0.40      0.03      0.06        63
        69.0       0.49      0.78      0.61       307
        70.0       0.31      0.51      0.39        69
        71.0       0.77      0.35      0.48        66
        72.0       1.00      0.07      0.12        15
        73.0       0.69      0.44      0.54        25
        74.0       0.50      0.06      0.10        18
        75.0       0.44      0.19      0.26        59
        76.0       0.53      0.64      0.58       206
        77.0       0.63      0.36      0.45        76
        78.0       0.81      0.44      0.57        59
        79.0       0.62      0.44      0.52       140
        80.0       0.84      0.74      0.78        42
        81.0       0.71      0.44      0.54       175
        82.0       0.77      0.23      0.36        43
        83.0       0.86      0.24      0.38        25
        84.0       0.69      0.43      0.53       105
        85.0       0.50      0.21      0.30        14
        86.0       0.58      0.71      0.64       242
        87.0       0.67      0.81      0.73       310
        88.0       0.79      0.53      0.63        59
        89.0       0.00      0.00      0.00        11
        90.0       0.36      0.60      0.45       187
        91.0       0.42      0.39      0.40        46
        92.0       0.17      0.07      0.10        40
        93.0       0.54      0.58      0.56        33
        94.0       0.60      0.65      0.62       289
        95.0       1.00      0.03      0.06        32
        96.0       0.80      0.76      0.78        75
        97.0       0.47      0.29      0.36        28
        98.0       0.86      0.68      0.76        37
        99.0       0.81      0.91      0.86        23
       100.0       0.00      0.00      0.00        25
       101.0       0.69      0.44      0.54        66
       102.0       0.80      0.76      0.78        21
       103.0       0.70      0.74      0.72        65
       104.0       0.58      0.28      0.37        40
       105.0       1.00      0.67      0.80        12
       106.0       0.81      0.78      0.80       113
       107.0       0.72      0.78      0.75       162
       108.0       0.71      0.21      0.32        24
       109.0       0.95      0.77      0.85        53
       110.0       0.44      0.50      0.47        14
       111.0       0.36      0.73      0.49       123
       112.0       0.64      0.61      0.62        41
       113.0       0.80      0.94      0.87       429
       114.0       0.57      0.77      0.65        65
       115.0       0.69      0.58      0.63        31
       116.0       0.61      0.86      0.71       173
       117.0       0.96      0.83      0.89        30
       118.0       0.63      0.87      0.73       117
       119.0       0.91      0.88      0.90       136
       120.0       0.54      0.74      0.62        61
       121.0       0.82      0.92      0.87       225
       122.0       0.93      0.80      0.86        35
       123.0       0.93      0.37      0.53        38
       124.0       0.83      0.63      0.72        30
       125.0       0.93      0.81      0.87        16
       126.0       0.94      0.77      0.85        22
       127.0       0.71      0.88      0.79        73

    accuracy                           0.67     12226
   macro avg       0.64      0.51      0.54     12226
weighted avg       0.68      0.67      0.65     12226


===confusion_matrix===

[[307   0   0 ...   0   0   0]
 [  1   3   0 ...   0   0   0]
 [  0   0   5 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   2]
 [  0   0   0 ...   0  17   5]
 [  0   0   0 ...   0   1  64]]

===multilabel confusion matrix===

[[[11614   255]
  [   50   307]]

 [[12213     0]
  [   10     3]]

 [[12203     4]
  [   14     5]]

 [[12132    15]
  [   44    35]]

 [[12157    14]
  [   47     8]]

 [[12143    24]
  [   55     4]]

 [[12147    35]
  [   34    10]]

 [[12150    28]
  [   12    36]]

 [[12215     1]
  [   10     0]]

 [[12196     9]
  [   10    11]]

 [[12210     1]
  [   14     1]]

 [[12189     1]
  [    9    27]]

 [[12212     2]
  [   11     1]]

 [[12198     3]
  [    4    21]]

 [[12202     4]
  [   17     3]]

 [[12200     4]
  [    8    14]]

 [[12196     7]
  [    9    14]]

 [[12085    23]
  [   23    95]]

 [[12207     1]
  [   12     6]]

 [[12211     2]
  [   13     0]]

 [[12114    23]
  [   67    22]]

 [[12212     2]
  [   11     1]]

 [[12191    11]
  [    7    17]]

 [[12213     1]
  [   11     1]]

 [[12201     2]
  [   23     0]]

 [[12177    12]
  [   18    19]]

 [[12208     1]
  [    4    13]]

 [[12169    21]
  [   28     8]]

 [[12214     0]
  [    9     3]]

 [[12164    25]
  [   11    26]]

 [[12178    16]
  [   11    21]]

 [[12177    10]
  [    7    32]]

 [[11352   128]
  [  125   621]]

 [[12134    18]
  [    8    66]]

 [[12159     9]
  [    8    50]]

 [[12163    15]
  [   14    34]]

 [[11600   124]
  [  191   311]]

 [[11923    63]
  [   83   157]]

 [[12190     3]
  [   16    17]]

 [[11696   186]
  [   85   259]]

 [[12022    13]
  [   54   137]]

 [[12188     7]
  [   19    12]]

 [[11703   139]
  [   94   290]]

 [[12017    92]
  [    8   109]]

 [[11680   110]
  [  132   304]]

 [[12163    14]
  [   25    24]]

 [[11743    81]
  [   64   338]]

 [[12209     0]
  [   15     2]]

 [[12178     6]
  [   29    13]]

 [[12146     3]
  [   14    63]]

 [[12020    34]
  [   15   157]]

 [[12207     0]
  [   13     6]]

 [[11509   218]
  [  176   323]]

 [[12117    10]
  [   35    64]]

 [[12215     0]
  [   11     0]]

 [[12101    22]
  [   21    82]]

 [[12206     2]
  [   13     5]]

 [[12215     0]
  [   11     0]]

 [[12187     4]
  [    2    33]]

 [[11933    62]
  [  108   123]]

 [[12164     5]
  [   16    41]]

 [[12193     4]
  [   29     0]]

 [[12172     6]
  [   30    18]]

 [[12142    35]
  [   33    16]]

 [[12190     2]
  [   14    20]]

 [[12025    46]
  [   42   113]]

 [[12204     8]
  [   11     3]]

 [[11859    52]
  [  151   164]]

 [[12160     3]
  [   61     2]]

 [[11673   246]
  [   67   240]]

 [[12080    77]
  [   34    35]]

 [[12153     7]
  [   43    23]]

 [[12211     0]
  [   14     1]]

 [[12196     5]
  [   14    11]]

 [[12207     1]
  [   17     1]]

 [[12153    14]
  [   48    11]]

 [[11903   117]
  [   74   132]]

 [[12134    16]
  [   49    27]]

 [[12161     6]
  [   33    26]]

 [[12048    38]
  [   78    62]]

 [[12178     6]
  [   11    31]]

 [[12020    31]
  [   98    77]]

 [[12180     3]
  [   33    10]]

 [[12200     1]
  [   19     6]]

 [[12101    20]
  [   60    45]]

 [[12209     3]
  [   11     3]]

 [[11860   124]
  [   71   171]]

 [[11791   125]
  [   60   250]]

 [[12159     8]
  [   28    31]]

 [[12213     2]
  [   11     0]]

 [[11842   197]
  [   75   112]]

 [[12155    25]
  [   28    18]]

 [[12171    15]
  [   37     3]]

 [[12177    16]
  [   14    19]]

 [[11813   124]
  [  102   187]]

 [[12194     0]
  [   31     1]]

 [[12137    14]
  [   18    57]]

 [[12189     9]
  [   20     8]]

 [[12185     4]
  [   12    25]]

 [[12198     5]
  [    2    21]]

 [[12199     2]
  [   25     0]]

 [[12147    13]
  [   37    29]]

 [[12201     4]
  [    5    16]]

 [[12140    21]
  [   17    48]]

 [[12178     8]
  [   29    11]]

 [[12214     0]
  [    4     8]]

 [[12093    20]
  [   25    88]]

 [[12014    50]
  [   36   126]]

 [[12200     2]
  [   19     5]]

 [[12171     2]
  [   12    41]]

 [[12203     9]
  [    7     7]]

 [[11946   157]
  [   33    90]]

 [[12171    14]
  [   16    25]]

 [[11699    98]
  [   25   404]]

 [[12123    38]
  [   15    50]]

 [[12187     8]
  [   13    18]]

 [[11958    95]
  [   25   148]]

 [[12195     1]
  [    5    25]]

 [[12049    60]
  [   15   102]]

 [[12078    12]
  [   16   120]]

 [[12127    38]
  [   16    45]]

 [[11956    45]
  [   17   208]]

 [[12189     2]
  [    7    28]]

 [[12187     1]
  [   24    14]]

 [[12192     4]
  [   11    19]]

 [[12209     1]
  [    3    13]]

 [[12203     1]
  [    5    17]]

 [[12127    26]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6669
MCC	0.6598
log_loss	1.5456
f1 score weighted	0.6538
f1 score macro	0.5368
f1 score micro	0.6669
roc_auc ovr	0.9713
roc_auc ovo	0.9673
precision	0.6764
recall	0.6669

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c707d05b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c707d07f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c707d0850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c707d0640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.54      0.91      0.68       358
         1.0       0.67      0.33      0.44        12
         2.0       0.69      0.50      0.58        18
         3.0       0.58      0.68      0.63        79
         4.0       0.29      0.40      0.34        55
         5.0       0.44      0.12      0.19        58
         6.0       0.35      0.24      0.29        45
         7.0       0.71      0.53      0.61        47
         8.0       0.00      0.00      0.00        10
         9.0       0.62      0.62      0.62        21
        10.0       0.67      0.13      0.22        15
        11.0       0.85      0.78      0.81        36
        12.0       1.00      0.08      0.15        12
        13.0       0.88      0.56      0.68        25
        14.0       0.38      0.45      0.41        20
        15.0       0.85      0.77      0.81        22
        16.0       0.56      0.61      0.58        23
        17.0       0.82      0.85      0.83       118
        18.0       0.44      0.61      0.51        18
        19.0       0.50      0.08      0.13        13
        20.0       0.69      0.35      0.46        89
        21.0       0.50      0.15      0.24        13
        22.0       0.95      0.80      0.87        25
        23.0       0.67      0.17      0.27        12
        24.0       0.25      0.26      0.26        23
        25.0       0.55      0.59      0.57        37
        26.0       0.89      1.00      0.94        17
        27.0       0.50      0.19      0.28        36
        28.0       1.00      0.25      0.40        12
        29.0       0.48      0.78      0.60        36
        30.0       0.71      0.62      0.67        32
        31.0       0.63      0.92      0.75        39
        32.0       0.83      0.83      0.83       747
        33.0       0.94      0.82      0.88        74
        34.0       0.92      0.79      0.85        58
        35.0       0.67      0.79      0.73        47
        36.0       0.63      0.71      0.67       502
        37.0       0.70      0.61      0.65       240
        38.0       0.77      0.59      0.67        34
        39.0       0.38      0.84      0.53       344
        40.0       0.84      0.73      0.78       191
        41.0       0.73      0.50      0.59        32
        42.0       0.85      0.68      0.76       384
        43.0       0.54      0.85      0.66       117
        44.0       0.79      0.72      0.75       437
        45.0       0.71      0.49      0.58        49
        46.0       0.78      0.86      0.82       401
        47.0       1.00      0.06      0.11        17
        48.0       0.58      0.50      0.54        42
        49.0       0.94      0.83      0.88        77
        50.0       0.94      0.81      0.87       171
        51.0       0.92      0.55      0.69        20
        52.0       0.78      0.61      0.69       499
        53.0       0.74      0.61      0.67       100
        54.0       1.00      0.09      0.17        11
        55.0       0.86      0.80      0.83       104
        56.0       0.43      0.16      0.23        19
        57.0       1.00      0.09      0.17        11
        58.0       0.91      0.91      0.91        35
        59.0       0.54      0.67      0.60       230
        60.0       0.87      0.81      0.84        58
        61.0       1.00      0.03      0.07        29
        62.0       0.49      0.41      0.44        49
        63.0       0.23      0.20      0.22        50
        64.0       0.92      0.68      0.78        34
        65.0       0.85      0.82      0.84       155
        66.0       0.67      0.14      0.24        14
        67.0       0.69      0.67      0.68       314
        68.0       0.25      0.05      0.08        62
        69.0       0.47      0.75      0.58       307
        70.0       0.39      0.34      0.36        68
        71.0       0.59      0.55      0.57        66
        72.0       0.50      0.07      0.12        15
        73.0       0.93      0.52      0.67        25
        74.0       0.00      0.00      0.00        19
        75.0       0.17      0.10      0.13        59
        76.0       0.75      0.73      0.74       206
        77.0       0.58      0.47      0.52        77
        78.0       0.76      0.59      0.67        59
        79.0       0.59      0.69      0.64       139
        80.0       0.82      0.79      0.80        42
        81.0       0.52      0.43      0.47       174
        82.0       0.83      0.44      0.58        43
        83.0       0.36      0.32      0.34        25
        84.0       0.64      0.52      0.58       105
        85.0       0.73      0.53      0.62        15
        86.0       0.67      0.67      0.67       242
        87.0       0.67      0.85      0.75       309
        88.0       0.80      0.56      0.66        59
        89.0       0.00      0.00      0.00        11
        90.0       0.59      0.58      0.59       188
        91.0       0.63      0.26      0.36        47
        92.0       0.46      0.15      0.23        40
        93.0       0.88      0.45      0.60        33
        94.0       0.59      0.71      0.64       288
        95.0       0.44      0.22      0.29        32
        96.0       0.87      0.83      0.85        75
        97.0       0.70      0.26      0.38        27
        98.0       0.91      0.53      0.67        38
        99.0       0.85      0.96      0.90        23
       100.0       0.33      0.08      0.13        25
       101.0       0.80      0.42      0.55        66
       102.0       0.62      0.91      0.74        22
       103.0       0.80      0.83      0.82        64
       104.0       0.45      0.36      0.40        39
       105.0       1.00      0.75      0.86        12
       106.0       0.98      0.73      0.84       113
       107.0       0.76      0.80      0.78       161
       108.0       0.50      0.52      0.51        23
       109.0       0.85      0.89      0.87        53
       110.0       0.90      0.64      0.75        14
       111.0       0.86      0.63      0.73       123
       112.0       0.79      0.54      0.64        41
       113.0       0.93      0.87      0.90       429
       114.0       0.74      0.82      0.77        65
       115.0       0.89      0.52      0.65        31
       116.0       0.63      0.77      0.70       173
       117.0       0.90      0.84      0.87        31
       118.0       0.83      0.81      0.82       117
       119.0       0.96      0.82      0.88       135
       120.0       0.73      0.82      0.77        62
       121.0       0.87      0.82      0.84       224
       122.0       0.90      0.80      0.85        35
       123.0       0.69      0.54      0.61        37
       124.0       0.83      0.50      0.62        30
       125.0       0.75      0.75      0.75        16
       126.0       0.86      0.86      0.86        22
       127.0       0.73      0.82      0.77        73

    accuracy                           0.69     12226
   macro avg       0.69      0.55      0.58     12226
weighted avg       0.71      0.69      0.68     12226


===confusion_matrix===

[[324   1   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   2]
 [  0   0   0 ...   0  19   2]
 [  0   0   0 ...   0   2  60]]

===multilabel confusion matrix===

[[[11591   277]
  [   34   324]]

 [[12212     2]
  [    8     4]]

 [[12204     4]
  [    9     9]]

 [[12108    39]
  [   25    54]]

 [[12117    54]
  [   33    22]]

 [[12159     9]
  [   51     7]]

 [[12161    20]
  [   34    11]]

 [[12169    10]
  [   22    25]]

 [[12215     1]
  [   10     0]]

 [[12197     8]
  [    8    13]]

 [[12210     1]
  [   13     2]]

 [[12185     5]
  [    8    28]]

 [[12214     0]
  [   11     1]]

 [[12199     2]
  [   11    14]]

 [[12191    15]
  [   11     9]]

 [[12201     3]
  [    5    17]]

 [[12192    11]
  [    9    14]]

 [[12086    22]
  [   18   100]]

 [[12194    14]
  [    7    11]]

 [[12212     1]
  [   12     1]]

 [[12123    14]
  [   58    31]]

 [[12211     2]
  [   11     2]]

 [[12200     1]
  [    5    20]]

 [[12213     1]
  [   10     2]]

 [[12185    18]
  [   17     6]]

 [[12171    18]
  [   15    22]]

 [[12207     2]
  [    0    17]]

 [[12183     7]
  [   29     7]]

 [[12214     0]
  [    9     3]]

 [[12160    30]
  [    8    28]]

 [[12186     8]
  [   12    20]]

 [[12166    21]
  [    3    36]]

 [[11355   124]
  [  130   617]]

 [[12148     4]
  [   13    61]]

 [[12164     4]
  [   12    46]]

 [[12161    18]
  [   10    37]]

 [[11517   207]
  [  148   354]]

 [[11923    63]
  [   93   147]]

 [[12186     6]
  [   14    20]]

 [[11418   464]
  [   55   289]]

 [[12009    26]
  [   52   139]]

 [[12188     6]
  [   16    16]]

 [[11797    45]
  [  123   261]]

 [[12025    84]
  [   18    99]]

 [[11705    84]
  [  122   315]]

 [[12167    10]
  [   25    24]]

 [[11727    98]
  [   57   344]]

 [[12209     0]
  [   16     1]]

 [[12169    15]
  [   21    21]]

 [[12145     4]
  [   13    64]]

 [[12046     9]
  [   33   138]]

 [[12205     1]
  [    9    11]]

 [[11643    84]
  [  193   306]]

 [[12105    21]
  [   39    61]]

 [[12215     0]
  [   10     1]]

 [[12108    14]
  [   21    83]]

 [[12203     4]
  [   16     3]]

 [[12215     0]
  [   10     1]]

 [[12188     3]
  [    3    32]]

 [[11868   128]
  [   77   153]]

 [[12161     7]
  [   11    47]]

 [[12197     0]
  [   28     1]]

 [[12156    21]
  [   29    20]]

 [[12143    33]
  [   40    10]]

 [[12190     2]
  [   11    23]]

 [[12049    22]
  [   28   127]]

 [[12211     1]
  [   12     2]]

 [[11819    93]
  [  103   211]]

 [[12155     9]
  [   59     3]]

 [[11656   263]
  [   76   231]]

 [[12122    36]
  [   45    23]]

 [[12135    25]
  [   30    36]]

 [[12210     1]
  [   14     1]]

 [[12200     1]
  [   12    13]]

 [[12207     0]
  [   19     0]]

 [[12138    29]
  [   53     6]]

 [[11970    50]
  [   56   150]]

 [[12123    26]
  [   41    36]]

 [[12156    11]
  [   24    35]]

 [[12020    67]
  [   43    96]]

 [[12177     7]
  [    9    33]]

 [[11982    70]
  [   99    75]]

 [[12179     4]
  [   24    19]]

 [[12187    14]
  [   17     8]]

 [[12090    31]
  [   50    55]]

 [[12208     3]
  [    7     8]]

 [[11905    79]
  [   81   161]]

 [[11788   129]
  [   47   262]]

 [[12159     8]
  [   26    33]]

 [[12213     2]
  [   11     0]]

 [[11963    75]
  [   79   109]]

 [[12172     7]
  [   35    12]]

 [[12179     7]
  [   34     6]]

 [[12191     2]
  [   18    15]]

 [[11794   144]
  [   83   205]]

 [[12185     9]
  [   25     7]]

 [[12142     9]
  [   13    62]]

 [[12196     3]
  [   20     7]]

 [[12186     2]
  [   18    20]]

 [[12199     4]
  [    1    22]]

 [[12197     4]
  [   23     2]]

 [[12153     7]
  [   38    28]]

 [[12192    12]
  [    2    20]]

 [[12149    13]
  [   11    53]]

 [[12170    17]
  [   25    14]]

 [[12214     0]
  [    3     9]]

 [[12111     2]
  [   30    83]]

 [[12024    41]
  [   33   128]]

 [[12191    12]
  [   11    12]]

 [[12165     8]
  [    6    47]]

 [[12211     1]
  [    5     9]]

 [[12090    13]
  [   45    78]]

 [[12179     6]
  [   19    22]]

 [[11770    27]
  [   57   372]]

 [[12142    19]
  [   12    53]]

 [[12193     2]
  [   15    16]]

 [[11975    78]
  [   39   134]]

 [[12192     3]
  [    5    26]]

 [[12089    20]
  [   22    95]]

 [[12086     5]
  [   24   111]]

 [[12145    19]
  [   11    51]]

 [[11975    27]
  [   41   183]]

 [[12188     3]
  [    7    28]]

 [[12180     9]
  [   17    20]]

 [[12193     3]
  [   15    15]]

 [[12206     4]
  [    4    12]]

 [[12201     3]
  [    3    19]]

 [[12131    22]
  [   13    60]]]

===scores report===
metrics	scores
Accuracy	0.6866
MCC	0.6802
log_loss	1.4549
f1 score weighted	0.6808
f1 score macro	0.5805
f1 score micro	0.6866
roc_auc ovr	0.9742
roc_auc ovo	0.9702
precision	0.7081
recall	0.6866

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c707d05b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c707d07f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c707d0850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c707d0640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.71      0.75       358
         1.0       0.58      0.58      0.58        12
         2.0       1.00      0.26      0.42        19
         3.0       0.81      0.53      0.64        79
         4.0       0.69      0.16      0.26        55
         5.0       0.16      0.10      0.13        58
         6.0       0.20      0.27      0.23        45
         7.0       0.69      0.38      0.49        47
         8.0       0.40      0.20      0.27        10
         9.0       0.50      0.48      0.49        21
        10.0       0.40      0.13      0.20        15
        11.0       1.00      0.78      0.88        36
        12.0       0.50      0.08      0.14        12
        13.0       0.78      0.72      0.75        25
        14.0       1.00      0.11      0.19        19
        15.0       0.93      0.64      0.76        22
        16.0       0.39      0.65      0.49        23
        17.0       0.98      0.68      0.80       118
        18.0       0.15      0.61      0.25        18
        19.0       0.00      0.00      0.00        12
        20.0       0.48      0.48      0.48        90
        21.0       0.83      0.38      0.53        13
        22.0       0.59      0.76      0.67        25
        23.0       0.00      0.00      0.00        13
        24.0       0.28      0.32      0.30        22
        25.0       0.69      0.53      0.60        38
        26.0       1.00      0.94      0.97        17
        27.0       0.40      0.06      0.10        35
        28.0       0.20      0.08      0.12        12
        29.0       0.62      0.44      0.52        36
        30.0       0.67      0.31      0.43        32
        31.0       0.87      0.87      0.87        38
        32.0       0.58      0.88      0.70       747
        33.0       0.48      0.87      0.62        75
        34.0       0.68      0.86      0.76        59
        35.0       0.78      0.53      0.63        47
        36.0       0.66      0.67      0.67       501
        37.0       0.66      0.64      0.65       241
        38.0       0.88      0.64      0.74        33
        39.0       0.65      0.63      0.64       344
        40.0       0.90      0.78      0.83       192
        41.0       0.76      0.50      0.60        32
        42.0       0.81      0.69      0.75       384
        43.0       0.78      0.78      0.78       117
        44.0       0.93      0.62      0.74       436
        45.0       0.72      0.27      0.39        49
        46.0       0.63      0.86      0.73       401
        47.0       0.00      0.00      0.00        17
        48.0       0.85      0.26      0.40        42
        49.0       0.98      0.79      0.88        77
        50.0       0.71      0.90      0.79       172
        51.0       0.90      0.45      0.60        20
        52.0       0.65      0.57      0.61       499
        53.0       0.84      0.64      0.73       100
        54.0       0.00      0.00      0.00        11
        55.0       0.80      0.83      0.81       104
        56.0       0.57      0.22      0.32        18
        57.0       0.20      0.10      0.13        10
        58.0       0.91      0.83      0.87        35
        59.0       0.40      0.71      0.52       230
        60.0       0.72      0.81      0.76        58
        61.0       0.00      0.00      0.00        29
        62.0       0.52      0.35      0.41        49
        63.0       0.12      0.32      0.18        50
        64.0       0.49      0.74      0.59        34
        65.0       0.37      0.85      0.51       155
        66.0       0.67      0.14      0.24        14
        67.0       0.77      0.54      0.64       314
        68.0       0.18      0.03      0.05        62
        69.0       0.72      0.44      0.55       307
        70.0       0.34      0.28      0.31        68
        71.0       0.32      0.36      0.34        66
        72.0       0.00      0.00      0.00        14
        73.0       0.88      0.62      0.73        24
        74.0       0.00      0.00      0.00        19
        75.0       0.15      0.12      0.13        60
        76.0       0.75      0.61      0.67       206
        77.0       0.64      0.36      0.46        77
        78.0       0.83      0.49      0.62        59
        79.0       0.80      0.43      0.56       139
        80.0       0.85      0.79      0.81        42
        81.0       0.68      0.25      0.36       174
        82.0       0.83      0.23      0.36        43
        83.0       1.00      0.04      0.07        26
        84.0       0.58      0.32      0.41       106
        85.0       1.00      0.13      0.24        15
        86.0       0.74      0.64      0.69       241
        87.0       0.73      0.74      0.73       309
        88.0       0.37      0.63      0.46        59
        89.0       0.80      0.40      0.53        10
        90.0       0.86      0.29      0.44       188
        91.0       0.60      0.39      0.47        46
        92.0       0.20      0.07      0.11        41
        93.0       0.79      0.34      0.48        32
        94.0       0.60      0.60      0.60       288
        95.0       0.23      0.23      0.23        31
        96.0       0.64      0.81      0.71        75
        97.0       1.00      0.11      0.20        27
        98.0       0.85      0.45      0.59        38
        99.0       0.73      0.92      0.81        24
       100.0       0.00      0.00      0.00        25
       101.0       0.92      0.34      0.49        65
       102.0       0.84      0.73      0.78        22
       103.0       0.83      0.69      0.75        64
       104.0       1.00      0.33      0.49        40
       105.0       1.00      0.58      0.74        12
       106.0       0.52      0.76      0.62       113
       107.0       0.78      0.76      0.77       161
       108.0       0.80      0.17      0.28        24
       109.0       0.76      0.87      0.81        52
       110.0       1.00      0.73      0.85        15
       111.0       0.20      0.80      0.32       124
       112.0       0.07      0.71      0.12        41
       113.0       0.79      0.90      0.84       430
       114.0       1.00      0.37      0.54        65
       115.0       0.29      0.52      0.37        31
       116.0       0.99      0.57      0.72       173
       117.0       1.00      0.71      0.83        31
       118.0       0.79      0.79      0.79       117
       119.0       0.95      0.62      0.75       136
       120.0       0.56      0.58      0.57        62
       121.0       0.86      0.79      0.82       224
       122.0       1.00      0.69      0.81        35
       123.0       0.89      0.43      0.58        37
       124.0       0.69      0.87      0.77        31
       125.0       1.00      0.60      0.75        15
       126.0       0.33      0.05      0.08        21
       127.0       0.59      0.89      0.71        73

    accuracy                           0.62     12226
   macro avg       0.63      0.49      0.51     12226
weighted avg       0.69      0.62      0.62     12226


===confusion_matrix===

[[253   0   0 ...   0   0   0]
 [  0   7   0 ...   0   0   0]
 [  0   0   5 ...   0   0   0]
 ...
 [  0   0   0 ...   9   0   0]
 [  0   0   0 ...   0   1  19]
 [  0   0   0 ...   0   1  65]]

===multilabel confusion matrix===

[[[11804    64]
  [  105   253]]

 [[12209     5]
  [    5     7]]

 [[12207     0]
  [   14     5]]

 [[12137    10]
  [   37    42]]

 [[12167     4]
  [   46     9]]

 [[12137    31]
  [   52     6]]

 [[12132    49]
  [   33    12]]

 [[12171     8]
  [   29    18]]

 [[12213     3]
  [    8     2]]

 [[12195    10]
  [   11    10]]

 [[12208     3]
  [   13     2]]

 [[12190     0]
  [    8    28]]

 [[12213     1]
  [   11     1]]

 [[12196     5]
  [    7    18]]

 [[12207     0]
  [   17     2]]

 [[12203     1]
  [    8    14]]

 [[12180    23]
  [    8    15]]

 [[12106     2]
  [   38    80]]

 [[12148    60]
  [    7    11]]

 [[12214     0]
  [   12     0]]

 [[12090    46]
  [   47    43]]

 [[12212     1]
  [    8     5]]

 [[12188    13]
  [    6    19]]

 [[12212     1]
  [   13     0]]

 [[12186    18]
  [   15     7]]

 [[12179     9]
  [   18    20]]

 [[12209     0]
  [    1    16]]

 [[12188     3]
  [   33     2]]

 [[12210     4]
  [   11     1]]

 [[12180    10]
  [   20    16]]

 [[12189     5]
  [   22    10]]

 [[12183     5]
  [    5    33]]

 [[11006   473]
  [   89   658]]

 [[12081    70]
  [   10    65]]

 [[12143    24]
  [    8    51]]

 [[12172     7]
  [   22    25]]

 [[11554   171]
  [  165   336]]

 [[11906    79]
  [   87   154]]

 [[12190     3]
  [   12    21]]

 [[11764   118]
  [  126   218]]

 [[12017    17]
  [   43   149]]

 [[12189     5]
  [   16    16]]

 [[11779    63]
  [  118   266]]

 [[12083    26]
  [   26    91]]

 [[11771    19]
  [  166   270]]

 [[12172     5]
  [   36    13]]

 [[11620   205]
  [   56   345]]

 [[12209     0]
  [   17     0]]

 [[12182     2]
  [   31    11]]

 [[12148     1]
  [   16    61]]

 [[11991    63]
  [   18   154]]

 [[12205     1]
  [   11     9]]

 [[11578   149]
  [  217   282]]

 [[12114    12]
  [   36    64]]

 [[12215     0]
  [   11     0]]

 [[12100    22]
  [   18    86]]

 [[12205     3]
  [   14     4]]

 [[12212     4]
  [    9     1]]

 [[12188     3]
  [    6    29]]

 [[11756   240]
  [   67   163]]

 [[12150    18]
  [   11    47]]

 [[12197     0]
  [   29     0]]

 [[12161    16]
  [   32    17]]

 [[12060   116]
  [   34    16]]

 [[12166    26]
  [    9    25]]

 [[11845   226]
  [   23   132]]

 [[12211     1]
  [   12     2]]

 [[11861    51]
  [  143   171]]

 [[12155     9]
  [   60     2]]

 [[11865    54]
  [  171   136]]

 [[12121    37]
  [   49    19]]

 [[12110    50]
  [   42    24]]

 [[12208     4]
  [   14     0]]

 [[12200     2]
  [    9    15]]

 [[12207     0]
  [   19     0]]

 [[12127    39]
  [   53     7]]

 [[11978    42]
  [   80   126]]

 [[12133    16]
  [   49    28]]

 [[12161     6]
  [   30    29]]

 [[12072    15]
  [   79    60]]

 [[12178     6]
  [    9    33]]

 [[12032    20]
  [  131    43]]

 [[12181     2]
  [   33    10]]

 [[12200     0]
  [   25     1]]

 [[12095    25]
  [   72    34]]

 [[12211     0]
  [   13     2]]

 [[11931    54]
  [   86   155]]

 [[11830    87]
  [   79   230]]

 [[12103    64]
  [   22    37]]

 [[12215     1]
  [    6     4]]

 [[12029     9]
  [  133    55]]

 [[12168    12]
  [   28    18]]

 [[12173    12]
  [   38     3]]

 [[12191     3]
  [   21    11]]

 [[11822   116]
  [  115   173]]

 [[12171    24]
  [   24     7]]

 [[12116    35]
  [   14    61]]

 [[12199     0]
  [   24     3]]

 [[12185     3]
  [   21    17]]

 [[12194     8]
  [    2    22]]

 [[12201     0]
  [   25     0]]

 [[12159     2]
  [   43    22]]

 [[12201     3]
  [    6    16]]

 [[12153     9]
  [   20    44]]

 [[12186     0]
  [   27    13]]

 [[12214     0]
  [    5     7]]

 [[12033    80]
  [   27    86]]

 [[12030    35]
  [   38   123]]

 [[12201     1]
  [   20     4]]

 [[12160    14]
  [    7    45]]

 [[12211     0]
  [    4    11]]

 [[11711   391]
  [   25    99]]

 [[11776   409]
  [   12    29]]

 [[11692   104]
  [   45   385]]

 [[12161     0]
  [   41    24]]

 [[12155    40]
  [   15    16]]

 [[12052     1]
  [   75    98]]

 [[12195     0]
  [    9    22]]

 [[12085    24]
  [   24    93]]

 [[12086     4]
  [   52    84]]

 [[12136    28]
  [   26    36]]

 [[11972    30]
  [   46   178]]

 [[12191     0]
  [   11    24]]

 [[12187     2]
  [   21    16]]

 [[12183    12]
  [    4    27]]

 [[12211     0]
  [    6     9]]

 [[12203     2]
  [   20     1]]

 [[12107    46]
  [    8    65]]]

===scores report===
metrics	scores
Accuracy	0.6217
MCC	0.6146
log_loss	1.7826
f1 score weighted	0.6236
f1 score macro	0.5093
f1 score micro	0.6217
roc_auc ovr	0.9683
roc_auc ovo	0.9634
precision	0.6867
recall	0.6217

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7121125378261225	0.7055576550782725	1.3077067506105164	0.7020849634227201	0.6127593445555934	0.7121125378261225	0.9789838429636823	0.9760537566123507	0.71108969864194	0.7121125378261225
1	0.6745726670483356	0.6674947338245306	1.4710040626508445	0.666418779438339	0.5705207794030522	0.6745726670483356	0.9723475515704613	0.9692630758161096	0.6823504792931487	0.6745726670483356
2	0.6669393096679208	0.6597830514412643	1.5455610565747735	0.6537689907797142	0.536846793096001	0.6669393096679208	0.9713100449281404	0.9673250351329805	0.676430188382	0.6669393096679208
3	0.6865696057582202	0.6801737349740561	1.454914051076925	0.6807722382839841	0.5805397698572657	0.6865696057582202	0.9741795480380948	0.970224762476327	0.708051476515234	0.6865696057582202
4	0.621707835759856	0.6145504288828707	1.7826380009632803	0.6236086476495091	0.5093029017509936	0.621707835759856	0.9682834345937996	0.9633757974098496	0.6866876289196211	0.621707835759856
mean	0.672380391212091	0.6655119208401988	1.5123647843752681	0.6653307239148533	0.5619939177325811	0.672380391212091	0.9730208844188357	0.9692484854895236	0.6929218943503889	0.672380391212091
std	0.029604380087302293	0.02984109508312289	0.15559293745881334	0.02632452724595552	0.035784090331207934	0.029604380087302293	0.0035418400788999817	0.004134082032156781	0.014011214199921502	0.029604380087302293

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 27410.7919 secs

