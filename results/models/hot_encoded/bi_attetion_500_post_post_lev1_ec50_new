/home/amsequeira/enzymeClassification/models/hot_encoded/bi_attetion_500_post_post_lev1_ec50_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6fb0511220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6fb05112e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6fb0511460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6fb05111c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.79      0.77      1793
         1.0       0.82      0.87      0.84      4921
         2.0       0.81      0.77      0.79      3576
         3.0       0.77      0.61      0.68       943
         4.0       0.71      0.78      0.74       695
         5.0       0.90      0.86      0.88      1073
         6.0       0.93      0.90      0.91       471

    accuracy                           0.81     13472
   macro avg       0.81      0.80      0.80     13472
weighted avg       0.81      0.81      0.81     13472


===confusion_matrix===

[[1421  164  119   31   32   11   15]
 [ 154 4274  308   69   68   41    7]
 [ 172  505 2750   53   61   26    9]
 [  65  141  117  571   34   12    3]
 [  28   60   42   14  540   11    0]
 [  26   69   30    4   24  920    0]
 [  10   21   12    1    2    0  425]]

===multilabel confusion matrix===

[[[11224   455]
  [  372  1421]]

 [[ 7591   960]
  [  647  4274]]

 [[ 9268   628]
  [  826  2750]]

 [[12357   172]
  [  372   571]]

 [[12556   221]
  [  155   540]]

 [[12298   101]
  [  153   920]]

 [[12967    34]
  [   46   425]]]

===scores report===
metrics	scores
Accuracy	0.8092
MCC	0.7491
log_loss	0.7058
f1 score weighted	0.8081
f1 score macro	0.8027
f1 score micro	0.8092
roc_auc ovr	0.9575
roc_auc ovo	0.9629
precision	0.8097
recall	0.8092

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6fb0511220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6fb05112e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6fb0511460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6fb05111c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.77      0.78      1792
         1.0       0.85      0.84      0.84      4921
         2.0       0.77      0.82      0.79      3576
         3.0       0.73      0.70      0.71       943
         4.0       0.83      0.76      0.80       696
         5.0       0.90      0.87      0.88      1072
         6.0       0.92      0.89      0.90       471

    accuracy                           0.82     13471
   macro avg       0.83      0.81      0.82     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1379  148  164   55   22   12   12]
 [ 146 4141  449   87   31   56   11]
 [ 136  369 2935   74   37   16    9]
 [  39  104  124  658   10    6    2]
 [  15   52   70   16  530   12    1]
 [  24   57   48    8    5  929    1]
 [  13   14   18    4    1    3  418]]

===multilabel confusion matrix===

[[[11306   373]
  [  413  1379]]

 [[ 7806   744]
  [  780  4141]]

 [[ 9022   873]
  [  641  2935]]

 [[12284   244]
  [  285   658]]

 [[12669   106]
  [  166   530]]

 [[12294   105]
  [  143   929]]

 [[12964    36]
  [   53   418]]]

===scores report===
metrics	scores
Accuracy	0.8158
MCC	0.7581
log_loss	0.6435
f1 score weighted	0.8159
f1 score macro	0.8161
f1 score micro	0.8158
roc_auc ovr	0.9602
roc_auc ovo	0.9669
precision	0.8168
recall	0.8158

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6fb0511220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6fb05112e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6fb0511460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6fb05111c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.74      0.80      1792
         1.0       0.83      0.85      0.84      4921
         2.0       0.78      0.82      0.80      3576
         3.0       0.75      0.66      0.70       943
         4.0       0.76      0.76      0.76       695
         5.0       0.83      0.91      0.87      1072
         6.0       0.95      0.88      0.91       472

    accuracy                           0.82     13471
   macro avg       0.83      0.80      0.81     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1319  186  174   43   39   24    7]
 [  78 4207  418   74   52   86    6]
 [  57  430 2930   62   43   44   10]
 [  30  131  119  621   25   17    0]
 [  15   63   52   17  531   17    0]
 [   9   51   26    6    8  972    0]
 [   5   23   22    0    0    6  416]]

===multilabel confusion matrix===

[[[11485   194]
  [  473  1319]]

 [[ 7666   884]
  [  714  4207]]

 [[ 9084   811]
  [  646  2930]]

 [[12326   202]
  [  322   621]]

 [[12609   167]
  [  164   531]]

 [[12205   194]
  [  100   972]]

 [[12976    23]
  [   56   416]]]

===scores report===
metrics	scores
Accuracy	0.8163
MCC	0.7582
log_loss	0.6848
f1 score weighted	0.8155
f1 score macro	0.8124
f1 score micro	0.8163
roc_auc ovr	0.9579
roc_auc ovo	0.9643
precision	0.8174
recall	0.8163

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6fb0511220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6fb05112e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6fb0511460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6fb05111c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.71      0.78      1792
         1.0       0.82      0.87      0.84      4920
         2.0       0.79      0.82      0.80      3576
         3.0       0.72      0.72      0.72       944
         4.0       0.84      0.73      0.78       695
         5.0       0.90      0.87      0.88      1072
         6.0       0.90      0.89      0.90       472

    accuracy                           0.82     13471
   macro avg       0.83      0.80      0.82     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1266  218  202   63   17   17    9]
 [  70 4285  383   87   33   47   15]
 [  47  444 2940   76   29   25   15]
 [  30  132   95  675    7    5    0]
 [  17   80   54   24  506    8    6]
 [  10   72   42   10    7  930    1]
 [   9   20   18    2    0    1  422]]

===multilabel confusion matrix===

[[[11496   183]
  [  526  1266]]

 [[ 7585   966]
  [  635  4285]]

 [[ 9101   794]
  [  636  2940]]

 [[12265   262]
  [  269   675]]

 [[12683    93]
  [  189   506]]

 [[12296   103]
  [  142   930]]

 [[12953    46]
  [   50   422]]]

===scores report===
metrics	scores
Accuracy	0.8184
MCC	0.7603
log_loss	0.6289
f1 score weighted	0.8176
f1 score macro	0.8156
f1 score micro	0.8184
roc_auc ovr	0.9612
roc_auc ovo	0.9674
precision	0.8206
recall	0.8184

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6fb0511220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6fb05112e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6fb0511460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6fb05111c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.77      0.79      1792
         1.0       0.83      0.85      0.84      4920
         2.0       0.79      0.81      0.80      3576
         3.0       0.73      0.67      0.70       944
         4.0       0.84      0.69      0.76       695
         5.0       0.83      0.92      0.87      1073
         6.0       0.91      0.90      0.91       471

    accuracy                           0.81     13471
   macro avg       0.82      0.80      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1378  160  152   41   13   37   11]
 [ 138 4160  415   83   31   79   14]
 [  96  423 2881   83   31   49   13]
 [  46  122  101  634   14   24    3]
 [  38   75   67   19  483   13    0]
 [   8   55   20    7    1  982    0]
 [  14   21    9    2    0    1  424]]

===multilabel confusion matrix===

[[[11339   340]
  [  414  1378]]

 [[ 7695   856]
  [  760  4160]]

 [[ 9131   764]
  [  695  2881]]

 [[12292   235]
  [  310   634]]

 [[12686    90]
  [  212   483]]

 [[12195   203]
  [   91   982]]

 [[12959    41]
  [   47   424]]]

===scores report===
metrics	scores
Accuracy	0.8123
MCC	0.7532
log_loss	0.7046
f1 score weighted	0.8114
f1 score macro	0.8082
f1 score micro	0.8123
roc_auc ovr	0.9571
roc_auc ovo	0.9632
precision	0.8119
recall	0.8123

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8091597387173397	0.7490969360103716	0.7057531385704908	0.8081210275464733	0.8027204471379423	0.8091597387173397	0.9574520316337577	0.9628549715449152	0.8097212833380555	0.8091597387173397
1	0.8158265904535669	0.7580931447969478	0.6434661603454208	0.815937354554501	0.816123380056967	0.8158265904535669	0.9601671820405728	0.9668722500958022	0.8167834873959825	0.8158265904535669
2	0.8162719916858436	0.7581668511076523	0.6848029676498006	0.8154656821729059	0.8124333133242542	0.8162719916858436	0.9579135964343792	0.9643149724443814	0.8173624866086497	0.8162719916858436
3	0.8183505307698018	0.7602666026492435	0.6289360711444196	0.8176130571759267	0.8156381205020338	0.8183505307698018	0.9611957001619381	0.9673870679569027	0.8205795254638738	0.8183505307698018
4	0.812263380595353	0.7532199285926491	0.7046231574233935	0.8113753647908339	0.8082138307840465	0.812263380595353	0.9570505523129322	0.96321347270659	0.8119229173260025	0.812263380595353
mean	0.8143744464443812	0.7557686926313728	0.6735162990267052	0.8137024972481282	0.8110258183610487	0.8143744464443812	0.9587558125167159	0.9649285469497183	0.8152739400265128	0.8143744464443812
std	0.003260933069753671	0.00405940810984121	0.031700621143731254	0.003463069064052831	0.005022468987294919	0.003260933069753671	0.0016286252200492452	0.001867617506627605	0.003920493498496608	0.003260933069753671

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 27483.8301 secs

