/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_terminals_bilstm_attentio_cv_only_enz_hot_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8dcc3e0220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8dcc3e0880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8dcc3e08e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8dcc3e0670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.80      0.86      3813
         1.0       0.81      0.96      0.88     10869
         2.0       0.90      0.80      0.85      6897
         3.0       0.96      0.80      0.87      2585
         4.0       0.93      0.85      0.89      1616
         5.0       0.95      0.94      0.95      3258
         6.0       0.98      0.94      0.96      1372

    accuracy                           0.88     30410
   macro avg       0.92      0.87      0.89     30410
weighted avg       0.89      0.88      0.88     30410


===confusion_matrix===

[[ 3055   546   133    17    21    32     9]
 [   48 10469   245    24    20    57     6]
 [  103  1170  5490    36    40    46    12]
 [   34   333   114  2069    14    21     0]
 [   24   144    49    11  1375    12     1]
 [    3   146    26     3     4  3075     1]
 [    4    56    16     1     0     3  1292]]

===multilabel confusion matrix===

[[[26381   216]
  [  758  3055]]

 [[17146  2395]
  [  400 10469]]

 [[22930   583]
  [ 1407  5490]]

 [[27733    92]
  [  516  2069]]

 [[28695    99]
  [  241  1375]]

 [[26981   171]
  [  183  3075]]

 [[29009    29]
  [   80  1292]]]

===scores report===
metrics	scores
Accuracy	0.8821
MCC	0.8498
log_loss	0.3658
f1 score weighted	0.8815
f1 score macro	0.8940
f1 score micro	0.8821
roc_auc ovr	0.9843
roc_auc ovo	0.9868
precision	0.8896
recall	0.8821

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8dcc3e0220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8dcc3e0880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8dcc3e08e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8dcc3e0670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.91      0.91      3813
         1.0       0.92      0.95      0.93     10869
         2.0       0.91      0.89      0.90      6897
         3.0       0.95      0.89      0.92      2585
         4.0       0.93      0.89      0.91      1616
         5.0       0.98      0.96      0.97      3258
         6.0       0.98      0.96      0.97      1372

    accuracy                           0.93     30410
   macro avg       0.94      0.92      0.93     30410
weighted avg       0.93      0.93      0.93     30410


===confusion_matrix===

[[ 3482   160   119    20    23     4     5]
 [  131 10318   306    48    26    34     6]
 [  140   507  6140    41    40    20     9]
 [   48   123    87  2308    14     4     1]
 [   37    66    48    16  1445     4     0]
 [   17    72    34     5     2  3128     0]
 [   10    17    22     0     2     2  1319]]

===multilabel confusion matrix===

[[[26214   383]
  [  331  3482]]

 [[18596   945]
  [  551 10318]]

 [[22897   616]
  [  757  6140]]

 [[27695   130]
  [  277  2308]]

 [[28687   107]
  [  171  1445]]

 [[27084    68]
  [  130  3128]]

 [[29017    21]
  [   53  1319]]]

===scores report===
metrics	scores
Accuracy	0.9254
MCC	0.9043
log_loss	0.2810
f1 score weighted	0.9253
f1 score macro	0.9303
f1 score micro	0.9254
roc_auc ovr	0.9917
roc_auc ovo	0.9932
precision	0.9257
recall	0.9254

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8dcc3e0220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8dcc3e0880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8dcc3e08e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8dcc3e0670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.85      0.89      3814
         1.0       0.92      0.92      0.92     10869
         2.0       0.88      0.88      0.88      6896
         3.0       0.72      0.92      0.81      2584
         4.0       0.96      0.83      0.89      1617
         5.0       0.98      0.94      0.96      3258
         6.0       0.97      0.97      0.97      1372

    accuracy                           0.90     30410
   macro avg       0.91      0.90      0.90     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[3233  196  173  175   13    9   15]
 [  76 9957  406  366   14   36   14]
 [  86  483 6041  243   17   17    9]
 [  27   72   97 2381    3    4    0]
 [  31   66   91   77 1346    3    3]
 [  12   79   50   41    2 3072    2]
 [   5   19   19    5    0    0 1324]]

===multilabel confusion matrix===

[[[26359   237]
  [  581  3233]]

 [[18626   915]
  [  912  9957]]

 [[22678   836]
  [  855  6041]]

 [[26919   907]
  [  203  2381]]

 [[28744    49]
  [  271  1346]]

 [[27083    69]
  [  186  3072]]

 [[28995    43]
  [   48  1324]]]

===scores report===
metrics	scores
Accuracy	0.8995
MCC	0.8719
log_loss	0.3221
f1 score weighted	0.9006
f1 score macro	0.9018
f1 score micro	0.8995
roc_auc ovr	0.9878
roc_auc ovo	0.9900
precision	0.9047
recall	0.8995

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8dcc3e0220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8dcc3e0880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8dcc3e08e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8dcc3e0670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.90      0.87      3813
         1.0       0.93      0.90      0.91     10868
         2.0       0.88      0.88      0.88      6897
         3.0       0.92      0.87      0.90      2585
         4.0       0.81      0.90      0.86      1616
         5.0       0.93      0.96      0.95      3258
         6.0       0.98      0.95      0.97      1372

    accuracy                           0.90     30409
   macro avg       0.90      0.91      0.91     30409
weighted avg       0.90      0.90      0.90     30409


===confusion_matrix===

[[3440  118  159   33   35   20    8]
 [ 298 9754  468   84  131  123   10]
 [ 185  374 6103   60  116   57    2]
 [  74   93  114 2261   39    4    0]
 [  20   58   50   14 1461   13    0]
 [  23   38   34    7   17 3139    0]
 [  16   19   17    4    0    6 1310]]

===multilabel confusion matrix===

[[[25980   616]
  [  373  3440]]

 [[18841   700]
  [ 1114  9754]]

 [[22670   842]
  [  794  6103]]

 [[27622   202]
  [  324  2261]]

 [[28455   338]
  [  155  1461]]

 [[26928   223]
  [  119  3139]]

 [[29017    20]
  [   62  1310]]]

===scores report===
metrics	scores
Accuracy	0.9033
MCC	0.8769
log_loss	0.3145
f1 score weighted	0.9036
f1 score macro	0.9058
f1 score micro	0.9033
roc_auc ovr	0.9885
roc_auc ovo	0.9908
precision	0.9048
recall	0.9033

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8dcc3e0220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8dcc3e0880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8dcc3e08e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8dcc3e0670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.88      0.90      3813
         1.0       0.90      0.94      0.92     10868
         2.0       0.90      0.86      0.88      6897
         3.0       0.96      0.86      0.90      2585
         4.0       0.92      0.88      0.90      1616
         5.0       0.89      0.97      0.93      3258
         6.0       0.94      0.96      0.95      1372

    accuracy                           0.91     30409
   macro avg       0.92      0.91      0.91     30409
weighted avg       0.91      0.91      0.91     30409


===confusion_matrix===

[[ 3357   203   151    10    21    52    19]
 [  104 10232   290    37    26   153    26]
 [  114   641  5911    41    48   114    28]
 [   40   177    89  2216    21    37     5]
 [   18   100    48     9  1420    19     2]
 [   14    31    32     4     2  3174     1]
 [    7    28    11     2     0     4  1320]]

===multilabel confusion matrix===

[[[26299   297]
  [  456  3357]]

 [[18361  1180]
  [  636 10232]]

 [[22891   621]
  [  986  5911]]

 [[27721   103]
  [  369  2216]]

 [[28675   118]
  [  196  1420]]

 [[26772   379]
  [   84  3174]]

 [[28956    81]
  [   52  1320]]]

===scores report===
metrics	scores
Accuracy	0.9086
MCC	0.8830
log_loss	0.2974
f1 score weighted	0.9082
f1 score macro	0.9123
f1 score micro	0.9086
roc_auc ovr	0.9893
roc_auc ovo	0.9913
precision	0.9094
recall	0.9086

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8821111476487997	0.8497781851475021	0.36575584836417047	0.881475503872388	0.8940377088802263	0.8821111476487998	0.9842881902006073	0.9867541319729188	0.8895821204791785	0.8821111476487997
1	0.9253535021374548	0.9042562721313102	0.28096908614539723	0.9253039446975947	0.9303005766694847	0.9253535021374548	0.9916804183717812	0.9932080673435689	0.9257245372573023	0.9253535021374548
2	0.8995067412035515	0.8718847983161834	0.3221378073103417	0.9005582477164449	0.901791381212086	0.8995067412035515	0.9878192256560843	0.9899676669804464	0.9047064070744527	0.8995067412035515
3	0.9032852116149824	0.8769433473357633	0.3145375171191259	0.90359427781551	0.9057824530430724	0.9032852116149824	0.9884840373159866	0.9907617884556479	0.9047863055017364	0.9032852116149824
4	0.9086125818014403	0.8829730247043726	0.2973868407755397	0.9081637866800082	0.9123195670066117	0.9086125818014403	0.9893036704326642	0.9913316311679439	0.9094008574762036	0.9086125818014403
mean	0.9037738368812457	0.8771671255270264	0.316157419942915	0.9038191521563892	0.9088463373622963	0.9037738368812457	0.9883151083954248	0.9904046571841052	0.9068400455577749	0.9037738368812457
std	0.01397722697767842	0.017582021735627118	0.028597016270253208	0.014074053037822783	0.012254003258814749	0.013977226977678385	0.0023997113558744997	0.0021148629643365975	0.011574005562853531	0.01397722697767842

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 74362.7350 secs

