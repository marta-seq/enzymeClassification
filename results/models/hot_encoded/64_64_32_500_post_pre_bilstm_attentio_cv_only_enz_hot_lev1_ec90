/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_hot_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fef6031c5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fef6031c790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fef6031c7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fef6031c580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.90      0.90      3813
         1.0       0.91      0.95      0.93     10869
         2.0       0.91      0.87      0.89      6897
         3.0       0.90      0.91      0.90      2585
         4.0       0.95      0.89      0.92      1616
         5.0       0.97      0.96      0.96      3258
         6.0       0.97      0.97      0.97      1372

    accuracy                           0.92     30410
   macro avg       0.93      0.92      0.93     30410
weighted avg       0.92      0.92      0.92     30410


===confusion_matrix===

[[ 3418   192   119    51    10    14     9]
 [  145 10306   277    74    19    39     9]
 [  120   559  6026    97    39    37    19]
 [   36   105    80  2348     5    10     1]
 [   24    65    49    23  1444    11     0]
 [   14    59    36    10     3  3136     0]
 [    9    13    13     4     0     2  1331]]

===multilabel confusion matrix===

[[[26249   348]
  [  395  3418]]

 [[18548   993]
  [  563 10306]]

 [[22939   574]
  [  871  6026]]

 [[27566   259]
  [  237  2348]]

 [[28718    76]
  [  172  1444]]

 [[27039   113]
  [  122  3136]]

 [[29000    38]
  [   41  1331]]]

===scores report===
metrics	scores
Accuracy	0.9210
MCC	0.8988
log_loss	0.2899
f1 score weighted	0.9208
f1 score macro	0.9265
f1 score micro	0.9210
roc_auc ovr	0.9912
roc_auc ovo	0.9928
precision	0.9212
recall	0.9210

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fef6031c5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fef6031c790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fef6031c7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fef6031c580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.89      0.91      3813
         1.0       0.92      0.94      0.93     10869
         2.0       0.92      0.86      0.89      6897
         3.0       0.83      0.92      0.88      2585
         4.0       0.91      0.90      0.91      1616
         5.0       0.96      0.97      0.96      3258
         6.0       0.97      0.97      0.97      1372

    accuracy                           0.92     30410
   macro avg       0.92      0.92      0.92     30410
weighted avg       0.92      0.92      0.92     30410


===confusion_matrix===

[[ 3411   172   111    83    15    15     6]
 [   95 10228   280   161    49    41    15]
 [  126   519  5959   179    54    47    13]
 [   26    92    51  2389    15    11     1]
 [   25    53    50    33  1451     3     1]
 [    9    66    20    13     6  3144     0]
 [    7     9    17     4     0     0  1335]]

===multilabel confusion matrix===

[[[26309   288]
  [  402  3411]]

 [[18630   911]
  [  641 10228]]

 [[22984   529]
  [  938  5959]]

 [[27352   473]
  [  196  2389]]

 [[28655   139]
  [  165  1451]]

 [[27035   117]
  [  114  3144]]

 [[29002    36]
  [   37  1335]]]

===scores report===
metrics	scores
Accuracy	0.9180
MCC	0.8953
log_loss	0.2948
f1 score weighted	0.9179
f1 score macro	0.9212
f1 score micro	0.9180
roc_auc ovr	0.9909
roc_auc ovo	0.9927
precision	0.9188
recall	0.9180

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fef6031c5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fef6031c790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fef6031c7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fef6031c580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.91      0.87      3814
         1.0       0.92      0.92      0.92     10869
         2.0       0.86      0.89      0.87      6896
         3.0       0.93      0.86      0.90      2584
         4.0       0.97      0.84      0.90      1617
         5.0       0.98      0.94      0.96      3258
         6.0       0.97      0.95      0.96      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.90      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3470   148   149    26     5     7     9]
 [  245 10005   506    61    11    24    17]
 [  217   472  6117    51    10    22     7]
 [   77   112   138  2234    13     8     2]
 [   59    76    97    22  1357     4     2]
 [   44    73    81     6     3  3051     0]
 [   15    15    31     0     0     1  1310]]

===multilabel confusion matrix===

[[[25939   657]
  [  344  3470]]

 [[18645   896]
  [  864 10005]]

 [[22512  1002]
  [  779  6117]]

 [[27660   166]
  [  350  2234]]

 [[28751    42]
  [  260  1357]]

 [[27086    66]
  [  207  3051]]

 [[29001    37]
  [   62  1310]]]

===scores report===
metrics	scores
Accuracy	0.9058
MCC	0.8793
log_loss	0.3069
f1 score weighted	0.9061
f1 score macro	0.9119
f1 score micro	0.9058
roc_auc ovr	0.9881
roc_auc ovo	0.9899
precision	0.9078
recall	0.9058

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fef6031c5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fef6031c790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fef6031c7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fef6031c580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.91      0.84      3813
         1.0       0.92      0.90      0.91     10868
         2.0       0.90      0.84      0.87      6897
         3.0       0.97      0.82      0.89      2585
         4.0       0.79      0.90      0.84      1616
         5.0       0.89      0.97      0.93      3258
         6.0       0.98      0.95      0.96      1372

    accuracy                           0.89     30409
   macro avg       0.89      0.90      0.89     30409
weighted avg       0.89      0.89      0.89     30409


===confusion_matrix===

[[3465  168   72   12   45   40   11]
 [ 328 9769  414   37  140  178    2]
 [ 393  412 5775   20  148  137   12]
 [ 128  155  112 2124   46   19    1]
 [  51   62   26    6 1455   14    2]
 [  25   37   28    0   10 3158    0]
 [  24   24   12    0    4    3 1305]]

===multilabel confusion matrix===

[[[25647   949]
  [  348  3465]]

 [[18683   858]
  [ 1099  9769]]

 [[22848   664]
  [ 1122  5775]]

 [[27749    75]
  [  461  2124]]

 [[28400   393]
  [  161  1455]]

 [[26760   391]
  [  100  3158]]

 [[29009    28]
  [   67  1305]]]

===scores report===
metrics	scores
Accuracy	0.8896
MCC	0.8599
log_loss	0.3587
f1 score weighted	0.8900
f1 score macro	0.8912
f1 score micro	0.8896
roc_auc ovr	0.9860
roc_auc ovo	0.9888
precision	0.8938
recall	0.8896

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fef6031c5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fef6031c790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fef6031c7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fef6031c580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.87      0.87      3813
         1.0       0.90      0.92      0.91     10868
         2.0       0.90      0.81      0.85      6897
         3.0       0.78      0.91      0.84      2585
         4.0       0.77      0.89      0.83      1616
         5.0       0.99      0.92      0.95      3258
         6.0       0.98      0.92      0.95      1372

    accuracy                           0.89     30409
   macro avg       0.88      0.89      0.89     30409
weighted avg       0.89      0.89      0.89     30409


===confusion_matrix===

[[3334  191  128   97   53    4    6]
 [ 179 9983  309  238  147    8    4]
 [ 198  680 5604  243  149   12   11]
 [  51   91   72 2345   25    1    0]
 [  28   52   52   44 1440    0    0]
 [  37   87   52   49   42 2991    0]
 [  20   58   18    6    6    1 1263]]

===multilabel confusion matrix===

[[[26083   513]
  [  479  3334]]

 [[18382  1159]
  [  885  9983]]

 [[22881   631]
  [ 1293  5604]]

 [[27147   677]
  [  240  2345]]

 [[28371   422]
  [  176  1440]]

 [[27125    26]
  [  267  2991]]

 [[29016    21]
  [  109  1263]]]

===scores report===
metrics	scores
Accuracy	0.8866
MCC	0.8555
log_loss	0.3508
f1 score weighted	0.8871
f1 score macro	0.8857
f1 score micro	0.8866
roc_auc ovr	0.9858
roc_auc ovo	0.9886
precision	0.8904
recall	0.8866

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9210457086484709	0.8988333579460147	0.2899402496492875	0.9208463652996326	0.9264520132503372	0.9210457086484709	0.9911670618170628	0.992786922108412	0.9211971839034547	0.9210457086484709
1	0.9180203880302532	0.8952563952164919	0.2947885754493122	0.9179443934117666	0.9211909522763151	0.9180203880302532	0.9909274210109055	0.9927182928868312	0.9187913855775015	0.9180203880302532
2	0.9057546859585662	0.8792725065292125	0.3068955777595692	0.9061255101192557	0.9118748737084952	0.9057546859585662	0.988135341590822	0.9899347525842283	0.9077573850616831	0.9057546859585662
3	0.8895721661350258	0.8598804893388344	0.3586873562286531	0.8899823595865353	0.8911654420073071	0.8895721661350258	0.9860227296943622	0.9888282971704045	0.8938452283074193	0.8895721661350258
4	0.8865796310302871	0.8555355943500421	0.3508087074385364	0.8870903898541175	0.8857134849964787	0.8865796310302871	0.9857867841585323	0.9885894531221272	0.8904000306551964	0.8865796310302871
mean	0.9041945159605206	0.8777556686761191	0.3202240933050717	0.9043978036542615	0.9072793532477867	0.9041945159605206	0.988407867654337	0.9905715435744007	0.906398242701051	0.9041945159605206
std	0.014153789947871618	0.01769801656044108	0.028832506995496682	0.013888137700988255	0.01616778956015677	0.014153789947871618	0.0023062755160476087	0.001837907941687131	0.012553620020182519	0.014153789947871618

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 62115.9455 secs

