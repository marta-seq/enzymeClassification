/home/amsequeira/enzymeClassification/models/hot_encoded/bi_attetion_500_post_post_lev3_ec90_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f35504491f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f35504493d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3550449430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3550449190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.94      0.89       825
         1.0       0.44      0.29      0.35        14
         2.0       0.54      0.84      0.66        31
         3.0       1.00      0.09      0.17        11
         4.0       0.95      0.69      0.80        52
         5.0       0.85      0.75      0.80       176
         6.0       0.70      0.57      0.63       102
         7.0       0.70      0.36      0.48        97
         8.0       1.00      0.21      0.35        14
         9.0       0.65      0.43      0.52        70
        10.0       0.84      0.74      0.79       104
        11.0       1.00      0.11      0.20        18
        12.0       0.43      0.21      0.29        14
        13.0       0.72      0.72      0.72        43
        14.0       0.95      0.53      0.68        34
        15.0       0.98      0.81      0.89        64
        16.0       1.00      0.08      0.14        13
        17.0       1.00      0.42      0.59        19
        18.0       1.00      0.88      0.93        72
        19.0       1.00      0.30      0.46        30
        20.0       1.00      0.93      0.96        94
        21.0       0.67      0.80      0.73        46
        22.0       0.91      0.80      0.85        25
        23.0       1.00      0.90      0.95       345
        24.0       0.36      0.53      0.43        30
        25.0       0.67      0.20      0.31        20
        26.0       0.78      0.72      0.75       167
        27.0       0.80      0.78      0.79        36
        28.0       0.96      0.77      0.85        61
        29.0       0.93      0.81      0.86        63
        30.0       1.00      0.27      0.43        11
        31.0       0.00      0.00      0.00        11
        32.0       0.59      0.25      0.35        40
        33.0       0.83      0.71      0.76        73
        34.0       1.00      0.96      0.98        57
        35.0       0.88      0.93      0.90        15
        36.0       0.48      0.26      0.34        50
        37.0       0.93      0.74      0.82        19
        38.0       0.88      0.72      0.79        29
        39.0       0.89      0.95      0.92       101
        40.0       1.00      0.67      0.80        12
        41.0       1.00      1.00      1.00        14
        42.0       0.96      0.69      0.80        67
        43.0       0.90      0.82      0.86        76
        44.0       0.85      1.00      0.92        11
        45.0       0.97      0.89      0.93        37
        46.0       0.78      0.93      0.85      1613
        47.0       0.94      0.98      0.96       299
        48.0       1.00      0.97      0.98       244
        49.0       0.81      0.97      0.88       168
        50.0       0.79      0.83      0.81      1024
        51.0       0.77      0.75      0.76       353
        52.0       0.94      0.77      0.85        86
        53.0       0.73      0.84      0.78       607
        54.0       0.86      0.91      0.88       543
        55.0       1.00      0.86      0.92        78
        56.0       0.94      0.89      0.91       954
        57.0       0.77      0.93      0.84       247
        58.0       1.00      0.97      0.99        34
        59.0       0.82      0.86      0.84       877
        60.0       0.81      0.34      0.48        77
        61.0       0.80      0.85      0.82       566
        62.0       0.00      0.00      0.00        24
        63.0       0.78      0.33      0.46        55
        64.0       0.94      0.97      0.95       254
        65.0       1.00      0.29      0.44        14
        66.0       0.95      0.95      0.95       456
        67.0       0.90      0.68      0.78        38
        68.0       0.84      0.86      0.85      1189
        69.0       0.88      0.79      0.83       224
        70.0       0.90      0.47      0.62        19
        71.0       0.96      0.94      0.95       358
        72.0       1.00      0.47      0.64        32
        73.0       0.00      0.00      0.00        13
        74.0       0.99      0.97      0.98       127
        75.0       1.00      0.92      0.96        12
        76.0       0.47      0.91      0.62       460
        77.0       0.91      0.87      0.89       103
        78.0       0.72      0.25      0.37        52
        79.0       0.76      0.61      0.68        83
        80.0       0.79      0.42      0.55        80
        81.0       1.00      0.83      0.91        84
        82.0       0.82      0.90      0.86       335
        83.0       0.76      0.57      0.65        23
        84.0       0.78      0.73      0.75       518
        85.0       0.57      0.05      0.09        87
        86.0       1.00      0.46      0.63        13
        87.0       0.54      0.78      0.64       480
        88.0       0.70      0.64      0.67       126
        89.0       1.00      0.96      0.98        25
        90.0       0.93      0.76      0.84       152
        91.0       0.50      0.15      0.23        20
        92.0       0.41      0.25      0.31        28
        93.0       0.89      0.74      0.81        42
        94.0       0.50      0.09      0.15        34
        95.0       0.92      0.34      0.50        99
        96.0       0.90      0.80      0.85       415
        97.0       0.94      0.57      0.71       118
        98.0       0.96      0.67      0.79        99
        99.0       0.95      0.68      0.79       253
       100.0       0.96      0.94      0.95       116
       101.0       0.66      0.81      0.73       423
       102.0       0.89      0.76      0.82        99
       103.0       0.83      0.80      0.81        60
       104.0       0.97      0.74      0.84       266
       105.0       0.91      0.84      0.87        37
       106.0       0.92      0.86      0.89       494
       107.0       1.00      0.43      0.60        14
       108.0       0.87      0.89      0.88       610
       109.0       0.97      0.93      0.95       206
       110.0       0.48      0.45      0.47        22
       111.0       0.73      0.92      0.81       534
       112.0       0.55      0.73      0.63        98
       113.0       0.81      0.79      0.80        86
       114.0       0.98      0.90      0.94       109
       115.0       0.95      0.88      0.91       858
       116.0       0.56      0.51      0.53        61
       117.0       0.96      0.91      0.93       209
       118.0       0.00      0.00      0.00        13
       119.0       0.90      0.69      0.78        65
       120.0       0.99      0.96      0.97       156
       121.0       0.89      0.94      0.91        84
       122.0       0.72      0.51      0.60        55
       123.0       0.94      0.66      0.78       154
       124.0       0.98      0.88      0.93        52
       125.0       0.88      0.88      0.88       147
       126.0       0.84      0.62      0.72        77
       127.0       0.94      0.84      0.89        19
       128.0       0.96      0.83      0.89       198
       129.0       0.90      0.93      0.91       450
       130.0       1.00      0.82      0.90        11
       131.0       0.47      0.49      0.48        43
       132.0       0.92      0.69      0.79        16
       133.0       0.88      0.98      0.92       204
       134.0       0.97      0.93      0.95        76
       135.0       0.94      0.78      0.85       255
       136.0       0.75      0.15      0.25        20
       137.0       1.00      0.69      0.82        13
       138.0       0.84      0.72      0.77        67
       139.0       0.96      0.98      0.97      1464
       140.0       0.84      0.90      0.87       146
       141.0       0.92      0.90      0.91        99
       142.0       0.96      0.91      0.94       455
       143.0       0.99      0.93      0.96        82
       144.0       0.92      0.98      0.95       411
       145.0       0.92      0.95      0.94       406
       146.0       1.00      0.17      0.29        12
       147.0       0.96      0.86      0.91       149
       148.0       0.96      0.95      0.96       703
       149.0       0.99      0.95      0.97       195
       150.0       1.00      0.64      0.78        33
       151.0       0.94      0.65      0.77        68
       152.0       0.97      0.77      0.86        93
       153.0       1.00      0.85      0.92        33
       154.0       0.89      0.86      0.88        49
       155.0       0.73      0.94      0.82       154

    accuracy                           0.85     28656
   macro avg       0.83      0.69      0.73     28656
weighted avg       0.86      0.85      0.84     28656


===confusion_matrix===

[[773   1   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0  26 ...   0   0   0]
 ...
 [  0   0   0 ...  28   1   3]
 [  0   0   0 ...   0  42   6]
 [  0   0   0 ...   0   2 145]]

===multilabel confusion matrix===

[[[27695   136]
  [   52   773]]

 [[28637     5]
  [   10     4]]

 [[28603    22]
  [    5    26]]

 [[28645     0]
  [   10     1]]

 [[28602     2]
  [   16    36]]

 [[28457    23]
  [   44   132]]

 [[28529    25]
  [   44    58]]

 [[28544    15]
  [   62    35]]

 [[28642     0]
  [   11     3]]

 [[28570    16]
  [   40    30]]

 [[28537    15]
  [   27    77]]

 [[28638     0]
  [   16     2]]

 [[28638     4]
  [   11     3]]

 [[28601    12]
  [   12    31]]

 [[28621     1]
  [   16    18]]

 [[28591     1]
  [   12    52]]

 [[28643     0]
  [   12     1]]

 [[28637     0]
  [   11     8]]

 [[28584     0]
  [    9    63]]

 [[28626     0]
  [   21     9]]

 [[28562     0]
  [    7    87]]

 [[28592    18]
  [    9    37]]

 [[28629     2]
  [    5    20]]

 [[28310     1]
  [   33   312]]

 [[28597    29]
  [   14    16]]

 [[28634     2]
  [   16     4]]

 [[28456    33]
  [   47   120]]

 [[28613     7]
  [    8    28]]

 [[28593     2]
  [   14    47]]

 [[28589     4]
  [   12    51]]

 [[28645     0]
  [    8     3]]

 [[28645     0]
  [   11     0]]

 [[28609     7]
  [   30    10]]

 [[28572    11]
  [   21    52]]

 [[28599     0]
  [    2    55]]

 [[28639     2]
  [    1    14]]

 [[28592    14]
  [   37    13]]

 [[28636     1]
  [    5    14]]

 [[28624     3]
  [    8    21]]

 [[28543    12]
  [    5    96]]

 [[28644     0]
  [    4     8]]

 [[28642     0]
  [    0    14]]

 [[28587     2]
  [   21    46]]

 [[28573     7]
  [   14    62]]

 [[28643     2]
  [    0    11]]

 [[28618     1]
  [    4    33]]

 [[26627   416]
  [  107  1506]]

 [[28339    18]
  [    6   293]]

 [[28411     1]
  [    7   237]]

 [[28449    39]
  [    5   163]]

 [[27412   220]
  [  176   848]]

 [[28226    77]
  [   90   263]]

 [[28566     4]
  [   20    66]]

 [[27863   186]
  [  100   507]]

 [[28031    82]
  [   47   496]]

 [[28578     0]
  [   11    67]]

 [[27648    54]
  [  106   848]]

 [[28339    70]
  [   17   230]]

 [[28622     0]
  [    1    33]]

 [[27619   160]
  [  127   750]]

 [[28573     6]
  [   51    26]]

 [[27972   118]
  [   87   479]]

 [[28632     0]
  [   24     0]]

 [[28596     5]
  [   37    18]]

 [[28385    17]
  [    7   247]]

 [[28642     0]
  [   10     4]]

 [[28178    22]
  [   24   432]]

 [[28615     3]
  [   12    26]]

 [[27272   195]
  [  165  1024]]

 [[28408    24]
  [   47   177]]

 [[28636     1]
  [   10     9]]

 [[28283    15]
  [   20   338]]

 [[28624     0]
  [   17    15]]

 [[28642     1]
  [   13     0]]

 [[28528     1]
  [    4   123]]

 [[28644     0]
  [    1    11]]

 [[27730   466]
  [   43   417]]

 [[28544     9]
  [   13    90]]

 [[28599     5]
  [   39    13]]

 [[28557    16]
  [   32    51]]

 [[28567     9]
  [   46    34]]

 [[28572     0]
  [   14    70]]

 [[28257    64]
  [   35   300]]

 [[28629     4]
  [   10    13]]

 [[28031   107]
  [  142   376]]

 [[28566     3]
  [   83     4]]

 [[28643     0]
  [    7     6]]

 [[27850   326]
  [  104   376]]

 [[28496    34]
  [   45    81]]

 [[28631     0]
  [    1    24]]

 [[28495     9]
  [   36   116]]

 [[28633     3]
  [   17     3]]

 [[28618    10]
  [   21     7]]

 [[28610     4]
  [   11    31]]

 [[28619     3]
  [   31     3]]

 [[28554     3]
  [   65    34]]

 [[28206    35]
  [   84   331]]

 [[28534     4]
  [   51    67]]

 [[28554     3]
  [   33    66]]

 [[28393    10]
  [   80   173]]

 [[28536     4]
  [    7   109]]

 [[28059   174]
  [   79   344]]

 [[28548     9]
  [   24    75]]

 [[28586    10]
  [   12    48]]

 [[28384     6]
  [   68   198]]

 [[28616     3]
  [    6    31]]

 [[28125    37]
  [   68   426]]

 [[28642     0]
  [    8     6]]

 [[27964    82]
  [   66   544]]

 [[28445     5]
  [   14   192]]

 [[28623    11]
  [   12    10]]

 [[27939   183]
  [   41   493]]

 [[28498    60]
  [   26    72]]

 [[28554    16]
  [   18    68]]

 [[28545     2]
  [   11    98]]

 [[27757    41]
  [  106   752]]

 [[28571    24]
  [   30    31]]

 [[28439     8]
  [   19   190]]

 [[28643     0]
  [   13     0]]

 [[28586     5]
  [   20    45]]

 [[28498     2]
  [    7   149]]

 [[28562    10]
  [    5    79]]

 [[28590    11]
  [   27    28]]

 [[28496     6]
  [   52   102]]

 [[28603     1]
  [    6    46]]

 [[28491    18]
  [   17   130]]

 [[28570     9]
  [   29    48]]

 [[28636     1]
  [    3    16]]

 [[28452     6]
  [   34   164]]

 [[28159    47]
  [   31   419]]

 [[28645     0]
  [    2     9]]

 [[28589    24]
  [   22    21]]

 [[28639     1]
  [    5    11]]

 [[28424    28]
  [    5   199]]

 [[28578     2]
  [    5    71]]

 [[28389    12]
  [   56   199]]

 [[28635     1]
  [   17     3]]

 [[28643     0]
  [    4     9]]

 [[28580     9]
  [   19    48]]

 [[27131    61]
  [   28  1436]]

 [[28485    25]
  [   15   131]]

 [[28549     8]
  [   10    89]]

 [[28185    16]
  [   40   415]]

 [[28573     1]
  [    6    76]]

 [[28209    36]
  [    7   404]]

 [[28218    32]
  [   19   387]]

 [[28644     0]
  [   10     2]]

 [[28502     5]
  [   21   128]]

 [[27928    25]
  [   35   668]]

 [[28459     2]
  [    9   186]]

 [[28623     0]
  [   12    21]]

 [[28585     3]
  [   24    44]]

 [[28561     2]
  [   21    72]]

 [[28623     0]
  [    5    28]]

 [[28602     5]
  [    7    42]]

 [[28449    53]
  [    9   145]]]

===scores report===
metrics	scores
Accuracy	0.8450
MCC	0.8419
log_loss	0.7124
f1 score weighted	0.8412
f1 score macro	0.7288
f1 score micro	0.8450
roc_auc ovr	0.9939
roc_auc ovo	0.9913
precision	0.8555
recall	0.8450

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f35504491f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f35504493d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3550449430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3550449190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([56., 56., 56., ..., 98., 51., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.90      0.88       825
         1.0       1.00      0.29      0.44        14
         2.0       0.77      0.77      0.77        31
         3.0       1.00      0.08      0.15        12
         4.0       0.98      0.77      0.86        52
         5.0       0.87      0.85      0.86       176
         6.0       0.47      0.61      0.53       102
         7.0       0.48      0.44      0.46        97
         8.0       0.71      0.36      0.48        14
         9.0       0.55      0.44      0.49        70
        10.0       0.65      0.82      0.72       104
        11.0       0.00      0.00      0.00        18
        12.0       0.75      0.21      0.33        14
        13.0       0.75      0.50      0.60        42
        14.0       0.70      0.68      0.69        34
        15.0       0.90      0.81      0.85        64
        16.0       0.33      0.07      0.12        14
        17.0       0.91      0.53      0.67        19
        18.0       0.97      0.86      0.91        72
        19.0       0.39      0.52      0.44        31
        20.0       1.00      0.99      0.99        94
        21.0       0.67      0.87      0.76        45
        22.0       1.00      0.80      0.89        25
        23.0       0.98      0.95      0.96       346
        24.0       0.94      0.50      0.65        30
        25.0       1.00      0.16      0.27        19
        26.0       0.81      0.62      0.71       167
        27.0       0.83      0.67      0.74        36
        28.0       0.97      0.93      0.95        60
        29.0       0.90      0.60      0.72        62
        30.0       0.86      0.55      0.67        11
        31.0       0.20      0.09      0.13        11
        32.0       1.00      0.33      0.49        40
        33.0       0.83      0.70      0.76        74
        34.0       0.96      0.98      0.97        56
        35.0       1.00      0.88      0.93        16
        36.0       0.41      0.18      0.25        51
        37.0       0.88      0.74      0.80        19
        38.0       1.00      0.55      0.71        29
        39.0       0.95      0.90      0.92       101
        40.0       1.00      0.75      0.86        12
        41.0       0.76      1.00      0.87        13
        42.0       0.74      0.93      0.82        67
        43.0       0.96      0.91      0.93        76
        44.0       1.00      1.00      1.00        12
        45.0       1.00      0.83      0.91        36
        46.0       0.91      0.91      0.91      1613
        47.0       0.97      0.98      0.97       299
        48.0       1.00      0.98      0.99       243
        49.0       0.93      0.96      0.94       169
        50.0       0.76      0.82      0.79      1024
        51.0       0.62      0.80      0.70       352
        52.0       0.94      0.88      0.91        86
        53.0       0.64      0.84      0.73       607
        54.0       0.91      0.91      0.91       543
        55.0       1.00      0.85      0.92        78
        56.0       0.86      0.90      0.88       954
        57.0       0.93      0.89      0.91       247
        58.0       0.94      1.00      0.97        34
        59.0       0.82      0.88      0.85       877
        60.0       0.63      0.43      0.51        77
        61.0       0.67      0.91      0.77       565
        62.0       0.86      0.25      0.39        24
        63.0       0.49      0.64      0.55        55
        64.0       0.98      0.96      0.97       255
        65.0       1.00      0.36      0.53        14
        66.0       0.96      0.93      0.95       457
        67.0       1.00      0.62      0.77        37
        68.0       0.95      0.80      0.87      1189
        69.0       0.95      0.84      0.89       224
        70.0       0.88      0.70      0.78        20
        71.0       0.94      0.95      0.95       358
        72.0       1.00      0.50      0.67        32
        73.0       1.00      0.23      0.38        13
        74.0       0.99      0.95      0.97       128
        75.0       1.00      0.92      0.96        13
        76.0       0.88      0.75      0.81       460
        77.0       0.95      0.83      0.88       104
        78.0       0.34      0.42      0.38        52
        79.0       0.84      0.51      0.64        84
        80.0       0.70      0.44      0.54        80
        81.0       0.96      0.80      0.87        83
        82.0       0.88      0.90      0.89       335
        83.0       1.00      0.38      0.55        24
        84.0       0.71      0.77      0.74       518
        85.0       0.22      0.11      0.15        88
        86.0       0.80      0.92      0.86        13
        87.0       0.60      0.80      0.68       480
        88.0       0.81      0.63      0.71       126
        89.0       1.00      1.00      1.00        25
        90.0       0.65      0.91      0.76       153
        91.0       0.86      0.30      0.44        20
        92.0       0.40      0.37      0.38        27
        93.0       0.73      0.71      0.72        42
        94.0       0.55      0.35      0.43        34
        95.0       0.56      0.66      0.60        99
        96.0       0.82      0.83      0.82       416
        97.0       0.74      0.59      0.66       118
        98.0       0.95      0.78      0.86        99
        99.0       0.84      0.77      0.81       253
       100.0       0.94      0.96      0.95       115
       101.0       0.82      0.78      0.80       423
       102.0       0.84      0.87      0.86        99
       103.0       0.81      0.70      0.75        61
       104.0       0.73      0.90      0.81       266
       105.0       0.91      0.83      0.87        36
       106.0       0.94      0.79      0.86       494
       107.0       0.90      0.64      0.75        14
       108.0       0.87      0.90      0.88       610
       109.0       0.97      0.98      0.97       206
       110.0       1.00      0.50      0.67        22
       111.0       0.95      0.87      0.91       535
       112.0       0.69      0.72      0.71        98
       113.0       0.82      0.55      0.66        86
       114.0       0.95      0.90      0.92       109
       115.0       0.76      0.93      0.84       858
       116.0       0.87      0.33      0.48        61
       117.0       0.88      0.87      0.88       208
       118.0       0.50      0.08      0.13        13
       119.0       0.77      0.85      0.81        65
       120.0       0.89      0.92      0.91       157
       121.0       0.87      0.99      0.93        84
       122.0       0.78      0.56      0.65        55
       123.0       0.76      0.69      0.73       154
       124.0       0.98      0.92      0.95        52
       125.0       0.96      0.90      0.93       147
       126.0       0.86      0.57      0.69        77
       127.0       1.00      0.72      0.84        18
       128.0       0.84      0.88      0.86       197
       129.0       0.94      0.94      0.94       449
       130.0       1.00      0.73      0.84        11
       131.0       0.72      0.53      0.61        43
       132.0       0.92      0.73      0.81        15
       133.0       0.98      0.98      0.98       204
       134.0       0.99      0.97      0.98        76
       135.0       0.96      0.87      0.91       255
       136.0       0.57      0.42      0.48        19
       137.0       1.00      0.54      0.70        13
       138.0       0.78      0.67      0.72        67
       139.0       0.95      1.00      0.97      1463
       140.0       0.88      0.86      0.87       147
       141.0       0.97      0.86      0.91        99
       142.0       0.94      0.92      0.93       455
       143.0       1.00      0.94      0.97        82
       144.0       0.98      0.93      0.95       410
       145.0       0.96      0.97      0.96       406
       146.0       0.75      0.25      0.38        12
       147.0       0.88      0.92      0.90       149
       148.0       0.97      0.97      0.97       702
       149.0       0.98      0.95      0.97       196
       150.0       0.95      0.66      0.78        32
       151.0       0.85      0.74      0.79        69
       152.0       0.94      0.96      0.95        93
       153.0       0.88      0.88      0.88        32
       154.0       0.87      0.92      0.89        49
       155.0       0.94      0.88      0.91       154

    accuracy                           0.85     28655
   macro avg       0.84      0.72      0.75     28655
weighted avg       0.86      0.85      0.85     28655


===confusion_matrix===

[[744   0   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0  24 ...   0   0   0]
 ...
 [  0   0   0 ...  28   0   0]
 [  0   0   0 ...   1  45   1]
 [  0   0   0 ...   1   5 135]]

===multilabel confusion matrix===

[[[27716   114]
  [   81   744]]

 [[28641     0]
  [   10     4]]

 [[28617     7]
  [    7    24]]

 [[28643     0]
  [   11     1]]

 [[28602     1]
  [   12    40]]

 [[28456    23]
  [   27   149]]

 [[28484    69]
  [   40    62]]

 [[28511    47]
  [   54    43]]

 [[28639     2]
  [    9     5]]

 [[28560    25]
  [   39    31]]

 [[28505    46]
  [   19    85]]

 [[28637     0]
  [   18     0]]

 [[28640     1]
  [   11     3]]

 [[28606     7]
  [   21    21]]

 [[28611    10]
  [   11    23]]

 [[28585     6]
  [   12    52]]

 [[28639     2]
  [   13     1]]

 [[28635     1]
  [    9    10]]

 [[28581     2]
  [   10    62]]

 [[28599    25]
  [   15    16]]

 [[28561     0]
  [    1    93]]

 [[28591    19]
  [    6    39]]

 [[28630     0]
  [    5    20]]

 [[28301     8]
  [   17   329]]

 [[28624     1]
  [   15    15]]

 [[28636     0]
  [   16     3]]

 [[28464    24]
  [   63   104]]

 [[28614     5]
  [   12    24]]

 [[28593     2]
  [    4    56]]

 [[28589     4]
  [   25    37]]

 [[28643     1]
  [    5     6]]

 [[28640     4]
  [   10     1]]

 [[28615     0]
  [   27    13]]

 [[28570    11]
  [   22    52]]

 [[28597     2]
  [    1    55]]

 [[28639     0]
  [    2    14]]

 [[28591    13]
  [   42     9]]

 [[28634     2]
  [    5    14]]

 [[28626     0]
  [   13    16]]

 [[28549     5]
  [   10    91]]

 [[28643     0]
  [    3     9]]

 [[28638     4]
  [    0    13]]

 [[28566    22]
  [    5    62]]

 [[28576     3]
  [    7    69]]

 [[28643     0]
  [    0    12]]

 [[28619     0]
  [    6    30]]

 [[26902   140]
  [  139  1474]]

 [[28348     8]
  [    7   292]]

 [[28411     1]
  [    5   238]]

 [[28474    12]
  [    7   162]]

 [[27362   269]
  [  185   839]]

 [[28132   171]
  [   70   282]]

 [[28564     5]
  [   10    76]]

 [[27760   288]
  [   98   509]]

 [[28061    51]
  [   49   494]]

 [[28577     0]
  [   12    66]]

 [[27559   142]
  [   97   857]]

 [[28391    17]
  [   27   220]]

 [[28619     2]
  [    0    34]]

 [[27608   170]
  [  106   771]]

 [[28559    19]
  [   44    33]]

 [[27842   248]
  [   53   512]]

 [[28630     1]
  [   18     6]]

 [[28563    37]
  [   20    35]]

 [[28396     4]
  [   11   244]]

 [[28641     0]
  [    9     5]]

 [[28182    16]
  [   30   427]]

 [[28618     0]
  [   14    23]]

 [[27419    47]
  [  234   955]]

 [[28421    10]
  [   36   188]]

 [[28633     2]
  [    6    14]]

 [[28277    20]
  [   18   340]]

 [[28623     0]
  [   16    16]]

 [[28642     0]
  [   10     3]]

 [[28526     1]
  [    6   122]]

 [[28642     0]
  [    1    12]]

 [[28148    47]
  [  113   347]]

 [[28546     5]
  [   18    86]]

 [[28561    42]
  [   30    22]]

 [[28563     8]
  [   41    43]]

 [[28560    15]
  [   45    35]]

 [[28569     3]
  [   17    66]]

 [[28279    41]
  [   35   300]]

 [[28631     0]
  [   15     9]]

 [[27975   162]
  [  121   397]]

 [[28532    35]
  [   78    10]]

 [[28639     3]
  [    1    12]]

 [[27915   260]
  [   97   383]]

 [[28510    19]
  [   47    79]]

 [[28630     0]
  [    0    25]]

 [[28428    74]
  [   14   139]]

 [[28634     1]
  [   14     6]]

 [[28613    15]
  [   17    10]]

 [[28602    11]
  [   12    30]]

 [[28611    10]
  [   22    12]]

 [[28504    52]
  [   34    65]]

 [[28161    78]
  [   72   344]]

 [[28512    25]
  [   48    70]]

 [[28552     4]
  [   22    77]]

 [[28366    36]
  [   57   196]]

 [[28533     7]
  [    5   110]]

 [[28161    71]
  [   93   330]]

 [[28540    16]
  [   13    86]]

 [[28584    10]
  [   18    43]]

 [[28302    87]
  [   27   239]]

 [[28616     3]
  [    6    30]]

 [[28134    27]
  [  104   390]]

 [[28640     1]
  [    5     9]]

 [[27960    85]
  [   61   549]]

 [[28442     7]
  [    5   201]]

 [[28633     0]
  [   11    11]]

 [[28095    25]
  [   69   466]]

 [[28525    32]
  [   27    71]]

 [[28559    10]
  [   39    47]]

 [[28541     5]
  [   11    98]]

 [[27551   246]
  [   61   797]]

 [[28591     3]
  [   41    20]]

 [[28423    24]
  [   27   181]]

 [[28641     1]
  [   12     1]]

 [[28574    16]
  [   10    55]]

 [[28480    18]
  [   12   145]]

 [[28559    12]
  [    1    83]]

 [[28591     9]
  [   24    31]]

 [[28468    33]
  [   47   107]]

 [[28602     1]
  [    4    48]]

 [[28503     5]
  [   14   133]]

 [[28571     7]
  [   33    44]]

 [[28637     0]
  [    5    13]]

 [[28426    32]
  [   24   173]]

 [[28180    26]
  [   25   424]]

 [[28644     0]
  [    3     8]]

 [[28603     9]
  [   20    23]]

 [[28639     1]
  [    4    11]]

 [[28447     4]
  [    5   199]]

 [[28578     1]
  [    2    74]]

 [[28391     9]
  [   34   221]]

 [[28630     6]
  [   11     8]]

 [[28642     0]
  [    6     7]]

 [[28575    13]
  [   22    45]]

 [[27114    78]
  [    7  1456]]

 [[28490    18]
  [   20   127]]

 [[28553     3]
  [   14    85]]

 [[28175    25]
  [   37   418]]

 [[28573     0]
  [    5    77]]

 [[28238     7]
  [   30   380]]

 [[28232    17]
  [   14   392]]

 [[28642     1]
  [    9     3]]

 [[28487    19]
  [   12   137]]

 [[27929    24]
  [   21   681]]

 [[28455     4]
  [    9   187]]

 [[28622     1]
  [   11    21]]

 [[28577     9]
  [   18    51]]

 [[28556     6]
  [    4    89]]

 [[28619     4]
  [    4    28]]

 [[28599     7]
  [    4    45]]

 [[28493     8]
  [   19   135]]]

===scores report===
metrics	scores
Accuracy	0.8521
MCC	0.8491
log_loss	0.6824
f1 score weighted	0.8500
f1 score macro	0.7519
f1 score micro	0.8521
roc_auc ovr	0.9938
roc_auc ovo	0.9912
precision	0.8595
recall	0.8521

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f35504491f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f35504493d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3550449430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3550449190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  51.,  96., 109.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.89      0.88       825
         1.0       1.00      0.07      0.13        14
         2.0       0.89      0.78      0.83        32
         3.0       0.00      0.00      0.00        12
         4.0       0.90      0.71      0.80        52
         5.0       0.91      0.79      0.84       176
         6.0       0.77      0.48      0.59       102
         7.0       0.44      0.28      0.34        97
         8.0       0.80      0.29      0.42        14
         9.0       0.70      0.54      0.61        69
        10.0       0.72      0.69      0.71       104
        11.0       0.25      0.06      0.09        18
        12.0       0.67      0.27      0.38        15
        13.0       0.96      0.62      0.75        42
        14.0       0.70      0.56      0.62        34
        15.0       0.79      0.83      0.81        64
        16.0       1.00      0.23      0.38        13
        17.0       1.00      0.37      0.54        19
        18.0       0.88      0.90      0.89        71
        19.0       0.83      0.16      0.27        31
        20.0       1.00      0.95      0.97        94
        21.0       0.78      0.87      0.82        46
        22.0       1.00      0.76      0.86        25
        23.0       0.94      0.95      0.94       346
        24.0       0.89      0.52      0.65        31
        25.0       0.00      0.00      0.00        20
        26.0       0.75      0.60      0.67       167
        27.0       1.00      0.56      0.71        36
        28.0       0.83      0.97      0.89        60
        29.0       0.96      0.79      0.87        62
        30.0       1.00      0.64      0.78        11
        31.0       0.00      0.00      0.00        12
        32.0       0.57      0.30      0.39        40
        33.0       0.84      0.78      0.81        74
        34.0       1.00      1.00      1.00        56
        35.0       0.87      0.81      0.84        16
        36.0       0.25      0.06      0.10        51
        37.0       0.76      0.84      0.80        19
        38.0       0.79      0.76      0.77        29
        39.0       0.97      0.87      0.92       101
        40.0       1.00      0.33      0.50        12
        41.0       0.93      1.00      0.96        13
        42.0       0.71      0.88      0.79        67
        43.0       0.98      0.82      0.89        76
        44.0       0.92      1.00      0.96        11
        45.0       0.97      0.76      0.85        37
        46.0       0.75      0.94      0.83      1613
        47.0       0.97      0.96      0.96       299
        48.0       0.98      0.96      0.97       243
        49.0       0.97      0.96      0.96       169
        50.0       0.83      0.85      0.84      1023
        51.0       0.52      0.84      0.64       352
        52.0       0.84      0.81      0.83        86
        53.0       0.73      0.81      0.77       606
        54.0       0.93      0.90      0.91       543
        55.0       0.98      0.82      0.90        79
        56.0       0.92      0.91      0.92       954
        57.0       0.92      0.90      0.91       247
        58.0       1.00      0.94      0.97        34
        59.0       0.79      0.87      0.83       877
        60.0       0.81      0.34      0.48        77
        61.0       0.78      0.80      0.79       566
        62.0       0.00      0.00      0.00        24
        63.0       0.78      0.65      0.71        55
        64.0       0.98      0.95      0.96       255
        65.0       0.45      0.38      0.42        13
        66.0       0.92      0.97      0.94       457
        67.0       1.00      0.70      0.83        37
        68.0       0.72      0.90      0.80      1189
        69.0       0.91      0.87      0.89       223
        70.0       0.62      0.26      0.37        19
        71.0       0.90      0.97      0.94       357
        72.0       0.89      0.53      0.67        32
        73.0       1.00      0.08      0.14        13
        74.0       0.95      0.96      0.95       128
        75.0       1.00      0.92      0.96        13
        76.0       0.61      0.82      0.70       460
        77.0       0.96      0.79      0.87       104
        78.0       0.81      0.32      0.46        53
        79.0       0.65      0.61      0.63        83
        80.0       0.61      0.54      0.58        79
        81.0       0.97      0.80      0.88        84
        82.0       0.94      0.85      0.89       334
        83.0       0.75      0.38      0.50        24
        84.0       0.78      0.69      0.73       518
        85.0       0.14      0.05      0.07        88
        86.0       0.83      0.38      0.53        13
        87.0       0.69      0.70      0.69       480
        88.0       0.75      0.72      0.74       127
        89.0       0.96      0.96      0.96        24
        90.0       0.85      0.76      0.80       153
        91.0       0.86      0.30      0.44        20
        92.0       0.71      0.19      0.29        27
        93.0       0.92      0.83      0.88        42
        94.0       0.50      0.24      0.32        34
        95.0       0.58      0.35      0.44        99
        96.0       0.85      0.81      0.83       416
        97.0       0.78      0.68      0.73       118
        98.0       0.97      0.64      0.77        99
        99.0       0.67      0.77      0.72       253
       100.0       0.97      0.97      0.97       115
       101.0       0.82      0.74      0.78       423
       102.0       0.94      0.74      0.83        98
       103.0       0.89      0.67      0.76        60
       104.0       0.93      0.80      0.86       265
       105.0       1.00      0.92      0.96        36
       106.0       0.92      0.83      0.87       495
       107.0       0.92      0.86      0.89        14
       108.0       0.84      0.89      0.86       610
       109.0       1.00      0.90      0.95       206
       110.0       1.00      0.14      0.24        22
       111.0       0.92      0.85      0.88       535
       112.0       0.89      0.64      0.75        98
       113.0       0.54      0.43      0.48        86
       114.0       0.88      0.89      0.89       110
       115.0       0.90      0.86      0.88       858
       116.0       1.00      0.28      0.44        61
       117.0       0.82      0.91      0.86       208
       118.0       0.00      0.00      0.00        13
       119.0       0.93      0.58      0.71        66
       120.0       0.93      0.92      0.93       157
       121.0       0.99      1.00      0.99        84
       122.0       0.83      0.64      0.72        55
       123.0       0.87      0.65      0.75       153
       124.0       0.98      0.94      0.96        52
       125.0       0.93      0.93      0.93       147
       126.0       0.82      0.62      0.71        76
       127.0       0.93      0.78      0.85        18
       128.0       0.85      0.83      0.84       197
       129.0       0.98      0.89      0.93       450
       130.0       0.82      0.75      0.78        12
       131.0       0.86      0.57      0.69        42
       132.0       1.00      0.93      0.97        15
       133.0       0.98      0.97      0.97       204
       134.0       0.91      0.95      0.93        76
       135.0       0.79      0.86      0.82       256
       136.0       0.89      0.42      0.57        19
       137.0       0.83      0.77      0.80        13
       138.0       0.72      0.61      0.66        67
       139.0       0.86      0.99      0.92      1464
       140.0       0.96      0.92      0.94       147
       141.0       0.89      0.87      0.88        98
       142.0       0.99      0.92      0.95       455
       143.0       1.00      0.94      0.97        82
       144.0       0.97      0.94      0.96       410
       145.0       0.93      0.95      0.94       406
       146.0       0.67      0.17      0.27        12
       147.0       0.85      0.90      0.87       149
       148.0       0.94      0.96      0.95       702
       149.0       0.98      0.97      0.98       196
       150.0       1.00      0.81      0.90        32
       151.0       0.96      0.74      0.84        69
       152.0       0.91      0.94      0.92        93
       153.0       1.00      0.85      0.92        33
       154.0       0.90      0.94      0.92        50
       155.0       0.85      0.95      0.90       154

    accuracy                           0.84     28655
   macro avg       0.82      0.69      0.73     28655
weighted avg       0.84      0.84      0.84     28655


===confusion_matrix===

[[732   0   0 ...   0   0   0]
 [  1   1   2 ...   0   0   0]
 [  0   0  25 ...   0   0   0]
 ...
 [  0   0   0 ...  28   0   1]
 [  0   0   0 ...   0  47   1]
 [  0   0   0 ...   0   3 146]]

===multilabel confusion matrix===

[[[27725   105]
  [   93   732]]

 [[28641     0]
  [   13     1]]

 [[28620     3]
  [    7    25]]

 [[28643     0]
  [   12     0]]

 [[28599     4]
  [   15    37]]

 [[28465    14]
  [   37   139]]

 [[28538    15]
  [   53    49]]

 [[28524    34]
  [   70    27]]

 [[28640     1]
  [   10     4]]

 [[28570    16]
  [   32    37]]

 [[28523    28]
  [   32    72]]

 [[28634     3]
  [   17     1]]

 [[28638     2]
  [   11     4]]

 [[28612     1]
  [   16    26]]

 [[28613     8]
  [   15    19]]

 [[28577    14]
  [   11    53]]

 [[28642     0]
  [   10     3]]

 [[28636     0]
  [   12     7]]

 [[28575     9]
  [    7    64]]

 [[28623     1]
  [   26     5]]

 [[28561     0]
  [    5    89]]

 [[28598    11]
  [    6    40]]

 [[28630     0]
  [    6    19]]

 [[28287    22]
  [   18   328]]

 [[28622     2]
  [   15    16]]

 [[28634     1]
  [   20     0]]

 [[28455    33]
  [   67   100]]

 [[28619     0]
  [   16    20]]

 [[28583    12]
  [    2    58]]

 [[28591     2]
  [   13    49]]

 [[28644     0]
  [    4     7]]

 [[28643     0]
  [   12     0]]

 [[28606     9]
  [   28    12]]

 [[28570    11]
  [   16    58]]

 [[28599     0]
  [    0    56]]

 [[28637     2]
  [    3    13]]

 [[28595     9]
  [   48     3]]

 [[28631     5]
  [    3    16]]

 [[28620     6]
  [    7    22]]

 [[28551     3]
  [   13    88]]

 [[28643     0]
  [    8     4]]

 [[28641     1]
  [    0    13]]

 [[28564    24]
  [    8    59]]

 [[28578     1]
  [   14    62]]

 [[28643     1]
  [    0    11]]

 [[28617     1]
  [    9    28]]

 [[26542   500]
  [  103  1510]]

 [[28347     9]
  [   12   287]]

 [[28407     5]
  [    9   234]]

 [[28481     5]
  [    7   162]]

 [[27456   176]
  [  150   873]]

 [[28036   267]
  [   58   294]]

 [[28556    13]
  [   16    70]]

 [[27864   185]
  [  114   492]]

 [[28075    37]
  [   57   486]]

 [[28575     1]
  [   14    65]]

 [[27627    74]
  [   83   871]]

 [[28389    19]
  [   24   223]]

 [[28621     0]
  [    2    32]]

 [[27579   199]
  [  110   767]]

 [[28572     6]
  [   51    26]]

 [[27960   129]
  [  111   455]]

 [[28631     0]
  [   24     0]]

 [[28590    10]
  [   19    36]]

 [[28394     6]
  [   12   243]]

 [[28636     6]
  [    8     5]]

 [[28158    40]
  [   15   442]]

 [[28618     0]
  [   11    26]]

 [[27044   422]
  [  123  1066]]

 [[28412    20]
  [   30   193]]

 [[28633     3]
  [   14     5]]

 [[28261    37]
  [   11   346]]

 [[28621     2]
  [   15    17]]

 [[28642     0]
  [   12     1]]

 [[28520     7]
  [    5   123]]

 [[28642     0]
  [    1    12]]

 [[27953   242]
  [   81   379]]

 [[28548     3]
  [   22    82]]

 [[28598     4]
  [   36    17]]

 [[28544    28]
  [   32    51]]

 [[28549    27]
  [   36    43]]

 [[28569     2]
  [   17    67]]

 [[28302    19]
  [   49   285]]

 [[28628     3]
  [   15     9]]

 [[28035   102]
  [  158   360]]

 [[28543    24]
  [   84     4]]

 [[28641     1]
  [    8     5]]

 [[28021   154]
  [  144   336]]

 [[28497    31]
  [   35    92]]

 [[28630     1]
  [    1    23]]

 [[28482    20]
  [   37   116]]

 [[28634     1]
  [   14     6]]

 [[28626     2]
  [   22     5]]

 [[28610     3]
  [    7    35]]

 [[28613     8]
  [   26     8]]

 [[28531    25]
  [   64    35]]

 [[28181    58]
  [   80   336]]

 [[28515    22]
  [   38    80]]

 [[28554     2]
  [   36    63]]

 [[28308    94]
  [   59   194]]

 [[28537     3]
  [    3   112]]

 [[28165    67]
  [  109   314]]

 [[28552     5]
  [   25    73]]

 [[28590     5]
  [   20    40]]

 [[28373    17]
  [   53   212]]

 [[28619     0]
  [    3    33]]

 [[28126    34]
  [   86   409]]

 [[28640     1]
  [    2    12]]

 [[27938   107]
  [   65   545]]

 [[28449     0]
  [   20   186]]

 [[28633     0]
  [   19     3]]

 [[28078    42]
  [   81   454]]

 [[28549     8]
  [   35    63]]

 [[28537    32]
  [   49    37]]

 [[28532    13]
  [   12    98]]

 [[27716    81]
  [  118   740]]

 [[28594     0]
  [   44    17]]

 [[28405    42]
  [   18   190]]

 [[28642     0]
  [   13     0]]

 [[28586     3]
  [   28    38]]

 [[28487    11]
  [   12   145]]

 [[28570     1]
  [    0    84]]

 [[28593     7]
  [   20    35]]

 [[28487    15]
  [   53   100]]

 [[28602     1]
  [    3    49]]

 [[28498    10]
  [   11   136]]

 [[28569    10]
  [   29    47]]

 [[28636     1]
  [    4    14]]

 [[28429    29]
  [   34   163]]

 [[28196     9]
  [   50   400]]

 [[28641     2]
  [    3     9]]

 [[28609     4]
  [   18    24]]

 [[28640     0]
  [    1    14]]

 [[28447     4]
  [    7   197]]

 [[28572     7]
  [    4    72]]

 [[28341    58]
  [   36   220]]

 [[28635     1]
  [   11     8]]

 [[28640     2]
  [    3    10]]

 [[28572    16]
  [   26    41]]

 [[26960   231]
  [   16  1448]]

 [[28503     5]
  [   12   135]]

 [[28546    11]
  [   13    85]]

 [[28195     5]
  [   37   418]]

 [[28573     0]
  [    5    77]]

 [[28233    12]
  [   24   386]]

 [[28220    29]
  [   20   386]]

 [[28642     1]
  [   10     2]]

 [[28482    24]
  [   15   134]]

 [[27909    44]
  [   29   673]]

 [[28456     3]
  [    5   191]]

 [[28623     0]
  [    6    26]]

 [[28584     2]
  [   18    51]]

 [[28553     9]
  [    6    87]]

 [[28622     0]
  [    5    28]]

 [[28600     5]
  [    3    47]]

 [[28476    25]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8422
MCC	0.8389
log_loss	0.7238
f1 score weighted	0.8365
f1 score macro	0.7297
f1 score micro	0.8422
roc_auc ovr	0.9933
roc_auc ovo	0.9902
precision	0.8448
recall	0.8422

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f35504491f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f35504493d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3550449430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3550449190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  96.,  46., 108.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.89      0.89       824
         1.0       0.00      0.00      0.00        14
         2.0       0.64      0.84      0.73        32
         3.0       0.00      0.00      0.00        12
         4.0       0.97      0.65      0.78        52
         5.0       0.96      0.75      0.84       175
         6.0       0.83      0.50      0.62       101
         7.0       0.90      0.18      0.31        98
         8.0       1.00      0.21      0.35        14
         9.0       0.64      0.36      0.46        70
        10.0       0.76      0.71      0.74       104
        11.0       0.75      0.17      0.27        18
        12.0       0.71      0.33      0.45        15
        13.0       0.67      0.71      0.69        42
        14.0       0.74      0.41      0.53        34
        15.0       0.81      0.89      0.85        65
        16.0       0.00      0.00      0.00        13
        17.0       0.90      0.47      0.62        19
        18.0       0.94      0.86      0.90        72
        19.0       0.67      0.20      0.31        30
        20.0       1.00      0.90      0.95        94
        21.0       0.89      0.74      0.81        46
        22.0       0.84      0.84      0.84        25
        23.0       0.98      0.92      0.95       345
        24.0       0.81      0.57      0.67        30
        25.0       1.00      0.05      0.10        20
        26.0       0.96      0.68      0.79       168
        27.0       0.96      0.63      0.76        35
        28.0       0.96      0.84      0.89        61
        29.0       0.98      0.67      0.79        63
        30.0       0.20      0.09      0.13        11
        31.0       0.00      0.00      0.00        12
        32.0       0.93      0.35      0.51        40
        33.0       0.78      0.77      0.78        74
        34.0       1.00      0.98      0.99        57
        35.0       0.63      0.75      0.69        16
        36.0       0.36      0.08      0.13        50
        37.0       1.00      0.65      0.79        20
        38.0       0.89      0.59      0.71        29
        39.0       0.96      0.88      0.92       101
        40.0       1.00      0.58      0.74        12
        41.0       0.88      1.00      0.93        14
        42.0       0.85      0.85      0.85        67
        43.0       0.97      0.88      0.92        76
        44.0       1.00      0.91      0.95        11
        45.0       0.92      0.92      0.92        37
        46.0       0.90      0.92      0.90      1613
        47.0       1.00      0.96      0.98       299
        48.0       0.97      0.98      0.97       243
        49.0       0.96      0.95      0.96       168
        50.0       0.62      0.89      0.73      1024
        51.0       0.76      0.66      0.71       353
        52.0       0.78      0.88      0.83        85
        53.0       0.82      0.74      0.78       606
        54.0       0.96      0.90      0.93       543
        55.0       0.93      0.71      0.81        79
        56.0       0.91      0.91      0.91       954
        57.0       0.96      0.85      0.90       247
        58.0       0.97      0.94      0.96        34
        59.0       0.97      0.79      0.87       876
        60.0       0.93      0.18      0.31        76
        61.0       0.85      0.78      0.82       566
        62.0       0.00      0.00      0.00        24
        63.0       0.72      0.42      0.53        55
        64.0       0.98      0.97      0.98       255
        65.0       0.00      0.00      0.00        13
        66.0       0.94      0.98      0.96       457
        67.0       0.89      0.65      0.75        37
        68.0       0.62      0.93      0.74      1189
        69.0       0.90      0.83      0.86       223
        70.0       0.89      0.42      0.57        19
        71.0       0.94      0.93      0.94       357
        72.0       0.94      0.52      0.67        31
        73.0       0.00      0.00      0.00        13
        74.0       0.98      0.97      0.97       128
        75.0       1.00      0.62      0.76        13
        76.0       0.83      0.72      0.77       461
        77.0       0.89      0.83      0.86       104
        78.0       0.73      0.21      0.32        53
        79.0       0.70      0.53      0.60        83
        80.0       0.74      0.51      0.60        79
        81.0       1.00      0.82      0.90        84
        82.0       0.71      0.90      0.79       334
        83.0       0.75      0.38      0.50        24
        84.0       0.76      0.71      0.73       518
        85.0       0.05      0.02      0.03        88
        86.0       0.40      0.83      0.54        12
        87.0       0.61      0.77      0.68       481
        88.0       0.70      0.60      0.65       126
        89.0       0.96      1.00      0.98        24
        90.0       0.97      0.75      0.84       152
        91.0       1.00      0.25      0.40        20
        92.0       0.67      0.07      0.13        27
        93.0       0.94      0.74      0.83        42
        94.0       0.70      0.21      0.33        33
        95.0       0.66      0.19      0.29       100
        96.0       0.78      0.81      0.80       415
        97.0       0.76      0.50      0.60       118
        98.0       0.95      0.83      0.89       100
        99.0       0.83      0.75      0.79       253
       100.0       0.97      0.97      0.97       116
       101.0       0.56      0.82      0.67       423
       102.0       0.97      0.79      0.87        99
       103.0       0.89      0.53      0.67        60
       104.0       0.88      0.83      0.86       265
       105.0       0.94      0.86      0.90        36
       106.0       0.84      0.86      0.85       495
       107.0       0.93      0.93      0.93        15
       108.0       0.97      0.83      0.89       611
       109.0       0.98      0.96      0.97       207
       110.0       0.91      0.45      0.61        22
       111.0       0.90      0.84      0.87       535
       112.0       0.82      0.54      0.65        98
       113.0       0.79      0.51      0.62        87
       114.0       0.84      0.95      0.89       110
       115.0       0.65      0.91      0.76       858
       116.0       0.51      0.37      0.43        60
       117.0       0.92      0.91      0.92       209
       118.0       0.00      0.00      0.00        12
       119.0       0.84      0.73      0.78        66
       120.0       0.98      0.89      0.93       157
       121.0       0.96      0.96      0.96        84
       122.0       0.90      0.51      0.65        55
       123.0       0.50      0.78      0.61       153
       124.0       1.00      0.88      0.94        51
       125.0       1.00      0.86      0.92       146
       126.0       0.78      0.51      0.61        77
       127.0       1.00      0.67      0.80        18
       128.0       0.94      0.81      0.87       197
       129.0       0.96      0.92      0.94       450
       130.0       0.58      0.64      0.61        11
       131.0       0.91      0.48      0.62        42
       132.0       1.00      0.73      0.85        15
       133.0       0.87      0.99      0.92       204
       134.0       0.97      0.96      0.97        76
       135.0       0.79      0.85      0.82       256
       136.0       1.00      0.10      0.18        20
       137.0       0.85      0.85      0.85        13
       138.0       0.88      0.52      0.65        67
       139.0       0.90      0.99      0.95      1464
       140.0       0.95      0.82      0.88       147
       141.0       0.84      0.86      0.85        98
       142.0       0.92      0.92      0.92       455
       143.0       0.91      0.94      0.92        82
       144.0       0.94      0.96      0.95       410
       145.0       0.86      0.97      0.91       406
       146.0       0.00      0.00      0.00        12
       147.0       0.96      0.87      0.91       148
       148.0       0.93      0.97      0.95       702
       149.0       0.98      0.97      0.98       196
       150.0       1.00      0.56      0.72        32
       151.0       0.92      0.65      0.76        69
       152.0       0.93      0.88      0.91        93
       153.0       0.97      0.88      0.92        33
       154.0       0.84      0.86      0.85        50
       155.0       0.79      0.91      0.85       153

    accuracy                           0.83     28655
   macro avg       0.80      0.67      0.70     28655
weighted avg       0.85      0.83      0.83     28655


===confusion_matrix===

[[736   0   0 ...   0   0   0]
 [  0   0   1 ...   0   0   0]
 [  0   0  27 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   1]
 [  0   0   0 ...   0  43   6]
 [  0   0   0 ...   0   7 139]]

===multilabel confusion matrix===

[[[27735    96]
  [   88   736]]

 [[28641     0]
  [   14     0]]

 [[28608    15]
  [    5    27]]

 [[28643     0]
  [   12     0]]

 [[28602     1]
  [   18    34]]

 [[28475     5]
  [   44   131]]

 [[28544    10]
  [   51    50]]

 [[28555     2]
  [   80    18]]

 [[28641     0]
  [   11     3]]

 [[28571    14]
  [   45    25]]

 [[28528    23]
  [   30    74]]

 [[28636     1]
  [   15     3]]

 [[28638     2]
  [   10     5]]

 [[28598    15]
  [   12    30]]

 [[28616     5]
  [   20    14]]

 [[28576    14]
  [    7    58]]

 [[28640     2]
  [   13     0]]

 [[28635     1]
  [   10     9]]

 [[28579     4]
  [   10    62]]

 [[28622     3]
  [   24     6]]

 [[28561     0]
  [    9    85]]

 [[28605     4]
  [   12    34]]

 [[28626     4]
  [    4    21]]

 [[28302     8]
  [   26   319]]

 [[28621     4]
  [   13    17]]

 [[28635     0]
  [   19     1]]

 [[28482     5]
  [   54   114]]

 [[28619     1]
  [   13    22]]

 [[28592     2]
  [   10    51]]

 [[28591     1]
  [   21    42]]

 [[28640     4]
  [   10     1]]

 [[28643     0]
  [   12     0]]

 [[28614     1]
  [   26    14]]

 [[28565    16]
  [   17    57]]

 [[28598     0]
  [    1    56]]

 [[28632     7]
  [    4    12]]

 [[28598     7]
  [   46     4]]

 [[28635     0]
  [    7    13]]

 [[28624     2]
  [   12    17]]

 [[28550     4]
  [   12    89]]

 [[28643     0]
  [    5     7]]

 [[28639     2]
  [    0    14]]

 [[28578    10]
  [   10    57]]

 [[28577     2]
  [    9    67]]

 [[28644     0]
  [    1    10]]

 [[28615     3]
  [    3    34]]

 [[26869   173]
  [  137  1476]]

 [[28356     0]
  [   12   287]]

 [[28404     8]
  [    6   237]]

 [[28481     6]
  [    8   160]]

 [[27083   548]
  [  112   912]]

 [[28228    74]
  [  119   234]]

 [[28549    21]
  [   10    75]]

 [[27953    96]
  [  159   447]]

 [[28093    19]
  [   52   491]]

 [[28572     4]
  [   23    56]]

 [[27618    83]
  [   87   867]]

 [[28399     9]
  [   36   211]]

 [[28620     1]
  [    2    32]]

 [[27758    21]
  [  187   689]]

 [[28578     1]
  [   62    14]]

 [[28012    77]
  [  122   444]]

 [[28631     0]
  [   24     0]]

 [[28591     9]
  [   32    23]]

 [[28396     4]
  [    7   248]]

 [[28642     0]
  [   13     0]]

 [[28168    30]
  [    9   448]]

 [[28615     3]
  [   13    24]]

 [[26776   690]
  [   81  1108]]

 [[28412    20]
  [   39   184]]

 [[28635     1]
  [   11     8]]

 [[28276    22]
  [   24   333]]

 [[28623     1]
  [   15    16]]

 [[28640     2]
  [   13     0]]

 [[28524     3]
  [    4   124]]

 [[28642     0]
  [    5     8]]

 [[28127    67]
  [  131   330]]

 [[28540    11]
  [   18    86]]

 [[28598     4]
  [   42    11]]

 [[28553    19]
  [   39    44]]

 [[28562    14]
  [   39    40]]

 [[28571     0]
  [   15    69]]

 [[28196   125]
  [   35   299]]

 [[28628     3]
  [   15     9]]

 [[28019   118]
  [  150   368]]

 [[28531    36]
  [   86     2]]

 [[28628    15]
  [    2    10]]

 [[27940   234]
  [  109   372]]

 [[28496    33]
  [   50    76]]

 [[28630     1]
  [    0    24]]

 [[28499     4]
  [   38   114]]

 [[28635     0]
  [   15     5]]

 [[28627     1]
  [   25     2]]

 [[28611     2]
  [   11    31]]

 [[28619     3]
  [   26     7]]

 [[28545    10]
  [   81    19]]

 [[28144    96]
  [   77   338]]

 [[28518    19]
  [   59    59]]

 [[28551     4]
  [   17    83]]

 [[28363    39]
  [   62   191]]

 [[28535     4]
  [    3   113]]

 [[27962   270]
  [   75   348]]

 [[28554     2]
  [   21    78]]

 [[28591     4]
  [   28    32]]

 [[28360    30]
  [   44   221]]

 [[28617     2]
  [    5    31]]

 [[28081    79]
  [   67   428]]

 [[28639     1]
  [    1    14]]

 [[28029    15]
  [  104   507]]

 [[28443     5]
  [    8   199]]

 [[28632     1]
  [   12    10]]

 [[28072    48]
  [   87   448]]

 [[28545    12]
  [   45    53]]

 [[28556    12]
  [   43    44]]

 [[28525    20]
  [    5   105]]

 [[27379   418]
  [   75   783]]

 [[28574    21]
  [   38    22]]

 [[28430    16]
  [   19   190]]

 [[28643     0]
  [   12     0]]

 [[28580     9]
  [   18    48]]

 [[28495     3]
  [   18   139]]

 [[28568     3]
  [    3    81]]

 [[28597     3]
  [   27    28]]

 [[28382   120]
  [   33   120]]

 [[28604     0]
  [    6    45]]

 [[28509     0]
  [   21   125]]

 [[28567    11]
  [   38    39]]

 [[28637     0]
  [    6    12]]

 [[28447    11]
  [   37   160]]

 [[28189    16]
  [   37   413]]

 [[28639     5]
  [    4     7]]

 [[28611     2]
  [   22    20]]

 [[28640     0]
  [    4    11]]

 [[28421    30]
  [    3   201]]

 [[28577     2]
  [    3    73]]

 [[28340    59]
  [   39   217]]

 [[28635     0]
  [   18     2]]

 [[28640     2]
  [    2    11]]

 [[28583     5]
  [   32    35]]

 [[27038   153]
  [   10  1454]]

 [[28502     6]
  [   27   120]]

 [[28541    16]
  [   14    84]]

 [[28165    35]
  [   35   420]]

 [[28565     8]
  [    5    77]]

 [[28219    26]
  [   16   394]]

 [[28184    65]
  [   11   395]]

 [[28643     0]
  [   12     0]]

 [[28501     6]
  [   19   129]]

 [[27901    52]
  [   18   684]]

 [[28456     3]
  [    5   191]]

 [[28623     0]
  [   14    18]]

 [[28582     4]
  [   24    45]]

 [[28556     6]
  [   11    82]]

 [[28621     1]
  [    4    29]]

 [[28597     8]
  [    7    43]]

 [[28466    36]
  [   14   139]]]

===scores report===
metrics	scores
Accuracy	0.8342
MCC	0.8310
log_loss	0.7657
f1 score weighted	0.8284
f1 score macro	0.7040
f1 score micro	0.8342
roc_auc ovr	0.9934
roc_auc ovo	0.9902
precision	0.8454
recall	0.8342

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f35504491f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f35504493d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3550449430>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3550449190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56., 115., ...,  96., 109.,  88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.90      0.89       824
         1.0       0.17      0.07      0.10        14
         2.0       0.63      0.84      0.72        32
         3.0       0.00      0.00      0.00        11
         4.0       0.49      0.73      0.59        51
         5.0       0.50      0.85      0.63       176
         6.0       0.43      0.63      0.51       102
         7.0       0.31      0.57      0.40        97
         8.0       0.70      0.50      0.58        14
         9.0       0.54      0.43      0.48        70
        10.0       0.77      0.89      0.83       103
        11.0       0.00      0.00      0.00        18
        12.0       0.67      0.13      0.22        15
        13.0       0.66      0.81      0.73        43
        14.0       0.57      0.59      0.58        34
        15.0       0.66      0.82      0.73        65
        16.0       1.00      0.08      0.14        13
        17.0       1.00      0.58      0.73        19
        18.0       1.00      0.89      0.94        72
        19.0       1.00      0.03      0.06        30
        20.0       0.94      1.00      0.97        94
        21.0       0.76      0.76      0.76        46
        22.0       0.82      0.36      0.50        25
        23.0       0.97      0.94      0.95       345
        24.0       0.92      0.73      0.81        30
        25.0       0.00      0.00      0.00        20
        26.0       0.74      0.74      0.74       168
        27.0       0.74      0.80      0.77        35
        28.0       0.89      0.90      0.89        61
        29.0       0.92      0.73      0.81        63
        30.0       0.33      0.55      0.41        11
        31.0       0.00      0.00      0.00        12
        32.0       0.61      0.47      0.54        40
        33.0       0.60      0.68      0.63        74
        34.0       0.90      0.98      0.94        57
        35.0       0.94      1.00      0.97        15
        36.0       0.47      0.14      0.22        50
        37.0       0.85      0.89      0.87        19
        38.0       0.88      0.72      0.79        29
        39.0       0.90      0.88      0.89       101
        40.0       0.33      0.54      0.41        13
        41.0       0.87      0.93      0.90        14
        42.0       0.80      0.79      0.79        66
        43.0       0.80      0.89      0.84        76
        44.0       0.62      0.91      0.74        11
        45.0       0.91      0.84      0.87        37
        46.0       0.97      0.86      0.91      1612
        47.0       0.91      1.00      0.95       299
        48.0       1.00      0.97      0.98       243
        49.0       0.99      0.92      0.95       168
        50.0       0.92      0.76      0.83      1024
        51.0       0.85      0.70      0.77       353
        52.0       0.79      0.91      0.85        85
        53.0       0.77      0.76      0.77       606
        54.0       0.98      0.86      0.92       543
        55.0       0.93      0.69      0.79        78
        56.0       0.95      0.87      0.91       954
        57.0       0.87      0.94      0.90       247
        58.0       0.97      1.00      0.99        34
        59.0       0.94      0.80      0.87       877
        60.0       0.69      0.32      0.43        76
        61.0       0.88      0.80      0.84       566
        62.0       0.00      0.00      0.00        24
        63.0       0.49      0.45      0.47        55
        64.0       0.94      0.98      0.96       255
        65.0       0.50      0.43      0.46        14
        66.0       0.90      0.96      0.93       457
        67.0       0.95      0.54      0.69        37
        68.0       0.79      0.87      0.83      1189
        69.0       0.96      0.86      0.91       224
        70.0       0.85      0.58      0.69        19
        71.0       0.95      0.96      0.95       357
        72.0       0.70      0.66      0.68        32
        73.0       0.00      0.00      0.00        12
        74.0       0.96      0.95      0.96       127
        75.0       0.88      0.58      0.70        12
        76.0       0.80      0.79      0.79       460
        77.0       0.88      0.81      0.84       103
        78.0       0.58      0.40      0.48        52
        79.0       0.94      0.61      0.74        83
        80.0       0.40      0.57      0.47        80
        81.0       1.00      0.82      0.90        84
        82.0       0.91      0.87      0.89       334
        83.0       0.68      0.65      0.67        23
        84.0       0.75      0.72      0.73       519
        85.0       0.05      0.02      0.03        88
        86.0       1.00      0.50      0.67        12
        87.0       0.54      0.79      0.64       480
        88.0       0.88      0.55      0.68       126
        89.0       0.96      1.00      0.98        25
        90.0       0.62      0.79      0.70       152
        91.0       0.20      0.60      0.30        20
        92.0       0.29      0.14      0.19        28
        93.0       0.89      0.79      0.84        42
        94.0       0.23      0.21      0.22        34
        95.0       0.82      0.50      0.62       100
        96.0       0.61      0.84      0.70       415
        97.0       0.85      0.40      0.54       118
        98.0       0.99      0.71      0.82        99
        99.0       0.51      0.87      0.65       253
       100.0       0.94      0.91      0.93       116
       101.0       0.56      0.83      0.67       423
       102.0       0.82      0.81      0.82        99
       103.0       0.76      0.78      0.77        60
       104.0       0.72      0.85      0.78       265
       105.0       0.97      0.78      0.87        37
       106.0       0.85      0.83      0.84       495
       107.0       1.00      0.73      0.85        15
       108.0       0.92      0.84      0.88       611
       109.0       0.93      0.96      0.94       206
       110.0       0.62      0.36      0.46        22
       111.0       0.73      0.89      0.80       534
       112.0       0.63      0.76      0.69        98
       113.0       0.92      0.54      0.68        87
       114.0       0.93      0.85      0.89       110
       115.0       0.96      0.87      0.91       858
       116.0       0.55      0.36      0.44        61
       117.0       0.99      0.93      0.96       209
       118.0       0.00      0.00      0.00        13
       119.0       0.96      0.66      0.78        65
       120.0       0.97      0.96      0.97       156
       121.0       0.97      0.98      0.97        85
       122.0       0.89      0.61      0.72        56
       123.0       0.88      0.64      0.74       154
       124.0       0.93      0.83      0.88        52
       125.0       0.96      0.90      0.93       146
       126.0       0.73      0.64      0.68        77
       127.0       0.93      0.78      0.85        18
       128.0       0.53      0.92      0.67       198
       129.0       0.92      0.94      0.93       450
       130.0       1.00      0.64      0.78        11
       131.0       1.00      0.56      0.72        43
       132.0       0.67      0.93      0.78        15
       133.0       0.95      0.99      0.97       205
       134.0       0.89      0.95      0.92        77
       135.0       0.73      0.84      0.78       255
       136.0       1.00      0.05      0.10        20
       137.0       0.65      0.92      0.76        12
       138.0       0.82      0.63      0.71        67
       139.0       0.92      0.99      0.96      1464
       140.0       0.94      0.87      0.90       147
       141.0       0.88      0.86      0.87        98
       142.0       0.97      0.87      0.92       455
       143.0       0.96      0.95      0.96        82
       144.0       0.99      0.92      0.95       411
       145.0       0.90      0.98      0.94       405
       146.0       0.50      0.64      0.56        11
       147.0       0.99      0.86      0.92       148
       148.0       0.94      0.94      0.94       702
       149.0       0.99      0.98      0.98       196
       150.0       0.78      0.78      0.78        32
       151.0       0.88      0.75      0.81        69
       152.0       0.94      0.86      0.90        93
       153.0       0.74      0.94      0.83        33
       154.0       0.71      0.90      0.80        50
       155.0       0.85      0.90      0.88       154

    accuracy                           0.84     28655
   macro avg       0.76      0.70      0.71     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[739   1   0 ...   0   2   0]
 [  0   1   6 ...   0   0   0]
 [  0   0  27 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  45   5]
 [  0   0   0 ...   4   8 139]]

===multilabel confusion matrix===

[[[27732    99]
  [   85   739]]

 [[28636     5]
  [   13     1]]

 [[28607    16]
  [    5    27]]

 [[28644     0]
  [   11     0]]

 [[28566    38]
  [   14    37]]

 [[28328   151]
  [   26   150]]

 [[28469    84]
  [   38    64]]

 [[28436   122]
  [   42    55]]

 [[28638     3]
  [    7     7]]

 [[28559    26]
  [   40    30]]

 [[28524    28]
  [   11    92]]

 [[28634     3]
  [   18     0]]

 [[28639     1]
  [   13     2]]

 [[28594    18]
  [    8    35]]

 [[28606    15]
  [   14    20]]

 [[28563    27]
  [   12    53]]

 [[28642     0]
  [   12     1]]

 [[28636     0]
  [    8    11]]

 [[28583     0]
  [    8    64]]

 [[28625     0]
  [   29     1]]

 [[28555     6]
  [    0    94]]

 [[28598    11]
  [   11    35]]

 [[28628     2]
  [   16     9]]

 [[28300    10]
  [   21   324]]

 [[28623     2]
  [    8    22]]

 [[28635     0]
  [   20     0]]

 [[28442    45]
  [   43   125]]

 [[28610    10]
  [    7    28]]

 [[28587     7]
  [    6    55]]

 [[28588     4]
  [   17    46]]

 [[28632    12]
  [    5     6]]

 [[28642     1]
  [   12     0]]

 [[28603    12]
  [   21    19]]

 [[28547    34]
  [   24    50]]

 [[28592     6]
  [    1    56]]

 [[28639     1]
  [    0    15]]

 [[28597     8]
  [   43     7]]

 [[28633     3]
  [    2    17]]

 [[28623     3]
  [    8    21]]

 [[28544    10]
  [   12    89]]

 [[28628    14]
  [    6     7]]

 [[28639     2]
  [    1    13]]

 [[28576    13]
  [   14    52]]

 [[28562    17]
  [    8    68]]

 [[28638     6]
  [    1    10]]

 [[28615     3]
  [    6    31]]

 [[26995    48]
  [  221  1391]]

 [[28326    30]
  [    1   298]]

 [[28411     1]
  [    7   236]]

 [[28486     1]
  [   14   154]]

 [[27562    69]
  [  242   782]]

 [[28258    44]
  [  106   247]]

 [[28550    20]
  [    8    77]]

 [[27913   136]
  [  143   463]]

 [[28102    10]
  [   74   469]]

 [[28573     4]
  [   24    54]]

 [[27662    39]
  [  127   827]]

 [[28373    35]
  [   14   233]]

 [[28620     1]
  [    0    34]]

 [[27736    42]
  [  172   705]]

 [[28568    11]
  [   52    24]]

 [[28030    59]
  [  116   450]]

 [[28631     0]
  [   24     0]]

 [[28574    26]
  [   30    25]]

 [[28384    16]
  [    5   250]]

 [[28635     6]
  [    8     6]]

 [[28149    49]
  [   20   437]]

 [[28617     1]
  [   17    20]]

 [[27184   282]
  [  154  1035]]

 [[28424     7]
  [   32   192]]

 [[28634     2]
  [    8    11]]

 [[28278    20]
  [   13   344]]

 [[28614     9]
  [   11    21]]

 [[28643     0]
  [   12     0]]

 [[28523     5]
  [    6   121]]

 [[28642     1]
  [    5     7]]

 [[28102    93]
  [   98   362]]

 [[28541    11]
  [   20    83]]

 [[28588    15]
  [   31    21]]

 [[28569     3]
  [   32    51]]

 [[28505    70]
  [   34    46]]

 [[28571     0]
  [   15    69]]

 [[28294    27]
  [   45   289]]

 [[28625     7]
  [    8    15]]

 [[28008   128]
  [  145   374]]

 [[28530    37]
  [   86     2]]

 [[28643     0]
  [    6     6]]

 [[27857   318]
  [  103   377]]

 [[28520     9]
  [   57    69]]

 [[28629     1]
  [    0    25]]

 [[28431    72]
  [   32   120]]

 [[28588    47]
  [    8    12]]

 [[28617    10]
  [   24     4]]

 [[28609     4]
  [    9    33]]

 [[28597    24]
  [   27     7]]

 [[28544    11]
  [   50    50]]

 [[28017   223]
  [   68   347]]

 [[28529     8]
  [   71    47]]

 [[28555     1]
  [   29    70]]

 [[28193   209]
  [   32   221]]

 [[28532     7]
  [   10   106]]

 [[27955   277]
  [   74   349]]

 [[28539    17]
  [   19    80]]

 [[28580    15]
  [   13    47]]

 [[28304    86]
  [   40   225]]

 [[28617     1]
  [    8    29]]

 [[28088    72]
  [   82   413]]

 [[28640     0]
  [    4    11]]

 [[28001    43]
  [   95   516]]

 [[28433    16]
  [    8   198]]

 [[28628     5]
  [   14     8]]

 [[27944   177]
  [   58   476]]

 [[28513    44]
  [   24    74]]

 [[28564     4]
  [   40    47]]

 [[28538     7]
  [   17    93]]

 [[27764    33]
  [  109   749]]

 [[28576    18]
  [   39    22]]

 [[28445     1]
  [   14   195]]

 [[28642     0]
  [   13     0]]

 [[28588     2]
  [   22    43]]

 [[28495     4]
  [    6   150]]

 [[28567     3]
  [    2    83]]

 [[28595     4]
  [   22    34]]

 [[28488    13]
  [   56    98]]

 [[28600     3]
  [    9    43]]

 [[28504     5]
  [   15   131]]

 [[28560    18]
  [   28    49]]

 [[28636     1]
  [    4    14]]

 [[28295   162]
  [   15   183]]

 [[28167    38]
  [   27   423]]

 [[28644     0]
  [    4     7]]

 [[28612     0]
  [   19    24]]

 [[28633     7]
  [    1    14]]

 [[28440    10]
  [    3   202]]

 [[28569     9]
  [    4    73]]

 [[28323    77]
  [   42   213]]

 [[28635     0]
  [   19     1]]

 [[28637     6]
  [    1    11]]

 [[28579     9]
  [   25    42]]

 [[27070   121]
  [    8  1456]]

 [[28500     8]
  [   19   128]]

 [[28546    11]
  [   14    84]]

 [[28188    12]
  [   57   398]]

 [[28570     3]
  [    4    78]]

 [[28239     5]
  [   33   378]]

 [[28205    45]
  [    9   396]]

 [[28637     7]
  [    4     7]]

 [[28506     1]
  [   21   127]]

 [[27914    39]
  [   40   662]]

 [[28457     2]
  [    4   192]]

 [[28616     7]
  [    7    25]]

 [[28579     7]
  [   17    52]]

 [[28557     5]
  [   13    80]]

 [[28611    11]
  [    2    31]]

 [[28587    18]
  [    5    45]]

 [[28477    24]
  [   15   139]]]

===scores report===
metrics	scores
Accuracy	0.8360
MCC	0.8328
log_loss	0.7709
f1 score weighted	0.8358
f1 score macro	0.7088
f1 score micro	0.8360
roc_auc ovr	0.9934
roc_auc ovo	0.9910
precision	0.8510
recall	0.8360

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8450237297599107	0.8418838755413217	0.7123556416775114	0.8412096017543302	0.7288446316383435	0.8450237297599107	0.9938580664708073	0.991267201076498	0.8554548450610312	0.8450237297599107
1	0.8521025998953062	0.8491053219939968	0.6823691337736504	0.8499915640166059	0.7518829252852937	0.8521025998953063	0.9937951759623459	0.9911852879273854	0.8595076291094073	0.8521025998953062
2	0.8421915896004187	0.8388928415637917	0.7238054159075377	0.8364520721899801	0.7297010801106727	0.8421915896004187	0.993303787151519	0.9901863184183313	0.844806654920294	0.8421915896004187
3	0.83423486302565	0.83097267736736	0.7656557246470672	0.828432591497926	0.7040291106718676	0.83423486302565	0.993354737375899	0.9902381468713165	0.8454454573731702	0.83423486302565
4	0.8359797592043273	0.8328340824754931	0.7708721340874214	0.8358275749471188	0.7087873397476833	0.8359797592043274	0.9933605038935409	0.9910068782292885	0.8509666872084127	0.8359797592043273
mean	0.8419065082971227	0.8387377597883926	0.7310116100186377	0.8383826808811922	0.7246490174907722	0.8419065082971227	0.9935344541708224	0.9907767665045639	0.8512362547344632	0.8419065082971227
std	0.006445760170164022	0.006520097416377091	0.03333208946640448	0.007099545679303481	0.017097284150397133	0.0064457601701640365	0.00024019361873910027	0.00046885120879940534	0.0056772861984387725	0.006445760170164022

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 65045.1405 secs

