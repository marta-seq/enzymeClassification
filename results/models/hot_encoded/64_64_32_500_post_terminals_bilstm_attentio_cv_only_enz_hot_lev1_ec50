/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_terminals_bilstm_attentio_cv_only_enz_hot_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc7f46be220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc7f46be880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc7f46be8e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc7f46be670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.81      0.78      1793
         1.0       0.85      0.85      0.85      4921
         2.0       0.79      0.79      0.79      3576
         3.0       0.70      0.66      0.68       943
         4.0       0.74      0.75      0.74       695
         5.0       0.87      0.84      0.86      1073
         6.0       0.94      0.87      0.90       471

    accuracy                           0.81     13472
   macro avg       0.81      0.79      0.80     13472
weighted avg       0.81      0.81      0.81     13472


===confusion_matrix===

[[1446  121  145   38   21   17    5]
 [ 185 4166  366   97   39   62    6]
 [ 150  394 2810  100   78   32   12]
 [  61  101  119  622   27   12    1]
 [  34   47   69   20  518    7    0]
 [  37   61   44    9   17  905    0]
 [  13   23   24    1    1    1  408]]

===multilabel confusion matrix===

[[[11199   480]
  [  347  1446]]

 [[ 7804   747]
  [  755  4166]]

 [[ 9129   767]
  [  766  2810]]

 [[12264   265]
  [  321   622]]

 [[12594   183]
  [  177   518]]

 [[12268   131]
  [  168   905]]

 [[12977    24]
  [   63   408]]]

===scores report===
metrics	scores
Accuracy	0.8072
MCC	0.7473
log_loss	0.6746
f1 score weighted	0.8073
f1 score macro	0.7992
f1 score micro	0.8072
roc_auc ovr	0.9579
roc_auc ovo	0.9632
precision	0.8080
recall	0.8072

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc7f46be220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc7f46be880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc7f46be8e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc7f46be670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.73      0.76      1792
         1.0       0.80      0.86      0.83      4921
         2.0       0.78      0.77      0.77      3576
         3.0       0.73      0.64      0.68       943
         4.0       0.82      0.73      0.77       696
         5.0       0.88      0.86      0.87      1072
         6.0       0.89      0.89      0.89       471

    accuracy                           0.80     13471
   macro avg       0.81      0.78      0.80     13471
weighted avg       0.80      0.80      0.80     13471


===confusion_matrix===

[[1314  221  159   42   19   19   18]
 [ 129 4239  385   80   35   37   16]
 [ 141  525 2739   66   42   47   16]
 [  45  148  124  599   13   13    1]
 [  23   80   59   19  511    4    0]
 [  19   71   42    9    5  926    0]
 [  12   21   13    2    0    2  421]]

===multilabel confusion matrix===

[[[11310   369]
  [  478  1314]]

 [[ 7484  1066]
  [  682  4239]]

 [[ 9113   782]
  [  837  2739]]

 [[12310   218]
  [  344   599]]

 [[12661   114]
  [  185   511]]

 [[12277   122]
  [  146   926]]

 [[12949    51]
  [   50   421]]]

===scores report===
metrics	scores
Accuracy	0.7979
MCC	0.7333
log_loss	0.6786
f1 score weighted	0.7967
f1 score macro	0.7969
f1 score micro	0.7979
roc_auc ovr	0.9518
roc_auc ovo	0.9600
precision	0.7973
recall	0.7979

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc7f46be220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc7f46be880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc7f46be8e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc7f46be670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.78      0.78      1792
         1.0       0.82      0.87      0.84      4921
         2.0       0.81      0.79      0.80      3576
         3.0       0.72      0.70      0.71       943
         4.0       0.87      0.73      0.80       695
         5.0       0.92      0.86      0.89      1072
         6.0       0.94      0.87      0.90       472

    accuracy                           0.82     13471
   macro avg       0.84      0.80      0.82     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1402  175  141   54    7    9    4]
 [ 141 4291  344   85   24   30    6]
 [ 133  478 2817   85   24   25   14]
 [  44  125   94  656   15    8    1]
 [  33   74   54   21  508    4    1]
 [  25   73   36    7    4  926    1]
 [  15   30   13    3    0    2  409]]

===multilabel confusion matrix===

[[[11288   391]
  [  390  1402]]

 [[ 7595   955]
  [  630  4291]]

 [[ 9213   682]
  [  759  2817]]

 [[12273   255]
  [  287   656]]

 [[12702    74]
  [  187   508]]

 [[12321    78]
  [  146   926]]

 [[12972    27]
  [   63   409]]]

===scores report===
metrics	scores
Accuracy	0.8172
MCC	0.7590
log_loss	0.6737
f1 score weighted	0.8169
f1 score macro	0.8170
f1 score micro	0.8172
roc_auc ovr	0.9596
roc_auc ovo	0.9649
precision	0.8182
recall	0.8172

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc7f46be220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc7f46be880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc7f46be8e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc7f46be670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.80      0.77      1792
         1.0       0.84      0.86      0.85      4920
         2.0       0.81      0.77      0.79      3576
         3.0       0.73      0.71      0.72       944
         4.0       0.80      0.74      0.77       695
         5.0       0.88      0.87      0.87      1072
         6.0       0.92      0.87      0.89       472

    accuracy                           0.81     13471
   macro avg       0.82      0.80      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1435  150  123   41   13   19   11]
 [ 169 4218  356   77   39   49   12]
 [ 181  451 2761   85   55   34    9]
 [  59  100   85  668   17   14    1]
 [  38   46   56   26  514   11    4]
 [  33   56   32   13    6  932    0]
 [  18   22   14    2    2    3  411]]

===multilabel confusion matrix===

[[[11181   498]
  [  357  1435]]

 [[ 7726   825]
  [  702  4218]]

 [[ 9229   666]
  [  815  2761]]

 [[12283   244]
  [  276   668]]

 [[12644   132]
  [  181   514]]

 [[12269   130]
  [  140   932]]

 [[12962    37]
  [   61   411]]]

===scores report===
metrics	scores
Accuracy	0.8120
MCC	0.7535
log_loss	0.6661
f1 score weighted	0.8119
f1 score macro	0.8084
f1 score micro	0.8120
roc_auc ovr	0.9598
roc_auc ovo	0.9665
precision	0.8125
recall	0.8120

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc7f46be220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc7f46be880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc7f46be8e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc7f46be670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.79      0.79      1792
         1.0       0.86      0.82      0.84      4920
         2.0       0.77      0.84      0.80      3576
         3.0       0.64      0.72      0.68       944
         4.0       0.84      0.65      0.74       695
         5.0       0.90      0.87      0.88      1073
         6.0       0.91      0.89      0.90       471

    accuracy                           0.81     13471
   macro avg       0.82      0.80      0.80     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1411  121  162   56   15   17   10]
 [ 162 4023  491  162   33   34   15]
 [ 102  310 2996  104   20   29   15]
 [  52   84  110  679   11    7    1]
 [  34   72   84   39  453   11    2]
 [  15   63   40   20    3  932    0]
 [   8   20   17    0    2    4  420]]

===multilabel confusion matrix===

[[[11306   373]
  [  381  1411]]

 [[ 7881   670]
  [  897  4023]]

 [[ 8991   904]
  [  580  2996]]

 [[12146   381]
  [  265   679]]

 [[12692    84]
  [  242   453]]

 [[12296   102]
  [  141   932]]

 [[12957    43]
  [   51   420]]]

===scores report===
metrics	scores
Accuracy	0.8102
MCC	0.7519
log_loss	0.7134
f1 score weighted	0.8108
f1 score macro	0.8035
f1 score micro	0.8102
roc_auc ovr	0.9579
roc_auc ovo	0.9637
precision	0.8141
recall	0.8102

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.807229809976247	0.7473328391233759	0.6746287411916931	0.8073478252780653	0.7991943160813451	0.807229809976247	0.9579062733717615	0.9632190200756588	0.8079821126399069	0.807229809976247
1	0.7979363076237844	0.7332765804887871	0.6785659086929204	0.7967223580976911	0.7968593808794829	0.7979363076237844	0.9517666408027121	0.9599939377970106	0.7973269573101192	0.7979363076237844
2	0.8172370276891099	0.7589781810902242	0.673708935120872	0.8169343531290268	0.816975926564153	0.8172370276891099	0.9595724414954319	0.9649349280598408	0.8182419117674158	0.8172370276891099
3	0.8120406799792146	0.7535010651216988	0.666052608478428	0.8118729387582246	0.8084424139198483	0.8120406799792146	0.9597541661773569	0.9665194647757124	0.8124646508807004	0.8120406799792146
4	0.8101848415113948	0.7518909294292109	0.7134099750748084	0.8107752454045912	0.8035288084577806	0.8101848415113948	0.957880553084495	0.9637483566476596	0.8141496645505147	0.8101848415113948
mean	0.8089257333559502	0.7489959190506593	0.6812732337117444	0.8087305441335199	0.805000169180522	0.8089257333559502	0.9573760149863515	0.9636831414711764	0.8100330594297315	0.8089257333559502
std	0.006387636391309647	0.008696969832156003	0.016571874249510704	0.0067448702375117395	0.0071751387513412455	0.006387636391309647	0.0029148140207199197	0.0021652521788426134	0.007153960374722489	0.006387636391309647

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 30280.5447 secs

