/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_terminals_bilstm_attentio_cv_only_enz_hot_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7faf5028e610>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7faf5028e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7faf5028e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7faf5028e4c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.60      0.96      0.74       911
         1.0       0.85      0.64      0.73        53
         2.0       0.79      0.83      0.81       179
         3.0       0.35      0.28      0.31        25
         4.0       0.90      0.42      0.57       112
         5.0       0.87      0.54      0.66       491
         6.0       0.96      0.81      0.88        64
         7.0       0.90      0.24      0.38        37
         8.0       0.79      0.86      0.83       206
         9.0       0.64      0.75      0.69        71
        10.0       0.83      0.91      0.87       404
        11.0       0.89      0.50      0.64        16
        12.0       0.64      0.78      0.70       378
        13.0       0.90      0.71      0.79       191
        14.0       0.25      0.04      0.07        76
        15.0       0.75      0.68      0.71        66
        16.0       0.97      0.79      0.88       141
        17.0       0.66      0.80      0.72       182
        18.0       1.00      0.67      0.80        12
        19.0       0.94      0.89      0.92        38
        20.0       0.96      0.90      0.93      2162
        21.0       0.99      0.94      0.97       168
        22.0       0.94      0.75      0.84      1470
        23.0       0.91      0.82      0.86      1259
        24.0       0.96      0.82      0.89       956
        25.0       0.69      0.91      0.79       283
        26.0       0.82      0.91      0.86      3919
        27.0       0.96      0.92      0.94       531
        28.0       1.00      0.67      0.80        12
        29.0       0.81      0.74      0.77      2345
        30.0       0.67      0.72      0.69       615
        31.0       1.00      0.66      0.79        32
        32.0       0.73      0.80      0.77      1449
        33.0       0.80      0.83      0.81       893
        34.0       0.97      0.81      0.88      1377
        35.0       1.00      0.32      0.48        22
        36.0       0.94      0.75      0.84       844
        37.0       0.80      0.90      0.84      1142
        38.0       0.97      0.84      0.90       314
        39.0       0.96      0.39      0.56        56
        40.0       0.96      0.75      0.84       154
        41.0       0.89      0.90      0.90        52
        42.0       0.73      0.79      0.76       247
        43.0       0.91      0.79      0.85       198
        44.0       0.95      0.88      0.91       529
        45.0       0.78      0.92      0.84       540
        46.0       0.62      0.25      0.36        20
        47.0       0.77      0.69      0.73        80
        48.0       0.99      0.98      0.98      1466
        49.0       0.96      0.80      0.87       148
        50.0       0.84      0.97      0.90      1453
        51.0       0.46      0.50      0.48        12
        52.0       0.95      0.91      0.93       151
        53.0       0.93      0.96      0.94       903
        54.0       0.75      0.73      0.74       108
        55.0       0.76      0.96      0.85        93
        56.0       0.97      0.88      0.92        33
        57.0       0.81      0.88      0.84        49
        58.0       0.88      0.84      0.86       154

    accuracy                           0.84     29892
   macro avg       0.84      0.74      0.77     29892
weighted avg       0.86      0.84      0.84     29892


===confusion_matrix===

[[876   0   0 ...   0   0   0]
 [  3  34   0 ...   0   0   0]
 [  1   0 149 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   0]
 [  0   0   0 ...   0  43   1]
 [  0   0   0 ...   0   8 130]]

===multilabel confusion matrix===

[[[28398   583]
  [   35   876]]

 [[29833     6]
  [   19    34]]

 [[29674    39]
  [   30   149]]

 [[29854    13]
  [   18     7]]

 [[29775     5]
  [   65    47]]

 [[29360    41]
  [  227   264]]

 [[29826     2]
  [   12    52]]

 [[29854     1]
  [   28     9]]

 [[29640    46]
  [   28   178]]

 [[29791    30]
  [   18    53]]

 [[29412    76]
  [   35   369]]

 [[29875     1]
  [    8     8]]

 [[29348   166]
  [   82   296]]

 [[29686    15]
  [   56   135]]

 [[29807     9]
  [   73     3]]

 [[29811    15]
  [   21    45]]

 [[29748     3]
  [   29   112]]

 [[29636    74]
  [   37   145]]

 [[29880     0]
  [    4     8]]

 [[29852     2]
  [    4    34]]

 [[27641    89]
  [  209  1953]]

 [[29723     1]
  [   10   158]]

 [[28347    75]
  [  361  1109]]

 [[28532   101]
  [  227  1032]]

 [[28905    31]
  [  172   784]]

 [[29496   113]
  [   26   257]]

 [[25192   781]
  [  347  3572]]

 [[29339    22]
  [   43   488]]

 [[29880     0]
  [    4     8]]

 [[27140   407]
  [  614  1731]]

 [[29064   213]
  [  175   440]]

 [[29860     0]
  [   11    21]]

 [[28019   424]
  [  284  1165]]

 [[28810   189]
  [  149   744]]

 [[28475    40]
  [  259  1118]]

 [[29870     0]
  [   15     7]]

 [[29008    40]
  [  207   637]]

 [[28487   263]
  [  119  1023]]

 [[29569     9]
  [   51   263]]

 [[29835     1]
  [   34    22]]

 [[29733     5]
  [   39   115]]

 [[29834     6]
  [    5    47]]

 [[29573    72]
  [   52   195]]

 [[29678    16]
  [   41   157]]

 [[29338    25]
  [   62   467]]

 [[29210   142]
  [   44   496]]

 [[29869     3]
  [   15     5]]

 [[29796    16]
  [   25    55]]

 [[28406    20]
  [   35  1431]]

 [[29739     5]
  [   29   119]]

 [[28172   267]
  [   47  1406]]

 [[29873     7]
  [    6     6]]

 [[29734     7]
  [   14   137]]

 [[28923    66]
  [   38   865]]

 [[29758    26]
  [   29    79]]

 [[29771    28]
  [    4    89]]

 [[29858     1]
  [    4    29]]

 [[29833    10]
  [    6    43]]

 [[29721    17]
  [   24   130]]]

===scores report===
metrics	scores
Accuracy	0.8439
MCC	0.8359
log_loss	0.6449
f1 score weighted	0.8432
f1 score macro	0.7700
f1 score micro	0.8439
roc_auc ovr	0.9908
roc_auc ovo	0.9884
precision	0.8550
recall	0.8439

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7faf5028e610>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7faf5028e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7faf5028e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7faf5028e4c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.90      0.87       912
         1.0       0.97      0.70      0.81        53
         2.0       0.65      0.80      0.72       179
         3.0       0.67      0.24      0.35        25
         4.0       0.94      0.52      0.67       112
         5.0       0.76      0.75      0.76       492
         6.0       0.90      0.80      0.85        65
         7.0       1.00      0.26      0.42        38
         8.0       0.83      0.86      0.84       206
         9.0       0.76      0.72      0.74        71
        10.0       0.94      0.83      0.88       405
        11.0       0.90      0.53      0.67        17
        12.0       0.72      0.79      0.75       377
        13.0       0.91      0.74      0.82       191
        14.0       0.47      0.12      0.19        76
        15.0       0.80      0.56      0.66        66
        16.0       0.87      0.78      0.82       140
        17.0       0.81      0.79      0.80       182
        18.0       0.92      1.00      0.96        11
        19.0       1.00      0.84      0.91        37
        20.0       0.83      0.95      0.89      2163
        21.0       0.98      0.94      0.96       169
        22.0       0.92      0.74      0.82      1469
        23.0       0.93      0.83      0.88      1259
        24.0       0.95      0.87      0.91       956
        25.0       0.95      0.84      0.89       282
        26.0       0.89      0.89      0.89      3919
        27.0       0.93      0.93      0.93       531
        28.0       1.00      0.58      0.74        12
        29.0       0.78      0.81      0.79      2346
        30.0       0.49      0.81      0.61       615
        31.0       1.00      0.78      0.88        32
        32.0       0.76      0.77      0.77      1450
        33.0       0.76      0.81      0.79       893
        34.0       0.90      0.88      0.89      1376
        35.0       1.00      0.23      0.37        22
        36.0       0.85      0.79      0.82       843
        37.0       0.97      0.81      0.88      1142
        38.0       0.97      0.84      0.90       314
        39.0       0.91      0.55      0.69        56
        40.0       0.94      0.69      0.79       154
        41.0       1.00      0.90      0.95        52
        42.0       0.96      0.82      0.88       247
        43.0       0.93      0.80      0.86       198
        44.0       0.78      0.93      0.85       529
        45.0       0.97      0.88      0.92       539
        46.0       1.00      0.11      0.19        19
        47.0       0.76      0.65      0.70        80
        48.0       0.85      0.99      0.91      1466
        49.0       0.92      0.81      0.86       148
        50.0       0.87      0.95      0.91      1453
        51.0       1.00      0.08      0.15        12
        52.0       0.97      0.83      0.90       151
        53.0       0.97      0.93      0.95       903
        54.0       0.81      0.84      0.82       108
        55.0       0.82      0.99      0.90        93
        56.0       1.00      0.79      0.88        33
        57.0       0.89      0.82      0.85        49
        58.0       0.89      0.82      0.86       154

    accuracy                           0.85     29892
   macro avg       0.88      0.74      0.78     29892
weighted avg       0.86      0.85      0.85     29892


===confusion_matrix===

[[820   0   1 ...   0   0   0]
 [  0  37   5 ...   0   0   0]
 [  0   0 144 ...   0   0   0]
 ...
 [  0   0   0 ...  26   1   1]
 [  0   0   0 ...   0  40   8]
 [  0   0   0 ...   0   4 127]]

===multilabel confusion matrix===

[[[28830   150]
  [   92   820]]

 [[29838     1]
  [   16    37]]

 [[29637    76]
  [   35   144]]

 [[29864     3]
  [   19     6]]

 [[29776     4]
  [   54    58]]

 [[29283   117]
  [  121   371]]

 [[29821     6]
  [   13    52]]

 [[29854     0]
  [   28    10]]

 [[29650    36]
  [   29   177]]

 [[29805    16]
  [   20    51]]

 [[29467    20]
  [   69   336]]

 [[29874     1]
  [    8     9]]

 [[29397   118]
  [   80   297]]

 [[29687    14]
  [   49   142]]

 [[29806    10]
  [   67     9]]

 [[29817     9]
  [   29    37]]

 [[29736    16]
  [   31   109]]

 [[29677    33]
  [   38   144]]

 [[29880     1]
  [    0    11]]

 [[29855     0]
  [    6    31]]

 [[27307   422]
  [  101  2062]]

 [[29719     4]
  [   10   159]]

 [[28334    89]
  [  378  1091]]

 [[28555    78]
  [  211  1048]]

 [[28894    42]
  [  122   834]]

 [[29598    12]
  [   45   237]]

 [[25546   427]
  [  421  3498]]

 [[29324    37]
  [   36   495]]

 [[29880     0]
  [    5     7]]

 [[27017   529]
  [  452  1894]]

 [[28760   517]
  [  118   497]]

 [[29860     0]
  [    7    25]]

 [[28096   346]
  [  330  1120]]

 [[28776   223]
  [  169   724]]

 [[28382   134]
  [  163  1213]]

 [[29870     0]
  [   17     5]]

 [[28929   120]
  [  174   669]]

 [[28722    28]
  [  217   925]]

 [[29569     9]
  [   49   265]]

 [[29833     3]
  [   25    31]]

 [[29731     7]
  [   48   106]]

 [[29840     0]
  [    5    47]]

 [[29637     8]
  [   45   202]]

 [[29683    11]
  [   40   158]]

 [[29228   135]
  [   37   492]]

 [[29337    16]
  [   64   475]]

 [[29873     0]
  [   17     2]]

 [[29796    16]
  [   28    52]]

 [[28161   265]
  [   11  1455]]

 [[29733    11]
  [   28   120]]

 [[28241   198]
  [   69  1384]]

 [[29880     0]
  [   11     1]]

 [[29737     4]
  [   25   126]]

 [[28964    25]
  [   67   836]]

 [[29762    22]
  [   17    91]]

 [[29779    20]
  [    1    92]]

 [[29859     0]
  [    7    26]]

 [[29838     5]
  [    9    40]]

 [[29722    16]
  [   27   127]]]

===scores report===
metrics	scores
Accuracy	0.8525
MCC	0.8447
log_loss	0.5973
f1 score weighted	0.8523
f1 score macro	0.7787
f1 score micro	0.8525
roc_auc ovr	0.9915
roc_auc ovo	0.9897
precision	0.8619
recall	0.8525

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7faf5028e610>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7faf5028e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7faf5028e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7faf5028e4c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.85      0.88       912
         1.0       0.81      0.83      0.82        52
         2.0       0.88      0.70      0.78       179
         3.0       0.44      0.28      0.34        25
         4.0       0.47      0.54      0.50       112
         5.0       0.88      0.74      0.80       492
         6.0       0.68      0.88      0.77        65
         7.0       1.00      0.42      0.59        38
         8.0       0.95      0.78      0.85       205
         9.0       0.92      0.69      0.79        71
        10.0       0.73      0.92      0.81       405
        11.0       1.00      0.65      0.79        17
        12.0       0.90      0.70      0.79       377
        13.0       0.67      0.78      0.72       190
        14.0       0.50      0.01      0.03        76
        15.0       0.83      0.73      0.78        67
        16.0       0.97      0.80      0.88       140
        17.0       0.88      0.68      0.77       183
        18.0       0.85      0.92      0.88        12
        19.0       0.92      0.89      0.90        37
        20.0       0.93      0.91      0.92      2162
        21.0       0.98      0.94      0.96       169
        22.0       0.65      0.88      0.75      1470
        23.0       0.91      0.86      0.88      1259
        24.0       0.93      0.91      0.92       956
        25.0       0.81      0.94      0.87       282
        26.0       0.95      0.85      0.90      3918
        27.0       0.99      0.89      0.94       531
        28.0       0.92      0.92      0.92        13
        29.0       0.78      0.77      0.78      2346
        30.0       0.72      0.66      0.69       615
        31.0       0.96      0.75      0.84        32
        32.0       0.64      0.85      0.73      1450
        33.0       0.58      0.88      0.70       893
        34.0       0.96      0.84      0.90      1376
        35.0       0.75      0.68      0.71        22
        36.0       0.89      0.82      0.85       843
        37.0       0.93      0.86      0.89      1142
        38.0       0.95      0.91      0.93       314
        39.0       0.70      0.51      0.59        55
        40.0       0.97      0.69      0.81       154
        41.0       1.00      0.87      0.93        52
        42.0       0.99      0.74      0.85       247
        43.0       0.88      0.87      0.87       197
        44.0       0.96      0.89      0.92       530
        45.0       0.95      0.89      0.91       540
        46.0       1.00      0.16      0.27        19
        47.0       0.90      0.67      0.77        79
        48.0       0.93      0.99      0.96      1465
        49.0       0.90      0.89      0.89       149
        50.0       0.92      0.94      0.93      1453
        51.0       0.60      0.25      0.35        12
        52.0       0.98      0.85      0.91       152
        53.0       0.93      0.93      0.93       903
        54.0       0.75      0.74      0.74       108
        55.0       1.00      0.76      0.87        93
        56.0       0.97      0.88      0.92        32
        57.0       0.89      0.94      0.91        50
        58.0       0.82      0.86      0.84       154

    accuracy                           0.85     29892
   macro avg       0.85      0.77      0.79     29892
weighted avg       0.87      0.85      0.85     29892


===confusion_matrix===

[[779   0   0 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  0   0 126 ...   0   0   0]
 ...
 [  0   0   0 ...  28   2   2]
 [  0   0   0 ...   0  47   3]
 [  0   0   0 ...   0   2 133]]

===multilabel confusion matrix===

[[[28897    83]
  [  133   779]]

 [[29830    10]
  [    9    43]]

 [[29696    17]
  [   53   126]]

 [[29858     9]
  [   18     7]]

 [[29712    68]
  [   52    60]]

 [[29349    51]
  [  127   365]]

 [[29800    27]
  [    8    57]]

 [[29854     0]
  [   22    16]]

 [[29678     9]
  [   46   159]]

 [[29817     4]
  [   22    49]]

 [[29346   141]
  [   33   372]]

 [[29875     0]
  [    6    11]]

 [[29486    29]
  [  112   265]]

 [[29629    73]
  [   42   148]]

 [[29815     1]
  [   75     1]]

 [[29815    10]
  [   18    49]]

 [[29749     3]
  [   28   112]]

 [[29692    17]
  [   59   124]]

 [[29878     2]
  [    1    11]]

 [[29852     3]
  [    4    33]]

 [[27585   145]
  [  196  1966]]

 [[29720     3]
  [   10   159]]

 [[27717   705]
  [  176  1294]]

 [[28520   113]
  [  173  1086]]

 [[28871    65]
  [   90   866]]

 [[29549    61]
  [   18   264]]

 [[25797   177]
  [  586  3332]]

 [[29357     4]
  [   60   471]]

 [[29878     1]
  [    1    12]]

 [[27043   503]
  [  537  1809]]

 [[29117   160]
  [  211   404]]

 [[29859     1]
  [    8    24]]

 [[27761   681]
  [  214  1236]]

 [[28423   576]
  [  104   789]]

 [[28466    50]
  [  215  1161]]

 [[29865     5]
  [    7    15]]

 [[28967    82]
  [  155   688]]

 [[28672    78]
  [  161   981]]

 [[29564    14]
  [   27   287]]

 [[29825    12]
  [   27    28]]

 [[29735     3]
  [   48   106]]

 [[29840     0]
  [    7    45]]

 [[29643     2]
  [   63   184]]

 [[29672    23]
  [   26   171]]

 [[29343    19]
  [   59   471]]

 [[29325    27]
  [   62   478]]

 [[29873     0]
  [   16     3]]

 [[29807     6]
  [   26    53]]

 [[28311   116]
  [   12  1453]]

 [[29728    15]
  [   17   132]]

 [[28325   114]
  [   91  1362]]

 [[29878     2]
  [    9     3]]

 [[29738     2]
  [   23   129]]

 [[28927    62]
  [   66   837]]

 [[29757    27]
  [   28    80]]

 [[29799     0]
  [   22    71]]

 [[29859     1]
  [    4    28]]

 [[29836     6]
  [    3    47]]

 [[29709    29]
  [   21   133]]]

===scores report===
metrics	scores
Accuracy	0.8512
MCC	0.8439
log_loss	0.6210
f1 score weighted	0.8532
f1 score macro	0.7920
f1 score micro	0.8512
roc_auc ovr	0.9914
roc_auc ovo	0.9899
precision	0.8664
recall	0.8512

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7faf5028e610>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7faf5028e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7faf5028e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7faf5028e4c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.76      0.79       912
         1.0       0.91      0.75      0.82        52
         2.0       0.59      0.38      0.46       179
         3.0       0.00      0.00      0.00        24
         4.0       0.20      0.02      0.03       112
         5.0       0.71      0.47      0.56       492
         6.0       0.56      0.78      0.65        64
         7.0       0.00      0.00      0.00        38
         8.0       0.99      0.66      0.79       205
         9.0       0.80      0.40      0.53        70
        10.0       0.96      0.66      0.78       405
        11.0       0.00      0.00      0.00        17
        12.0       0.68      0.56      0.62       378
        13.0       0.96      0.52      0.67       191
        14.0       0.00      0.00      0.00        76
        15.0       0.82      0.34      0.48        67
        16.0       0.61      0.50      0.55       140
        17.0       0.70      0.50      0.58       183
        18.0       1.00      0.50      0.67        12
        19.0       0.90      0.97      0.94        37
        20.0       0.96      0.84      0.89      2162
        21.0       0.84      0.88      0.86       168
        22.0       0.49      0.80      0.61      1470
        23.0       0.62      0.83      0.71      1259
        24.0       0.91      0.83      0.87       955
        25.0       0.87      0.74      0.80       282
        26.0       0.95      0.78      0.86      3918
        27.0       0.99      0.76      0.86       532
        28.0       1.00      0.31      0.47        13
        29.0       0.72      0.62      0.67      2346
        30.0       0.57      0.61      0.59       616
        31.0       0.96      0.75      0.84        32
        32.0       0.67      0.69      0.68      1449
        33.0       0.53      0.60      0.57       893
        34.0       0.85      0.82      0.84      1377
        35.0       0.00      0.00      0.00        22
        36.0       0.53      0.72      0.61       844
        37.0       0.36      0.91      0.52      1142
        38.0       0.93      0.74      0.82       314
        39.0       0.90      0.34      0.49        56
        40.0       0.85      0.61      0.71       153
        41.0       1.00      0.59      0.74        51
        42.0       0.80      0.63      0.71       246
        43.0       0.97      0.78      0.86       197
        44.0       0.78      0.81      0.79       530
        45.0       0.99      0.69      0.81       540
        46.0       0.00      0.00      0.00        20
        47.0       0.96      0.28      0.43        80
        48.0       0.99      0.93      0.96      1465
        49.0       0.73      0.64      0.68       148
        50.0       0.99      0.76      0.86      1453
        51.0       0.00      0.00      0.00        13
        52.0       1.00      0.68      0.81       151
        53.0       0.85      0.95      0.90       904
        54.0       0.66      0.44      0.53       108
        55.0       0.91      0.78      0.84        93
        56.0       0.97      0.88      0.92        33
        57.0       0.97      0.70      0.81        50
        58.0       0.64      0.92      0.76       153

    accuracy                           0.74     29892
   macro avg       0.71      0.58      0.62     29892
weighted avg       0.79      0.74      0.75     29892


===confusion_matrix===

[[697   0   0 ...   0   0   0]
 [  0  39   0 ...   0   0   0]
 [  2   0  68 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   2]
 [  0   0   0 ...   1  35  13]
 [  0   0   0 ...   0   1 141]]

===multilabel confusion matrix===

[[[28819   161]
  [  215   697]]

 [[29836     4]
  [   13    39]]

 [[29665    48]
  [  111    68]]

 [[29868     0]
  [   24     0]]

 [[29772     8]
  [  110     2]]

 [[29305    95]
  [  263   229]]

 [[29788    40]
  [   14    50]]

 [[29853     1]
  [   38     0]]

 [[29685     2]
  [   70   135]]

 [[29815     7]
  [   42    28]]

 [[29475    12]
  [  137   268]]

 [[29875     0]
  [   17     0]]

 [[29416    98]
  [  165   213]]

 [[29697     4]
  [   92    99]]

 [[29816     0]
  [   76     0]]

 [[29820     5]
  [   44    23]]

 [[29707    45]
  [   70    70]]

 [[29669    40]
  [   91    92]]

 [[29880     0]
  [    6     6]]

 [[29851     4]
  [    1    36]]

 [[27647    83]
  [  344  1818]]

 [[29697    27]
  [   21   147]]

 [[27214  1208]
  [  294  1176]]

 [[27999   634]
  [  213  1046]]

 [[28860    77]
  [  164   791]]

 [[29578    32]
  [   73   209]]

 [[25826   148]
  [  861  3057]]

 [[29357     3]
  [  130   402]]

 [[29879     0]
  [    9     4]]

 [[26992   554]
  [  896  1450]]

 [[28991   285]
  [  242   374]]

 [[29859     1]
  [    8    24]]

 [[27946   497]
  [  448  1001]]

 [[28528   471]
  [  353   540]]

 [[28321   194]
  [  248  1129]]

 [[29869     1]
  [   22     0]]

 [[28500   548]
  [  238   606]]

 [[26942  1808]
  [  106  1036]]

 [[29561    17]
  [   82   232]]

 [[29834     2]
  [   37    19]]

 [[29722    17]
  [   59    94]]

 [[29841     0]
  [   21    30]]

 [[29608    38]
  [   91   155]]

 [[29691     4]
  [   44   153]]

 [[29238   124]
  [   99   431]]

 [[29349     3]
  [  169   371]]

 [[29872     0]
  [   20     0]]

 [[29811     1]
  [   58    22]]

 [[28416    11]
  [  109  1356]]

 [[29709    35]
  [   54    94]]

 [[28423    16]
  [  342  1111]]

 [[29879     0]
  [   13     0]]

 [[29741     0]
  [   49   102]]

 [[28841   147]
  [   44   860]]

 [[29760    24]
  [   61    47]]

 [[29792     7]
  [   20    73]]

 [[29858     1]
  [    4    29]]

 [[29841     1]
  [   15    35]]

 [[29660    79]
  [   12   141]]]

===scores report===
metrics	scores
Accuracy	0.7433
MCC	0.7321
log_loss	1.0116
f1 score weighted	0.7506
f1 score macro	0.6204
f1 score micro	0.7433
roc_auc ovr	0.9797
roc_auc ovo	0.9760
precision	0.7881
recall	0.7433

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7faf5028e610>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7faf5028e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7faf5028e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7faf5028e4c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.88      0.88       911
         1.0       0.98      0.77      0.86        53
         2.0       0.98      0.78      0.87       180
         3.0       0.86      0.24      0.38        25
         4.0       0.78      0.50      0.61       111
         5.0       0.86      0.62      0.72       491
         6.0       0.86      0.86      0.86        64
         7.0       0.73      0.22      0.33        37
         8.0       0.91      0.87      0.89       205
         9.0       0.90      0.76      0.82        71
        10.0       0.93      0.88      0.90       404
        11.0       0.80      0.24      0.36        17
        12.0       0.89      0.80      0.84       378
        13.0       0.87      0.80      0.83       191
        14.0       0.71      0.07      0.12        76
        15.0       0.83      0.59      0.69        66
        16.0       0.85      0.83      0.84       140
        17.0       0.88      0.73      0.80       182
        18.0       0.71      1.00      0.83        12
        19.0       0.86      0.68      0.76        37
        20.0       0.87      0.95      0.91      2162
        21.0       0.93      0.96      0.94       168
        22.0       0.85      0.82      0.84      1470
        23.0       0.88      0.86      0.87      1259
        24.0       0.95      0.89      0.92       955
        25.0       0.81      0.93      0.87       283
        26.0       0.89      0.89      0.89      3919
        27.0       0.94      0.93      0.94       532
        28.0       0.92      0.92      0.92        13
        29.0       0.70      0.85      0.77      2345
        30.0       0.69      0.70      0.70       616
        31.0       0.96      0.81      0.88        32
        32.0       0.86      0.74      0.80      1449
        33.0       0.76      0.83      0.79       893
        34.0       0.95      0.85      0.90      1377
        35.0       0.94      0.68      0.79        22
        36.0       0.85      0.86      0.85       844
        37.0       0.82      0.91      0.86      1142
        38.0       0.93      0.89      0.91       314
        39.0       0.88      0.54      0.67        56
        40.0       0.95      0.75      0.84       153
        41.0       0.98      0.88      0.93        52
        42.0       0.88      0.77      0.82       247
        43.0       0.93      0.83      0.88       197
        44.0       0.89      0.89      0.89       529
        45.0       0.87      0.93      0.90       540
        46.0       1.00      0.15      0.26        20
        47.0       0.91      0.76      0.83        80
        48.0       0.95      0.99      0.97      1466
        49.0       0.92      0.86      0.89       148
        50.0       0.89      0.96      0.92      1453
        51.0       0.50      0.08      0.14        12
        52.0       0.91      0.85      0.88       151
        53.0       0.96      0.96      0.96       904
        54.0       0.94      0.71      0.81       108
        55.0       0.94      0.89      0.92        93
        56.0       0.88      0.88      0.88        33
        57.0       0.77      0.98      0.86        50
        58.0       0.89      0.82      0.85       154

    accuracy                           0.86     29892
   macro avg       0.87      0.76      0.79     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[800   0   0 ...   0   0   0]
 [  0  41   0 ...   0   0   0]
 [  0   0 141 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   0]
 [  0   0   0 ...   0  49   0]
 [  0   0   0 ...   2   8 126]]

===multilabel confusion matrix===

[[[28871   110]
  [  111   800]]

 [[29838     1]
  [   12    41]]

 [[29709     3]
  [   39   141]]

 [[29866     1]
  [   19     6]]

 [[29765    16]
  [   55    56]]

 [[29353    48]
  [  187   304]]

 [[29819     9]
  [    9    55]]

 [[29852     3]
  [   29     8]]

 [[29670    17]
  [   27   178]]

 [[29815     6]
  [   17    54]]

 [[29461    27]
  [   50   354]]

 [[29874     1]
  [   13     4]]

 [[29475    39]
  [   76   302]]

 [[29679    22]
  [   39   152]]

 [[29814     2]
  [   71     5]]

 [[29818     8]
  [   27    39]]

 [[29732    20]
  [   24   116]]

 [[29692    18]
  [   49   133]]

 [[29875     5]
  [    0    12]]

 [[29851     4]
  [   12    25]]

 [[27412   318]
  [  112  2050]]

 [[29711    13]
  [    6   162]]

 [[28209   213]
  [  263  1207]]

 [[28486   147]
  [  177  1082]]

 [[28895    42]
  [  108   847]]

 [[29549    60]
  [   21   262]]

 [[25537   436]
  [  417  3502]]

 [[29329    31]
  [   36   496]]

 [[29878     1]
  [    1    12]]

 [[26673   874]
  [  345  2000]]

 [[29085   191]
  [  185   431]]

 [[29859     1]
  [    6    26]]

 [[28268   175]
  [  377  1072]]

 [[28765   234]
  [  150   743]]

 [[28457    58]
  [  211  1166]]

 [[29869     1]
  [    7    15]]

 [[28916   132]
  [  119   725]]

 [[28518   232]
  [  103  1039]]

 [[29556    22]
  [   35   279]]

 [[29832     4]
  [   26    30]]

 [[29733     6]
  [   39   114]]

 [[29839     1]
  [    6    46]]

 [[29619    26]
  [   56   191]]

 [[29683    12]
  [   33   164]]

 [[29306    57]
  [   59   470]]

 [[29278    74]
  [   40   500]]

 [[29872     0]
  [   17     3]]

 [[29806     6]
  [   19    61]]

 [[28343    83]
  [   21  1445]]

 [[29733    11]
  [   20   128]]

 [[28269   170]
  [   63  1390]]

 [[29879     1]
  [   11     1]]

 [[29729    12]
  [   22   129]]

 [[28952    36]
  [   33   871]]

 [[29779     5]
  [   31    77]]

 [[29794     5]
  [   10    83]]

 [[29855     4]
  [    4    29]]

 [[29827    15]
  [    1    49]]

 [[29723    15]
  [   28   126]]]

===scores report===
metrics	scores
Accuracy	0.8634
MCC	0.8561
log_loss	0.5590
f1 score weighted	0.8615
f1 score macro	0.7904
f1 score micro	0.8634
roc_auc ovr	0.9920
roc_auc ovo	0.9903
precision	0.8674
recall	0.8634

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8439381774387796	0.8358547245209228	0.6449296631612059	0.8431744438633226	0.7700169321961607	0.8439381774387797	0.9908018717810755	0.9883724449709976	0.8550338948121666	0.8439381774387796
1	0.8524688879967884	0.8447128818625289	0.5973401198145495	0.8522854100245929	0.778665276123131	0.8524688879967883	0.9915262599517707	0.9897110789985532	0.8618797685091212	0.8524688879967884
2	0.8512310986217048	0.8438625494657593	0.6209637055054757	0.8532010600173515	0.7920054694620217	0.8512310986217048	0.991433458931102	0.9898615074290679	0.866432989931394	0.8512310986217048
3	0.7433427003880637	0.7321307814984822	1.0115557098039578	0.7506221329172967	0.620385772543769	0.7433427003880637	0.9796971143518244	0.9759889719107264	0.7880770483767344	0.7433427003880637
4	0.8633748160042821	0.8560700931176302	0.5590151134735206	0.8615137019021265	0.7904065375955003	0.8633748160042821	0.9919944657116254	0.990336956425078	0.86735275343928	0.8633748160042821
mean	0.8308711360899237	0.8225262060930646	0.6867608623517419	0.832159349744938	0.7502959975841165	0.8308711360899237	0.9890906341454796	0.9868541919468846	0.8477552910137393	0.8308711360899237
std	0.04420283881319937	0.04565449085917019	0.16485499904985537	0.04118043198066623	0.06545064287105057	0.04420283881319937	0.004712109658490872	0.005471626762221597	0.030155890145682297	0.04420283881319937

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 61132.5713 secs

