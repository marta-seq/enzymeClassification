/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_hot_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff330290460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff330290310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3302907f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff3302907c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.58      0.82      0.68       358
         1.0       0.21      0.25      0.23        12
         2.0       0.56      0.53      0.54        19
         3.0       0.49      0.56      0.52        80
         4.0       0.26      0.39      0.31        54
         5.0       0.27      0.14      0.18        58
         6.0       0.31      0.09      0.14        45
         7.0       0.75      0.50      0.60        48
         8.0       0.00      0.00      0.00        11
         9.0       0.71      0.24      0.36        21
        10.0       0.50      0.07      0.12        15
        11.0       0.57      0.72      0.63        36
        12.0       0.86      0.50      0.63        12
        13.0       0.70      0.84      0.76        25
        14.0       0.67      0.11      0.18        19
        15.0       0.75      0.55      0.63        22
        16.0       0.61      0.61      0.61        23
        17.0       0.85      0.87      0.86       119
        18.0       0.69      0.61      0.65        18
        19.0       0.00      0.00      0.00        12
        20.0       0.46      0.42      0.44        90
        21.0       0.67      0.33      0.44        12
        22.0       0.56      0.88      0.69        25
        23.0       0.00      0.00      0.00        12
        24.0       0.31      0.18      0.23        22
        25.0       0.43      0.47      0.45        38
        26.0       0.94      0.94      0.94        17
        27.0       0.30      0.09      0.13        35
        28.0       0.50      0.09      0.15        11
        29.0       0.62      0.64      0.63        36
        30.0       0.62      0.72      0.67        32
        31.0       0.47      0.82      0.60        38
        32.0       0.87      0.79      0.83       747
        33.0       0.88      0.81      0.85        74
        34.0       0.83      0.92      0.87        59
        35.0       0.80      0.73      0.76        48
        36.0       0.72      0.67      0.69       502
        37.0       0.60      0.74      0.66       241
        38.0       0.68      0.58      0.62        33
        39.0       0.74      0.64      0.69       344
        40.0       0.93      0.62      0.74       191
        41.0       0.73      0.50      0.59        32
        42.0       0.73      0.78      0.75       384
        43.0       0.79      0.75      0.77       118
        44.0       0.60      0.78      0.68       436
        45.0       0.97      0.79      0.87        48
        46.0       0.82      0.85      0.84       402
        47.0       1.00      0.12      0.21        17
        48.0       0.62      0.57      0.59        42
        49.0       0.90      0.88      0.89        78
        50.0       0.86      0.86      0.86       172
        51.0       1.00      0.55      0.71        20
        52.0       0.68      0.70      0.69       499
        53.0       0.90      0.73      0.81       100
        54.0       0.14      0.09      0.11        11
        55.0       0.74      0.82      0.77       103
        56.0       0.62      0.28      0.38        18
        57.0       0.29      0.20      0.24        10
        58.0       0.82      0.97      0.89        34
        59.0       0.62      0.66      0.64       231
        60.0       0.88      0.64      0.74        58
        61.0       0.00      0.00      0.00        30
        62.0       0.66      0.52      0.58        48
        63.0       0.22      0.18      0.20        50
        64.0       1.00      0.59      0.74        34
        65.0       0.91      0.66      0.77       155
        66.0       0.50      0.29      0.36        14
        67.0       0.55      0.65      0.59       314
        68.0       0.33      0.06      0.11        63
        69.0       0.48      0.73      0.58       308
        70.0       0.53      0.46      0.49        68
        71.0       0.51      0.36      0.42        66
        72.0       0.00      0.00      0.00        14
        73.0       0.70      0.28      0.40        25
        74.0       0.00      0.00      0.00        18
        75.0       0.28      0.33      0.31        60
        76.0       0.54      0.72      0.62       205
        77.0       0.45      0.26      0.33        77
        78.0       0.73      0.78      0.75        59
        79.0       0.59      0.59      0.59       139
        80.0       0.75      0.64      0.69        42
        81.0       0.37      0.54      0.44       175
        82.0       0.60      0.35      0.44        43
        83.0       0.53      0.31      0.39        26
        84.0       0.48      0.48      0.48       106
        85.0       0.57      0.57      0.57        14
        86.0       0.57      0.72      0.64       242
        87.0       0.81      0.80      0.80       309
        88.0       0.69      0.60      0.64        58
        89.0       0.33      0.09      0.14        11
        90.0       0.77      0.51      0.62       187
        91.0       0.57      0.26      0.36        46
        92.0       0.00      0.00      0.00        40
        93.0       0.62      0.66      0.64        32
        94.0       0.56      0.70      0.62       289
        95.0       0.33      0.03      0.06        31
        96.0       0.96      0.66      0.78        74
        97.0       0.61      0.41      0.49        27
        98.0       0.81      0.57      0.67        37
        99.0       0.79      0.92      0.85        24
       100.0       0.00      0.00      0.00        25
       101.0       0.79      0.42      0.55        65
       102.0       0.74      0.64      0.68        22
       103.0       0.80      0.75      0.77        64
       104.0       0.50      0.40      0.44        40
       105.0       1.00      0.83      0.91        12
       106.0       0.78      0.80      0.79       114
       107.0       0.80      0.84      0.82       161
       108.0       0.56      0.42      0.48        24
       109.0       0.74      0.65      0.69        52
       110.0       0.86      0.80      0.83        15
       111.0       0.81      0.58      0.67       123
       112.0       0.83      0.45      0.58        42
       113.0       0.90      0.88      0.89       430
       114.0       0.62      0.77      0.68        65
       115.0       0.65      0.55      0.60        31
       116.0       0.69      0.78      0.73       173
       117.0       0.78      0.94      0.85        31
       118.0       0.82      0.83      0.82       117
       119.0       0.61      0.88      0.72       136
       120.0       0.90      0.58      0.71        62
       121.0       0.70      0.88      0.78       224
       122.0       0.79      0.77      0.78        35
       123.0       0.81      0.70      0.75        37
       124.0       0.80      0.39      0.52        31
       125.0       0.80      0.80      0.80        15
       126.0       0.93      0.62      0.74        21
       127.0       0.63      0.95      0.76        73

    accuracy                           0.68     12227
   macro avg       0.62      0.54      0.56     12227
weighted avg       0.68      0.68      0.67     12227


===confusion_matrix===

[[294   1   0 ...   0   0   0]
 [  2   3   0 ...   0   0   0]
 [  0   0  10 ...   0   0   0]
 ...
 [  0   0   0 ...  12   1   1]
 [  0   0   0 ...   0  13   8]
 [  0   0   0 ...   0   0  69]]

===multilabel confusion matrix===

[[[11653   216]
  [   64   294]]

 [[12204    11]
  [    9     3]]

 [[12200     8]
  [    9    10]]

 [[12100    47]
  [   35    45]]

 [[12112    61]
  [   33    21]]

 [[12147    22]
  [   50     8]]

 [[12173     9]
  [   41     4]]

 [[12171     8]
  [   24    24]]

 [[12216     0]
  [   11     0]]

 [[12204     2]
  [   16     5]]

 [[12211     1]
  [   14     1]]

 [[12171    20]
  [   10    26]]

 [[12214     1]
  [    6     6]]

 [[12193     9]
  [    4    21]]

 [[12207     1]
  [   17     2]]

 [[12201     4]
  [   10    12]]

 [[12195     9]
  [    9    14]]

 [[12089    19]
  [   15   104]]

 [[12204     5]
  [    7    11]]

 [[12213     2]
  [   12     0]]

 [[12092    45]
  [   52    38]]

 [[12213     2]
  [    8     4]]

 [[12185    17]
  [    3    22]]

 [[12211     4]
  [   12     0]]

 [[12196     9]
  [   18     4]]

 [[12165    24]
  [   20    18]]

 [[12209     1]
  [    1    16]]

 [[12185     7]
  [   32     3]]

 [[12215     1]
  [   10     1]]

 [[12177    14]
  [   13    23]]

 [[12181    14]
  [    9    23]]

 [[12154    35]
  [    7    31]]

 [[11392    88]
  [  158   589]]

 [[12145     8]
  [   14    60]]

 [[12157    11]
  [    5    54]]

 [[12170     9]
  [   13    35]]

 [[11592   133]
  [  165   337]]

 [[11866   120]
  [   63   178]]

 [[12185     9]
  [   14    19]]

 [[11806    77]
  [  124   220]]

 [[12027     9]
  [   73   118]]

 [[12189     6]
  [   16    16]]

 [[11730   113]
  [   85   299]]

 [[12086    23]
  [   29    89]]

 [[11566   225]
  [   96   340]]

 [[12178     1]
  [   10    38]]

 [[11752    73]
  [   59   343]]

 [[12210     0]
  [   15     2]]

 [[12170    15]
  [   18    24]]

 [[12141     8]
  [    9    69]]

 [[12031    24]
  [   24   148]]

 [[12207     0]
  [    9    11]]

 [[11567   161]
  [  150   349]]

 [[12119     8]
  [   27    73]]

 [[12210     6]
  [   10     1]]

 [[12094    30]
  [   19    84]]

 [[12206     3]
  [   13     5]]

 [[12212     5]
  [    8     2]]

 [[12186     7]
  [    1    33]]

 [[11904    92]
  [   78   153]]

 [[12164     5]
  [   21    37]]

 [[12197     0]
  [   30     0]]

 [[12166    13]
  [   23    25]]

 [[12145    32]
  [   41     9]]

 [[12193     0]
  [   14    20]]

 [[12062    10]
  [   52   103]]

 [[12209     4]
  [   10     4]]

 [[11745   168]
  [  111   203]]

 [[12156     8]
  [   59     4]]

 [[11670   249]
  [   82   226]]

 [[12131    28]
  [   37    31]]

 [[12138    23]
  [   42    24]]

 [[12213     0]
  [   14     0]]

 [[12199     3]
  [   18     7]]

 [[12208     1]
  [   18     0]]

 [[12116    51]
  [   40    20]]

 [[11899   123]
  [   58   147]]

 [[12126    24]
  [   57    20]]

 [[12151    17]
  [   13    46]]

 [[12031    57]
  [   57    82]]

 [[12176     9]
  [   15    27]]

 [[11893   159]
  [   80    95]]

 [[12174    10]
  [   28    15]]

 [[12194     7]
  [   18     8]]

 [[12065    56]
  [   55    51]]

 [[12207     6]
  [    6     8]]

 [[11856   129]
  [   68   174]]

 [[11859    59]
  [   62   247]]

 [[12153    16]
  [   23    35]]

 [[12214     2]
  [   10     1]]

 [[12012    28]
  [   91    96]]

 [[12172     9]
  [   34    12]]

 [[12182     5]
  [   40     0]]

 [[12182    13]
  [   11    21]]

 [[11782   156]
  [   87   202]]

 [[12194     2]
  [   30     1]]

 [[12151     2]
  [   25    49]]

 [[12193     7]
  [   16    11]]

 [[12185     5]
  [   16    21]]

 [[12197     6]
  [    2    22]]

 [[12202     0]
  [   25     0]]

 [[12155     7]
  [   38    27]]

 [[12200     5]
  [    8    14]]

 [[12151    12]
  [   16    48]]

 [[12171    16]
  [   24    16]]

 [[12215     0]
  [    2    10]]

 [[12088    25]
  [   23    91]]

 [[12032    34]
  [   26   135]]

 [[12195     8]
  [   14    10]]

 [[12163    12]
  [   18    34]]

 [[12210     2]
  [    3    12]]

 [[12087    17]
  [   52    71]]

 [[12181     4]
  [   23    19]]

 [[11756    41]
  [   51   379]]

 [[12131    31]
  [   15    50]]

 [[12187     9]
  [   14    17]]

 [[11992    62]
  [   38   135]]

 [[12188     8]
  [    2    29]]

 [[12088    22]
  [   20    97]]

 [[12015    76]
  [   17   119]]

 [[12161     4]
  [   26    36]]

 [[11918    85]
  [   26   198]]

 [[12185     7]
  [    8    27]]

 [[12184     6]
  [   11    26]]

 [[12193     3]
  [   19    12]]

 [[12209     3]
  [    3    12]]

 [[12205     1]
  [    8    13]]

 [[12114    40]
  [    4    69]]]

===scores report===
metrics	scores
Accuracy	0.6783
MCC	0.6713
log_loss	1.4598
f1 score weighted	0.6690
f1 score macro	0.5570
f1 score micro	0.6783
roc_auc ovr	0.9745
roc_auc ovo	0.9713
precision	0.6825
recall	0.6783

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff330290460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff330290310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3302907f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff3302907c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.48      0.88      0.62       357
         1.0       0.27      0.50      0.35        12
         2.0       0.62      0.42      0.50        19
         3.0       0.39      0.56      0.46        80
         4.0       0.25      0.13      0.17        54
         5.0       0.00      0.00      0.00        58
         6.0       0.41      0.16      0.23        44
         7.0       0.94      0.31      0.47        48
         8.0       0.00      0.00      0.00        11
         9.0       0.50      0.05      0.09        21
        10.0       0.00      0.00      0.00        15
        11.0       0.78      0.69      0.74        36
        12.0       0.00      0.00      0.00        12
        13.0       0.86      0.48      0.62        25
        14.0       0.00      0.00      0.00        20
        15.0       0.88      0.65      0.75        23
        16.0       0.53      0.43      0.48        23
        17.0       0.91      0.66      0.76       119
        18.0       0.75      0.18      0.29        17
        19.0       0.00      0.00      0.00        13
        20.0       0.53      0.09      0.15        90
        21.0       0.00      0.00      0.00        12
        22.0       0.83      0.60      0.70        25
        23.0       0.25      0.08      0.12        12
        24.0       0.40      0.09      0.15        22
        25.0       0.36      0.54      0.43        37
        26.0       1.00      0.94      0.97        18
        27.0       0.00      0.00      0.00        35
        28.0       0.00      0.00      0.00        12
        29.0       0.67      0.11      0.19        37
        30.0       0.83      0.59      0.69        32
        31.0       0.52      0.74      0.61        39
        32.0       0.90      0.79      0.84       746
        33.0       1.00      0.74      0.85        74
        34.0       1.00      0.81      0.90        58
        35.0       0.62      0.48      0.54        48
        36.0       0.90      0.49      0.64       502
        37.0       0.77      0.59      0.66       241
        38.0       0.73      0.67      0.70        33
        39.0       0.52      0.59      0.55       344
        40.0       0.90      0.59      0.72       191
        41.0       1.00      0.45      0.62        31
        42.0       0.94      0.59      0.72       384
        43.0       0.88      0.81      0.84       118
        44.0       0.65      0.72      0.68       436
        45.0       0.89      0.81      0.85        48
        46.0       0.89      0.78      0.83       402
        47.0       0.80      0.24      0.36        17
        48.0       0.79      0.36      0.49        42
        49.0       0.97      0.81      0.88        77
        50.0       0.90      0.82      0.86       172
        51.0       0.83      0.75      0.79        20
        52.0       0.79      0.53      0.63       499
        53.0       0.96      0.51      0.66        99
        54.0       0.00      0.00      0.00        11
        55.0       0.84      0.73      0.78       103
        56.0       0.71      0.28      0.40        18
        57.0       0.50      0.09      0.15        11
        58.0       1.00      0.91      0.95        34
        59.0       0.28      0.73      0.41       231
        60.0       1.00      0.41      0.59        58
        61.0       0.00      0.00      0.00        30
        62.0       0.60      0.25      0.35        48
        63.0       0.20      0.06      0.09        49
        64.0       0.92      0.65      0.76        34
        65.0       0.91      0.67      0.77       154
        66.0       0.00      0.00      0.00        14
        67.0       0.59      0.53      0.56       314
        68.0       0.03      0.02      0.02        63
        69.0       0.19      0.86      0.31       308
        70.0       0.69      0.16      0.26        69
        71.0       0.28      0.42      0.34        66
        72.0       0.00      0.00      0.00        14
        73.0       0.67      0.40      0.50        25
        74.0       0.00      0.00      0.00        18
        75.0       0.11      0.02      0.03        59
        76.0       0.44      0.67      0.53       205
        77.0       0.14      0.16      0.15        77
        78.0       0.51      0.39      0.44        59
        79.0       0.50      0.43      0.46       139
        80.0       0.95      0.51      0.67        41
        81.0       0.19      0.41      0.26       175
        82.0       0.50      0.33      0.39        43
        83.0       0.00      0.00      0.00        26
        84.0       0.85      0.16      0.27       105
        85.0       0.50      0.07      0.12        14
        86.0       0.35      0.78      0.48       242
        87.0       0.93      0.69      0.79       309
        88.0       0.52      0.60      0.56        58
        89.0       0.00      0.00      0.00        11
        90.0       0.86      0.23      0.36       187
        91.0       0.60      0.26      0.36        46
        92.0       0.50      0.05      0.09        40
        93.0       1.00      0.33      0.50        33
        94.0       0.51      0.62      0.56       289
        95.0       0.00      0.00      0.00        32
        96.0       0.90      0.51      0.66        74
        97.0       0.42      0.30      0.35        27
        98.0       0.90      0.49      0.63        37
        99.0       0.95      0.79      0.86        24
       100.0       0.00      0.00      0.00        26
       101.0       0.78      0.22      0.34        65
       102.0       0.92      0.55      0.69        22
       103.0       0.95      0.61      0.74        64
       104.0       0.52      0.30      0.38        40
       105.0       1.00      0.62      0.76        13
       106.0       0.74      0.77      0.76       113
       107.0       0.82      0.78      0.80       162
       108.0       0.58      0.46      0.51        24
       109.0       0.36      0.81      0.50        52
       110.0       1.00      0.73      0.85        15
       111.0       0.91      0.34      0.50       123
       112.0       0.43      0.56      0.48        41
       113.0       0.92      0.86      0.89       430
       114.0       0.77      0.74      0.76        65
       115.0       0.52      0.55      0.53        31
       116.0       0.71      0.77      0.74       173
       117.0       0.85      0.77      0.81        30
       118.0       0.66      0.86      0.74       118
       119.0       0.60      0.80      0.69       136
       120.0       0.93      0.66      0.77        61
       121.0       0.96      0.80      0.87       225
       122.0       0.97      0.94      0.96        35
       123.0       0.85      0.74      0.79        38
       124.0       0.80      0.26      0.39        31
       125.0       1.00      0.81      0.90        16
       126.0       0.45      0.81      0.58        21
       127.0       0.59      0.68      0.63        73

    accuracy                           0.60     12227
   macro avg       0.59      0.45      0.48     12227
weighted avg       0.69      0.60      0.60     12227


===confusion_matrix===

[[313   3   0 ...   0   0   0]
 [  1   6   0 ...   0   0   0]
 [  0   0   8 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  17   3]
 [  0   0   0 ...   0  16  50]]

===multilabel confusion matrix===

[[[11533   337]
  [   44   313]]

 [[12199    16]
  [    6     6]]

 [[12203     5]
  [   11     8]]

 [[12076    71]
  [   35    45]]

 [[12152    21]
  [   47     7]]

 [[12152    17]
  [   58     0]]

 [[12173    10]
  [   37     7]]

 [[12178     1]
  [   33    15]]

 [[12216     0]
  [   11     0]]

 [[12205     1]
  [   20     1]]

 [[12212     0]
  [   15     0]]

 [[12184     7]
  [   11    25]]

 [[12215     0]
  [   12     0]]

 [[12200     2]
  [   13    12]]

 [[12206     1]
  [   20     0]]

 [[12202     2]
  [    8    15]]

 [[12195     9]
  [   13    10]]

 [[12100     8]
  [   41    78]]

 [[12209     1]
  [   14     3]]

 [[12214     0]
  [   13     0]]

 [[12130     7]
  [   82     8]]

 [[12214     1]
  [   12     0]]

 [[12199     3]
  [   10    15]]

 [[12212     3]
  [   11     1]]

 [[12202     3]
  [   20     2]]

 [[12154    36]
  [   17    20]]

 [[12209     0]
  [    1    17]]

 [[12192     0]
  [   35     0]]

 [[12215     0]
  [   12     0]]

 [[12188     2]
  [   33     4]]

 [[12191     4]
  [   13    19]]

 [[12161    27]
  [   10    29]]

 [[11419    62]
  [  157   589]]

 [[12153     0]
  [   19    55]]

 [[12169     0]
  [   11    47]]

 [[12165    14]
  [   25    23]]

 [[11697    28]
  [  254   248]]

 [[11943    43]
  [  100   141]]

 [[12186     8]
  [   11    22]]

 [[11695   188]
  [  141   203]]

 [[12024    12]
  [   78   113]]

 [[12196     0]
  [   17    14]]

 [[11828    15]
  [  159   225]]

 [[12096    13]
  [   23    95]]

 [[11618   173]
  [  120   316]]

 [[12174     5]
  [    9    39]]

 [[11788    37]
  [   89   313]]

 [[12209     1]
  [   13     4]]

 [[12181     4]
  [   27    15]]

 [[12148     2]
  [   15    62]]

 [[12039    16]
  [   31   141]]

 [[12204     3]
  [    5    15]]

 [[11658    70]
  [  237   262]]

 [[12126     2]
  [   49    50]]

 [[12216     0]
  [   11     0]]

 [[12110    14]
  [   28    75]]

 [[12207     2]
  [   13     5]]

 [[12215     1]
  [   10     1]]

 [[12193     0]
  [    3    31]]

 [[11570   426]
  [   63   168]]

 [[12169     0]
  [   34    24]]

 [[12197     0]
  [   30     0]]

 [[12171     8]
  [   36    12]]

 [[12166    12]
  [   46     3]]

 [[12191     2]
  [   12    22]]

 [[12063    10]
  [   51   103]]

 [[12213     0]
  [   14     0]]

 [[11798   115]
  [  149   165]]

 [[12136    28]
  [   62     1]]

 [[10791  1128]
  [   42   266]]

 [[12153     5]
  [   58    11]]

 [[12089    72]
  [   38    28]]

 [[12207     6]
  [   14     0]]

 [[12197     5]
  [   15    10]]

 [[12209     0]
  [   18     0]]

 [[12160     8]
  [   58     1]]

 [[11846   176]
  [   68   137]]

 [[12077    73]
  [   65    12]]

 [[12146    22]
  [   36    23]]

 [[12028    60]
  [   79    60]]

 [[12185     1]
  [   20    21]]

 [[11743   309]
  [  103    72]]

 [[12170    14]
  [   29    14]]

 [[12199     2]
  [   26     0]]

 [[12119     3]
  [   88    17]]

 [[12212     1]
  [   13     1]]

 [[11634   351]
  [   53   189]]

 [[11901    17]
  [   96   213]]

 [[12137    32]
  [   23    35]]

 [[12216     0]
  [   11     0]]

 [[12033     7]
  [  144    43]]

 [[12173     8]
  [   34    12]]

 [[12185     2]
  [   38     2]]

 [[12194     0]
  [   22    11]]

 [[11766   172]
  [  110   179]]

 [[12187     8]
  [   32     0]]

 [[12149     4]
  [   36    38]]

 [[12189    11]
  [   19     8]]

 [[12188     2]
  [   19    18]]

 [[12202     1]
  [    5    19]]

 [[12201     0]
  [   26     0]]

 [[12158     4]
  [   51    14]]

 [[12204     1]
  [   10    12]]

 [[12161     2]
  [   25    39]]

 [[12176    11]
  [   28    12]]

 [[12214     0]
  [    5     8]]

 [[12084    30]
  [   26    87]]

 [[12037    28]
  [   35   127]]

 [[12195     8]
  [   13    11]]

 [[12101    74]
  [   10    42]]

 [[12212     0]
  [    4    11]]

 [[12100     4]
  [   81    42]]

 [[12155    31]
  [   18    23]]

 [[11763    34]
  [   61   369]]

 [[12148    14]
  [   17    48]]

 [[12180    16]
  [   14    17]]

 [[11998    56]
  [   39   134]]

 [[12193     4]
  [    7    23]]

 [[12056    53]
  [   17   101]]

 [[12019    72]
  [   27   109]]

 [[12163     3]
  [   21    40]]

 [[11994     8]
  [   44   181]]

 [[12191     1]
  [    2    33]]

 [[12184     5]
  [   10    28]]

 [[12194     2]
  [   23     8]]

 [[12211     0]
  [    3    13]]

 [[12185    21]
  [    4    17]]

 [[12119    35]
  [   23    50]]]

===scores report===
metrics	scores
Accuracy	0.5971
MCC	0.5916
log_loss	1.9305
f1 score weighted	0.6030
f1 score macro	0.4787
f1 score micro	0.5971
roc_auc ovr	0.9644
roc_auc ovo	0.9587
precision	0.6853
recall	0.5971

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff330290460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff330290310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3302907f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff3302907c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.61      0.85      0.71       357
         1.0       0.40      0.15      0.22        13
         2.0       0.88      0.37      0.52        19
         3.0       0.70      0.51      0.59        79
         4.0       0.32      0.33      0.32        55
         5.0       0.16      0.10      0.12        59
         6.0       0.27      0.27      0.27        44
         7.0       0.76      0.54      0.63        48
         8.0       0.00      0.00      0.00        10
         9.0       0.82      0.43      0.56        21
        10.0       1.00      0.13      0.24        15
        11.0       0.93      0.69      0.79        36
        12.0       0.80      0.33      0.47        12
        13.0       0.90      0.72      0.80        25
        14.0       1.00      0.15      0.26        20
        15.0       0.88      0.64      0.74        22
        16.0       0.58      0.65      0.61        23
        17.0       0.75      0.88      0.81       118
        18.0       0.82      0.50      0.62        18
        19.0       0.00      0.00      0.00        13
        20.0       0.39      0.64      0.49        89
        21.0       0.75      0.25      0.38        12
        22.0       0.70      0.79      0.75        24
        23.0       0.17      0.08      0.11        12
        24.0       0.33      0.17      0.23        23
        25.0       0.53      0.57      0.55        37
        26.0       1.00      0.94      0.97        17
        27.0       0.38      0.17      0.23        36
        28.0       0.20      0.08      0.12        12
        29.0       0.52      0.73      0.61        37
        30.0       0.64      0.50      0.56        32
        31.0       0.62      0.79      0.70        39
        32.0       0.62      0.90      0.74       746
        33.0       0.86      0.85      0.86        74
        34.0       0.76      0.76      0.76        58
        35.0       1.00      0.25      0.40        48
        36.0       0.79      0.61      0.69       502
        37.0       0.48      0.76      0.59       240
        38.0       1.00      0.52      0.68        33
        39.0       0.78      0.68      0.72       344
        40.0       0.84      0.71      0.77       191
        41.0       0.80      0.52      0.63        31
        42.0       0.83      0.72      0.77       384
        43.0       0.71      0.87      0.78       117
        44.0       0.81      0.67      0.73       436
        45.0       0.95      0.73      0.83        49
        46.0       0.90      0.82      0.86       402
        47.0       1.00      0.35      0.52        17
        48.0       0.91      0.50      0.65        42
        49.0       0.93      0.91      0.92        77
        50.0       0.80      0.93      0.86       172
        51.0       1.00      0.32      0.48        19
        52.0       0.84      0.55      0.66       499
        53.0       0.86      0.62      0.72        99
        54.0       0.00      0.00      0.00        11
        55.0       0.70      0.76      0.73       103
        56.0       0.70      0.39      0.50        18
        57.0       1.00      0.36      0.53        11
        58.0       0.97      0.91      0.94        35
        59.0       0.41      0.76      0.53       231
        60.0       0.71      0.77      0.74        57
        61.0       0.00      0.00      0.00        29
        62.0       0.55      0.35      0.43        48
        63.0       0.30      0.27      0.28        49
        64.0       0.76      0.56      0.64        34
        65.0       0.66      0.76      0.71       155
        66.0       0.50      0.14      0.22        14
        67.0       0.47      0.70      0.56       315
        68.0       0.45      0.08      0.14        63
        69.0       0.47      0.67      0.55       307
        70.0       0.30      0.49      0.37        69
        71.0       0.69      0.41      0.51        66
        72.0       0.50      0.20      0.29        15
        73.0       0.83      0.20      0.32        25
        74.0       0.00      0.00      0.00        18
        75.0       0.44      0.31      0.36        59
        76.0       0.64      0.72      0.67       206
        77.0       0.37      0.42      0.39        76
        78.0       0.86      0.42      0.57        59
        79.0       0.65      0.53      0.58       140
        80.0       0.84      0.74      0.78        42
        81.0       0.56      0.38      0.45       175
        82.0       0.81      0.30      0.44        43
        83.0       0.82      0.36      0.50        25
        84.0       0.71      0.39      0.50       105
        85.0       1.00      0.43      0.60        14
        86.0       0.57      0.74      0.65       242
        87.0       0.84      0.68      0.75       310
        88.0       0.64      0.54      0.59        59
        89.0       1.00      0.18      0.31        11
        90.0       0.72      0.49      0.58       187
        91.0       0.71      0.33      0.45        46
        92.0       0.26      0.25      0.26        40
        93.0       0.81      0.39      0.53        33
        94.0       0.62      0.67      0.65       289
        95.0       0.17      0.03      0.05        32
        96.0       1.00      0.76      0.86        75
        97.0       0.73      0.29      0.41        28
        98.0       0.77      0.73      0.75        37
        99.0       0.84      0.91      0.87        23
       100.0       0.00      0.00      0.00        25
       101.0       0.92      0.55      0.69        66
       102.0       0.75      0.71      0.73        21
       103.0       0.87      0.80      0.83        65
       104.0       0.44      0.20      0.28        40
       105.0       0.75      0.75      0.75        12
       106.0       0.54      0.81      0.65       113
       107.0       0.86      0.77      0.81       162
       108.0       0.64      0.38      0.47        24
       109.0       0.87      0.75      0.81        53
       110.0       0.75      0.43      0.55        14
       111.0       0.53      0.73      0.61       123
       112.0       0.44      0.54      0.48        41
       113.0       0.75      0.93      0.83       429
       114.0       0.80      0.75      0.78        65
       115.0       0.63      0.61      0.62        31
       116.0       0.91      0.80      0.85       173
       117.0       0.63      0.80      0.71        30
       118.0       0.64      0.87      0.74       117
       119.0       0.77      0.85      0.81       136
       120.0       0.78      0.59      0.67        61
       121.0       0.87      0.91      0.89       225
       122.0       0.90      0.77      0.83        35
       123.0       0.89      0.66      0.76        38
       124.0       0.81      0.57      0.67        30
       125.0       1.00      0.81      0.90        16
       126.0       0.94      0.68      0.79        22
       127.0       0.70      0.95      0.81        73

    accuracy                           0.67     12226
   macro avg       0.67      0.53      0.57     12226
weighted avg       0.70      0.67      0.66     12226


===confusion_matrix===

[[304   1   0 ...   0   0   0]
 [  2   2   0 ...   0   0   0]
 [  0   0   7 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   1]
 [  0   0   0 ...   0  15   7]
 [  0   0   0 ...   0   1  69]]

===multilabel confusion matrix===

[[[11671   198]
  [   53   304]]

 [[12210     3]
  [   11     2]]

 [[12206     1]
  [   12     7]]

 [[12130    17]
  [   39    40]]

 [[12133    38]
  [   37    18]]

 [[12135    32]
  [   53     6]]

 [[12150    32]
  [   32    12]]

 [[12170     8]
  [   22    26]]

 [[12216     0]
  [   10     0]]

 [[12203     2]
  [   12     9]]

 [[12211     0]
  [   13     2]]

 [[12188     2]
  [   11    25]]

 [[12213     1]
  [    8     4]]

 [[12199     2]
  [    7    18]]

 [[12206     0]
  [   17     3]]

 [[12202     2]
  [    8    14]]

 [[12192    11]
  [    8    15]]

 [[12073    35]
  [   14   104]]

 [[12206     2]
  [    9     9]]

 [[12213     0]
  [   13     0]]

 [[12049    88]
  [   32    57]]

 [[12213     1]
  [    9     3]]

 [[12194     8]
  [    5    19]]

 [[12209     5]
  [   11     1]]

 [[12195     8]
  [   19     4]]

 [[12170    19]
  [   16    21]]

 [[12209     0]
  [    1    16]]

 [[12180    10]
  [   30     6]]

 [[12210     4]
  [   11     1]]

 [[12164    25]
  [   10    27]]

 [[12185     9]
  [   16    16]]

 [[12168    19]
  [    8    31]]

 [[11068   412]
  [   73   673]]

 [[12142    10]
  [   11    63]]

 [[12154    14]
  [   14    44]]

 [[12178     0]
  [   36    12]]

 [[11644    80]
  [  196   306]]

 [[11786   200]
  [   58   182]]

 [[12193     0]
  [   16    17]]

 [[11815    67]
  [  111   233]]

 [[12010    25]
  [   56   135]]

 [[12191     4]
  [   15    16]]

 [[11787    55]
  [  109   275]]

 [[12068    41]
  [   15   102]]

 [[11720    70]
  [  146   290]]

 [[12175     2]
  [   13    36]]

 [[11788    36]
  [   72   330]]

 [[12209     0]
  [   11     6]]

 [[12182     2]
  [   21    21]]

 [[12144     5]
  [    7    70]]

 [[12014    40]
  [   12   160]]

 [[12207     0]
  [   13     6]]

 [[11676    51]
  [  227   272]]

 [[12117    10]
  [   38    61]]

 [[12214     1]
  [   11     0]]

 [[12090    33]
  [   25    78]]

 [[12205     3]
  [   11     7]]

 [[12215     0]
  [    7     4]]

 [[12190     1]
  [    3    32]]

 [[11743   252]
  [   55   176]]

 [[12151    18]
  [   13    44]]

 [[12197     0]
  [   29     0]]

 [[12164    14]
  [   31    17]]

 [[12147    30]
  [   36    13]]

 [[12186     6]
  [   15    19]]

 [[12011    60]
  [   37   118]]

 [[12210     2]
  [   12     2]]

 [[11662   249]
  [   94   221]]

 [[12157     6]
  [   58     5]]

 [[11684   235]
  [  101   206]]

 [[12077    80]
  [   35    34]]

 [[12148    12]
  [   39    27]]

 [[12208     3]
  [   12     3]]

 [[12200     1]
  [   20     5]]

 [[12208     0]
  [   18     0]]

 [[12144    23]
  [   41    18]]

 [[11935    85]
  [   58   148]]

 [[12095    55]
  [   44    32]]

 [[12163     4]
  [   34    25]]

 [[12047    39]
  [   66    74]]

 [[12178     6]
  [   11    31]]

 [[11998    53]
  [  108    67]]

 [[12180     3]
  [   30    13]]

 [[12199     2]
  [   16     9]]

 [[12104    17]
  [   64    41]]

 [[12212     0]
  [    8     6]]

 [[11849   135]
  [   62   180]]

 [[11877    39]
  [   99   211]]

 [[12149    18]
  [   27    32]]

 [[12215     0]
  [    9     2]]

 [[12003    36]
  [   95    92]]

 [[12174     6]
  [   31    15]]

 [[12158    28]
  [   30    10]]

 [[12190     3]
  [   20    13]]

 [[11821   116]
  [   96   193]]

 [[12189     5]
  [   31     1]]

 [[12151     0]
  [   18    57]]

 [[12195     3]
  [   20     8]]

 [[12181     8]
  [   10    27]]

 [[12199     4]
  [    2    21]]

 [[12198     3]
  [   25     0]]

 [[12157     3]
  [   30    36]]

 [[12200     5]
  [    6    15]]

 [[12153     8]
  [   13    52]]

 [[12176    10]
  [   32     8]]

 [[12211     3]
  [    3     9]]

 [[12037    76]
  [   22    91]]

 [[12044    20]
  [   38   124]]

 [[12197     5]
  [   15     9]]

 [[12167     6]
  [   13    40]]

 [[12210     2]
  [    8     6]]

 [[12023    80]
  [   33    90]]

 [[12157    28]
  [   19    22]]

 [[11666   131]
  [   29   400]]

 [[12149    12]
  [   16    49]]

 [[12184    11]
  [   12    19]]

 [[12039    14]
  [   35   138]]

 [[12182    14]
  [    6    24]]

 [[12052    57]
  [   15   102]]

 [[12056    34]
  [   20   116]]

 [[12155    10]
  [   25    36]]

 [[11970    31]
  [   21   204]]

 [[12188     3]
  [    8    27]]

 [[12185     3]
  [   13    25]]

 [[12192     4]
  [   13    17]]

 [[12210     0]
  [    3    13]]

 [[12203     1]
  [    7    15]]

 [[12124    29]
  [    4    69]]]

===scores report===
metrics	scores
Accuracy	0.6726
MCC	0.6658
log_loss	1.4971
f1 score weighted	0.6645
f1 score macro	0.5661
f1 score micro	0.6726
roc_auc ovr	0.9738
roc_auc ovo	0.9698
precision	0.6960
recall	0.6726

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff330290460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff330290310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3302907f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff3302907c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.78      0.76       358
         1.0       0.67      0.33      0.44        12
         2.0       1.00      0.06      0.11        18
         3.0       0.79      0.53      0.64        79
         4.0       0.28      0.25      0.27        55
         5.0       0.17      0.05      0.08        58
         6.0       0.56      0.20      0.30        45
         7.0       0.89      0.53      0.67        47
         8.0       0.25      0.10      0.14        10
         9.0       0.71      0.48      0.57        21
        10.0       0.00      0.00      0.00        15
        11.0       0.59      0.81      0.68        36
        12.0       0.25      0.17      0.20        12
        13.0       0.62      0.32      0.42        25
        14.0       0.33      0.05      0.09        20
        15.0       0.92      0.55      0.69        22
        16.0       0.57      0.52      0.55        23
        17.0       0.99      0.75      0.85       118
        18.0       0.67      0.33      0.44        18
        19.0       0.50      0.08      0.13        13
        20.0       0.41      0.36      0.38        89
        21.0       1.00      0.15      0.27        13
        22.0       1.00      0.60      0.75        25
        23.0       0.00      0.00      0.00        12
        24.0       0.50      0.04      0.08        23
        25.0       0.75      0.49      0.59        37
        26.0       1.00      0.71      0.83        17
        27.0       0.33      0.17      0.22        36
        28.0       0.50      0.08      0.14        12
        29.0       0.81      0.47      0.60        36
        30.0       0.67      0.62      0.65        32
        31.0       0.80      0.82      0.81        39
        32.0       0.80      0.80      0.80       747
        33.0       0.86      0.88      0.87        74
        34.0       0.84      0.90      0.87        58
        35.0       0.76      0.62      0.68        47
        36.0       0.60      0.71      0.65       502
        37.0       0.66      0.70      0.68       240
        38.0       0.77      0.29      0.43        34
        39.0       0.83      0.53      0.64       344
        40.0       0.89      0.71      0.79       191
        41.0       1.00      0.59      0.75        32
        42.0       0.71      0.74      0.72       384
        43.0       0.85      0.75      0.80       117
        44.0       0.64      0.76      0.69       437
        45.0       0.97      0.71      0.82        49
        46.0       0.69      0.89      0.78       401
        47.0       0.82      0.53      0.64        17
        48.0       0.86      0.45      0.59        42
        49.0       0.89      0.81      0.84        77
        50.0       0.85      0.82      0.84       171
        51.0       1.00      0.55      0.71        20
        52.0       0.61      0.67      0.64       499
        53.0       0.76      0.54      0.63       100
        54.0       1.00      0.09      0.17        11
        55.0       0.87      0.75      0.80       104
        56.0       0.50      0.16      0.24        19
        57.0       1.00      0.09      0.17        11
        58.0       0.97      0.91      0.94        35
        59.0       0.42      0.73      0.54       230
        60.0       0.92      0.83      0.87        58
        61.0       0.00      0.00      0.00        29
        62.0       0.58      0.43      0.49        49
        63.0       0.12      0.06      0.08        50
        64.0       0.89      0.71      0.79        34
        65.0       0.72      0.83      0.77       155
        66.0       0.00      0.00      0.00        14
        67.0       0.45      0.71      0.55       314
        68.0       0.00      0.00      0.00        62
        69.0       0.47      0.67      0.55       307
        70.0       0.42      0.31      0.36        68
        71.0       0.29      0.23      0.25        66
        72.0       0.00      0.00      0.00        15
        73.0       0.89      0.32      0.47        25
        74.0       0.00      0.00      0.00        19
        75.0       0.40      0.10      0.16        59
        76.0       0.72      0.67      0.69       206
        77.0       0.87      0.43      0.57        77
        78.0       0.64      0.58      0.61        59
        79.0       0.79      0.48      0.60       139
        80.0       0.89      0.79      0.84        42
        81.0       0.31      0.52      0.38       174
        82.0       0.44      0.51      0.47        43
        83.0       0.28      0.20      0.23        25
        84.0       0.38      0.53      0.44       105
        85.0       0.62      0.53      0.57        15
        86.0       0.66      0.67      0.66       242
        87.0       0.84      0.71      0.77       309
        88.0       0.88      0.51      0.65        59
        89.0       0.00      0.00      0.00        11
        90.0       0.28      0.60      0.38       188
        91.0       0.54      0.30      0.38        47
        92.0       0.15      0.05      0.08        40
        93.0       0.68      0.45      0.55        33
        94.0       0.40      0.69      0.50       288
        95.0       0.33      0.03      0.06        32
        96.0       0.86      0.80      0.83        75
        97.0       0.57      0.30      0.39        27
        98.0       0.83      0.39      0.54        38
        99.0       0.91      0.87      0.89        23
       100.0       0.00      0.00      0.00        25
       101.0       0.44      0.53      0.48        66
       102.0       0.83      0.68      0.75        22
       103.0       0.71      0.75      0.73        64
       104.0       0.81      0.33      0.47        39
       105.0       1.00      0.75      0.86        12
       106.0       0.77      0.78      0.78       113
       107.0       0.77      0.76      0.77       161
       108.0       0.60      0.26      0.36        23
       109.0       0.90      0.72      0.80        53
       110.0       1.00      0.57      0.73        14
       111.0       0.78      0.58      0.66       123
       112.0       1.00      0.37      0.54        41
       113.0       0.94      0.86      0.90       429
       114.0       0.87      0.74      0.80        65
       115.0       0.56      0.45      0.50        31
       116.0       0.83      0.67      0.74       173
       117.0       0.79      0.87      0.83        31
       118.0       0.90      0.79      0.84       117
       119.0       0.79      0.81      0.80       135
       120.0       0.97      0.61      0.75        62
       121.0       0.61      0.91      0.73       224
       122.0       0.96      0.74      0.84        35
       123.0       0.75      0.57      0.65        37
       124.0       0.82      0.60      0.69        30
       125.0       0.82      0.56      0.67        16
       126.0       1.00      0.59      0.74        22
       127.0       0.69      0.88      0.77        73

    accuracy                           0.66     12226
   macro avg       0.65      0.50      0.54     12226
weighted avg       0.68      0.66      0.65     12226


===confusion_matrix===

[[279   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0   1 ...   0   0   0]
 ...
 [  0   0   0 ...   9   0   2]
 [  0   0   0 ...   0  13   9]
 [  0   0   0 ...   1   0  64]]

===multilabel confusion matrix===

[[[11771    97]
  [   79   279]]

 [[12212     2]
  [    8     4]]

 [[12208     0]
  [   17     1]]

 [[12136    11]
  [   37    42]]

 [[12135    36]
  [   41    14]]

 [[12153    15]
  [   55     3]]

 [[12174     7]
  [   36     9]]

 [[12176     3]
  [   22    25]]

 [[12213     3]
  [    9     1]]

 [[12201     4]
  [   11    10]]

 [[12209     2]
  [   15     0]]

 [[12170    20]
  [    7    29]]

 [[12208     6]
  [   10     2]]

 [[12196     5]
  [   17     8]]

 [[12204     2]
  [   19     1]]

 [[12203     1]
  [   10    12]]

 [[12194     9]
  [   11    12]]

 [[12107     1]
  [   30    88]]

 [[12205     3]
  [   12     6]]

 [[12212     1]
  [   12     1]]

 [[12091    46]
  [   57    32]]

 [[12213     0]
  [   11     2]]

 [[12201     0]
  [   10    15]]

 [[12214     0]
  [   12     0]]

 [[12202     1]
  [   22     1]]

 [[12183     6]
  [   19    18]]

 [[12209     0]
  [    5    12]]

 [[12178    12]
  [   30     6]]

 [[12213     1]
  [   11     1]]

 [[12186     4]
  [   19    17]]

 [[12184    10]
  [   12    20]]

 [[12179     8]
  [    7    32]]

 [[11333   146]
  [  148   599]]

 [[12141    11]
  [    9    65]]

 [[12158    10]
  [    6    52]]

 [[12170     9]
  [   18    29]]

 [[11483   241]
  [  146   356]]

 [[11900    86]
  [   71   169]]

 [[12189     3]
  [   24    10]]

 [[11844    38]
  [  163   181]]

 [[12019    16]
  [   56   135]]

 [[12194     0]
  [   13    19]]

 [[11725   117]
  [  101   283]]

 [[12093    16]
  [   29    88]]

 [[11601   188]
  [  106   331]]

 [[12176     1]
  [   14    35]]

 [[11669   156]
  [   46   355]]

 [[12207     2]
  [    8     9]]

 [[12181     3]
  [   23    19]]

 [[12141     8]
  [   15    62]]

 [[12030    25]
  [   30   141]]

 [[12206     0]
  [    9    11]]

 [[11515   212]
  [  164   335]]

 [[12109    17]
  [   46    54]]

 [[12215     0]
  [   10     1]]

 [[12110    12]
  [   26    78]]

 [[12204     3]
  [   16     3]]

 [[12215     0]
  [   10     1]]

 [[12190     1]
  [    3    32]]

 [[11767   229]
  [   62   168]]

 [[12164     4]
  [   10    48]]

 [[12196     1]
  [   29     0]]

 [[12162    15]
  [   28    21]]

 [[12154    22]
  [   47     3]]

 [[12189     3]
  [   10    24]]

 [[12021    50]
  [   26   129]]

 [[12209     3]
  [   14     0]]

 [[11638   274]
  [   90   224]]

 [[12156     8]
  [   62     0]]

 [[11683   236]
  [  100   207]]

 [[12129    29]
  [   47    21]]

 [[12123    37]
  [   51    15]]

 [[12211     0]
  [   15     0]]

 [[12200     1]
  [   17     8]]

 [[12207     0]
  [   19     0]]

 [[12158     9]
  [   53     6]]

 [[11966    54]
  [   68   138]]

 [[12144     5]
  [   44    33]]

 [[12148    19]
  [   25    34]]

 [[12069    18]
  [   72    67]]

 [[12180     4]
  [    9    33]]

 [[11848   204]
  [   84    90]]

 [[12155    28]
  [   21    22]]

 [[12188    13]
  [   20     5]]

 [[12028    93]
  [   49    56]]

 [[12206     5]
  [    7     8]]

 [[11902    82]
  [   81   161]]

 [[11875    42]
  [   90   219]]

 [[12163     4]
  [   29    30]]

 [[12215     0]
  [   11     0]]

 [[11754   284]
  [   76   112]]

 [[12167    12]
  [   33    14]]

 [[12175    11]
  [   38     2]]

 [[12186     7]
  [   18    15]]

 [[11636   302]
  [   89   199]]

 [[12192     2]
  [   31     1]]

 [[12141    10]
  [   15    60]]

 [[12193     6]
  [   19     8]]

 [[12185     3]
  [   23    15]]

 [[12201     2]
  [    3    20]]

 [[12200     1]
  [   25     0]]

 [[12116    44]
  [   31    35]]

 [[12201     3]
  [    7    15]]

 [[12142    20]
  [   16    48]]

 [[12184     3]
  [   26    13]]

 [[12214     0]
  [    3     9]]

 [[12087    26]
  [   25    88]]

 [[12028    37]
  [   38   123]]

 [[12199     4]
  [   17     6]]

 [[12169     4]
  [   15    38]]

 [[12212     0]
  [    6     8]]

 [[12083    20]
  [   52    71]]

 [[12185     0]
  [   26    15]]

 [[11772    25]
  [   59   370]]

 [[12154     7]
  [   17    48]]

 [[12184    11]
  [   17    14]]

 [[12030    23]
  [   57   116]]

 [[12188     7]
  [    4    27]]

 [[12099    10]
  [   25    92]]

 [[12062    29]
  [   25   110]]

 [[12163     1]
  [   24    38]]

 [[11872   130]
  [   21   203]]

 [[12190     1]
  [    9    26]]

 [[12182     7]
  [   16    21]]

 [[12192     4]
  [   12    18]]

 [[12208     2]
  [    7     9]]

 [[12204     0]
  [    9    13]]

 [[12124    29]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6552
MCC	0.6477
log_loss	1.5408
f1 score weighted	0.6485
f1 score macro	0.5364
f1 score micro	0.6552
roc_auc ovr	0.9708
roc_auc ovo	0.9661
precision	0.6773
recall	0.6552

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff330290460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff330290310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3302907f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff3302907c0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.65      0.70      0.67       358
         1.0       0.40      0.33      0.36        12
         2.0       0.90      0.47      0.62        19
         3.0       0.78      0.54      0.64        79
         4.0       0.48      0.20      0.28        55
         5.0       0.50      0.03      0.06        58
         6.0       0.54      0.16      0.24        45
         7.0       0.63      0.36      0.46        47
         8.0       0.00      0.00      0.00        10
         9.0       0.43      0.43      0.43        21
        10.0       0.67      0.27      0.38        15
        11.0       0.93      0.78      0.85        36
        12.0       0.67      0.33      0.44        12
        13.0       0.80      0.64      0.71        25
        14.0       0.57      0.21      0.31        19
        15.0       0.90      0.41      0.56        22
        16.0       0.43      0.70      0.53        23
        17.0       0.36      0.93      0.52       118
        18.0       0.23      0.44      0.30        18
        19.0       0.33      0.17      0.22        12
        20.0       0.77      0.27      0.40        90
        21.0       1.00      0.23      0.38        13
        22.0       0.65      0.68      0.67        25
        23.0       0.50      0.15      0.24        13
        24.0       0.10      0.32      0.16        22
        25.0       0.94      0.45      0.61        38
        26.0       0.85      1.00      0.92        17
        27.0       0.50      0.17      0.26        35
        28.0       1.00      0.08      0.15        12
        29.0       0.95      0.50      0.65        36
        30.0       0.60      0.66      0.63        32
        31.0       0.89      0.82      0.85        38
        32.0       0.76      0.82      0.79       747
        33.0       0.97      0.79      0.87        75
        34.0       0.92      0.81      0.86        59
        35.0       0.75      0.83      0.79        47
        36.0       0.69      0.67      0.68       501
        37.0       0.85      0.65      0.73       241
        38.0       0.77      0.61      0.68        33
        39.0       0.66      0.70      0.68       344
        40.0       0.72      0.75      0.73       192
        41.0       0.82      0.56      0.67        32
        42.0       0.86      0.66      0.75       384
        43.0       0.52      0.77      0.62       117
        44.0       0.83      0.67      0.74       436
        45.0       0.71      0.90      0.79        49
        46.0       0.88      0.81      0.84       401
        47.0       0.00      0.00      0.00        17
        48.0       0.69      0.69      0.69        42
        49.0       0.95      0.81      0.87        77
        50.0       0.98      0.76      0.86       172
        51.0       1.00      0.45      0.62        20
        52.0       0.49      0.68      0.57       499
        53.0       0.86      0.65      0.74       100
        54.0       0.33      0.09      0.14        11
        55.0       0.50      0.89      0.64       104
        56.0       0.56      0.28      0.37        18
        57.0       1.00      0.10      0.18        10
        58.0       0.79      0.77      0.78        35
        59.0       0.58      0.65      0.61       230
        60.0       0.85      0.76      0.80        58
        61.0       0.00      0.00      0.00        29
        62.0       0.86      0.39      0.54        49
        63.0       0.38      0.18      0.24        50
        64.0       0.71      0.65      0.68        34
        65.0       0.77      0.78      0.78       155
        66.0       0.50      0.14      0.22        14
        67.0       0.48      0.62      0.54       314
        68.0       0.20      0.02      0.03        62
        69.0       0.56      0.66      0.61       307
        70.0       0.53      0.29      0.38        68
        71.0       0.53      0.39      0.45        66
        72.0       0.45      0.36      0.40        14
        73.0       0.71      0.42      0.53        24
        74.0       0.00      0.00      0.00        19
        75.0       0.70      0.12      0.20        60
        76.0       0.62      0.68      0.65       206
        77.0       0.54      0.45      0.49        77
        78.0       0.78      0.61      0.69        59
        79.0       0.57      0.53      0.54       139
        80.0       0.83      0.71      0.77        42
        81.0       0.55      0.44      0.49       174
        82.0       0.69      0.47      0.56        43
        83.0       0.38      0.19      0.26        26
        84.0       0.62      0.49      0.55       106
        85.0       0.80      0.27      0.40        15
        86.0       0.93      0.60      0.73       241
        87.0       0.43      0.86      0.57       309
        88.0       0.66      0.56      0.61        59
        89.0       0.50      0.30      0.37        10
        90.0       0.67      0.50      0.57       188
        91.0       0.90      0.39      0.55        46
        92.0       0.33      0.02      0.05        41
        93.0       0.63      0.38      0.47        32
        94.0       0.76      0.57      0.65       288
        95.0       0.45      0.29      0.35        31
        96.0       0.93      0.52      0.67        75
        97.0       0.67      0.22      0.33        27
        98.0       1.00      0.37      0.54        38
        99.0       1.00      0.92      0.96        24
       100.0       0.00      0.00      0.00        25
       101.0       0.75      0.55      0.64        65
       102.0       1.00      0.64      0.78        22
       103.0       0.55      0.78      0.65        64
       104.0       0.57      0.30      0.39        40
       105.0       1.00      0.75      0.86        12
       106.0       0.73      0.74      0.74       113
       107.0       0.75      0.79      0.77       161
       108.0       1.00      0.08      0.15        24
       109.0       0.66      0.81      0.72        52
       110.0       0.62      0.87      0.72        15
       111.0       0.48      0.73      0.58       124
       112.0       0.20      0.68      0.30        41
       113.0       0.72      0.91      0.80       430
       114.0       0.98      0.62      0.75        65
       115.0       0.68      0.42      0.52        31
       116.0       0.97      0.67      0.79       173
       117.0       1.00      0.71      0.83        31
       118.0       0.50      0.88      0.64       117
       119.0       0.71      0.88      0.78       136
       120.0       0.27      0.82      0.41        62
       121.0       0.82      0.86      0.84       224
       122.0       0.89      0.71      0.79        35
       123.0       0.91      0.57      0.70        37
       124.0       0.57      0.84      0.68        31
       125.0       0.65      0.73      0.69        15
       126.0       0.93      0.62      0.74        21
       127.0       0.73      0.71      0.72        73

    accuracy                           0.65     12226
   macro avg       0.66      0.52      0.55     12226
weighted avg       0.69      0.65      0.65     12226


===confusion_matrix===

[[250   0   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...  11   1   0]
 [  0   0   0 ...   1  13   5]
 [  1   0   0 ...   0   0  52]]

===multilabel confusion matrix===

[[[11734   134]
  [  108   250]]

 [[12208     6]
  [    8     4]]

 [[12206     1]
  [   10     9]]

 [[12135    12]
  [   36    43]]

 [[12159    12]
  [   44    11]]

 [[12166     2]
  [   56     2]]

 [[12175     6]
  [   38     7]]

 [[12169    10]
  [   30    17]]

 [[12216     0]
  [   10     0]]

 [[12193    12]
  [   12     9]]

 [[12209     2]
  [   11     4]]

 [[12188     2]
  [    8    28]]

 [[12212     2]
  [    8     4]]

 [[12197     4]
  [    9    16]]

 [[12204     3]
  [   15     4]]

 [[12203     1]
  [   13     9]]

 [[12182    21]
  [    7    16]]

 [[11912   196]
  [    8   110]]

 [[12181    27]
  [   10     8]]

 [[12210     4]
  [   10     2]]

 [[12129     7]
  [   66    24]]

 [[12213     0]
  [   10     3]]

 [[12192     9]
  [    8    17]]

 [[12211     2]
  [   11     2]]

 [[12144    60]
  [   15     7]]

 [[12187     1]
  [   21    17]]

 [[12206     3]
  [    0    17]]

 [[12185     6]
  [   29     6]]

 [[12214     0]
  [   11     1]]

 [[12189     1]
  [   18    18]]

 [[12180    14]
  [   11    21]]

 [[12184     4]
  [    7    31]]

 [[11281   198]
  [  131   616]]

 [[12149     2]
  [   16    59]]

 [[12163     4]
  [   11    48]]

 [[12166    13]
  [    8    39]]

 [[11576   149]
  [  165   336]]

 [[11957    28]
  [   85   156]]

 [[12187     6]
  [   13    20]]

 [[11761   121]
  [  104   240]]

 [[11977    57]
  [   48   144]]

 [[12190     4]
  [   14    18]]

 [[11801    41]
  [  130   254]]

 [[12025    84]
  [   27    90]]

 [[11732    58]
  [  143   293]]

 [[12159    18]
  [    5    44]]

 [[11781    44]
  [   76   325]]

 [[12209     0]
  [   17     0]]

 [[12171    13]
  [   13    29]]

 [[12146     3]
  [   15    62]]

 [[12052     2]
  [   41   131]]

 [[12206     0]
  [   11     9]]

 [[11373   354]
  [  159   340]]

 [[12115    11]
  [   35    65]]

 [[12213     2]
  [   10     1]]

 [[12029    93]
  [   11    93]]

 [[12204     4]
  [   13     5]]

 [[12216     0]
  [    9     1]]

 [[12184     7]
  [    8    27]]

 [[11889   107]
  [   81   149]]

 [[12160     8]
  [   14    44]]

 [[12197     0]
  [   29     0]]

 [[12174     3]
  [   30    19]]

 [[12161    15]
  [   41     9]]

 [[12183     9]
  [   12    22]]

 [[12035    36]
  [   34   121]]

 [[12210     2]
  [   12     2]]

 [[11702   210]
  [  118   196]]

 [[12160     4]
  [   61     1]]

 [[11761   158]
  [  104   203]]

 [[12140    18]
  [   48    20]]

 [[12137    23]
  [   40    26]]

 [[12206     6]
  [    9     5]]

 [[12198     4]
  [   14    10]]

 [[12206     1]
  [   19     0]]

 [[12163     3]
  [   53     7]]

 [[11934    86]
  [   65   141]]

 [[12119    30]
  [   42    35]]

 [[12157    10]
  [   23    36]]

 [[12031    56]
  [   66    73]]

 [[12178     6]
  [   12    30]]

 [[11989    63]
  [   97    77]]

 [[12174     9]
  [   23    20]]

 [[12192     8]
  [   21     5]]

 [[12088    32]
  [   54    52]]

 [[12210     1]
  [   11     4]]

 [[11974    11]
  [   97   144]]

 [[11560   357]
  [   44   265]]

 [[12150    17]
  [   26    33]]

 [[12213     3]
  [    7     3]]

 [[11991    47]
  [   94    94]]

 [[12178     2]
  [   28    18]]

 [[12183     2]
  [   40     1]]

 [[12187     7]
  [   20    12]]

 [[11887    51]
  [  124   164]]

 [[12184    11]
  [   22     9]]

 [[12148     3]
  [   36    39]]

 [[12196     3]
  [   21     6]]

 [[12188     0]
  [   24    14]]

 [[12202     0]
  [    2    22]]

 [[12199     2]
  [   25     0]]

 [[12149    12]
  [   29    36]]

 [[12204     0]
  [    8    14]]

 [[12121    41]
  [   14    50]]

 [[12177     9]
  [   28    12]]

 [[12214     0]
  [    3     9]]

 [[12082    31]
  [   29    84]]

 [[12023    42]
  [   34   127]]

 [[12202     0]
  [   22     2]]

 [[12152    22]
  [   10    42]]

 [[12203     8]
  [    2    13]]

 [[12003    99]
  [   34    90]]

 [[12070   115]
  [   13    28]]

 [[11644   152]
  [   38   392]]

 [[12160     1]
  [   25    40]]

 [[12189     6]
  [   18    13]]

 [[12049     4]
  [   57   116]]

 [[12195     0]
  [    9    22]]

 [[12005   104]
  [   14   103]]

 [[12040    50]
  [   16   120]]

 [[12028   136]
  [   11    51]]

 [[11961    41]
  [   31   193]]

 [[12188     3]
  [   10    25]]

 [[12187     2]
  [   16    21]]

 [[12175    20]
  [    5    26]]

 [[12205     6]
  [    4    11]]

 [[12204     1]
  [    8    13]]

 [[12134    19]
  [   21    52]]]

===scores report===
metrics	scores
Accuracy	0.6542
MCC	0.6470
log_loss	1.6953
f1 score weighted	0.6484
f1 score macro	0.5469
f1 score micro	0.6542
roc_auc ovr	0.9693
roc_auc ovo	0.9637
precision	0.6890
recall	0.6542

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.678253046536354	0.6713396027420164	1.4598299719839056	0.6690205791817279	0.5569880827059543	0.678253046536354	0.9745093913681228	0.9713188901354332	0.6825122862757361	0.678253046536354
1	0.5971211253782612	0.5915687632317436	1.930484062433711	0.6030190166921664	0.4786594191383244	0.5971211253782612	0.964363629030943	0.9587197462045397	0.6853289764964845	0.5971211253782612
2	0.6725830197938819	0.6657894511295533	1.4970834913331093	0.6645337202022525	0.5661226422764427	0.6725830197938819	0.9738166517663597	0.9698314566222589	0.696037756441663	0.6725830197938819
3	0.6551611320137412	0.6476788835455759	1.5407967425155846	0.6485376883277358	0.536407523415636	0.6551611320137412	0.970827782403818	0.9660546240181077	0.6773293854342899	0.6551611320137412
4	0.6541796172092262	0.6470003080049106	1.6952661790333252	0.6484459682636127	0.546937299664454	0.6541796172092262	0.9692544089970665	0.963682838460723	0.6889504830583303	0.6541796172092262
mean	0.6514595881862929	0.64467540173076	1.624692089459927	0.646711394533499	0.5370229934401622	0.6514595881862929	0.970554372713262	0.9659215110882124	0.6860317775413008	0.6514595881862929
std	0.028767541772521714	0.028254287612481412	0.17262174497310248	0.023369651210019042	0.030823281552528295	0.028767541772521714	0.0036434764454587646	0.004501425691566275	0.006280936747186339	0.028767541772521714

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 27387.4323 secs

