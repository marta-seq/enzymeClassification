/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_hot_lev3_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f15e43d1490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f15e43d1340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f15e43d1820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f15e43d17f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.90      0.87       825
         1.0       0.00      0.00      0.00        14
         2.0       1.00      0.52      0.68        31
         3.0       0.00      0.00      0.00        11
         4.0       0.68      0.87      0.76        52
         5.0       0.69      0.81      0.74       176
         6.0       0.67      0.63      0.65       102
         7.0       0.73      0.20      0.31        97
         8.0       0.75      0.21      0.33        14
         9.0       0.75      0.30      0.43        70
        10.0       0.92      0.70      0.80       104
        11.0       0.33      0.06      0.10        18
        12.0       0.26      0.36      0.30        14
        13.0       0.67      0.74      0.70        43
        14.0       0.85      0.50      0.63        34
        15.0       0.88      0.77      0.82        64
        16.0       0.00      0.00      0.00        13
        17.0       0.92      0.58      0.71        19
        18.0       0.93      0.89      0.91        72
        19.0       1.00      0.17      0.29        30
        20.0       0.97      0.96      0.96        94
        21.0       0.59      0.80      0.68        46
        22.0       1.00      0.72      0.84        25
        23.0       0.99      0.91      0.95       345
        24.0       0.84      0.87      0.85        30
        25.0       1.00      0.10      0.18        20
        26.0       0.70      0.77      0.73       167
        27.0       0.83      0.69      0.76        36
        28.0       0.98      0.87      0.92        61
        29.0       0.64      0.84      0.73        63
        30.0       0.75      0.27      0.40        11
        31.0       0.00      0.00      0.00        11
        32.0       0.70      0.53      0.60        40
        33.0       0.89      0.67      0.77        73
        34.0       1.00      1.00      1.00        57
        35.0       0.82      0.93      0.87        15
        36.0       0.33      0.16      0.22        50
        37.0       1.00      0.63      0.77        19
        38.0       0.90      0.62      0.73        29
        39.0       0.85      0.95      0.90       101
        40.0       0.67      0.17      0.27        12
        41.0       1.00      1.00      1.00        14
        42.0       0.95      0.84      0.89        67
        43.0       0.92      0.86      0.88        76
        44.0       1.00      1.00      1.00        11
        45.0       0.91      0.86      0.89        37
        46.0       0.83      0.93      0.87      1613
        47.0       0.99      0.97      0.98       299
        48.0       0.99      0.98      0.98       244
        49.0       0.80      0.94      0.87       168
        50.0       0.85      0.75      0.80      1024
        51.0       0.88      0.68      0.77       353
        52.0       0.98      0.67      0.80        86
        53.0       0.69      0.84      0.76       607
        54.0       0.92      0.90      0.91       543
        55.0       0.99      0.91      0.95        78
        56.0       0.86      0.93      0.89       954
        57.0       0.87      0.93      0.90       247
        58.0       1.00      0.97      0.99        34
        59.0       0.78      0.87      0.83       877
        60.0       0.88      0.84      0.86        77
        61.0       0.91      0.83      0.87       566
        62.0       0.89      0.67      0.76        24
        63.0       1.00      0.44      0.61        55
        64.0       0.98      0.97      0.97       254
        65.0       1.00      0.21      0.35        14
        66.0       0.96      0.95      0.96       456
        67.0       1.00      0.68      0.81        38
        68.0       0.65      0.92      0.76      1189
        69.0       0.90      0.80      0.85       224
        70.0       0.75      0.47      0.58        19
        71.0       0.99      0.94      0.96       358
        72.0       1.00      0.44      0.61        32
        73.0       0.00      0.00      0.00        13
        74.0       0.98      0.97      0.98       127
        75.0       1.00      0.92      0.96        12
        76.0       0.70      0.79      0.74       460
        77.0       0.95      0.85      0.90       103
        78.0       0.88      0.13      0.23        52
        79.0       0.71      0.67      0.69        83
        80.0       0.69      0.42      0.53        80
        81.0       0.99      0.85      0.91        84
        82.0       0.88      0.88      0.88       335
        83.0       1.00      0.30      0.47        23
        84.0       0.67      0.73      0.70       518
        85.0       0.44      0.05      0.08        87
        86.0       0.60      0.23      0.33        13
        87.0       0.58      0.71      0.64       480
        88.0       0.93      0.60      0.73       126
        89.0       0.96      0.92      0.94        25
        90.0       1.00      0.64      0.78       152
        91.0       0.86      0.30      0.44        20
        92.0       0.86      0.21      0.34        28
        93.0       0.88      0.50      0.64        42
        94.0       0.60      0.09      0.15        34
        95.0       0.56      0.39      0.46        99
        96.0       0.92      0.79      0.85       415
        97.0       0.97      0.52      0.67       118
        98.0       0.93      0.65      0.76        99
        99.0       0.96      0.69      0.80       253
       100.0       0.98      0.91      0.94       116
       101.0       0.56      0.86      0.68       423
       102.0       0.97      0.87      0.91        99
       103.0       0.91      0.83      0.87        60
       104.0       0.92      0.82      0.87       266
       105.0       0.76      0.86      0.81        37
       106.0       0.88      0.86      0.87       494
       107.0       0.92      0.79      0.85        14
       108.0       0.97      0.74      0.84       610
       109.0       1.00      0.83      0.91       206
       110.0       0.85      0.50      0.63        22
       111.0       0.69      0.93      0.79       534
       112.0       0.61      0.68      0.64        98
       113.0       0.80      0.66      0.73        86
       114.0       0.89      0.90      0.89       109
       115.0       0.65      0.94      0.77       858
       116.0       1.00      0.03      0.06        61
       117.0       0.99      0.91      0.95       209
       118.0       0.00      0.00      0.00        13
       119.0       0.94      0.75      0.84        65
       120.0       0.98      0.93      0.95       156
       121.0       0.99      0.95      0.97        84
       122.0       0.97      0.51      0.67        55
       123.0       0.95      0.79      0.87       154
       124.0       0.92      0.90      0.91        52
       125.0       0.97      0.86      0.91       147
       126.0       0.42      0.64      0.51        77
       127.0       0.94      0.84      0.89        19
       128.0       0.98      0.82      0.89       198
       129.0       0.87      0.94      0.90       450
       130.0       1.00      0.73      0.84        11
       131.0       0.47      0.65      0.54        43
       132.0       0.93      0.81      0.87        16
       133.0       0.93      0.96      0.94       204
       134.0       0.99      0.91      0.95        76
       135.0       0.86      0.84      0.85       255
       136.0       0.67      0.30      0.41        20
       137.0       0.82      0.69      0.75        13
       138.0       0.89      0.37      0.53        67
       139.0       0.99      0.93      0.96      1464
       140.0       0.97      0.84      0.90       146
       141.0       0.92      0.93      0.92        99
       142.0       0.97      0.87      0.92       455
       143.0       0.94      0.93      0.93        82
       144.0       0.99      0.96      0.97       411
       145.0       0.92      0.96      0.94       406
       146.0       0.50      0.25      0.33        12
       147.0       0.99      0.77      0.86       149
       148.0       0.96      0.93      0.94       703
       149.0       0.99      0.95      0.97       195
       150.0       0.85      0.67      0.75        33
       151.0       0.95      0.85      0.90        68
       152.0       0.94      0.89      0.92        93
       153.0       0.91      0.94      0.93        33
       154.0       0.87      0.92      0.89        49
       155.0       0.93      0.91      0.92       154

    accuracy                           0.84     28656
   macro avg       0.82      0.69      0.72     28656
weighted avg       0.85      0.84      0.83     28656


===confusion_matrix===

[[746   0   0 ...   0   0   0]
 [  0   0   0 ...   0   0   0]
 [  0   0  16 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  45   2]
 [  0   0   0 ...   0   5 140]]

===multilabel confusion matrix===

[[[27687   144]
  [   79   746]]

 [[28642     0]
  [   14     0]]

 [[28625     0]
  [   15    16]]

 [[28645     0]
  [   11     0]]

 [[28583    21]
  [    7    45]]

 [[28416    64]
  [   34   142]]

 [[28523    31]
  [   38    64]]

 [[28552     7]
  [   78    19]]

 [[28641     1]
  [   11     3]]

 [[28579     7]
  [   49    21]]

 [[28546     6]
  [   31    73]]

 [[28636     2]
  [   17     1]]

 [[28628    14]
  [    9     5]]

 [[28597    16]
  [   11    32]]

 [[28619     3]
  [   17    17]]

 [[28585     7]
  [   15    49]]

 [[28643     0]
  [   13     0]]

 [[28636     1]
  [    8    11]]

 [[28579     5]
  [    8    64]]

 [[28626     0]
  [   25     5]]

 [[28559     3]
  [    4    90]]

 [[28584    26]
  [    9    37]]

 [[28631     0]
  [    7    18]]

 [[28309     2]
  [   31   314]]

 [[28621     5]
  [    4    26]]

 [[28636     0]
  [   18     2]]

 [[28433    56]
  [   38   129]]

 [[28615     5]
  [   11    25]]

 [[28594     1]
  [    8    53]]

 [[28563    30]
  [   10    53]]

 [[28644     1]
  [    8     3]]

 [[28644     1]
  [   11     0]]

 [[28607     9]
  [   19    21]]

 [[28577     6]
  [   24    49]]

 [[28599     0]
  [    0    57]]

 [[28638     3]
  [    1    14]]

 [[28590    16]
  [   42     8]]

 [[28637     0]
  [    7    12]]

 [[28625     2]
  [   11    18]]

 [[28538    17]
  [    5    96]]

 [[28643     1]
  [   10     2]]

 [[28642     0]
  [    0    14]]

 [[28586     3]
  [   11    56]]

 [[28574     6]
  [   11    65]]

 [[28645     0]
  [    0    11]]

 [[28616     3]
  [    5    32]]

 [[26731   312]
  [  119  1494]]

 [[28353     4]
  [    9   290]]

 [[28409     3]
  [    6   238]]

 [[28449    39]
  [   10   158]]

 [[27493   139]
  [  251   773]]

 [[28269    34]
  [  112   241]]

 [[28569     1]
  [   28    58]]

 [[27819   230]
  [   98   509]]

 [[28072    41]
  [   55   488]]

 [[28577     1]
  [    7    71]]

 [[27553   149]
  [   69   885]]

 [[28376    33]
  [   18   229]]

 [[28622     0]
  [    1    33]]

 [[27568   211]
  [  113   764]]

 [[28570     9]
  [   12    65]]

 [[28042    48]
  [   96   470]]

 [[28630     2]
  [    8    16]]

 [[28601     0]
  [   31    24]]

 [[28396     6]
  [    7   247]]

 [[28642     0]
  [   11     3]]

 [[28184    16]
  [   24   432]]

 [[28618     0]
  [   12    26]]

 [[26877   590]
  [  101  1088]]

 [[28411    21]
  [   44   180]]

 [[28634     3]
  [   10     9]]

 [[28295     3]
  [   23   335]]

 [[28624     0]
  [   18    14]]

 [[28643     0]
  [   13     0]]

 [[28527     2]
  [    4   123]]

 [[28644     0]
  [    1    11]]

 [[28043   153]
  [   98   362]]

 [[28548     5]
  [   15    88]]

 [[28603     1]
  [   45     7]]

 [[28550    23]
  [   27    56]]

 [[28561    15]
  [   46    34]]

 [[28571     1]
  [   13    71]]

 [[28282    39]
  [   40   295]]

 [[28633     0]
  [   16     7]]

 [[27950   188]
  [  138   380]]

 [[28564     5]
  [   83     4]]

 [[28641     2]
  [   10     3]]

 [[27931   245]
  [  140   340]]

 [[28524     6]
  [   50    76]]

 [[28630     1]
  [    2    23]]

 [[28504     0]
  [   55    97]]

 [[28635     1]
  [   14     6]]

 [[28627     1]
  [   22     6]]

 [[28611     3]
  [   21    21]]

 [[28620     2]
  [   31     3]]

 [[28526    31]
  [   60    39]]

 [[28213    28]
  [   86   329]]

 [[28536     2]
  [   57    61]]

 [[28552     5]
  [   35    64]]

 [[28396     7]
  [   78   175]]

 [[28538     2]
  [   11   105]]

 [[27946   287]
  [   61   362]]

 [[28554     3]
  [   13    86]]

 [[28591     5]
  [   10    50]]

 [[28372    18]
  [   49   217]]

 [[28609    10]
  [    5    32]]

 [[28104    58]
  [   69   425]]

 [[28641     1]
  [    3    11]]

 [[28032    14]
  [  161   449]]

 [[28450     0]
  [   34   172]]

 [[28632     2]
  [   11    11]]

 [[27904   218]
  [   38   496]]

 [[28515    43]
  [   31    67]]

 [[28556    14]
  [   29    57]]

 [[28535    12]
  [   11    98]]

 [[27367   431]
  [   51   807]]

 [[28595     0]
  [   59     2]]

 [[28445     2]
  [   19   190]]

 [[28643     0]
  [   13     0]]

 [[28588     3]
  [   16    49]]

 [[28497     3]
  [   11   145]]

 [[28571     1]
  [    4    80]]

 [[28600     1]
  [   27    28]]

 [[28496     6]
  [   32   122]]

 [[28600     4]
  [    5    47]]

 [[28505     4]
  [   20   127]]

 [[28511    68]
  [   28    49]]

 [[28636     1]
  [    3    16]]

 [[28454     4]
  [   35   163]]

 [[28145    61]
  [   29   421]]

 [[28645     0]
  [    3     8]]

 [[28581    32]
  [   15    28]]

 [[28639     1]
  [    3    13]]

 [[28438    14]
  [    9   195]]

 [[28579     1]
  [    7    69]]

 [[28366    35]
  [   42   213]]

 [[28633     3]
  [   14     6]]

 [[28641     2]
  [    4     9]]

 [[28586     3]
  [   42    25]]

 [[27179    13]
  [  107  1357]]

 [[28506     4]
  [   23   123]]

 [[28549     8]
  [    7    92]]

 [[28189    12]
  [   57   398]]

 [[28569     5]
  [    6    76]]

 [[28239     6]
  [   16   395]]

 [[28215    35]
  [   17   389]]

 [[28641     3]
  [    9     3]]

 [[28506     1]
  [   35   114]]

 [[27925    28]
  [   49   654]]

 [[28460     1]
  [   10   185]]

 [[28619     4]
  [   11    22]]

 [[28585     3]
  [   10    58]]

 [[28558     5]
  [   10    83]]

 [[28620     3]
  [    2    31]]

 [[28600     7]
  [    4    45]]

 [[28491    11]
  [   14   140]]]

===scores report===
metrics	scores
Accuracy	0.8359
MCC	0.8326
log_loss	0.7557
f1 score weighted	0.8314
f1 score macro	0.7220
f1 score micro	0.8359
roc_auc ovr	0.9936
roc_auc ovo	0.9907
precision	0.8501
recall	0.8359

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f15e43d1490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f15e43d1340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f15e43d1820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f15e43d17f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([56., 56., 56., ..., 98., 51., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.96      0.82       825
         1.0       0.67      0.14      0.24        14
         2.0       0.86      0.61      0.72        31
         3.0       0.00      0.00      0.00        12
         4.0       0.97      0.69      0.81        52
         5.0       0.62      0.79      0.70       176
         6.0       0.55      0.58      0.56       102
         7.0       0.54      0.38      0.45        97
         8.0       0.58      0.50      0.54        14
         9.0       0.42      0.40      0.41        70
        10.0       0.75      0.80      0.78       104
        11.0       0.00      0.00      0.00        18
        12.0       0.50      0.07      0.12        14
        13.0       0.76      0.62      0.68        42
        14.0       0.94      0.47      0.63        34
        15.0       0.79      0.78      0.79        64
        16.0       1.00      0.21      0.35        14
        17.0       0.79      0.58      0.67        19
        18.0       1.00      0.90      0.95        72
        19.0       0.73      0.26      0.38        31
        20.0       0.89      0.98      0.93        94
        21.0       0.97      0.76      0.85        45
        22.0       0.96      0.88      0.92        25
        23.0       0.92      0.95      0.94       346
        24.0       0.96      0.77      0.85        30
        25.0       0.33      0.32      0.32        19
        26.0       0.69      0.66      0.67       167
        27.0       0.93      0.69      0.79        36
        28.0       0.98      0.95      0.97        60
        29.0       0.94      0.71      0.81        62
        30.0       0.71      0.45      0.56        11
        31.0       0.00      0.00      0.00        11
        32.0       0.38      0.25      0.30        40
        33.0       0.90      0.62      0.74        74
        34.0       0.97      1.00      0.98        56
        35.0       1.00      0.81      0.90        16
        36.0       0.85      0.22      0.34        51
        37.0       0.93      0.74      0.82        19
        38.0       0.94      0.55      0.70        29
        39.0       0.87      0.87      0.87       101
        40.0       0.89      0.67      0.76        12
        41.0       1.00      1.00      1.00        13
        42.0       0.95      0.78      0.85        67
        43.0       0.77      0.96      0.85        76
        44.0       0.92      1.00      0.96        12
        45.0       0.89      0.86      0.87        36
        46.0       0.86      0.91      0.89      1613
        47.0       0.93      0.97      0.95       299
        48.0       0.98      0.98      0.98       243
        49.0       0.84      0.93      0.88       169
        50.0       0.77      0.82      0.79      1024
        51.0       0.91      0.59      0.72       352
        52.0       0.67      0.94      0.78        86
        53.0       0.84      0.76      0.80       607
        54.0       0.94      0.91      0.93       543
        55.0       0.94      0.86      0.90        78
        56.0       0.96      0.83      0.89       954
        57.0       0.79      0.93      0.85       247
        58.0       0.94      1.00      0.97        34
        59.0       0.90      0.84      0.87       877
        60.0       0.97      0.83      0.90        77
        61.0       0.93      0.80      0.86       565
        62.0       0.85      0.46      0.59        24
        63.0       0.92      0.42      0.57        55
        64.0       0.99      0.98      0.98       255
        65.0       0.78      0.50      0.61        14
        66.0       0.97      0.92      0.95       457
        67.0       1.00      0.70      0.83        37
        68.0       0.93      0.79      0.86      1189
        69.0       0.95      0.82      0.88       224
        70.0       0.81      0.65      0.72        20
        71.0       0.94      0.94      0.94       358
        72.0       0.91      0.66      0.76        32
        73.0       1.00      0.08      0.14        13
        74.0       0.97      0.95      0.96       128
        75.0       0.85      0.85      0.85        13
        76.0       0.63      0.82      0.71       460
        77.0       0.98      0.82      0.89       104
        78.0       0.75      0.35      0.47        52
        79.0       0.84      0.57      0.68        84
        80.0       0.31      0.42      0.36        80
        81.0       0.93      0.81      0.86        83
        82.0       0.93      0.89      0.91       335
        83.0       0.62      0.21      0.31        24
        84.0       0.60      0.78      0.68       518
        85.0       0.45      0.06      0.10        88
        86.0       1.00      0.15      0.27        13
        87.0       0.45      0.88      0.59       480
        88.0       0.80      0.65      0.72       126
        89.0       1.00      1.00      1.00        25
        90.0       0.70      0.86      0.77       153
        91.0       0.83      0.25      0.38        20
        92.0       0.89      0.30      0.44        27
        93.0       0.90      0.64      0.75        42
        94.0       0.67      0.06      0.11        34
        95.0       0.30      0.30      0.30        99
        96.0       0.93      0.82      0.87       416
        97.0       0.87      0.45      0.59       118
        98.0       0.97      0.63      0.76        99
        99.0       0.87      0.76      0.81       253
       100.0       0.99      0.86      0.92       115
       101.0       0.66      0.82      0.73       423
       102.0       0.95      0.78      0.86        99
       103.0       0.71      0.80      0.75        61
       104.0       0.69      0.88      0.77       266
       105.0       0.82      0.86      0.84        36
       106.0       0.90      0.80      0.84       494
       107.0       1.00      0.79      0.88        14
       108.0       0.94      0.78      0.85       610
       109.0       0.98      0.83      0.90       206
       110.0       0.89      0.36      0.52        22
       111.0       0.87      0.89      0.88       535
       112.0       0.61      0.63      0.62        98
       113.0       0.70      0.55      0.61        86
       114.0       0.77      0.90      0.83       109
       115.0       0.78      0.93      0.85       858
       116.0       0.69      0.36      0.47        61
       117.0       0.95      0.88      0.91       208
       118.0       0.67      0.15      0.25        13
       119.0       0.70      0.69      0.70        65
       120.0       0.99      0.88      0.93       157
       121.0       0.98      0.98      0.98        84
       122.0       0.76      0.47      0.58        55
       123.0       0.84      0.73      0.78       154
       124.0       0.94      0.88      0.91        52
       125.0       0.77      0.93      0.84       147
       126.0       0.76      0.66      0.71        77
       127.0       0.94      0.83      0.88        18
       128.0       0.88      0.84      0.86       197
       129.0       0.91      0.93      0.92       449
       130.0       1.00      0.55      0.71        11
       131.0       0.73      0.56      0.63        43
       132.0       0.92      0.73      0.81        15
       133.0       0.94      0.98      0.96       204
       134.0       0.96      0.92      0.94        76
       135.0       0.89      0.84      0.87       255
       136.0       0.78      0.37      0.50        19
       137.0       1.00      0.92      0.96        13
       138.0       0.79      0.39      0.52        67
       139.0       0.86      0.99      0.92      1463
       140.0       0.94      0.89      0.92       147
       141.0       0.80      0.88      0.84        99
       142.0       0.94      0.90      0.92       455
       143.0       0.97      0.94      0.96        82
       144.0       0.93      0.93      0.93       410
       145.0       0.97      0.96      0.96       406
       146.0       0.75      0.25      0.38        12
       147.0       0.93      0.92      0.92       149
       148.0       0.94      0.97      0.95       702
       149.0       0.98      0.93      0.96       196
       150.0       1.00      0.56      0.72        32
       151.0       0.89      0.93      0.91        69
       152.0       0.85      0.98      0.91        93
       153.0       0.83      0.91      0.87        32
       154.0       0.94      0.94      0.94        49
       155.0       0.98      0.91      0.94       154

    accuracy                           0.84     28655
   macro avg       0.82      0.70      0.73     28655
weighted avg       0.85      0.84      0.83     28655


===confusion_matrix===

[[791   0   0 ...   0   1   0]
 [  3   2   0 ...   0   0   0]
 [  1   0  19 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   0]
 [  0   0   0 ...   1  46   1]
 [  0   0   0 ...   1   1 140]]

===multilabel confusion matrix===

[[[27518   312]
  [   34   791]]

 [[28640     1]
  [   12     2]]

 [[28621     3]
  [   12    19]]

 [[28643     0]
  [   12     0]]

 [[28602     1]
  [   16    36]]

 [[28394    85]
  [   37   139]]

 [[28504    49]
  [   43    59]]

 [[28526    32]
  [   60    37]]

 [[28636     5]
  [    7     7]]

 [[28546    39]
  [   42    28]]

 [[28524    27]
  [   21    83]]

 [[28637     0]
  [   18     0]]

 [[28640     1]
  [   13     1]]

 [[28605     8]
  [   16    26]]

 [[28620     1]
  [   18    16]]

 [[28578    13]
  [   14    50]]

 [[28641     0]
  [   11     3]]

 [[28633     3]
  [    8    11]]

 [[28583     0]
  [    7    65]]

 [[28621     3]
  [   23     8]]

 [[28550    11]
  [    2    92]]

 [[28609     1]
  [   11    34]]

 [[28629     1]
  [    3    22]]

 [[28281    28]
  [   17   329]]

 [[28624     1]
  [    7    23]]

 [[28624    12]
  [   13     6]]

 [[28437    51]
  [   56   111]]

 [[28617     2]
  [   11    25]]

 [[28594     1]
  [    3    57]]

 [[28590     3]
  [   18    44]]

 [[28642     2]
  [    6     5]]

 [[28639     5]
  [   11     0]]

 [[28599    16]
  [   30    10]]

 [[28576     5]
  [   28    46]]

 [[28597     2]
  [    0    56]]

 [[28639     0]
  [    3    13]]

 [[28602     2]
  [   40    11]]

 [[28635     1]
  [    5    14]]

 [[28625     1]
  [   13    16]]

 [[28541    13]
  [   13    88]]

 [[28642     1]
  [    4     8]]

 [[28642     0]
  [    0    13]]

 [[28585     3]
  [   15    52]]

 [[28557    22]
  [    3    73]]

 [[28642     1]
  [    0    12]]

 [[28615     4]
  [    5    31]]

 [[26801   241]
  [  140  1473]]

 [[28335    21]
  [   10   289]]

 [[28406     6]
  [    4   239]]

 [[28457    29]
  [   12   157]]

 [[27377   254]
  [  188   836]]

 [[28283    20]
  [  144   208]]

 [[28529    40]
  [    5    81]]

 [[27957    91]
  [  144   463]]

 [[28083    29]
  [   48   495]]

 [[28573     4]
  [   11    67]]

 [[27666    35]
  [  162   792]]

 [[28347    61]
  [   18   229]]

 [[28619     2]
  [    0    34]]

 [[27696    82]
  [  143   734]]

 [[28576     2]
  [   13    64]]

 [[28056    34]
  [  114   451]]

 [[28629     2]
  [   13    11]]

 [[28598     2]
  [   32    23]]

 [[28397     3]
  [    5   250]]

 [[28639     2]
  [    7     7]]

 [[28184    14]
  [   35   422]]

 [[28618     0]
  [   11    26]]

 [[27398    68]
  [  244   945]]

 [[28422     9]
  [   40   184]]

 [[28632     3]
  [    7    13]]

 [[28275    22]
  [   23   335]]

 [[28621     2]
  [   11    21]]

 [[28642     0]
  [   12     1]]

 [[28523     4]
  [    7   121]]

 [[28640     2]
  [    2    11]]

 [[27977   218]
  [   83   377]]

 [[28549     2]
  [   19    85]]

 [[28597     6]
  [   34    18]]

 [[28562     9]
  [   36    48]]

 [[28498    77]
  [   46    34]]

 [[28567     5]
  [   16    67]]

 [[28298    22]
  [   38   297]]

 [[28628     3]
  [   19     5]]

 [[27871   266]
  [  114   404]]

 [[28561     6]
  [   83     5]]

 [[28642     0]
  [   11     2]]

 [[27653   522]
  [   57   423]]

 [[28509    20]
  [   44    82]]

 [[28630     0]
  [    0    25]]

 [[28446    56]
  [   21   132]]

 [[28634     1]
  [   15     5]]

 [[28627     1]
  [   19     8]]

 [[28610     3]
  [   15    27]]

 [[28620     1]
  [   32     2]]

 [[28486    70]
  [   69    30]]

 [[28214    25]
  [   74   342]]

 [[28529     8]
  [   65    53]]

 [[28554     2]
  [   37    62]]

 [[28373    29]
  [   61   192]]

 [[28539     1]
  [   16    99]]

 [[28056   176]
  [   76   347]]

 [[28552     4]
  [   22    77]]

 [[28574    20]
  [   12    49]]

 [[28281   108]
  [   31   235]]

 [[28612     7]
  [    5    31]]

 [[28116    45]
  [  101   393]]

 [[28641     0]
  [    3    11]]

 [[28017    28]
  [  137   473]]

 [[28446     3]
  [   34   172]]

 [[28632     1]
  [   14     8]]

 [[28049    71]
  [   61   474]]

 [[28518    39]
  [   36    62]]

 [[28549    20]
  [   39    47]]

 [[28517    29]
  [   11    98]]

 [[27568   229]
  [   60   798]]

 [[28584    10]
  [   39    22]]

 [[28438     9]
  [   26   182]]

 [[28641     1]
  [   11     2]]

 [[28571    19]
  [   20    45]]

 [[28496     2]
  [   19   138]]

 [[28569     2]
  [    2    82]]

 [[28592     8]
  [   29    26]]

 [[28480    21]
  [   41   113]]

 [[28600     3]
  [    6    46]]

 [[28468    40]
  [   11   136]]

 [[28562    16]
  [   26    51]]

 [[28636     1]
  [    3    15]]

 [[28435    23]
  [   31   166]]

 [[28167    39]
  [   32   417]]

 [[28644     0]
  [    5     6]]

 [[28603     9]
  [   19    24]]

 [[28639     1]
  [    4    11]]

 [[28439    12]
  [    4   200]]

 [[28576     3]
  [    6    70]]

 [[28374    26]
  [   40   215]]

 [[28634     2]
  [   12     7]]

 [[28642     0]
  [    1    12]]

 [[28581     7]
  [   41    26]]

 [[26958   234]
  [    8  1455]]

 [[28500     8]
  [   16   131]]

 [[28534    22]
  [   12    87]]

 [[28175    25]
  [   45   410]]

 [[28571     2]
  [    5    77]]

 [[28217    28]
  [   27   383]]

 [[28235    14]
  [   15   391]]

 [[28642     1]
  [    9     3]]

 [[28495    11]
  [   12   137]]

 [[27913    40]
  [   24   678]]

 [[28456     3]
  [   13   183]]

 [[28623     0]
  [   14    18]]

 [[28578     8]
  [    5    64]]

 [[28546    16]
  [    2    91]]

 [[28617     6]
  [    3    29]]

 [[28603     3]
  [    3    46]]

 [[28498     3]
  [   14   140]]]

===scores report===
metrics	scores
Accuracy	0.8371
MCC	0.8339
log_loss	0.7471
f1 score weighted	0.8347
f1 score macro	0.7329
f1 score micro	0.8371
roc_auc ovr	0.9934
roc_auc ovo	0.9900
precision	0.8508
recall	0.8371

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f15e43d1490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f15e43d1340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f15e43d1820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f15e43d17f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  51.,  96., 109.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.94      0.89       825
         1.0       0.60      0.21      0.32        14
         2.0       0.92      0.69      0.79        32
         3.0       0.00      0.00      0.00        12
         4.0       0.87      0.79      0.83        52
         5.0       0.69      0.81      0.75       176
         6.0       0.58      0.72      0.64       102
         7.0       0.58      0.31      0.40        97
         8.0       0.89      0.57      0.70        14
         9.0       0.53      0.33      0.41        69
        10.0       0.74      0.78      0.76       104
        11.0       1.00      0.06      0.11        18
        12.0       0.83      0.33      0.48        15
        13.0       0.84      0.74      0.78        42
        14.0       0.90      0.56      0.69        34
        15.0       0.82      0.84      0.83        64
        16.0       1.00      0.23      0.38        13
        17.0       0.80      0.42      0.55        19
        18.0       0.98      0.89      0.93        71
        19.0       0.82      0.29      0.43        31
        20.0       1.00      0.99      0.99        94
        21.0       0.80      0.80      0.80        46
        22.0       1.00      0.76      0.86        25
        23.0       0.97      0.96      0.96       346
        24.0       0.88      0.74      0.81        31
        25.0       0.33      0.05      0.09        20
        26.0       0.86      0.71      0.77       167
        27.0       0.90      0.75      0.82        36
        28.0       0.96      0.90      0.93        60
        29.0       0.96      0.87      0.92        62
        30.0       0.44      0.36      0.40        11
        31.0       0.00      0.00      0.00        12
        32.0       0.74      0.42      0.54        40
        33.0       0.94      0.80      0.86        74
        34.0       1.00      1.00      1.00        56
        35.0       0.88      0.88      0.88        16
        36.0       0.67      0.16      0.25        51
        37.0       0.62      0.95      0.75        19
        38.0       1.00      0.79      0.88        29
        39.0       0.93      0.96      0.95       101
        40.0       1.00      0.75      0.86        12
        41.0       1.00      1.00      1.00        13
        42.0       0.76      0.82      0.79        67
        43.0       0.92      0.91      0.91        76
        44.0       1.00      1.00      1.00        11
        45.0       1.00      0.76      0.86        37
        46.0       0.92      0.91      0.91      1613
        47.0       0.99      0.96      0.98       299
        48.0       1.00      0.94      0.97       243
        49.0       0.95      0.95      0.95       169
        50.0       0.89      0.83      0.86      1023
        51.0       0.84      0.78      0.81       352
        52.0       0.93      0.81      0.87        86
        53.0       0.80      0.83      0.81       606
        54.0       0.88      0.91      0.89       543
        55.0       0.93      0.85      0.89        79
        56.0       0.87      0.94      0.90       954
        57.0       0.82      0.95      0.88       247
        58.0       0.97      1.00      0.99        34
        59.0       0.87      0.88      0.88       877
        60.0       0.98      0.78      0.87        77
        61.0       0.80      0.88      0.84       566
        62.0       1.00      0.38      0.55        24
        63.0       0.72      0.56      0.63        55
        64.0       0.99      0.97      0.98       255
        65.0       1.00      0.15      0.27        13
        66.0       0.93      0.97      0.95       457
        67.0       1.00      0.76      0.86        37
        68.0       0.77      0.89      0.83      1189
        69.0       0.91      0.84      0.87       223
        70.0       0.80      0.42      0.55        19
        71.0       0.95      0.96      0.95       357
        72.0       0.85      0.53      0.65        32
        73.0       0.50      0.08      0.13        13
        74.0       0.95      0.96      0.96       128
        75.0       0.82      0.69      0.75        13
        76.0       0.78      0.81      0.79       460
        77.0       0.98      0.80      0.88       104
        78.0       0.66      0.40      0.49        53
        79.0       0.77      0.59      0.67        83
        80.0       0.60      0.57      0.58        79
        81.0       1.00      0.82      0.90        84
        82.0       0.94      0.87      0.90       334
        83.0       0.59      0.42      0.49        24
        84.0       0.75      0.77      0.76       518
        85.0       0.27      0.16      0.20        88
        86.0       1.00      0.15      0.27        13
        87.0       0.56      0.77      0.65       480
        88.0       0.79      0.70      0.74       127
        89.0       1.00      0.96      0.98        24
        90.0       0.78      0.80      0.79       153
        91.0       0.56      0.45      0.50        20
        92.0       1.00      0.52      0.68        27
        93.0       0.94      0.69      0.79        42
        94.0       0.50      0.24      0.32        34
        95.0       0.53      0.48      0.51        99
        96.0       0.78      0.87      0.82       416
        97.0       0.81      0.58      0.67       118
        98.0       0.86      0.84      0.85        99
        99.0       0.77      0.80      0.79       253
       100.0       0.99      0.97      0.98       115
       101.0       0.72      0.81      0.77       423
       102.0       0.77      0.80      0.78        98
       103.0       0.84      0.85      0.84        60
       104.0       0.90      0.82      0.86       265
       105.0       0.97      0.89      0.93        36
       106.0       0.85      0.86      0.85       495
       107.0       0.85      0.79      0.81        14
       108.0       0.86      0.87      0.87       610
       109.0       0.93      0.90      0.92       206
       110.0       0.89      0.36      0.52        22
       111.0       0.87      0.89      0.88       535
       112.0       0.75      0.59      0.66        98
       113.0       0.80      0.62      0.70        86
       114.0       0.97      0.90      0.93       110
       115.0       0.82      0.90      0.86       858
       116.0       0.69      0.54      0.61        61
       117.0       0.93      0.93      0.93       208
       118.0       0.00      0.00      0.00        13
       119.0       0.96      0.71      0.82        66
       120.0       0.95      0.92      0.94       157
       121.0       0.95      0.99      0.97        84
       122.0       0.86      0.58      0.70        55
       123.0       0.78      0.80      0.79       153
       124.0       0.93      0.96      0.94        52
       125.0       0.97      0.93      0.95       147
       126.0       0.85      0.66      0.74        76
       127.0       0.88      0.83      0.86        18
       128.0       0.81      0.87      0.84       197
       129.0       0.88      0.95      0.91       450
       130.0       0.82      0.75      0.78        12
       131.0       0.90      0.62      0.73        42
       132.0       1.00      0.87      0.93        15
       133.0       0.97      0.95      0.96       204
       134.0       1.00      0.91      0.95        76
       135.0       0.90      0.84      0.87       256
       136.0       1.00      0.26      0.42        19
       137.0       1.00      0.85      0.92        13
       138.0       0.82      0.61      0.70        67
       139.0       0.94      0.98      0.96      1464
       140.0       0.93      0.94      0.94       147
       141.0       0.95      0.90      0.92        98
       142.0       0.93      0.94      0.93       455
       143.0       0.99      0.93      0.96        82
       144.0       0.99      0.95      0.97       410
       145.0       0.94      0.97      0.95       406
       146.0       0.60      0.25      0.35        12
       147.0       0.98      0.87      0.92       149
       148.0       0.93      0.97      0.95       702
       149.0       0.97      0.97      0.97       196
       150.0       1.00      0.94      0.97        32
       151.0       0.97      0.88      0.92        69
       152.0       0.93      0.96      0.94        93
       153.0       0.90      0.85      0.88        33
       154.0       0.79      0.88      0.83        50
       155.0       0.93      0.91      0.92       154

    accuracy                           0.86     28655
   macro avg       0.84      0.73      0.76     28655
weighted avg       0.86      0.86      0.86     28655


===confusion_matrix===

[[778   0   0 ...   0   0   0]
 [  1   3   1 ...   0   0   0]
 [  0   0  22 ...   0   0   0]
 ...
 [  0   0   0 ...  28   1   0]
 [  0   0   0 ...   1  44   2]
 [  0   0   0 ...   1   8 140]]

===multilabel confusion matrix===

[[[27681   149]
  [   47   778]]

 [[28639     2]
  [   11     3]]

 [[28621     2]
  [   10    22]]

 [[28643     0]
  [   12     0]]

 [[28597     6]
  [   11    41]]

 [[28415    64]
  [   33   143]]

 [[28501    52]
  [   29    73]]

 [[28536    22]
  [   67    30]]

 [[28640     1]
  [    6     8]]

 [[28566    20]
  [   46    23]]

 [[28523    28]
  [   23    81]]

 [[28637     0]
  [   17     1]]

 [[28639     1]
  [   10     5]]

 [[28607     6]
  [   11    31]]

 [[28619     2]
  [   15    19]]

 [[28579    12]
  [   10    54]]

 [[28642     0]
  [   10     3]]

 [[28634     2]
  [   11     8]]

 [[28583     1]
  [    8    63]]

 [[28622     2]
  [   22     9]]

 [[28561     0]
  [    1    93]]

 [[28600     9]
  [    9    37]]

 [[28630     0]
  [    6    19]]

 [[28298    11]
  [   15   331]]

 [[28621     3]
  [    8    23]]

 [[28633     2]
  [   19     1]]

 [[28468    20]
  [   49   118]]

 [[28616     3]
  [    9    27]]

 [[28593     2]
  [    6    54]]

 [[28591     2]
  [    8    54]]

 [[28639     5]
  [    7     4]]

 [[28641     2]
  [   12     0]]

 [[28609     6]
  [   23    17]]

 [[28577     4]
  [   15    59]]

 [[28599     0]
  [    0    56]]

 [[28637     2]
  [    2    14]]

 [[28600     4]
  [   43     8]]

 [[28625    11]
  [    1    18]]

 [[28626     0]
  [    6    23]]

 [[28547     7]
  [    4    97]]

 [[28643     0]
  [    3     9]]

 [[28642     0]
  [    0    13]]

 [[28571    17]
  [   12    55]]

 [[28573     6]
  [    7    69]]

 [[28644     0]
  [    0    11]]

 [[28618     0]
  [    9    28]]

 [[26910   132]
  [  146  1467]]

 [[28354     2]
  [   11   288]]

 [[28412     0]
  [   14   229]]

 [[28478     8]
  [    9   160]]

 [[27525   107]
  [  178   845]]

 [[28249    54]
  [   76   276]]

 [[28564     5]
  [   16    70]]

 [[27920   129]
  [  103   503]]

 [[28043    69]
  [   51   492]]

 [[28571     5]
  [   12    67]]

 [[27571   130]
  [   62   892]]

 [[28357    51]
  [   12   235]]

 [[28620     1]
  [    0    34]]

 [[27667   111]
  [  105   772]]

 [[28577     1]
  [   17    60]]

 [[27967   122]
  [   68   498]]

 [[28631     0]
  [   15     9]]

 [[28588    12]
  [   24    31]]

 [[28397     3]
  [    8   247]]

 [[28642     0]
  [   11     2]]

 [[28165    33]
  [   15   442]]

 [[28618     0]
  [    9    28]]

 [[27149   317]
  [  126  1063]]

 [[28413    19]
  [   35   188]]

 [[28634     2]
  [   11     8]]

 [[28279    19]
  [   16   341]]

 [[28620     3]
  [   15    17]]

 [[28641     1]
  [   12     1]]

 [[28521     6]
  [    5   123]]

 [[28640     2]
  [    4     9]]

 [[28087   108]
  [   87   373]]

 [[28549     2]
  [   21    83]]

 [[28591    11]
  [   32    21]]

 [[28557    15]
  [   34    49]]

 [[28546    30]
  [   34    45]]

 [[28571     0]
  [   15    69]]

 [[28302    19]
  [   43   291]]

 [[28624     7]
  [   14    10]]

 [[28005   132]
  [  119   399]]

 [[28530    37]
  [   74    14]]

 [[28642     0]
  [   11     2]]

 [[27887   288]
  [  109   371]]

 [[28505    23]
  [   38    89]]

 [[28631     0]
  [    1    23]]

 [[28467    35]
  [   30   123]]

 [[28628     7]
  [   11     9]]

 [[28628     0]
  [   13    14]]

 [[28611     2]
  [   13    29]]

 [[28613     8]
  [   26     8]]

 [[28513    43]
  [   51    48]]

 [[28135   104]
  [   54   362]]

 [[28521    16]
  [   50    68]]

 [[28542    14]
  [   16    83]]

 [[28341    61]
  [   50   203]]

 [[28539     1]
  [    3   112]]

 [[28100   132]
  [   79   344]]

 [[28534    23]
  [   20    78]]

 [[28585    10]
  [    9    51]]

 [[28366    24]
  [   49   216]]

 [[28618     1]
  [    4    32]]

 [[28084    76]
  [   69   426]]

 [[28639     2]
  [    3    11]]

 [[27960    85]
  [   78   532]]

 [[28436    13]
  [   20   186]]

 [[28632     1]
  [   14     8]]

 [[28046    74]
  [   60   475]]

 [[28538    19]
  [   40    58]]

 [[28556    13]
  [   33    53]]

 [[28542     3]
  [   11    99]]

 [[27628   169]
  [   85   773]]

 [[28579    15]
  [   28    33]]

 [[28432    15]
  [   14   194]]

 [[28642     0]
  [   13     0]]

 [[28587     2]
  [   19    47]]

 [[28491     7]
  [   13   144]]

 [[28567     4]
  [    1    83]]

 [[28595     5]
  [   23    32]]

 [[28467    35]
  [   31   122]]

 [[28599     4]
  [    2    50]]

 [[28504     4]
  [   11   136]]

 [[28570     9]
  [   26    50]]

 [[28635     2]
  [    3    15]]

 [[28418    40]
  [   26   171]]

 [[28147    58]
  [   22   428]]

 [[28641     2]
  [    3     9]]

 [[28610     3]
  [   16    26]]

 [[28640     0]
  [    2    13]]

 [[28444     7]
  [   10   194]]

 [[28579     0]
  [    7    69]]

 [[28376    23]
  [   40   216]]

 [[28636     0]
  [   14     5]]

 [[28642     0]
  [    2    11]]

 [[28579     9]
  [   26    41]]

 [[27102    89]
  [   27  1437]]

 [[28498    10]
  [    9   138]]

 [[28552     5]
  [   10    88]]

 [[28167    33]
  [   29   426]]

 [[28572     1]
  [    6    76]]

 [[28241     4]
  [   19   391]]

 [[28222    27]
  [   11   395]]

 [[28641     2]
  [    9     3]]

 [[28503     3]
  [   19   130]]

 [[27901    52]
  [   22   680]]

 [[28454     5]
  [    6   190]]

 [[28623     0]
  [    2    30]]

 [[28584     2]
  [    8    61]]

 [[28555     7]
  [    4    89]]

 [[28619     3]
  [    5    28]]

 [[28593    12]
  [    6    44]]

 [[28490    11]
  [   14   140]]]

===scores report===
metrics	scores
Accuracy	0.8622
MCC	0.8593
log_loss	0.6351
f1 score weighted	0.8583
f1 score macro	0.7596
f1 score micro	0.8622
roc_auc ovr	0.9947
roc_auc ovo	0.9921
precision	0.8630
recall	0.8622

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f15e43d1490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f15e43d1340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f15e43d1820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f15e43d17f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  96.,  46., 108.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.95      0.80       824
         1.0       0.00      0.00      0.00        14
         2.0       0.96      0.69      0.80        32
         3.0       0.00      0.00      0.00        12
         4.0       0.89      0.79      0.84        52
         5.0       0.92      0.69      0.79       175
         6.0       0.71      0.53      0.61       101
         7.0       0.53      0.30      0.38        98
         8.0       1.00      0.29      0.44        14
         9.0       0.31      0.41      0.35        70
        10.0       0.47      0.80      0.59       104
        11.0       0.00      0.00      0.00        18
        12.0       0.33      0.27      0.30        15
        13.0       0.51      0.76      0.61        42
        14.0       0.81      0.38      0.52        34
        15.0       0.70      0.91      0.79        65
        16.0       0.11      0.08      0.09        13
        17.0       0.75      0.47      0.58        19
        18.0       0.95      0.81      0.87        72
        19.0       0.70      0.23      0.35        30
        20.0       1.00      0.97      0.98        94
        21.0       0.84      0.67      0.75        46
        22.0       1.00      0.68      0.81        25
        23.0       0.78      0.95      0.86       345
        24.0       1.00      0.63      0.78        30
        25.0       0.50      0.15      0.23        20
        26.0       0.58      0.80      0.68       168
        27.0       0.92      0.69      0.79        35
        28.0       0.83      0.85      0.84        61
        29.0       0.97      0.62      0.76        63
        30.0       1.00      0.36      0.53        11
        31.0       0.00      0.00      0.00        12
        32.0       1.00      0.35      0.52        40
        33.0       0.91      0.68      0.78        74
        34.0       0.92      0.98      0.95        57
        35.0       0.68      0.81      0.74        16
        36.0       0.50      0.14      0.22        50
        37.0       0.46      0.95      0.62        20
        38.0       0.90      0.62      0.73        29
        39.0       0.81      0.91      0.86       101
        40.0       0.60      0.25      0.35        12
        41.0       1.00      1.00      1.00        14
        42.0       0.87      0.61      0.72        67
        43.0       0.94      0.89      0.92        76
        44.0       0.91      0.91      0.91        11
        45.0       0.94      0.92      0.93        37
        46.0       0.90      0.89      0.90      1613
        47.0       0.97      0.98      0.98       299
        48.0       0.99      0.97      0.98       243
        49.0       0.99      0.91      0.95       168
        50.0       0.74      0.84      0.79      1024
        51.0       0.67      0.78      0.72       353
        52.0       0.82      0.85      0.83        85
        53.0       0.52      0.89      0.66       606
        54.0       0.71      0.91      0.79       543
        55.0       0.86      0.75      0.80        79
        56.0       0.81      0.92      0.86       954
        57.0       0.95      0.88      0.91       247
        58.0       1.00      0.94      0.97        34
        59.0       0.96      0.84      0.89       876
        60.0       0.99      0.88      0.93        76
        61.0       0.85      0.84      0.85       566
        62.0       1.00      0.21      0.34        24
        63.0       0.55      0.56      0.56        55
        64.0       0.96      0.96      0.96       255
        65.0       0.67      0.31      0.42        13
        66.0       0.98      0.97      0.98       457
        67.0       0.92      0.65      0.76        37
        68.0       0.88      0.86      0.87      1189
        69.0       0.74      0.83      0.78       223
        70.0       0.81      0.68      0.74        19
        71.0       0.94      0.93      0.94       357
        72.0       0.60      0.48      0.54        31
        73.0       0.00      0.00      0.00        13
        74.0       0.90      0.98      0.94       128
        75.0       1.00      0.62      0.76        13
        76.0       0.88      0.67      0.76       461
        77.0       0.99      0.79      0.88       104
        78.0       1.00      0.15      0.26        53
        79.0       0.88      0.46      0.60        83
        80.0       0.78      0.53      0.63        79
        81.0       0.91      0.86      0.88        84
        82.0       0.91      0.86      0.88       334
        83.0       0.73      0.33      0.46        24
        84.0       0.84      0.69      0.76       518
        85.0       0.38      0.03      0.06        88
        86.0       1.00      0.58      0.74        12
        87.0       0.58      0.68      0.63       481
        88.0       0.60      0.64      0.62       126
        89.0       1.00      0.96      0.98        24
        90.0       0.81      0.74      0.77       152
        91.0       0.45      0.25      0.32        20
        92.0       1.00      0.22      0.36        27
        93.0       0.92      0.57      0.71        42
        94.0       0.67      0.30      0.42        33
        95.0       0.82      0.36      0.50       100
        96.0       0.65      0.86      0.74       415
        97.0       0.44      0.69      0.54       118
        98.0       0.92      0.85      0.89       100
        99.0       0.68      0.69      0.68       253
       100.0       0.97      0.97      0.97       116
       101.0       0.81      0.78      0.79       423
       102.0       0.68      0.87      0.76        99
       103.0       0.92      0.57      0.70        60
       104.0       0.98      0.77      0.86       265
       105.0       1.00      0.86      0.93        36
       106.0       0.92      0.82      0.87       495
       107.0       1.00      0.93      0.97        15
       108.0       0.83      0.83      0.83       611
       109.0       0.92      0.94      0.93       207
       110.0       0.75      0.14      0.23        22
       111.0       0.95      0.81      0.87       535
       112.0       0.84      0.53      0.65        98
       113.0       0.83      0.51      0.63        87
       114.0       1.00      0.85      0.92       110
       115.0       0.91      0.86      0.89       858
       116.0       0.32      0.58      0.41        60
       117.0       0.94      0.89      0.91       209
       118.0       0.00      0.00      0.00        12
       119.0       0.98      0.68      0.80        66
       120.0       0.84      0.90      0.87       157
       121.0       0.96      0.96      0.96        84
       122.0       0.81      0.64      0.71        55
       123.0       0.94      0.73      0.82       153
       124.0       0.80      0.88      0.84        51
       125.0       0.99      0.86      0.92       146
       126.0       0.71      0.62      0.66        77
       127.0       1.00      0.78      0.88        18
       128.0       0.67      0.92      0.78       197
       129.0       0.95      0.94      0.94       450
       130.0       1.00      0.55      0.71        11
       131.0       0.83      0.60      0.69        42
       132.0       0.82      0.60      0.69        15
       133.0       0.99      0.95      0.97       204
       134.0       0.96      0.96      0.96        76
       135.0       0.76      0.88      0.81       256
       136.0       0.33      0.05      0.09        20
       137.0       0.76      1.00      0.87        13
       138.0       0.63      0.66      0.64        67
       139.0       0.99      0.96      0.97      1464
       140.0       0.96      0.82      0.89       147
       141.0       0.99      0.71      0.83        98
       142.0       0.99      0.88      0.93       455
       143.0       1.00      0.90      0.95        82
       144.0       0.97      0.93      0.95       410
       145.0       0.97      0.92      0.95       406
       146.0       1.00      0.08      0.15        12
       147.0       0.91      0.91      0.91       148
       148.0       0.95      0.96      0.96       702
       149.0       0.96      0.97      0.96       196
       150.0       0.95      0.56      0.71        32
       151.0       0.90      0.90      0.90        69
       152.0       0.91      0.99      0.95        93
       153.0       0.97      0.94      0.95        33
       154.0       0.91      0.82      0.86        50
       155.0       0.91      0.92      0.91       153

    accuracy                           0.83     28655
   macro avg       0.80      0.68      0.71     28655
weighted avg       0.85      0.83      0.83     28655


===confusion_matrix===

[[780   0   0 ...   0   0   0]
 [  1   0   0 ...   0   0   0]
 [  1   0  22 ...   0   0   0]
 ...
 [  0   0   0 ...  31   1   0]
 [  0   0   0 ...   0  41   7]
 [  0   0   0 ...   0   3 140]]

===multilabel confusion matrix===

[[[27484   347]
  [   44   780]]

 [[28640     1]
  [   14     0]]

 [[28622     1]
  [   10    22]]

 [[28643     0]
  [   12     0]]

 [[28598     5]
  [   11    41]]

 [[28469    11]
  [   54   121]]

 [[28532    22]
  [   47    54]]

 [[28531    26]
  [   69    29]]

 [[28641     0]
  [   10     4]]

 [[28520    65]
  [   41    29]]

 [[28459    92]
  [   21    83]]

 [[28637     0]
  [   18     0]]

 [[28632     8]
  [   11     4]]

 [[28582    31]
  [   10    32]]

 [[28618     3]
  [   21    13]]

 [[28565    25]
  [    6    59]]

 [[28634     8]
  [   12     1]]

 [[28633     3]
  [   10     9]]

 [[28580     3]
  [   14    58]]

 [[28622     3]
  [   23     7]]

 [[28561     0]
  [    3    91]]

 [[28603     6]
  [   15    31]]

 [[28630     0]
  [    8    17]]

 [[28217    93]
  [   16   329]]

 [[28625     0]
  [   11    19]]

 [[28632     3]
  [   17     3]]

 [[28391    96]
  [   33   135]]

 [[28618     2]
  [   11    24]]

 [[28583    11]
  [    9    52]]

 [[28591     1]
  [   24    39]]

 [[28644     0]
  [    7     4]]

 [[28637     6]
  [   12     0]]

 [[28615     0]
  [   26    14]]

 [[28576     5]
  [   24    50]]

 [[28593     5]
  [    1    56]]

 [[28633     6]
  [    3    13]]

 [[28598     7]
  [   43     7]]

 [[28613    22]
  [    1    19]]

 [[28624     2]
  [   11    18]]

 [[28533    21]
  [    9    92]]

 [[28641     2]
  [    9     3]]

 [[28641     0]
  [    0    14]]

 [[28582     6]
  [   26    41]]

 [[28575     4]
  [    8    68]]

 [[28643     1]
  [    1    10]]

 [[28616     2]
  [    3    34]]

 [[26887   155]
  [  172  1441]]

 [[28346    10]
  [    5   294]]

 [[28410     2]
  [    8   235]]

 [[28486     1]
  [   15   153]]

 [[27330   301]
  [  164   860]]

 [[28166   136]
  [   77   276]]

 [[28554    16]
  [   13    72]]

 [[27558   491]
  [   64   542]]

 [[27907   205]
  [   50   493]]

 [[28566    10]
  [   20    59]]

 [[27497   204]
  [   74   880]]

 [[28396    12]
  [   30   217]]

 [[28621     0]
  [    2    32]]

 [[27745    34]
  [  140   736]]

 [[28578     1]
  [    9    67]]

 [[28004    85]
  [   89   477]]

 [[28631     0]
  [   19     5]]

 [[28575    25]
  [   24    31]]

 [[28390    10]
  [   11   244]]

 [[28640     2]
  [    9     4]]

 [[28191     7]
  [   13   444]]

 [[28616     2]
  [   13    24]]

 [[27324   142]
  [  170  1019]]

 [[28367    65]
  [   37   186]]

 [[28633     3]
  [    6    13]]

 [[28277    21]
  [   24   333]]

 [[28614    10]
  [   16    15]]

 [[28642     0]
  [   13     0]]

 [[28513    14]
  [    2   126]]

 [[28642     0]
  [    5     8]]

 [[28152    42]
  [  153   308]]

 [[28550     1]
  [   22    82]]

 [[28602     0]
  [   45     8]]

 [[28567     5]
  [   45    38]]

 [[28564    12]
  [   37    42]]

 [[28564     7]
  [   12    72]]

 [[28294    27]
  [   48   286]]

 [[28628     3]
  [   16     8]]

 [[28068    69]
  [  160   358]]

 [[28562     5]
  [   85     3]]

 [[28643     0]
  [    5     7]]

 [[27933   241]
  [  152   329]]

 [[28474    55]
  [   45    81]]

 [[28631     0]
  [    1    23]]

 [[28476    27]
  [   40   112]]

 [[28629     6]
  [   15     5]]

 [[28628     0]
  [   21     6]]

 [[28611     2]
  [   18    24]]

 [[28617     5]
  [   23    10]]

 [[28547     8]
  [   64    36]]

 [[28049   191]
  [   59   356]]

 [[28431   106]
  [   36    82]]

 [[28548     7]
  [   15    85]]

 [[28319    83]
  [   78   175]]

 [[28536     3]
  [    3   113]]

 [[28153    79]
  [   95   328]]

 [[28516    40]
  [   13    86]]

 [[28592     3]
  [   26    34]]

 [[28386     4]
  [   61   204]]

 [[28619     0]
  [    5    31]]

 [[28125    35]
  [   87   408]]

 [[28640     0]
  [    1    14]]

 [[27938   106]
  [  104   507]]

 [[28431    17]
  [   13   194]]

 [[28632     1]
  [   19     3]]

 [[28097    23]
  [  102   433]]

 [[28547    10]
  [   46    52]]

 [[28559     9]
  [   43    44]]

 [[28545     0]
  [   17    93]]

 [[27726    71]
  [  118   740]]

 [[28519    76]
  [   25    35]]

 [[28434    12]
  [   24   185]]

 [[28643     0]
  [   12     0]]

 [[28588     1]
  [   21    45]]

 [[28471    27]
  [   16   141]]

 [[28568     3]
  [    3    81]]

 [[28592     8]
  [   20    35]]

 [[28495     7]
  [   42   111]]

 [[28593    11]
  [    6    45]]

 [[28508     1]
  [   20   126]]

 [[28558    20]
  [   29    48]]

 [[28637     0]
  [    4    14]]

 [[28370    88]
  [   16   181]]

 [[28183    22]
  [   29   421]]

 [[28644     0]
  [    5     6]]

 [[28608     5]
  [   17    25]]

 [[28638     2]
  [    6     9]]

 [[28450     1]
  [   10   194]]

 [[28576     3]
  [    3    73]]

 [[28327    72]
  [   32   224]]

 [[28633     2]
  [   19     1]]

 [[28638     4]
  [    0    13]]

 [[28562    26]
  [   23    44]]

 [[27177    14]
  [   61  1403]]

 [[28503     5]
  [   26   121]]

 [[28556     1]
  [   28    70]]

 [[28196     4]
  [   53   402]]

 [[28573     0]
  [    8    74]]

 [[28235    10]
  [   29   381]]

 [[28238    11]
  [   31   375]]

 [[28643     0]
  [   11     1]]

 [[28493    14]
  [   13   135]]

 [[27917    36]
  [   27   675]]

 [[28451     8]
  [    6   190]]

 [[28622     1]
  [   14    18]]

 [[28579     7]
  [    7    62]]

 [[28553     9]
  [    1    92]]

 [[28621     1]
  [    2    31]]

 [[28601     4]
  [    9    41]]

 [[28488    14]
  [   13   140]]]

===scores report===
metrics	scores
Accuracy	0.8342
MCC	0.8309
log_loss	0.7519
f1 score weighted	0.8319
f1 score macro	0.7110
f1 score micro	0.8342
roc_auc ovr	0.9936
roc_auc ovo	0.9904
precision	0.8485
recall	0.8342

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f15e43d1490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f15e43d1340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f15e43d1820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f15e43d17f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56., 115., ...,  96., 109.,  88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.92      0.89       824
         1.0       1.00      0.07      0.13        14
         2.0       0.76      0.69      0.72        32
         3.0       0.00      0.00      0.00        11
         4.0       0.83      0.69      0.75        51
         5.0       0.89      0.69      0.78       176
         6.0       0.77      0.58      0.66       102
         7.0       0.61      0.26      0.36        97
         8.0       0.86      0.43      0.57        14
         9.0       0.62      0.44      0.52        70
        10.0       0.81      0.84      0.83       103
        11.0       0.18      0.11      0.14        18
        12.0       0.50      0.20      0.29        15
        13.0       0.87      0.77      0.81        43
        14.0       0.88      0.62      0.72        34
        15.0       1.00      0.66      0.80        65
        16.0       0.23      0.23      0.23        13
        17.0       0.91      0.53      0.67        19
        18.0       0.97      0.89      0.93        72
        19.0       0.73      0.37      0.49        30
        20.0       0.99      0.99      0.99        94
        21.0       0.93      0.57      0.70        46
        22.0       1.00      0.28      0.44        25
        23.0       0.97      0.94      0.96       345
        24.0       0.81      0.73      0.77        30
        25.0       0.00      0.00      0.00        20
        26.0       0.87      0.66      0.75       168
        27.0       0.90      0.77      0.83        35
        28.0       0.93      0.90      0.92        61
        29.0       0.86      0.81      0.84        63
        30.0       0.67      0.55      0.60        11
        31.0       0.00      0.00      0.00        12
        32.0       0.90      0.23      0.36        40
        33.0       0.87      0.65      0.74        74
        34.0       1.00      1.00      1.00        57
        35.0       1.00      1.00      1.00        15
        36.0       0.17      0.02      0.04        50
        37.0       0.77      0.89      0.83        19
        38.0       0.90      0.66      0.76        29
        39.0       0.92      0.87      0.89       101
        40.0       1.00      0.69      0.82        13
        41.0       1.00      0.86      0.92        14
        42.0       0.71      0.86      0.78        66
        43.0       0.98      0.82      0.89        76
        44.0       1.00      0.82      0.90        11
        45.0       1.00      0.81      0.90        37
        46.0       0.83      0.92      0.87      1612
        47.0       0.99      0.99      0.99       299
        48.0       0.99      0.98      0.99       243
        49.0       0.96      0.90      0.93       168
        50.0       0.79      0.85      0.82      1024
        51.0       0.61      0.80      0.69       353
        52.0       0.95      0.88      0.91        85
        53.0       0.74      0.82      0.78       606
        54.0       0.93      0.90      0.92       543
        55.0       0.91      0.76      0.83        78
        56.0       0.93      0.89      0.91       954
        57.0       0.90      0.91      0.91       247
        58.0       1.00      1.00      1.00        34
        59.0       0.79      0.87      0.82       877
        60.0       0.97      0.82      0.89        76
        61.0       0.69      0.91      0.78       566
        62.0       0.88      0.29      0.44        24
        63.0       0.69      0.45      0.55        55
        64.0       1.00      0.96      0.98       255
        65.0       0.80      0.57      0.67        14
        66.0       0.96      0.95      0.96       457
        67.0       0.90      0.51      0.66        37
        68.0       0.72      0.90      0.80      1189
        69.0       0.85      0.89      0.87       224
        70.0       1.00      0.53      0.69        19
        71.0       0.94      0.96      0.95       357
        72.0       0.67      0.62      0.65        32
        73.0       0.00      0.00      0.00        12
        74.0       0.98      0.93      0.96       127
        75.0       1.00      0.92      0.96        12
        76.0       0.81      0.77      0.79       460
        77.0       0.94      0.84      0.89       103
        78.0       0.51      0.35      0.41        52
        79.0       0.66      0.64      0.65        83
        80.0       0.90      0.45      0.60        80
        81.0       0.96      0.82      0.88        84
        82.0       0.92      0.87      0.89       334
        83.0       0.79      0.48      0.59        23
        84.0       0.78      0.73      0.75       519
        85.0       0.10      0.05      0.06        88
        86.0       0.40      0.17      0.24        12
        87.0       0.74      0.57      0.64       480
        88.0       0.66      0.66      0.66       126
        89.0       1.00      1.00      1.00        25
        90.0       0.86      0.70      0.78       152
        91.0       1.00      0.25      0.40        20
        92.0       0.67      0.36      0.47        28
        93.0       0.96      0.64      0.77        42
        94.0       1.00      0.24      0.38        34
        95.0       0.39      0.40      0.39       100
        96.0       0.77      0.79      0.78       415
        97.0       0.82      0.39      0.53       118
        98.0       0.89      0.77      0.83        99
        99.0       0.78      0.74      0.76       253
       100.0       0.91      0.92      0.92       116
       101.0       0.78      0.78      0.78       423
       102.0       0.96      0.77      0.85        99
       103.0       1.00      0.75      0.86        60
       104.0       0.85      0.85      0.85       265
       105.0       1.00      0.81      0.90        37
       106.0       0.81      0.85      0.83       495
       107.0       1.00      0.67      0.80        15
       108.0       0.56      0.95      0.71       611
       109.0       0.94      0.91      0.92       206
       110.0       0.90      0.41      0.56        22
       111.0       0.78      0.90      0.83       534
       112.0       0.86      0.72      0.78        98
       113.0       0.72      0.61      0.66        87
       114.0       0.95      0.85      0.89       110
       115.0       0.90      0.90      0.90       858
       116.0       0.88      0.23      0.36        61
       117.0       0.87      0.93      0.90       209
       118.0       0.50      0.08      0.13        13
       119.0       0.89      0.83      0.86        65
       120.0       0.99      0.97      0.98       156
       121.0       0.97      1.00      0.98        85
       122.0       0.94      0.52      0.67        56
       123.0       0.90      0.72      0.80       154
       124.0       0.96      0.83      0.89        52
       125.0       0.96      0.90      0.93       146
       126.0       0.96      0.60      0.74        77
       127.0       0.88      0.78      0.82        18
       128.0       0.89      0.84      0.86       198
       129.0       0.99      0.89      0.93       450
       130.0       1.00      0.55      0.71        11
       131.0       0.96      0.56      0.71        43
       132.0       1.00      0.87      0.93        15
       133.0       0.99      0.94      0.97       205
       134.0       1.00      0.95      0.97        77
       135.0       0.87      0.79      0.83       255
       136.0       0.57      0.20      0.30        20
       137.0       0.85      0.92      0.88        12
       138.0       0.78      0.31      0.45        67
       139.0       0.97      0.97      0.97      1464
       140.0       0.94      0.90      0.92       147
       141.0       0.98      0.86      0.91        98
       142.0       0.88      0.91      0.89       455
       143.0       0.99      0.93      0.96        82
       144.0       0.95      0.93      0.94       411
       145.0       0.88      0.97      0.92       405
       146.0       1.00      0.45      0.62        11
       147.0       0.96      0.91      0.93       148
       148.0       0.94      0.95      0.95       702
       149.0       0.99      0.97      0.98       196
       150.0       0.94      0.53      0.68        32
       151.0       0.91      0.88      0.90        69
       152.0       0.98      0.89      0.93        93
       153.0       1.00      0.94      0.97        33
       154.0       0.94      0.88      0.91        50
       155.0       0.80      0.95      0.87       154

    accuracy                           0.84     28655
   macro avg       0.83      0.69      0.74     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[761   0   0 ...   0   0   0]
 [  2   1   0 ...   0   0   0]
 [  0   0  22 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   1]
 [  0   0   0 ...   0  44   6]
 [  0   0   0 ...   0   3 146]]

===multilabel confusion matrix===

[[[27697   134]
  [   63   761]]

 [[28641     0]
  [   13     1]]

 [[28616     7]
  [   10    22]]

 [[28644     0]
  [   11     0]]

 [[28597     7]
  [   16    35]]

 [[28464    15]
  [   55   121]]

 [[28535    18]
  [   43    59]]

 [[28542    16]
  [   72    25]]

 [[28640     1]
  [    8     6]]

 [[28566    19]
  [   39    31]]

 [[28532    20]
  [   16    87]]

 [[28628     9]
  [   16     2]]

 [[28637     3]
  [   12     3]]

 [[28607     5]
  [   10    33]]

 [[28618     3]
  [   13    21]]

 [[28590     0]
  [   22    43]]

 [[28632    10]
  [   10     3]]

 [[28635     1]
  [    9    10]]

 [[28581     2]
  [    8    64]]

 [[28621     4]
  [   19    11]]

 [[28560     1]
  [    1    93]]

 [[28607     2]
  [   20    26]]

 [[28630     0]
  [   18     7]]

 [[28300    10]
  [   20   325]]

 [[28620     5]
  [    8    22]]

 [[28635     0]
  [   20     0]]

 [[28471    16]
  [   57   111]]

 [[28617     3]
  [    8    27]]

 [[28590     4]
  [    6    55]]

 [[28584     8]
  [   12    51]]

 [[28641     3]
  [    5     6]]

 [[28638     5]
  [   12     0]]

 [[28614     1]
  [   31     9]]

 [[28574     7]
  [   26    48]]

 [[28598     0]
  [    0    57]]

 [[28640     0]
  [    0    15]]

 [[28600     5]
  [   49     1]]

 [[28631     5]
  [    2    17]]

 [[28624     2]
  [   10    19]]

 [[28546     8]
  [   13    88]]

 [[28642     0]
  [    4     9]]

 [[28641     0]
  [    2    12]]

 [[28566    23]
  [    9    57]]

 [[28578     1]
  [   14    62]]

 [[28644     0]
  [    2     9]]

 [[28618     0]
  [    7    30]]

 [[26731   312]
  [  121  1491]]

 [[28352     4]
  [    4   295]]

 [[28410     2]
  [    5   238]]

 [[28481     6]
  [   16   152]]

 [[27403   228]
  [  156   868]]

 [[28122   180]
  [   72   281]]

 [[28566     4]
  [   10    75]]

 [[27873   176]
  [  111   495]]

 [[28077    35]
  [   53   490]]

 [[28571     6]
  [   19    59]]

 [[27635    66]
  [  106   848]]

 [[28384    24]
  [   21   226]]

 [[28621     0]
  [    0    34]]

 [[27574   204]
  [  118   759]]

 [[28577     2]
  [   14    62]]

 [[27852   237]
  [   49   517]]

 [[28630     1]
  [   17     7]]

 [[28589    11]
  [   30    25]]

 [[28400     0]
  [   11   244]]

 [[28639     2]
  [    6     8]]

 [[28181    17]
  [   22   435]]

 [[28616     2]
  [   18    19]]

 [[27051   415]
  [  115  1074]]

 [[28396    35]
  [   25   199]]

 [[28636     0]
  [    9    10]]

 [[28277    21]
  [   16   341]]

 [[28613    10]
  [   12    20]]

 [[28643     0]
  [   12     0]]

 [[28526     2]
  [    9   118]]

 [[28643     0]
  [    1    11]]

 [[28114    81]
  [  107   353]]

 [[28546     6]
  [   16    87]]

 [[28586    17]
  [   34    18]]

 [[28545    27]
  [   30    53]]

 [[28571     4]
  [   44    36]]

 [[28568     3]
  [   15    69]]

 [[28295    26]
  [   44   290]]

 [[28629     3]
  [   12    11]]

 [[28028   108]
  [  141   378]]

 [[28531    36]
  [   84     4]]

 [[28640     3]
  [   10     2]]

 [[28077    98]
  [  205   275]]

 [[28486    43]
  [   43    83]]

 [[28630     0]
  [    0    25]]

 [[28486    17]
  [   45   107]]

 [[28635     0]
  [   15     5]]

 [[28622     5]
  [   18    10]]

 [[28612     1]
  [   15    27]]

 [[28621     0]
  [   26     8]]

 [[28492    63]
  [   60    40]]

 [[28145    95]
  [   88   327]]

 [[28527    10]
  [   72    46]]

 [[28547     9]
  [   23    76]]

 [[28348    54]
  [   65   188]]

 [[28529    10]
  [    9   107]]

 [[28141    91]
  [   93   330]]

 [[28553     3]
  [   23    76]]

 [[28595     0]
  [   15    45]]

 [[28351    39]
  [   40   225]]

 [[28618     0]
  [    7    30]]

 [[28063    97]
  [   74   421]]

 [[28640     0]
  [    5    10]]

 [[27589   455]
  [   30   581]]

 [[28437    12]
  [   19   187]]

 [[28632     1]
  [   13     9]]

 [[27983   138]
  [   54   480]]

 [[28545    12]
  [   27    71]]

 [[28547    21]
  [   34    53]]

 [[28540     5]
  [   17    93]]

 [[27716    81]
  [   87   771]]

 [[28592     2]
  [   47    14]]

 [[28416    30]
  [   14   195]]

 [[28641     1]
  [   12     1]]

 [[28583     7]
  [   11    54]]

 [[28498     1]
  [    5   151]]

 [[28567     3]
  [    0    85]]

 [[28597     2]
  [   27    29]]

 [[28488    13]
  [   43   111]]

 [[28601     2]
  [    9    43]]

 [[28503     6]
  [   14   132]]

 [[28576     2]
  [   31    46]]

 [[28635     2]
  [    4    14]]

 [[28437    20]
  [   32   166]]

 [[28199     6]
  [   51   399]]

 [[28644     0]
  [    5     6]]

 [[28611     1]
  [   19    24]]

 [[28640     0]
  [    2    13]]

 [[28448     2]
  [   12   193]]

 [[28578     0]
  [    4    73]]

 [[28371    29]
  [   54   201]]

 [[28632     3]
  [   16     4]]

 [[28641     2]
  [    1    11]]

 [[28582     6]
  [   46    21]]

 [[27147    44]
  [   38  1426]]

 [[28499     9]
  [   15   132]]

 [[28555     2]
  [   14    84]]

 [[28142    58]
  [   40   415]]

 [[28572     1]
  [    6    76]]

 [[28224    20]
  [   29   382]]

 [[28196    54]
  [   12   393]]

 [[28644     0]
  [    6     5]]

 [[28501     6]
  [   14   134]]

 [[27914    39]
  [   38   664]]

 [[28457     2]
  [    5   191]]

 [[28622     1]
  [   15    17]]

 [[28580     6]
  [    8    61]]

 [[28560     2]
  [   10    83]]

 [[28622     0]
  [    2    31]]

 [[28602     3]
  [    6    44]]

 [[28464    37]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8436
MCC	0.8403
log_loss	0.7066
f1 score weighted	0.8386
f1 score macro	0.7377
f1 score micro	0.8436
roc_auc ovr	0.9938
roc_auc ovo	0.9910
precision	0.8489
recall	0.8436

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8359156895589056	0.8326440855750585	0.7556871457738449	0.8314078982032427	0.7219529825595441	0.8359156895589056	0.993647619854434	0.9906979298273271	0.8501440515509155	0.8359156895589056
1	0.8371313906822544	0.8339454164485622	0.7471380548531705	0.8347150405927075	0.7329279880780919	0.8371313906822543	0.9933643032250186	0.9900427248853941	0.8507927511678717	0.8371313906822544
2	0.8621532018844879	0.8592814171770894	0.6350534695817978	0.8582557502588317	0.7595655511771132	0.8621532018844879	0.994702607107824	0.9920622012229596	0.8629800849808633	0.8621532018844879
3	0.8341650671785029	0.830905788155191	0.7519360657090822	0.8319405162815302	0.710977920913896	0.8341650671785029	0.9935921461709154	0.9903767924472243	0.8485251889200098	0.8341650671785029
4	0.8435526086197871	0.8403435785135674	0.7066299195738861	0.8385619651129576	0.7377122792904919	0.8435526086197871	0.9938464805270643	0.991032656938827	0.8489365472635976	0.8435526086197871
mean	0.8425835915847875	0.8394240571738937	0.7192889310983563	0.8389762340898539	0.7326273444038274	0.8425835915847875	0.9938306313770513	0.9908424610643465	0.8522757247766515	0.8425835915847875
std	0.010285597761761923	0.010427892327252842	0.04565545459953072	0.009968050618713259	0.016335565321162773	0.010285597761761935	0.0004622603653672606	0.0006930014459689351	0.005413745367540118	0.010285597761761923

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 61387.6200 secs

