/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_terminals_bilstm_attentio_cv_only_enz_hot_lev3_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f156c711670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f156c711850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f156c7118b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f156c7115b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.93      0.85       825
         1.0       0.00      0.00      0.00        14
         2.0       0.79      0.84      0.81        31
         3.0       0.00      0.00      0.00        11
         4.0       0.85      0.75      0.80        52
         5.0       0.88      0.72      0.79       176
         6.0       0.63      0.57      0.60       102
         7.0       0.61      0.24      0.34        97
         8.0       1.00      0.07      0.13        14
         9.0       0.70      0.54      0.61        70
        10.0       0.96      0.76      0.85       104
        11.0       0.00      0.00      0.00        18
        12.0       0.62      0.36      0.45        14
        13.0       0.93      0.63      0.75        43
        14.0       0.71      0.50      0.59        34
        15.0       0.84      0.84      0.84        64
        16.0       0.43      0.23      0.30        13
        17.0       0.79      0.58      0.67        19
        18.0       0.98      0.90      0.94        72
        19.0       1.00      0.27      0.42        30
        20.0       0.99      0.95      0.97        94
        21.0       0.72      0.67      0.70        46
        22.0       0.86      0.72      0.78        25
        23.0       0.94      0.95      0.94       345
        24.0       0.87      0.67      0.75        30
        25.0       0.25      0.05      0.08        20
        26.0       0.74      0.77      0.76       167
        27.0       0.96      0.75      0.84        36
        28.0       1.00      0.74      0.85        61
        29.0       0.94      0.76      0.84        63
        30.0       1.00      0.55      0.71        11
        31.0       0.00      0.00      0.00        11
        32.0       0.74      0.35      0.47        40
        33.0       0.84      0.78      0.81        73
        34.0       1.00      0.98      0.99        57
        35.0       0.88      0.93      0.90        15
        36.0       0.65      0.30      0.41        50
        37.0       0.83      1.00      0.90        19
        38.0       0.84      0.72      0.78        29
        39.0       0.92      0.97      0.94       101
        40.0       0.75      0.25      0.38        12
        41.0       1.00      1.00      1.00        14
        42.0       0.86      0.76      0.81        67
        43.0       1.00      0.86      0.92        76
        44.0       1.00      1.00      1.00        11
        45.0       0.97      0.86      0.91        37
        46.0       0.92      0.89      0.90      1613
        47.0       0.95      0.99      0.97       299
        48.0       0.99      0.97      0.98       244
        49.0       0.97      0.92      0.95       168
        50.0       0.80      0.82      0.81      1024
        51.0       0.29      0.93      0.44       353
        52.0       0.97      0.71      0.82        86
        53.0       0.74      0.82      0.78       607
        54.0       0.91      0.90      0.90       543
        55.0       1.00      0.90      0.95        78
        56.0       0.95      0.89      0.92       954
        57.0       0.93      0.89      0.91       247
        58.0       0.97      0.94      0.96        34
        59.0       0.77      0.87      0.82       877
        60.0       0.94      0.75      0.83        77
        61.0       0.91      0.89      0.90       566
        62.0       0.89      0.33      0.48        24
        63.0       0.81      0.47      0.60        55
        64.0       0.98      0.99      0.98       254
        65.0       1.00      0.14      0.25        14
        66.0       0.94      0.96      0.95       456
        67.0       0.96      0.66      0.78        38
        68.0       0.77      0.88      0.82      1189
        69.0       0.92      0.88      0.90       224
        70.0       0.78      0.74      0.76        19
        71.0       0.95      0.95      0.95       358
        72.0       0.77      0.62      0.69        32
        73.0       0.67      0.15      0.25        13
        74.0       0.99      0.94      0.96       127
        75.0       1.00      0.92      0.96        12
        76.0       0.86      0.73      0.79       460
        77.0       0.98      0.84      0.91       103
        78.0       0.82      0.17      0.29        52
        79.0       0.76      0.66      0.71        83
        80.0       0.86      0.45      0.59        80
        81.0       0.97      0.82      0.89        84
        82.0       0.92      0.87      0.90       335
        83.0       0.68      0.57      0.62        23
        84.0       0.76      0.71      0.74       518
        85.0       0.00      0.00      0.00        87
        86.0       1.00      0.62      0.76        13
        87.0       0.70      0.65      0.67       480
        88.0       0.69      0.64      0.67       126
        89.0       1.00      0.96      0.98        25
        90.0       0.89      0.77      0.83       152
        91.0       1.00      0.20      0.33        20
        92.0       1.00      0.14      0.25        28
        93.0       0.83      0.71      0.77        42
        94.0       0.50      0.18      0.26        34
        95.0       0.46      0.43      0.45        99
        96.0       0.66      0.88      0.76       415
        97.0       0.79      0.55      0.65       118
        98.0       0.56      0.79      0.65        99
        99.0       0.71      0.76      0.73       253
       100.0       0.92      0.95      0.94       116
       101.0       0.61      0.84      0.71       423
       102.0       0.95      0.84      0.89        99
       103.0       0.93      0.85      0.89        60
       104.0       0.83      0.83      0.83       266
       105.0       1.00      0.84      0.91        37
       106.0       0.79      0.89      0.84       494
       107.0       0.90      0.64      0.75        14
       108.0       0.89      0.83      0.86       610
       109.0       0.98      0.91      0.94       206
       110.0       0.77      0.45      0.57        22
       111.0       0.98      0.79      0.87       534
       112.0       0.85      0.61      0.71        98
       113.0       0.68      0.65      0.67        86
       114.0       0.99      0.87      0.93       109
       115.0       0.88      0.91      0.89       858
       116.0       0.62      0.67      0.65        61
       117.0       0.92      0.87      0.90       209
       118.0       0.00      0.00      0.00        13
       119.0       0.84      0.82      0.83        65
       120.0       0.97      0.94      0.95       156
       121.0       0.94      0.95      0.95        84
       122.0       0.84      0.47      0.60        55
       123.0       0.79      0.81      0.80       154
       124.0       1.00      0.79      0.88        52
       125.0       0.97      0.89      0.93       147
       126.0       0.94      0.44      0.60        77
       127.0       0.88      0.79      0.83        19
       128.0       0.90      0.83      0.86       198
       129.0       0.98      0.88      0.93       450
       130.0       0.86      0.55      0.67        11
       131.0       0.81      0.58      0.68        43
       132.0       0.92      0.75      0.83        16
       133.0       0.97      0.96      0.96       204
       134.0       0.96      0.93      0.95        76
       135.0       0.97      0.83      0.89       255
       136.0       0.88      0.35      0.50        20
       137.0       0.91      0.77      0.83        13
       138.0       0.98      0.66      0.79        67
       139.0       0.99      0.95      0.97      1464
       140.0       0.96      0.72      0.82       146
       141.0       0.95      0.88      0.91        99
       142.0       0.97      0.90      0.93       455
       143.0       0.99      0.93      0.96        82
       144.0       0.99      0.97      0.98       411
       145.0       0.84      0.97      0.90       406
       146.0       0.50      0.17      0.25        12
       147.0       0.95      0.85      0.90       149
       148.0       0.91      0.97      0.94       703
       149.0       0.96      0.95      0.96       195
       150.0       0.92      0.73      0.81        33
       151.0       0.75      0.66      0.70        68
       152.0       0.99      0.84      0.91        93
       153.0       1.00      0.82      0.90        33
       154.0       0.92      0.90      0.91        49
       155.0       0.76      0.92      0.83       154

    accuracy                           0.84     28656
   macro avg       0.83      0.70      0.74     28656
weighted avg       0.86      0.84      0.84     28656


===confusion_matrix===

[[766   0   0 ...   0   0   0]
 [  6   0   0 ...   0   0   0]
 [  0   0  26 ...   0   0   0]
 ...
 [  0   0   0 ...  27   2   2]
 [  0   0   0 ...   0  44   4]
 [  0   0   0 ...   0   1 141]]

===multilabel confusion matrix===

[[[27618   213]
  [   59   766]]

 [[28642     0]
  [   14     0]]

 [[28618     7]
  [    5    26]]

 [[28644     1]
  [   11     0]]

 [[28597     7]
  [   13    39]]

 [[28463    17]
  [   49   127]]

 [[28520    34]
  [   44    58]]

 [[28544    15]
  [   74    23]]

 [[28642     0]
  [   13     1]]

 [[28570    16]
  [   32    38]]

 [[28549     3]
  [   25    79]]

 [[28638     0]
  [   18     0]]

 [[28639     3]
  [    9     5]]

 [[28611     2]
  [   16    27]]

 [[28615     7]
  [   17    17]]

 [[28582    10]
  [   10    54]]

 [[28639     4]
  [   10     3]]

 [[28634     3]
  [    8    11]]

 [[28583     1]
  [    7    65]]

 [[28626     0]
  [   22     8]]

 [[28561     1]
  [    5    89]]

 [[28598    12]
  [   15    31]]

 [[28628     3]
  [    7    18]]

 [[28290    21]
  [   18   327]]

 [[28623     3]
  [   10    20]]

 [[28633     3]
  [   19     1]]

 [[28444    45]
  [   38   129]]

 [[28619     1]
  [    9    27]]

 [[28595     0]
  [   16    45]]

 [[28590     3]
  [   15    48]]

 [[28645     0]
  [    5     6]]

 [[28645     0]
  [   11     0]]

 [[28611     5]
  [   26    14]]

 [[28572    11]
  [   16    57]]

 [[28599     0]
  [    1    56]]

 [[28639     2]
  [    1    14]]

 [[28598     8]
  [   35    15]]

 [[28633     4]
  [    0    19]]

 [[28623     4]
  [    8    21]]

 [[28546     9]
  [    3    98]]

 [[28643     1]
  [    9     3]]

 [[28642     0]
  [    0    14]]

 [[28581     8]
  [   16    51]]

 [[28580     0]
  [   11    65]]

 [[28645     0]
  [    0    11]]

 [[28618     1]
  [    5    32]]

 [[26910   133]
  [  177  1436]]

 [[28340    17]
  [    3   296]]

 [[28409     3]
  [    8   236]]

 [[28483     5]
  [   13   155]]

 [[27416   216]
  [  186   838]]

 [[27512   791]
  [   26   327]]

 [[28568     2]
  [   25    61]]

 [[27879   170]
  [  111   496]]

 [[28062    51]
  [   54   489]]

 [[28578     0]
  [    8    70]]

 [[27657    45]
  [  107   847]]

 [[28393    16]
  [   26   221]]

 [[28621     1]
  [    2    32]]

 [[27547   232]
  [  114   763]]

 [[28575     4]
  [   19    58]]

 [[28040    50]
  [   64   502]]

 [[28631     1]
  [   16     8]]

 [[28595     6]
  [   29    26]]

 [[28396     6]
  [    2   252]]

 [[28642     0]
  [   12     2]]

 [[28172    28]
  [   20   436]]

 [[28617     1]
  [   13    25]]

 [[27148   319]
  [  138  1051]]

 [[28416    16]
  [   28   196]]

 [[28633     4]
  [    5    14]]

 [[28280    18]
  [   18   340]]

 [[28618     6]
  [   12    20]]

 [[28642     1]
  [   11     2]]

 [[28528     1]
  [    8   119]]

 [[28644     0]
  [    1    11]]

 [[28142    54]
  [  123   337]]

 [[28551     2]
  [   16    87]]

 [[28602     2]
  [   43     9]]

 [[28556    17]
  [   28    55]]

 [[28570     6]
  [   44    36]]

 [[28570     2]
  [   15    69]]

 [[28297    24]
  [   42   293]]

 [[28627     6]
  [   10    13]]

 [[28023   115]
  [  148   370]]

 [[28568     1]
  [   87     0]]

 [[28643     0]
  [    5     8]]

 [[28044   132]
  [  169   311]]

 [[28494    36]
  [   45    81]]

 [[28631     0]
  [    1    24]]

 [[28490    14]
  [   35   117]]

 [[28636     0]
  [   16     4]]

 [[28628     0]
  [   24     4]]

 [[28608     6]
  [   12    30]]

 [[28616     6]
  [   28     6]]

 [[28506    51]
  [   56    43]]

 [[28054   187]
  [   48   367]]

 [[28521    17]
  [   53    65]]

 [[28495    62]
  [   21    78]]

 [[28325    78]
  [   61   192]]

 [[28531     9]
  [    6   110]]

 [[28003   230]
  [   67   356]]

 [[28553     4]
  [   16    83]]

 [[28592     4]
  [    9    51]]

 [[28344    46]
  [   46   220]]

 [[28619     0]
  [    6    31]]

 [[28045   117]
  [   55   439]]

 [[28641     1]
  [    5     9]]

 [[27982    64]
  [  101   509]]

 [[28446     4]
  [   18   188]]

 [[28631     3]
  [   12    10]]

 [[28113     9]
  [  113   421]]

 [[28547    11]
  [   38    60]]

 [[28544    26]
  [   30    56]]

 [[28546     1]
  [   14    95]]

 [[27689   109]
  [   77   781]]

 [[28570    25]
  [   20    41]]

 [[28432    15]
  [   27   182]]

 [[28641     2]
  [   13     0]]

 [[28581    10]
  [   12    53]]

 [[28495     5]
  [    9   147]]

 [[28567     5]
  [    4    80]]

 [[28596     5]
  [   29    26]]

 [[28469    33]
  [   29   125]]

 [[28604     0]
  [   11    41]]

 [[28505     4]
  [   16   131]]

 [[28577     2]
  [   43    34]]

 [[28635     2]
  [    4    15]]

 [[28439    19]
  [   33   165]]

 [[28199     7]
  [   53   397]]

 [[28644     1]
  [    5     6]]

 [[28607     6]
  [   18    25]]

 [[28639     1]
  [    4    12]]

 [[28445     7]
  [    9   195]]

 [[28577     3]
  [    5    71]]

 [[28394     7]
  [   43   212]]

 [[28635     1]
  [   13     7]]

 [[28642     1]
  [    3    10]]

 [[28588     1]
  [   23    44]]

 [[27182    10]
  [   71  1393]]

 [[28506     4]
  [   41   105]]

 [[28552     5]
  [   12    87]]

 [[28187    14]
  [   44   411]]

 [[28573     1]
  [    6    76]]

 [[28239     6]
  [   14   397]]

 [[28177    73]
  [   11   395]]

 [[28642     2]
  [   10     2]]

 [[28501     6]
  [   22   127]]

 [[27886    67]
  [   21   682]]

 [[28453     8]
  [    9   186]]

 [[28621     2]
  [    9    24]]

 [[28573    15]
  [   23    45]]

 [[28562     1]
  [   15    78]]

 [[28623     0]
  [    6    27]]

 [[28603     4]
  [    5    44]]

 [[28457    45]
  [   13   141]]]

===scores report===
metrics	scores
Accuracy	0.8425
MCC	0.8396
log_loss	0.7079
f1 score weighted	0.8427
f1 score macro	0.7381
f1 score micro	0.8425
roc_auc ovr	0.9939
roc_auc ovo	0.9915
precision	0.8590
recall	0.8425

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f156c711670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f156c711850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f156c7118b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f156c7115b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([56., 56., 56., ..., 98., 51., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.90      0.89       825
         1.0       1.00      0.21      0.35        14
         2.0       0.66      0.68      0.67        31
         3.0       1.00      0.08      0.15        12
         4.0       0.89      0.79      0.84        52
         5.0       0.84      0.78      0.81       176
         6.0       0.47      0.61      0.53       102
         7.0       0.59      0.18      0.27        97
         8.0       1.00      0.29      0.44        14
         9.0       0.58      0.30      0.40        70
        10.0       0.71      0.80      0.75       104
        11.0       0.67      0.11      0.19        18
        12.0       0.17      0.14      0.15        14
        13.0       0.67      0.71      0.69        42
        14.0       0.78      0.62      0.69        34
        15.0       0.72      0.80      0.76        64
        16.0       0.75      0.21      0.33        14
        17.0       0.76      0.84      0.80        19
        18.0       0.93      0.89      0.91        72
        19.0       0.75      0.10      0.17        31
        20.0       0.97      0.97      0.97        94
        21.0       0.80      0.80      0.80        45
        22.0       0.91      0.84      0.87        25
        23.0       0.98      0.94      0.96       346
        24.0       1.00      0.57      0.72        30
        25.0       0.00      0.00      0.00        19
        26.0       0.86      0.67      0.75       167
        27.0       0.92      0.67      0.77        36
        28.0       0.78      0.97      0.87        60
        29.0       0.95      0.68      0.79        62
        30.0       0.67      0.18      0.29        11
        31.0       0.50      0.09      0.15        11
        32.0       0.94      0.42      0.59        40
        33.0       0.71      0.72      0.71        74
        34.0       1.00      1.00      1.00        56
        35.0       0.88      0.94      0.91        16
        36.0       0.52      0.31      0.39        51
        37.0       0.88      0.79      0.83        19
        38.0       0.90      0.66      0.76        29
        39.0       0.95      0.92      0.93       101
        40.0       1.00      0.75      0.86        12
        41.0       1.00      0.92      0.96        13
        42.0       0.92      0.85      0.88        67
        43.0       0.83      0.96      0.89        76
        44.0       1.00      1.00      1.00        12
        45.0       1.00      0.86      0.93        36
        46.0       0.76      0.94      0.84      1613
        47.0       0.97      0.97      0.97       299
        48.0       0.98      0.98      0.98       243
        49.0       0.97      0.92      0.95       169
        50.0       0.86      0.76      0.81      1024
        51.0       0.53      0.83      0.64       352
        52.0       0.94      0.88      0.91        86
        53.0       0.81      0.77      0.79       607
        54.0       0.95      0.90      0.93       543
        55.0       0.97      0.85      0.90        78
        56.0       0.77      0.92      0.84       954
        57.0       0.97      0.85      0.90       247
        58.0       0.94      1.00      0.97        34
        59.0       0.71      0.89      0.79       877
        60.0       0.98      0.73      0.84        77
        61.0       0.85      0.89      0.87       565
        62.0       0.62      0.42      0.50        24
        63.0       0.52      0.60      0.56        55
        64.0       0.97      0.98      0.97       255
        65.0       0.75      0.21      0.33        14
        66.0       0.98      0.93      0.95       457
        67.0       1.00      0.78      0.88        37
        68.0       0.89      0.81      0.85      1189
        69.0       0.91      0.86      0.88       224
        70.0       1.00      0.45      0.62        20
        71.0       0.97      0.95      0.96       358
        72.0       0.79      0.47      0.59        32
        73.0       1.00      0.08      0.14        13
        74.0       0.97      0.95      0.96       128
        75.0       1.00      0.85      0.92        13
        76.0       0.71      0.75      0.73       460
        77.0       0.94      0.87      0.90       104
        78.0       0.88      0.27      0.41        52
        79.0       0.76      0.65      0.71        84
        80.0       0.67      0.46      0.55        80
        81.0       0.97      0.80      0.87        83
        82.0       0.93      0.87      0.90       335
        83.0       1.00      0.33      0.50        24
        84.0       0.71      0.77      0.74       518
        85.0       0.06      0.02      0.03        88
        86.0       1.00      0.62      0.76        13
        87.0       0.58      0.81      0.68       480
        88.0       0.89      0.59      0.71       126
        89.0       0.96      1.00      0.98        25
        90.0       0.85      0.80      0.83       153
        91.0       1.00      0.35      0.52        20
        92.0       0.75      0.22      0.34        27
        93.0       1.00      0.74      0.85        42
        94.0       0.91      0.29      0.44        34
        95.0       0.67      0.33      0.45        99
        96.0       0.82      0.84      0.83       416
        97.0       0.60      0.63      0.61       118
        98.0       0.94      0.74      0.82        99
        99.0       0.81      0.77      0.79       253
       100.0       0.96      0.90      0.93       115
       101.0       0.85      0.75      0.80       423
       102.0       0.84      0.85      0.84        99
       103.0       0.92      0.79      0.85        61
       104.0       0.83      0.85      0.84       266
       105.0       0.88      0.83      0.86        36
       106.0       0.72      0.87      0.79       494
       107.0       0.90      0.64      0.75        14
       108.0       0.81      0.89      0.85       610
       109.0       0.93      0.96      0.94       206
       110.0       0.86      0.55      0.67        22
       111.0       0.92      0.83      0.88       535
       112.0       0.82      0.66      0.73        98
       113.0       0.96      0.52      0.68        86
       114.0       0.90      0.87      0.88       109
       115.0       0.82      0.90      0.86       858
       116.0       0.83      0.31      0.45        61
       117.0       0.99      0.81      0.89       208
       118.0       0.00      0.00      0.00        13
       119.0       0.93      0.58      0.72        65
       120.0       0.97      0.92      0.95       157
       121.0       0.97      0.99      0.98        84
       122.0       0.65      0.51      0.57        55
       123.0       0.84      0.78      0.81       154
       124.0       0.94      0.96      0.95        52
       125.0       0.95      0.93      0.94       147
       126.0       0.80      0.56      0.66        77
       127.0       0.93      0.78      0.85        18
       128.0       0.84      0.82      0.83       197
       129.0       0.90      0.96      0.93       449
       130.0       0.83      0.45      0.59        11
       131.0       0.90      0.63      0.74        43
       132.0       0.92      0.73      0.81        15
       133.0       0.92      0.97      0.94       204
       134.0       1.00      0.96      0.98        76
       135.0       0.88      0.87      0.88       255
       136.0       1.00      0.32      0.48        19
       137.0       1.00      0.77      0.87        13
       138.0       0.87      0.61      0.72        67
       139.0       0.96      0.99      0.98      1463
       140.0       0.95      0.78      0.86       147
       141.0       0.95      0.91      0.93        99
       142.0       0.98      0.89      0.93       455
       143.0       0.99      0.94      0.96        82
       144.0       0.99      0.93      0.96       410
       145.0       0.96      0.96      0.96       406
       146.0       1.00      0.25      0.40        12
       147.0       0.98      0.90      0.94       149
       148.0       0.92      0.97      0.94       702
       149.0       0.99      0.94      0.97       196
       150.0       0.84      0.81      0.83        32
       151.0       0.70      0.90      0.79        69
       152.0       0.94      0.94      0.94        93
       153.0       0.90      0.88      0.89        32
       154.0       0.92      0.96      0.94        49
       155.0       0.92      0.95      0.94       154

    accuracy                           0.85     28655
   macro avg       0.85      0.71      0.74     28655
weighted avg       0.85      0.85      0.84     28655


===confusion_matrix===

[[744   0   0 ...   0   0   0]
 [  1   3   0 ...   0   0   0]
 [  0   0  21 ...   0   0   0]
 ...
 [  0   0   0 ...  28   1   0]
 [  0   0   0 ...   0  47   2]
 [  0   0   0 ...   0   1 147]]

===multilabel confusion matrix===

[[[27722   108]
  [   81   744]]

 [[28641     0]
  [   11     3]]

 [[28613    11]
  [   10    21]]

 [[28643     0]
  [   11     1]]

 [[28598     5]
  [   11    41]]

 [[28453    26]
  [   38   138]]

 [[28484    69]
  [   40    62]]

 [[28546    12]
  [   80    17]]

 [[28641     0]
  [   10     4]]

 [[28570    15]
  [   49    21]]

 [[28517    34]
  [   21    83]]

 [[28636     1]
  [   16     2]]

 [[28631    10]
  [   12     2]]

 [[28598    15]
  [   12    30]]

 [[28615     6]
  [   13    21]]

 [[28571    20]
  [   13    51]]

 [[28640     1]
  [   11     3]]

 [[28631     5]
  [    3    16]]

 [[28578     5]
  [    8    64]]

 [[28623     1]
  [   28     3]]

 [[28558     3]
  [    3    91]]

 [[28601     9]
  [    9    36]]

 [[28628     2]
  [    4    21]]

 [[28302     7]
  [   21   325]]

 [[28625     0]
  [   13    17]]

 [[28636     0]
  [   19     0]]

 [[28470    18]
  [   55   112]]

 [[28617     2]
  [   12    24]]

 [[28579    16]
  [    2    58]]

 [[28591     2]
  [   20    42]]

 [[28643     1]
  [    9     2]]

 [[28643     1]
  [   10     1]]

 [[28614     1]
  [   23    17]]

 [[28559    22]
  [   21    53]]

 [[28599     0]
  [    0    56]]

 [[28637     2]
  [    1    15]]

 [[28589    15]
  [   35    16]]

 [[28634     2]
  [    4    15]]

 [[28624     2]
  [   10    19]]

 [[28549     5]
  [    8    93]]

 [[28643     0]
  [    3     9]]

 [[28642     0]
  [    1    12]]

 [[28583     5]
  [   10    57]]

 [[28564    15]
  [    3    73]]

 [[28643     0]
  [    0    12]]

 [[28619     0]
  [    5    31]]

 [[26564   478]
  [   89  1524]]

 [[28347     9]
  [   10   289]]

 [[28408     4]
  [    6   237]]

 [[28481     5]
  [   13   156]]

 [[27507   124]
  [  249   775]]

 [[28040   263]
  [   61   291]]

 [[28564     5]
  [   10    76]]

 [[27938   110]
  [  139   468]]

 [[28088    24]
  [   53   490]]

 [[28575     2]
  [   12    66]]

 [[27438   263]
  [   73   881]]

 [[28401     7]
  [   38   209]]

 [[28619     2]
  [    0    34]]

 [[27454   324]
  [   93   784]]

 [[28577     1]
  [   21    56]]

 [[27999    91]
  [   61   504]]

 [[28625     6]
  [   14    10]]

 [[28570    30]
  [   22    33]]

 [[28391     9]
  [    6   249]]

 [[28640     1]
  [   11     3]]

 [[28188    10]
  [   32   425]]

 [[28618     0]
  [    8    29]]

 [[27346   120]
  [  224   965]]

 [[28411    20]
  [   31   193]]

 [[28635     0]
  [   11     9]]

 [[28288     9]
  [   18   340]]

 [[28619     4]
  [   17    15]]

 [[28642     0]
  [   12     1]]

 [[28523     4]
  [    7   121]]

 [[28642     0]
  [    2    11]]

 [[28056   139]
  [  116   344]]

 [[28545     6]
  [   14    90]]

 [[28601     2]
  [   38    14]]

 [[28554    17]
  [   29    55]]

 [[28557    18]
  [   43    37]]

 [[28570     2]
  [   17    66]]

 [[28299    21]
  [   42   293]]

 [[28631     0]
  [   16     8]]

 [[27976   161]
  [  121   397]]

 [[28538    29]
  [   86     2]]

 [[28642     0]
  [    5     8]]

 [[27893   282]
  [   90   390]]

 [[28520     9]
  [   52    74]]

 [[28629     1]
  [    0    25]]

 [[28480    22]
  [   30   123]]

 [[28635     0]
  [   13     7]]

 [[28626     2]
  [   21     6]]

 [[28613     0]
  [   11    31]]

 [[28620     1]
  [   24    10]]

 [[28540    16]
  [   66    33]]

 [[28163    76]
  [   67   349]]

 [[28487    50]
  [   44    74]]

 [[28551     5]
  [   26    73]]

 [[28355    47]
  [   57   196]]

 [[28536     4]
  [   11   104]]

 [[28175    57]
  [  104   319]]

 [[28540    16]
  [   15    84]]

 [[28590     4]
  [   13    48]]

 [[28344    45]
  [   40   226]]

 [[28615     4]
  [    6    30]]

 [[27993   168]
  [   64   430]]

 [[28640     1]
  [    5     9]]

 [[27918   127]
  [   66   544]]

 [[28433    16]
  [    8   198]]

 [[28631     2]
  [   10    12]]

 [[28083    37]
  [   90   445]]

 [[28543    14]
  [   33    65]]

 [[28567     2]
  [   41    45]]

 [[28535    11]
  [   14    95]]

 [[27631   166]
  [   87   771]]

 [[28590     4]
  [   42    19]]

 [[28446     1]
  [   40   168]]

 [[28642     0]
  [   13     0]]

 [[28587     3]
  [   27    38]]

 [[28494     4]
  [   12   145]]

 [[28568     3]
  [    1    83]]

 [[28585    15]
  [   27    28]]

 [[28478    23]
  [   34   120]]

 [[28600     3]
  [    2    50]]

 [[28501     7]
  [   11   136]]

 [[28567    11]
  [   34    43]]

 [[28636     1]
  [    4    14]]

 [[28428    30]
  [   36   161]]

 [[28160    46]
  [   19   430]]

 [[28643     1]
  [    6     5]]

 [[28609     3]
  [   16    27]]

 [[28639     1]
  [    4    11]]

 [[28434    17]
  [    7   197]]

 [[28579     0]
  [    3    73]]

 [[28371    29]
  [   32   223]]

 [[28636     0]
  [   13     6]]

 [[28642     0]
  [    3    10]]

 [[28582     6]
  [   26    41]]

 [[27132    60]
  [    9  1454]]

 [[28502     6]
  [   32   115]]

 [[28551     5]
  [    9    90]]

 [[28190    10]
  [   49   406]]

 [[28572     1]
  [    5    77]]

 [[28243     2]
  [   30   380]]

 [[28233    16]
  [   16   390]]

 [[28643     0]
  [    9     3]]

 [[28503     3]
  [   15   134]]

 [[27892    61]
  [   24   678]]

 [[28457     2]
  [   11   185]]

 [[28618     5]
  [    6    26]]

 [[28560    26]
  [    7    62]]

 [[28556     6]
  [    6    87]]

 [[28620     3]
  [    4    28]]

 [[28602     4]
  [    2    47]]

 [[28488    13]
  [    7   147]]]

===scores report===
metrics	scores
Accuracy	0.8461
MCC	0.8430
log_loss	0.7065
f1 score weighted	0.8418
f1 score macro	0.7449
f1 score micro	0.8461
roc_auc ovr	0.9936
roc_auc ovo	0.9904
precision	0.8528
recall	0.8461

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f156c711670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f156c711850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f156c7118b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f156c7115b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  51.,  96., 109.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.96      0.78       825
         1.0       0.00      0.00      0.00        14
         2.0       1.00      0.66      0.79        32
         3.0       0.00      0.00      0.00        12
         4.0       0.93      0.73      0.82        52
         5.0       0.93      0.69      0.79       176
         6.0       0.51      0.61      0.56       102
         7.0       0.90      0.20      0.32        97
         8.0       0.00      0.00      0.00        14
         9.0       0.47      0.49      0.48        69
        10.0       0.74      0.74      0.74       104
        11.0       0.00      0.00      0.00        18
        12.0       0.83      0.33      0.48        15
        13.0       1.00      0.57      0.73        42
        14.0       0.83      0.29      0.43        34
        15.0       1.00      0.69      0.81        64
        16.0       0.50      0.23      0.32        13
        17.0       1.00      0.16      0.27        19
        18.0       1.00      0.80      0.89        71
        19.0       1.00      0.10      0.18        31
        20.0       0.98      0.97      0.97        94
        21.0       0.59      0.87      0.70        46
        22.0       1.00      0.68      0.81        25
        23.0       0.95      0.92      0.94       346
        24.0       0.91      0.65      0.75        31
        25.0       0.00      0.00      0.00        20
        26.0       0.76      0.56      0.64       167
        27.0       1.00      0.58      0.74        36
        28.0       0.89      0.95      0.92        60
        29.0       0.71      0.84      0.77        62
        30.0       1.00      0.09      0.17        11
        31.0       0.00      0.00      0.00        12
        32.0       1.00      0.17      0.30        40
        33.0       0.66      0.82      0.73        74
        34.0       1.00      0.98      0.99        56
        35.0       1.00      0.81      0.90        16
        36.0       0.88      0.14      0.24        51
        37.0       0.46      0.95      0.62        19
        38.0       0.81      0.76      0.79        29
        39.0       0.93      0.86      0.89       101
        40.0       0.50      0.08      0.14        12
        41.0       1.00      0.77      0.87        13
        42.0       0.74      0.87      0.80        67
        43.0       1.00      0.71      0.83        76
        44.0       1.00      1.00      1.00        11
        45.0       1.00      0.76      0.86        37
        46.0       0.87      0.92      0.89      1613
        47.0       0.96      0.96      0.96       299
        48.0       0.98      0.96      0.97       243
        49.0       0.99      0.94      0.96       169
        50.0       0.83      0.80      0.82      1023
        51.0       0.49      0.84      0.62       352
        52.0       0.95      0.69      0.80        86
        53.0       0.50      0.83      0.62       606
        54.0       0.97      0.88      0.92       543
        55.0       0.92      0.89      0.90        79
        56.0       0.87      0.92      0.89       954
        57.0       0.93      0.85      0.89       247
        58.0       1.00      0.97      0.99        34
        59.0       0.63      0.90      0.74       877
        60.0       0.75      0.73      0.74        77
        61.0       0.85      0.93      0.88       566
        62.0       1.00      0.04      0.08        24
        63.0       0.68      0.62      0.65        55
        64.0       0.99      0.93      0.96       255
        65.0       0.00      0.00      0.00        13
        66.0       0.91      0.96      0.93       457
        67.0       0.90      0.70      0.79        37
        68.0       0.74      0.89      0.81      1189
        69.0       0.59      0.90      0.72       223
        70.0       0.89      0.42      0.57        19
        71.0       0.97      0.94      0.95       357
        72.0       0.51      0.62      0.56        32
        73.0       0.00      0.00      0.00        13
        74.0       0.97      0.96      0.96       128
        75.0       1.00      0.38      0.56        13
        76.0       0.61      0.75      0.68       460
        77.0       0.95      0.81      0.88       104
        78.0       1.00      0.11      0.20        53
        79.0       0.47      0.60      0.53        83
        80.0       0.83      0.44      0.58        79
        81.0       0.89      0.80      0.84        84
        82.0       0.82      0.86      0.84       334
        83.0       0.80      0.33      0.47        24
        84.0       0.75      0.73      0.74       518
        85.0       0.00      0.00      0.00        88
        86.0       1.00      0.38      0.56        13
        87.0       0.90      0.26      0.40       480
        88.0       0.99      0.61      0.75       127
        89.0       1.00      0.96      0.98        24
        90.0       0.99      0.65      0.79       153
        91.0       0.00      0.00      0.00        20
        92.0       1.00      0.30      0.46        27
        93.0       0.97      0.83      0.90        42
        94.0       0.00      0.00      0.00        34
        95.0       1.00      0.19      0.32        99
        96.0       0.81      0.83      0.82       416
        97.0       0.62      0.58      0.60       118
        98.0       0.48      0.78      0.59        99
        99.0       0.91      0.57      0.70       253
       100.0       0.93      0.96      0.94       115
       101.0       0.92      0.74      0.82       423
       102.0       0.97      0.62      0.76        98
       103.0       1.00      0.40      0.57        60
       104.0       0.83      0.85      0.84       265
       105.0       1.00      0.83      0.91        36
       106.0       0.68      0.89      0.77       495
       107.0       1.00      0.64      0.78        14
       108.0       0.94      0.82      0.88       610
       109.0       0.90      0.96      0.93       206
       110.0       0.88      0.64      0.74        22
       111.0       0.93      0.80      0.86       535
       112.0       0.92      0.45      0.60        98
       113.0       0.91      0.34      0.49        86
       114.0       0.99      0.90      0.94       110
       115.0       0.96      0.83      0.89       858
       116.0       0.00      0.00      0.00        61
       117.0       0.93      0.88      0.91       208
       118.0       0.00      0.00      0.00        13
       119.0       0.79      0.64      0.71        66
       120.0       0.99      0.88      0.93       157
       121.0       0.97      0.99      0.98        84
       122.0       0.79      0.56      0.66        55
       123.0       0.89      0.70      0.78       153
       124.0       0.86      0.94      0.90        52
       125.0       0.80      0.93      0.86       147
       126.0       0.78      0.51      0.62        76
       127.0       1.00      0.83      0.91        18
       128.0       0.95      0.80      0.87       197
       129.0       1.00      0.81      0.90       450
       130.0       1.00      0.33      0.50        12
       131.0       0.71      0.76      0.74        42
       132.0       1.00      0.87      0.93        15
       133.0       0.99      0.89      0.94       204
       134.0       0.71      0.97      0.82        76
       135.0       0.74      0.80      0.77       256
       136.0       0.78      0.37      0.50        19
       137.0       0.73      0.85      0.79        13
       138.0       0.82      0.67      0.74        67
       139.0       0.97      0.97      0.97      1464
       140.0       0.85      0.82      0.83       147
       141.0       0.99      0.80      0.88        98
       142.0       0.93      0.91      0.92       455
       143.0       0.95      0.94      0.94        82
       144.0       0.98      0.94      0.96       410
       145.0       0.98      0.92      0.95       406
       146.0       0.40      0.17      0.24        12
       147.0       1.00      0.74      0.85       149
       148.0       0.74      0.97      0.84       702
       149.0       1.00      0.94      0.97       196
       150.0       0.79      0.94      0.86        32
       151.0       0.54      0.71      0.61        69
       152.0       0.95      0.90      0.93        93
       153.0       1.00      0.79      0.88        33
       154.0       0.88      0.90      0.89        50
       155.0       0.80      0.90      0.85       154

    accuracy                           0.82     28655
   macro avg       0.79      0.65      0.68     28655
weighted avg       0.84      0.82      0.81     28655


===confusion_matrix===

[[789   0   0 ...   0   0   0]
 [  1   0   0 ...   0   0   0]
 [  1   0  21 ...   0   0   0]
 ...
 [  1   0   0 ...  26   0   1]
 [  0   0   0 ...   0  45   4]
 [  0   0   0 ...   0   4 138]]

===multilabel confusion matrix===

[[[27415   415]
  [   36   789]]

 [[28641     0]
  [   14     0]]

 [[28623     0]
  [   11    21]]

 [[28643     0]
  [   12     0]]

 [[28600     3]
  [   14    38]]

 [[28470     9]
  [   54   122]]

 [[28494    59]
  [   40    62]]

 [[28556     2]
  [   78    19]]

 [[28641     0]
  [   14     0]]

 [[28548    38]
  [   35    34]]

 [[28524    27]
  [   27    77]]

 [[28637     0]
  [   18     0]]

 [[28639     1]
  [   10     5]]

 [[28613     0]
  [   18    24]]

 [[28619     2]
  [   24    10]]

 [[28591     0]
  [   20    44]]

 [[28639     3]
  [   10     3]]

 [[28636     0]
  [   16     3]]

 [[28584     0]
  [   14    57]]

 [[28624     0]
  [   28     3]]

 [[28559     2]
  [    3    91]]

 [[28581    28]
  [    6    40]]

 [[28630     0]
  [    8    17]]

 [[28293    16]
  [   27   319]]

 [[28622     2]
  [   11    20]]

 [[28635     0]
  [   20     0]]

 [[28459    29]
  [   74    93]]

 [[28619     0]
  [   15    21]]

 [[28588     7]
  [    3    57]]

 [[28572    21]
  [   10    52]]

 [[28644     0]
  [   10     1]]

 [[28643     0]
  [   12     0]]

 [[28615     0]
  [   33     7]]

 [[28550    31]
  [   13    61]]

 [[28599     0]
  [    1    55]]

 [[28639     0]
  [    3    13]]

 [[28603     1]
  [   44     7]]

 [[28615    21]
  [    1    18]]

 [[28621     5]
  [    7    22]]

 [[28547     7]
  [   14    87]]

 [[28642     1]
  [   11     1]]

 [[28642     0]
  [    3    10]]

 [[28568    20]
  [    9    58]]

 [[28579     0]
  [   22    54]]

 [[28644     0]
  [    0    11]]

 [[28618     0]
  [    9    28]]

 [[26822   220]
  [  129  1484]]

 [[28345    11]
  [   11   288]]

 [[28408     4]
  [    9   234]]

 [[28484     2]
  [   10   159]]

 [[27464   168]
  [  201   822]]

 [[28003   300]
  [   58   294]]

 [[28566     3]
  [   27    59]]

 [[27540   509]
  [  105   501]]

 [[28096    16]
  [   66   477]]

 [[28570     6]
  [    9    70]]

 [[27565   136]
  [   80   874]]

 [[28392    16]
  [   38   209]]

 [[28621     0]
  [    1    33]]

 [[27309   469]
  [   87   790]]

 [[28559    19]
  [   21    56]]

 [[27993    96]
  [   41   525]]

 [[28631     0]
  [   23     1]]

 [[28584    16]
  [   21    34]]

 [[28398     2]
  [   17   238]]

 [[28642     0]
  [   13     0]]

 [[28154    44]
  [   20   437]]

 [[28615     3]
  [   11    26]]

 [[27095   371]
  [  127  1062]]

 [[28294   138]
  [   22   201]]

 [[28635     1]
  [   11     8]]

 [[28288    10]
  [   22   335]]

 [[28604    19]
  [   12    20]]

 [[28642     0]
  [   13     0]]

 [[28523     4]
  [    5   123]]

 [[28642     0]
  [    8     5]]

 [[27979   216]
  [  115   345]]

 [[28547     4]
  [   20    84]]

 [[28602     0]
  [   47     6]]

 [[28515    57]
  [   33    50]]

 [[28569     7]
  [   44    35]]

 [[28563     8]
  [   17    67]]

 [[28258    63]
  [   46   288]]

 [[28629     2]
  [   16     8]]

 [[28008   129]
  [  141   377]]

 [[28560     7]
  [   88     0]]

 [[28642     0]
  [    8     5]]

 [[28161    14]
  [  356   124]]

 [[28527     1]
  [   50    77]]

 [[28631     0]
  [    1    23]]

 [[28501     1]
  [   53   100]]

 [[28634     1]
  [   20     0]]

 [[28628     0]
  [   19     8]]

 [[28612     1]
  [    7    35]]

 [[28621     0]
  [   34     0]]

 [[28556     0]
  [   80    19]]

 [[28159    80]
  [   69   347]]

 [[28496    41]
  [   50    68]]

 [[28471    85]
  [   22    77]]

 [[28388    14]
  [  109   144]]

 [[28532     8]
  [    5   110]]

 [[28204    28]
  [  110   313]]

 [[28555     2]
  [   37    61]]

 [[28595     0]
  [   36    24]]

 [[28343    47]
  [   40   225]]

 [[28619     0]
  [    6    30]]

 [[27950   210]
  [   56   439]]

 [[28641     0]
  [    5     9]]

 [[28015    30]
  [  112   498]]

 [[28428    21]
  [    9   197]]

 [[28631     2]
  [    8    14]]

 [[28089    31]
  [  106   429]]

 [[28553     4]
  [   54    44]]

 [[28566     3]
  [   57    29]]

 [[28544     1]
  [   11    99]]

 [[27767    30]
  [  146   712]]

 [[28594     0]
  [   61     0]]

 [[28434    13]
  [   25   183]]

 [[28642     0]
  [   13     0]]

 [[28578    11]
  [   24    42]]

 [[28497     1]
  [   19   138]]

 [[28568     3]
  [    1    83]]

 [[28592     8]
  [   24    31]]

 [[28489    13]
  [   46   107]]

 [[28595     8]
  [    3    49]]

 [[28475    33]
  [   11   136]]

 [[28568    11]
  [   37    39]]

 [[28637     0]
  [    3    15]]

 [[28449     9]
  [   39   158]]

 [[28204     1]
  [   84   366]]

 [[28643     0]
  [    8     4]]

 [[28600    13]
  [   10    32]]

 [[28640     0]
  [    2    13]]

 [[28449     2]
  [   22   182]]

 [[28549    30]
  [    2    74]]

 [[28328    71]
  [   51   205]]

 [[28634     2]
  [   12     7]]

 [[28638     4]
  [    2    11]]

 [[28578    10]
  [   22    45]]

 [[27152    39]
  [   40  1424]]

 [[28486    22]
  [   26   121]]

 [[28556     1]
  [   20    78]]

 [[28170    30]
  [   43   412]]

 [[28569     4]
  [    5    77]]

 [[28239     6]
  [   24   386]]

 [[28240     9]
  [   32   374]]

 [[28640     3]
  [   10     2]]

 [[28506     0]
  [   39   110]]

 [[27710   243]
  [   21   681]]

 [[28459     0]
  [   12   184]]

 [[28615     8]
  [    2    30]]

 [[28544    42]
  [   20    49]]

 [[28558     4]
  [    9    84]]

 [[28622     0]
  [    7    26]]

 [[28599     6]
  [    5    45]]

 [[28467    34]
  [   16   138]]]

===scores report===
metrics	scores
Accuracy	0.8194
MCC	0.8159
log_loss	0.8580
f1 score weighted	0.8114
f1 score macro	0.6817
f1 score micro	0.8194
roc_auc ovr	0.9929
roc_auc ovo	0.9894
precision	0.8374
recall	0.8194

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f156c711670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f156c711850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f156c7118b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f156c7115b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  96.,  46., 108.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.95      0.87       824
         1.0       0.86      0.43      0.57        14
         2.0       0.85      0.91      0.88        32
         3.0       1.00      0.08      0.15        12
         4.0       0.85      0.85      0.85        52
         5.0       0.84      0.77      0.80       175
         6.0       0.51      0.61      0.56       101
         7.0       0.46      0.38      0.41        98
         8.0       0.67      0.29      0.40        14
         9.0       0.58      0.40      0.47        70
        10.0       0.86      0.71      0.78       104
        11.0       1.00      0.11      0.20        18
        12.0       0.88      0.47      0.61        15
        13.0       0.89      0.74      0.81        42
        14.0       0.80      0.47      0.59        34
        15.0       0.91      0.91      0.91        65
        16.0       1.00      0.08      0.14        13
        17.0       0.82      0.47      0.60        19
        18.0       0.98      0.86      0.92        72
        19.0       0.79      0.37      0.50        30
        20.0       0.87      0.98      0.92        94
        21.0       0.75      0.89      0.81        46
        22.0       0.83      0.80      0.82        25
        23.0       0.95      0.95      0.95       345
        24.0       0.64      0.90      0.75        30
        25.0       0.00      0.00      0.00        20
        26.0       0.92      0.68      0.78       168
        27.0       1.00      0.66      0.79        35
        28.0       0.93      0.90      0.92        61
        29.0       0.84      0.68      0.75        63
        30.0       0.00      0.00      0.00        11
        31.0       0.00      0.00      0.00        12
        32.0       0.68      0.57      0.62        40
        33.0       0.95      0.85      0.90        74
        34.0       0.97      0.98      0.97        57
        35.0       0.81      0.81      0.81        16
        36.0       0.34      0.22      0.27        50
        37.0       0.76      0.95      0.84        20
        38.0       1.00      0.62      0.77        29
        39.0       0.95      0.91      0.93       101
        40.0       0.56      0.42      0.48        12
        41.0       1.00      0.93      0.96        14
        42.0       0.84      0.79      0.82        67
        43.0       0.87      0.91      0.89        76
        44.0       1.00      0.91      0.95        11
        45.0       1.00      0.95      0.97        37
        46.0       0.77      0.94      0.85      1613
        47.0       0.90      0.98      0.94       299
        48.0       0.99      0.98      0.99       243
        49.0       0.98      0.93      0.95       168
        50.0       0.85      0.80      0.82      1024
        51.0       0.79      0.75      0.77       353
        52.0       0.92      0.81      0.86        85
        53.0       0.60      0.86      0.71       606
        54.0       0.94      0.90      0.92       543
        55.0       0.90      0.76      0.82        79
        56.0       0.85      0.92      0.88       954
        57.0       0.81      0.94      0.87       247
        58.0       1.00      0.97      0.99        34
        59.0       0.86      0.85      0.85       876
        60.0       0.97      0.78      0.86        76
        61.0       0.93      0.86      0.89       566
        62.0       1.00      0.29      0.45        24
        63.0       0.86      0.35      0.49        55
        64.0       0.98      0.97      0.97       255
        65.0       1.00      0.46      0.63        13
        66.0       0.96      0.96      0.96       457
        67.0       0.95      0.57      0.71        37
        68.0       0.77      0.88      0.82      1189
        69.0       0.96      0.81      0.88       223
        70.0       0.91      0.53      0.67        19
        71.0       0.97      0.93      0.95       357
        72.0       0.76      0.42      0.54        31
        73.0       0.50      0.08      0.13        13
        74.0       1.00      0.97      0.98       128
        75.0       1.00      0.77      0.87        13
        76.0       0.74      0.72      0.73       461
        77.0       0.98      0.83      0.90       104
        78.0       0.83      0.19      0.31        53
        79.0       0.85      0.55      0.67        83
        80.0       0.80      0.59      0.68        79
        81.0       1.00      0.77      0.87        84
        82.0       0.93      0.87      0.90       334
        83.0       0.58      0.62      0.60        24
        84.0       0.87      0.67      0.76       518
        85.0       0.11      0.01      0.02        88
        86.0       1.00      0.67      0.80        12
        87.0       0.58      0.76      0.66       481
        88.0       0.85      0.60      0.71       126
        89.0       0.89      1.00      0.94        24
        90.0       0.84      0.77      0.80       152
        91.0       0.29      0.20      0.24        20
        92.0       1.00      0.07      0.14        27
        93.0       0.97      0.79      0.87        42
        94.0       0.54      0.21      0.30        33
        95.0       0.70      0.53      0.60       100
        96.0       0.93      0.78      0.85       415
        97.0       0.94      0.53      0.67       118
        98.0       0.95      0.75      0.84       100
        99.0       0.75      0.74      0.74       253
       100.0       0.96      0.96      0.96       116
       101.0       0.77      0.76      0.77       423
       102.0       0.84      0.83      0.83        99
       103.0       0.67      0.78      0.72        60
       104.0       0.73      0.85      0.78       265
       105.0       0.97      0.89      0.93        36
       106.0       0.91      0.87      0.89       495
       107.0       1.00      0.80      0.89        15
       108.0       0.90      0.83      0.86       611
       109.0       0.97      0.96      0.96       207
       110.0       0.80      0.55      0.65        22
       111.0       0.74      0.91      0.82       535
       112.0       0.92      0.62      0.74        98
       113.0       0.61      0.71      0.66        87
       114.0       0.95      0.95      0.95       110
       115.0       0.86      0.90      0.88       858
       116.0       0.76      0.37      0.49        60
       117.0       0.98      0.88      0.93       209
       118.0       0.00      0.00      0.00        12
       119.0       0.98      0.71      0.82        66
       120.0       0.99      0.90      0.95       157
       121.0       0.98      0.98      0.98        84
       122.0       0.75      0.60      0.67        55
       123.0       1.00      0.69      0.81       153
       124.0       0.93      0.84      0.89        51
       125.0       0.91      0.91      0.91       146
       126.0       0.69      0.58      0.63        77
       127.0       1.00      0.72      0.84        18
       128.0       0.89      0.88      0.88       197
       129.0       0.94      0.94      0.94       450
       130.0       0.73      0.73      0.73        11
       131.0       0.75      0.64      0.69        42
       132.0       0.80      0.80      0.80        15
       133.0       0.96      0.98      0.97       204
       134.0       0.97      0.97      0.97        76
       135.0       0.82      0.87      0.84       256
       136.0       0.75      0.15      0.25        20
       137.0       0.65      1.00      0.79        13
       138.0       0.78      0.70      0.74        67
       139.0       0.92      0.99      0.95      1464
       140.0       0.93      0.80      0.86       147
       141.0       0.92      0.91      0.91        98
       142.0       0.97      0.90      0.93       455
       143.0       0.95      0.95      0.95        82
       144.0       0.97      0.96      0.96       410
       145.0       0.96      0.95      0.96       406
       146.0       0.75      0.50      0.60        12
       147.0       0.92      0.84      0.88       148
       148.0       0.87      0.98      0.92       702
       149.0       0.99      0.94      0.97       196
       150.0       0.96      0.75      0.84        32
       151.0       0.91      0.70      0.79        69
       152.0       0.85      0.90      0.88        93
       153.0       1.00      0.76      0.86        33
       154.0       0.91      0.86      0.89        50
       155.0       0.82      0.91      0.86       153

    accuracy                           0.85     28655
   macro avg       0.83      0.71      0.74     28655
weighted avg       0.85      0.85      0.84     28655


===confusion_matrix===

[[781   0   0 ...   0   0   0]
 [  0   6   1 ...   0   0   0]
 [  1   0  29 ...   0   0   0]
 ...
 [  0   0   0 ...  25   1   0]
 [  0   0   0 ...   0  43   7]
 [  0   0   0 ...   0   3 139]]

===multilabel confusion matrix===

[[[27636   195]
  [   43   781]]

 [[28640     1]
  [    8     6]]

 [[28618     5]
  [    3    29]]

 [[28643     0]
  [   11     1]]

 [[28595     8]
  [    8    44]]

 [[28454    26]
  [   40   135]]

 [[28495    59]
  [   39    62]]

 [[28513    44]
  [   61    37]]

 [[28639     2]
  [   10     4]]

 [[28565    20]
  [   42    28]]

 [[28539    12]
  [   30    74]]

 [[28637     0]
  [   16     2]]

 [[28639     1]
  [    8     7]]

 [[28609     4]
  [   11    31]]

 [[28617     4]
  [   18    16]]

 [[28584     6]
  [    6    59]]

 [[28642     0]
  [   12     1]]

 [[28634     2]
  [   10     9]]

 [[28582     1]
  [   10    62]]

 [[28622     3]
  [   19    11]]

 [[28547    14]
  [    2    92]]

 [[28595    14]
  [    5    41]]

 [[28626     4]
  [    5    20]]

 [[28292    18]
  [   18   327]]

 [[28610    15]
  [    3    27]]

 [[28632     3]
  [   20     0]]

 [[28477    10]
  [   53   115]]

 [[28620     0]
  [   12    23]]

 [[28590     4]
  [    6    55]]

 [[28584     8]
  [   20    43]]

 [[28644     0]
  [   11     0]]

 [[28643     0]
  [   12     0]]

 [[28604    11]
  [   17    23]]

 [[28578     3]
  [   11    63]]

 [[28596     2]
  [    1    56]]

 [[28636     3]
  [    3    13]]

 [[28584    21]
  [   39    11]]

 [[28629     6]
  [    1    19]]

 [[28626     0]
  [   11    18]]

 [[28549     5]
  [    9    92]]

 [[28639     4]
  [    7     5]]

 [[28641     0]
  [    1    13]]

 [[28578    10]
  [   14    53]]

 [[28569    10]
  [    7    69]]

 [[28644     0]
  [    1    10]]

 [[28618     0]
  [    2    35]]

 [[26586   456]
  [   92  1521]]

 [[28323    33]
  [    7   292]]

 [[28410     2]
  [    4   239]]

 [[28483     4]
  [   11   157]]

 [[27487   144]
  [  204   820]]

 [[28233    69]
  [   89   264]]

 [[28564     6]
  [   16    69]]

 [[27705   344]
  [   85   521]]

 [[28078    34]
  [   52   491]]

 [[28569     7]
  [   19    60]]

 [[27543   158]
  [   80   874]]

 [[28355    53]
  [   14   233]]

 [[28621     0]
  [    1    33]]

 [[27657   122]
  [  131   745]]

 [[28577     2]
  [   17    59]]

 [[28050    39]
  [   80   486]]

 [[28631     0]
  [   17     7]]

 [[28597     3]
  [   36    19]]

 [[28395     5]
  [    8   247]]

 [[28642     0]
  [    7     6]]

 [[28179    19]
  [   17   440]]

 [[28617     1]
  [   16    21]]

 [[27152   314]
  [  138  1051]]

 [[28425     7]
  [   42   181]]

 [[28635     1]
  [    9    10]]

 [[28289     9]
  [   26   331]]

 [[28620     4]
  [   18    13]]

 [[28641     1]
  [   12     1]]

 [[28527     0]
  [    4   124]]

 [[28642     0]
  [    3    10]]

 [[28079   115]
  [  127   334]]

 [[28549     2]
  [   18    86]]

 [[28600     2]
  [   43    10]]

 [[28564     8]
  [   37    46]]

 [[28564    12]
  [   32    47]]

 [[28571     0]
  [   19    65]]

 [[28298    23]
  [   44   290]]

 [[28620    11]
  [    9    15]]

 [[28085    52]
  [  170   348]]

 [[28559     8]
  [   87     1]]

 [[28643     0]
  [    4     8]]

 [[27906   268]
  [  116   365]]

 [[28516    13]
  [   50    76]]

 [[28628     3]
  [    0    24]]

 [[28480    23]
  [   35   117]]

 [[28625    10]
  [   16     4]]

 [[28628     0]
  [   25     2]]

 [[28612     1]
  [    9    33]]

 [[28616     6]
  [   26     7]]

 [[28532    23]
  [   47    53]]

 [[28217    23]
  [   91   324]]

 [[28533     4]
  [   56    62]]

 [[28551     4]
  [   25    75]]

 [[28338    64]
  [   65   188]]

 [[28534     5]
  [    5   111]]

 [[28138    94]
  [  100   323]]

 [[28540    16]
  [   17    82]]

 [[28572    23]
  [   13    47]]

 [[28307    83]
  [   41   224]]

 [[28618     1]
  [    4    32]]

 [[28119    41]
  [   62   433]]

 [[28640     0]
  [    3    12]]

 [[27988    56]
  [  106   505]]

 [[28441     7]
  [    9   198]]

 [[28630     3]
  [   10    12]]

 [[27952   168]
  [   49   486]]

 [[28552     5]
  [   37    61]]

 [[28529    39]
  [   25    62]]

 [[28540     5]
  [    6   104]]

 [[27671   126]
  [   86   772]]

 [[28588     7]
  [   38    22]]

 [[28443     3]
  [   26   183]]

 [[28643     0]
  [   12     0]]

 [[28588     1]
  [   19    47]]

 [[28497     1]
  [   15   142]]

 [[28569     2]
  [    2    82]]

 [[28589    11]
  [   22    33]]

 [[28502     0]
  [   48   105]]

 [[28601     3]
  [    8    43]]

 [[28496    13]
  [   13   133]]

 [[28558    20]
  [   32    45]]

 [[28637     0]
  [    5    13]]

 [[28437    21]
  [   24   173]]

 [[28178    27]
  [   25   425]]

 [[28641     3]
  [    3     8]]

 [[28604     9]
  [   15    27]]

 [[28637     3]
  [    3    12]]

 [[28443     8]
  [    4   200]]

 [[28577     2]
  [    2    74]]

 [[28349    50]
  [   33   223]]

 [[28634     1]
  [   17     3]]

 [[28635     7]
  [    0    13]]

 [[28575    13]
  [   20    47]]

 [[27060   131]
  [   14  1450]]

 [[28499     9]
  [   30   117]]

 [[28549     8]
  [    9    89]]

 [[28186    14]
  [   47   408]]

 [[28569     4]
  [    4    78]]

 [[28231    14]
  [   15   395]]

 [[28233    16]
  [   20   386]]

 [[28641     2]
  [    6     6]]

 [[28496    11]
  [   23   125]]

 [[27846   107]
  [   11   691]]

 [[28458     1]
  [   12   184]]

 [[28622     1]
  [    8    24]]

 [[28581     5]
  [   21    48]]

 [[28547    15]
  [    9    84]]

 [[28622     0]
  [    8    25]]

 [[28601     4]
  [    7    43]]

 [[28472    30]
  [   14   139]]]

===scores report===
metrics	scores
Accuracy	0.8493
MCC	0.8462
log_loss	0.6768
f1 score weighted	0.8444
f1 score macro	0.7448
f1 score micro	0.8493
roc_auc ovr	0.9943
roc_auc ovo	0.9918
precision	0.8535
recall	0.8493

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f156c711670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f156c711850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f156c7118b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f156c7115b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56., 115., ...,  96., 109.,  88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.95      0.87       824
         1.0       1.00      0.14      0.25        14
         2.0       0.70      0.81      0.75        32
         3.0       0.00      0.00      0.00        11
         4.0       0.80      0.71      0.75        51
         5.0       0.79      0.79      0.79       176
         6.0       0.76      0.50      0.60       102
         7.0       0.84      0.28      0.42        97
         8.0       1.00      0.50      0.67        14
         9.0       0.62      0.40      0.49        70
        10.0       0.86      0.86      0.86       103
        11.0       1.00      0.11      0.20        18
        12.0       0.33      0.07      0.11        15
        13.0       0.89      0.74      0.81        43
        14.0       0.80      0.47      0.59        34
        15.0       0.69      0.80      0.74        65
        16.0       1.00      0.15      0.27        13
        17.0       0.69      0.58      0.63        19
        18.0       0.97      0.89      0.93        72
        19.0       1.00      0.03      0.06        30
        20.0       0.99      0.98      0.98        94
        21.0       0.75      0.89      0.81        46
        22.0       0.90      0.36      0.51        25
        23.0       0.95      0.93      0.94       345
        24.0       1.00      0.60      0.75        30
        25.0       0.25      0.05      0.08        20
        26.0       0.81      0.70      0.75       168
        27.0       0.96      0.66      0.78        35
        28.0       1.00      0.89      0.94        61
        29.0       1.00      0.78      0.88        63
        30.0       0.67      0.18      0.29        11
        31.0       1.00      0.17      0.29        12
        32.0       1.00      0.23      0.37        40
        33.0       0.77      0.74      0.76        74
        34.0       0.97      0.98      0.97        57
        35.0       0.94      1.00      0.97        15
        36.0       0.37      0.26      0.31        50
        37.0       0.78      0.95      0.86        19
        38.0       0.89      0.55      0.68        29
        39.0       0.93      0.91      0.92       101
        40.0       1.00      0.77      0.87        13
        41.0       1.00      0.86      0.92        14
        42.0       0.96      0.77      0.86        66
        43.0       0.98      0.84      0.91        76
        44.0       1.00      0.91      0.95        11
        45.0       0.94      0.81      0.87        37
        46.0       0.92      0.91      0.91      1612
        47.0       0.93      0.99      0.96       299
        48.0       1.00      0.96      0.98       243
        49.0       0.96      0.92      0.94       168
        50.0       0.82      0.82      0.82      1024
        51.0       0.85      0.78      0.81       353
        52.0       0.94      0.87      0.90        85
        53.0       0.70      0.84      0.76       606
        54.0       0.97      0.87      0.92       543
        55.0       1.00      0.67      0.80        78
        56.0       0.81      0.92      0.86       954
        57.0       0.96      0.90      0.93       247
        58.0       1.00      0.97      0.99        34
        59.0       0.79      0.85      0.82       877
        60.0       1.00      0.68      0.81        76
        61.0       0.87      0.88      0.88       566
        62.0       0.68      0.62      0.65        24
        63.0       0.67      0.60      0.63        55
        64.0       0.99      0.95      0.97       255
        65.0       0.86      0.43      0.57        14
        66.0       0.95      0.95      0.95       457
        67.0       0.95      0.51      0.67        37
        68.0       0.71      0.89      0.79      1189
        69.0       0.91      0.90      0.90       224
        70.0       0.71      0.53      0.61        19
        71.0       0.97      0.93      0.95       357
        72.0       0.92      0.38      0.53        32
        73.0       0.00      0.00      0.00        12
        74.0       0.99      0.94      0.96       127
        75.0       1.00      0.75      0.86        12
        76.0       0.79      0.77      0.78       460
        77.0       0.89      0.83      0.86       103
        78.0       0.86      0.35      0.49        52
        79.0       0.80      0.58      0.67        83
        80.0       0.55      0.53      0.54        80
        81.0       0.88      0.83      0.85        84
        82.0       0.91      0.86      0.88       334
        83.0       0.67      0.78      0.72        23
        84.0       0.78      0.69      0.73       519
        85.0       0.10      0.01      0.02        88
        86.0       1.00      0.42      0.59        12
        87.0       0.56      0.71      0.62       480
        88.0       0.91      0.65      0.76       126
        89.0       1.00      0.96      0.98        25
        90.0       0.72      0.69      0.70       152
        91.0       0.75      0.30      0.43        20
        92.0       1.00      0.50      0.67        28
        93.0       0.95      0.83      0.89        42
        94.0       0.33      0.06      0.10        34
        95.0       0.83      0.48      0.61       100
        96.0       0.66      0.86      0.75       415
        97.0       0.64      0.40      0.49       118
        98.0       0.84      0.82      0.83        99
        99.0       0.55      0.86      0.67       253
       100.0       0.95      0.91      0.93       116
       101.0       0.71      0.79      0.75       423
       102.0       0.93      0.78      0.85        99
       103.0       0.91      0.70      0.79        60
       104.0       0.91      0.84      0.87       265
       105.0       0.94      0.81      0.87        37
       106.0       0.72      0.88      0.79       495
       107.0       1.00      0.67      0.80        15
       108.0       0.87      0.83      0.85       611
       109.0       0.96      0.95      0.95       206
       110.0       0.88      0.64      0.74        22
       111.0       0.91      0.84      0.87       534
       112.0       0.75      0.70      0.73        98
       113.0       0.90      0.51      0.65        87
       114.0       0.96      0.88      0.92       110
       115.0       0.78      0.90      0.84       858
       116.0       0.64      0.41      0.50        61
       117.0       0.86      0.95      0.90       209
       118.0       0.00      0.00      0.00        13
       119.0       0.95      0.58      0.72        65
       120.0       0.99      0.96      0.97       156
       121.0       0.98      0.96      0.97        85
       122.0       1.00      0.55      0.71        56
       123.0       0.90      0.77      0.83       154
       124.0       1.00      0.79      0.88        52
       125.0       1.00      0.83      0.91       146
       126.0       0.50      0.71      0.59        77
       127.0       1.00      0.83      0.91        18
       128.0       0.65      0.91      0.76       198
       129.0       0.96      0.93      0.94       450
       130.0       1.00      0.45      0.62        11
       131.0       0.95      0.47      0.62        43
       132.0       1.00      0.87      0.93        15
       133.0       0.96      0.96      0.96       205
       134.0       0.99      0.95      0.97        77
       135.0       0.91      0.80      0.85       255
       136.0       0.57      0.20      0.30        20
       137.0       0.79      0.92      0.85        12
       138.0       0.82      0.60      0.69        67
       139.0       0.99      0.98      0.98      1464
       140.0       0.99      0.78      0.87       147
       141.0       0.79      0.87      0.83        98
       142.0       0.94      0.89      0.92       455
       143.0       0.99      0.95      0.97        82
       144.0       0.98      0.94      0.96       411
       145.0       0.86      0.97      0.91       405
       146.0       0.40      0.18      0.25        11
       147.0       0.97      0.86      0.91       148
       148.0       0.92      0.96      0.94       702
       149.0       0.92      0.97      0.94       196
       150.0       0.96      0.72      0.82        32
       151.0       0.91      0.74      0.82        69
       152.0       0.95      0.95      0.95        93
       153.0       0.97      0.91      0.94        33
       154.0       0.81      0.88      0.85        50
       155.0       0.88      0.94      0.91       154

    accuracy                           0.84     28655
   macro avg       0.84      0.70      0.74     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[785   0   0 ...   0   0   0]
 [  0   2   5 ...   0   0   0]
 [  0   0  26 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   1]
 [  0   0   0 ...   0  44   5]
 [  0   0   0 ...   0   8 144]]

===multilabel confusion matrix===

[[[27630   201]
  [   39   785]]

 [[28641     0]
  [   12     2]]

 [[28612    11]
  [    6    26]]

 [[28642     2]
  [   11     0]]

 [[28595     9]
  [   15    36]]

 [[28442    37]
  [   37   139]]

 [[28537    16]
  [   51    51]]

 [[28553     5]
  [   70    27]]

 [[28641     0]
  [    7     7]]

 [[28568    17]
  [   42    28]]

 [[28538    14]
  [   14    89]]

 [[28637     0]
  [   16     2]]

 [[28638     2]
  [   14     1]]

 [[28608     4]
  [   11    32]]

 [[28617     4]
  [   18    16]]

 [[28567    23]
  [   13    52]]

 [[28642     0]
  [   11     2]]

 [[28631     5]
  [    8    11]]

 [[28581     2]
  [    8    64]]

 [[28625     0]
  [   29     1]]

 [[28560     1]
  [    2    92]]

 [[28595    14]
  [    5    41]]

 [[28629     1]
  [   16     9]]

 [[28292    18]
  [   23   322]]

 [[28625     0]
  [   12    18]]

 [[28632     3]
  [   19     1]]

 [[28460    27]
  [   51   117]]

 [[28619     1]
  [   12    23]]

 [[28594     0]
  [    7    54]]

 [[28592     0]
  [   14    49]]

 [[28643     1]
  [    9     2]]

 [[28643     0]
  [   10     2]]

 [[28615     0]
  [   31     9]]

 [[28565    16]
  [   19    55]]

 [[28596     2]
  [    1    56]]

 [[28639     1]
  [    0    15]]

 [[28583    22]
  [   37    13]]

 [[28631     5]
  [    1    18]]

 [[28624     2]
  [   13    16]]

 [[28547     7]
  [    9    92]]

 [[28642     0]
  [    3    10]]

 [[28641     0]
  [    2    12]]

 [[28587     2]
  [   15    51]]

 [[28578     1]
  [   12    64]]

 [[28644     0]
  [    1    10]]

 [[28616     2]
  [    7    30]]

 [[26908   135]
  [  153  1459]]

 [[28334    22]
  [    2   297]]

 [[28411     1]
  [   10   233]]

 [[28481     6]
  [   14   154]]

 [[27447   184]
  [  186   838]]

 [[28254    48]
  [   78   275]]

 [[28565     5]
  [   11    74]]

 [[27827   222]
  [   94   512]]

 [[28095    17]
  [   70   473]]

 [[28577     0]
  [   26    52]]

 [[27500   201]
  [   75   879]]

 [[28399     9]
  [   24   223]]

 [[28621     0]
  [    1    33]]

 [[27586   192]
  [  133   744]]

 [[28579     0]
  [   24    52]]

 [[28016    73]
  [   68   498]]

 [[28624     7]
  [    9    15]]

 [[28584    16]
  [   22    33]]

 [[28397     3]
  [   12   243]]

 [[28640     1]
  [    8     6]]

 [[28177    21]
  [   21   436]]

 [[28617     1]
  [   18    19]]

 [[27026   440]
  [  132  1057]]

 [[28410    21]
  [   23   201]]

 [[28632     4]
  [    9    10]]

 [[28287    11]
  [   25   332]]

 [[28622     1]
  [   20    12]]

 [[28640     3]
  [   12     0]]

 [[28527     1]
  [    8   119]]

 [[28643     0]
  [    3     9]]

 [[28102    93]
  [  107   353]]

 [[28542    10]
  [   18    85]]

 [[28600     3]
  [   34    18]]

 [[28560    12]
  [   35    48]]

 [[28540    35]
  [   38    42]]

 [[28561    10]
  [   14    70]]

 [[28292    29]
  [   48   286]]

 [[28623     9]
  [    5    18]]

 [[28033   103]
  [  160   359]]

 [[28558     9]
  [   87     1]]

 [[28643     0]
  [    7     5]]

 [[27901   274]
  [  138   342]]

 [[28521     8]
  [   44    82]]

 [[28630     0]
  [    1    24]]

 [[28462    41]
  [   47   105]]

 [[28633     2]
  [   14     6]]

 [[28627     0]
  [   14    14]]

 [[28611     2]
  [    7    35]]

 [[28617     4]
  [   32     2]]

 [[28545    10]
  [   52    48]]

 [[28058   182]
  [   58   357]]

 [[28511    26]
  [   71    47]]

 [[28541    15]
  [   18    81]]

 [[28225   177]
  [   35   218]]

 [[28533     6]
  [   10   106]]

 [[28096   136]
  [   90   333]]

 [[28550     6]
  [   22    77]]

 [[28591     4]
  [   18    42]]

 [[28368    22]
  [   43   222]]

 [[28616     2]
  [    7    30]]

 [[27990   170]
  [   61   434]]

 [[28640     0]
  [    5    10]]

 [[27968    76]
  [  101   510]]

 [[28440     9]
  [   11   195]]

 [[28631     2]
  [    8    14]]

 [[28075    46]
  [   87   447]]

 [[28534    23]
  [   29    69]]

 [[28563     5]
  [   43    44]]

 [[28541     4]
  [   13    97]]

 [[27580   217]
  [   82   776]]

 [[28580    14]
  [   36    25]]

 [[28414    32]
  [   10   199]]

 [[28642     0]
  [   13     0]]

 [[28588     2]
  [   27    38]]

 [[28497     2]
  [    7   149]]

 [[28568     2]
  [    3    82]]

 [[28599     0]
  [   25    31]]

 [[28488    13]
  [   36   118]]

 [[28603     0]
  [   11    41]]

 [[28509     0]
  [   25   121]]

 [[28523    55]
  [   22    55]]

 [[28637     0]
  [    3    15]]

 [[28359    98]
  [   17   181]]

 [[28188    17]
  [   32   418]]

 [[28644     0]
  [    6     5]]

 [[28611     1]
  [   23    20]]

 [[28640     0]
  [    2    13]]

 [[28442     8]
  [    9   196]]

 [[28577     1]
  [    4    73]]

 [[28379    21]
  [   50   205]]

 [[28632     3]
  [   16     4]]

 [[28640     3]
  [    1    11]]

 [[28579     9]
  [   27    40]]

 [[27171    20]
  [   24  1440]]

 [[28507     1]
  [   32   115]]

 [[28535    22]
  [   13    85]]

 [[28176    24]
  [   49   406]]

 [[28572     1]
  [    4    78]]

 [[28237     7]
  [   26   385]]

 [[28185    65]
  [   14   391]]

 [[28641     3]
  [    9     2]]

 [[28503     4]
  [   21   127]]

 [[27896    57]
  [   26   676]]

 [[28442    17]
  [    6   190]]

 [[28622     1]
  [    9    23]]

 [[28581     5]
  [   18    51]]

 [[28557     5]
  [    5    88]]

 [[28621     1]
  [    3    30]]

 [[28595    10]
  [    6    44]]

 [[28482    19]
  [   10   144]]]

===scores report===
metrics	scores
Accuracy	0.8448
MCC	0.8416
log_loss	0.7066
f1 score weighted	0.8403
f1 score macro	0.7379
f1 score micro	0.8448
roc_auc ovr	0.9937
roc_auc ovo	0.9909
precision	0.8513
recall	0.8448

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8425460636515912	0.839617358673872	0.7078637216364068	0.8426813916153747	0.7380942601004098	0.8425460636515912	0.9939009180638566	0.9914987822047007	0.8590186916110136	0.8425460636515912
1	0.8461001570406561	0.8429559561912361	0.7064914753638215	0.8417979272314481	0.7448667186934258	0.8461001570406561	0.9935718206923781	0.9903731344170575	0.8528335321878237	0.8461001570406561
2	0.8194032455068924	0.8158972772739146	0.8579917608724718	0.8113613529068079	0.6816995696618189	0.8194032455068923	0.9929054822940728	0.9894049097816298	0.8373930759334234	0.8194032455068924
3	0.8492758680858489	0.846150663575698	0.6768183613267675	0.8443775377676863	0.7447958276402975	0.8492758680858489	0.9943169442860169	0.99177021324483	0.8534812896297702	0.8492758680858489
4	0.8447740359448613	0.8415736656298219	0.7065863500535802	0.8402758806613438	0.7379246585200318	0.8447740359448613	0.9936571868423437	0.9909116010071323	0.8512630703835151	0.8447740359448613
mean	0.84041987404597	0.8372389842689085	0.7311503338506096	0.8360988180365322	0.7294762069231968	0.84041987404597	0.9936704704357338	0.9907917281310701	0.8507979319491092	0.84041987404597
std	0.010731936717708241	0.010881326948481516	0.06448941891123029	0.012439753648198788	0.02408241214837084	0.010731936717708284	0.0004617682602792655	0.0008450105228999068	0.00719487991223539	0.010731936717708241

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 72143.6884 secs

