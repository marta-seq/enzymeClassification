/home/amsequeira/enzymeClassification/models/hot_encoded/bi_attetion_500_post_post_lev3_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f851448c730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f851448c5b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f851448c790>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.7815259133660516)
('Validation Accuracy mean: ', 0.5118587947515554)
('Training Loss mean: ', 1.1090567146622858)
('Validation Loss mean: ', 2.8759314930716227)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500, 21)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 128)          44032     
_________________________________________________________________
bidirectional_1 (Bidirection (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_2 (Bidirection (None, 500, 64)           41216     
_________________________________________________________________
attention (attention)        (None, 64)                564       
_________________________________________________________________
dense (Dense)                (None, 32)                2080      
_________________________________________________________________
batch_normalization (BatchNo (None, 32)                128       
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                528       
_________________________________________________________________
batch_normalization_1 (Batch (None, 16)                64        
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 156)               2652      
=================================================================
Total params: 190,080
Trainable params: 189,984
Non-trainable params: 96
_________________________________________________________________Finished run_model in 16697.4635 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f851448c910>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.89      0.97      0.93       825
           1       0.91      0.71      0.80        14
           2       0.90      0.84      0.87        32
           3       0.43      0.27      0.33        11
           4       0.75      0.88      0.81        52
           5       0.91      0.85      0.88       176
           6       0.68      0.84      0.75       102
           7       0.66      0.71      0.68        97
           8       0.89      0.57      0.70        14
           9       0.79      0.66      0.72        70
          10       0.82      0.89      0.86       104
          11       0.89      0.44      0.59        18
          12       0.91      0.67      0.77        15
          13       0.94      0.76      0.84        42
          14       0.92      0.71      0.80        34
          15       0.90      0.89      0.90        64
          16       1.00      0.62      0.76        13
          17       1.00      0.79      0.88        19
          18       0.96      0.94      0.95        72
          19       0.96      0.83      0.89        30
          20       0.98      1.00      0.99        94
          21       0.94      1.00      0.97        46
          22       0.96      0.96      0.96        25
          23       0.98      0.80      0.88       345
          24       0.00      0.00      0.00        30
          25       0.62      0.50      0.56        20
          26       0.89      0.89      0.89       167
          27       0.94      0.83      0.88        36
          28       0.96      0.79      0.86        61
          29       0.88      0.95      0.92        63
          30       0.69      0.82      0.75        11
          31       0.50      0.18      0.27        11
          32       0.72      0.85      0.78        40
          33       0.94      0.82      0.88        74
          34       0.98      1.00      0.99        57
          35       1.00      1.00      1.00        16
          36       0.62      0.48      0.54        50
          37       0.95      0.95      0.95        19
          38       1.00      0.90      0.95        29
          39       1.00      0.98      0.99       101
          40       1.00      0.25      0.40        12
          41       1.00      1.00      1.00        14
          42       0.75      0.93      0.83        67
          43       0.89      0.92      0.90        76
          44       0.92      1.00      0.96        11
          45       0.87      0.92      0.89        37
          46       0.89      0.93      0.91      1613
          47       0.98      1.00      0.99       299
          48       0.98      0.98      0.98       243
          49       0.94      1.00      0.97       168
          50       0.82      0.82      0.82      1024
          51       0.78      0.88      0.82       353
          52       0.85      0.95      0.90        86
          53       0.83      0.91      0.87       606
          54       0.95      0.96      0.95       543
          55       1.00      0.81      0.89        78
          56       0.90      0.97      0.93       954
          57       0.88      0.88      0.88       247
          58       1.00      1.00      1.00        34
          59       0.84      0.94      0.89       877
          60       0.73      0.69      0.71        77
          61       0.82      0.90      0.86       566
          62       1.00      0.50      0.67        24
          63       0.80      0.64      0.71        55
          64       0.99      0.80      0.89       255
          65       0.85      0.85      0.85        13
          66       0.94      0.95      0.94       457
          67       0.97      0.78      0.87        37
          68       0.86      0.87      0.87      1189
          69       0.83      0.94      0.88       224
          70       0.00      0.00      0.00        19
          71       0.98      0.99      0.99       357
          72       0.93      0.84      0.89        32
          73       1.00      0.08      0.14        13
          74       0.99      0.99      0.99       128
          75       0.00      0.00      0.00        12
          76       0.85      0.82      0.84       460
          77       0.98      0.90      0.94       104
          78       0.59      0.37      0.45        52
          79       0.83      0.87      0.85        83
          80       0.62      0.81      0.70        80
          81       0.76      0.15      0.26        84
          82       0.94      0.68      0.79       334
          83       0.57      0.50      0.53        24
          84       0.78      0.80      0.79       518
          85       0.66      0.22      0.32        88
          86       0.92      0.92      0.92        12
          87       0.61      0.94      0.74       480
          88       0.75      0.77      0.76       126
          89       0.00      0.00      0.00        25
          90       0.84      0.92      0.88       152
          91       1.00      0.30      0.46        20
          92       0.68      0.56      0.61        27
          93       0.94      0.76      0.84        42
          94       0.87      0.76      0.81        34
          95       0.67      0.68      0.67        99
          96       0.77      0.85      0.81       415
          97       0.89      0.66      0.76       118
          98       0.70      0.84      0.76        99
          99       0.85      0.87      0.86       253
         100       0.90      0.95      0.92       116
         101       0.82      0.87      0.84       423
         102       0.91      0.97      0.94        99
         103       0.86      0.92      0.89        60
         104       0.83      0.95      0.89       265
         105       0.97      0.94      0.96        36
         106       0.85      0.76      0.80       495
         107       1.00      0.86      0.92        14
         108       0.85      0.73      0.79       610
         109       0.94      0.75      0.84       206
         110       0.90      0.86      0.88        22
         111       0.91      0.94      0.93       535
         112       0.76      0.74      0.75        98
         113       0.87      0.92      0.89        86
         114       0.99      0.95      0.97       110
         115       0.88      0.92      0.90       858
         116       0.75      0.59      0.66        61
         117       0.96      0.96      0.96       209
         118       0.50      0.08      0.13        13
         119       0.84      0.75      0.80        65
         120       0.98      0.99      0.99       157
         121       0.99      1.00      0.99        84
         122       0.77      0.87      0.82        55
         123       0.88      0.81      0.84       154
         124       1.00      0.98      0.99        52
         125       0.97      0.96      0.96       147
         126       0.81      0.81      0.81        77
         127       1.00      0.94      0.97        18
         128       0.91      0.87      0.89       197
         129       0.95      0.98      0.96       450
         130       1.00      0.82      0.90        11
         131       0.85      0.93      0.89        43
         132       1.00      0.87      0.93        15
         133       0.97      0.97      0.97       204
         134       0.94      0.99      0.96        76
         135       0.91      0.95      0.93       255
         136       0.85      0.55      0.67        20
         137       0.92      0.92      0.92        13
         138       0.76      0.93      0.83        67
         139       0.97      1.00      0.98      1464
         140       0.91      0.97      0.94       147
         141       0.96      0.98      0.97        98
         142       0.95      0.96      0.96       455
         143       1.00      0.93      0.96        82
         144       0.97      0.97      0.97       410
         145       0.96      1.00      0.98       406
         146       0.64      0.75      0.69        12
         147       0.85      0.86      0.85       149
         148       0.96      0.51      0.66       702
         149       1.00      0.95      0.97       196
         150       0.80      0.88      0.84        32
         151       0.65      0.64      0.64        69
         152       0.95      0.82      0.88        93
         153       0.84      0.97      0.90        33
         154       0.82      1.00      0.90        50
         155       0.77      0.82      0.80       154

    accuracy                           0.88     28656
   macro avg       0.85      0.79      0.81     28656
weighted avg       0.88      0.88      0.87     28656


===confusion_matrix===

[[802   0   0 ...   0   0   0]
 [  0  10   1 ...   0   0   0]
 [  0   0  27 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   0]
 [  0   0   0 ...   0  50   0]
 [  0   0   0 ...   1   5 127]]

===multilabel confusion matrix===

[[[27728   103]
  [   23   802]]

 [[28641     1]
  [    4    10]]

 [[28621     3]
  [    5    27]]

 [[28641     4]
  [    8     3]]

 [[28589    15]
  [    6    46]]

 [[28466    14]
  [   27   149]]

 [[28513    41]
  [   16    86]]

 [[28523    36]
  [   28    69]]

 [[28641     1]
  [    6     8]]

 [[28574    12]
  [   24    46]]

 [[28532    20]
  [   11    93]]

 [[28637     1]
  [   10     8]]

 [[28640     1]
  [    5    10]]

 [[28612     2]
  [   10    32]]

 [[28620     2]
  [   10    24]]

 [[28586     6]
  [    7    57]]

 [[28643     0]
  [    5     8]]

 [[28637     0]
  [    4    15]]

 [[28581     3]
  [    4    68]]

 [[28625     1]
  [    5    25]]

 [[28560     2]
  [    0    94]]

 [[28607     3]
  [    0    46]]

 [[28630     1]
  [    1    24]]

 [[28306     5]
  [   69   276]]

 [[28626     0]
  [   30     0]]

 [[28630     6]
  [   10    10]]

 [[28470    19]
  [   19   148]]

 [[28618     2]
  [    6    30]]

 [[28593     2]
  [   13    48]]

 [[28585     8]
  [    3    60]]

 [[28641     4]
  [    2     9]]

 [[28643     2]
  [    9     2]]

 [[28603    13]
  [    6    34]]

 [[28578     4]
  [   13    61]]

 [[28598     1]
  [    0    57]]

 [[28640     0]
  [    0    16]]

 [[28591    15]
  [   26    24]]

 [[28636     1]
  [    1    18]]

 [[28627     0]
  [    3    26]]

 [[28555     0]
  [    2    99]]

 [[28644     0]
  [    9     3]]

 [[28642     0]
  [    0    14]]

 [[28568    21]
  [    5    62]]

 [[28571     9]
  [    6    70]]

 [[28644     1]
  [    0    11]]

 [[28614     5]
  [    3    34]]

 [[26862   181]
  [  111  1502]]

 [[28350     7]
  [    1   298]]

 [[28407     6]
  [    6   237]]

 [[28478    10]
  [    0   168]]

 [[27453   179]
  [  182   842]]

 [[28214    89]
  [   43   310]]

 [[28555    15]
  [    4    82]]

 [[27941   109]
  [   56   550]]

 [[28084    29]
  [   24   519]]

 [[28578     0]
  [   15    63]]

 [[27598   104]
  [   29   925]]

 [[28380    29]
  [   30   217]]

 [[28622     0]
  [    0    34]]

 [[27627   152]
  [   56   821]]

 [[28559    20]
  [   24    53]]

 [[27976   114]
  [   54   512]]

 [[28632     0]
  [   12    12]]

 [[28592     9]
  [   20    35]]

 [[28398     3]
  [   50   205]]

 [[28641     2]
  [    2    11]]

 [[28170    29]
  [   24   433]]

 [[28618     1]
  [    8    29]]

 [[27297   170]
  [  153  1036]]

 [[28389    43]
  [   14   210]]

 [[28637     0]
  [   19     0]]

 [[28292     7]
  [    3   354]]

 [[28622     2]
  [    5    27]]

 [[28643     0]
  [   12     1]]

 [[28527     1]
  [    1   127]]

 [[28644     0]
  [   12     0]]

 [[28129    67]
  [   81   379]]

 [[28550     2]
  [   10    94]]

 [[28591    13]
  [   33    19]]

 [[28558    15]
  [   11    72]]

 [[28536    40]
  [   15    65]]

 [[28568     4]
  [   71    13]]

 [[28307    15]
  [  108   226]]

 [[28623     9]
  [   12    12]]

 [[28022   116]
  [  104   414]]

 [[28558    10]
  [   69    19]]

 [[28643     1]
  [    1    11]]

 [[27892   284]
  [   28   452]]

 [[28498    32]
  [   29    97]]

 [[28631     0]
  [   25     0]]

 [[28477    27]
  [   12   140]]

 [[28636     0]
  [   14     6]]

 [[28622     7]
  [   12    15]]

 [[28612     2]
  [   10    32]]

 [[28618     4]
  [    8    26]]

 [[28524    33]
  [   32    67]]

 [[28137   104]
  [   63   352]]

 [[28528    10]
  [   40    78]]

 [[28521    36]
  [   16    83]]

 [[28365    38]
  [   32   221]]

 [[28528    12]
  [    6   110]]

 [[28151    82]
  [   54   369]]

 [[28548     9]
  [    3    96]]

 [[28587     9]
  [    5    55]]

 [[28340    51]
  [   12   253]]

 [[28619     1]
  [    2    34]]

 [[28096    65]
  [  118   377]]

 [[28642     0]
  [    2    12]]

 [[27969    77]
  [  166   444]]

 [[28440    10]
  [   51   155]]

 [[28632     2]
  [    3    19]]

 [[28072    49]
  [   30   505]]

 [[28535    23]
  [   25    73]]

 [[28558    12]
  [    7    79]]

 [[28545     1]
  [    6   104]]

 [[27688   110]
  [   66   792]]

 [[28583    12]
  [   25    36]]

 [[28439     8]
  [    8   201]]

 [[28642     1]
  [   12     1]]

 [[28582     9]
  [   16    49]]

 [[28496     3]
  [    1   156]]

 [[28571     1]
  [    0    84]]

 [[28587    14]
  [    7    48]]

 [[28485    17]
  [   30   124]]

 [[28604     0]
  [    1    51]]

 [[28504     5]
  [    6   141]]

 [[28564    15]
  [   15    62]]

 [[28638     0]
  [    1    17]]

 [[28442    17]
  [   25   172]]

 [[28184    22]
  [   10   440]]

 [[28645     0]
  [    2     9]]

 [[28606     7]
  [    3    40]]

 [[28641     0]
  [    2    13]]

 [[28445     7]
  [    6   198]]

 [[28575     5]
  [    1    75]]

 [[28378    23]
  [   12   243]]

 [[28634     2]
  [    9    11]]

 [[28642     1]
  [    1    12]]

 [[28569    20]
  [    5    62]]

 [[27147    45]
  [    4  1460]]

 [[28495    14]
  [    5   142]]

 [[28554     4]
  [    2    96]]

 [[28177    24]
  [   16   439]]

 [[28574     0]
  [    6    76]]

 [[28235    11]
  [   14   396]]

 [[28235    15]
  [    0   406]]

 [[28639     5]
  [    3     9]]

 [[28484    23]
  [   21   128]]

 [[27941    13]
  [  347   355]]

 [[28460     0]
  [   10   186]]

 [[28617     7]
  [    4    28]]

 [[28563    24]
  [   25    44]]

 [[28559     4]
  [   17    76]]

 [[28617     6]
  [    1    32]]

 [[28595    11]
  [    0    50]]

 [[28464    38]
  [   27   127]]]

===scores report===
metrics	scores
Accuracy	0.8773
MCC	0.8749
log_loss	0.6506
f1 score weighted	0.8724
f1 score macro	0.8070
f1 score micro	0.8773
roc_auc ovr	0.9945
roc_auc ovo	0.9927
precision	0.8791
recall	0.8773

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f851448c730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f851448c5b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f851448c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f851448c910>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.95      0.83       825
         1.0       0.75      0.21      0.33        14
         2.0       0.95      0.65      0.77        31
         3.0       0.33      0.18      0.24        11
         4.0       0.83      0.77      0.80        52
         5.0       0.97      0.73      0.83       176
         6.0       0.85      0.44      0.58       102
         7.0       0.82      0.28      0.42        97
         8.0       0.67      0.14      0.24        14
         9.0       0.57      0.61      0.59        70
        10.0       0.82      0.82      0.82       104
        11.0       0.56      0.28      0.37        18
        12.0       0.50      0.07      0.12        14
        13.0       0.74      0.65      0.69        43
        14.0       1.00      0.38      0.55        34
        15.0       0.94      0.77      0.84        64
        16.0       1.00      0.15      0.27        13
        17.0       1.00      0.47      0.64        19
        18.0       0.97      0.92      0.94        72
        19.0       0.65      0.50      0.57        30
        20.0       0.96      0.96      0.96        94
        21.0       0.80      0.76      0.78        46
        22.0       1.00      0.68      0.81        25
        23.0       0.89      0.95      0.92       345
        24.0       0.87      0.43      0.58        30
        25.0       1.00      0.05      0.10        20
        26.0       0.82      0.74      0.78       167
        27.0       0.94      0.83      0.88        36
        28.0       0.95      0.87      0.91        61
        29.0       1.00      0.86      0.92        63
        30.0       1.00      0.18      0.31        11
        31.0       0.00      0.00      0.00        11
        32.0       0.71      0.30      0.42        40
        33.0       0.92      0.66      0.77        73
        34.0       1.00      1.00      1.00        57
        35.0       0.88      0.93      0.90        15
        36.0       0.58      0.22      0.32        50
        37.0       0.65      0.79      0.71        19
        38.0       1.00      0.62      0.77        29
        39.0       0.99      0.91      0.95       101
        40.0       0.82      0.75      0.78        12
        41.0       0.93      1.00      0.97        14
        42.0       0.75      0.87      0.81        67
        43.0       0.93      0.86      0.89        76
        44.0       0.85      1.00      0.92        11
        45.0       1.00      0.84      0.91        37
        46.0       0.85      0.91      0.88      1613
        47.0       0.89      0.99      0.94       299
        48.0       0.98      0.97      0.98       244
        49.0       0.96      0.93      0.95       168
        50.0       0.90      0.78      0.84      1024
        51.0       0.82      0.71      0.76       353
        52.0       0.93      0.78      0.85        86
        53.0       0.61      0.88      0.72       607
        54.0       0.92      0.90      0.91       543
        55.0       0.93      0.90      0.92        78
        56.0       0.89      0.91      0.90       954
        57.0       0.88      0.90      0.89       247
        58.0       0.87      0.97      0.92        34
        59.0       0.90      0.80      0.85       877
        60.0       0.47      0.52      0.49        77
        61.0       0.60      0.92      0.72       566
        62.0       1.00      0.25      0.40        24
        63.0       0.53      0.65      0.59        55
        64.0       0.95      0.98      0.97       254
        65.0       0.67      0.14      0.24        14
        66.0       0.95      0.95      0.95       456
        67.0       0.86      0.66      0.75        38
        68.0       0.88      0.87      0.88      1189
        69.0       0.76      0.90      0.82       224
        70.0       1.00      0.53      0.69        19
        71.0       0.93      0.97      0.95       358
        72.0       0.84      0.66      0.74        32
        73.0       1.00      0.23      0.38        13
        74.0       0.93      0.96      0.95       127
        75.0       0.85      0.92      0.88        12
        76.0       0.78      0.82      0.80       460
        77.0       0.99      0.83      0.90       103
        78.0       0.91      0.19      0.32        52
        79.0       0.93      0.52      0.67        83
        80.0       0.80      0.46      0.59        80
        81.0       0.92      0.82      0.87        84
        82.0       0.93      0.88      0.90       335
        83.0       0.86      0.26      0.40        23
        84.0       0.55      0.77      0.65       518
        85.0       0.14      0.03      0.06        87
        86.0       1.00      0.69      0.82        13
        87.0       0.51      0.84      0.64       480
        88.0       0.70      0.70      0.70       126
        89.0       0.69      0.96      0.80        25
        90.0       0.86      0.79      0.82       152
        91.0       1.00      0.30      0.46        20
        92.0       0.58      0.25      0.35        28
        93.0       0.89      0.74      0.81        42
        94.0       0.71      0.35      0.47        34
        95.0       0.75      0.49      0.60        99
        96.0       0.81      0.80      0.81       415
        97.0       0.68      0.57      0.62       118
        98.0       0.74      0.78      0.76        99
        99.0       0.91      0.79      0.85       253
       100.0       0.98      0.93      0.96       116
       101.0       0.88      0.74      0.80       423
       102.0       0.83      0.89      0.86        99
       103.0       0.78      0.87      0.82        60
       104.0       0.96      0.76      0.84       266
       105.0       0.89      0.89      0.89        37
       106.0       0.79      0.90      0.84       494
       107.0       1.00      0.57      0.73        14
       108.0       0.93      0.88      0.90       610
       109.0       0.85      0.94      0.89       206
       110.0       0.83      0.45      0.59        22
       111.0       0.94      0.87      0.90       534
       112.0       0.93      0.68      0.79        98
       113.0       0.93      0.63      0.75        86
       114.0       1.00      0.88      0.94       109
       115.0       0.96      0.88      0.92       858
       116.0       0.48      0.48      0.48        61
       117.0       0.91      0.93      0.92       209
       118.0       0.00      0.00      0.00        13
       119.0       0.98      0.65      0.78        65
       120.0       0.89      0.96      0.92       156
       121.0       0.95      0.96      0.96        84
       122.0       1.00      0.47      0.64        55
       123.0       0.74      0.73      0.74       154
       124.0       0.96      0.98      0.97        52
       125.0       0.82      0.90      0.86       147
       126.0       0.82      0.66      0.73        77
       127.0       0.80      0.84      0.82        19
       128.0       0.88      0.86      0.87       198
       129.0       0.95      0.90      0.92       450
       130.0       0.86      0.55      0.67        11
       131.0       0.96      0.56      0.71        43
       132.0       0.87      0.81      0.84        16
       133.0       0.93      0.98      0.96       204
       134.0       1.00      0.93      0.97        76
       135.0       0.87      0.80      0.84       255
       136.0       0.00      0.00      0.00        20
       137.0       0.90      0.69      0.78        13
       138.0       0.84      0.70      0.76        67
       139.0       0.95      0.99      0.97      1464
       140.0       0.93      0.90      0.91       146
       141.0       0.91      0.92      0.91        99
       142.0       0.93      0.93      0.93       455
       143.0       0.94      0.91      0.93        82
       144.0       0.91      0.99      0.95       411
       145.0       0.98      0.95      0.96       406
       146.0       0.83      0.42      0.56        12
       147.0       0.93      0.85      0.89       149
       148.0       0.95      0.95      0.95       703
       149.0       0.99      0.94      0.97       195
       150.0       0.92      0.73      0.81        33
       151.0       0.88      0.66      0.76        68
       152.0       0.79      0.95      0.86        93
       153.0       0.84      0.94      0.89        33
       154.0       0.85      0.92      0.88        49
       155.0       0.84      0.82      0.83       154

    accuracy                           0.85     28656
   macro avg       0.84      0.70      0.74     28656
weighted avg       0.86      0.85      0.85     28656


===confusion_matrix===

[[783   0   0 ...   0   0   0]
 [  1   3   0 ...   0   0   0]
 [  0   0  20 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   1]
 [  0   0   0 ...   0  45   3]
 [  0   0   0 ...   1   7 127]]

===multilabel confusion matrix===

[[[27557   274]
  [   42   783]]

 [[28641     1]
  [   11     3]]

 [[28624     1]
  [   11    20]]

 [[28641     4]
  [    9     2]]

 [[28596     8]
  [   12    40]]

 [[28476     4]
  [   47   129]]

 [[28546     8]
  [   57    45]]

 [[28553     6]
  [   70    27]]

 [[28641     1]
  [   12     2]]

 [[28554    32]
  [   27    43]]

 [[28533    19]
  [   19    85]]

 [[28634     4]
  [   13     5]]

 [[28641     1]
  [   13     1]]

 [[28603    10]
  [   15    28]]

 [[28622     0]
  [   21    13]]

 [[28589     3]
  [   15    49]]

 [[28643     0]
  [   11     2]]

 [[28637     0]
  [   10     9]]

 [[28582     2]
  [    6    66]]

 [[28618     8]
  [   15    15]]

 [[28558     4]
  [    4    90]]

 [[28601     9]
  [   11    35]]

 [[28631     0]
  [    8    17]]

 [[28271    40]
  [   17   328]]

 [[28624     2]
  [   17    13]]

 [[28636     0]
  [   19     1]]

 [[28461    28]
  [   43   124]]

 [[28618     2]
  [    6    30]]

 [[28592     3]
  [    8    53]]

 [[28593     0]
  [    9    54]]

 [[28645     0]
  [    9     2]]

 [[28645     0]
  [   11     0]]

 [[28611     5]
  [   28    12]]

 [[28579     4]
  [   25    48]]

 [[28599     0]
  [    0    57]]

 [[28639     2]
  [    1    14]]

 [[28598     8]
  [   39    11]]

 [[28629     8]
  [    4    15]]

 [[28627     0]
  [   11    18]]

 [[28554     1]
  [    9    92]]

 [[28642     2]
  [    3     9]]

 [[28641     1]
  [    0    14]]

 [[28570    19]
  [    9    58]]

 [[28575     5]
  [   11    65]]

 [[28643     2]
  [    0    11]]

 [[28619     0]
  [    6    31]]

 [[26791   252]
  [  149  1464]]

 [[28320    37]
  [    4   295]]

 [[28407     5]
  [    7   237]]

 [[28481     7]
  [   11   157]]

 [[27542    90]
  [  224   800]]

 [[28248    55]
  [  104   249]]

 [[28565     5]
  [   19    67]]

 [[27711   338]
  [   74   533]]

 [[28071    42]
  [   55   488]]

 [[28573     5]
  [    8    70]]

 [[27593   109]
  [   86   868]]

 [[28379    30]
  [   25   222]]

 [[28617     5]
  [    1    33]]

 [[27701    78]
  [  178   699]]

 [[28533    46]
  [   37    40]]

 [[27738   352]
  [   47   519]]

 [[28632     0]
  [   18     6]]

 [[28569    32]
  [   19    36]]

 [[28389    13]
  [    4   250]]

 [[28641     1]
  [   12     2]]

 [[28178    22]
  [   25   431]]

 [[28614     4]
  [   13    25]]

 [[27330   137]
  [  151  1038]]

 [[28368    64]
  [   22   202]]

 [[28637     0]
  [    9    10]]

 [[28272    26]
  [   11   347]]

 [[28620     4]
  [   11    21]]

 [[28643     0]
  [   10     3]]

 [[28520     9]
  [    5   122]]

 [[28642     2]
  [    1    11]]

 [[28091   105]
  [   84   376]]

 [[28552     1]
  [   18    85]]

 [[28603     1]
  [   42    10]]

 [[28570     3]
  [   40    43]]

 [[28567     9]
  [   43    37]]

 [[28566     6]
  [   15    69]]

 [[28300    21]
  [   41   294]]

 [[28632     1]
  [   17     6]]

 [[27814   324]
  [  117   401]]

 [[28550    19]
  [   84     3]]

 [[28643     0]
  [    4     9]]

 [[27795   381]
  [   78   402]]

 [[28493    37]
  [   38    88]]

 [[28620    11]
  [    1    24]]

 [[28485    19]
  [   32   120]]

 [[28636     0]
  [   14     6]]

 [[28623     5]
  [   21     7]]

 [[28610     4]
  [   11    31]]

 [[28617     5]
  [   22    12]]

 [[28541    16]
  [   50    49]]

 [[28164    77]
  [   82   333]]

 [[28506    32]
  [   51    67]]

 [[28530    27]
  [   22    77]]

 [[28383    20]
  [   52   201]]

 [[28538     2]
  [    8   108]]

 [[28192    41]
  [  111   312]]

 [[28539    18]
  [   11    88]]

 [[28581    15]
  [    8    52]]

 [[28381     9]
  [   65   201]]

 [[28615     4]
  [    4    33]]

 [[28043   119]
  [   50   444]]

 [[28642     0]
  [    6     8]]

 [[28003    43]
  [   73   537]]

 [[28417    33]
  [   13   193]]

 [[28632     2]
  [   12    10]]

 [[28092    30]
  [   71   463]]

 [[28553     5]
  [   31    67]]

 [[28566     4]
  [   32    54]]

 [[28547     0]
  [   13    96]]

 [[27766    32]
  [  107   751]]

 [[28563    32]
  [   32    29]]

 [[28428    19]
  [   14   195]]

 [[28643     0]
  [   13     0]]

 [[28590     1]
  [   23    42]]

 [[28481    19]
  [    6   150]]

 [[28568     4]
  [    3    81]]

 [[28601     0]
  [   29    26]]

 [[28462    40]
  [   41   113]]

 [[28602     2]
  [    1    51]]

 [[28481    28]
  [   15   132]]

 [[28568    11]
  [   26    51]]

 [[28633     4]
  [    3    16]]

 [[28434    24]
  [   28   170]]

 [[28184    22]
  [   44   406]]

 [[28644     1]
  [    5     6]]

 [[28612     1]
  [   19    24]]

 [[28638     2]
  [    3    13]]

 [[28438    14]
  [    4   200]]

 [[28580     0]
  [    5    71]]

 [[28370    31]
  [   50   205]]

 [[28636     0]
  [   20     0]]

 [[28642     1]
  [    4     9]]

 [[28580     9]
  [   20    47]]

 [[27119    73]
  [   15  1449]]

 [[28500    10]
  [   15   131]]

 [[28548     9]
  [    8    91]]

 [[28169    32]
  [   34   421]]

 [[28569     5]
  [    7    75]]

 [[28204    41]
  [    6   405]]

 [[28243     7]
  [   22   384]]

 [[28643     1]
  [    7     5]]

 [[28498     9]
  [   22   127]]

 [[27918    35]
  [   35   668]]

 [[28460     1]
  [   12   183]]

 [[28621     2]
  [    9    24]]

 [[28582     6]
  [   23    45]]

 [[28540    23]
  [    5    88]]

 [[28617     6]
  [    2    31]]

 [[28599     8]
  [    4    45]]

 [[28478    24]
  [   27   127]]]

===scores report===
metrics	scores
Accuracy	0.8486
MCC	0.8456
log_loss	0.6982
f1 score weighted	0.8455
f1 score macro	0.7390
f1 score micro	0.8486
roc_auc ovr	0.9941
roc_auc ovo	0.9914
precision	0.8597
recall	0.8486

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f851448c730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f851448c5b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f851448c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f851448c910>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([56., 56., 56., ..., 98., 51., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.92      0.89       825
         1.0       0.00      0.00      0.00        14
         2.0       0.79      0.84      0.81        31
         3.0       0.00      0.00      0.00        12
         4.0       1.00      0.71      0.83        52
         5.0       0.86      0.77      0.81       176
         6.0       0.59      0.53      0.56       102
         7.0       0.83      0.31      0.45        97
         8.0       1.00      0.14      0.25        14
         9.0       0.46      0.51      0.48        70
        10.0       0.74      0.78      0.76       104
        11.0       0.00      0.00      0.00        18
        12.0       0.50      0.14      0.22        14
        13.0       0.88      0.50      0.64        42
        14.0       0.95      0.53      0.68        34
        15.0       0.94      0.77      0.84        64
        16.0       1.00      0.07      0.13        14
        17.0       0.80      0.21      0.33        19
        18.0       0.91      0.89      0.90        72
        19.0       0.50      0.03      0.06        31
        20.0       1.00      0.94      0.97        94
        21.0       0.81      0.76      0.78        45
        22.0       0.95      0.80      0.87        25
        23.0       0.96      0.95      0.95       346
        24.0       0.74      0.67      0.70        30
        25.0       0.00      0.00      0.00        19
        26.0       0.87      0.60      0.71       167
        27.0       1.00      0.75      0.86        36
        28.0       0.94      0.98      0.96        60
        29.0       0.91      0.66      0.77        62
        30.0       0.50      0.09      0.15        11
        31.0       0.33      0.09      0.14        11
        32.0       1.00      0.25      0.40        40
        33.0       0.93      0.68      0.78        74
        34.0       1.00      1.00      1.00        56
        35.0       0.82      0.88      0.85        16
        36.0       0.61      0.39      0.48        51
        37.0       0.93      0.68      0.79        19
        38.0       0.95      0.72      0.82        29
        39.0       0.86      0.95      0.91       101
        40.0       1.00      0.08      0.15        12
        41.0       1.00      1.00      1.00        13
        42.0       0.83      0.79      0.81        67
        43.0       0.96      0.96      0.96        76
        44.0       1.00      1.00      1.00        12
        45.0       1.00      0.83      0.91        36
        46.0       0.77      0.92      0.84      1613
        47.0       0.99      0.97      0.98       299
        48.0       0.99      0.98      0.99       243
        49.0       0.96      0.97      0.97       169
        50.0       0.80      0.79      0.80      1024
        51.0       0.71      0.70      0.70       352
        52.0       1.00      0.81      0.90        86
        53.0       0.69      0.84      0.76       607
        54.0       0.86      0.92      0.89       543
        55.0       0.99      0.85      0.91        78
        56.0       0.82      0.88      0.85       954
        57.0       0.93      0.88      0.90       247
        58.0       0.97      0.94      0.96        34
        59.0       0.70      0.91      0.79       877
        60.0       0.62      0.19      0.30        77
        61.0       0.70      0.84      0.76       565
        62.0       1.00      0.08      0.15        24
        63.0       0.58      0.45      0.51        55
        64.0       0.99      0.96      0.97       255
        65.0       0.00      0.00      0.00        14
        66.0       0.97      0.92      0.95       457
        67.0       0.94      0.78      0.85        37
        68.0       0.71      0.89      0.79      1189
        69.0       0.83      0.88      0.86       224
        70.0       0.91      0.50      0.65        20
        71.0       0.94      0.95      0.95       358
        72.0       0.87      0.41      0.55        32
        73.0       1.00      0.08      0.14        13
        74.0       0.98      0.91      0.94       128
        75.0       0.87      1.00      0.93        13
        76.0       0.77      0.77      0.77       460
        77.0       0.99      0.84      0.91       104
        78.0       0.60      0.23      0.33        52
        79.0       0.88      0.55      0.68        84
        80.0       0.82      0.35      0.49        80
        81.0       0.99      0.80      0.88        83
        82.0       0.95      0.85      0.90       335
        83.0       0.75      0.25      0.38        24
        84.0       0.67      0.76      0.71       518
        85.0       0.11      0.02      0.04        88
        86.0       1.00      0.31      0.47        13
        87.0       0.67      0.69      0.68       480
        88.0       0.96      0.60      0.74       126
        89.0       1.00      1.00      1.00        25
        90.0       0.79      0.90      0.84       153
        91.0       0.67      0.40      0.50        20
        92.0       1.00      0.19      0.31        27
        93.0       0.94      0.74      0.83        42
        94.0       0.88      0.21      0.33        34
        95.0       0.81      0.34      0.48        99
        96.0       0.82      0.81      0.81       416
        97.0       0.84      0.47      0.61       118
        98.0       0.71      0.80      0.75        99
        99.0       0.95      0.73      0.82       253
       100.0       0.96      0.92      0.94       115
       101.0       0.73      0.81      0.77       423
       102.0       0.90      0.83      0.86        99
       103.0       0.88      0.75      0.81        61
       104.0       0.88      0.76      0.82       266
       105.0       0.97      0.83      0.90        36
       106.0       0.76      0.85      0.80       494
       107.0       0.93      0.93      0.93        14
       108.0       0.92      0.87      0.89       610
       109.0       0.94      0.97      0.95       206
       110.0       1.00      0.59      0.74        22
       111.0       0.86      0.88      0.87       535
       112.0       0.87      0.56      0.68        98
       113.0       0.80      0.47      0.59        86
       114.0       0.92      0.92      0.92       109
       115.0       0.75      0.91      0.83       858
       116.0       0.72      0.38      0.49        61
       117.0       0.76      0.92      0.83       208
       118.0       0.00      0.00      0.00        13
       119.0       0.84      0.71      0.77        65
       120.0       0.98      0.91      0.94       157
       121.0       0.98      0.99      0.98        84
       122.0       0.81      0.47      0.60        55
       123.0       0.81      0.65      0.72       154
       124.0       0.96      0.88      0.92        52
       125.0       0.90      0.90      0.90       147
       126.0       0.81      0.56      0.66        77
       127.0       0.81      0.72      0.76        18
       128.0       0.93      0.78      0.85       197
       129.0       0.88      0.94      0.91       449
       130.0       1.00      0.82      0.90        11
       131.0       0.82      0.53      0.65        43
       132.0       0.91      0.67      0.77        15
       133.0       0.99      0.98      0.98       204
       134.0       1.00      0.95      0.97        76
       135.0       0.93      0.80      0.86       255
       136.0       0.43      0.16      0.23        19
       137.0       1.00      0.54      0.70        13
       138.0       1.00      0.37      0.54        67
       139.0       0.96      0.99      0.97      1463
       140.0       0.93      0.84      0.88       147
       141.0       0.93      0.88      0.90        99
       142.0       0.96      0.89      0.93       455
       143.0       0.99      0.95      0.97        82
       144.0       0.96      0.94      0.95       410
       145.0       0.94      0.97      0.95       406
       146.0       0.75      0.25      0.38        12
       147.0       0.97      0.86      0.91       149
       148.0       0.94      0.97      0.95       702
       149.0       0.99      0.96      0.97       196
       150.0       0.87      0.81      0.84        32
       151.0       0.89      0.86      0.87        69
       152.0       0.99      0.89      0.94        93
       153.0       0.96      0.84      0.90        32
       154.0       0.88      0.86      0.87        49
       155.0       0.85      0.95      0.90       154

    accuracy                           0.84     28655
   macro avg       0.83      0.67      0.71     28655
weighted avg       0.84      0.84      0.83     28655


===confusion_matrix===

[[756   0   0 ...   0   0   0]
 [  3   0   0 ...   0   0   0]
 [  0   0  26 ...   0   0   0]
 ...
 [  0   0   0 ...  27   1   4]
 [  0   0   0 ...   0  42   5]
 [  0   0   0 ...   0   3 146]]

===multilabel confusion matrix===

[[[27710   120]
  [   69   756]]

 [[28641     0]
  [   14     0]]

 [[28617     7]
  [    5    26]]

 [[28643     0]
  [   12     0]]

 [[28603     0]
  [   15    37]]

 [[28456    23]
  [   40   136]]

 [[28515    38]
  [   48    54]]

 [[28552     6]
  [   67    30]]

 [[28641     0]
  [   12     2]]

 [[28542    43]
  [   34    36]]

 [[28523    28]
  [   23    81]]

 [[28637     0]
  [   18     0]]

 [[28639     2]
  [   12     2]]

 [[28610     3]
  [   21    21]]

 [[28620     1]
  [   16    18]]

 [[28588     3]
  [   15    49]]

 [[28641     0]
  [   13     1]]

 [[28635     1]
  [   15     4]]

 [[28577     6]
  [    8    64]]

 [[28623     1]
  [   30     1]]

 [[28561     0]
  [    6    88]]

 [[28602     8]
  [   11    34]]

 [[28629     1]
  [    5    20]]

 [[28294    15]
  [   17   329]]

 [[28618     7]
  [   10    20]]

 [[28635     1]
  [   19     0]]

 [[28473    15]
  [   67   100]]

 [[28619     0]
  [    9    27]]

 [[28591     4]
  [    1    59]]

 [[28589     4]
  [   21    41]]

 [[28643     1]
  [   10     1]]

 [[28642     2]
  [   10     1]]

 [[28615     0]
  [   30    10]]

 [[28577     4]
  [   24    50]]

 [[28599     0]
  [    0    56]]

 [[28636     3]
  [    2    14]]

 [[28591    13]
  [   31    20]]

 [[28635     1]
  [    6    13]]

 [[28625     1]
  [    8    21]]

 [[28539    15]
  [    5    96]]

 [[28643     0]
  [   11     1]]

 [[28642     0]
  [    0    13]]

 [[28577    11]
  [   14    53]]

 [[28576     3]
  [    3    73]]

 [[28643     0]
  [    0    12]]

 [[28619     0]
  [    6    30]]

 [[26609   433]
  [  127  1486]]

 [[28354     2]
  [    8   291]]

 [[28410     2]
  [    5   238]]

 [[28480     6]
  [    5   164]]

 [[27429   202]
  [  212   812]]

 [[28203   100]
  [  106   246]]

 [[28569     0]
  [   16    70]]

 [[27817   231]
  [   98   509]]

 [[28029    83]
  [   44   499]]

 [[28576     1]
  [   12    66]]

 [[27519   182]
  [  111   843]]

 [[28392    16]
  [   30   217]]

 [[28620     1]
  [    2    32]]

 [[27440   338]
  [   80   797]]

 [[28569     9]
  [   62    15]]

 [[27883   207]
  [   92   473]]

 [[28631     0]
  [   22     2]]

 [[28582    18]
  [   30    25]]

 [[28397     3]
  [   11   244]]

 [[28641     0]
  [   14     0]]

 [[28185    13]
  [   36   421]]

 [[28616     2]
  [    8    29]]

 [[27042   424]
  [  136  1053]]

 [[28392    39]
  [   27   197]]

 [[28634     1]
  [   10    10]]

 [[28277    20]
  [   18   340]]

 [[28621     2]
  [   19    13]]

 [[28642     0]
  [   12     1]]

 [[28525     2]
  [   12   116]]

 [[28640     2]
  [    0    13]]

 [[28087   108]
  [  108   352]]

 [[28550     1]
  [   17    87]]

 [[28595     8]
  [   40    12]]

 [[28565     6]
  [   38    46]]

 [[28569     6]
  [   52    28]]

 [[28571     1]
  [   17    66]]

 [[28305    15]
  [   51   284]]

 [[28629     2]
  [   18     6]]

 [[27942   195]
  [  124   394]]

 [[28550    17]
  [   86     2]]

 [[28642     0]
  [    9     4]]

 [[28013   162]
  [  149   331]]

 [[28526     3]
  [   51    75]]

 [[28630     0]
  [    0    25]]

 [[28465    37]
  [   16   137]]

 [[28631     4]
  [   12     8]]

 [[28628     0]
  [   22     5]]

 [[28611     2]
  [   11    31]]

 [[28620     1]
  [   27     7]]

 [[28548     8]
  [   65    34]]

 [[28163    76]
  [   80   336]]

 [[28526    11]
  [   62    56]]

 [[28523    33]
  [   20    79]]

 [[28392    10]
  [   69   184]]

 [[28536     4]
  [    9   106]]

 [[28106   126]
  [   80   343]]

 [[28547     9]
  [   17    82]]

 [[28588     6]
  [   15    46]]

 [[28361    28]
  [   63   203]]

 [[28618     1]
  [    6    30]]

 [[28030   131]
  [   74   420]]

 [[28640     1]
  [    1    13]]

 [[28000    45]
  [   82   528]]

 [[28436    13]
  [    6   200]]

 [[28633     0]
  [    9    13]]

 [[28044    76]
  [   65   470]]

 [[28549     8]
  [   43    55]]

 [[28559    10]
  [   46    40]]

 [[28537     9]
  [    9   100]]

 [[27541   256]
  [   73   785]]

 [[28585     9]
  [   38    23]]

 [[28386    61]
  [   17   191]]

 [[28642     0]
  [   13     0]]

 [[28581     9]
  [   19    46]]

 [[28495     3]
  [   14   143]]

 [[28569     2]
  [    1    83]]

 [[28594     6]
  [   29    26]]

 [[28478    23]
  [   54   100]]

 [[28601     2]
  [    6    46]]

 [[28494    14]
  [   14   133]]

 [[28568    10]
  [   34    43]]

 [[28634     3]
  [    5    13]]

 [[28446    12]
  [   43   154]]

 [[28151    55]
  [   29   420]]

 [[28644     0]
  [    2     9]]

 [[28607     5]
  [   20    23]]

 [[28639     1]
  [    5    10]]

 [[28449     2]
  [    5   199]]

 [[28579     0]
  [    4    72]]

 [[28385    15]
  [   52   203]]

 [[28632     4]
  [   16     3]]

 [[28642     0]
  [    6     7]]

 [[28588     0]
  [   42    25]]

 [[27126    66]
  [   15  1448]]

 [[28499     9]
  [   24   123]]

 [[28549     7]
  [   12    87]]

 [[28183    17]
  [   48   407]]

 [[28572     1]
  [    4    78]]

 [[28231    14]
  [   25   385]]

 [[28222    27]
  [   13   393]]

 [[28642     1]
  [    9     3]]

 [[28502     4]
  [   21   128]]

 [[27906    47]
  [   22   680]]

 [[28457     2]
  [    8   188]]

 [[28619     4]
  [    6    26]]

 [[28579     7]
  [   10    59]]

 [[28561     1]
  [   10    83]]

 [[28622     1]
  [    5    27]]

 [[28600     6]
  [    7    42]]

 [[28475    26]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8382
MCC	0.8348
log_loss	0.7355
f1 score weighted	0.8307
f1 score macro	0.7147
f1 score micro	0.8382
roc_auc ovr	0.9933
roc_auc ovo	0.9900
precision	0.8412
recall	0.8382

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f851448c730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f851448c5b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f851448c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f851448c910>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  51.,  96., 109.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.88      0.91       825
         1.0       1.00      0.14      0.25        14
         2.0       0.96      0.78      0.86        32
         3.0       0.00      0.00      0.00        12
         4.0       0.95      0.69      0.80        52
         5.0       0.54      0.85      0.66       176
         6.0       0.63      0.61      0.62       102
         7.0       0.46      0.32      0.38        97
         8.0       1.00      0.07      0.13        14
         9.0       0.49      0.61      0.55        69
        10.0       0.81      0.72      0.76       104
        11.0       0.40      0.11      0.17        18
        12.0       0.78      0.47      0.58        15
        13.0       0.76      0.81      0.78        42
        14.0       0.80      0.59      0.68        34
        15.0       0.66      0.89      0.76        64
        16.0       0.50      0.08      0.13        13
        17.0       0.64      0.47      0.55        19
        18.0       0.89      0.93      0.91        71
        19.0       0.71      0.39      0.50        31
        20.0       0.94      0.99      0.96        94
        21.0       0.90      0.83      0.86        46
        22.0       0.87      0.80      0.83        25
        23.0       0.96      0.95      0.95       346
        24.0       0.84      0.68      0.75        31
        25.0       0.00      0.00      0.00        20
        26.0       0.66      0.68      0.67       167
        27.0       0.67      0.61      0.64        36
        28.0       0.98      0.88      0.93        60
        29.0       0.78      0.82      0.80        62
        30.0       1.00      0.64      0.78        11
        31.0       0.00      0.00      0.00        12
        32.0       0.74      0.35      0.47        40
        33.0       0.66      0.84      0.74        74
        34.0       0.98      1.00      0.99        56
        35.0       0.93      0.81      0.87        16
        36.0       0.33      0.04      0.07        51
        37.0       0.67      0.84      0.74        19
        38.0       1.00      0.66      0.79        29
        39.0       0.92      0.92      0.92       101
        40.0       0.50      0.42      0.45        12
        41.0       1.00      1.00      1.00        13
        42.0       0.97      0.88      0.92        67
        43.0       0.82      0.96      0.88        76
        44.0       0.92      1.00      0.96        11
        45.0       1.00      0.76      0.86        37
        46.0       0.80      0.93      0.86      1613
        47.0       0.95      0.98      0.96       299
        48.0       0.95      0.96      0.95       243
        49.0       0.98      0.96      0.97       169
        50.0       0.90      0.78      0.84      1023
        51.0       0.75      0.77      0.76       352
        52.0       0.84      0.81      0.83        86
        53.0       0.91      0.67      0.78       606
        54.0       0.97      0.89      0.93       543
        55.0       0.98      0.75      0.85        79
        56.0       0.91      0.91      0.91       954
        57.0       0.86      0.92      0.89       247
        58.0       0.97      1.00      0.99        34
        59.0       0.92      0.82      0.86       877
        60.0       0.42      0.47      0.44        77
        61.0       0.79      0.83      0.81       566
        62.0       0.00      0.00      0.00        24
        63.0       0.88      0.40      0.55        55
        64.0       0.99      0.95      0.97       255
        65.0       0.50      0.23      0.32        13
        66.0       0.86      0.97      0.92       457
        67.0       0.96      0.73      0.83        37
        68.0       0.84      0.85      0.84      1189
        69.0       0.87      0.85      0.86       223
        70.0       0.80      0.42      0.55        19
        71.0       0.94      0.96      0.95       357
        72.0       1.00      0.38      0.55        32
        73.0       1.00      0.08      0.14        13
        74.0       0.98      0.95      0.96       128
        75.0       0.78      0.54      0.64        13
        76.0       0.68      0.77      0.73       460
        77.0       0.96      0.77      0.86       104
        78.0       0.31      0.53      0.39        53
        79.0       0.61      0.65      0.63        83
        80.0       0.41      0.63      0.50        79
        81.0       0.91      0.83      0.87        84
        82.0       0.74      0.89      0.81       334
        83.0       0.41      0.62      0.49        24
        84.0       0.78      0.69      0.74       518
        85.0       0.17      0.08      0.11        88
        86.0       1.00      0.77      0.87        13
        87.0       0.58      0.74      0.65       480
        88.0       0.61      0.75      0.67       127
        89.0       1.00      0.96      0.98        24
        90.0       0.82      0.75      0.78       153
        91.0       0.50      0.40      0.44        20
        92.0       0.57      0.30      0.39        27
        93.0       0.97      0.81      0.88        42
        94.0       0.77      0.29      0.43        34
        95.0       0.52      0.47      0.49        99
        96.0       0.89      0.81      0.85       416
        97.0       0.67      0.61      0.64       118
        98.0       0.89      0.74      0.81        99
        99.0       0.60      0.82      0.70       253
       100.0       0.96      0.96      0.96       115
       101.0       0.59      0.83      0.69       423
       102.0       0.94      0.80      0.86        98
       103.0       0.90      0.75      0.82        60
       104.0       0.83      0.85      0.84       265
       105.0       0.91      0.89      0.90        36
       106.0       0.74      0.88      0.80       495
       107.0       1.00      0.57      0.73        14
       108.0       0.94      0.86      0.90       610
       109.0       0.98      0.96      0.97       206
       110.0       1.00      0.32      0.48        22
       111.0       0.91      0.84      0.87       535
       112.0       0.83      0.65      0.73        98
       113.0       0.55      0.60      0.58        86
       114.0       0.96      0.89      0.92       110
       115.0       0.87      0.88      0.87       858
       116.0       0.51      0.46      0.48        61
       117.0       0.92      0.89      0.90       208
       118.0       0.00      0.00      0.00        13
       119.0       0.77      0.65      0.70        66
       120.0       0.91      0.92      0.91       157
       121.0       0.97      1.00      0.98        84
       122.0       0.62      0.65      0.64        55
       123.0       0.93      0.61      0.74       153
       124.0       0.83      0.94      0.88        52
       125.0       0.99      0.92      0.95       147
       126.0       0.87      0.63      0.73        76
       127.0       0.95      1.00      0.97        18
       128.0       0.70      0.86      0.77       197
       129.0       0.94      0.95      0.94       450
       130.0       0.73      0.67      0.70        12
       131.0       0.97      0.74      0.84        42
       132.0       0.82      0.93      0.87        15
       133.0       0.98      0.95      0.97       204
       134.0       0.94      0.96      0.95        76
       135.0       0.59      0.89      0.71       256
       136.0       0.88      0.37      0.52        19
       137.0       0.77      0.77      0.77        13
       138.0       0.51      0.64      0.57        67
       139.0       0.95      0.98      0.97      1464
       140.0       0.96      0.83      0.89       147
       141.0       0.96      0.91      0.93        98
       142.0       0.95      0.92      0.93       455
       143.0       1.00      0.90      0.95        82
       144.0       0.97      0.96      0.96       410
       145.0       0.92      0.97      0.95       406
       146.0       0.83      0.42      0.56        12
       147.0       0.97      0.82      0.89       149
       148.0       0.96      0.95      0.96       702
       149.0       0.99      0.96      0.97       196
       150.0       1.00      0.75      0.86        32
       151.0       0.87      0.80      0.83        69
       152.0       1.00      0.83      0.91        93
       153.0       1.00      0.79      0.88        33
       154.0       0.92      0.72      0.81        50
       155.0       0.74      0.91      0.82       154

    accuracy                           0.84     28655
   macro avg       0.79      0.71      0.73     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[729   0   0 ...   0   0   1]
 [  0   2   1 ...   0   0   0]
 [  0   0  25 ...   0   0   0]
 ...
 [  0   0   0 ...  26   1   3]
 [  0   0   0 ...   0  36  11]
 [  0   0   0 ...   0   2 140]]

===multilabel confusion matrix===

[[[27777    53]
  [   96   729]]

 [[28641     0]
  [   12     2]]

 [[28622     1]
  [    7    25]]

 [[28641     2]
  [   12     0]]

 [[28601     2]
  [   16    36]]

 [[28350   129]
  [   27   149]]

 [[28517    36]
  [   40    62]]

 [[28522    36]
  [   66    31]]

 [[28641     0]
  [   13     1]]

 [[28543    43]
  [   27    42]]

 [[28533    18]
  [   29    75]]

 [[28634     3]
  [   16     2]]

 [[28638     2]
  [    8     7]]

 [[28602    11]
  [    8    34]]

 [[28616     5]
  [   14    20]]

 [[28562    29]
  [    7    57]]

 [[28641     1]
  [   12     1]]

 [[28631     5]
  [   10     9]]

 [[28576     8]
  [    5    66]]

 [[28619     5]
  [   19    12]]

 [[28555     6]
  [    1    93]]

 [[28605     4]
  [    8    38]]

 [[28627     3]
  [    5    20]]

 [[28295    14]
  [   18   328]]

 [[28620     4]
  [   10    21]]

 [[28635     0]
  [   20     0]]

 [[28429    59]
  [   54   113]]

 [[28608    11]
  [   14    22]]

 [[28594     1]
  [    7    53]]

 [[28579    14]
  [   11    51]]

 [[28644     0]
  [    4     7]]

 [[28643     0]
  [   12     0]]

 [[28610     5]
  [   26    14]]

 [[28549    32]
  [   12    62]]

 [[28598     1]
  [    0    56]]

 [[28638     1]
  [    3    13]]

 [[28600     4]
  [   49     2]]

 [[28628     8]
  [    3    16]]

 [[28626     0]
  [   10    19]]

 [[28546     8]
  [    8    93]]

 [[28638     5]
  [    7     5]]

 [[28642     0]
  [    0    13]]

 [[28586     2]
  [    8    59]]

 [[28563    16]
  [    3    73]]

 [[28643     1]
  [    0    11]]

 [[28618     0]
  [    9    28]]

 [[26670   372]
  [  116  1497]]

 [[28341    15]
  [    7   292]]

 [[28400    12]
  [   10   233]]

 [[28482     4]
  [    6   163]]

 [[27540    92]
  [  221   802]]

 [[28212    91]
  [   82   270]]

 [[28556    13]
  [   16    70]]

 [[28011    38]
  [  198   408]]

 [[28099    13]
  [   59   484]]

 [[28575     1]
  [   20    59]]

 [[27615    86]
  [   89   865]]

 [[28370    38]
  [   20   227]]

 [[28620     1]
  [    0    34]]

 [[27714    64]
  [  160   717]]

 [[28528    50]
  [   41    36]]

 [[27967   122]
  [   97   469]]

 [[28630     1]
  [   24     0]]

 [[28597     3]
  [   33    22]]

 [[28397     3]
  [   14   241]]

 [[28639     3]
  [   10     3]]

 [[28128    70]
  [   12   445]]

 [[28617     1]
  [   10    27]]

 [[27267   199]
  [  175  1014]]

 [[28404    28]
  [   34   189]]

 [[28634     2]
  [   11     8]]

 [[28275    23]
  [   14   343]]

 [[28623     0]
  [   20    12]]

 [[28642     0]
  [   12     1]]

 [[28524     3]
  [    7   121]]

 [[28640     2]
  [    6     7]]

 [[28030   165]
  [  104   356]]

 [[28548     3]
  [   24    80]]

 [[28541    61]
  [   25    28]]

 [[28537    35]
  [   29    54]]

 [[28505    71]
  [   29    50]]

 [[28564     7]
  [   14    70]]

 [[28219   102]
  [   37   297]]

 [[28609    22]
  [    9    15]]

 [[28038    99]
  [  158   360]]

 [[28534    33]
  [   81     7]]

 [[28642     0]
  [    3    10]]

 [[27917   258]
  [  127   353]]

 [[28468    60]
  [   32    95]]

 [[28631     0]
  [    1    23]]

 [[28476    26]
  [   38   115]]

 [[28627     8]
  [   12     8]]

 [[28622     6]
  [   19     8]]

 [[28612     1]
  [    8    34]]

 [[28618     3]
  [   24    10]]

 [[28512    44]
  [   52    47]]

 [[28199    40]
  [   81   335]]

 [[28502    35]
  [   46    72]]

 [[28547     9]
  [   26    73]]

 [[28266   136]
  [   45   208]]

 [[28536     4]
  [    5   110]]

 [[27990   242]
  [   72   351]]

 [[28552     5]
  [   20    78]]

 [[28590     5]
  [   15    45]]

 [[28345    45]
  [   40   225]]

 [[28616     3]
  [    4    32]]

 [[28009   151]
  [   60   435]]

 [[28641     0]
  [    6     8]]

 [[28010    35]
  [   87   523]]

 [[28444     5]
  [    9   197]]

 [[28633     0]
  [   15     7]]

 [[28075    45]
  [   86   449]]

 [[28544    13]
  [   34    64]]

 [[28527    42]
  [   34    52]]

 [[28541     4]
  [   12    98]]

 [[27686   111]
  [  107   751]]

 [[28567    27]
  [   33    28]]

 [[28431    16]
  [   23   185]]

 [[28642     0]
  [   13     0]]

 [[28576    13]
  [   23    43]]

 [[28484    14]
  [   13   144]]

 [[28568     3]
  [    0    84]]

 [[28578    22]
  [   19    36]]

 [[28495     7]
  [   60    93]]

 [[28593    10]
  [    3    49]]

 [[28507     1]
  [   12   135]]

 [[28572     7]
  [   28    48]]

 [[28636     1]
  [    0    18]]

 [[28385    73]
  [   28   169]]

 [[28176    29]
  [   24   426]]

 [[28640     3]
  [    4     8]]

 [[28612     1]
  [   11    31]]

 [[28637     3]
  [    1    14]]

 [[28447     4]
  [   10   194]]

 [[28574     5]
  [    3    73]]

 [[28242   157]
  [   27   229]]

 [[28635     1]
  [   12     7]]

 [[28639     3]
  [    3    10]]

 [[28546    42]
  [   24    43]]

 [[27118    73]
  [   27  1437]]

 [[28503     5]
  [   25   122]]

 [[28553     4]
  [    9    89]]

 [[28178    22]
  [   38   417]]

 [[28573     0]
  [    8    74]]

 [[28232    13]
  [   17   393]]

 [[28216    33]
  [   12   394]]

 [[28642     1]
  [    7     5]]

 [[28502     4]
  [   27   122]]

 [[27926    27]
  [   32   670]]

 [[28457     2]
  [    8   188]]

 [[28623     0]
  [    8    24]]

 [[28578     8]
  [   14    55]]

 [[28562     0]
  [   16    77]]

 [[28622     0]
  [    7    26]]

 [[28602     3]
  [   14    36]]

 [[28453    48]
  [   14   140]]]

===scores report===
metrics	scores
Accuracy	0.8410
MCC	0.8378
log_loss	0.7228
f1 score weighted	0.8390
f1 score macro	0.7290
f1 score micro	0.8410
roc_auc ovr	0.9935
roc_auc ovo	0.9910
precision	0.8485
recall	0.8410

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f851448c730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f851448c5b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f851448c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f851448c910>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  96.,  46., 108.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.93      0.89       824
         1.0       1.00      0.14      0.25        14
         2.0       0.92      0.69      0.79        32
         3.0       1.00      0.08      0.15        12
         4.0       0.98      0.81      0.88        52
         5.0       0.64      0.82      0.72       175
         6.0       0.80      0.39      0.52       101
         7.0       0.57      0.42      0.48        98
         8.0       0.44      0.29      0.35        14
         9.0       0.32      0.40      0.35        70
        10.0       0.80      0.64      0.71       104
        11.0       0.43      0.17      0.24        18
        12.0       0.89      0.53      0.67        15
        13.0       0.38      0.83      0.52        42
        14.0       0.65      0.38      0.48        34
        15.0       0.94      0.77      0.85        65
        16.0       1.00      0.08      0.14        13
        17.0       1.00      0.26      0.42        19
        18.0       0.98      0.86      0.92        72
        19.0       0.64      0.30      0.41        30
        20.0       0.99      0.97      0.98        94
        21.0       0.97      0.76      0.85        46
        22.0       1.00      0.64      0.78        25
        23.0       0.97      0.96      0.97       345
        24.0       0.71      0.57      0.63        30
        25.0       0.00      0.00      0.00        20
        26.0       0.82      0.70      0.75       168
        27.0       0.83      0.57      0.68        35
        28.0       0.95      0.92      0.93        61
        29.0       0.95      0.63      0.76        63
        30.0       1.00      0.36      0.53        11
        31.0       0.50      0.08      0.14        12
        32.0       1.00      0.15      0.26        40
        33.0       1.00      0.66      0.80        74
        34.0       1.00      0.98      0.99        57
        35.0       1.00      0.75      0.86        16
        36.0       0.64      0.18      0.28        50
        37.0       0.93      0.65      0.76        20
        38.0       0.96      0.76      0.85        29
        39.0       0.98      0.92      0.95       101
        40.0       1.00      0.17      0.29        12
        41.0       0.92      0.86      0.89        14
        42.0       0.89      0.82      0.85        67
        43.0       0.97      0.86      0.91        76
        44.0       1.00      0.82      0.90        11
        45.0       1.00      0.86      0.93        37
        46.0       0.86      0.92      0.89      1613
        47.0       0.99      0.97      0.98       299
        48.0       0.97      0.98      0.97       243
        49.0       0.96      0.96      0.96       168
        50.0       0.56      0.92      0.69      1024
        51.0       0.68      0.77      0.72       353
        52.0       0.81      0.87      0.84        85
        53.0       0.58      0.86      0.69       606
        54.0       0.95      0.90      0.92       543
        55.0       1.00      0.65      0.78        79
        56.0       0.90      0.91      0.91       954
        57.0       0.82      0.91      0.87       247
        58.0       1.00      0.97      0.99        34
        59.0       0.80      0.88      0.84       876
        60.0       0.86      0.32      0.46        76
        61.0       0.80      0.81      0.80       566
        62.0       0.67      0.08      0.15        24
        63.0       0.58      0.47      0.52        55
        64.0       0.95      0.97      0.96       255
        65.0       1.00      0.15      0.27        13
        66.0       0.97      0.97      0.97       457
        67.0       1.00      0.65      0.79        37
        68.0       0.78      0.90      0.83      1189
        69.0       0.85      0.83      0.84       223
        70.0       0.80      0.42      0.55        19
        71.0       0.98      0.91      0.94       357
        72.0       0.87      0.42      0.57        31
        73.0       0.00      0.00      0.00        13
        74.0       1.00      0.98      0.99       128
        75.0       1.00      0.77      0.87        13
        76.0       0.85      0.76      0.80       461
        77.0       0.97      0.82      0.89       104
        78.0       0.56      0.26      0.36        53
        79.0       0.79      0.46      0.58        83
        80.0       0.79      0.62      0.70        79
        81.0       0.99      0.79      0.87        84
        82.0       0.91      0.83      0.87       334
        83.0       1.00      0.21      0.34        24
        84.0       0.57      0.79      0.66       518
        85.0       0.03      0.01      0.02        88
        86.0       0.82      0.75      0.78        12
        87.0       0.72      0.58      0.64       481
        88.0       0.83      0.62      0.71       126
        89.0       1.00      1.00      1.00        24
        90.0       0.92      0.77      0.84       152
        91.0       1.00      0.30      0.46        20
        92.0       0.50      0.04      0.07        27
        93.0       0.91      0.76      0.83        42
        94.0       0.64      0.21      0.32        33
        95.0       0.59      0.54      0.56       100
        96.0       0.89      0.77      0.82       415
        97.0       0.69      0.50      0.58       118
        98.0       0.87      0.81      0.84       100
        99.0       0.71      0.70      0.70       253
       100.0       0.94      0.95      0.94       116
       101.0       0.74      0.80      0.77       423
       102.0       0.97      0.78      0.87        99
       103.0       0.89      0.80      0.84        60
       104.0       0.97      0.77      0.85       265
       105.0       0.89      0.92      0.90        36
       106.0       0.85      0.90      0.87       495
       107.0       0.92      0.80      0.86        15
       108.0       0.90      0.89      0.89       611
       109.0       0.92      0.97      0.94       207
       110.0       0.82      0.41      0.55        22
       111.0       0.93      0.83      0.88       535
       112.0       0.83      0.63      0.72        98
       113.0       0.88      0.61      0.72        87
       114.0       0.98      0.94      0.96       110
       115.0       0.86      0.90      0.88       858
       116.0       1.00      0.20      0.33        60
       117.0       0.87      0.90      0.89       209
       118.0       0.00      0.00      0.00        12
       119.0       0.77      0.77      0.77        66
       120.0       0.98      0.85      0.91       157
       121.0       0.95      0.95      0.95        84
       122.0       0.93      0.47      0.63        55
       123.0       0.83      0.73      0.78       153
       124.0       0.98      0.82      0.89        51
       125.0       0.99      0.89      0.94       146
       126.0       0.89      0.55      0.68        77
       127.0       1.00      0.83      0.91        18
       128.0       0.92      0.83      0.87       197
       129.0       0.90      0.95      0.92       450
       130.0       1.00      0.64      0.78        11
       131.0       0.85      0.69      0.76        42
       132.0       0.91      0.67      0.77        15
       133.0       0.98      0.95      0.96       204
       134.0       1.00      0.97      0.99        76
       135.0       0.91      0.84      0.88       256
       136.0       1.00      0.10      0.18        20
       137.0       1.00      0.62      0.76        13
       138.0       0.86      0.66      0.75        67
       139.0       0.99      0.97      0.98      1464
       140.0       0.93      0.82      0.87       147
       141.0       0.87      0.83      0.85        98
       142.0       0.98      0.92      0.95       455
       143.0       0.83      0.94      0.88        82
       144.0       0.96      0.95      0.96       410
       145.0       0.97      0.96      0.97       406
       146.0       0.67      0.17      0.27        12
       147.0       0.96      0.88      0.92       148
       148.0       0.99      0.97      0.98       702
       149.0       0.99      0.97      0.98       196
       150.0       1.00      0.59      0.75        32
       151.0       0.92      0.70      0.79        69
       152.0       0.99      0.88      0.93        93
       153.0       1.00      0.88      0.94        33
       154.0       1.00      0.70      0.82        50
       155.0       0.78      0.93      0.85       153

    accuracy                           0.84     28655
   macro avg       0.85      0.67      0.72     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[765   0   0 ...   0   0   0]
 [  0   2   0 ...   0   0   0]
 [  0   0  22 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   2]
 [  0   0   0 ...   0  35  14]
 [  0   0   0 ...   0   0 143]]

===multilabel confusion matrix===

[[[27706   125]
  [   59   765]]

 [[28641     0]
  [   12     2]]

 [[28621     2]
  [   10    22]]

 [[28643     0]
  [   11     1]]

 [[28602     1]
  [   10    42]]

 [[28399    81]
  [   32   143]]

 [[28544    10]
  [   62    39]]

 [[28526    31]
  [   57    41]]

 [[28636     5]
  [   10     4]]

 [[28525    60]
  [   42    28]]

 [[28534    17]
  [   37    67]]

 [[28633     4]
  [   15     3]]

 [[28639     1]
  [    7     8]]

 [[28555    58]
  [    7    35]]

 [[28614     7]
  [   21    13]]

 [[28587     3]
  [   15    50]]

 [[28642     0]
  [   12     1]]

 [[28636     0]
  [   14     5]]

 [[28582     1]
  [   10    62]]

 [[28620     5]
  [   21     9]]

 [[28560     1]
  [    3    91]]

 [[28608     1]
  [   11    35]]

 [[28630     0]
  [    9    16]]

 [[28301     9]
  [   14   331]]

 [[28618     7]
  [   13    17]]

 [[28635     0]
  [   20     0]]

 [[28461    26]
  [   51   117]]

 [[28616     4]
  [   15    20]]

 [[28591     3]
  [    5    56]]

 [[28590     2]
  [   23    40]]

 [[28644     0]
  [    7     4]]

 [[28642     1]
  [   11     1]]

 [[28615     0]
  [   34     6]]

 [[28581     0]
  [   25    49]]

 [[28598     0]
  [    1    56]]

 [[28639     0]
  [    4    12]]

 [[28600     5]
  [   41     9]]

 [[28634     1]
  [    7    13]]

 [[28625     1]
  [    7    22]]

 [[28552     2]
  [    8    93]]

 [[28643     0]
  [   10     2]]

 [[28640     1]
  [    2    12]]

 [[28581     7]
  [   12    55]]

 [[28577     2]
  [   11    65]]

 [[28644     0]
  [    2     9]]

 [[28618     0]
  [    5    32]]

 [[26791   251]
  [  122  1491]]

 [[28352     4]
  [    8   291]]

 [[28404     8]
  [    5   238]]

 [[28481     6]
  [    7   161]]

 [[26887   744]
  [   84   940]]

 [[28172   130]
  [   82   271]]

 [[28553    17]
  [   11    74]]

 [[27671   378]
  [   83   523]]

 [[28087    25]
  [   55   488]]

 [[28576     0]
  [   28    51]]

 [[27604    97]
  [   84   870]]

 [[28360    48]
  [   22   225]]

 [[28621     0]
  [    1    33]]

 [[27590   189]
  [  102   774]]

 [[28575     4]
  [   52    24]]

 [[27975   114]
  [  110   456]]

 [[28630     1]
  [   22     2]]

 [[28581    19]
  [   29    26]]

 [[28388    12]
  [    7   248]]

 [[28642     0]
  [   11     2]]

 [[28183    15]
  [   12   445]]

 [[28618     0]
  [   13    24]]

 [[27160   306]
  [  123  1066]]

 [[28399    33]
  [   38   185]]

 [[28634     2]
  [   11     8]]

 [[28293     5]
  [   33   324]]

 [[28622     2]
  [   18    13]]

 [[28642     0]
  [   13     0]]

 [[28527     0]
  [    3   125]]

 [[28642     0]
  [    3    10]]

 [[28133    61]
  [  112   349]]

 [[28548     3]
  [   19    85]]

 [[28591    11]
  [   39    14]]

 [[28562    10]
  [   45    38]]

 [[28563    13]
  [   30    49]]

 [[28570     1]
  [   18    66]]

 [[28294    27]
  [   56   278]]

 [[28631     0]
  [   19     5]]

 [[27832   305]
  [  109   409]]

 [[28534    33]
  [   87     1]]

 [[28641     2]
  [    3     9]]

 [[28068   106]
  [  202   279]]

 [[28513    16]
  [   48    78]]

 [[28631     0]
  [    0    24]]

 [[28493    10]
  [   35   117]]

 [[28635     0]
  [   14     6]]

 [[28627     1]
  [   26     1]]

 [[28610     3]
  [   10    32]]

 [[28618     4]
  [   26     7]]

 [[28517    38]
  [   46    54]]

 [[28201    39]
  [   97   318]]

 [[28511    26]
  [   59    59]]

 [[28543    12]
  [   19    81]]

 [[28328    74]
  [   75   178]]

 [[28532     7]
  [    6   110]]

 [[28113   119]
  [   86   337]]

 [[28554     2]
  [   22    77]]

 [[28589     6]
  [   12    48]]

 [[28383     7]
  [   62   203]]

 [[28615     4]
  [    3    33]]

 [[28081    79]
  [   51   444]]

 [[28639     1]
  [    3    12]]

 [[27982    62]
  [   70   541]]

 [[28431    17]
  [    7   200]]

 [[28631     2]
  [   13     9]]

 [[28089    31]
  [   93   442]]

 [[28544    13]
  [   36    62]]

 [[28561     7]
  [   34    53]]

 [[28543     2]
  [    7   103]]

 [[27669   128]
  [   85   773]]

 [[28595     0]
  [   48    12]]

 [[28417    29]
  [   20   189]]

 [[28642     1]
  [   12     0]]

 [[28574    15]
  [   15    51]]

 [[28495     3]
  [   23   134]]

 [[28567     4]
  [    4    80]]

 [[28598     2]
  [   29    26]]

 [[28480    22]
  [   42   111]]

 [[28603     1]
  [    9    42]]

 [[28508     1]
  [   16   130]]

 [[28573     5]
  [   35    42]]

 [[28637     0]
  [    3    15]]

 [[28444    14]
  [   33   164]]

 [[28158    47]
  [   23   427]]

 [[28644     0]
  [    4     7]]

 [[28608     5]
  [   13    29]]

 [[28639     1]
  [    5    10]]

 [[28448     3]
  [   11   193]]

 [[28579     0]
  [    2    74]]

 [[28378    21]
  [   40   216]]

 [[28635     0]
  [   18     2]]

 [[28642     0]
  [    5     8]]

 [[28581     7]
  [   23    44]]

 [[27173    18]
  [   37  1427]]

 [[28499     9]
  [   27   120]]

 [[28545    12]
  [   17    81]]

 [[28190    10]
  [   38   417]]

 [[28557    16]
  [    5    77]]

 [[28228    17]
  [   19   391]]

 [[28239    10]
  [   17   389]]

 [[28642     1]
  [   10     2]]

 [[28501     6]
  [   18   130]]

 [[27943    10]
  [   21   681]]

 [[28458     1]
  [    6   190]]

 [[28623     0]
  [   13    19]]

 [[28582     4]
  [   21    48]]

 [[28561     1]
  [   11    82]]

 [[28622     0]
  [    4    29]]

 [[28605     0]
  [   15    35]]

 [[28461    41]
  [   10   143]]]

===scores report===
metrics	scores
Accuracy	0.8425
MCC	0.8394
log_loss	0.7055
f1 score weighted	0.8387
f1 score macro	0.7211
f1 score micro	0.8425
roc_auc ovr	0.9941
roc_auc ovo	0.9907
precision	0.8548
recall	0.8425

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f851448c730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f851448c5b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f851448c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f851448c910>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56., 115., ...,  96., 109.,  88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.91      0.87       824
         1.0       0.00      0.00      0.00        14
         2.0       0.77      0.84      0.81        32
         3.0       1.00      0.09      0.17        11
         4.0       0.97      0.69      0.80        51
         5.0       0.87      0.81      0.84       176
         6.0       0.45      0.62      0.52       102
         7.0       0.34      0.54      0.42        97
         8.0       1.00      0.43      0.60        14
         9.0       0.64      0.50      0.56        70
        10.0       0.71      0.91      0.80       103
        11.0       0.67      0.22      0.33        18
        12.0       1.00      0.07      0.12        15
        13.0       0.78      0.74      0.76        43
        14.0       0.74      0.59      0.66        34
        15.0       0.78      0.83      0.81        65
        16.0       0.20      0.08      0.11        13
        17.0       0.75      0.47      0.58        19
        18.0       0.98      0.89      0.93        72
        19.0       1.00      0.07      0.12        30
        20.0       0.99      0.99      0.99        94
        21.0       0.92      0.72      0.80        46
        22.0       0.92      0.44      0.59        25
        23.0       0.96      0.93      0.95       345
        24.0       0.90      0.30      0.45        30
        25.0       0.50      0.10      0.17        20
        26.0       0.65      0.70      0.67       168
        27.0       0.68      0.71      0.69        35
        28.0       0.96      0.87      0.91        61
        29.0       0.83      0.68      0.75        63
        30.0       0.00      0.00      0.00        11
        31.0       0.75      0.25      0.38        12
        32.0       0.81      0.42      0.56        40
        33.0       0.88      0.69      0.77        74
        34.0       1.00      1.00      1.00        57
        35.0       1.00      1.00      1.00        15
        36.0       0.38      0.28      0.32        50
        37.0       0.84      0.84      0.84        19
        38.0       0.60      0.62      0.61        29
        39.0       0.57      0.95      0.72       101
        40.0       0.62      0.62      0.62        13
        41.0       1.00      0.86      0.92        14
        42.0       0.92      0.68      0.78        66
        43.0       0.82      0.91      0.86        76
        44.0       1.00      0.91      0.95        11
        45.0       0.94      0.86      0.90        37
        46.0       0.83      0.92      0.87      1612
        47.0       0.95      0.99      0.97       299
        48.0       1.00      0.97      0.98       243
        49.0       0.99      0.90      0.94       168
        50.0       0.87      0.82      0.84      1024
        51.0       0.83      0.68      0.75       353
        52.0       0.97      0.85      0.91        85
        53.0       0.75      0.82      0.79       606
        54.0       0.96      0.88      0.92       543
        55.0       0.67      0.79      0.73        78
        56.0       0.85      0.89      0.87       954
        57.0       0.86      0.93      0.89       247
        58.0       1.00      1.00      1.00        34
        59.0       0.90      0.83      0.86       877
        60.0       0.40      0.58      0.47        76
        61.0       0.87      0.75      0.81       566
        62.0       1.00      0.08      0.15        24
        63.0       0.83      0.36      0.51        55
        64.0       0.98      0.96      0.97       255
        65.0       1.00      0.21      0.35        14
        66.0       0.94      0.96      0.95       457
        67.0       0.95      0.54      0.69        37
        68.0       0.93      0.80      0.86      1189
        69.0       0.86      0.91      0.88       224
        70.0       1.00      0.58      0.73        19
        71.0       0.95      0.96      0.96       357
        72.0       0.74      0.72      0.73        32
        73.0       0.00      0.00      0.00        12
        74.0       0.98      0.95      0.97       127
        75.0       1.00      0.83      0.91        12
        76.0       0.62      0.80      0.70       460
        77.0       0.98      0.83      0.89       103
        78.0       0.93      0.27      0.42        52
        79.0       0.74      0.61      0.67        83
        80.0       0.73      0.51      0.60        80
        81.0       0.85      0.83      0.84        84
        82.0       0.85      0.89      0.87       334
        83.0       0.68      0.57      0.62        23
        84.0       0.80      0.66      0.72       519
        85.0       0.08      0.01      0.02        88
        86.0       1.00      0.58      0.74        12
        87.0       0.59      0.73      0.65       480
        88.0       0.48      0.68      0.56       126
        89.0       1.00      0.92      0.96        25
        90.0       0.85      0.74      0.79       152
        91.0       0.88      0.35      0.50        20
        92.0       1.00      0.04      0.07        28
        93.0       0.97      0.76      0.85        42
        94.0       0.78      0.21      0.33        34
        95.0       0.76      0.52      0.62       100
        96.0       0.74      0.81      0.77       415
        97.0       0.53      0.47      0.50       118
        98.0       0.88      0.77      0.82        99
        99.0       0.83      0.84      0.83       253
       100.0       0.97      0.93      0.95       116
       101.0       0.67      0.80      0.73       423
       102.0       0.78      0.81      0.80        99
       103.0       0.85      0.85      0.85        60
       104.0       0.84      0.85      0.84       265
       105.0       1.00      0.78      0.88        37
       106.0       0.73      0.87      0.79       495
       107.0       0.87      0.87      0.87        15
       108.0       0.94      0.86      0.90       611
       109.0       0.99      0.95      0.97       206
       110.0       0.73      0.50      0.59        22
       111.0       0.76      0.88      0.81       534
       112.0       0.67      0.70      0.69        98
       113.0       0.65      0.57      0.61        87
       114.0       0.96      0.85      0.90       110
       115.0       0.70      0.93      0.80       858
       116.0       0.61      0.67      0.64        61
       117.0       0.97      0.94      0.95       209
       118.0       0.00      0.00      0.00        13
       119.0       0.92      0.75      0.83        65
       120.0       0.92      0.96      0.94       156
       121.0       0.95      0.99      0.97        85
       122.0       0.60      0.70      0.64        56
       123.0       0.89      0.64      0.75       154
       124.0       0.80      0.85      0.82        52
       125.0       0.96      0.89      0.92       146
       126.0       0.63      0.65      0.64        77
       127.0       0.93      0.72      0.81        18
       128.0       0.85      0.91      0.88       198
       129.0       0.89      0.95      0.92       450
       130.0       1.00      0.45      0.62        11
       131.0       0.81      0.70      0.75        43
       132.0       0.86      0.80      0.83        15
       133.0       0.99      0.94      0.97       205
       134.0       0.96      0.95      0.95        77
       135.0       0.72      0.87      0.78       255
       136.0       0.75      0.15      0.25        20
       137.0       0.85      0.92      0.88        12
       138.0       0.98      0.64      0.77        67
       139.0       0.99      0.98      0.98      1464
       140.0       0.90      0.88      0.89       147
       141.0       0.95      0.86      0.90        98
       142.0       0.97      0.88      0.92       455
       143.0       0.91      0.96      0.93        82
       144.0       0.98      0.95      0.96       411
       145.0       0.98      0.94      0.96       405
       146.0       0.75      0.27      0.40        11
       147.0       0.98      0.88      0.93       148
       148.0       0.89      0.97      0.93       702
       149.0       0.99      0.97      0.98       196
       150.0       0.95      0.62      0.75        32
       151.0       0.89      0.74      0.81        69
       152.0       0.93      0.96      0.94        93
       153.0       0.89      0.94      0.91        33
       154.0       1.00      0.66      0.80        50
       155.0       0.84      0.90      0.87       154

    accuracy                           0.84     28655
   macro avg       0.81      0.70      0.72     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[747   0   0 ...   0   0   0]
 [  0   0   2 ...   0   0   0]
 [  1   0  27 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  33  17]
 [  0   0   0 ...   1   0 139]]

===multilabel confusion matrix===

[[[27675   156]
  [   77   747]]

 [[28641     0]
  [   14     0]]

 [[28615     8]
  [    5    27]]

 [[28644     0]
  [   10     1]]

 [[28603     1]
  [   16    35]]

 [[28457    22]
  [   34   142]]

 [[28476    77]
  [   39    63]]

 [[28457   101]
  [   45    52]]

 [[28641     0]
  [    8     6]]

 [[28565    20]
  [   35    35]]

 [[28514    38]
  [    9    94]]

 [[28635     2]
  [   14     4]]

 [[28640     0]
  [   14     1]]

 [[28603     9]
  [   11    32]]

 [[28614     7]
  [   14    20]]

 [[28575    15]
  [   11    54]]

 [[28638     4]
  [   12     1]]

 [[28633     3]
  [   10     9]]

 [[28582     1]
  [    8    64]]

 [[28625     0]
  [   28     2]]

 [[28560     1]
  [    1    93]]

 [[28606     3]
  [   13    33]]

 [[28629     1]
  [   14    11]]

 [[28296    14]
  [   23   322]]

 [[28624     1]
  [   21     9]]

 [[28633     2]
  [   18     2]]

 [[28424    63]
  [   51   117]]

 [[28608    12]
  [   10    25]]

 [[28592     2]
  [    8    53]]

 [[28583     9]
  [   20    43]]

 [[28644     0]
  [   11     0]]

 [[28642     1]
  [    9     3]]

 [[28611     4]
  [   23    17]]

 [[28574     7]
  [   23    51]]

 [[28598     0]
  [    0    57]]

 [[28640     0]
  [    0    15]]

 [[28582    23]
  [   36    14]]

 [[28633     3]
  [    3    16]]

 [[28614    12]
  [   11    18]]

 [[28483    71]
  [    5    96]]

 [[28637     5]
  [    5     8]]

 [[28641     0]
  [    2    12]]

 [[28585     4]
  [   21    45]]

 [[28564    15]
  [    7    69]]

 [[28644     0]
  [    1    10]]

 [[28616     2]
  [    5    32]]

 [[26741   302]
  [  132  1480]]

 [[28341    15]
  [    4   295]]

 [[28412     0]
  [    8   235]]

 [[28485     2]
  [   16   152]]

 [[27502   129]
  [  184   840]]

 [[28254    48]
  [  112   241]]

 [[28568     2]
  [   13    72]]

 [[27887   162]
  [  109   497]]

 [[28092    20]
  [   67   476]]

 [[28547    30]
  [   16    62]]

 [[27553   148]
  [  103   851]]

 [[28371    37]
  [   17   230]]

 [[28621     0]
  [    0    34]]

 [[27693    85]
  [  145   732]]

 [[28513    66]
  [   32    44]]

 [[28024    65]
  [  140   426]]

 [[28631     0]
  [   22     2]]

 [[28596     4]
  [   35    20]]

 [[28396     4]
  [    9   246]]

 [[28641     0]
  [   11     3]]

 [[28171    27]
  [   19   438]]

 [[28617     1]
  [   17    20]]

 [[27397    69]
  [  234   955]]

 [[28399    32]
  [   21   203]]

 [[28636     0]
  [    8    11]]

 [[28279    19]
  [   13   344]]

 [[28615     8]
  [    9    23]]

 [[28643     0]
  [   12     0]]

 [[28526     2]
  [    6   121]]

 [[28643     0]
  [    2    10]]

 [[27967   228]
  [   90   370]]

 [[28550     2]
  [   18    85]]

 [[28602     1]
  [   38    14]]

 [[28554    18]
  [   32    51]]

 [[28560    15]
  [   39    41]]

 [[28559    12]
  [   14    70]]

 [[28270    51]
  [   37   297]]

 [[28626     6]
  [   10    13]]

 [[28052    84]
  [  179   340]]

 [[28555    12]
  [   87     1]]

 [[28643     0]
  [    5     7]]

 [[27932   243]
  [  131   349]]

 [[28435    94]
  [   40    86]]

 [[28630     0]
  [    2    23]]

 [[28483    20]
  [   39   113]]

 [[28634     1]
  [   13     7]]

 [[28627     0]
  [   27     1]]

 [[28612     1]
  [   10    32]]

 [[28619     2]
  [   27     7]]

 [[28539    16]
  [   48    52]]

 [[28119   121]
  [   79   336]]

 [[28488    49]
  [   63    55]]

 [[28546    10]
  [   23    76]]

 [[28359    43]
  [   41   212]]

 [[28536     3]
  [    8   108]]

 [[28069   163]
  [   85   338]]

 [[28534    22]
  [   19    80]]

 [[28586     9]
  [    9    51]]

 [[28346    44]
  [   41   224]]

 [[28618     0]
  [    8    29]]

 [[28002   158]
  [   65   430]]

 [[28638     2]
  [    2    13]]

 [[28012    32]
  [   87   524]]

 [[28448     1]
  [   11   195]]

 [[28629     4]
  [   11    11]]

 [[27973   148]
  [   66   468]]

 [[28523    34]
  [   29    69]]

 [[28541    27]
  [   37    50]]

 [[28541     4]
  [   17    93]]

 [[27450   347]
  [   58   800]]

 [[28568    26]
  [   20    41]]

 [[28440     6]
  [   13   196]]

 [[28642     0]
  [   13     0]]

 [[28586     4]
  [   16    49]]

 [[28486    13]
  [    7   149]]

 [[28566     4]
  [    1    84]]

 [[28573    26]
  [   17    39]]

 [[28489    12]
  [   55    99]]

 [[28592    11]
  [    8    44]]

 [[28503     6]
  [   16   130]]

 [[28549    29]
  [   27    50]]

 [[28636     1]
  [    5    13]]

 [[28425    32]
  [   17   181]]

 [[28151    54]
  [   23   427]]

 [[28644     0]
  [    6     5]]

 [[28605     7]
  [   13    30]]

 [[28638     2]
  [    3    12]]

 [[28448     2]
  [   12   193]]

 [[28575     3]
  [    4    73]]

 [[28312    88]
  [   34   221]]

 [[28634     1]
  [   17     3]]

 [[28641     2]
  [    1    11]]

 [[28587     1]
  [   24    43]]

 [[27170    21]
  [   31  1433]]

 [[28493    15]
  [   18   129]]

 [[28553     4]
  [   14    84]]

 [[28189    11]
  [   55   400]]

 [[28565     8]
  [    3    79]]

 [[28235     9]
  [   22   389]]

 [[28244     6]
  [   24   381]]

 [[28643     1]
  [    8     3]]

 [[28505     2]
  [   18   130]]

 [[27872    81]
  [   23   679]]

 [[28457     2]
  [    6   190]]

 [[28622     1]
  [   12    20]]

 [[28580     6]
  [   18    51]]

 [[28555     7]
  [    4    89]]

 [[28618     4]
  [    2    31]]

 [[28605     0]
  [   17    33]]

 [[28474    27]
  [   15   139]]]

===scores report===
metrics	scores
Accuracy	0.8409
MCC	0.8377
log_loss	0.7225
f1 score weighted	0.8377
f1 score macro	0.7246
f1 score micro	0.8409
roc_auc ovr	0.9936
roc_auc ovo	0.9909
precision	0.8486
recall	0.8409

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8485831937465104	0.8455922611938388	0.6981528733496659	0.8455353253540866	0.7390234774762167	0.8485831937465104	0.9941030298162074	0.9913613176350314	0.859702467097231	0.8485831937465104
1	0.8382481242366079	0.8348235093409102	0.7355125758027812	0.8306792934455007	0.7146556558199155	0.8382481242366079	0.9932557449263026	0.989992580318526	0.8411768798878716	0.8382481242366079
2	0.8409701622753446	0.8377680040739226	0.7228401505897066	0.8390076101160375	0.7289930166281248	0.8409701622753447	0.9934889860237086	0.9910134783551239	0.8485091954369567	0.8409701622753446
3	0.8425056709125807	0.8393748707125618	0.7055025044925416	0.8386621583975744	0.7211366835387373	0.8425056709125807	0.9941066383059506	0.9906980519606133	0.854807818636607	0.8425056709125807
4	0.840935264351771	0.8377246109844043	0.7224803401043918	0.837662506073239	0.7245763348909977	0.840935264351771	0.9935771867624771	0.9909440244520075	0.8486097211821649	0.840935264351771
mean	0.8422484831045629	0.8390566512611276	0.7168976888678175	0.8383093786772877	0.7256770336707984	0.8422484831045629	0.9937063171669293	0.9908018905442605	0.8505612164481663	0.8422484831045629
std	0.0034512671062471956	0.0035824543039773846	0.013373191073957567	0.004721502533288478	0.008153776941785448	0.003451267106247187	0.0003419241938311596	0.00045687976804802783	0.006287781647869943	0.0034512671062471956

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 59588.6931 secs

