/home/amsequeira/enzymeClassification/models/hot_encoded/bi_attetion_500_post_post_lev3_ec50_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64f403d070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64f403d400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64f403d460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64f403d190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.69      0.73       358
         1.0       1.00      0.50      0.67        12
         2.0       0.73      0.42      0.53        19
         3.0       0.65      0.62      0.64        80
         4.0       0.45      0.37      0.41        54
         5.0       0.29      0.09      0.13        58
         6.0       0.56      0.42      0.48        45
         7.0       0.75      0.50      0.60        48
         8.0       1.00      0.09      0.17        11
         9.0       0.56      0.43      0.49        21
        10.0       0.50      0.13      0.21        15
        11.0       0.81      0.61      0.70        36
        12.0       0.75      0.50      0.60        12
        13.0       0.73      0.76      0.75        25
        14.0       0.32      0.32      0.32        19
        15.0       0.89      0.77      0.83        22
        16.0       0.53      0.39      0.45        23
        17.0       0.88      0.82      0.85       119
        18.0       0.62      0.44      0.52        18
        19.0       0.25      0.08      0.12        12
        20.0       0.48      0.58      0.53        90
        21.0       0.67      0.33      0.44        12
        22.0       0.69      0.80      0.74        25
        23.0       0.00      0.00      0.00        12
        24.0       0.38      0.14      0.20        22
        25.0       0.73      0.58      0.65        38
        26.0       0.94      1.00      0.97        17
        27.0       0.55      0.17      0.26        35
        28.0       0.33      0.09      0.14        11
        29.0       0.72      0.64      0.68        36
        30.0       0.85      0.69      0.76        32
        31.0       0.64      0.84      0.73        38
        32.0       0.89      0.81      0.85       747
        33.0       0.93      0.85      0.89        74
        34.0       0.91      0.98      0.94        59
        35.0       0.51      0.85      0.64        48
        36.0       0.50      0.80      0.62       502
        37.0       0.44      0.81      0.57       241
        38.0       0.71      0.52      0.60        33
        39.0       0.61      0.74      0.67       344
        40.0       0.82      0.69      0.75       191
        41.0       0.95      0.56      0.71        32
        42.0       0.87      0.72      0.79       384
        43.0       0.75      0.79      0.77       118
        44.0       0.80      0.69      0.74       436
        45.0       0.55      0.46      0.50        48
        46.0       0.78      0.81      0.79       402
        47.0       0.75      0.18      0.29        17
        48.0       0.76      0.45      0.57        42
        49.0       0.98      0.81      0.89        78
        50.0       0.95      0.84      0.90       172
        51.0       1.00      0.35      0.52        20
        52.0       0.77      0.66      0.71       499
        53.0       0.93      0.81      0.87       100
        54.0       0.00      0.00      0.00        11
        55.0       0.81      0.81      0.81       103
        56.0       0.86      0.33      0.48        18
        57.0       0.30      0.30      0.30        10
        58.0       0.87      1.00      0.93        34
        59.0       0.62      0.63      0.63       231
        60.0       0.93      0.64      0.76        58
        61.0       0.31      0.13      0.19        30
        62.0       0.46      0.44      0.45        48
        63.0       0.56      0.20      0.29        50
        64.0       0.82      0.68      0.74        34
        65.0       0.72      0.81      0.76       155
        66.0       0.40      0.57      0.47        14
        67.0       0.51      0.70      0.59       314
        68.0       0.08      0.05      0.06        63
        69.0       0.55      0.70      0.62       308
        70.0       0.52      0.47      0.49        68
        71.0       0.53      0.50      0.52        66
        72.0       0.00      0.00      0.00        14
        73.0       0.88      0.60      0.71        25
        74.0       1.00      0.06      0.11        18
        75.0       0.40      0.30      0.34        60
        76.0       0.73      0.60      0.66       205
        77.0       0.66      0.25      0.36        77
        78.0       0.86      0.73      0.79        59
        79.0       0.80      0.53      0.64       139
        80.0       0.82      0.88      0.85        42
        81.0       0.46      0.57      0.51       175
        82.0       0.71      0.40      0.51        43
        83.0       0.75      0.23      0.35        26
        84.0       0.44      0.60      0.51       106
        85.0       0.82      0.64      0.72        14
        86.0       0.71      0.73      0.72       242
        87.0       0.67      0.81      0.73       309
        88.0       0.60      0.86      0.71        58
        89.0       0.25      0.18      0.21        11
        90.0       0.42      0.52      0.47       187
        91.0       0.57      0.35      0.43        46
        92.0       0.29      0.23      0.25        40
        93.0       0.74      0.44      0.55        32
        94.0       0.51      0.74      0.61       289
        95.0       0.40      0.06      0.11        31
        96.0       0.80      0.76      0.78        74
        97.0       0.44      0.26      0.33        27
        98.0       0.92      0.62      0.74        37
        99.0       0.91      0.88      0.89        24
       100.0       0.17      0.04      0.06        25
       101.0       0.88      0.45      0.59        65
       102.0       0.94      0.77      0.85        22
       103.0       0.65      0.80      0.72        64
       104.0       0.76      0.33      0.46        40
       105.0       1.00      0.83      0.91        12
       106.0       0.79      0.81      0.80       114
       107.0       0.89      0.73      0.80       161
       108.0       0.81      0.54      0.65        24
       109.0       0.66      0.73      0.69        52
       110.0       0.74      0.93      0.82        15
       111.0       0.95      0.71      0.81       123
       112.0       0.69      0.60      0.64        42
       113.0       0.85      0.95      0.90       430
       114.0       0.58      0.86      0.69        65
       115.0       0.76      0.61      0.68        31
       116.0       0.88      0.76      0.81       173
       117.0       0.81      0.97      0.88        31
       118.0       0.93      0.79      0.85       117
       119.0       0.87      0.89      0.88       136
       120.0       0.80      0.63      0.70        62
       121.0       0.87      0.87      0.87       224
       122.0       0.96      0.63      0.76        35
       123.0       0.70      0.84      0.77        37
       124.0       0.81      0.84      0.83        31
       125.0       0.76      0.87      0.81        15
       126.0       1.00      0.76      0.86        21
       127.0       0.87      0.89      0.88        73

    accuracy                           0.69     12227
   macro avg       0.68      0.57      0.60     12227
weighted avg       0.71      0.69      0.69     12227


===confusion_matrix===

[[248   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0   8 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  16   4]
 [  0   0   0 ...   1   0  65]]

===multilabel confusion matrix===

[[[11792    77]
  [  110   248]]

 [[12215     0]
  [    6     6]]

 [[12205     3]
  [   11     8]]

 [[12120    27]
  [   30    50]]

 [[12149    24]
  [   34    20]]

 [[12157    12]
  [   53     5]]

 [[12167    15]
  [   26    19]]

 [[12171     8]
  [   24    24]]

 [[12216     0]
  [   10     1]]

 [[12199     7]
  [   12     9]]

 [[12210     2]
  [   13     2]]

 [[12186     5]
  [   14    22]]

 [[12213     2]
  [    6     6]]

 [[12195     7]
  [    6    19]]

 [[12195    13]
  [   13     6]]

 [[12203     2]
  [    5    17]]

 [[12196     8]
  [   14     9]]

 [[12094    14]
  [   21    98]]

 [[12204     5]
  [   10     8]]

 [[12212     3]
  [   11     1]]

 [[12081    56]
  [   38    52]]

 [[12213     2]
  [    8     4]]

 [[12193     9]
  [    5    20]]

 [[12212     3]
  [   12     0]]

 [[12200     5]
  [   19     3]]

 [[12181     8]
  [   16    22]]

 [[12209     1]
  [    0    17]]

 [[12187     5]
  [   29     6]]

 [[12214     2]
  [   10     1]]

 [[12182     9]
  [   13    23]]

 [[12191     4]
  [   10    22]]

 [[12171    18]
  [    6    32]]

 [[11408    72]
  [  144   603]]

 [[12148     5]
  [   11    63]]

 [[12162     6]
  [    1    58]]

 [[12139    40]
  [    7    41]]

 [[11324   401]
  [  101   401]]

 [[11741   245]
  [   46   195]]

 [[12187     7]
  [   16    17]]

 [[11718   165]
  [   89   255]]

 [[12007    29]
  [   60   131]]

 [[12194     1]
  [   14    18]]

 [[11801    42]
  [  108   276]]

 [[12078    31]
  [   25    93]]

 [[11716    75]
  [  134   302]]

 [[12161    18]
  [   26    22]]

 [[11733    92]
  [   77   325]]

 [[12209     1]
  [   14     3]]

 [[12179     6]
  [   23    19]]

 [[12148     1]
  [   15    63]]

 [[12048     7]
  [   27   145]]

 [[12207     0]
  [   13     7]]

 [[11628   100]
  [  169   330]]

 [[12121     6]
  [   19    81]]

 [[12215     1]
  [   11     0]]

 [[12105    19]
  [   20    83]]

 [[12208     1]
  [   12     6]]

 [[12210     7]
  [    7     3]]

 [[12188     5]
  [    0    34]]

 [[11909    87]
  [   86   145]]

 [[12166     3]
  [   21    37]]

 [[12188     9]
  [   26     4]]

 [[12154    25]
  [   27    21]]

 [[12169     8]
  [   40    10]]

 [[12188     5]
  [   11    23]]

 [[12024    48]
  [   30   125]]

 [[12201    12]
  [    6     8]]

 [[11701   212]
  [   95   219]]

 [[12129    35]
  [   60     3]]

 [[11739   180]
  [   91   217]]

 [[12129    30]
  [   36    32]]

 [[12132    29]
  [   33    33]]

 [[12209     4]
  [   14     0]]

 [[12200     2]
  [   10    15]]

 [[12209     0]
  [   17     1]]

 [[12140    27]
  [   42    18]]

 [[11977    45]
  [   81   124]]

 [[12140    10]
  [   58    19]]

 [[12161     7]
  [   16    43]]

 [[12070    18]
  [   65    74]]

 [[12177     8]
  [    5    37]]

 [[11934   118]
  [   75   100]]

 [[12177     7]
  [   26    17]]

 [[12199     2]
  [   20     6]]

 [[12041    80]
  [   42    64]]

 [[12211     2]
  [    5     9]]

 [[11913    72]
  [   66   176]]

 [[11795   123]
  [   58   251]]

 [[12136    33]
  [    8    50]]

 [[12210     6]
  [    9     2]]

 [[11907   133]
  [   90    97]]

 [[12169    12]
  [   30    16]]

 [[12165    22]
  [   31     9]]

 [[12190     5]
  [   18    14]]

 [[11735   203]
  [   75   214]]

 [[12193     3]
  [   29     2]]

 [[12139    14]
  [   18    56]]

 [[12191     9]
  [   20     7]]

 [[12188     2]
  [   14    23]]

 [[12201     2]
  [    3    21]]

 [[12197     5]
  [   24     1]]

 [[12158     4]
  [   36    29]]

 [[12204     1]
  [    5    17]]

 [[12136    27]
  [   13    51]]

 [[12183     4]
  [   27    13]]

 [[12215     0]
  [    2    10]]

 [[12088    25]
  [   22    92]]

 [[12051    15]
  [   43   118]]

 [[12200     3]
  [   11    13]]

 [[12155    20]
  [   14    38]]

 [[12207     5]
  [    1    14]]

 [[12099     5]
  [   36    87]]

 [[12174    11]
  [   17    25]]

 [[11725    72]
  [   21   409]]

 [[12121    41]
  [    9    56]]

 [[12190     6]
  [   12    19]]

 [[12036    18]
  [   42   131]]

 [[12189     7]
  [    1    30]]

 [[12103     7]
  [   25    92]]

 [[12073    18]
  [   15   121]]

 [[12155    10]
  [   23    39]]

 [[11973    30]
  [   30   194]]

 [[12191     1]
  [   13    22]]

 [[12177    13]
  [    6    31]]

 [[12190     6]
  [    5    26]]

 [[12208     4]
  [    2    13]]

 [[12206     0]
  [    5    16]]

 [[12144    10]
  [    8    65]]]

===scores report===
metrics	scores
Accuracy	0.6926
MCC	0.6861
log_loss	1.4056
f1 score weighted	0.6883
f1 score macro	0.5973
f1 score micro	0.6926
roc_auc ovr	0.9759
roc_auc ovo	0.9737
precision	0.7113
recall	0.6926

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64f403d070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64f403d400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64f403d460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64f403d190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.64      0.85      0.73       357
         1.0       0.50      0.42      0.45        12
         2.0       0.85      0.58      0.69        19
         3.0       0.66      0.46      0.54        80
         4.0       0.37      0.33      0.35        54
         5.0       0.48      0.19      0.27        58
         6.0       0.32      0.36      0.34        44
         7.0       0.55      0.71      0.62        48
         8.0       0.50      0.09      0.15        11
         9.0       0.75      0.71      0.73        21
        10.0       0.33      0.07      0.11        15
        11.0       0.87      0.75      0.81        36
        12.0       0.43      0.25      0.32        12
        13.0       0.80      0.64      0.71        25
        14.0       0.50      0.20      0.29        20
        15.0       0.94      0.70      0.80        23
        16.0       0.72      0.78      0.75        23
        17.0       0.85      0.87      0.86       119
        18.0       1.00      0.35      0.52        17
        19.0       0.20      0.08      0.11        13
        20.0       0.55      0.47      0.51        90
        21.0       1.00      0.25      0.40        12
        22.0       0.81      0.68      0.74        25
        23.0       0.60      0.25      0.35        12
        24.0       1.00      0.23      0.37        22
        25.0       0.74      0.54      0.62        37
        26.0       0.86      1.00      0.92        18
        27.0       0.53      0.23      0.32        35
        28.0       0.17      0.08      0.11        12
        29.0       0.69      0.65      0.67        37
        30.0       0.69      0.62      0.66        32
        31.0       0.74      0.72      0.73        39
        32.0       0.69      0.86      0.77       746
        33.0       0.96      0.93      0.95        74
        34.0       0.93      0.86      0.89        58
        35.0       0.89      0.71      0.79        48
        36.0       0.62      0.73      0.67       502
        37.0       0.60      0.76      0.67       241
        38.0       0.58      0.67      0.62        33
        39.0       0.59      0.76      0.66       344
        40.0       0.88      0.72      0.79       191
        41.0       0.89      0.55      0.68        31
        42.0       0.69      0.79      0.74       384
        43.0       0.78      0.92      0.84       118
        44.0       0.70      0.77      0.74       436
        45.0       0.58      0.52      0.55        48
        46.0       0.72      0.83      0.77       402
        47.0       0.00      0.00      0.00        17
        48.0       0.52      0.55      0.53        42
        49.0       0.99      0.88      0.93        77
        50.0       0.89      0.83      0.86       172
        51.0       0.89      0.80      0.84        20
        52.0       0.71      0.72      0.71       499
        53.0       0.85      0.69      0.76        99
        54.0       0.33      0.09      0.14        11
        55.0       0.83      0.87      0.85       103
        56.0       0.67      0.22      0.33        18
        57.0       1.00      0.09      0.17        11
        58.0       1.00      0.91      0.95        34
        59.0       0.71      0.63      0.67       231
        60.0       0.78      0.69      0.73        58
        61.0       0.50      0.17      0.25        30
        62.0       0.58      0.38      0.46        48
        63.0       0.47      0.18      0.26        49
        64.0       0.96      0.68      0.79        34
        65.0       0.81      0.75      0.78       154
        66.0       0.67      0.29      0.40        14
        67.0       0.62      0.56      0.59       314
        68.0       0.22      0.06      0.10        63
        69.0       0.47      0.78      0.58       308
        70.0       0.70      0.46      0.56        69
        71.0       0.44      0.56      0.49        66
        72.0       0.00      0.00      0.00        14
        73.0       0.95      0.76      0.84        25
        74.0       0.00      0.00      0.00        18
        75.0       0.31      0.08      0.13        59
        76.0       0.70      0.65      0.67       205
        77.0       0.42      0.32      0.36        77
        78.0       0.76      0.53      0.62        59
        79.0       0.62      0.67      0.64       139
        80.0       0.82      0.88      0.85        41
        81.0       0.46      0.41      0.43       175
        82.0       0.67      0.70      0.68        43
        83.0       0.50      0.42      0.46        26
        84.0       0.60      0.52      0.56       105
        85.0       0.67      0.43      0.52        14
        86.0       0.74      0.67      0.70       242
        87.0       0.86      0.79      0.83       309
        88.0       0.94      0.86      0.90        58
        89.0       0.60      0.27      0.37        11
        90.0       0.58      0.56      0.57       187
        91.0       0.56      0.43      0.49        46
        92.0       0.53      0.20      0.29        40
        93.0       0.62      0.61      0.62        33
        94.0       0.63      0.69      0.66       289
        95.0       0.69      0.28      0.40        32
        96.0       0.77      0.72      0.74        74
        97.0       0.46      0.59      0.52        27
        98.0       0.83      0.54      0.66        37
        99.0       0.88      0.88      0.88        24
       100.0       0.43      0.12      0.18        26
       101.0       0.57      0.40      0.47        65
       102.0       0.67      0.64      0.65        22
       103.0       0.87      0.73      0.80        64
       104.0       0.47      0.38      0.42        40
       105.0       0.89      0.62      0.73        13
       106.0       0.84      0.80      0.82       113
       107.0       0.80      0.83      0.81       162
       108.0       0.57      0.50      0.53        24
       109.0       0.90      0.85      0.87        52
       110.0       0.65      0.87      0.74        15
       111.0       0.82      0.76      0.79       123
       112.0       0.70      0.56      0.62        41
       113.0       0.90      0.94      0.92       430
       114.0       0.88      0.77      0.82        65
       115.0       0.80      0.65      0.71        31
       116.0       0.86      0.76      0.81       173
       117.0       0.93      0.83      0.88        30
       118.0       0.91      0.89      0.90       118
       119.0       0.88      0.88      0.88       136
       120.0       0.94      0.72      0.81        61
       121.0       0.88      0.88      0.88       225
       122.0       1.00      0.97      0.99        35
       123.0       0.78      0.66      0.71        38
       124.0       0.66      0.81      0.72        31
       125.0       0.91      0.62      0.74        16
       126.0       0.85      0.81      0.83        21
       127.0       0.75      0.78      0.77        73

    accuracy                           0.70     12227
   macro avg       0.68      0.58      0.61     12227
weighted avg       0.70      0.70      0.70     12227


===confusion_matrix===

[[305   0   0 ...   0   0   0]
 [  0   5   0 ...   0   0   0]
 [  1   0  11 ...   0   0   0]
 ...
 [  0   0   0 ...  10   0   1]
 [  0   0   0 ...   0  17   2]
 [  0   0   0 ...   0   2  57]]

===multilabel confusion matrix===

[[[11697   173]
  [   52   305]]

 [[12210     5]
  [    7     5]]

 [[12206     2]
  [    8    11]]

 [[12128    19]
  [   43    37]]

 [[12142    31]
  [   36    18]]

 [[12157    12]
  [   47    11]]

 [[12149    34]
  [   28    16]]

 [[12151    28]
  [   14    34]]

 [[12215     1]
  [   10     1]]

 [[12201     5]
  [    6    15]]

 [[12210     2]
  [   14     1]]

 [[12187     4]
  [    9    27]]

 [[12211     4]
  [    9     3]]

 [[12198     4]
  [    9    16]]

 [[12203     4]
  [   16     4]]

 [[12203     1]
  [    7    16]]

 [[12197     7]
  [    5    18]]

 [[12090    18]
  [   15   104]]

 [[12210     0]
  [   11     6]]

 [[12210     4]
  [   12     1]]

 [[12103    34]
  [   48    42]]

 [[12215     0]
  [    9     3]]

 [[12198     4]
  [    8    17]]

 [[12213     2]
  [    9     3]]

 [[12205     0]
  [   17     5]]

 [[12183     7]
  [   17    20]]

 [[12206     3]
  [    0    18]]

 [[12185     7]
  [   27     8]]

 [[12210     5]
  [   11     1]]

 [[12179    11]
  [   13    24]]

 [[12186     9]
  [   12    20]]

 [[12178    10]
  [   11    28]]

 [[11196   285]
  [  104   642]]

 [[12150     3]
  [    5    69]]

 [[12165     4]
  [    8    50]]

 [[12175     4]
  [   14    34]]

 [[11505   220]
  [  137   365]]

 [[11865   121]
  [   57   184]]

 [[12178    16]
  [   11    22]]

 [[11703   180]
  [   84   260]]

 [[12018    18]
  [   54   137]]

 [[12194     2]
  [   14    17]]

 [[11708   135]
  [   82   302]]

 [[12079    30]
  [   10   108]]

 [[11649   142]
  [   99   337]]

 [[12161    18]
  [   23    25]]

 [[11695   130]
  [   69   333]]

 [[12210     0]
  [   17     0]]

 [[12164    21]
  [   19    23]]

 [[12149     1]
  [    9    68]]

 [[12038    17]
  [   30   142]]

 [[12205     2]
  [    4    16]]

 [[11579   149]
  [  140   359]]

 [[12116    12]
  [   31    68]]

 [[12214     2]
  [   10     1]]

 [[12106    18]
  [   13    90]]

 [[12207     2]
  [   14     4]]

 [[12216     0]
  [   10     1]]

 [[12193     0]
  [    3    31]]

 [[11935    61]
  [   85   146]]

 [[12158    11]
  [   18    40]]

 [[12192     5]
  [   25     5]]

 [[12166    13]
  [   30    18]]

 [[12168    10]
  [   40     9]]

 [[12192     1]
  [   11    23]]

 [[12045    28]
  [   38   116]]

 [[12211     2]
  [   10     4]]

 [[11804   109]
  [  137   177]]

 [[12150    14]
  [   59     4]]

 [[11645   274]
  [   69   239]]

 [[12144    14]
  [   37    32]]

 [[12113    48]
  [   29    37]]

 [[12213     0]
  [   14     0]]

 [[12201     1]
  [    6    19]]

 [[12208     1]
  [   18     0]]

 [[12157    11]
  [   54     5]]

 [[11964    58]
  [   72   133]]

 [[12115    35]
  [   52    25]]

 [[12158    10]
  [   28    31]]

 [[12031    57]
  [   46    93]]

 [[12178     8]
  [    5    36]]

 [[11970    82]
  [  104    71]]

 [[12169    15]
  [   13    30]]

 [[12190    11]
  [   15    11]]

 [[12086    36]
  [   50    55]]

 [[12210     3]
  [    8     6]]

 [[11927    58]
  [   80   162]]

 [[11879    39]
  [   64   245]]

 [[12166     3]
  [    8    50]]

 [[12214     2]
  [    8     3]]

 [[11965    75]
  [   83   104]]

 [[12165    16]
  [   26    20]]

 [[12180     7]
  [   32     8]]

 [[12182    12]
  [   13    20]]

 [[11820   118]
  [   89   200]]

 [[12191     4]
  [   23     9]]

 [[12137    16]
  [   21    53]]

 [[12181    19]
  [   11    16]]

 [[12186     4]
  [   17    20]]

 [[12200     3]
  [    3    21]]

 [[12197     4]
  [   23     3]]

 [[12142    20]
  [   39    26]]

 [[12198     7]
  [    8    14]]

 [[12156     7]
  [   17    47]]

 [[12170    17]
  [   25    15]]

 [[12213     1]
  [    5     8]]

 [[12097    17]
  [   23    90]]

 [[12031    34]
  [   28   134]]

 [[12194     9]
  [   12    12]]

 [[12170     5]
  [    8    44]]

 [[12205     7]
  [    2    13]]

 [[12084    20]
  [   29    94]]

 [[12176    10]
  [   18    23]]

 [[11752    45]
  [   26   404]]

 [[12155     7]
  [   15    50]]

 [[12191     5]
  [   11    20]]

 [[12033    21]
  [   41   132]]

 [[12195     2]
  [    5    25]]

 [[12098    11]
  [   13   105]]

 [[12074    17]
  [   16   120]]

 [[12163     3]
  [   17    44]]

 [[11975    27]
  [   26   199]]

 [[12192     0]
  [    1    34]]

 [[12182     7]
  [   13    25]]

 [[12183    13]
  [    6    25]]

 [[12210     1]
  [    6    10]]

 [[12203     3]
  [    4    17]]

 [[12135    19]
  [   16    57]]]

===scores report===
metrics	scores
Accuracy	0.7043
MCC	0.6977
log_loss	1.3612
f1 score weighted	0.6951
f1 score macro	0.6066
f1 score micro	0.7043
roc_auc ovr	0.9760
roc_auc ovo	0.9724
precision	0.7046
recall	0.7043

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64f403d070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64f403d400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64f403d460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64f403d190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.63      0.84      0.72       357
         1.0       0.73      0.62      0.67        13
         2.0       0.37      0.37      0.37        19
         3.0       0.37      0.51      0.43        79
         4.0       0.31      0.20      0.24        55
         5.0       0.35      0.19      0.24        59
         6.0       0.53      0.39      0.45        44
         7.0       0.79      0.62      0.70        48
         8.0       0.50      0.20      0.29        10
         9.0       0.45      0.48      0.47        21
        10.0       0.67      0.13      0.22        15
        11.0       0.84      0.75      0.79        36
        12.0       1.00      0.67      0.80        12
        13.0       0.82      0.72      0.77        25
        14.0       0.50      0.15      0.23        20
        15.0       0.92      0.50      0.65        22
        16.0       0.79      0.48      0.59        23
        17.0       0.82      0.84      0.83       118
        18.0       0.80      0.22      0.35        18
        19.0       0.00      0.00      0.00        13
        20.0       0.51      0.48      0.50        89
        21.0       0.80      0.33      0.47        12
        22.0       0.84      0.88      0.86        24
        23.0       0.33      0.08      0.13        12
        24.0       1.00      0.13      0.23        23
        25.0       0.84      0.57      0.68        37
        26.0       0.68      0.88      0.77        17
        27.0       0.22      0.11      0.15        36
        28.0       1.00      0.08      0.15        12
        29.0       0.68      0.73      0.70        37
        30.0       0.62      0.56      0.59        32
        31.0       0.70      0.72      0.71        39
        32.0       0.66      0.87      0.76       746
        33.0       0.80      0.89      0.84        74
        34.0       0.88      0.78      0.83        58
        35.0       0.74      0.73      0.74        48
        36.0       0.65      0.67      0.66       502
        37.0       0.65      0.69      0.67       240
        38.0       0.73      0.67      0.70        33
        39.0       0.56      0.74      0.64       344
        40.0       0.81      0.72      0.76       191
        41.0       0.86      0.39      0.53        31
        42.0       0.71      0.76      0.74       384
        43.0       0.56      0.90      0.69       117
        44.0       0.81      0.71      0.76       436
        45.0       0.59      0.20      0.30        49
        46.0       0.67      0.83      0.74       402
        47.0       0.00      0.00      0.00        17
        48.0       0.61      0.40      0.49        42
        49.0       0.96      0.83      0.89        77
        50.0       0.83      0.92      0.87       172
        51.0       0.50      0.32      0.39        19
        52.0       0.80      0.63      0.70       499
        53.0       0.78      0.76      0.77        99
        54.0       0.00      0.00      0.00        11
        55.0       0.74      0.76      0.75       103
        56.0       0.83      0.28      0.42        18
        57.0       0.20      0.09      0.13        11
        58.0       0.94      0.94      0.94        35
        59.0       0.51      0.62      0.56       231
        60.0       0.95      0.74      0.83        57
        61.0       0.50      0.03      0.06        29
        62.0       0.51      0.40      0.45        48
        63.0       0.30      0.27      0.28        49
        64.0       0.90      0.56      0.69        34
        65.0       0.83      0.75      0.79       155
        66.0       0.50      0.14      0.22        14
        67.0       0.59      0.61      0.60       315
        68.0       0.24      0.08      0.12        63
        69.0       0.55      0.68      0.61       307
        70.0       0.50      0.29      0.37        69
        71.0       0.66      0.56      0.61        66
        72.0       0.00      0.00      0.00        15
        73.0       0.87      0.52      0.65        25
        74.0       0.33      0.06      0.10        18
        75.0       0.33      0.03      0.06        59
        76.0       0.75      0.55      0.64       206
        77.0       0.69      0.33      0.45        76
        78.0       0.64      0.59      0.61        59
        79.0       0.66      0.63      0.64       140
        80.0       0.94      0.69      0.79        42
        81.0       0.51      0.35      0.42       175
        82.0       0.61      0.33      0.42        43
        83.0       0.57      0.32      0.41        25
        84.0       0.61      0.49      0.54       105
        85.0       0.38      0.43      0.40        14
        86.0       0.76      0.70      0.73       242
        87.0       0.86      0.80      0.83       310
        88.0       0.94      0.80      0.86        59
        89.0       0.33      0.18      0.24        11
        90.0       0.34      0.68      0.45       187
        91.0       0.69      0.43      0.53        46
        92.0       0.60      0.23      0.33        40
        93.0       0.67      0.55      0.60        33
        94.0       0.40      0.76      0.52       289
        95.0       0.00      0.00      0.00        32
        96.0       0.84      0.76      0.80        75
        97.0       0.23      0.36      0.28        28
        98.0       1.00      0.43      0.60        37
        99.0       0.80      0.87      0.83        23
       100.0       0.29      0.08      0.12        25
       101.0       0.57      0.36      0.44        66
       102.0       0.45      0.71      0.56        21
       103.0       0.74      0.83      0.78        65
       104.0       0.42      0.42      0.42        40
       105.0       1.00      0.50      0.67        12
       106.0       0.89      0.69      0.78       113
       107.0       0.73      0.79      0.76       162
       108.0       0.57      0.17      0.26        24
       109.0       0.93      0.77      0.85        53
       110.0       0.50      0.64      0.56        14
       111.0       0.74      0.66      0.70       123
       112.0       0.92      0.54      0.68        41
       113.0       0.90      0.95      0.92       429
       114.0       0.79      0.77      0.78        65
       115.0       0.69      0.65      0.67        31
       116.0       0.89      0.82      0.86       173
       117.0       0.77      0.80      0.79        30
       118.0       0.94      0.83      0.88       117
       119.0       0.97      0.87      0.91       136
       120.0       0.88      0.49      0.63        61
       121.0       0.83      0.92      0.87       225
       122.0       0.90      0.74      0.81        35
       123.0       0.80      0.53      0.63        38
       124.0       0.71      0.57      0.63        30
       125.0       0.74      0.88      0.80        16
       126.0       0.86      0.82      0.84        22
       127.0       0.73      0.78      0.75        73

    accuracy                           0.68     12226
   macro avg       0.65      0.53      0.56     12226
weighted avg       0.69      0.68      0.67     12226


===confusion_matrix===

[[299   0   0 ...   0   0   1]
 [  2   8   0 ...   0   0   0]
 [  0   0   7 ...   0   0   0]
 ...
 [  0   0   0 ...  14   1   1]
 [  0   0   0 ...   0  18   3]
 [  0   0   0 ...   1   2  57]]

===multilabel confusion matrix===

[[[11692   177]
  [   58   299]]

 [[12210     3]
  [    5     8]]

 [[12195    12]
  [   12     7]]

 [[12080    67]
  [   39    40]]

 [[12147    24]
  [   44    11]]

 [[12147    20]
  [   48    11]]

 [[12167    15]
  [   27    17]]

 [[12170     8]
  [   18    30]]

 [[12214     2]
  [    8     2]]

 [[12193    12]
  [   11    10]]

 [[12210     1]
  [   13     2]]

 [[12185     5]
  [    9    27]]

 [[12214     0]
  [    4     8]]

 [[12197     4]
  [    7    18]]

 [[12203     3]
  [   17     3]]

 [[12203     1]
  [   11    11]]

 [[12200     3]
  [   12    11]]

 [[12086    22]
  [   19    99]]

 [[12207     1]
  [   14     4]]

 [[12209     4]
  [   13     0]]

 [[12096    41]
  [   46    43]]

 [[12213     1]
  [    8     4]]

 [[12198     4]
  [    3    21]]

 [[12212     2]
  [   11     1]]

 [[12203     0]
  [   20     3]]

 [[12185     4]
  [   16    21]]

 [[12202     7]
  [    2    15]]

 [[12176    14]
  [   32     4]]

 [[12214     0]
  [   11     1]]

 [[12176    13]
  [   10    27]]

 [[12183    11]
  [   14    18]]

 [[12175    12]
  [   11    28]]

 [[11151   329]
  [   94   652]]

 [[12135    17]
  [    8    66]]

 [[12162     6]
  [   13    45]]

 [[12166    12]
  [   13    35]]

 [[11545   179]
  [  167   335]]

 [[11898    88]
  [   74   166]]

 [[12185     8]
  [   11    22]]

 [[11686   196]
  [   91   253]]

 [[12003    32]
  [   54   137]]

 [[12193     2]
  [   19    12]]

 [[11726   116]
  [   93   291]]

 [[12027    82]
  [   12   105]]

 [[11715    75]
  [  126   310]]

 [[12170     7]
  [   39    10]]

 [[11662   162]
  [   68   334]]

 [[12209     0]
  [   17     0]]

 [[12173    11]
  [   25    17]]

 [[12146     3]
  [   13    64]]

 [[12021    33]
  [   13   159]]

 [[12201     6]
  [   13     6]]

 [[11649    78]
  [  185   314]]

 [[12106    21]
  [   24    75]]

 [[12215     0]
  [   11     0]]

 [[12096    27]
  [   25    78]]

 [[12207     1]
  [   13     5]]

 [[12211     4]
  [   10     1]]

 [[12189     2]
  [    2    33]]

 [[11860   135]
  [   88   143]]

 [[12167     2]
  [   15    42]]

 [[12196     1]
  [   28     1]]

 [[12160    18]
  [   29    19]]

 [[12147    30]
  [   36    13]]

 [[12190     2]
  [   15    19]]

 [[12047    24]
  [   39   116]]

 [[12210     2]
  [   12     2]]

 [[11780   131]
  [  124   191]]

 [[12147    16]
  [   58     5]]

 [[11747   172]
  [   97   210]]

 [[12137    20]
  [   49    20]]

 [[12141    19]
  [   29    37]]

 [[12211     0]
  [   15     0]]

 [[12199     2]
  [   12    13]]

 [[12206     2]
  [   17     1]]

 [[12163     4]
  [   57     2]]

 [[11982    38]
  [   92   114]]

 [[12139    11]
  [   51    25]]

 [[12147    20]
  [   24    35]]

 [[12041    45]
  [   52    88]]

 [[12182     2]
  [   13    29]]

 [[11991    60]
  [  113    62]]

 [[12174     9]
  [   29    14]]

 [[12195     6]
  [   17     8]]

 [[12088    33]
  [   54    51]]

 [[12202    10]
  [    8     6]]

 [[11930    54]
  [   72   170]]

 [[11875    41]
  [   61   249]]

 [[12164     3]
  [   12    47]]

 [[12211     4]
  [    9     2]]

 [[11790   249]
  [   60   127]]

 [[12171     9]
  [   26    20]]

 [[12180     6]
  [   31     9]]

 [[12184     9]
  [   15    18]]

 [[11607   330]
  [   69   220]]

 [[12194     0]
  [   32     0]]

 [[12140    11]
  [   18    57]]

 [[12164    34]
  [   18    10]]

 [[12189     0]
  [   21    16]]

 [[12198     5]
  [    3    20]]

 [[12196     5]
  [   23     2]]

 [[12142    18]
  [   42    24]]

 [[12187    18]
  [    6    15]]

 [[12142    19]
  [   11    54]]

 [[12163    23]
  [   23    17]]

 [[12214     0]
  [    6     6]]

 [[12103    10]
  [   35    78]]

 [[12017    47]
  [   34   128]]

 [[12199     3]
  [   20     4]]

 [[12170     3]
  [   12    41]]

 [[12203     9]
  [    5     9]]

 [[12075    28]
  [   42    81]]

 [[12183     2]
  [   19    22]]

 [[11751    46]
  [   23   406]]

 [[12148    13]
  [   15    50]]

 [[12186     9]
  [   11    20]]

 [[12036    17]
  [   31   142]]

 [[12189     7]
  [    6    24]]

 [[12103     6]
  [   20    97]]

 [[12086     4]
  [   18   118]]

 [[12161     4]
  [   31    30]]

 [[11957    44]
  [   17   208]]

 [[12188     3]
  [    9    26]]

 [[12183     5]
  [   18    20]]

 [[12189     7]
  [   13    17]]

 [[12205     5]
  [    2    14]]

 [[12201     3]
  [    4    18]]

 [[12132    21]
  [   16    57]]]

===scores report===
metrics	scores
Accuracy	0.6779
MCC	0.6709
log_loss	1.4704
f1 score weighted	0.6684
f1 score macro	0.5603
f1 score micro	0.6779
roc_auc ovr	0.9728
roc_auc ovo	0.9690
precision	0.6881
recall	0.6779

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64f403d070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64f403d400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64f403d460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64f403d190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.81      0.73       358
         1.0       0.43      0.50      0.46        12
         2.0       0.67      0.22      0.33        18
         3.0       0.56      0.48      0.52        79
         4.0       0.48      0.25      0.33        55
         5.0       0.18      0.09      0.12        58
         6.0       0.33      0.07      0.11        45
         7.0       0.86      0.51      0.64        47
         8.0       0.75      0.30      0.43        10
         9.0       1.00      0.43      0.60        21
        10.0       0.00      0.00      0.00        15
        11.0       0.97      0.78      0.86        36
        12.0       1.00      0.17      0.29        12
        13.0       0.75      0.60      0.67        25
        14.0       1.00      0.20      0.33        20
        15.0       0.65      0.68      0.67        22
        16.0       0.45      0.57      0.50        23
        17.0       0.83      0.81      0.82       118
        18.0       1.00      0.39      0.56        18
        19.0       0.00      0.00      0.00        13
        20.0       0.38      0.53      0.44        89
        21.0       0.00      0.00      0.00        13
        22.0       0.90      0.76      0.83        25
        23.0       1.00      0.08      0.15        12
        24.0       0.38      0.26      0.31        23
        25.0       0.60      0.68      0.63        37
        26.0       1.00      1.00      1.00        17
        27.0       0.36      0.14      0.20        36
        28.0       0.25      0.08      0.12        12
        29.0       0.68      0.53      0.59        36
        30.0       0.90      0.56      0.69        32
        31.0       0.80      0.90      0.84        39
        32.0       0.59      0.88      0.71       747
        33.0       0.92      0.82      0.87        74
        34.0       0.98      0.78      0.87        58
        35.0       0.93      0.57      0.71        47
        36.0       0.60      0.69      0.64       502
        37.0       0.66      0.68      0.67       240
        38.0       0.88      0.44      0.59        34
        39.0       0.68      0.59      0.63       344
        40.0       0.87      0.74      0.80       191
        41.0       0.95      0.59      0.73        32
        42.0       0.69      0.74      0.71       384
        43.0       0.92      0.69      0.79       117
        44.0       0.66      0.78      0.72       437
        45.0       0.79      0.39      0.52        49
        46.0       0.87      0.79      0.83       401
        47.0       0.42      0.29      0.34        17
        48.0       0.56      0.55      0.55        42
        49.0       0.86      0.91      0.89        77
        50.0       0.75      0.84      0.79       171
        51.0       0.82      0.45      0.58        20
        52.0       0.64      0.71      0.67       499
        53.0       0.73      0.56      0.63       100
        54.0       0.00      0.00      0.00        11
        55.0       0.64      0.83      0.72       104
        56.0       0.36      0.26      0.30        19
        57.0       0.00      0.00      0.00        11
        58.0       0.86      0.91      0.89        35
        59.0       0.58      0.65      0.61       230
        60.0       0.89      0.83      0.86        58
        61.0       0.00      0.00      0.00        29
        62.0       0.78      0.29      0.42        49
        63.0       0.12      0.12      0.12        50
        64.0       0.96      0.65      0.77        34
        65.0       0.82      0.85      0.84       155
        66.0       0.00      0.00      0.00        14
        67.0       0.41      0.68      0.51       314
        68.0       0.67      0.03      0.06        62
        69.0       0.56      0.66      0.61       307
        70.0       0.34      0.32      0.33        68
        71.0       0.75      0.41      0.53        66
        72.0       0.00      0.00      0.00        15
        73.0       0.93      0.56      0.70        25
        74.0       0.33      0.05      0.09        19
        75.0       0.25      0.07      0.11        59
        76.0       0.64      0.73      0.68       206
        77.0       0.56      0.53      0.55        77
        78.0       0.69      0.63      0.65        59
        79.0       0.82      0.70      0.75       139
        80.0       0.83      0.81      0.82        42
        81.0       0.29      0.44      0.35       174
        82.0       0.56      0.44      0.49        43
        83.0       0.38      0.20      0.26        25
        84.0       0.49      0.52      0.50       105
        85.0       1.00      0.53      0.70        15
        86.0       0.69      0.64      0.66       242
        87.0       0.82      0.82      0.82       309
        88.0       0.91      0.81      0.86        59
        89.0       1.00      0.09      0.17        11
        90.0       0.87      0.37      0.52       188
        91.0       0.69      0.23      0.35        47
        92.0       0.41      0.17      0.25        40
        93.0       0.45      0.52      0.48        33
        94.0       0.58      0.60      0.59       288
        95.0       0.40      0.25      0.31        32
        96.0       0.98      0.67      0.79        75
        97.0       0.64      0.26      0.37        27
        98.0       0.73      0.63      0.68        38
        99.0       0.92      0.96      0.94        23
       100.0       0.00      0.00      0.00        25
       101.0       0.92      0.36      0.52        66
       102.0       0.90      0.86      0.88        22
       103.0       0.69      0.84      0.76        64
       104.0       0.59      0.26      0.36        39
       105.0       0.90      0.75      0.82        12
       106.0       0.61      0.79      0.68       113
       107.0       0.74      0.83      0.78       161
       108.0       0.42      0.22      0.29        23
       109.0       0.71      0.83      0.77        53
       110.0       1.00      0.79      0.88        14
       111.0       0.56      0.78      0.65       123
       112.0       0.75      0.80      0.78        41
       113.0       0.93      0.90      0.91       429
       114.0       0.82      0.77      0.79        65
       115.0       0.49      0.55      0.52        31
       116.0       0.88      0.70      0.78       173
       117.0       0.96      0.84      0.90        31
       118.0       0.85      0.75      0.80       117
       119.0       0.81      0.87      0.84       135
       120.0       0.90      0.73      0.80        62
       121.0       0.84      0.84      0.84       224
       122.0       0.96      0.77      0.86        35
       123.0       0.60      0.49      0.54        37
       124.0       0.59      0.77      0.67        30
       125.0       0.69      0.69      0.69        16
       126.0       0.78      0.82      0.80        22
       127.0       0.74      0.81      0.77        73

    accuracy                           0.67     12226
   macro avg       0.65      0.53      0.56     12226
weighted avg       0.68      0.67      0.66     12226


===confusion_matrix===

[[290   1   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0   4 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   0]
 [  0   0   0 ...   0  18   2]
 [  0   0   0 ...   0   3  59]]

===multilabel confusion matrix===

[[[11718   150]
  [   68   290]]

 [[12206     8]
  [    6     6]]

 [[12206     2]
  [   14     4]]

 [[12117    30]
  [   41    38]]

 [[12156    15]
  [   41    14]]

 [[12145    23]
  [   53     5]]

 [[12175     6]
  [   42     3]]

 [[12175     4]
  [   23    24]]

 [[12215     1]
  [    7     3]]

 [[12205     0]
  [   12     9]]

 [[12210     1]
  [   15     0]]

 [[12189     1]
  [    8    28]]

 [[12214     0]
  [   10     2]]

 [[12196     5]
  [   10    15]]

 [[12206     0]
  [   16     4]]

 [[12196     8]
  [    7    15]]

 [[12187    16]
  [   10    13]]

 [[12088    20]
  [   22    96]]

 [[12208     0]
  [   11     7]]

 [[12213     0]
  [   13     0]]

 [[12059    78]
  [   42    47]]

 [[12212     1]
  [   13     0]]

 [[12199     2]
  [    6    19]]

 [[12214     0]
  [   11     1]]

 [[12193    10]
  [   17     6]]

 [[12172    17]
  [   12    25]]

 [[12209     0]
  [    0    17]]

 [[12181     9]
  [   31     5]]

 [[12211     3]
  [   11     1]]

 [[12181     9]
  [   17    19]]

 [[12192     2]
  [   14    18]]

 [[12178     9]
  [    4    35]]

 [[11028   451]
  [   91   656]]

 [[12147     5]
  [   13    61]]

 [[12167     1]
  [   13    45]]

 [[12177     2]
  [   20    27]]

 [[11495   229]
  [  158   344]]

 [[11902    84]
  [   76   164]]

 [[12190     2]
  [   19    15]]

 [[11787    95]
  [  141   203]]

 [[12013    22]
  [   50   141]]

 [[12193     1]
  [   13    19]]

 [[11711   131]
  [   99   285]]

 [[12102     7]
  [   36    81]]

 [[11616   173]
  [   97   340]]

 [[12172     5]
  [   30    19]]

 [[11779    46]
  [   86   315]]

 [[12202     7]
  [   12     5]]

 [[12166    18]
  [   19    23]]

 [[12138    11]
  [    7    70]]

 [[12007    48]
  [   27   144]]

 [[12204     2]
  [   11     9]]

 [[11532   195]
  [  146   353]]

 [[12105    21]
  [   44    56]]

 [[12215     0]
  [   11     0]]

 [[12073    49]
  [   18    86]]

 [[12198     9]
  [   14     5]]

 [[12214     1]
  [   11     0]]

 [[12186     5]
  [    3    32]]

 [[11888   108]
  [   80   150]]

 [[12162     6]
  [   10    48]]

 [[12196     1]
  [   29     0]]

 [[12173     4]
  [   35    14]]

 [[12132    44]
  [   44     6]]

 [[12191     1]
  [   12    22]]

 [[12043    28]
  [   23   132]]

 [[12212     0]
  [   14     0]]

 [[11604   308]
  [   99   215]]

 [[12163     1]
  [   60     2]]

 [[11761   158]
  [  103   204]]

 [[12116    42]
  [   46    22]]

 [[12151     9]
  [   39    27]]

 [[12211     0]
  [   15     0]]

 [[12200     1]
  [   11    14]]

 [[12205     2]
  [   18     1]]

 [[12155    12]
  [   55     4]]

 [[11934    86]
  [   56   150]]

 [[12117    32]
  [   36    41]]

 [[12150    17]
  [   22    37]]

 [[12065    22]
  [   42    97]]

 [[12177     7]
  [    8    34]]

 [[11864   188]
  [   97    77]]

 [[12168    15]
  [   24    19]]

 [[12193     8]
  [   20     5]]

 [[12063    58]
  [   50    55]]

 [[12211     0]
  [    7     8]]

 [[11914    70]
  [   87   155]]

 [[11861    56]
  [   57   252]]

 [[12162     5]
  [   11    48]]

 [[12215     0]
  [   10     1]]

 [[12028    10]
  [  119    69]]

 [[12174     5]
  [   36    11]]

 [[12176    10]
  [   33     7]]

 [[12172    21]
  [   16    17]]

 [[11814   124]
  [  116   172]]

 [[12182    12]
  [   24     8]]

 [[12150     1]
  [   25    50]]

 [[12195     4]
  [   20     7]]

 [[12179     9]
  [   14    24]]

 [[12201     2]
  [    1    22]]

 [[12201     0]
  [   25     0]]

 [[12158     2]
  [   42    24]]

 [[12202     2]
  [    3    19]]

 [[12138    24]
  [   10    54]]

 [[12180     7]
  [   29    10]]

 [[12213     1]
  [    3     9]]

 [[12055    58]
  [   24    89]]

 [[12018    47]
  [   28   133]]

 [[12196     7]
  [   18     5]]

 [[12155    18]
  [    9    44]]

 [[12212     0]
  [    3    11]]

 [[12027    76]
  [   27    96]]

 [[12174    11]
  [    8    33]]

 [[11767    30]
  [   44   385]]

 [[12150    11]
  [   15    50]]

 [[12177    18]
  [   14    17]]

 [[12036    17]
  [   52   121]]

 [[12194     1]
  [    5    26]]

 [[12094    15]
  [   29    88]]

 [[12063    28]
  [   18   117]]

 [[12159     5]
  [   17    45]]

 [[11966    36]
  [   35   189]]

 [[12190     1]
  [    8    27]]

 [[12177    12]
  [   19    18]]

 [[12180    16]
  [    7    23]]

 [[12205     5]
  [    5    11]]

 [[12199     5]
  [    4    18]]

 [[12132    21]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.6719
MCC	0.6645
log_loss	1.4884
f1 score weighted	0.6611
f1 score macro	0.5601
f1 score micro	0.6719
roc_auc ovr	0.9729
roc_auc ovo	0.9689
precision	0.6820
recall	0.6719

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64f403d070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64f403d400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64f403d460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64f403d190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.60      0.83      0.70       358
         1.0       0.67      0.33      0.44        12
         2.0       0.71      0.26      0.38        19
         3.0       0.43      0.61      0.50        79
         4.0       0.30      0.11      0.16        55
         5.0       0.31      0.17      0.22        58
         6.0       0.38      0.58      0.46        45
         7.0       0.51      0.60      0.55        47
         8.0       0.00      0.00      0.00        10
         9.0       0.53      0.43      0.47        21
        10.0       0.22      0.13      0.17        15
        11.0       0.79      0.75      0.77        36
        12.0       0.53      0.67      0.59        12
        13.0       1.00      0.72      0.84        25
        14.0       1.00      0.11      0.19        19
        15.0       0.82      0.82      0.82        22
        16.0       0.50      0.48      0.49        23
        17.0       0.82      0.85      0.83       118
        18.0       0.57      0.22      0.32        18
        19.0       0.00      0.00      0.00        12
        20.0       0.84      0.34      0.49        90
        21.0       0.67      0.15      0.25        13
        22.0       0.95      0.72      0.82        25
        23.0       0.00      0.00      0.00        13
        24.0       0.80      0.18      0.30        22
        25.0       0.72      0.61      0.66        38
        26.0       1.00      0.71      0.83        17
        27.0       0.24      0.11      0.15        35
        28.0       0.00      0.00      0.00        12
        29.0       0.54      0.53      0.54        36
        30.0       0.88      0.44      0.58        32
        31.0       0.91      0.76      0.83        38
        32.0       0.80      0.83      0.82       747
        33.0       0.81      0.92      0.86        75
        34.0       0.89      0.83      0.86        59
        35.0       0.70      0.68      0.69        47
        36.0       0.74      0.74      0.74       501
        37.0       0.79      0.65      0.72       241
        38.0       0.85      0.67      0.75        33
        39.0       0.58      0.72      0.65       344
        40.0       0.90      0.75      0.82       192
        41.0       0.87      0.41      0.55        32
        42.0       0.62      0.80      0.70       384
        43.0       0.74      0.77      0.75       117
        44.0       0.63      0.73      0.68       436
        45.0       0.56      0.39      0.46        49
        46.0       0.66      0.90      0.76       401
        47.0       0.00      0.00      0.00        17
        48.0       0.60      0.60      0.60        42
        49.0       0.85      0.94      0.89        77
        50.0       0.71      0.89      0.79       172
        51.0       0.90      0.45      0.60        20
        52.0       0.63      0.68      0.65       499
        53.0       0.81      0.62      0.70       100
        54.0       0.50      0.09      0.15        11
        55.0       0.88      0.81      0.84       104
        56.0       0.67      0.33      0.44        18
        57.0       0.33      0.10      0.15        10
        58.0       0.96      0.77      0.86        35
        59.0       0.68      0.62      0.65       230
        60.0       0.81      0.79      0.80        58
        61.0       0.00      0.00      0.00        29
        62.0       0.74      0.41      0.53        49
        63.0       0.44      0.24      0.31        50
        64.0       0.86      0.56      0.68        34
        65.0       0.94      0.72      0.82       155
        66.0       0.80      0.29      0.42        14
        67.0       0.50      0.67      0.57       314
        68.0       0.17      0.02      0.03        62
        69.0       0.61      0.67      0.64       307
        70.0       0.56      0.34      0.42        68
        71.0       0.51      0.41      0.45        66
        72.0       0.00      0.00      0.00        14
        73.0       0.70      0.67      0.68        24
        74.0       0.00      0.00      0.00        19
        75.0       0.58      0.12      0.19        60
        76.0       0.63      0.67      0.65       206
        77.0       0.88      0.36      0.51        77
        78.0       0.68      0.68      0.68        59
        79.0       0.52      0.46      0.49       139
        80.0       0.77      0.81      0.79        42
        81.0       0.54      0.42      0.47       174
        82.0       0.76      0.51      0.61        43
        83.0       0.60      0.12      0.19        26
        84.0       0.50      0.49      0.50       106
        85.0       0.55      0.73      0.63        15
        86.0       0.73      0.68      0.71       241
        87.0       0.83      0.81      0.82       309
        88.0       0.68      0.80      0.73        59
        89.0       1.00      0.20      0.33        10
        90.0       0.46      0.57      0.51       188
        91.0       0.61      0.50      0.55        46
        92.0       0.33      0.02      0.05        41
        93.0       0.73      0.50      0.59        32
        94.0       0.66      0.69      0.67       288
        95.0       0.38      0.10      0.15        31
        96.0       0.82      0.72      0.77        75
        97.0       0.22      0.30      0.25        27
        98.0       0.72      0.55      0.63        38
        99.0       0.96      0.96      0.96        24
       100.0       0.00      0.00      0.00        25
       101.0       0.61      0.38      0.47        65
       102.0       0.94      0.73      0.82        22
       103.0       0.76      0.81      0.79        64
       104.0       0.67      0.20      0.31        40
       105.0       0.71      0.83      0.77        12
       106.0       0.69      0.81      0.74       113
       107.0       0.66      0.83      0.73       161
       108.0       0.67      0.33      0.44        24
       109.0       0.64      0.58      0.61        52
       110.0       0.63      0.80      0.71        15
       111.0       0.72      0.56      0.63       124
       112.0       0.71      0.61      0.66        41
       113.0       0.66      0.97      0.79       430
       114.0       0.72      0.77      0.75        65
       115.0       0.64      0.45      0.53        31
       116.0       0.64      0.77      0.70       173
       117.0       0.96      0.77      0.86        31
       118.0       0.88      0.83      0.85       117
       119.0       0.84      0.87      0.85       136
       120.0       0.77      0.69      0.73        62
       121.0       0.93      0.79      0.86       224
       122.0       0.93      0.71      0.81        35
       123.0       0.89      0.46      0.61        37
       124.0       0.53      0.58      0.55        31
       125.0       0.58      0.73      0.65        15
       126.0       0.82      0.67      0.74        21
       127.0       0.68      0.81      0.74        73

    accuracy                           0.68     12226
   macro avg       0.64      0.53      0.55     12226
weighted avg       0.68      0.68      0.67     12226


===confusion_matrix===

[[298   0   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0   5 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   0]
 [  0   0   0 ...   0  14   5]
 [  0   0   0 ...   1   1  59]]

===multilabel confusion matrix===

[[[11671   197]
  [   60   298]]

 [[12212     2]
  [    8     4]]

 [[12205     2]
  [   14     5]]

 [[12083    64]
  [   31    48]]

 [[12157    14]
  [   49     6]]

 [[12146    22]
  [   48    10]]

 [[12139    42]
  [   19    26]]

 [[12152    27]
  [   19    28]]

 [[12215     1]
  [   10     0]]

 [[12197     8]
  [   12     9]]

 [[12204     7]
  [   13     2]]

 [[12183     7]
  [    9    27]]

 [[12207     7]
  [    4     8]]

 [[12201     0]
  [    7    18]]

 [[12207     0]
  [   17     2]]

 [[12200     4]
  [    4    18]]

 [[12192    11]
  [   12    11]]

 [[12086    22]
  [   18   100]]

 [[12205     3]
  [   14     4]]

 [[12214     0]
  [   12     0]]

 [[12130     6]
  [   59    31]]

 [[12212     1]
  [   11     2]]

 [[12200     1]
  [    7    18]]

 [[12210     3]
  [   13     0]]

 [[12203     1]
  [   18     4]]

 [[12179     9]
  [   15    23]]

 [[12209     0]
  [    5    12]]

 [[12178    13]
  [   31     4]]

 [[12213     1]
  [   12     0]]

 [[12174    16]
  [   17    19]]

 [[12192     2]
  [   18    14]]

 [[12185     3]
  [    9    29]]

 [[11321   158]
  [  124   623]]

 [[12135    16]
  [    6    69]]

 [[12161     6]
  [   10    49]]

 [[12165    14]
  [   15    32]]

 [[11595   130]
  [  129   372]]

 [[11944    41]
  [   84   157]]

 [[12189     4]
  [   11    22]]

 [[11704   178]
  [   95   249]]

 [[12018    16]
  [   48   144]]

 [[12192     2]
  [   19    13]]

 [[11655   187]
  [   78   306]]

 [[12077    32]
  [   27    90]]

 [[11606   184]
  [  116   320]]

 [[12162    15]
  [   30    19]]

 [[11637   188]
  [   41   360]]

 [[12209     0]
  [   17     0]]

 [[12167    17]
  [   17    25]]

 [[12136    13]
  [    5    72]]

 [[11991    63]
  [   19   153]]

 [[12205     1]
  [   11     9]]

 [[11530   197]
  [  162   337]]

 [[12111    15]
  [   38    62]]

 [[12214     1]
  [   10     1]]

 [[12110    12]
  [   20    84]]

 [[12205     3]
  [   12     6]]

 [[12214     2]
  [    9     1]]

 [[12190     1]
  [    8    27]]

 [[11930    66]
  [   87   143]]

 [[12157    11]
  [   12    46]]

 [[12195     2]
  [   29     0]]

 [[12170     7]
  [   29    20]]

 [[12161    15]
  [   38    12]]

 [[12189     3]
  [   15    19]]

 [[12064     7]
  [   43   112]]

 [[12211     1]
  [   10     4]]

 [[11698   214]
  [  103   211]]

 [[12159     5]
  [   61     1]]

 [[11788   131]
  [  101   206]]

 [[12140    18]
  [   45    23]]

 [[12134    26]
  [   39    27]]

 [[12211     1]
  [   14     0]]

 [[12195     7]
  [    8    16]]

 [[12207     0]
  [   19     0]]

 [[12161     5]
  [   53     7]]

 [[11940    80]
  [   67   139]]

 [[12145     4]
  [   49    28]]

 [[12148    19]
  [   19    40]]

 [[12029    58]
  [   75    64]]

 [[12174    10]
  [    8    34]]

 [[11990    62]
  [  101    73]]

 [[12176     7]
  [   21    22]]

 [[12198     2]
  [   23     3]]

 [[12068    52]
  [   54    52]]

 [[12202     9]
  [    4    11]]

 [[11923    62]
  [   76   165]]

 [[11867    50]
  [   59   250]]

 [[12145    22]
  [   12    47]]

 [[12216     0]
  [    8     2]]

 [[11911   127]
  [   81   107]]

 [[12165    15]
  [   23    23]]

 [[12183     2]
  [   40     1]]

 [[12188     6]
  [   16    16]]

 [[11836   102]
  [   90   198]]

 [[12190     5]
  [   28     3]]

 [[12139    12]
  [   21    54]]

 [[12170    29]
  [   19     8]]

 [[12180     8]
  [   17    21]]

 [[12201     1]
  [    1    23]]

 [[12200     1]
  [   25     0]]

 [[12145    16]
  [   40    25]]

 [[12203     1]
  [    6    16]]

 [[12146    16]
  [   12    52]]

 [[12182     4]
  [   32     8]]

 [[12210     4]
  [    2    10]]

 [[12072    41]
  [   22    91]]

 [[11997    68]
  [   28   133]]

 [[12198     4]
  [   16     8]]

 [[12157    17]
  [   22    30]]

 [[12204     7]
  [    3    12]]

 [[12075    27]
  [   54    70]]

 [[12175    10]
  [   16    25]]

 [[11578   218]
  [   11   419]]

 [[12142    19]
  [   15    50]]

 [[12187     8]
  [   17    14]]

 [[11978    75]
  [   39   134]]

 [[12194     1]
  [    7    24]]

 [[12096    13]
  [   20    97]]

 [[12067    23]
  [   18   118]]

 [[12151    13]
  [   19    43]]

 [[11989    13]
  [   47   177]]

 [[12189     2]
  [   10    25]]

 [[12187     2]
  [   20    17]]

 [[12179    16]
  [   13    18]]

 [[12203     8]
  [    4    11]]

 [[12202     3]
  [    7    14]]

 [[12125    28]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.6799
MCC	0.6727
log_loss	1.4361
f1 score weighted	0.6652
f1 score macro	0.5542
f1 score micro	0.6799
roc_auc ovr	0.9741
roc_auc ovo	0.9697
precision	0.6778
recall	0.6799

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.692565633434203	0.6861291912404429	1.4056339518755898	0.6883250253039334	0.5973188045356383	0.692565633434203	0.9759446067818526	0.9737472418105286	0.7113137415823523	0.692565633434203
1	0.7043428477958616	0.6976598673161338	1.361190304719776	0.6950631030312783	0.6065528750301694	0.7043428477958616	0.9760153333436761	0.972442056992431	0.7045613268107965	0.7043428477958616
2	0.6778995583183379	0.6708608997752058	1.470355044040567	0.6683501321000547	0.5602923009106899	0.6778995583183379	0.9727894688232585	0.9689829695082337	0.6880634786091927	0.6778995583183379
3	0.671928676590872	0.6645277624799298	1.4884383715022678	0.6610840361962947	0.5600554241422991	0.671928676590872	0.9728991755877467	0.9689086838577434	0.6819621152171993	0.671928676590872
4	0.6799443808277441	0.672739057174327	1.4360817594688138	0.6651855711346221	0.5542447440936259	0.6799443808277441	0.9741428969747369	0.9696991131026471	0.677845248293503	0.6799443808277441
mean	0.6853362193934037	0.6783833555972079	1.432339886321403	0.6756015735532366	0.5756928297424846	0.6853362193934037	0.9743582963022541	0.9707560130543168	0.6927491821026088	0.6853362193934037
std	0.011641773109519698	0.011933187175050685	0.04556679441734428	0.013509054404514808	0.021733615903095867	0.011641773109519698	0.001407039621544439	0.001972994663849805	0.01299702660987364	0.011641773109519698

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 30012.5987 secs

