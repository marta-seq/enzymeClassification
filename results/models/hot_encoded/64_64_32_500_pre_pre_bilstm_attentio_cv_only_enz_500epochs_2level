/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_2level
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb4fe835c10>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb4fe8359a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb4fe835bb0>]/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_2level
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f217434e520>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f217434e790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f217434e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f217434e4f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.93      0.89       911
         1.0       0.95      0.66      0.78        53
         2.0       0.91      0.83      0.87       179
         3.0       0.67      0.40      0.50        25
         4.0       0.72      0.66      0.69       112
         5.0       0.85      0.79      0.82       491
         6.0       0.91      0.81      0.86        64
         7.0       0.88      0.62      0.73        37
         8.0       0.90      0.89      0.89       206
         9.0       0.98      0.89      0.93        71
        10.0       0.94      0.93      0.94       404
        11.0       0.73      0.69      0.71        16
        12.0       0.81      0.83      0.82       378
        13.0       0.85      0.84      0.85       191
        14.0       0.67      0.37      0.47        76
        15.0       0.84      0.82      0.83        66
        16.0       0.92      0.86      0.89       141
        17.0       0.89      0.82      0.85       182
        18.0       0.91      0.83      0.87        12
        19.0       0.89      0.89      0.89        38
        20.0       0.93      0.94      0.94      2162
        21.0       0.95      0.96      0.95       168
        22.0       0.86      0.87      0.86      1470
        23.0       0.90      0.90      0.90      1259
        24.0       0.93      0.92      0.92       956
        25.0       0.95      0.93      0.94       283
        26.0       0.91      0.93      0.92      3919
        27.0       0.96      0.92      0.94       531
        28.0       1.00      0.67      0.80        12
        29.0       0.81      0.83      0.82      2345
        30.0       0.70      0.82      0.76       615
        31.0       0.95      0.66      0.78        32
        32.0       0.82      0.82      0.82      1449
        33.0       0.88      0.87      0.87       893
        34.0       0.93      0.90      0.92      1377
        35.0       1.00      0.68      0.81        22
        36.0       0.86      0.89      0.88       844
        37.0       0.92      0.90      0.91      1142
        38.0       0.96      0.90      0.93       314
        39.0       0.93      0.68      0.78        56
        40.0       0.94      0.81      0.87       154
        41.0       0.96      0.87      0.91        52
        42.0       0.89      0.79      0.84       247
        43.0       0.94      0.84      0.89       198
        44.0       0.92      0.94      0.93       529
        45.0       0.94      0.90      0.92       540
        46.0       0.90      0.45      0.60        20
        47.0       0.84      0.76      0.80        80
        48.0       0.97      0.99      0.98      1466
        49.0       0.96      0.89      0.93       148
        50.0       0.94      0.97      0.95      1453
        51.0       0.75      0.25      0.38        12
        52.0       0.94      0.94      0.94       151
        53.0       0.97      0.96      0.97       903
        54.0       0.94      0.90      0.92       108
        55.0       0.97      0.97      0.97        93
        56.0       1.00      0.94      0.97        33
        57.0       0.88      0.88      0.88        49
        58.0       0.91      0.95      0.93       154

    accuracy                           0.90     29892
   macro avg       0.89      0.82      0.85     29892
weighted avg       0.90      0.90      0.89     29892


===confusion_matrix===

[[850   0   0 ...   0   0   0]
 [  0  35   0 ...   0   0   0]
 [  2   0 148 ...   0   0   0]
 ...
 [  0   0   0 ...  31   1   0]
 [  0   0   0 ...   0  43   5]
 [  0   0   0 ...   0   5 146]]

===multilabel confusion matrix===

[[[28834   147]
  [   61   850]]

 [[29837     2]
  [   18    35]]

 [[29699    14]
  [   31   148]]

 [[29862     5]
  [   15    10]]

 [[29751    29]
  [   38    74]]

 [[29333    68]
  [  105   386]]

 [[29823     5]
  [   12    52]]

 [[29852     3]
  [   14    23]]

 [[29666    20]
  [   23   183]]

 [[29820     1]
  [    8    63]]

 [[29464    24]
  [   28   376]]

 [[29872     4]
  [    5    11]]

 [[29439    75]
  [   66   312]]

 [[29673    28]
  [   30   161]]

 [[29802    14]
  [   48    28]]

 [[29816    10]
  [   12    54]]

 [[29740    11]
  [   20   121]]

 [[29691    19]
  [   32   150]]

 [[29879     1]
  [    2    10]]

 [[29850     4]
  [    4    34]]

 [[27581   149]
  [  120  2042]]

 [[29715     9]
  [    7   161]]

 [[28215   207]
  [  194  1276]]

 [[28507   126]
  [  132  1127]]

 [[28868    68]
  [   76   880]]

 [[29596    13]
  [   20   263]]

 [[25604   369]
  [  292  3627]]

 [[29338    23]
  [   41   490]]

 [[29880     0]
  [    4     8]]

 [[27093   454]
  [  387  1958]]

 [[29059   218]
  [  109   506]]

 [[29859     1]
  [   11    21]]

 [[28179   264]
  [  255  1194]]

 [[28889   110]
  [  116   777]]

 [[28429    86]
  [  143  1234]]

 [[29870     0]
  [    7    15]]

 [[28923   125]
  [   89   755]]

 [[28664    86]
  [  114  1028]]

 [[29565    13]
  [   31   283]]

 [[29833     3]
  [   18    38]]

 [[29730     8]
  [   29   125]]

 [[29838     2]
  [    7    45]]

 [[29622    23]
  [   52   195]]

 [[29683    11]
  [   32   166]]

 [[29321    42]
  [   31   498]]

 [[29323    29]
  [   55   485]]

 [[29871     1]
  [   11     9]]

 [[29800    12]
  [   19    61]]

 [[28388    38]
  [   16  1450]]

 [[29739     5]
  [   16   132]]

 [[28352    87]
  [   48  1405]]

 [[29879     1]
  [    9     3]]

 [[29732     9]
  [    9   142]]

 [[28961    28]
  [   32   871]]

 [[29778     6]
  [   11    97]]

 [[29796     3]
  [    3    90]]

 [[29859     0]
  [    2    31]]

 [[29837     6]
  [    6    43]]

 [[29723    15]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8952
MCC	0.8895
log_loss	0.4900
f1 score weighted	0.8948
f1 score macro	0.8489
f1 score micro	0.8952
roc_auc ovr	0.9946
roc_auc ovo	0.9932
precision	0.8961
recall	0.8952

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f217434e520>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f217434e790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f217434e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f217434e4f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.93      0.90       912
         1.0       0.91      0.79      0.85        53
         2.0       0.93      0.80      0.86       179
         3.0       0.69      0.36      0.47        25
         4.0       0.75      0.68      0.71       112
         5.0       0.87      0.77      0.82       492
         6.0       0.88      0.82      0.85        65
         7.0       0.87      0.53      0.66        38
         8.0       0.94      0.89      0.92       206
         9.0       0.87      0.76      0.81        71
        10.0       0.94      0.90      0.92       405
        11.0       0.83      0.59      0.69        17
        12.0       0.86      0.81      0.84       377
        13.0       0.91      0.83      0.87       191
        14.0       0.58      0.34      0.43        76
        15.0       0.70      0.80      0.75        66
        16.0       0.94      0.84      0.89       140
        17.0       0.89      0.84      0.87       182
        18.0       1.00      1.00      1.00        11
        19.0       1.00      0.89      0.94        37
        20.0       0.95      0.95      0.95      2163
        21.0       0.99      0.92      0.95       169
        22.0       0.85      0.89      0.87      1469
        23.0       0.90      0.90      0.90      1259
        24.0       0.93      0.92      0.92       956
        25.0       0.95      0.90      0.93       282
        26.0       0.89      0.94      0.92      3919
        27.0       0.96      0.94      0.95       531
        28.0       1.00      0.92      0.96        12
        29.0       0.84      0.84      0.84      2346
        30.0       0.71      0.80      0.75       615
        31.0       0.91      0.91      0.91        32
        32.0       0.81      0.84      0.83      1450
        33.0       0.86      0.85      0.85       893
        34.0       0.95      0.91      0.93      1376
        35.0       0.92      0.55      0.69        22
        36.0       0.86      0.89      0.88       843
        37.0       0.92      0.88      0.90      1142
        38.0       0.96      0.90      0.93       314
        39.0       0.85      0.62      0.72        56
        40.0       0.91      0.80      0.85       154
        41.0       1.00      0.92      0.96        52
        42.0       0.87      0.89      0.88       247
        43.0       0.93      0.85      0.89       198
        44.0       0.94      0.93      0.94       529
        45.0       0.95      0.94      0.94       539
        46.0       0.90      0.47      0.62        19
        47.0       0.90      0.81      0.86        80
        48.0       0.97      0.98      0.97      1466
        49.0       0.93      0.92      0.93       148
        50.0       0.95      0.95      0.95      1453
        51.0       0.25      0.08      0.12        12
        52.0       0.97      0.95      0.96       151
        53.0       0.96      0.97      0.97       903
        54.0       0.91      0.90      0.90       108
        55.0       0.98      0.96      0.97        93
        56.0       1.00      0.88      0.94        33
        57.0       0.94      0.92      0.93        49
        58.0       0.90      0.95      0.92       154

    accuracy                           0.90     29892
   macro avg       0.89      0.82      0.85     29892
weighted avg       0.90      0.90      0.90     29892


===confusion_matrix===

[[847   0   0 ...   0   0   0]
 [  0  42   0 ...   0   0   0]
 [  0   0 144 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   2]
 [  0   0   0 ...   0  45   4]
 [  0   0   0 ...   0   1 146]]

===multilabel confusion matrix===

[[[28857   123]
  [   65   847]]

 [[29835     4]
  [   11    42]]

 [[29702    11]
  [   35   144]]

 [[29863     4]
  [   16     9]]

 [[29755    25]
  [   36    76]]

 [[29343    57]
  [  112   380]]

 [[29820     7]
  [   12    53]]

 [[29851     3]
  [   18    20]]

 [[29674    12]
  [   22   184]]

 [[29813     8]
  [   17    54]]

 [[29465    22]
  [   41   364]]

 [[29873     2]
  [    7    10]]

 [[29467    48]
  [   71   306]]

 [[29685    16]
  [   33   158]]

 [[29797    19]
  [   50    26]]

 [[29803    23]
  [   13    53]]

 [[29744     8]
  [   22   118]]

 [[29692    18]
  [   29   153]]

 [[29881     0]
  [    0    11]]

 [[29855     0]
  [    4    33]]

 [[27611   118]
  [  109  2054]]

 [[29721     2]
  [   13   156]]

 [[28198   225]
  [  167  1302]]

 [[28507   126]
  [  124  1135]]

 [[28865    71]
  [   79   877]]

 [[29597    13]
  [   28   254]]

 [[25522   451]
  [  219  3700]]

 [[29342    19]
  [   32   499]]

 [[29880     0]
  [    1    11]]

 [[27162   384]
  [  375  1971]]

 [[29071   206]
  [  120   495]]

 [[29857     3]
  [    3    29]]

 [[28153   289]
  [  227  1223]]

 [[28873   126]
  [  138   755]]

 [[28445    71]
  [  127  1249]]

 [[29869     1]
  [   10    12]]

 [[28929   120]
  [   94   749]]

 [[28657    93]
  [  138  1004]]

 [[29567    11]
  [   31   283]]

 [[29830     6]
  [   21    35]]

 [[29726    12]
  [   31   123]]

 [[29840     0]
  [    4    48]]

 [[29612    33]
  [   26   221]]

 [[29682    12]
  [   29   169]]

 [[29330    33]
  [   35   494]]

 [[29327    26]
  [   33   506]]

 [[29872     1]
  [   10     9]]

 [[29805     7]
  [   15    65]]

 [[28387    39]
  [   35  1431]]

 [[29734    10]
  [   12   136]]

 [[28374    65]
  [   75  1378]]

 [[29877     3]
  [   11     1]]

 [[29737     4]
  [    7   144]]

 [[28956    33]
  [   30   873]]

 [[29774    10]
  [   11    97]]

 [[29797     2]
  [    4    89]]

 [[29859     0]
  [    4    29]]

 [[29840     3]
  [    4    45]]

 [[29722    16]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8978
MCC	0.8923
log_loss	0.4844
f1 score weighted	0.8974
f1 score macro	0.8490
f1 score micro	0.8978
roc_auc ovr	0.9949
roc_auc ovo	0.9934
precision	0.8985
recall	0.8978

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f217434e520>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f217434e790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f217434e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f217434e4f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.92      0.91       912
         1.0       0.96      0.85      0.90        52
         2.0       0.86      0.82      0.84       179
         3.0       0.67      0.24      0.35        25
         4.0       0.78      0.64      0.71       112
         5.0       0.83      0.82      0.83       492
         6.0       1.00      0.86      0.93        65
         7.0       0.84      0.55      0.67        38
         8.0       0.94      0.89      0.91       205
         9.0       0.88      0.85      0.86        71
        10.0       0.94      0.93      0.93       405
        11.0       1.00      0.65      0.79        17
        12.0       0.86      0.83      0.84       377
        13.0       0.89      0.89      0.89       190
        14.0       0.65      0.29      0.40        76
        15.0       0.84      0.73      0.78        67
        16.0       0.91      0.92      0.91       140
        17.0       0.88      0.83      0.85       183
        18.0       0.85      0.92      0.88        12
        19.0       1.00      0.95      0.97        37
        20.0       0.94      0.93      0.94      2162
        21.0       0.97      0.96      0.97       169
        22.0       0.89      0.87      0.88      1470
        23.0       0.91      0.89      0.90      1259
        24.0       0.92      0.93      0.93       956
        25.0       0.94      0.94      0.94       282
        26.0       0.89      0.94      0.92      3918
        27.0       0.92      0.92      0.92       531
        28.0       1.00      0.92      0.96        13
        29.0       0.80      0.84      0.82      2346
        30.0       0.75      0.77      0.76       615
        31.0       0.89      0.75      0.81        32
        32.0       0.82      0.86      0.84      1450
        33.0       0.89      0.86      0.88       893
        34.0       0.93      0.90      0.91      1376
        35.0       1.00      0.55      0.71        22
        36.0       0.84      0.90      0.87       843
        37.0       0.93      0.92      0.93      1142
        38.0       0.95      0.93      0.94       314
        39.0       0.80      0.51      0.62        55
        40.0       0.93      0.79      0.86       154
        41.0       1.00      0.88      0.94        52
        42.0       0.90      0.84      0.87       247
        43.0       0.97      0.87      0.92       197
        44.0       0.95      0.93      0.94       530
        45.0       0.95      0.91      0.93       540
        46.0       0.82      0.47      0.60        19
        47.0       0.85      0.67      0.75        79
        48.0       0.97      0.99      0.98      1465
        49.0       0.98      0.89      0.93       149
        50.0       0.95      0.96      0.96      1453
        51.0       1.00      0.25      0.40        12
        52.0       0.99      0.94      0.96       152
        53.0       0.95      0.97      0.96       903
        54.0       0.92      0.88      0.90       108
        55.0       0.98      0.92      0.95        93
        56.0       0.94      1.00      0.97        32
        57.0       0.94      0.98      0.96        50
        58.0       0.91      0.94      0.92       154

    accuracy                           0.90     29892
   macro avg       0.90      0.82      0.85     29892
weighted avg       0.90      0.90      0.90     29892


===confusion_matrix===

[[835   0   2 ...   0   0   0]
 [  0  44   0 ...   0   0   0]
 [  1   0 146 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   0]
 [  0   0   0 ...   0  49   1]
 [  0   0   0 ...   2   3 145]]

===multilabel confusion matrix===

[[[28885    95]
  [   77   835]]

 [[29838     2]
  [    8    44]]

 [[29689    24]
  [   33   146]]

 [[29864     3]
  [   19     6]]

 [[29760    20]
  [   40    72]]

 [[29320    80]
  [   88   404]]

 [[29827     0]
  [    9    56]]

 [[29850     4]
  [   17    21]]

 [[29676    11]
  [   23   182]]

 [[29813     8]
  [   11    60]]

 [[29464    23]
  [   30   375]]

 [[29875     0]
  [    6    11]]

 [[29464    51]
  [   64   313]]

 [[29681    21]
  [   21   169]]

 [[29804    12]
  [   54    22]]

 [[29816     9]
  [   18    49]]

 [[29739    13]
  [   11   129]]

 [[29688    21]
  [   32   151]]

 [[29878     2]
  [    1    11]]

 [[29855     0]
  [    2    35]]

 [[27603   127]
  [  143  2019]]

 [[29718     5]
  [    6   163]]

 [[28261   161]
  [  194  1276]]

 [[28523   110]
  [  140  1119]]

 [[28860    76]
  [   64   892]]

 [[29594    16]
  [   16   266]]

 [[25536   438]
  [  242  3676]]

 [[29321    40]
  [   42   489]]

 [[29879     0]
  [    1    12]]

 [[27065   481]
  [  371  1975]]

 [[29122   155]
  [  141   474]]

 [[29857     3]
  [    8    24]]

 [[28159   283]
  [  196  1254]]

 [[28909    90]
  [  126   767]]

 [[28417    99]
  [  142  1234]]

 [[29870     0]
  [   10    12]]

 [[28906   143]
  [   82   761]]

 [[28677    73]
  [   93  1049]]

 [[29561    17]
  [   21   293]]

 [[29830     7]
  [   27    28]]

 [[29729     9]
  [   32   122]]

 [[29840     0]
  [    6    46]]

 [[29621    24]
  [   39   208]]

 [[29689     6]
  [   25   172]]

 [[29336    26]
  [   37   493]]

 [[29324    28]
  [   48   492]]

 [[29871     2]
  [   10     9]]

 [[29804     9]
  [   26    53]]

 [[28381    46]
  [   16  1449]]

 [[29740     3]
  [   17   132]]

 [[28371    68]
  [   58  1395]]

 [[29880     0]
  [    9     3]]

 [[29738     2]
  [    9   143]]

 [[28947    42]
  [   27   876]]

 [[29776     8]
  [   13    95]]

 [[29797     2]
  [    7    86]]

 [[29858     2]
  [    0    32]]

 [[29839     3]
  [    1    49]]

 [[29723    15]
  [    9   145]]]

===scores report===
metrics	scores
Accuracy	0.8990
MCC	0.8936
log_loss	0.4699
f1 score weighted	0.8983
f1 score macro	0.8524
f1 score micro	0.8990
roc_auc ovr	0.9949
roc_auc ovo	0.9936
precision	0.8994
recall	0.8990

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f217434e520>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f217434e790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f217434e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f217434e4f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 1, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.91      0.89       912
         1.0       0.92      0.90      0.91        52
         2.0       0.86      0.82      0.84       179
         3.0       0.55      0.25      0.34        24
         4.0       0.76      0.63      0.69       112
         5.0       0.85      0.75      0.80       492
         6.0       0.93      0.80      0.86        64
         7.0       0.81      0.55      0.66        38
         8.0       0.97      0.87      0.92       205
         9.0       0.93      0.77      0.84        70
        10.0       0.93      0.90      0.92       405
        11.0       1.00      0.53      0.69        17
        12.0       0.85      0.83      0.84       378
        13.0       0.88      0.82      0.85       191
        14.0       0.57      0.37      0.45        76
        15.0       0.81      0.75      0.78        67
        16.0       0.90      0.89      0.89       140
        17.0       0.89      0.84      0.86       183
        18.0       1.00      0.92      0.96        12
        19.0       1.00      0.95      0.97        37
        20.0       0.94      0.95      0.95      2162
        21.0       0.98      0.96      0.97       168
        22.0       0.88      0.89      0.88      1470
        23.0       0.91      0.90      0.91      1259
        24.0       0.95      0.93      0.94       955
        25.0       0.94      0.96      0.95       282
        26.0       0.91      0.92      0.92      3918
        27.0       0.96      0.93      0.95       532
        28.0       1.00      0.92      0.96        13
        29.0       0.82      0.85      0.84      2346
        30.0       0.74      0.78      0.76       616
        31.0       0.93      0.78      0.85        32
        32.0       0.80      0.87      0.84      1449
        33.0       0.85      0.88      0.86       893
        34.0       0.92      0.91      0.92      1377
        35.0       0.94      0.68      0.79        22
        36.0       0.88      0.90      0.89       844
        37.0       0.89      0.91      0.90      1142
        38.0       0.94      0.93      0.93       314
        39.0       0.87      0.71      0.78        56
        40.0       0.91      0.77      0.84       153
        41.0       1.00      0.92      0.96        51
        42.0       0.87      0.82      0.84       246
        43.0       0.97      0.89      0.93       197
        44.0       0.96      0.94      0.95       530
        45.0       0.95      0.90      0.92       540
        46.0       0.89      0.40      0.55        20
        47.0       0.85      0.69      0.76        80
        48.0       0.98      0.99      0.98      1465
        49.0       0.95      0.90      0.92       148
        50.0       0.95      0.95      0.95      1453
        51.0       1.00      0.38      0.56        13
        52.0       0.99      0.92      0.95       151
        53.0       0.96      0.97      0.97       904
        54.0       0.96      0.86      0.91       108
        55.0       0.94      0.90      0.92        93
        56.0       0.91      0.94      0.93        33
        57.0       0.94      0.98      0.96        50
        58.0       0.90      0.92      0.91       153

    accuracy                           0.90     29892
   macro avg       0.90      0.83      0.85     29892
weighted avg       0.90      0.90      0.90     29892


===confusion_matrix===

[[834   0   1 ...   0   0   0]
 [  0  47   0 ...   0   0   0]
 [  0   0 147 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   1]
 [  0   0   0 ...   0  49   0]
 [  0   0   0 ...   2   3 141]]

===multilabel confusion matrix===

[[[28856   124]
  [   78   834]]

 [[29836     4]
  [    5    47]]

 [[29689    24]
  [   32   147]]

 [[29863     5]
  [   18     6]]

 [[29758    22]
  [   41    71]]

 [[29333    67]
  [  121   371]]

 [[29824     4]
  [   13    51]]

 [[29849     5]
  [   17    21]]

 [[29681     6]
  [   27   178]]

 [[29818     4]
  [   16    54]]

 [[29460    27]
  [   40   365]]

 [[29875     0]
  [    8     9]]

 [[29458    56]
  [   65   313]]

 [[29679    22]
  [   34   157]]

 [[29795    21]
  [   48    28]]

 [[29813    12]
  [   17    50]]

 [[29738    14]
  [   16   124]]

 [[29690    19]
  [   30   153]]

 [[29880     0]
  [    1    11]]

 [[29855     0]
  [    2    35]]

 [[27609   121]
  [  106  2056]]

 [[29721     3]
  [    7   161]]

 [[28244   178]
  [  168  1302]]

 [[28518   115]
  [  120  1139]]

 [[28890    47]
  [   67   888]]

 [[29592    18]
  [   10   272]]

 [[25612   362]
  [  299  3619]]

 [[29341    19]
  [   35   497]]

 [[29879     0]
  [    1    12]]

 [[27111   435]
  [  342  2004]]

 [[29111   165]
  [  135   481]]

 [[29858     2]
  [    7    25]]

 [[28129   314]
  [  183  1266]]

 [[28860   139]
  [  110   783]]

 [[28413   102]
  [  129  1248]]

 [[29869     1]
  [    7    15]]

 [[28949    99]
  [   83   761]]

 [[28622   128]
  [  101  1041]]

 [[29559    19]
  [   22   292]]

 [[29830     6]
  [   16    40]]

 [[29728    11]
  [   35   118]]

 [[29841     0]
  [    4    47]]

 [[29617    29]
  [   45   201]]

 [[29689     6]
  [   21   176]]

 [[29340    22]
  [   32   498]]

 [[29324    28]
  [   55   485]]

 [[29871     1]
  [   12     8]]

 [[29802    10]
  [   25    55]]

 [[28397    30]
  [   20  1445]]

 [[29737     7]
  [   15   133]]

 [[28359    80]
  [   67  1386]]

 [[29879     0]
  [    8     5]]

 [[29739     2]
  [   12   139]]

 [[28956    32]
  [   31   873]]

 [[29780     4]
  [   15    93]]

 [[29794     5]
  [    9    84]]

 [[29856     3]
  [    2    31]]

 [[29839     3]
  [    1    49]]

 [[29723    16]
  [   12   141]]]

===scores report===
metrics	scores
Accuracy	0.8997
MCC	0.8943
log_loss	0.4552
f1 score weighted	0.8992
f1 score macro	0.8549
f1 score micro	0.8997
roc_auc ovr	0.9952
roc_auc ovo	0.9940
precision	0.9002
recall	0.8997

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f217434e520>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f217434e790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f217434e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f217434e4f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.93      0.91       911
         1.0       0.94      0.83      0.88        53
         2.0       0.89      0.85      0.87       180
         3.0       0.67      0.40      0.50        25
         4.0       0.79      0.66      0.72       111
         5.0       0.82      0.81      0.82       491
         6.0       0.95      0.92      0.94        64
         7.0       0.85      0.59      0.70        37
         8.0       0.94      0.91      0.93       205
         9.0       0.97      0.89      0.93        71
        10.0       0.93      0.92      0.92       404
        11.0       1.00      0.35      0.52        17
        12.0       0.82      0.88      0.85       378
        13.0       0.90      0.80      0.85       191
        14.0       0.60      0.43      0.50        76
        15.0       0.87      0.82      0.84        66
        16.0       0.90      0.84      0.87       140
        17.0       0.88      0.84      0.86       182
        18.0       1.00      1.00      1.00        12
        19.0       1.00      0.78      0.88        37
        20.0       0.95      0.95      0.95      2162
        21.0       0.98      0.96      0.97       168
        22.0       0.88      0.86      0.87      1470
        23.0       0.91      0.91      0.91      1259
        24.0       0.93      0.93      0.93       955
        25.0       0.93      0.97      0.95       283
        26.0       0.91      0.93      0.92      3919
        27.0       0.95      0.93      0.94       532
        28.0       1.00      0.92      0.96        13
        29.0       0.86      0.85      0.85      2345
        30.0       0.75      0.80      0.78       616
        31.0       0.96      0.81      0.88        32
        32.0       0.83      0.85      0.84      1449
        33.0       0.84      0.86      0.85       893
        34.0       0.92      0.91      0.92      1377
        35.0       0.94      0.73      0.82        22
        36.0       0.87      0.93      0.90       844
        37.0       0.90      0.92      0.91      1142
        38.0       0.95      0.93      0.94       314
        39.0       0.83      0.71      0.77        56
        40.0       0.95      0.81      0.87       153
        41.0       1.00      0.92      0.96        52
        42.0       0.91      0.85      0.88       247
        43.0       0.92      0.90      0.91       197
        44.0       0.94      0.91      0.93       529
        45.0       0.93      0.93      0.93       540
        46.0       0.91      0.50      0.65        20
        47.0       0.89      0.81      0.85        80
        48.0       0.98      0.99      0.99      1466
        49.0       0.96      0.91      0.94       148
        50.0       0.96      0.96      0.96      1453
        51.0       0.80      0.33      0.47        12
        52.0       0.97      0.91      0.94       151
        53.0       0.96      0.97      0.97       904
        54.0       0.96      0.86      0.91       108
        55.0       0.93      0.99      0.96        93
        56.0       0.97      0.88      0.92        33
        57.0       0.84      0.94      0.89        50
        58.0       0.95      0.95      0.95       154

    accuracy                           0.90     29892
   macro avg       0.91      0.84      0.86     29892
weighted avg       0.90      0.90      0.90     29892


===confusion_matrix===

[[847   0   0 ...   0   0   0]
 [  0  44   1 ...   0   0   0]
 [  1   0 153 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   0]
 [  0   0   0 ...   0  47   1]
 [  0   0   0 ...   1   4 146]]

===multilabel confusion matrix===

[[[28873   108]
  [   64   847]]

 [[29836     3]
  [    9    44]]

 [[29693    19]
  [   27   153]]

 [[29862     5]
  [   15    10]]

 [[29762    19]
  [   38    73]]

 [[29313    88]
  [   91   400]]

 [[29825     3]
  [    5    59]]

 [[29851     4]
  [   15    22]]

 [[29675    12]
  [   18   187]]

 [[29819     2]
  [    8    63]]

 [[29460    28]
  [   33   371]]

 [[29875     0]
  [   11     6]]

 [[29441    73]
  [   45   333]]

 [[29684    17]
  [   38   153]]

 [[29794    22]
  [   43    33]]

 [[29818     8]
  [   12    54]]

 [[29739    13]
  [   22   118]]

 [[29689    21]
  [   30   152]]

 [[29880     0]
  [    0    12]]

 [[29855     0]
  [    8    29]]

 [[27613   117]
  [  116  2046]]

 [[29720     4]
  [    6   162]]

 [[28255   167]
  [  200  1270]]

 [[28522   111]
  [  112  1147]]

 [[28866    71]
  [   70   885]]

 [[29587    22]
  [    9   274]]

 [[25607   366]
  [  263  3656]]

 [[29336    24]
  [   35   497]]

 [[29879     0]
  [    1    12]]

 [[27211   336]
  [  355  1990]]

 [[29116   160]
  [  123   493]]

 [[29859     1]
  [    6    26]]

 [[28199   244]
  [  217  1232]]

 [[28855   144]
  [  123   770]]

 [[28413   102]
  [  126  1251]]

 [[29869     1]
  [    6    16]]

 [[28930   118]
  [   62   782]]

 [[28633   117]
  [   92  1050]]

 [[29561    17]
  [   21   293]]

 [[29828     8]
  [   16    40]]

 [[29732     7]
  [   29   124]]

 [[29840     0]
  [    4    48]]

 [[29623    22]
  [   36   211]]

 [[29679    16]
  [   20   177]]

 [[29334    29]
  [   47   482]]

 [[29316    36]
  [   36   504]]

 [[29871     1]
  [   10    10]]

 [[29804     8]
  [   15    65]]

 [[28395    31]
  [   12  1454]]

 [[29739     5]
  [   13   135]]

 [[28381    58]
  [   63  1390]]

 [[29879     1]
  [    8     4]]

 [[29736     5]
  [   13   138]]

 [[28956    32]
  [   26   878]]

 [[29780     4]
  [   15    93]]

 [[29792     7]
  [    1    92]]

 [[29858     1]
  [    4    29]]

 [[29833     9]
  [    3    47]]

 [[29731     7]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.9045
MCC	0.8994
log_loss	0.4558
f1 score weighted	0.9041
f1 score macro	0.8642
f1 score micro	0.9045
roc_auc ovr	0.9952
roc_auc ovo	0.9938
precision	0.9047
recall	0.9045

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8951558945537268	0.8894982543030959	0.48999603956725774	0.894788541848229	0.8489124681605896	0.8951558945537268	0.994569947196856	0.9932254869141037	0.8960796086171462	0.8951558945537268
1	0.897832195905259	0.8922903660249859	0.4843889572898367	0.8973629757360284	0.8490044637974978	0.8978321959052589	0.9948740125777517	0.9934370682924655	0.8985352602066833	0.897832195905259
2	0.8990365315134484	0.893555218885605	0.46985317910679025	0.8982632935506678	0.852390795815362	0.8990365315134484	0.9948790382508501	0.9935806730499832	0.8994139682641948	0.8990365315134484
3	0.8997056068513315	0.8942823119208426	0.4552188580759361	0.8992289778337428	0.8549469376182577	0.8997056068513314	0.9952028173920833	0.9940495274452724	0.9002271935086558	0.8997056068513315
4	0.9045229492840894	0.8993792634326858	0.4557727362139691	0.9040523286846247	0.8642465030914569	0.9045229492840893	0.9952089412925188	0.9938054480836069	0.9046949801094252	0.9045229492840894
mean	0.899250635621571	0.8938010829134431	0.47104595405075794	0.8987392235306585	0.8539002336966328	0.899250635621571	0.9949469513420119	0.9936196407570863	0.8997902021412211	0.899250635621571
std	0.0030603596646964224	0.003231245207349589	0.014299177169850765	0.0030396512546163614	0.005643857725971659	0.003060359664696391	0.0002392365133057397	0.00028619411812296196	0.0028189623574210016	0.0030603596646964224

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 227195.3872 secs

