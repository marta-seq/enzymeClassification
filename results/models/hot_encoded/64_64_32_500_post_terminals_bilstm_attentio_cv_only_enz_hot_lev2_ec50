/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_terminals_bilstm_attentio_cv_only_enz_hot_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2cd8775640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2cd8775880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2cd87758e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2cd87754f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.57      0.81      0.67       402
         1.0       0.91      0.53      0.67        19
         2.0       0.32      0.76      0.45        82
         3.0       0.20      0.06      0.10        16
         4.0       0.38      0.23      0.28        62
         5.0       0.75      0.44      0.55       277
         6.0       0.62      0.67      0.64        36
         7.0       0.00      0.00      0.00        26
         8.0       0.56      0.43      0.49        72
         9.0       0.70      0.53      0.60        30
        10.0       0.62      0.79      0.69       156
        11.0       0.61      0.37      0.46       168
        12.0       0.56      0.42      0.48        83
        13.0       0.33      0.06      0.10        53
        14.0       0.24      0.39      0.30        31
        15.0       0.39      0.54      0.46        52
        16.0       0.42      0.68      0.52        94
        17.0       0.96      0.75      0.84       885
        18.0       0.78      0.79      0.78        48
        19.0       0.84      0.63      0.72       781
        20.0       0.88      0.65      0.75       591
        21.0       0.90      0.69      0.78       385
        22.0       0.49      0.84      0.61       128
        23.0       0.88      0.74      0.80      1888
        24.0       0.86      0.70      0.78       169
        25.0       0.65      0.65      0.65      1296
        26.0       0.65      0.52      0.58       381
        27.0       1.00      0.21      0.35        14
        28.0       0.50      0.76      0.60       769
        29.0       0.51      0.49      0.50       372
        30.0       0.79      0.75      0.77       631
        31.0       0.00      0.00      0.00        11
        32.0       0.65      0.54      0.59       316
        33.0       0.39      0.75      0.52       405
        34.0       0.75      0.51      0.61        96
        35.0       0.05      0.04      0.04        26
        36.0       0.78      0.38      0.52        65
        37.0       0.62      0.48      0.54        21
        38.0       0.54      0.62      0.58       121
        39.0       0.67      0.72      0.69       114
        40.0       0.56      0.79      0.66       207
        41.0       0.52      0.77      0.62       194
        42.0       0.65      0.43      0.51        47
        43.0       0.97      0.88      0.92       431
        44.0       0.64      0.73      0.69        67
        45.0       0.65      0.84      0.73       488
        46.0       0.94      0.55      0.69        62
        47.0       0.86      0.91      0.88       264
        48.0       0.50      0.49      0.49        49
        49.0       0.78      0.60      0.68        30
        50.0       0.69      0.73      0.71        15
        51.0       0.92      0.52      0.67        21
        52.0       0.69      0.88      0.77        73

    accuracy                           0.68     13120
   macro avg       0.62      0.57      0.57     13120
weighted avg       0.72      0.68      0.69     13120


===confusion_matrix===

[[325   0   2 ...   0   0   0]
 [  0  10   2 ...   0   0   0]
 [  0   0  62 ...   0   0   0]
 ...
 [  0   0   0 ...  11   1   1]
 [  0   0   0 ...   0  11   7]
 [  0   0   0 ...   0   0  64]]

===multilabel confusion matrix===

[[[12472   246]
  [   77   325]]

 [[13100     1]
  [    9    10]]

 [[12904   134]
  [   20    62]]

 [[13100     4]
  [   15     1]]

 [[13035    23]
  [   48    14]]

 [[12803    40]
  [  156   121]]

 [[13069    15]
  [   12    24]]

 [[13089     5]
  [   26     0]]

 [[13024    24]
  [   41    31]]

 [[13083     7]
  [   14    16]]

 [[12888    76]
  [   33   123]]

 [[12912    40]
  [  106    62]]

 [[13009    28]
  [   48    35]]

 [[13061     6]
  [   50     3]]

 [[13051    38]
  [   19    12]]

 [[13025    43]
  [   24    28]]

 [[12937    89]
  [   30    64]]

 [[12207    28]
  [  219   666]]

 [[13061    11]
  [   10    38]]

 [[12244    95]
  [  289   492]]

 [[12478    51]
  [  208   383]]

 [[12705    30]
  [  121   264]]

 [[12879   113]
  [   21   107]]

 [[11039   193]
  [  494  1394]]

 [[12932    19]
  [   50   119]]

 [[11371   453]
  [  460   836]]

 [[12634   105]
  [  182   199]]

 [[13106     0]
  [   11     3]]

 [[11771   580]
  [  184   585]]

 [[12569   179]
  [  189   183]]

 [[12359   130]
  [  155   476]]

 [[13109     0]
  [   11     0]]

 [[12711    93]
  [  146   170]]

 [[12250   465]
  [  102   303]]

 [[13008    16]
  [   47    49]]

 [[13073    21]
  [   25     1]]

 [[13048     7]
  [   40    25]]

 [[13093     6]
  [   11    10]]

 [[12935    64]
  [   46    75]]

 [[12966    40]
  [   32    82]]

 [[12786   127]
  [   43   164]]

 [[12789   137]
  [   45   149]]

 [[13062    11]
  [   27    20]]

 [[12679    10]
  [   52   379]]

 [[13026    27]
  [   18    49]]

 [[12412   220]
  [   78   410]]

 [[13056     2]
  [   28    34]]

 [[12816    40]
  [   24   240]]

 [[13047    24]
  [   25    24]]

 [[13085     5]
  [   12    18]]

 [[13100     5]
  [    4    11]]

 [[13098     1]
  [   10    11]]

 [[13018    29]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6832
MCC	0.6666
log_loss	1.3210
f1 score weighted	0.6877
f1 score macro	0.5674
f1 score micro	0.6832
roc_auc ovr	0.9649
roc_auc ovo	0.9641
precision	0.7205
recall	0.6832

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2cd8775640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2cd8775880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2cd87758e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2cd87754f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.61      0.83      0.70       402
         1.0       1.00      0.32      0.48        19
         2.0       0.81      0.43      0.56        81
         3.0       0.33      0.12      0.18        16
         4.0       0.56      0.35      0.44        62
         5.0       0.69      0.51      0.59       277
         6.0       0.93      0.75      0.83        36
         7.0       0.88      0.27      0.41        26
         8.0       0.57      0.42      0.49        73
         9.0       0.71      0.34      0.47        29
        10.0       0.83      0.62      0.71       156
        11.0       0.43      0.52      0.47       168
        12.0       0.74      0.39      0.51        83
        13.0       0.20      0.06      0.09        53
        14.0       0.75      0.28      0.41        32
        15.0       0.83      0.37      0.51        52
        16.0       0.69      0.60      0.64        95
        17.0       0.85      0.83      0.84       884
        18.0       1.00      0.48      0.65        48
        19.0       0.70      0.72      0.71       782
        20.0       0.81      0.62      0.70       591
        21.0       0.64      0.78      0.70       385
        22.0       0.86      0.70      0.77       128
        23.0       0.61      0.90      0.73      1888
        24.0       0.54      0.81      0.65       169
        25.0       0.75      0.58      0.65      1295
        26.0       0.50      0.65      0.56       381
        27.0       0.83      0.36      0.50        14
        28.0       0.59      0.62      0.60       769
        29.0       0.50      0.60      0.55       371
        30.0       0.82      0.72      0.76       631
        31.0       1.00      0.09      0.17        11
        32.0       0.59      0.50      0.54       316
        33.0       0.78      0.59      0.67       405
        34.0       0.76      0.47      0.58        96
        35.0       0.33      0.08      0.12        26
        36.0       1.00      0.35      0.52        65
        37.0       0.71      0.68      0.70        22
        38.0       0.66      0.60      0.63       121
        39.0       0.90      0.71      0.79       113
        40.0       0.88      0.64      0.74       208
        41.0       0.73      0.72      0.72       193
        42.0       0.94      0.33      0.48        46
        43.0       0.94      0.93      0.93       431
        44.0       0.94      0.48      0.64        66
        45.0       0.84      0.79      0.81       489
        46.0       0.84      0.44      0.57        62
        47.0       0.85      0.85      0.85       264
        48.0       0.70      0.47      0.56        49
        49.0       0.88      0.71      0.79        31
        50.0       1.00      0.94      0.97        16
        51.0       0.86      0.57      0.69        21
        52.0       0.76      0.93      0.83        73

    accuracy                           0.69     13120
   macro avg       0.74      0.55      0.61     13120
weighted avg       0.71      0.69      0.69     13120


===confusion_matrix===

[[334   0   0 ...   0   0   0]
 [  2   6   0 ...   0   0   0]
 [  0   0  35 ...   0   0   0]
 ...
 [  0   0   0 ...  15   0   1]
 [  0   0   0 ...   0  12   8]
 [  0   0   0 ...   0   0  68]]

===multilabel confusion matrix===

[[[12504   214]
  [   68   334]]

 [[13101     0]
  [   13     6]]

 [[13031     8]
  [   46    35]]

 [[13100     4]
  [   14     2]]

 [[13041    17]
  [   40    22]]

 [[12781    62]
  [  136   141]]

 [[13082     2]
  [    9    27]]

 [[13093     1]
  [   19     7]]

 [[13024    23]
  [   42    31]]

 [[13087     4]
  [   19    10]]

 [[12944    20]
  [   60    96]]

 [[12835   117]
  [   80    88]]

 [[13026    11]
  [   51    32]]

 [[13055    12]
  [   50     3]]

 [[13085     3]
  [   23     9]]

 [[13064     4]
  [   33    19]]

 [[12999    26]
  [   38    57]]

 [[12111   125]
  [  149   735]]

 [[13072     0]
  [   25    23]]

 [[12096   242]
  [  219   563]]

 [[12442    87]
  [  223   368]]

 [[12565   170]
  [   83   302]]

 [[12978    14]
  [   39    89]]

 [[10165  1067]
  [  195  1693]]

 [[12836   115]
  [   32   137]]

 [[11567   258]
  [  541   754]]

 [[12488   251]
  [  134   247]]

 [[13105     1]
  [    9     5]]

 [[12029   322]
  [  296   473]]

 [[12526   223]
  [  147   224]]

 [[12387   102]
  [  178   453]]

 [[13109     0]
  [   10     1]]

 [[12693   111]
  [  159   157]]

 [[12647    68]
  [  166   239]]

 [[13010    14]
  [   51    45]]

 [[13090     4]
  [   24     2]]

 [[13055     0]
  [   42    23]]

 [[13092     6]
  [    7    15]]

 [[12962    37]
  [   49    72]]

 [[12998     9]
  [   33    80]]

 [[12894    18]
  [   74   134]]

 [[12876    51]
  [   55   138]]

 [[13073     1]
  [   31    15]]

 [[12662    27]
  [   29   402]]

 [[13052     2]
  [   34    32]]

 [[12560    71]
  [  105   384]]

 [[13053     5]
  [   35    27]]

 [[12817    39]
  [   40   224]]

 [[13061    10]
  [   26    23]]

 [[13086     3]
  [    9    22]]

 [[13104     0]
  [    1    15]]

 [[13097     2]
  [    9    12]]

 [[13025    22]
  [    5    68]]]

===scores report===
metrics	scores
Accuracy	0.6947
MCC	0.6762
log_loss	1.2905
f1 score weighted	0.6902
f1 score macro	0.6073
f1 score micro	0.6947
roc_auc ovr	0.9650
roc_auc ovo	0.9616
precision	0.7146
recall	0.6947

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2cd8775640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2cd8775880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2cd87758e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2cd87754f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.74      0.75       401
         1.0       1.00      0.55      0.71        20
         2.0       0.59      0.48      0.53        82
         3.0       0.00      0.00      0.00        16
         4.0       0.25      0.45      0.32        62
         5.0       0.41      0.69      0.52       277
         6.0       0.97      0.81      0.88        36
         7.0       0.80      0.16      0.27        25
         8.0       0.61      0.41      0.49        73
         9.0       0.45      0.59      0.51        29
        10.0       0.75      0.66      0.70       156
        11.0       0.52      0.45      0.48       168
        12.0       0.38      0.64      0.47        83
        13.0       0.25      0.09      0.14        54
        14.0       0.33      0.23      0.27        31
        15.0       0.45      0.42      0.43        53
        16.0       0.51      0.63      0.56        95
        17.0       0.69      0.88      0.77       884
        18.0       0.83      0.81      0.82        47
        19.0       0.65      0.74      0.69       782
        20.0       0.86      0.64      0.73       592
        21.0       0.85      0.70      0.77       385
        22.0       0.81      0.80      0.81       128
        23.0       0.84      0.77      0.80      1887
        24.0       0.90      0.65      0.76       168
        25.0       0.65      0.67      0.66      1295
        26.0       0.53      0.68      0.59       381
        27.0       1.00      0.36      0.53        14
        28.0       0.64      0.59      0.61       768
        29.0       0.47      0.60      0.53       372
        30.0       0.79      0.75      0.77       631
        31.0       0.33      0.10      0.15        10
        32.0       0.56      0.58      0.57       316
        33.0       0.85      0.53      0.65       405
        34.0       0.92      0.64      0.75        96
        35.0       0.50      0.08      0.13        26
        36.0       0.90      0.29      0.44        66
        37.0       0.57      0.59      0.58        22
        38.0       0.83      0.56      0.67       121
        39.0       0.85      0.83      0.84       113
        40.0       0.83      0.71      0.77       208
        41.0       0.66      0.73      0.70       194
        42.0       0.74      0.54      0.62        46
        43.0       0.82      0.97      0.89       431
        44.0       0.85      0.71      0.78        66
        45.0       0.82      0.80      0.81       489
        46.0       0.72      0.61      0.66        62
        47.0       0.67      0.87      0.76       263
        48.0       0.86      0.50      0.63        50
        49.0       0.65      0.90      0.76        31
        50.0       0.88      0.88      0.88        16
        51.0       0.85      0.81      0.83        21
        52.0       0.84      0.73      0.78        73

    accuracy                           0.70     13120
   macro avg       0.68      0.60      0.61     13120
weighted avg       0.72      0.70      0.70     13120


===confusion_matrix===

[[297   0   0 ...   0   0   0]
 [  0  11   0 ...   0   0   0]
 [  1   0  39 ...   0   0   0]
 ...
 [  0   0   0 ...  14   0   0]
 [  0   0   0 ...   0  17   2]
 [  0   0   0 ...   2   2  53]]

===multilabel confusion matrix===

[[[12627    92]
  [  104   297]]

 [[13100     0]
  [    9    11]]

 [[13011    27]
  [   43    39]]

 [[13103     1]
  [   16     0]]

 [[12974    84]
  [   34    28]]

 [[12568   275]
  [   85   192]]

 [[13083     1]
  [    7    29]]

 [[13094     1]
  [   21     4]]

 [[13028    19]
  [   43    30]]

 [[13070    21]
  [   12    17]]

 [[12929    35]
  [   53   103]]

 [[12884    68]
  [   93    75]]

 [[12949    88]
  [   30    53]]

 [[13051    15]
  [   49     5]]

 [[13075    14]
  [   24     7]]

 [[13040    27]
  [   31    22]]

 [[12967    58]
  [   35    60]]

 [[11892   344]
  [  110   774]]

 [[13065     8]
  [    9    38]]

 [[12023   315]
  [  203   579]]

 [[12469    59]
  [  214   378]]

 [[12686    49]
  [  114   271]]

 [[12968    24]
  [   25   103]]

 [[10950   283]
  [  436  1451]]

 [[12940    12]
  [   58   110]]

 [[11353   472]
  [  429   866]]

 [[12510   229]
  [  123   258]]

 [[13106     0]
  [    9     5]]

 [[12103   249]
  [  318   450]]

 [[12495   253]
  [  148   224]]

 [[12364   125]
  [  157   474]]

 [[13108     2]
  [    9     1]]

 [[12663   141]
  [  133   183]]

 [[12676    39]
  [  190   215]]

 [[13019     5]
  [   35    61]]

 [[13092     2]
  [   24     2]]

 [[13052     2]
  [   47    19]]

 [[13088    10]
  [    9    13]]

 [[12985    14]
  [   53    68]]

 [[12991    16]
  [   19    94]]

 [[12882    30]
  [   60   148]]

 [[12854    72]
  [   52   142]]

 [[13065     9]
  [   21    25]]

 [[12600    89]
  [   13   418]]

 [[13046     8]
  [   19    47]]

 [[12543    88]
  [   99   390]]

 [[13043    15]
  [   24    38]]

 [[12745   112]
  [   33   230]]

 [[13066     4]
  [   25    25]]

 [[13074    15]
  [    3    28]]

 [[13102     2]
  [    2    14]]

 [[13096     3]
  [    4    17]]

 [[13037    10]
  [   20    53]]]

===scores report===
metrics	scores
Accuracy	0.7000
MCC	0.6827
log_loss	1.2302
f1 score weighted	0.7001
f1 score macro	0.6136
f1 score micro	0.7000
roc_auc ovr	0.9650
roc_auc ovo	0.9649
precision	0.7180
recall	0.7000

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2cd8775640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2cd8775880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2cd87758e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2cd87754f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.80      0.77       401
         1.0       0.89      0.40      0.55        20
         2.0       0.80      0.63      0.71        82
         3.0       0.00      0.00      0.00        15
         4.0       0.29      0.27      0.28        62
         5.0       0.64      0.67      0.65       278
         6.0       0.90      0.78      0.84        36
         7.0       0.80      0.32      0.46        25
         8.0       0.73      0.60      0.66        73
         9.0       0.48      0.45      0.46        29
        10.0       0.75      0.77      0.76       156
        11.0       0.55      0.59      0.57       168
        12.0       0.68      0.47      0.56        83
        13.0       0.33      0.09      0.14        54
        14.0       0.62      0.32      0.43        31
        15.0       0.51      0.34      0.41        53
        16.0       0.66      0.55      0.60        95
        17.0       0.78      0.86      0.82       884
        18.0       0.95      0.85      0.90        47
        19.0       0.72      0.73      0.72       781
        20.0       0.72      0.77      0.74       592
        21.0       0.80      0.77      0.78       385
        22.0       0.74      0.85      0.79       129
        23.0       0.83      0.82      0.82      1887
        24.0       0.91      0.76      0.83       168
        25.0       0.63      0.71      0.67      1295
        26.0       0.58      0.63      0.60       381
        27.0       0.75      0.46      0.57        13
        28.0       0.71      0.63      0.67       769
        29.0       0.57      0.54      0.56       372
        30.0       0.81      0.79      0.80       631
        31.0       0.75      0.27      0.40        11
        32.0       0.51      0.63      0.56       316
        33.0       0.64      0.68      0.66       405
        34.0       0.70      0.68      0.69        95
        35.0       0.33      0.12      0.18        25
        36.0       0.71      0.44      0.54        66
        37.0       0.80      0.73      0.76        22
        38.0       0.73      0.65      0.69       121
        39.0       0.85      0.81      0.83       113
        40.0       0.72      0.78      0.75       208
        41.0       0.80      0.73      0.76       194
        42.0       0.84      0.59      0.69        46
        43.0       0.87      0.93      0.90       431
        44.0       0.81      0.65      0.72        66
        45.0       0.87      0.80      0.83       489
        46.0       0.71      0.68      0.69        62
        47.0       0.86      0.93      0.89       263
        48.0       0.79      0.46      0.58        50
        49.0       0.89      0.81      0.85        31
        50.0       0.93      0.88      0.90        16
        51.0       0.83      0.86      0.84        22
        52.0       0.80      0.90      0.85        73

    accuracy                           0.73     13120
   macro avg       0.71      0.63      0.66     13120
weighted avg       0.73      0.73      0.73     13120


===confusion_matrix===

[[320   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  0   0  52 ...   0   0   0]
 ...
 [  0   0   0 ...  14   0   0]
 [  0   0   0 ...   0  19   2]
 [  0   0   0 ...   0   4  66]]

===multilabel confusion matrix===

[[[12611   108]
  [   81   320]]

 [[13099     1]
  [   12     8]]

 [[13025    13]
  [   30    52]]

 [[13101     4]
  [   15     0]]

 [[13016    42]
  [   45    17]]

 [[12738   104]
  [   93   185]]

 [[13081     3]
  [    8    28]]

 [[13093     2]
  [   17     8]]

 [[13031    16]
  [   29    44]]

 [[13077    14]
  [   16    13]]

 [[12924    40]
  [   36   120]]

 [[12870    82]
  [   69    99]]

 [[13019    18]
  [   44    39]]

 [[13056    10]
  [   49     5]]

 [[13083     6]
  [   21    10]]

 [[13050    17]
  [   35    18]]

 [[12998    27]
  [   43    52]]

 [[12022   214]
  [  121   763]]

 [[13071     2]
  [    7    40]]

 [[12116   223]
  [  211   570]]

 [[12351   177]
  [  139   453]]

 [[12659    76]
  [   88   297]]

 [[12952    39]
  [   19   110]]

 [[10922   311]
  [  345  1542]]

 [[12940    12]
  [   40   128]]

 [[11292   533]
  [  374   921]]

 [[12563   176]
  [  141   240]]

 [[13105     2]
  [    7     6]]

 [[12154   197]
  [  284   485]]

 [[12600   148]
  [  172   200]]

 [[12372   117]
  [  135   496]]

 [[13108     1]
  [    8     3]]

 [[12614   190]
  [  117   199]]

 [[12562   153]
  [  129   276]]

 [[12997    28]
  [   30    65]]

 [[13089     6]
  [   22     3]]

 [[13042    12]
  [   37    29]]

 [[13094     4]
  [    6    16]]

 [[12970    29]
  [   42    79]]

 [[12991    16]
  [   21    92]]

 [[12848    64]
  [   45   163]]

 [[12891    35]
  [   53   141]]

 [[13069     5]
  [   19    27]]

 [[12628    61]
  [   32   399]]

 [[13044    10]
  [   23    43]]

 [[12573    58]
  [   98   391]]

 [[13041    17]
  [   20    42]]

 [[12818    39]
  [   19   244]]

 [[13064     6]
  [   27    23]]

 [[13086     3]
  [    6    25]]

 [[13103     1]
  [    2    14]]

 [[13094     4]
  [    3    19]]

 [[13031    16]
  [    7    66]]]

===scores report===
metrics	scores
Accuracy	0.7338
MCC	0.7178
log_loss	1.1045
f1 score weighted	0.7315
f1 score macro	0.6551
f1 score micro	0.7338
roc_auc ovr	0.9709
roc_auc ovo	0.9700
precision	0.7349
recall	0.7338

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2cd8775640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2cd8775880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2cd87758e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2cd87754f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.68      0.82      0.74       402
         1.0       0.92      0.63      0.75        19
         2.0       0.55      0.61      0.58        82
         3.0       0.25      0.12      0.17        16
         4.0       0.39      0.32      0.35        62
         5.0       0.70      0.59      0.64       278
         6.0       0.79      0.64      0.71        36
         7.0       0.64      0.35      0.45        26
         8.0       0.69      0.48      0.56        73
         9.0       0.50      0.33      0.40        30
        10.0       0.69      0.72      0.70       156
        11.0       0.48      0.63      0.54       169
        12.0       0.54      0.59      0.56        83
        13.0       0.28      0.13      0.18        53
        14.0       0.74      0.45      0.56        31
        15.0       0.60      0.58      0.59        52
        16.0       0.61      0.55      0.58        95
        17.0       0.85      0.82      0.83       885
        18.0       0.84      0.79      0.82        48
        19.0       0.71      0.74      0.72       781
        20.0       0.77      0.68      0.73       592
        21.0       0.78      0.77      0.77       384
        22.0       0.74      0.78      0.76       128
        23.0       0.81      0.80      0.81      1887
        24.0       0.79      0.71      0.75       168
        25.0       0.68      0.68      0.68      1295
        26.0       0.55      0.64      0.59       381
        27.0       0.88      0.50      0.64        14
        28.0       0.60      0.66      0.63       769
        29.0       0.54      0.64      0.58       372
        30.0       0.86      0.73      0.79       630
        31.0       0.57      0.36      0.44        11
        32.0       0.60      0.61      0.60       316
        33.0       0.58      0.73      0.64       405
        34.0       0.67      0.74      0.70        95
        35.0       0.12      0.04      0.06        25
        36.0       0.79      0.48      0.60        65
        37.0       0.84      0.73      0.78        22
        38.0       0.64      0.64      0.64       121
        39.0       0.83      0.80      0.81       113
        40.0       0.75      0.78      0.77       208
        41.0       0.82      0.73      0.77       194
        42.0       0.79      0.49      0.61        47
        43.0       0.96      0.90      0.93       431
        44.0       0.80      0.71      0.75        66
        45.0       0.81      0.82      0.81       488
        46.0       0.80      0.70      0.75        63
        47.0       0.80      0.84      0.82       263
        48.0       0.58      0.37      0.45        49
        49.0       0.74      0.67      0.70        30
        50.0       0.94      1.00      0.97        15
        51.0       0.71      0.77      0.74        22
        52.0       0.76      0.81      0.78        73

    accuracy                           0.72     13119
   macro avg       0.69      0.63      0.65     13119
weighted avg       0.73      0.72      0.72     13119


===confusion_matrix===

[[328   0   0 ...   0   0   0]
 [  0  12   1 ...   0   0   0]
 [  1   0  50 ...   0   0   0]
 ...
 [  0   0   0 ...  15   0   0]
 [  0   0   0 ...   0  17   3]
 [  0   0   0 ...   0   6  59]]

===multilabel confusion matrix===

[[[12565   152]
  [   74   328]]

 [[13099     1]
  [    7    12]]

 [[12996    41]
  [   32    50]]

 [[13097     6]
  [   14     2]]

 [[13026    31]
  [   42    20]]

 [[12769    72]
  [  113   165]]

 [[13077     6]
  [   13    23]]

 [[13088     5]
  [   17     9]]

 [[13030    16]
  [   38    35]]

 [[13079    10]
  [   20    10]]

 [[12912    51]
  [   44   112]]

 [[12835   115]
  [   63   106]]

 [[12994    42]
  [   34    49]]

 [[13048    18]
  [   46     7]]

 [[13083     5]
  [   17    14]]

 [[13047    20]
  [   22    30]]

 [[12991    33]
  [   43    52]]

 [[12103   131]
  [  158   727]]

 [[13064     7]
  [   10    38]]

 [[12101   237]
  [  206   575]]

 [[12408   119]
  [  187   405]]

 [[12653    82]
  [   90   294]]

 [[12955    36]
  [   28   100]]

 [[10886   346]
  [  373  1514]]

 [[12920    31]
  [   49   119]]

 [[11402   422]
  [  412   883]]

 [[12538   200]
  [  138   243]]

 [[13104     1]
  [    7     7]]

 [[12014   336]
  [  262   507]]

 [[12543   204]
  [  135   237]]

 [[12414    75]
  [  167   463]]

 [[13105     3]
  [    7     4]]

 [[12673   130]
  [  123   193]]

 [[12497   217]
  [  110   295]]

 [[12989    35]
  [   25    70]]

 [[13087     7]
  [   24     1]]

 [[13046     8]
  [   34    31]]

 [[13094     3]
  [    6    16]]

 [[12954    44]
  [   44    77]]

 [[12987    19]
  [   23    90]]

 [[12856    55]
  [   45   163]]

 [[12895    30]
  [   53   141]]

 [[13066     6]
  [   24    23]]

 [[12673    15]
  [   41   390]]

 [[13041    12]
  [   19    47]]

 [[12534    97]
  [   87   401]]

 [[13045    11]
  [   19    44]]

 [[12800    56]
  [   41   222]]

 [[13057    13]
  [   31    18]]

 [[13082     7]
  [   10    20]]

 [[13103     1]
  [    0    15]]

 [[13090     7]
  [    5    17]]

 [[13027    19]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.7221
MCC	0.7056
log_loss	1.1683
f1 score weighted	0.7220
f1 score macro	0.6470
f1 score micro	0.7221
roc_auc ovr	0.9701
roc_auc ovo	0.9701
precision	0.7273
recall	0.7221

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6832317073170732	0.6666436809255466	1.321015576420273	0.6877418568779814	0.5674442683914209	0.6832317073170732	0.9648784953873676	0.9641192899561214	0.7205329433797507	0.6832317073170732
1	0.6947408536585366	0.6761812965399223	1.2904979236013394	0.6902496819780378	0.6073117769650945	0.6947408536585366	0.9650182724333469	0.9616075407998709	0.7146343696014731	0.6947408536585366
2	0.7	0.6827050465288499	1.2301630219849438	0.7001438742191325	0.6135712315906289	0.7	0.9650041879072564	0.9648661333704818	0.717974134395883	0.7
3	0.7338414634146342	0.7177649690449218	1.1045285768751625	0.7314515893690496	0.6550796446390006	0.7338414634146343	0.9708628307799048	0.9700249695166016	0.734905312430281	0.7338414634146342
4	0.7220824757984603	0.705595584467935	1.1682746669615984	0.7220171483261245	0.6470099742255822	0.7220824757984603	0.9701172845561529	0.9700844858551536	0.7272548480449386	0.7220824757984603
mean	0.7067793000377408	0.6897781155014352	1.2228959531686632	0.7063208301540651	0.6180833791623453	0.7067793000377408	0.9671762142128056	0.9661404838996459	0.7230603215704653	0.7067793000377408
std	0.01850362179772528	0.018992420327488175	0.07905013325747161	0.017432981954854477	0.03132468033498936	0.01850362179772531	0.002716429983402116	0.0033734595686832547	0.007227052897159728	0.01850362179772528

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 28605.0612 secs

