/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_hot_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ae8490430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ae84902e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ae84907c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ae84905e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.70      0.71       358
         1.0       0.00      0.00      0.00        12
         2.0       1.00      0.16      0.27        19
         3.0       0.22      0.34      0.27        80
         4.0       0.27      0.13      0.18        54
         5.0       0.00      0.00      0.00        58
         6.0       0.46      0.13      0.21        45
         7.0       0.65      0.31      0.42        48
         8.0       0.00      0.00      0.00        11
         9.0       0.58      0.33      0.42        21
        10.0       0.00      0.00      0.00        15
        11.0       0.96      0.61      0.75        36
        12.0       0.00      0.00      0.00        12
        13.0       0.93      0.56      0.70        25
        14.0       0.00      0.00      0.00        19
        15.0       1.00      0.36      0.53        22
        16.0       0.73      0.48      0.58        23
        17.0       0.94      0.67      0.78       119
        18.0       0.50      0.06      0.10        18
        19.0       0.00      0.00      0.00        12
        20.0       0.94      0.18      0.30        90
        21.0       0.00      0.00      0.00        12
        22.0       1.00      0.52      0.68        25
        23.0       0.00      0.00      0.00        12
        24.0       0.00      0.00      0.00        22
        25.0       1.00      0.11      0.19        38
        26.0       1.00      0.29      0.45        17
        27.0       1.00      0.03      0.06        35
        28.0       0.00      0.00      0.00        11
        29.0       0.73      0.22      0.34        36
        30.0       0.59      0.62      0.61        32
        31.0       0.96      0.68      0.80        38
        32.0       0.58      0.84      0.68       747
        33.0       0.98      0.82      0.90        74
        34.0       0.79      0.88      0.83        59
        35.0       0.44      0.46      0.45        48
        36.0       0.63      0.48      0.54       502
        37.0       0.77      0.64      0.70       241
        38.0       1.00      0.12      0.22        33
        39.0       0.41      0.77      0.53       344
        40.0       0.45      0.63      0.52       191
        41.0       0.88      0.44      0.58        32
        42.0       0.66      0.70      0.68       384
        43.0       0.61      0.68      0.64       118
        44.0       0.80      0.63      0.70       436
        45.0       0.84      0.75      0.79        48
        46.0       0.79      0.82      0.80       402
        47.0       0.00      0.00      0.00        17
        48.0       0.68      0.50      0.58        42
        49.0       0.97      0.87      0.92        78
        50.0       0.85      0.85      0.85       172
        51.0       0.43      0.15      0.22        20
        52.0       0.45      0.70      0.55       499
        53.0       0.65      0.73      0.69       100
        54.0       0.00      0.00      0.00        11
        55.0       0.78      0.63      0.70       103
        56.0       0.75      0.17      0.27        18
        57.0       0.00      0.00      0.00        10
        58.0       0.91      0.94      0.93        34
        59.0       0.41      0.66      0.51       231
        60.0       0.84      0.62      0.71        58
        61.0       0.00      0.00      0.00        30
        62.0       0.70      0.40      0.51        48
        63.0       0.43      0.12      0.19        50
        64.0       0.95      0.62      0.75        34
        65.0       0.70      0.76      0.73       155
        66.0       0.80      0.29      0.42        14
        67.0       0.54      0.61      0.57       314
        68.0       0.14      0.02      0.03        63
        69.0       0.46      0.57      0.51       308
        70.0       0.71      0.40      0.51        68
        71.0       0.91      0.15      0.26        66
        72.0       0.00      0.00      0.00        14
        73.0       0.00      0.00      0.00        25
        74.0       0.00      0.00      0.00        18
        75.0       1.00      0.05      0.10        60
        76.0       0.68      0.48      0.56       205
        77.0       0.86      0.08      0.14        77
        78.0       0.78      0.59      0.67        59
        79.0       0.75      0.33      0.46       139
        80.0       0.87      0.48      0.62        42
        81.0       0.30      0.23      0.26       175
        82.0       0.38      0.07      0.12        43
        83.0       0.25      0.04      0.07        26
        84.0       0.41      0.39      0.40       106
        85.0       1.00      0.21      0.35        14
        86.0       0.76      0.63      0.69       242
        87.0       0.55      0.81      0.65       309
        88.0       0.96      0.43      0.60        58
        89.0       0.00      0.00      0.00        11
        90.0       0.15      0.61      0.24       187
        91.0       0.83      0.11      0.19        46
        92.0       0.00      0.00      0.00        40
        93.0       0.60      0.28      0.38        32
        94.0       0.48      0.50      0.49       289
        95.0       0.00      0.00      0.00        31
        96.0       0.85      0.31      0.46        74
        97.0       0.00      0.00      0.00        27
        98.0       0.86      0.49      0.62        37
        99.0       1.00      0.92      0.96        24
       100.0       0.00      0.00      0.00        25
       101.0       0.59      0.34      0.43        65
       102.0       0.89      0.77      0.83        22
       103.0       0.57      0.62      0.60        64
       104.0       0.82      0.23      0.35        40
       105.0       1.00      0.83      0.91        12
       106.0       0.69      0.68      0.68       114
       107.0       0.86      0.70      0.77       161
       108.0       0.00      0.00      0.00        24
       109.0       0.92      0.65      0.76        52
       110.0       0.00      0.00      0.00        15
       111.0       0.78      0.55      0.65       123
       112.0       0.92      0.29      0.44        42
       113.0       0.59      0.93      0.72       430
       114.0       0.96      0.69      0.80        65
       115.0       0.92      0.39      0.55        31
       116.0       0.81      0.68      0.74       173
       117.0       0.88      0.90      0.89        31
       118.0       0.97      0.63      0.77       117
       119.0       0.83      0.71      0.77       136
       120.0       0.93      0.60      0.73        62
       121.0       0.66      0.84      0.74       224
       122.0       0.89      0.71      0.79        35
       123.0       0.96      0.73      0.83        37
       124.0       0.74      0.45      0.56        31
       125.0       0.81      0.87      0.84        15
       126.0       0.85      0.52      0.65        21
       127.0       0.66      0.90      0.76        73

    accuracy                           0.59     12227
   macro avg       0.59      0.41      0.44     12227
weighted avg       0.63      0.59      0.58     12227


===confusion_matrix===

[[249   0   0 ...   0   0   0]
 [  0   0   0 ...   0   0   0]
 [  0   0   3 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  11   9]
 [  0   0   0 ...   2   2  66]]

===multilabel confusion matrix===

[[[11773    96]
  [  109   249]]

 [[12215     0]
  [   12     0]]

 [[12208     0]
  [   16     3]]

 [[12053    94]
  [   53    27]]

 [[12154    19]
  [   47     7]]

 [[12169     0]
  [   58     0]]

 [[12175     7]
  [   39     6]]

 [[12171     8]
  [   33    15]]

 [[12216     0]
  [   11     0]]

 [[12201     5]
  [   14     7]]

 [[12212     0]
  [   15     0]]

 [[12190     1]
  [   14    22]]

 [[12215     0]
  [   12     0]]

 [[12201     1]
  [   11    14]]

 [[12208     0]
  [   19     0]]

 [[12205     0]
  [   14     8]]

 [[12200     4]
  [   12    11]]

 [[12103     5]
  [   39    80]]

 [[12208     1]
  [   17     1]]

 [[12215     0]
  [   12     0]]

 [[12136     1]
  [   74    16]]

 [[12215     0]
  [   12     0]]

 [[12202     0]
  [   12    13]]

 [[12215     0]
  [   12     0]]

 [[12205     0]
  [   22     0]]

 [[12189     0]
  [   34     4]]

 [[12210     0]
  [   12     5]]

 [[12192     0]
  [   34     1]]

 [[12216     0]
  [   11     0]]

 [[12188     3]
  [   28     8]]

 [[12181    14]
  [   12    20]]

 [[12188     1]
  [   12    26]]

 [[11022   458]
  [  120   627]]

 [[12152     1]
  [   13    61]]

 [[12154    14]
  [    7    52]]

 [[12151    28]
  [   26    22]]

 [[11580   145]
  [  260   242]]

 [[11939    47]
  [   86   155]]

 [[12194     0]
  [   29     4]]

 [[11494   389]
  [   78   266]]

 [[11886   150]
  [   70   121]]

 [[12193     2]
  [   18    14]]

 [[11703   140]
  [  116   268]]

 [[12057    52]
  [   38    80]]

 [[11721    70]
  [  161   275]]

 [[12172     7]
  [   12    36]]

 [[11737    88]
  [   73   329]]

 [[12210     0]
  [   17     0]]

 [[12175    10]
  [   21    21]]

 [[12147     2]
  [   10    68]]

 [[12030    25]
  [   26   146]]

 [[12203     4]
  [   17     3]]

 [[11296   432]
  [  148   351]]

 [[12088    39]
  [   27    73]]

 [[12216     0]
  [   11     0]]

 [[12106    18]
  [   38    65]]

 [[12208     1]
  [   15     3]]

 [[12217     0]
  [   10     0]]

 [[12190     3]
  [    2    32]]

 [[11781   215]
  [   79   152]]

 [[12162     7]
  [   22    36]]

 [[12197     0]
  [   30     0]]

 [[12171     8]
  [   29    19]]

 [[12169     8]
  [   44     6]]

 [[12192     1]
  [   13    21]]

 [[12021    51]
  [   37   118]]

 [[12212     1]
  [   10     4]]

 [[11752   161]
  [  123   191]]

 [[12158     6]
  [   62     1]]

 [[11712   207]
  [  133   175]]

 [[12148    11]
  [   41    27]]

 [[12160     1]
  [   56    10]]

 [[12213     0]
  [   14     0]]

 [[12201     1]
  [   25     0]]

 [[12209     0]
  [   18     0]]

 [[12167     0]
  [   57     3]]

 [[11975    47]
  [  107    98]]

 [[12149     1]
  [   71     6]]

 [[12158    10]
  [   24    35]]

 [[12073    15]
  [   93    46]]

 [[12182     3]
  [   22    20]]

 [[11957    95]
  [  134    41]]

 [[12179     5]
  [   40     3]]

 [[12198     3]
  [   25     1]]

 [[12063    58]
  [   65    41]]

 [[12213     0]
  [   11     3]]

 [[11936    49]
  [   89   153]]

 [[11710   208]
  [   58   251]]

 [[12168     1]
  [   33    25]]

 [[12215     1]
  [   11     0]]

 [[11390   650]
  [   72   115]]

 [[12180     1]
  [   41     5]]

 [[12187     0]
  [   40     0]]

 [[12189     6]
  [   23     9]]

 [[11781   157]
  [  144   145]]

 [[12196     0]
  [   31     0]]

 [[12149     4]
  [   51    23]]

 [[12199     1]
  [   27     0]]

 [[12187     3]
  [   19    18]]

 [[12203     0]
  [    2    22]]

 [[12202     0]
  [   25     0]]

 [[12147    15]
  [   43    22]]

 [[12203     2]
  [    5    17]]

 [[12133    30]
  [   24    40]]

 [[12185     2]
  [   31     9]]

 [[12215     0]
  [    2    10]]

 [[12079    34]
  [   37    77]]

 [[12047    19]
  [   48   113]]

 [[12203     0]
  [   24     0]]

 [[12172     3]
  [   18    34]]

 [[12212     0]
  [   15     0]]

 [[12085    19]
  [   55    68]]

 [[12184     1]
  [   30    12]]

 [[11519   278]
  [   30   400]]

 [[12160     2]
  [   20    45]]

 [[12195     1]
  [   19    12]]

 [[12026    28]
  [   56   117]]

 [[12192     4]
  [    3    28]]

 [[12108     2]
  [   43    74]]

 [[12071    20]
  [   39    97]]

 [[12162     3]
  [   25    37]]

 [[11905    98]
  [   35   189]]

 [[12189     3]
  [   10    25]]

 [[12189     1]
  [   10    27]]

 [[12191     5]
  [   17    14]]

 [[12209     3]
  [    2    13]]

 [[12204     2]
  [   10    11]]

 [[12120    34]
  [    7    66]]]

===scores report===
metrics	scores
Accuracy	0.5919
MCC	0.5831
log_loss	1.7441
f1 score weighted	0.5759
f1 score macro	0.4446
f1 score micro	0.5919
roc_auc ovr	0.9615
roc_auc ovo	0.9564
precision	0.6296
recall	0.5919

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ae8490430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ae84902e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ae84907c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ae84905e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.67      0.75      0.71       357
         1.0       1.00      0.08      0.15        12
         2.0       0.76      0.68      0.72        19
         3.0       0.56      0.19      0.28        80
         4.0       0.09      0.04      0.05        54
         5.0       0.50      0.03      0.06        58
         6.0       0.24      0.18      0.21        44
         7.0       0.68      0.58      0.63        48
         8.0       0.00      0.00      0.00        11
         9.0       0.59      0.62      0.60        21
        10.0       0.00      0.00      0.00        15
        11.0       0.72      0.64      0.68        36
        12.0       0.25      0.08      0.12        12
        13.0       0.93      0.56      0.70        25
        14.0       1.00      0.05      0.10        20
        15.0       0.90      0.39      0.55        23
        16.0       0.60      0.39      0.47        23
        17.0       0.82      0.54      0.65       119
        18.0       1.00      0.24      0.38        17
        19.0       0.00      0.00      0.00        13
        20.0       0.75      0.20      0.32        90
        21.0       0.00      0.00      0.00        12
        22.0       0.82      0.56      0.67        25
        23.0       0.00      0.00      0.00        12
        24.0       0.00      0.00      0.00        22
        25.0       0.93      0.35      0.51        37
        26.0       1.00      1.00      1.00        18
        27.0       0.00      0.00      0.00        35
        28.0       1.00      0.08      0.15        12
        29.0       0.50      0.27      0.35        37
        30.0       0.58      0.56      0.57        32
        31.0       0.83      0.51      0.63        39
        32.0       0.66      0.82      0.73       746
        33.0       0.86      0.86      0.86        74
        34.0       0.77      0.81      0.79        58
        35.0       0.80      0.42      0.55        48
        36.0       0.51      0.59      0.55       502
        37.0       0.53      0.66      0.59       241
        38.0       0.60      0.18      0.28        33
        39.0       0.40      0.74      0.52       344
        40.0       0.72      0.63      0.67       191
        41.0       0.79      0.35      0.49        31
        42.0       0.65      0.65      0.65       384
        43.0       0.76      0.81      0.78       118
        44.0       0.69      0.69      0.69       436
        45.0       0.86      0.79      0.83        48
        46.0       0.72      0.85      0.78       402
        47.0       1.00      0.12      0.21        17
        48.0       0.60      0.57      0.59        42
        49.0       0.87      0.84      0.86        77
        50.0       0.93      0.76      0.84       172
        51.0       1.00      0.60      0.75        20
        52.0       0.46      0.64      0.53       499
        53.0       0.75      0.57      0.64        99
        54.0       0.00      0.00      0.00        11
        55.0       0.83      0.55      0.66       103
        56.0       0.00      0.00      0.00        18
        57.0       0.00      0.00      0.00        11
        58.0       0.91      0.91      0.91        34
        59.0       0.47      0.61      0.53       231
        60.0       0.82      0.71      0.76        58
        61.0       0.00      0.00      0.00        30
        62.0       0.67      0.21      0.32        48
        63.0       0.00      0.00      0.00        49
        64.0       0.96      0.65      0.77        34
        65.0       0.69      0.68      0.68       154
        66.0       0.00      0.00      0.00        14
        67.0       0.56      0.56      0.56       314
        68.0       0.00      0.00      0.00        63
        69.0       0.39      0.70      0.50       308
        70.0       0.90      0.28      0.42        69
        71.0       0.45      0.23      0.30        66
        72.0       0.00      0.00      0.00        14
        73.0       0.91      0.40      0.56        25
        74.0       0.00      0.00      0.00        18
        75.0       0.00      0.00      0.00        59
        76.0       0.49      0.62      0.55       205
        77.0       0.92      0.14      0.25        77
        78.0       0.68      0.46      0.55        59
        79.0       0.46      0.47      0.47       139
        80.0       0.85      0.56      0.68        41
        81.0       0.22      0.41      0.28       175
        82.0       0.33      0.12      0.17        43
        83.0       0.25      0.04      0.07        26
        84.0       0.35      0.35      0.35       105
        85.0       1.00      0.36      0.53        14
        86.0       0.54      0.64      0.59       242
        87.0       0.78      0.69      0.73       309
        88.0       0.75      0.47      0.57        58
        89.0       0.00      0.00      0.00        11
        90.0       0.36      0.40      0.38       187
        91.0       0.78      0.15      0.25        46
        92.0       0.00      0.00      0.00        40
        93.0       0.75      0.27      0.40        33
        94.0       0.33      0.60      0.43       289
        95.0       0.00      0.00      0.00        32
        96.0       0.96      0.58      0.72        74
        97.0       0.57      0.15      0.24        27
        98.0       0.88      0.41      0.56        37
        99.0       0.95      0.83      0.89        24
       100.0       0.00      0.00      0.00        26
       101.0       0.75      0.28      0.40        65
       102.0       0.59      0.45      0.51        22
       103.0       0.74      0.61      0.67        64
       104.0       0.71      0.12      0.21        40
       105.0       1.00      0.54      0.70        13
       106.0       0.74      0.73      0.73       113
       107.0       0.77      0.73      0.75       162
       108.0       0.00      0.00      0.00        24
       109.0       0.91      0.77      0.83        52
       110.0       1.00      0.80      0.89        15
       111.0       0.79      0.62      0.69       123
       112.0       0.91      0.24      0.38        41
       113.0       0.72      0.88      0.79       430
       114.0       0.98      0.71      0.82        65
       115.0       0.88      0.45      0.60        31
       116.0       0.78      0.71      0.74       173
       117.0       1.00      0.77      0.87        30
       118.0       0.88      0.85      0.86       118
       119.0       0.66      0.71      0.68       136
       120.0       0.95      0.34      0.51        61
       121.0       0.67      0.83      0.74       225
       122.0       0.86      0.89      0.87        35
       123.0       0.73      0.71      0.72        38
       124.0       0.56      0.61      0.58        31
       125.0       0.59      0.81      0.68        16
       126.0       0.76      0.76      0.76        21
       127.0       0.70      0.70      0.70        73

    accuracy                           0.60     12227
   macro avg       0.59      0.43      0.47     12227
weighted avg       0.61      0.60      0.58     12227


===confusion_matrix===

[[269   0   0 ...   0   0   0]
 [  1   1   0 ...   0   0   0]
 [  0   0  13 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   1  16   3]
 [  0   0   0 ...   3   5  51]]

===multilabel confusion matrix===

[[[11740   130]
  [   88   269]]

 [[12215     0]
  [   11     1]]

 [[12204     4]
  [    6    13]]

 [[12135    12]
  [   65    15]]

 [[12152    21]
  [   52     2]]

 [[12167     2]
  [   56     2]]

 [[12158    25]
  [   36     8]]

 [[12166    13]
  [   20    28]]

 [[12216     0]
  [   11     0]]

 [[12197     9]
  [    8    13]]

 [[12210     2]
  [   15     0]]

 [[12182     9]
  [   13    23]]

 [[12212     3]
  [   11     1]]

 [[12201     1]
  [   11    14]]

 [[12207     0]
  [   19     1]]

 [[12203     1]
  [   14     9]]

 [[12198     6]
  [   14     9]]

 [[12094    14]
  [   55    64]]

 [[12210     0]
  [   13     4]]

 [[12214     0]
  [   13     0]]

 [[12131     6]
  [   72    18]]

 [[12215     0]
  [   12     0]]

 [[12199     3]
  [   11    14]]

 [[12215     0]
  [   12     0]]

 [[12205     0]
  [   22     0]]

 [[12189     1]
  [   24    13]]

 [[12209     0]
  [    0    18]]

 [[12192     0]
  [   35     0]]

 [[12215     0]
  [   11     1]]

 [[12180    10]
  [   27    10]]

 [[12182    13]
  [   14    18]]

 [[12184     4]
  [   19    20]]

 [[11169   312]
  [  138   608]]

 [[12143    10]
  [   10    64]]

 [[12155    14]
  [   11    47]]

 [[12174     5]
  [   28    20]]

 [[11444   281]
  [  205   297]]

 [[11843   143]
  [   81   160]]

 [[12190     4]
  [   27     6]]

 [[11504   379]
  [   88   256]]

 [[11990    46]
  [   71   120]]

 [[12193     3]
  [   20    11]]

 [[11706   137]
  [  135   249]]

 [[12078    31]
  [   22    96]]

 [[11655   136]
  [  133   303]]

 [[12173     6]
  [   10    38]]

 [[11694   131]
  [   60   342]]

 [[12210     0]
  [   15     2]]

 [[12169    16]
  [   18    24]]

 [[12140    10]
  [   12    65]]

 [[12045    10]
  [   41   131]]

 [[12207     0]
  [    8    12]]

 [[11350   378]
  [  181   318]]

 [[12109    19]
  [   43    56]]

 [[12215     1]
  [   11     0]]

 [[12112    12]
  [   46    57]]

 [[12208     1]
  [   18     0]]

 [[12216     0]
  [   11     0]]

 [[12190     3]
  [    3    31]]

 [[11836   160]
  [   89   142]]

 [[12160     9]
  [   17    41]]

 [[12197     0]
  [   30     0]]

 [[12174     5]
  [   38    10]]

 [[12178     0]
  [   49     0]]

 [[12192     1]
  [   12    22]]

 [[12025    48]
  [   49   105]]

 [[12213     0]
  [   14     0]]

 [[11775   138]
  [  139   175]]

 [[12148    16]
  [   63     0]]

 [[11580   339]
  [   93   215]]

 [[12156     2]
  [   50    19]]

 [[12143    18]
  [   51    15]]

 [[12213     0]
  [   14     0]]

 [[12201     1]
  [   15    10]]

 [[12209     0]
  [   18     0]]

 [[12168     0]
  [   59     0]]

 [[11892   130]
  [   78   127]]

 [[12149     1]
  [   66    11]]

 [[12155    13]
  [   32    27]]

 [[12013    75]
  [   74    65]]

 [[12182     4]
  [   18    23]]

 [[11794   258]
  [  104    71]]

 [[12174    10]
  [   38     5]]

 [[12198     3]
  [   25     1]]

 [[12054    68]
  [   68    37]]

 [[12213     0]
  [    9     5]]

 [[11852   133]
  [   86   156]]

 [[11859    59]
  [   96   213]]

 [[12160     9]
  [   31    27]]

 [[12216     0]
  [   11     0]]

 [[11907   133]
  [  113    74]]

 [[12179     2]
  [   39     7]]

 [[12187     0]
  [   40     0]]

 [[12191     3]
  [   24     9]]

 [[11593   345]
  [  117   172]]

 [[12195     0]
  [   32     0]]

 [[12151     2]
  [   31    43]]

 [[12197     3]
  [   23     4]]

 [[12188     2]
  [   22    15]]

 [[12202     1]
  [    4    20]]

 [[12201     0]
  [   26     0]]

 [[12156     6]
  [   47    18]]

 [[12198     7]
  [   12    10]]

 [[12149    14]
  [   25    39]]

 [[12185     2]
  [   35     5]]

 [[12214     0]
  [    6     7]]

 [[12085    29]
  [   31    82]]

 [[12030    35]
  [   44   118]]

 [[12203     0]
  [   24     0]]

 [[12171     4]
  [   12    40]]

 [[12212     0]
  [    3    12]]

 [[12084    20]
  [   47    76]]

 [[12185     1]
  [   31    10]]

 [[11646   151]
  [   50   380]]

 [[12161     1]
  [   19    46]]

 [[12194     2]
  [   17    14]]

 [[12020    34]
  [   51   122]]

 [[12197     0]
  [    7    23]]

 [[12095    14]
  [   18   100]]

 [[12042    49]
  [   40    96]]

 [[12165     1]
  [   40    21]]

 [[11909    93]
  [   38   187]]

 [[12187     5]
  [    4    31]]

 [[12179    10]
  [   11    27]]

 [[12181    15]
  [   12    19]]

 [[12202     9]
  [    3    13]]

 [[12201     5]
  [    5    16]]

 [[12132    22]
  [   22    51]]]

===scores report===
metrics	scores
Accuracy	0.5995
MCC	0.5901
log_loss	1.7372
f1 score weighted	0.5817
f1 score macro	0.4671
f1 score micro	0.5995
roc_auc ovr	0.9592
roc_auc ovo	0.9545
precision	0.6117
recall	0.5995

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ae8490430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ae84902e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ae84907c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ae84905e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.42      0.83      0.55       357
         1.0       0.50      0.08      0.13        13
         2.0       0.00      0.00      0.00        19
         3.0       0.31      0.29      0.30        79
         4.0       0.26      0.11      0.15        55
         5.0       0.33      0.02      0.03        59
         6.0       0.57      0.09      0.16        44
         7.0       0.65      0.35      0.46        48
         8.0       0.00      0.00      0.00        10
         9.0       0.62      0.48      0.54        21
        10.0       0.80      0.27      0.40        15
        11.0       0.55      0.78      0.64        36
        12.0       0.00      0.00      0.00        12
        13.0       0.83      0.60      0.70        25
        14.0       0.00      0.00      0.00        20
        15.0       0.58      0.32      0.41        22
        16.0       0.71      0.52      0.60        23
        17.0       0.58      0.90      0.70       118
        18.0       0.50      0.06      0.10        18
        19.0       0.00      0.00      0.00        13
        20.0       0.36      0.04      0.08        89
        21.0       0.00      0.00      0.00        12
        22.0       0.81      0.54      0.65        24
        23.0       0.00      0.00      0.00        12
        24.0       0.00      0.00      0.00        23
        25.0       0.37      0.27      0.31        37
        26.0       0.89      0.94      0.91        17
        27.0       0.62      0.14      0.23        36
        28.0       0.00      0.00      0.00        12
        29.0       0.38      0.49      0.42        37
        30.0       0.40      0.50      0.44        32
        31.0       0.76      0.72      0.74        39
        32.0       0.84      0.76      0.80       746
        33.0       0.68      0.81      0.74        74
        34.0       0.94      0.83      0.88        58
        35.0       0.82      0.48      0.61        48
        36.0       0.50      0.55      0.52       502
        37.0       0.74      0.56      0.64       240
        38.0       0.68      0.58      0.62        33
        39.0       0.62      0.55      0.59       344
        40.0       0.86      0.64      0.74       191
        41.0       1.00      0.42      0.59        31
        42.0       0.68      0.62      0.65       384
        43.0       0.38      0.82      0.52       117
        44.0       0.68      0.64      0.66       436
        45.0       0.97      0.67      0.80        49
        46.0       0.69      0.87      0.77       402
        47.0       1.00      0.12      0.21        17
        48.0       0.81      0.62      0.70        42
        49.0       0.93      0.87      0.90        77
        50.0       0.88      0.92      0.90       172
        51.0       0.58      0.37      0.45        19
        52.0       0.59      0.58      0.59       499
        53.0       0.98      0.60      0.74        99
        54.0       0.75      0.27      0.40        11
        55.0       0.50      0.73      0.59       103
        56.0       0.86      0.33      0.48        18
        57.0       0.00      0.00      0.00        11
        58.0       0.94      0.91      0.93        35
        59.0       0.48      0.49      0.48       231
        60.0       0.98      0.77      0.86        57
        61.0       0.00      0.00      0.00        29
        62.0       0.72      0.27      0.39        48
        63.0       0.11      0.02      0.03        49
        64.0       1.00      0.56      0.72        34
        65.0       0.92      0.59      0.72       155
        66.0       0.00      0.00      0.00        14
        67.0       0.44      0.64      0.52       315
        68.0       0.00      0.00      0.00        63
        69.0       0.38      0.78      0.51       307
        70.0       0.88      0.30      0.45        69
        71.0       0.33      0.21      0.26        66
        72.0       0.00      0.00      0.00        15
        73.0       0.75      0.24      0.36        25
        74.0       0.00      0.00      0.00        18
        75.0       0.00      0.00      0.00        59
        76.0       0.61      0.64      0.62       206
        77.0       0.70      0.28      0.40        76
        78.0       0.86      0.41      0.55        59
        79.0       0.71      0.40      0.51       140
        80.0       0.85      0.52      0.65        42
        81.0       0.41      0.35      0.38       175
        82.0       0.55      0.14      0.22        43
        83.0       1.00      0.08      0.15        25
        84.0       0.43      0.31      0.36       105
        85.0       0.50      0.29      0.36        14
        86.0       0.88      0.57      0.69       242
        87.0       0.78      0.67      0.72       310
        88.0       0.81      0.44      0.57        59
        89.0       0.00      0.00      0.00        11
        90.0       0.38      0.30      0.33       187
        91.0       0.64      0.20      0.30        46
        92.0       0.00      0.00      0.00        40
        93.0       0.50      0.09      0.15        33
        94.0       0.32      0.65      0.43       289
        95.0       0.00      0.00      0.00        32
        96.0       0.64      0.65      0.65        75
        97.0       0.25      0.07      0.11        28
        98.0       0.86      0.51      0.64        37
        99.0       0.80      0.87      0.83        23
       100.0       0.00      0.00      0.00        25
       101.0       0.79      0.29      0.42        66
       102.0       0.64      0.76      0.70        21
       103.0       0.52      0.80      0.63        65
       104.0       0.58      0.28      0.37        40
       105.0       0.80      0.67      0.73        12
       106.0       0.74      0.73      0.74       113
       107.0       0.85      0.65      0.74       162
       108.0       0.75      0.12      0.21        24
       109.0       0.66      0.81      0.73        53
       110.0       1.00      0.57      0.73        14
       111.0       0.81      0.54      0.65       123
       112.0       0.67      0.34      0.45        41
       113.0       0.56      0.93      0.70       429
       114.0       0.80      0.69      0.74        65
       115.0       0.49      0.55      0.52        31
       116.0       0.89      0.76      0.82       173
       117.0       1.00      0.80      0.89        30
       118.0       0.65      0.85      0.73       117
       119.0       0.35      0.91      0.51       136
       120.0       0.54      0.49      0.51        61
       121.0       0.74      0.91      0.82       225
       122.0       0.84      0.77      0.81        35
       123.0       0.59      0.58      0.59        38
       124.0       0.54      0.47      0.50        30
       125.0       0.67      0.75      0.71        16
       126.0       0.62      0.82      0.71        22
       127.0       0.67      0.70      0.68        73

    accuracy                           0.60     12226
   macro avg       0.56      0.44      0.46     12226
weighted avg       0.62      0.60      0.58     12226


===confusion_matrix===

[[295   1   0 ...   0   0   0]
 [  5   1   0 ...   0   0   0]
 [  0   0   0 ...   0   0   0]
 ...
 [  0   0   0 ...  12   2   1]
 [  0   0   0 ...   0  18   4]
 [  0   0   0 ...   1   5  51]]

===multilabel confusion matrix===

[[[11455   414]
  [   62   295]]

 [[12212     1]
  [   12     1]]

 [[12206     1]
  [   19     0]]

 [[12095    52]
  [   56    23]]

 [[12154    17]
  [   49     6]]

 [[12165     2]
  [   58     1]]

 [[12179     3]
  [   40     4]]

 [[12169     9]
  [   31    17]]

 [[12216     0]
  [   10     0]]

 [[12199     6]
  [   11    10]]

 [[12210     1]
  [   11     4]]

 [[12167    23]
  [    8    28]]

 [[12214     0]
  [   12     0]]

 [[12198     3]
  [   10    15]]

 [[12204     2]
  [   20     0]]

 [[12199     5]
  [   15     7]]

 [[12198     5]
  [   11    12]]

 [[12031    77]
  [   12   106]]

 [[12207     1]
  [   17     1]]

 [[12211     2]
  [   13     0]]

 [[12130     7]
  [   85     4]]

 [[12214     0]
  [   12     0]]

 [[12199     3]
  [   11    13]]

 [[12214     0]
  [   12     0]]

 [[12203     0]
  [   23     0]]

 [[12172    17]
  [   27    10]]

 [[12207     2]
  [    1    16]]

 [[12187     3]
  [   31     5]]

 [[12214     0]
  [   12     0]]

 [[12159    30]
  [   19    18]]

 [[12170    24]
  [   16    16]]

 [[12178     9]
  [   11    28]]

 [[11375   105]
  [  179   567]]

 [[12124    28]
  [   14    60]]

 [[12165     3]
  [   10    48]]

 [[12173     5]
  [   25    23]]

 [[11445   279]
  [  227   275]]

 [[11939    47]
  [  105   135]]

 [[12184     9]
  [   14    19]]

 [[11768   114]
  [  154   190]]

 [[12015    20]
  [   68   123]]

 [[12195     0]
  [   18    13]]

 [[11729   113]
  [  147   237]]

 [[11953   156]
  [   21    96]]

 [[11657   133]
  [  155   281]]

 [[12176     1]
  [   16    33]]

 [[11670   154]
  [   52   350]]

 [[12209     0]
  [   15     2]]

 [[12178     6]
  [   16    26]]

 [[12144     5]
  [   10    67]]

 [[12032    22]
  [   14   158]]

 [[12202     5]
  [   12     7]]

 [[11528   199]
  [  210   289]]

 [[12126     1]
  [   40    59]]

 [[12214     1]
  [    8     3]]

 [[12048    75]
  [   28    75]]

 [[12207     1]
  [   12     6]]

 [[12215     0]
  [   11     0]]

 [[12189     2]
  [    3    32]]

 [[11871   124]
  [  118   113]]

 [[12168     1]
  [   13    44]]

 [[12197     0]
  [   29     0]]

 [[12173     5]
  [   35    13]]

 [[12169     8]
  [   48     1]]

 [[12192     0]
  [   15    19]]

 [[12063     8]
  [   63    92]]

 [[12212     0]
  [   14     0]]

 [[11656   255]
  [  113   202]]

 [[12158     5]
  [   63     0]]

 [[11522   397]
  [   67   240]]

 [[12154     3]
  [   48    21]]

 [[12132    28]
  [   52    14]]

 [[12211     0]
  [   15     0]]

 [[12199     2]
  [   19     6]]

 [[12208     0]
  [   18     0]]

 [[12167     0]
  [   59     0]]

 [[11935    85]
  [   75   131]]

 [[12141     9]
  [   55    21]]

 [[12163     4]
  [   35    24]]

 [[12063    23]
  [   84    56]]

 [[12180     4]
  [   20    22]]

 [[11961    90]
  [  113    62]]

 [[12178     5]
  [   37     6]]

 [[12201     0]
  [   23     2]]

 [[12078    43]
  [   72    33]]

 [[12208     4]
  [   10     4]]

 [[11965    19]
  [  104   138]]

 [[11857    59]
  [  103   207]]

 [[12161     6]
  [   33    26]]

 [[12215     0]
  [   11     0]]

 [[11946    93]
  [  131    56]]

 [[12175     5]
  [   37     9]]

 [[12186     0]
  [   40     0]]

 [[12190     3]
  [   30     3]]

 [[11535   402]
  [  102   187]]

 [[12192     2]
  [   32     0]]

 [[12124    27]
  [   26    49]]

 [[12192     6]
  [   26     2]]

 [[12186     3]
  [   18    19]]

 [[12198     5]
  [    3    20]]

 [[12201     0]
  [   25     0]]

 [[12155     5]
  [   47    19]]

 [[12196     9]
  [    5    16]]

 [[12113    48]
  [   13    52]]

 [[12178     8]
  [   29    11]]

 [[12212     2]
  [    4     8]]

 [[12084    29]
  [   30    83]]

 [[12046    18]
  [   56   106]]

 [[12201     1]
  [   21     3]]

 [[12151    22]
  [   10    43]]

 [[12212     0]
  [    6     8]]

 [[12088    15]
  [   57    66]]

 [[12178     7]
  [   27    14]]

 [[11477   320]
  [   28   401]]

 [[12150    11]
  [   20    45]]

 [[12177    18]
  [   14    17]]

 [[12037    16]
  [   41   132]]

 [[12196     0]
  [    6    24]]

 [[12055    54]
  [   18    99]]

 [[11860   230]
  [   12   124]]

 [[12139    26]
  [   31    30]]

 [[11930    71]
  [   20   205]]

 [[12186     5]
  [    8    27]]

 [[12173    15]
  [   16    22]]

 [[12184    12]
  [   16    14]]

 [[12204     6]
  [    4    12]]

 [[12193    11]
  [    4    18]]

 [[12128    25]
  [   22    51]]]

===scores report===
metrics	scores
Accuracy	0.5976
MCC	0.5892
log_loss	1.7607
f1 score weighted	0.5803
f1 score macro	0.4607
f1 score micro	0.5976
roc_auc ovr	0.9602
roc_auc ovo	0.9562
precision	0.6169
recall	0.5976

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ae8490430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ae84902e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ae84907c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ae84905e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.46      0.84      0.59       358
         1.0       0.33      0.08      0.13        12
         2.0       0.33      0.06      0.10        18
         3.0       0.31      0.25      0.28        79
         4.0       0.22      0.11      0.15        55
         5.0       0.00      0.00      0.00        58
         6.0       0.50      0.20      0.29        45
         7.0       0.66      0.49      0.56        47
         8.0       0.00      0.00      0.00        10
         9.0       0.62      0.62      0.62        21
        10.0       0.50      0.07      0.12        15
        11.0       0.79      0.75      0.77        36
        12.0       0.00      0.00      0.00        12
        13.0       0.71      0.40      0.51        25
        14.0       0.00      0.00      0.00        20
        15.0       0.65      0.50      0.56        22
        16.0       0.71      0.43      0.54        23
        17.0       0.55      0.81      0.66       118
        18.0       0.42      0.28      0.33        18
        19.0       0.00      0.00      0.00        13
        20.0       0.34      0.12      0.18        89
        21.0       0.50      0.08      0.13        13
        22.0       1.00      0.56      0.72        25
        23.0       0.00      0.00      0.00        12
        24.0       0.00      0.00      0.00        23
        25.0       1.00      0.32      0.49        37
        26.0       1.00      0.35      0.52        17
        27.0       0.33      0.06      0.10        36
        28.0       0.50      0.25      0.33        12
        29.0       0.56      0.78      0.65        36
        30.0       0.51      0.78      0.62        32
        31.0       0.91      0.82      0.86        39
        32.0       0.76      0.81      0.78       747
        33.0       0.60      0.73      0.66        74
        34.0       1.00      0.78      0.87        58
        35.0       0.40      0.68      0.50        47
        36.0       0.38      0.69      0.49       502
        37.0       0.81      0.57      0.67       240
        38.0       0.56      0.26      0.36        34
        39.0       0.44      0.66      0.53       344
        40.0       0.89      0.70      0.79       191
        41.0       0.90      0.28      0.43        32
        42.0       0.80      0.57      0.67       384
        43.0       0.43      0.83      0.57       117
        44.0       0.84      0.62      0.71       437
        45.0       0.86      0.73      0.79        49
        46.0       0.75      0.88      0.81       401
        47.0       0.00      0.00      0.00        17
        48.0       0.75      0.29      0.41        42
        49.0       0.92      0.88      0.90        77
        50.0       0.95      0.77      0.85       171
        51.0       1.00      0.50      0.67        20
        52.0       0.44      0.69      0.53       499
        53.0       0.68      0.56      0.62       100
        54.0       0.00      0.00      0.00        11
        55.0       0.74      0.75      0.74       104
        56.0       0.20      0.16      0.18        19
        57.0       0.00      0.00      0.00        11
        58.0       0.88      0.86      0.87        35
        59.0       0.51      0.61      0.56       230
        60.0       0.94      0.84      0.89        58
        61.0       0.00      0.00      0.00        29
        62.0       0.75      0.31      0.43        49
        63.0       0.32      0.14      0.19        50
        64.0       0.88      0.65      0.75        34
        65.0       0.76      0.77      0.76       155
        66.0       1.00      0.07      0.13        14
        67.0       0.66      0.60      0.63       314
        68.0       0.00      0.00      0.00        62
        69.0       0.36      0.74      0.48       307
        70.0       0.35      0.25      0.29        68
        71.0       0.57      0.12      0.20        66
        72.0       0.00      0.00      0.00        15
        73.0       0.00      0.00      0.00        25
        74.0       0.00      0.00      0.00        19
        75.0       0.19      0.08      0.12        59
        76.0       0.47      0.69      0.56       206
        77.0       0.73      0.35      0.47        77
        78.0       0.83      0.58      0.68        59
        79.0       0.76      0.29      0.42       139
        80.0       0.83      0.48      0.61        42
        81.0       0.39      0.29      0.33       174
        82.0       0.31      0.09      0.14        43
        83.0       0.55      0.24      0.33        25
        84.0       0.53      0.35      0.42       105
        85.0       0.33      0.07      0.11        15
        86.0       0.84      0.50      0.63       242
        87.0       0.57      0.83      0.67       309
        88.0       0.78      0.53      0.63        59
        89.0       0.00      0.00      0.00        11
        90.0       0.47      0.32      0.38       188
        91.0       0.34      0.28      0.31        47
        92.0       0.00      0.00      0.00        40
        93.0       0.92      0.36      0.52        33
        94.0       0.52      0.57      0.54       288
        95.0       0.00      0.00      0.00        32
        96.0       0.85      0.55      0.67        75
        97.0       0.60      0.11      0.19        27
        98.0       0.81      0.34      0.48        38
        99.0       0.95      0.78      0.86        23
       100.0       0.00      0.00      0.00        25
       101.0       0.62      0.30      0.41        66
       102.0       0.64      0.82      0.72        22
       103.0       0.83      0.62      0.71        64
       104.0       0.75      0.23      0.35        39
       105.0       0.89      0.67      0.76        12
       106.0       0.84      0.66      0.74       113
       107.0       0.78      0.71      0.74       161
       108.0       0.00      0.00      0.00        23
       109.0       0.64      0.79      0.71        53
       110.0       1.00      0.29      0.44        14
       111.0       0.59      0.72      0.65       123
       112.0       0.68      0.32      0.43        41
       113.0       0.82      0.88      0.85       429
       114.0       0.61      0.92      0.74        65
       115.0       0.88      0.45      0.60        31
       116.0       0.90      0.69      0.78       173
       117.0       1.00      0.74      0.85        31
       118.0       0.69      0.84      0.75       117
       119.0       0.82      0.73      0.77       135
       120.0       0.70      0.68      0.69        62
       121.0       0.91      0.82      0.86       224
       122.0       0.82      0.77      0.79        35
       123.0       0.75      0.57      0.65        37
       124.0       0.88      0.70      0.78        30
       125.0       0.86      0.75      0.80        16
       126.0       0.88      0.64      0.74        22
       127.0       0.68      0.85      0.76        73

    accuracy                           0.61     12226
   macro avg       0.57      0.44      0.47     12226
weighted avg       0.63      0.61      0.59     12226


===confusion_matrix===

[[302   0   0 ...   0   0   0]
 [  1   1   0 ...   0   0   0]
 [  0   0   1 ...   0   0   0]
 ...
 [  0   0   0 ...  12   1   2]
 [  0   0   0 ...   0  14   7]
 [  0   0   0 ...   1   1  62]]

===multilabel confusion matrix===

[[[11512   356]
  [   56   302]]

 [[12212     2]
  [   11     1]]

 [[12206     2]
  [   17     1]]

 [[12103    44]
  [   59    20]]

 [[12150    21]
  [   49     6]]

 [[12161     7]
  [   58     0]]

 [[12172     9]
  [   36     9]]

 [[12167    12]
  [   24    23]]

 [[12216     0]
  [   10     0]]

 [[12197     8]
  [    8    13]]

 [[12210     1]
  [   14     1]]

 [[12183     7]
  [    9    27]]

 [[12214     0]
  [   12     0]]

 [[12197     4]
  [   15    10]]

 [[12206     0]
  [   20     0]]

 [[12198     6]
  [   11    11]]

 [[12199     4]
  [   13    10]]

 [[12031    77]
  [   22    96]]

 [[12201     7]
  [   13     5]]

 [[12213     0]
  [   13     0]]

 [[12116    21]
  [   78    11]]

 [[12212     1]
  [   12     1]]

 [[12201     0]
  [   11    14]]

 [[12214     0]
  [   12     0]]

 [[12203     0]
  [   23     0]]

 [[12189     0]
  [   25    12]]

 [[12209     0]
  [   11     6]]

 [[12186     4]
  [   34     2]]

 [[12211     3]
  [    9     3]]

 [[12168    22]
  [    8    28]]

 [[12170    24]
  [    7    25]]

 [[12184     3]
  [    7    32]]

 [[11287   192]
  [  143   604]]

 [[12116    36]
  [   20    54]]

 [[12168     0]
  [   13    45]]

 [[12131    48]
  [   15    32]]

 [[11147   577]
  [  155   347]]

 [[11955    31]
  [  104   136]]

 [[12185     7]
  [   25     9]]

 [[11596   286]
  [  118   226]]

 [[12019    16]
  [   57   134]]

 [[12193     1]
  [   23     9]]

 [[11787    55]
  [  164   220]]

 [[11980   129]
  [   20    97]]

 [[11736    53]
  [  168   269]]

 [[12171     6]
  [   13    36]]

 [[11707   118]
  [   50   351]]

 [[12209     0]
  [   17     0]]

 [[12180     4]
  [   30    12]]

 [[12143     6]
  [    9    68]]

 [[12048     7]
  [   39   132]]

 [[12206     0]
  [   10    10]]

 [[11283   444]
  [  157   342]]

 [[12100    26]
  [   44    56]]

 [[12215     0]
  [   11     0]]

 [[12094    28]
  [   26    78]]

 [[12195    12]
  [   16     3]]

 [[12215     0]
  [   11     0]]

 [[12187     4]
  [    5    30]]

 [[11862   134]
  [   89   141]]

 [[12165     3]
  [    9    49]]

 [[12197     0]
  [   29     0]]

 [[12172     5]
  [   34    15]]

 [[12161    15]
  [   43     7]]

 [[12189     3]
  [   12    22]]

 [[12033    38]
  [   36   119]]

 [[12212     0]
  [   13     1]]

 [[11816    96]
  [  127   187]]

 [[12163     1]
  [   62     0]]

 [[11518   401]
  [   81   226]]

 [[12127    31]
  [   51    17]]

 [[12154     6]
  [   58     8]]

 [[12209     2]
  [   15     0]]

 [[12201     0]
  [   25     0]]

 [[12207     0]
  [   19     0]]

 [[12146    21]
  [   54     5]]

 [[11858   162]
  [   64   142]]

 [[12139    10]
  [   50    27]]

 [[12160     7]
  [   25    34]]

 [[12074    13]
  [   98    41]]

 [[12180     4]
  [   22    20]]

 [[11973    79]
  [  124    50]]

 [[12174     9]
  [   39     4]]

 [[12196     5]
  [   19     6]]

 [[12088    33]
  [   68    37]]

 [[12209     2]
  [   14     1]]

 [[11961    23]
  [  120   122]]

 [[11721   196]
  [   53   256]]

 [[12158     9]
  [   28    31]]

 [[12215     0]
  [   11     0]]

 [[11971    67]
  [  128    60]]

 [[12154    25]
  [   34    13]]

 [[12184     2]
  [   40     0]]

 [[12192     1]
  [   21    12]]

 [[11783   155]
  [  123   165]]

 [[12194     0]
  [   32     0]]

 [[12144     7]
  [   34    41]]

 [[12197     2]
  [   24     3]]

 [[12185     3]
  [   25    13]]

 [[12202     1]
  [    5    18]]

 [[12201     0]
  [   25     0]]

 [[12148    12]
  [   46    20]]

 [[12194    10]
  [    4    18]]

 [[12154     8]
  [   24    40]]

 [[12184     3]
  [   30     9]]

 [[12213     1]
  [    4     8]]

 [[12099    14]
  [   38    75]]

 [[12033    32]
  [   47   114]]

 [[12203     0]
  [   23     0]]

 [[12149    24]
  [   11    42]]

 [[12212     0]
  [   10     4]]

 [[12043    60]
  [   35    88]]

 [[12179     6]
  [   28    13]]

 [[11714    83]
  [   53   376]]

 [[12123    38]
  [    5    60]]

 [[12193     2]
  [   17    14]]

 [[12040    13]
  [   53   120]]

 [[12195     0]
  [    8    23]]

 [[12064    45]
  [   19    98]]

 [[12069    22]
  [   37    98]]

 [[12146    18]
  [   20    42]]

 [[11983    19]
  [   40   184]]

 [[12185     6]
  [    8    27]]

 [[12182     7]
  [   16    21]]

 [[12193     3]
  [    9    21]]

 [[12208     2]
  [    4    12]]

 [[12202     2]
  [    8    14]]

 [[12124    29]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.6106
MCC	0.6021
log_loss	1.6794
f1 score weighted	0.5943
f1 score macro	0.4662
f1 score micro	0.6106
roc_auc ovr	0.9635
roc_auc ovo	0.9597
precision	0.6275
recall	0.6106

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ae8490430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ae84902e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ae84907c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ae84905e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.64      0.72      0.68       358
         1.0       0.00      0.00      0.00        12
         2.0       1.00      0.11      0.19        19
         3.0       0.40      0.51      0.45        79
         4.0       0.19      0.05      0.08        55
         5.0       0.17      0.02      0.03        58
         6.0       0.67      0.04      0.08        45
         7.0       0.50      0.09      0.15        47
         8.0       0.00      0.00      0.00        10
         9.0       1.00      0.10      0.17        21
        10.0       0.00      0.00      0.00        15
        11.0       0.83      0.69      0.76        36
        12.0       1.00      0.25      0.40        12
        13.0       0.83      0.60      0.70        25
        14.0       0.00      0.00      0.00        19
        15.0       0.93      0.59      0.72        22
        16.0       0.78      0.30      0.44        23
        17.0       0.70      0.81      0.75       118
        18.0       0.00      0.00      0.00        18
        19.0       0.33      0.08      0.13        12
        20.0       0.86      0.21      0.34        90
        21.0       0.00      0.00      0.00        13
        22.0       1.00      0.52      0.68        25
        23.0       1.00      0.08      0.14        13
        24.0       1.00      0.05      0.09        22
        25.0       0.67      0.32      0.43        38
        26.0       1.00      0.82      0.90        17
        27.0       0.50      0.03      0.05        35
        28.0       0.00      0.00      0.00        12
        29.0       0.75      0.17      0.27        36
        30.0       0.89      0.53      0.67        32
        31.0       0.97      0.82      0.89        38
        32.0       0.82      0.74      0.78       747
        33.0       0.97      0.80      0.88        75
        34.0       0.93      0.73      0.82        59
        35.0       0.74      0.30      0.42        47
        36.0       0.54      0.60      0.57       501
        37.0       0.38      0.72      0.49       241
        38.0       1.00      0.42      0.60        33
        39.0       0.57      0.60      0.59       344
        40.0       0.90      0.68      0.77       192
        41.0       0.92      0.34      0.50        32
        42.0       0.49      0.75      0.59       384
        43.0       0.86      0.60      0.71       117
        44.0       0.68      0.65      0.66       436
        45.0       0.98      0.84      0.90        49
        46.0       0.82      0.86      0.84       401
        47.0       0.00      0.00      0.00        17
        48.0       0.59      0.45      0.51        42
        49.0       0.93      0.84      0.88        77
        50.0       0.86      0.83      0.84       172
        51.0       1.00      0.40      0.57        20
        52.0       0.37      0.78      0.50       499
        53.0       0.80      0.57      0.67       100
        54.0       0.00      0.00      0.00        11
        55.0       0.49      0.70      0.58       104
        56.0       1.00      0.06      0.11        18
        57.0       0.00      0.00      0.00        10
        58.0       0.92      0.63      0.75        35
        59.0       0.64      0.47      0.54       230
        60.0       0.93      0.74      0.83        58
        61.0       0.00      0.00      0.00        29
        62.0       0.93      0.29      0.44        49
        63.0       0.00      0.00      0.00        50
        64.0       0.92      0.68      0.78        34
        65.0       0.93      0.73      0.82       155
        66.0       1.00      0.07      0.13        14
        67.0       0.46      0.58      0.51       314
        68.0       0.25      0.02      0.03        62
        69.0       0.43      0.72      0.54       307
        70.0       0.75      0.09      0.16        68
        71.0       0.61      0.29      0.39        66
        72.0       0.00      0.00      0.00        14
        73.0       0.80      0.33      0.47        24
        74.0       0.00      0.00      0.00        19
        75.0       1.00      0.03      0.06        60
        76.0       0.40      0.68      0.50       206
        77.0       0.54      0.38      0.44        77
        78.0       0.86      0.53      0.65        59
        79.0       0.31      0.52      0.39       139
        80.0       0.96      0.60      0.74        42
        81.0       0.22      0.43      0.29       174
        82.0       0.60      0.07      0.12        43
        83.0       0.00      0.00      0.00        26
        84.0       0.34      0.53      0.41       106
        85.0       1.00      0.13      0.24        15
        86.0       0.50      0.63      0.56       241
        87.0       0.73      0.69      0.71       309
        88.0       0.87      0.46      0.60        59
        89.0       0.00      0.00      0.00        10
        90.0       0.27      0.41      0.33       188
        91.0       0.00      0.00      0.00        46
        92.0       0.00      0.00      0.00        41
        93.0       0.83      0.47      0.60        32
        94.0       0.34      0.65      0.45       288
        95.0       0.00      0.00      0.00        31
        96.0       0.93      0.52      0.67        75
        97.0       1.00      0.11      0.20        27
        98.0       1.00      0.45      0.62        38
        99.0       0.87      0.83      0.85        24
       100.0       0.00      0.00      0.00        25
       101.0       0.77      0.42      0.54        65
       102.0       0.87      0.59      0.70        22
       103.0       0.96      0.70      0.81        64
       104.0       0.71      0.12      0.21        40
       105.0       1.00      0.83      0.91        12
       106.0       0.83      0.68      0.75       113
       107.0       0.90      0.63      0.74       161
       108.0       1.00      0.04      0.08        24
       109.0       0.87      0.63      0.73        52
       110.0       1.00      0.67      0.80        15
       111.0       0.89      0.47      0.61       124
       112.0       0.94      0.39      0.55        41
       113.0       0.92      0.80      0.86       430
       114.0       0.92      0.68      0.78        65
       115.0       0.90      0.29      0.44        31
       116.0       0.90      0.65      0.75       173
       117.0       0.95      0.65      0.77        31
       118.0       0.98      0.68      0.80       117
       119.0       0.68      0.85      0.76       136
       120.0       0.78      0.45      0.57        62
       121.0       0.79      0.84      0.81       224
       122.0       0.86      0.69      0.76        35
       123.0       0.91      0.57      0.70        37
       124.0       1.00      0.74      0.85        31
       125.0       0.80      0.80      0.80        15
       126.0       0.88      0.67      0.76        21
       127.0       0.67      0.88      0.76        73

    accuracy                           0.60     12226
   macro avg       0.65      0.42      0.46     12226
weighted avg       0.65      0.60      0.59     12226


===confusion_matrix===

[[258   0   0 ...   0   0   0]
 [  1   0   0 ...   0   0   0]
 [  0   0   2 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   1]
 [  0   0   0 ...   0  14   6]
 [  0   0   0 ...   1   2  64]]

===multilabel confusion matrix===

[[[11721   147]
  [  100   258]]

 [[12214     0]
  [   12     0]]

 [[12207     0]
  [   17     2]]

 [[12088    59]
  [   39    40]]

 [[12158    13]
  [   52     3]]

 [[12163     5]
  [   57     1]]

 [[12180     1]
  [   43     2]]

 [[12175     4]
  [   43     4]]

 [[12216     0]
  [   10     0]]

 [[12205     0]
  [   19     2]]

 [[12211     0]
  [   15     0]]

 [[12185     5]
  [   11    25]]

 [[12214     0]
  [    9     3]]

 [[12198     3]
  [   10    15]]

 [[12206     1]
  [   19     0]]

 [[12203     1]
  [    9    13]]

 [[12201     2]
  [   16     7]]

 [[12067    41]
  [   22    96]]

 [[12208     0]
  [   18     0]]

 [[12212     2]
  [   11     1]]

 [[12133     3]
  [   71    19]]

 [[12213     0]
  [   13     0]]

 [[12201     0]
  [   12    13]]

 [[12213     0]
  [   12     1]]

 [[12204     0]
  [   21     1]]

 [[12182     6]
  [   26    12]]

 [[12209     0]
  [    3    14]]

 [[12190     1]
  [   34     1]]

 [[12213     1]
  [   12     0]]

 [[12188     2]
  [   30     6]]

 [[12192     2]
  [   15    17]]

 [[12187     1]
  [    7    31]]

 [[11356   123]
  [  193   554]]

 [[12149     2]
  [   15    60]]

 [[12164     3]
  [   16    43]]

 [[12174     5]
  [   33    14]]

 [[11470   255]
  [  201   300]]

 [[11695   290]
  [   67   174]]

 [[12193     0]
  [   19    14]]

 [[11728   154]
  [  138   206]]

 [[12020    14]
  [   62   130]]

 [[12193     1]
  [   21    11]]

 [[11540   302]
  [   96   288]]

 [[12098    11]
  [   47    70]]

 [[11653   137]
  [  151   285]]

 [[12176     1]
  [    8    41]]

 [[11747    78]
  [   55   346]]

 [[12209     0]
  [   17     0]]

 [[12171    13]
  [   23    19]]

 [[12144     5]
  [   12    65]]

 [[12031    23]
  [   30   142]]

 [[12206     0]
  [   12     8]]

 [[11073   654]
  [  110   389]]

 [[12112    14]
  [   43    57]]

 [[12215     0]
  [   11     0]]

 [[12047    75]
  [   31    73]]

 [[12208     0]
  [   17     1]]

 [[12216     0]
  [   10     0]]

 [[12189     2]
  [   13    22]]

 [[11935    61]
  [  122   108]]

 [[12165     3]
  [   15    43]]

 [[12197     0]
  [   29     0]]

 [[12176     1]
  [   35    14]]

 [[12174     2]
  [   50     0]]

 [[12190     2]
  [   11    23]]

 [[12062     9]
  [   42   113]]

 [[12212     0]
  [   13     1]]

 [[11699   213]
  [  133   181]]

 [[12161     3]
  [   61     1]]

 [[11627   292]
  [   86   221]]

 [[12156     2]
  [   62     6]]

 [[12148    12]
  [   47    19]]

 [[12212     0]
  [   14     0]]

 [[12200     2]
  [   16     8]]

 [[12207     0]
  [   19     0]]

 [[12166     0]
  [   58     2]]

 [[11807   213]
  [   65   141]]

 [[12124    25]
  [   48    29]]

 [[12162     5]
  [   28    31]]

 [[11928   159]
  [   67    72]]

 [[12183     1]
  [   17    25]]

 [[11790   262]
  [   99    75]]

 [[12181     2]
  [   40     3]]

 [[12197     3]
  [   26     0]]

 [[12012   108]
  [   50    56]]

 [[12211     0]
  [   13     2]]

 [[11836   149]
  [   90   151]]

 [[11838    79]
  [   95   214]]

 [[12163     4]
  [   32    27]]

 [[12216     0]
  [   10     0]]

 [[11833   205]
  [  111    77]]

 [[12180     0]
  [   46     0]]

 [[12185     0]
  [   41     0]]

 [[12191     3]
  [   17    15]]

 [[11582   356]
  [  101   187]]

 [[12194     1]
  [   31     0]]

 [[12148     3]
  [   36    39]]

 [[12199     0]
  [   24     3]]

 [[12188     0]
  [   21    17]]

 [[12199     3]
  [    4    20]]

 [[12201     0]
  [   25     0]]

 [[12153     8]
  [   38    27]]

 [[12202     2]
  [    9    13]]

 [[12160     2]
  [   19    45]]

 [[12184     2]
  [   35     5]]

 [[12214     0]
  [    2    10]]

 [[12097    16]
  [   36    77]]

 [[12054    11]
  [   59   102]]

 [[12202     0]
  [   23     1]]

 [[12169     5]
  [   19    33]]

 [[12211     0]
  [    5    10]]

 [[12095     7]
  [   66    58]]

 [[12184     1]
  [   25    16]]

 [[11766    30]
  [   85   345]]

 [[12157     4]
  [   21    44]]

 [[12194     1]
  [   22     9]]

 [[12040    13]
  [   61   112]]

 [[12194     1]
  [   11    20]]

 [[12107     2]
  [   38    79]]

 [[12035    55]
  [   20   116]]

 [[12156     8]
  [   34    28]]

 [[11951    51]
  [   36   188]]

 [[12187     4]
  [   11    24]]

 [[12187     2]
  [   16    21]]

 [[12195     0]
  [    8    23]]

 [[12208     3]
  [    3    12]]

 [[12203     2]
  [    7    14]]

 [[12121    32]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.5986
MCC	0.5900
log_loss	1.7290
f1 score weighted	0.5878
f1 score macro	0.4642
f1 score micro	0.5986
roc_auc ovr	0.9614
roc_auc ovo	0.9558
precision	0.6484
recall	0.5986

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.5918868078841907	0.5830529917938343	1.7440762882352614	0.5758597014727446	0.4445560022477742	0.5918868078841907	0.9615419971200554	0.9563874244018666	0.6296427422792529	0.5918868078841907
1	0.5994929254927619	0.5900932514921591	1.73717632412378	0.5816611447394372	0.46705604404705897	0.5994929254927619	0.9592491613264613	0.9544720242669003	0.6117046933812689	0.5994929254927619
2	0.5975789301488631	0.589165001923116	1.760733666086716	0.5803475095999182	0.460657445576331	0.5975789301488631	0.9602321507571315	0.9562273549662683	0.616917043801834	0.5975789301488631
3	0.6105840013086864	0.6021158869602663	1.6794139898554334	0.5943258575670204	0.46623916700013085	0.6105840013086864	0.9634883088846231	0.959732289554877	0.6274797967353379	0.6105840013086864
4	0.5986422378537543	0.5899540844430858	1.7289591576464038	0.5878453833328385	0.46416019255196905	0.5986422378537543	0.9614086166428978	0.9557593469776828	0.6484262340932753	0.5986422378537543
mean	0.5996369805376512	0.5908762433224923	1.7300718851895192	0.5840079193423918	0.4605337702846528	0.5996369805376512	0.9611840469462338	0.9565156880335189	0.6268341020581938	0.5996369805376512
std	0.006085199687534317	0.006195557342434647	0.02740146597279182	0.006426280169061009	0.00828911228288914	0.006085199687534317	0.0014239432343136503	0.001743257080743462	0.012663116509779733	0.006085199687534317

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 13599.3383 secs

