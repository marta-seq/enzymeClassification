/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_hot_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c18774400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c187742b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c18774790>]/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_hot_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f736c6b8430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f736c6b82e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f736c6b87c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f736c6b85e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.86      0.82       911
         1.0       0.97      0.62      0.76        53
         2.0       0.92      0.73      0.81       179
         3.0       0.00      0.00      0.00        25
         4.0       0.81      0.15      0.26       112
         5.0       0.46      0.71      0.56       491
         6.0       0.91      0.77      0.83        64
         7.0       0.00      0.00      0.00        37
         8.0       0.96      0.74      0.83       206
         9.0       0.74      0.77      0.76        71
        10.0       0.96      0.79      0.87       404
        11.0       1.00      0.06      0.12        16
        12.0       0.76      0.62      0.69       378
        13.0       0.81      0.61      0.69       191
        14.0       0.00      0.00      0.00        76
        15.0       0.91      0.47      0.62        66
        16.0       0.90      0.70      0.79       141
        17.0       0.77      0.57      0.66       182
        18.0       1.00      0.75      0.86        12
        19.0       0.97      0.87      0.92        38
        20.0       0.95      0.87      0.91      2162
        21.0       0.97      0.93      0.95       168
        22.0       0.72      0.70      0.71      1470
        23.0       0.69      0.84      0.76      1259
        24.0       0.93      0.83      0.88       956
        25.0       0.92      0.83      0.87       283
        26.0       0.73      0.92      0.81      3919
        27.0       0.97      0.85      0.91       531
        28.0       1.00      0.67      0.80        12
        29.0       0.74      0.69      0.71      2345
        30.0       0.54      0.69      0.60       615
        31.0       1.00      0.66      0.79        32
        32.0       0.69      0.70      0.70      1449
        33.0       0.90      0.62      0.73       893
        34.0       0.86      0.84      0.85      1377
        35.0       1.00      0.09      0.17        22
        36.0       0.88      0.69      0.77       844
        37.0       0.66      0.86      0.75      1142
        38.0       0.89      0.84      0.86       314
        39.0       0.95      0.34      0.50        56
        40.0       0.81      0.65      0.72       154
        41.0       1.00      0.85      0.92        52
        42.0       0.96      0.60      0.74       247
        43.0       0.92      0.66      0.76       198
        44.0       0.88      0.87      0.87       529
        45.0       0.95      0.80      0.87       540
        46.0       0.00      0.00      0.00        20
        47.0       0.92      0.44      0.59        80
        48.0       0.88      0.98      0.93      1466
        49.0       0.93      0.86      0.90       148
        50.0       0.96      0.90      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.93      0.90      0.92       151
        53.0       0.94      0.95      0.95       903
        54.0       0.84      0.57      0.68       108
        55.0       0.91      0.91      0.91        93
        56.0       0.90      0.79      0.84        33
        57.0       0.74      0.86      0.79        49
        58.0       0.79      0.84      0.81       154

    accuracy                           0.80     29892
   macro avg       0.79      0.66      0.69     29892
weighted avg       0.81      0.80      0.80     29892


===confusion_matrix===

[[787   0   0 ...   0   0   0]
 [  0  33   0 ...   0   0   0]
 [  0   0 130 ...   0   0   0]
 ...
 [  0   0   0 ...  26   3   0]
 [  0   0   0 ...   0  42   7]
 [  0   0   0 ...   0   7 129]]

===multilabel confusion matrix===

[[[28756   225]
  [  124   787]]

 [[29838     1]
  [   20    33]]

 [[29701    12]
  [   49   130]]

 [[29867     0]
  [   25     0]]

 [[29776     4]
  [   95    17]]

 [[29000   401]
  [  144   347]]

 [[29823     5]
  [   15    49]]

 [[29855     0]
  [   37     0]]

 [[29679     7]
  [   54   152]]

 [[29802    19]
  [   16    55]]

 [[29476    12]
  [   83   321]]

 [[29876     0]
  [   15     1]]

 [[29439    75]
  [  142   236]]

 [[29673    28]
  [   75   116]]

 [[29816     0]
  [   76     0]]

 [[29823     3]
  [   35    31]]

 [[29740    11]
  [   42    99]]

 [[29679    31]
  [   78   104]]

 [[29880     0]
  [    3     9]]

 [[29853     1]
  [    5    33]]

 [[27634    96]
  [  280  1882]]

 [[29719     5]
  [   12   156]]

 [[28021   401]
  [  445  1025]]

 [[28167   466]
  [  200  1059]]

 [[28878    58]
  [  158   798]]

 [[29589    20]
  [   48   235]]

 [[24622  1351]
  [  326  3593]]

 [[29348    13]
  [   79   452]]

 [[29880     0]
  [    4     8]]

 [[26989   558]
  [  738  1607]]

 [[28917   360]
  [  193   422]]

 [[29860     0]
  [   11    21]]

 [[27998   445]
  [  439  1010]]

 [[28939    60]
  [  343   550]]

 [[28321   194]
  [  224  1153]]

 [[29870     0]
  [   20     2]]

 [[28972    76]
  [  265   579]]

 [[28254   496]
  [  160   982]]

 [[29544    34]
  [   50   264]]

 [[29835     1]
  [   37    19]]

 [[29715    23]
  [   54   100]]

 [[29840     0]
  [    8    44]]

 [[29639     6]
  [   99   148]]

 [[29682    12]
  [   68   130]]

 [[29298    65]
  [   68   461]]

 [[29327    25]
  [  107   433]]

 [[29872     0]
  [   20     0]]

 [[29809     3]
  [   45    35]]

 [[28231   195]
  [   25  1441]]

 [[29735     9]
  [   20   128]]

 [[28391    48]
  [  147  1306]]

 [[29880     0]
  [   12     0]]

 [[29731    10]
  [   15   136]]

 [[28938    51]
  [   42   861]]

 [[29772    12]
  [   46    62]]

 [[29791     8]
  [    8    85]]

 [[29856     3]
  [    7    26]]

 [[29828    15]
  [    7    42]]

 [[29704    34]
  [   25   129]]]

===scores report===
metrics	scores
Accuracy	0.7997
MCC	0.7889
log_loss	0.7775
f1 score weighted	0.7971
f1 score macro	0.6950
f1 score micro	0.7997
roc_auc ovr	0.9845
roc_auc ovo	0.9812
precision	0.8107
recall	0.7997

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f736c6b8430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f736c6b82e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f736c6b87c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f736c6b85e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.82      0.83       912
         1.0       0.95      0.72      0.82        53
         2.0       0.85      0.69      0.76       179
         3.0       0.33      0.04      0.07        25
         4.0       0.78      0.06      0.12       112
         5.0       0.81      0.50      0.62       492
         6.0       0.96      0.68      0.79        65
         7.0       0.00      0.00      0.00        38
         8.0       0.91      0.75      0.82       206
         9.0       0.77      0.48      0.59        71
        10.0       0.90      0.81      0.85       405
        11.0       0.00      0.00      0.00        17
        12.0       0.90      0.54      0.68       377
        13.0       0.86      0.65      0.74       191
        14.0       0.00      0.00      0.00        76
        15.0       0.74      0.53      0.62        66
        16.0       0.84      0.79      0.81       140
        17.0       0.69      0.68      0.69       182
        18.0       1.00      0.18      0.31        11
        19.0       1.00      0.73      0.84        37
        20.0       0.93      0.88      0.90      2163
        21.0       0.94      0.85      0.89       169
        22.0       0.65      0.74      0.69      1469
        23.0       0.86      0.75      0.80      1259
        24.0       0.93      0.81      0.87       956
        25.0       0.92      0.81      0.86       282
        26.0       0.79      0.87      0.83      3919
        27.0       0.95      0.84      0.89       531
        28.0       1.00      0.08      0.15        12
        29.0       0.58      0.77      0.67      2346
        30.0       0.61      0.62      0.62       615
        31.0       1.00      0.81      0.90        32
        32.0       0.62      0.73      0.67      1450
        33.0       0.57      0.76      0.65       893
        34.0       0.77      0.87      0.82      1376
        35.0       0.00      0.00      0.00        22
        36.0       0.79      0.74      0.76       843
        37.0       0.82      0.81      0.81      1142
        38.0       0.98      0.80      0.88       314
        39.0       0.75      0.43      0.55        56
        40.0       1.00      0.47      0.64       154
        41.0       0.98      0.90      0.94        52
        42.0       0.93      0.77      0.84       247
        43.0       0.95      0.78      0.86       198
        44.0       0.93      0.80      0.86       529
        45.0       0.98      0.83      0.90       539
        46.0       0.00      0.00      0.00        19
        47.0       0.86      0.39      0.53        80
        48.0       0.97      0.95      0.96      1466
        49.0       0.92      0.80      0.86       148
        50.0       0.91      0.91      0.91      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.99      0.87      0.93       151
        53.0       0.96      0.92      0.94       903
        54.0       0.90      0.59      0.72       108
        55.0       0.77      0.96      0.86        93
        56.0       1.00      0.73      0.84        33
        57.0       0.81      0.78      0.79        49
        58.0       0.83      0.73      0.78       154

    accuracy                           0.80     29892
   macro avg       0.77      0.62      0.67     29892
weighted avg       0.81      0.80      0.79     29892


===confusion_matrix===

[[747   1   1 ...   0   1   0]
 [  0  38   0 ...   0   0   0]
 [  0   0 124 ...   0   0   0]
 ...
 [  0   0   0 ...  24   2   0]
 [  0   0   0 ...   0  38   3]
 [  0   0   0 ...   0   5 113]]

===multilabel confusion matrix===

[[[28849   131]
  [  165   747]]

 [[29837     2]
  [   15    38]]

 [[29691    22]
  [   55   124]]

 [[29865     2]
  [   24     1]]

 [[29778     2]
  [  105     7]]

 [[29341    59]
  [  246   246]]

 [[29825     2]
  [   21    44]]

 [[29854     0]
  [   38     0]]

 [[29671    15]
  [   52   154]]

 [[29811    10]
  [   37    34]]

 [[29452    35]
  [   78   327]]

 [[29875     0]
  [   17     0]]

 [[29492    23]
  [  173   204]]

 [[29680    21]
  [   66   125]]

 [[29815     1]
  [   76     0]]

 [[29814    12]
  [   31    35]]

 [[29731    21]
  [   30   110]]

 [[29654    56]
  [   58   124]]

 [[29881     0]
  [    9     2]]

 [[29855     0]
  [   10    27]]

 [[27581   148]
  [  256  1907]]

 [[29713    10]
  [   25   144]]

 [[27823   600]
  [  377  1092]]

 [[28485   148]
  [  312   947]]

 [[28881    55]
  [  178   778]]

 [[29590    20]
  [   54   228]]

 [[25078   895]
  [  491  3428]]

 [[29337    24]
  [   83   448]]

 [[29880     0]
  [   11     1]]

 [[26254  1292]
  [  528  1818]]

 [[29029   248]
  [  231   384]]

 [[29860     0]
  [    6    26]]

 [[27799   643]
  [  396  1054]]

 [[28492   507]
  [  213   680]]

 [[28163   353]
  [  174  1202]]

 [[29870     0]
  [   22     0]]

 [[28880   169]
  [  223   620]]

 [[28542   208]
  [  216   926]]

 [[29573     5]
  [   62   252]]

 [[29828     8]
  [   32    24]]

 [[29738     0]
  [   81    73]]

 [[29839     1]
  [    5    47]]

 [[29631    14]
  [   58   189]]

 [[29685     9]
  [   43   155]]

 [[29332    31]
  [  106   423]]

 [[29344     9]
  [   92   447]]

 [[29873     0]
  [   19     0]]

 [[29807     5]
  [   49    31]]

 [[28387    39]
  [   66  1400]]

 [[29734    10]
  [   29   119]]

 [[28312   127]
  [  135  1318]]

 [[29880     0]
  [   12     0]]

 [[29740     1]
  [   20   131]]

 [[28958    31]
  [   69   834]]

 [[29777     7]
  [   44    64]]

 [[29773    26]
  [    4    89]]

 [[29859     0]
  [    9    24]]

 [[29834     9]
  [   11    38]]

 [[29715    23]
  [   41   113]]]

===scores report===
metrics	scores
Accuracy	0.7963
MCC	0.7851
log_loss	0.7849
f1 score weighted	0.7948
f1 score macro	0.6669
f1 score micro	0.7963
roc_auc ovr	0.9836
roc_auc ovo	0.9791
precision	0.8079
recall	0.7963

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f736c6b8430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f736c6b82e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f736c6b87c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f736c6b85e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.82      0.83       912
         1.0       0.95      0.79      0.86        52
         2.0       0.69      0.73      0.71       179
         3.0       0.33      0.04      0.07        25
         4.0       0.66      0.17      0.27       112
         5.0       0.71      0.63      0.67       492
         6.0       0.98      0.72      0.83        65
         7.0       0.00      0.00      0.00        38
         8.0       0.82      0.73      0.77       205
         9.0       0.91      0.55      0.68        71
        10.0       0.86      0.86      0.86       405
        11.0       0.75      0.18      0.29        17
        12.0       0.84      0.60      0.70       377
        13.0       0.78      0.71      0.74       190
        14.0       0.00      0.00      0.00        76
        15.0       0.97      0.42      0.58        67
        16.0       0.83      0.74      0.78       140
        17.0       0.78      0.70      0.74       183
        18.0       0.91      0.83      0.87        12
        19.0       0.97      0.86      0.91        37
        20.0       0.91      0.87      0.89      2162
        21.0       0.97      0.86      0.91       169
        22.0       0.77      0.65      0.71      1470
        23.0       0.86      0.76      0.81      1259
        24.0       0.90      0.87      0.88       956
        25.0       0.96      0.87      0.91       282
        26.0       0.90      0.83      0.86      3918
        27.0       0.72      0.87      0.79       531
        28.0       1.00      0.23      0.38        13
        29.0       0.57      0.79      0.67      2346
        30.0       0.52      0.72      0.60       615
        31.0       1.00      0.75      0.86        32
        32.0       0.66      0.73      0.69      1450
        33.0       0.57      0.78      0.66       893
        34.0       0.94      0.80      0.86      1376
        35.0       0.00      0.00      0.00        22
        36.0       0.87      0.71      0.78       843
        37.0       0.83      0.82      0.83      1142
        38.0       0.81      0.88      0.84       314
        39.0       0.82      0.33      0.47        55
        40.0       0.78      0.67      0.72       154
        41.0       1.00      0.81      0.89        52
        42.0       0.87      0.74      0.80       247
        43.0       0.66      0.84      0.74       197
        44.0       0.90      0.87      0.88       530
        45.0       0.92      0.83      0.87       540
        46.0       0.00      0.00      0.00        19
        47.0       0.95      0.53      0.68        79
        48.0       0.82      0.98      0.89      1465
        49.0       0.96      0.81      0.88       149
        50.0       0.90      0.91      0.90      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.88      0.89      0.89       152
        53.0       0.93      0.94      0.93       903
        54.0       0.88      0.66      0.75       108
        55.0       0.81      0.90      0.85        93
        56.0       1.00      0.91      0.95        32
        57.0       0.92      0.90      0.91        50
        58.0       0.88      0.84      0.86       154

    accuracy                           0.80     29892
   macro avg       0.77      0.66      0.69     29892
weighted avg       0.81      0.80      0.80     29892


===confusion_matrix===

[[752   0   1 ...   0   0   0]
 [  0  41   0 ...   0   0   0]
 [  0   0 131 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   1]
 [  0   0   0 ...   0  45   4]
 [  0   0   0 ...   0   3 129]]

===multilabel confusion matrix===

[[[28827   153]
  [  160   752]]

 [[29838     2]
  [   11    41]]

 [[29654    59]
  [   48   131]]

 [[29865     2]
  [   24     1]]

 [[29770    10]
  [   93    19]]

 [[29274   126]
  [  184   308]]

 [[29826     1]
  [   18    47]]

 [[29854     0]
  [   38     0]]

 [[29653    34]
  [   55   150]]

 [[29817     4]
  [   32    39]]

 [[29429    58]
  [   58   347]]

 [[29874     1]
  [   14     3]]

 [[29471    44]
  [  150   227]]

 [[29663    39]
  [   55   135]]

 [[29816     0]
  [   76     0]]

 [[29824     1]
  [   39    28]]

 [[29731    21]
  [   37   103]]

 [[29672    37]
  [   55   128]]

 [[29879     1]
  [    2    10]]

 [[29854     1]
  [    5    32]]

 [[27552   178]
  [  281  1881]]

 [[29718     5]
  [   23   146]]

 [[28141   281]
  [  516   954]]

 [[28480   153]
  [  305   954]]

 [[28849    87]
  [  129   827]]

 [[29601     9]
  [   37   245]]

 [[25605   369]
  [  655  3263]]

 [[29183   178]
  [   69   462]]

 [[29879     0]
  [   10     3]]

 [[26177  1369]
  [  494  1852]]

 [[28861   416]
  [  173   442]]

 [[29860     0]
  [    8    24]]

 [[27900   542]
  [  391  1059]]

 [[28464   535]
  [  197   696]]

 [[28442    74]
  [  274  1102]]

 [[29870     0]
  [   22     0]]

 [[28958    91]
  [  241   602]]

 [[28554   196]
  [  201   941]]

 [[29515    63]
  [   39   275]]

 [[29833     4]
  [   37    18]]

 [[29709    29]
  [   51   103]]

 [[29840     0]
  [   10    42]]

 [[29617    28]
  [   64   183]]

 [[29609    86]
  [   31   166]]

 [[29311    51]
  [   70   460]]

 [[29311    41]
  [   94   446]]

 [[29873     0]
  [   19     0]]

 [[29811     2]
  [   37    42]]

 [[28107   320]
  [   28  1437]]

 [[29738     5]
  [   28   121]]

 [[28293   146]
  [  134  1319]]

 [[29880     0]
  [   12     0]]

 [[29721    19]
  [   16   136]]

 [[28926    63]
  [   57   846]]

 [[29774    10]
  [   37    71]]

 [[29779    20]
  [    9    84]]

 [[29860     0]
  [    3    29]]

 [[29838     4]
  [    5    45]]

 [[29720    18]
  [   25   129]]]

===scores report===
metrics	scores
Accuracy	0.7997
MCC	0.7895
log_loss	0.7731
f1 score weighted	0.7995
f1 score macro	0.6943
f1 score micro	0.7997
roc_auc ovr	0.9842
roc_auc ovo	0.9809
precision	0.8116
recall	0.7997

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f736c6b8430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f736c6b82e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f736c6b87c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f736c6b85e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 1, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.68      0.85      0.76       912
         1.0       0.93      0.71      0.80        52
         2.0       0.79      0.59      0.67       179
         3.0       0.00      0.00      0.00        24
         4.0       0.20      0.01      0.02       112
         5.0       0.83      0.45      0.58       492
         6.0       0.79      0.78      0.79        64
         7.0       0.88      0.18      0.30        38
         8.0       0.97      0.76      0.85       205
         9.0       0.89      0.57      0.70        70
        10.0       0.88      0.77      0.82       405
        11.0       1.00      0.06      0.11        17
        12.0       0.81      0.57      0.67       378
        13.0       0.80      0.67      0.73       191
        14.0       0.00      0.00      0.00        76
        15.0       0.65      0.48      0.55        67
        16.0       0.63      0.78      0.70       140
        17.0       0.53      0.70      0.60       183
        18.0       0.91      0.83      0.87        12
        19.0       0.95      0.97      0.96        37
        20.0       0.97      0.85      0.91      2162
        21.0       0.91      0.83      0.87       168
        22.0       0.79      0.67      0.72      1470
        23.0       0.84      0.77      0.81      1259
        24.0       0.90      0.85      0.87       955
        25.0       0.91      0.91      0.91       282
        26.0       0.82      0.86      0.84      3918
        27.0       0.93      0.81      0.86       532
        28.0       1.00      0.62      0.76        13
        29.0       0.85      0.59      0.70      2346
        30.0       0.60      0.60      0.60       616
        31.0       0.80      0.62      0.70        32
        32.0       0.51      0.78      0.62      1449
        33.0       0.64      0.80      0.71       893
        34.0       0.92      0.80      0.85      1377
        35.0       1.00      0.18      0.31        22
        36.0       0.82      0.78      0.80       844
        37.0       0.68      0.84      0.75      1142
        38.0       0.96      0.83      0.89       314
        39.0       0.91      0.38      0.53        56
        40.0       1.00      0.57      0.72       153
        41.0       0.98      0.86      0.92        51
        42.0       0.87      0.71      0.78       246
        43.0       0.85      0.85      0.85       197
        44.0       0.90      0.84      0.87       530
        45.0       0.85      0.84      0.84       540
        46.0       0.00      0.00      0.00        20
        47.0       0.95      0.25      0.40        80
        48.0       0.85      0.96      0.90      1465
        49.0       0.89      0.84      0.87       148
        50.0       0.61      0.96      0.74      1453
        51.0       0.00      0.00      0.00        13
        52.0       0.99      0.77      0.87       151
        53.0       0.79      0.94      0.86       904
        54.0       0.83      0.59      0.69       108
        55.0       0.84      0.91      0.88        93
        56.0       0.89      0.97      0.93        33
        57.0       0.93      0.80      0.86        50
        58.0       0.86      0.78      0.82       153

    accuracy                           0.78     29892
   macro avg       0.78      0.65      0.68     29892
weighted avg       0.80      0.78      0.78     29892


===confusion_matrix===

[[776   0   0 ...   0   0   0]
 [  0  37   0 ...   0   0   0]
 [  0   0 105 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   0]
 [  0   0   0 ...   0  40   9]
 [  0   0   0 ...   1   3 119]]

===multilabel confusion matrix===

[[[28621   359]
  [  136   776]]

 [[29837     3]
  [   15    37]]

 [[29685    28]
  [   74   105]]

 [[29868     0]
  [   24     0]]

 [[29776     4]
  [  111     1]]

 [[29354    46]
  [  273   219]]

 [[29815    13]
  [   14    50]]

 [[29853     1]
  [   31     7]]

 [[29682     5]
  [   49   156]]

 [[29817     5]
  [   30    40]]

 [[29444    43]
  [   92   313]]

 [[29875     0]
  [   16     1]]

 [[29464    50]
  [  162   216]]

 [[29669    32]
  [   63   128]]

 [[29814     2]
  [   76     0]]

 [[29808    17]
  [   35    32]]

 [[29688    64]
  [   31   109]]

 [[29593   116]
  [   54   129]]

 [[29879     1]
  [    2    10]]

 [[29853     2]
  [    1    36]]

 [[27681    49]
  [  333  1829]]

 [[29710    14]
  [   29   139]]

 [[28161   261]
  [  492   978]]

 [[28452   181]
  [  285   974]]

 [[28849    88]
  [  144   811]]

 [[29586    24]
  [   25   257]]

 [[25229   745]
  [  535  3383]]

 [[29326    34]
  [  103   429]]

 [[29879     0]
  [    5     8]]

 [[27308   238]
  [  963  1383]]

 [[29031   245]
  [  247   369]]

 [[29855     5]
  [   12    20]]

 [[27368  1075]
  [  315  1134]]

 [[28608   391]
  [  183   710]]

 [[28424    91]
  [  281  1096]]

 [[29870     0]
  [   18     4]]

 [[28898   150]
  [  182   662]]

 [[28307   443]
  [  186   956]]

 [[29566    12]
  [   52   262]]

 [[29834     2]
  [   35    21]]

 [[29739     0]
  [   66    87]]

 [[29840     1]
  [    7    44]]

 [[29620    26]
  [   71   175]]

 [[29665    30]
  [   30   167]]

 [[29313    49]
  [   86   444]]

 [[29273    79]
  [   89   451]]

 [[29872     0]
  [   20     0]]

 [[29811     1]
  [   60    20]]

 [[28180   247]
  [   52  1413]]

 [[29729    15]
  [   23   125]]

 [[27531   908]
  [   60  1393]]

 [[29879     0]
  [   13     0]]

 [[29740     1]
  [   35   116]]

 [[28765   223]
  [   51   853]]

 [[29771    13]
  [   44    64]]

 [[29783    16]
  [    8    85]]

 [[29855     4]
  [    1    32]]

 [[29839     3]
  [   10    40]]

 [[29720    19]
  [   34   119]]]

===scores report===
metrics	scores
Accuracy	0.7834
MCC	0.7727
log_loss	0.8381
f1 score weighted	0.7805
f1 score macro	0.6831
f1 score micro	0.7834
roc_auc ovr	0.9835
roc_auc ovo	0.9818
precision	0.8008
recall	0.7834

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f736c6b8430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f736c6b82e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f736c6b87c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f736c6b85e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.84      0.85       911
         1.0       1.00      0.62      0.77        53
         2.0       0.85      0.69      0.76       180
         3.0       0.00      0.00      0.00        25
         4.0       1.00      0.02      0.04       111
         5.0       0.79      0.48      0.59       491
         6.0       1.00      0.78      0.88        64
         7.0       0.00      0.00      0.00        37
         8.0       0.93      0.77      0.84       205
         9.0       0.96      0.65      0.77        71
        10.0       0.92      0.86      0.89       404
        11.0       0.80      0.24      0.36        17
        12.0       0.73      0.67      0.70       378
        13.0       0.86      0.65      0.74       191
        14.0       0.00      0.00      0.00        76
        15.0       0.80      0.42      0.55        66
        16.0       0.98      0.64      0.78       140
        17.0       0.79      0.57      0.66       182
        18.0       1.00      0.92      0.96        12
        19.0       0.96      0.68      0.79        37
        20.0       0.69      0.93      0.79      2162
        21.0       0.92      0.90      0.91       168
        22.0       0.74      0.71      0.72      1470
        23.0       0.92      0.75      0.82      1259
        24.0       0.96      0.79      0.87       955
        25.0       0.96      0.86      0.91       283
        26.0       0.86      0.84      0.85      3919
        27.0       0.92      0.85      0.88       532
        28.0       1.00      0.54      0.70        13
        29.0       0.66      0.74      0.70      2345
        30.0       0.60      0.58      0.59       616
        31.0       1.00      0.81      0.90        32
        32.0       0.48      0.81      0.60      1449
        33.0       0.56      0.79      0.66       893
        34.0       0.97      0.75      0.85      1377
        35.0       1.00      0.41      0.58        22
        36.0       0.78      0.75      0.77       844
        37.0       0.94      0.79      0.86      1142
        38.0       0.89      0.83      0.86       314
        39.0       0.72      0.41      0.52        56
        40.0       0.95      0.54      0.69       153
        41.0       1.00      0.77      0.87        52
        42.0       0.93      0.71      0.81       247
        43.0       0.60      0.83      0.70       197
        44.0       0.86      0.82      0.84       529
        45.0       0.98      0.79      0.88       540
        46.0       0.00      0.00      0.00        20
        47.0       0.92      0.45      0.61        80
        48.0       0.93      0.98      0.95      1466
        49.0       0.98      0.86      0.91       148
        50.0       0.88      0.91      0.89      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.95      0.81      0.88       151
        53.0       0.96      0.92      0.94       904
        54.0       0.82      0.56      0.66       108
        55.0       0.63      0.98      0.76        93
        56.0       0.88      0.67      0.76        33
        57.0       0.79      0.92      0.85        50
        58.0       0.88      0.64      0.74       154

    accuracy                           0.79     29892
   macro avg       0.79      0.65      0.70     29892
weighted avg       0.81      0.79      0.79     29892


===confusion_matrix===

[[762   0   1 ...   0   0   0]
 [  1  33   0 ...   0   0   0]
 [  0   0 124 ...   0   0   0]
 ...
 [  0   0   0 ...  22   0   0]
 [  0   0   0 ...   0  46   2]
 [  0   0   0 ...   2   9  98]]

===multilabel confusion matrix===

[[[28864   117]
  [  149   762]]

 [[29839     0]
  [   20    33]]

 [[29690    22]
  [   56   124]]

 [[29866     1]
  [   25     0]]

 [[29781     0]
  [  109     2]]

 [[29337    64]
  [  257   234]]

 [[29828     0]
  [   14    50]]

 [[29855     0]
  [   37     0]]

 [[29675    12]
  [   48   157]]

 [[29819     2]
  [   25    46]]

 [[29458    30]
  [   55   349]]

 [[29874     1]
  [   13     4]]

 [[29421    93]
  [  126   252]]

 [[29681    20]
  [   67   124]]

 [[29816     0]
  [   76     0]]

 [[29819     7]
  [   38    28]]

 [[29750     2]
  [   50    90]]

 [[29683    27]
  [   79   103]]

 [[29880     0]
  [    1    11]]

 [[29854     1]
  [   12    25]]

 [[26838   892]
  [  158  2004]]

 [[29711    13]
  [   16   152]]

 [[28053   369]
  [  428  1042]]

 [[28547    86]
  [  321   938]]

 [[28905    32]
  [  200   755]]

 [[29600     9]
  [   40   243]]

 [[25452   521]
  [  624  3295]]

 [[29321    39]
  [   80   452]]

 [[29879     0]
  [    6     7]]

 [[26655   892]
  [  615  1730]]

 [[29035   241]
  [  257   359]]

 [[29860     0]
  [    6    26]]

 [[27194  1249]
  [  280  1169]]

 [[28453   546]
  [  189   704]]

 [[28479    36]
  [  341  1036]]

 [[29870     0]
  [   13     9]]

 [[28869   179]
  [  207   637]]

 [[28691    59]
  [  235   907]]

 [[29545    33]
  [   54   260]]

 [[29827     9]
  [   33    23]]

 [[29735     4]
  [   71    82]]

 [[29840     0]
  [   12    40]]

 [[29632    13]
  [   71   176]]

 [[29586   109]
  [   34   163]]

 [[29295    68]
  [   96   433]]

 [[29344     8]
  [  112   428]]

 [[29872     0]
  [   20     0]]

 [[29809     3]
  [   44    36]]

 [[28320   106]
  [   33  1433]]

 [[29741     3]
  [   21   127]]

 [[28258   181]
  [  135  1318]]

 [[29880     0]
  [   12     0]]

 [[29735     6]
  [   28   123]]

 [[28950    38]
  [   69   835]]

 [[29771    13]
  [   48    60]]

 [[29745    54]
  [    2    91]]

 [[29856     3]
  [   11    22]]

 [[29830    12]
  [    4    46]]

 [[29724    14]
  [   56    98]]]

===scores report===
metrics	scores
Accuracy	0.7913
MCC	0.7805
log_loss	0.8051
f1 score weighted	0.7916
f1 score macro	0.6950
f1 score micro	0.7913
roc_auc ovr	0.9837
roc_auc ovo	0.9799
precision	0.8128
recall	0.7913

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7996788438378162	0.7888791041250562	0.7775024397336598	0.7970605906127105	0.6949662148933393	0.7996788438378162	0.9844742187215738	0.9811698346053721	0.8107398769274644	0.7996788438378162
1	0.7963000133815068	0.7850852891305838	0.784936738289934	0.794822961965536	0.66688880376964	0.7963000133815068	0.9836388401342635	0.9790847951400526	0.8079041962662448	0.7963000133815068
2	0.7997457513716044	0.789488252217498	0.7731340080759392	0.7995343947543552	0.6943431706445121	0.7997457513716044	0.9842163894149489	0.9808699437307563	0.8115945760550313	0.7997457513716044
3	0.7834203131272581	0.7727191676555131	0.8380779184210423	0.7805250026344693	0.6830956854660275	0.7834203131272581	0.9835086397610374	0.9818138945895187	0.8008450396918874	0.7834203131272581
4	0.791281948347384	0.7805062406380981	0.8051004685779526	0.7915811382149145	0.6950277672759484	0.791281948347384	0.9836650389171953	0.9798995539673331	0.8127689722720157	0.791281948347384
mean	0.7940853740131139	0.7833356107533499	0.7957503146197057	0.7927048176363971	0.6868643284098935	0.7940853740131139	0.9839006253898038	0.9805676044066066	0.8087705322425286	0.7940853740131139
std	0.006161722538619971	0.006202594448631203	0.023834710466813052	0.006628920970321342	0.010967585278195914	0.006161722538619971	0.00037587270959214136	0.0009646081286872322	0.004275629422821813	0.006161722538619971

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 34738.7276 secs

