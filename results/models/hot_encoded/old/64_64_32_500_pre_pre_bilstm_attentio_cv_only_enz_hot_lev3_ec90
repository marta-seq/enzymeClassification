/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_hot_lev3_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbffc496430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbffc4962e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbffc4967c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbffc4965e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.89      0.90       825
         1.0       0.00      0.00      0.00        14
         2.0       0.95      0.58      0.72        31
         3.0       0.00      0.00      0.00        11
         4.0       0.87      0.79      0.83        52
         5.0       0.68      0.82      0.74       176
         6.0       0.68      0.59      0.63       102
         7.0       0.70      0.22      0.33        97
         8.0       0.50      0.14      0.22        14
         9.0       0.86      0.36      0.51        70
        10.0       0.76      0.84      0.80       104
        11.0       0.00      0.00      0.00        18
        12.0       0.80      0.29      0.42        14
        13.0       0.70      0.65      0.67        43
        14.0       0.75      0.53      0.62        34
        15.0       0.60      0.86      0.71        64
        16.0       0.00      0.00      0.00        13
        17.0       0.28      0.42      0.33        19
        18.0       0.87      0.90      0.88        72
        19.0       0.75      0.30      0.43        30
        20.0       1.00      0.90      0.95        94
        21.0       0.84      0.70      0.76        46
        22.0       0.83      0.76      0.79        25
        23.0       0.95      0.97      0.96       345
        24.0       0.95      0.70      0.81        30
        25.0       0.75      0.30      0.43        20
        26.0       0.90      0.66      0.76       167
        27.0       0.88      0.61      0.72        36
        28.0       0.91      0.87      0.89        61
        29.0       0.95      0.84      0.89        63
        30.0       0.75      0.27      0.40        11
        31.0       0.00      0.00      0.00        11
        32.0       0.56      0.45      0.50        40
        33.0       0.76      0.75      0.76        73
        34.0       0.98      1.00      0.99        57
        35.0       0.93      0.93      0.93        15
        36.0       0.54      0.38      0.45        50
        37.0       0.86      0.95      0.90        19
        38.0       0.83      0.69      0.75        29
        39.0       0.88      0.97      0.92       101
        40.0       1.00      0.25      0.40        12
        41.0       1.00      1.00      1.00        14
        42.0       0.73      0.93      0.82        67
        43.0       0.97      0.83      0.89        76
        44.0       0.91      0.91      0.91        11
        45.0       0.94      0.86      0.90        37
        46.0       0.97      0.86      0.91      1613
        47.0       0.99      0.96      0.97       299
        48.0       1.00      0.97      0.99       244
        49.0       0.96      0.94      0.95       168
        50.0       0.85      0.81      0.83      1024
        51.0       0.72      0.75      0.74       353
        52.0       0.91      0.80      0.85        86
        53.0       0.74      0.81      0.77       607
        54.0       0.84      0.91      0.87       543
        55.0       1.00      0.81      0.89        78
        56.0       0.83      0.92      0.87       954
        57.0       0.93      0.90      0.91       247
        58.0       1.00      1.00      1.00        34
        59.0       0.94      0.81      0.87       877
        60.0       0.94      0.84      0.89        77
        61.0       0.88      0.85      0.87       566
        62.0       1.00      0.29      0.45        24
        63.0       0.79      0.60      0.68        55
        64.0       0.98      0.97      0.97       254
        65.0       0.45      0.36      0.40        14
        66.0       0.95      0.95      0.95       456
        67.0       1.00      0.63      0.77        38
        68.0       0.77      0.91      0.83      1189
        69.0       0.95      0.83      0.88       224
        70.0       0.62      0.79      0.70        19
        71.0       0.97      0.94      0.96       358
        72.0       1.00      0.44      0.61        32
        73.0       0.00      0.00      0.00        13
        74.0       0.97      0.94      0.96       127
        75.0       1.00      0.92      0.96        12
        76.0       0.87      0.77      0.81       460
        77.0       1.00      0.83      0.91       103
        78.0       0.62      0.31      0.41        52
        79.0       0.75      0.67      0.71        83
        80.0       0.62      0.36      0.46        80
        81.0       0.97      0.83      0.90        84
        82.0       0.97      0.86      0.91       335
        83.0       0.60      0.13      0.21        23
        84.0       0.77      0.75      0.76       518
        85.0       0.18      0.14      0.16        87
        86.0       1.00      0.08      0.14        13
        87.0       0.47      0.80      0.59       480
        88.0       0.85      0.68      0.76       126
        89.0       1.00      0.84      0.91        25
        90.0       0.77      0.82      0.79       152
        91.0       0.67      0.30      0.41        20
        92.0       1.00      0.36      0.53        28
        93.0       0.79      0.52      0.63        42
        94.0       0.80      0.12      0.21        34
        95.0       0.59      0.45      0.51        99
        96.0       0.82      0.84      0.83       415
        97.0       0.84      0.53      0.65       118
        98.0       0.68      0.80      0.73        99
        99.0       0.81      0.75      0.78       253
       100.0       0.97      0.97      0.97       116
       101.0       0.71      0.83      0.76       423
       102.0       0.77      0.80      0.79        99
       103.0       0.80      0.75      0.78        60
       104.0       0.73      0.85      0.78       266
       105.0       0.84      0.84      0.84        37
       106.0       0.83      0.87      0.85       494
       107.0       1.00      0.64      0.78        14
       108.0       0.98      0.78      0.87       610
       109.0       0.96      0.82      0.88       206
       110.0       0.90      0.41      0.56        22
       111.0       0.69      0.90      0.79       534
       112.0       0.73      0.60      0.66        98
       113.0       0.85      0.65      0.74        86
       114.0       0.87      0.89      0.88       109
       115.0       0.60      0.95      0.73       858
       116.0       0.55      0.59      0.57        61
       117.0       0.97      0.91      0.94       209
       118.0       1.00      0.08      0.14        13
       119.0       0.94      0.71      0.81        65
       120.0       0.97      0.93      0.95       156
       121.0       0.95      0.92      0.93        84
       122.0       0.69      0.53      0.60        55
       123.0       0.67      0.84      0.75       154
       124.0       1.00      0.87      0.93        52
       125.0       0.97      0.88      0.93       147
       126.0       0.57      0.49      0.53        77
       127.0       1.00      0.79      0.88        19
       128.0       0.64      0.88      0.74       198
       129.0       0.87      0.95      0.91       450
       130.0       0.88      0.64      0.74        11
       131.0       0.83      0.58      0.68        43
       132.0       1.00      0.75      0.86        16
       133.0       0.98      0.97      0.97       204
       134.0       1.00      0.92      0.96        76
       135.0       0.99      0.78      0.87       255
       136.0       0.75      0.15      0.25        20
       137.0       0.90      0.69      0.78        13
       138.0       1.00      0.37      0.54        67
       139.0       0.95      0.98      0.96      1464
       140.0       0.96      0.87      0.91       146
       141.0       0.97      0.85      0.90        99
       142.0       0.98      0.85      0.91       455
       143.0       0.95      0.93      0.94        82
       144.0       0.97      0.97      0.97       411
       145.0       0.95      0.95      0.95       406
       146.0       0.50      0.08      0.14        12
       147.0       0.97      0.92      0.94       149
       148.0       0.92      0.95      0.94       703
       149.0       0.99      0.95      0.97       195
       150.0       0.96      0.70      0.81        33
       151.0       0.92      0.71      0.80        68
       152.0       0.99      0.82      0.89        93
       153.0       0.76      0.88      0.82        33
       154.0       0.75      0.98      0.85        49
       155.0       0.82      0.89      0.85       154

    accuracy                           0.84     28656
   macro avg       0.81      0.69      0.72     28656
weighted avg       0.86      0.84      0.84     28656


===confusion_matrix===

[[732   0   0 ...   0   1   0]
 [  0   0   0 ...   0   0   0]
 [  0   0  18 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   2]
 [  0   0   0 ...   0  48   0]
 [  0   0   0 ...   1  11 137]]

===multilabel confusion matrix===

[[[27756    75]
  [   93   732]]

 [[28642     0]
  [   14     0]]

 [[28624     1]
  [   13    18]]

 [[28643     2]
  [   11     0]]

 [[28598     6]
  [   11    41]]

 [[28411    69]
  [   31   145]]

 [[28526    28]
  [   42    60]]

 [[28550     9]
  [   76    21]]

 [[28640     2]
  [   12     2]]

 [[28582     4]
  [   45    25]]

 [[28525    27]
  [   17    87]]

 [[28636     2]
  [   18     0]]

 [[28641     1]
  [   10     4]]

 [[28601    12]
  [   15    28]]

 [[28616     6]
  [   16    18]]

 [[28556    36]
  [    9    55]]

 [[28643     0]
  [   13     0]]

 [[28616    21]
  [   11     8]]

 [[28574    10]
  [    7    65]]

 [[28623     3]
  [   21     9]]

 [[28562     0]
  [    9    85]]

 [[28604     6]
  [   14    32]]

 [[28627     4]
  [    6    19]]

 [[28295    16]
  [   12   333]]

 [[28625     1]
  [    9    21]]

 [[28634     2]
  [   14     6]]

 [[28476    13]
  [   56   111]]

 [[28617     3]
  [   14    22]]

 [[28590     5]
  [    8    53]]

 [[28590     3]
  [   10    53]]

 [[28644     1]
  [    8     3]]

 [[28645     0]
  [   11     0]]

 [[28602    14]
  [   22    18]]

 [[28566    17]
  [   18    55]]

 [[28598     1]
  [    0    57]]

 [[28640     1]
  [    1    14]]

 [[28590    16]
  [   31    19]]

 [[28634     3]
  [    1    18]]

 [[28623     4]
  [    9    20]]

 [[28542    13]
  [    3    98]]

 [[28644     0]
  [    9     3]]

 [[28642     0]
  [    0    14]]

 [[28566    23]
  [    5    62]]

 [[28578     2]
  [   13    63]]

 [[28644     1]
  [    1    10]]

 [[28617     2]
  [    5    32]]

 [[26993    50]
  [  225  1388]]

 [[28354     3]
  [   12   287]]

 [[28412     0]
  [    7   237]]

 [[28481     7]
  [   10   158]]

 [[27486   146]
  [  191   833]]

 [[28201   102]
  [   88   265]]

 [[28563     7]
  [   17    69]]

 [[27875   174]
  [  118   489]]

 [[28017    96]
  [   48   495]]

 [[28578     0]
  [   15    63]]

 [[27522   180]
  [   78   876]]

 [[28391    18]
  [   24   223]]

 [[28622     0]
  [    0    34]]

 [[27735    44]
  [  164   713]]

 [[28575     4]
  [   12    65]]

 [[28025    65]
  [   83   483]]

 [[28632     0]
  [   17     7]]

 [[28592     9]
  [   22    33]]

 [[28396     6]
  [    8   246]]

 [[28636     6]
  [    9     5]]

 [[28179    21]
  [   22   434]]

 [[28618     0]
  [   14    24]]

 [[27137   330]
  [  108  1081]]

 [[28422    10]
  [   39   185]]

 [[28628     9]
  [    4    15]]

 [[28288    10]
  [   20   338]]

 [[28624     0]
  [   18    14]]

 [[28642     1]
  [   13     0]]

 [[28525     4]
  [    7   120]]

 [[28644     0]
  [    1    11]]

 [[28143    53]
  [  108   352]]

 [[28553     0]
  [   17    86]]

 [[28594    10]
  [   36    16]]

 [[28554    19]
  [   27    56]]

 [[28558    18]
  [   51    29]]

 [[28570     2]
  [   14    70]]

 [[28312     9]
  [   48   287]]

 [[28631     2]
  [   20     3]]

 [[28024   114]
  [  128   390]]

 [[28514    55]
  [   75    12]]

 [[28643     0]
  [   12     1]]

 [[27742   434]
  [   97   383]]

 [[28515    15]
  [   40    86]]

 [[28631     0]
  [    4    21]]

 [[28467    37]
  [   28   124]]

 [[28633     3]
  [   14     6]]

 [[28628     0]
  [   18    10]]

 [[28608     6]
  [   20    22]]

 [[28621     1]
  [   30     4]]

 [[28526    31]
  [   54    45]]

 [[28162    79]
  [   65   350]]

 [[28526    12]
  [   55    63]]

 [[28519    38]
  [   20    79]]

 [[28359    44]
  [   63   190]]

 [[28536     4]
  [    4   112]]

 [[28092   141]
  [   74   349]]

 [[28534    23]
  [   20    79]]

 [[28585    11]
  [   15    45]]

 [[28304    86]
  [   39   227]]

 [[28613     6]
  [    6    31]]

 [[28072    90]
  [   62   432]]

 [[28642     0]
  [    5     9]]

 [[28038     8]
  [  135   475]]

 [[28443     7]
  [   37   169]]

 [[28633     1]
  [   13     9]]

 [[27909   213]
  [   51   483]]

 [[28536    22]
  [   39    59]]

 [[28560    10]
  [   30    56]]

 [[28533    14]
  [   12    97]]

 [[27249   549]
  [   42   816]]

 [[28566    29]
  [   25    36]]

 [[28442     5]
  [   18   191]]

 [[28643     0]
  [   12     1]]

 [[28588     3]
  [   19    46]]

 [[28496     4]
  [   11   145]]

 [[28568     4]
  [    7    77]]

 [[28588    13]
  [   26    29]]

 [[28438    64]
  [   24   130]]

 [[28604     0]
  [    7    45]]

 [[28505     4]
  [   17   130]]

 [[28550    29]
  [   39    38]]

 [[28637     0]
  [    4    15]]

 [[28360    98]
  [   23   175]]

 [[28142    64]
  [   21   429]]

 [[28644     1]
  [    4     7]]

 [[28608     5]
  [   18    25]]

 [[28640     0]
  [    4    12]]

 [[28447     5]
  [    7   197]]

 [[28580     0]
  [    6    70]]

 [[28398     3]
  [   55   200]]

 [[28635     1]
  [   17     3]]

 [[28642     1]
  [    4     9]]

 [[28589     0]
  [   42    25]]

 [[27119    73]
  [   31  1433]]

 [[28505     5]
  [   19   127]]

 [[28554     3]
  [   15    84]]

 [[28193     8]
  [   66   389]]

 [[28570     4]
  [    6    76]]

 [[28232    13]
  [   12   399]]

 [[28231    19]
  [   21   385]]

 [[28643     1]
  [   11     1]]

 [[28503     4]
  [   12   137]]

 [[27898    55]
  [   37   666]]

 [[28460     1]
  [   10   185]]

 [[28622     1]
  [   10    23]]

 [[28584     4]
  [   20    48]]

 [[28562     1]
  [   17    76]]

 [[28614     9]
  [    4    29]]

 [[28591    16]
  [    1    48]]

 [[28471    31]
  [   17   137]]]

===scores report===
metrics	scores
Accuracy	0.8424
MCC	0.8394
log_loss	0.7066
f1 score weighted	0.8404
f1 score macro	0.7229
f1 score micro	0.8424
roc_auc ovr	0.9942
roc_auc ovo	0.9916
precision	0.8551
recall	0.8424

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbffc496430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbffc4962e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbffc4967c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbffc4965e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 1, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([56., 56., 56., ..., 98., 51., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.95      0.84       825
         1.0       1.00      0.21      0.35        14
         2.0       0.90      0.61      0.73        31
         3.0       0.00      0.00      0.00        12
         4.0       0.83      0.83      0.83        52
         5.0       0.74      0.78      0.76       176
         6.0       0.38      0.65      0.48       102
         7.0       0.34      0.37      0.35        97
         8.0       0.78      0.50      0.61        14
         9.0       0.36      0.31      0.34        70
        10.0       0.74      0.78      0.76       104
        11.0       0.50      0.06      0.10        18
        12.0       0.36      0.29      0.32        14
        13.0       0.75      0.71      0.73        42
        14.0       0.84      0.62      0.71        34
        15.0       0.83      0.75      0.79        64
        16.0       1.00      0.07      0.13        14
        17.0       0.70      0.37      0.48        19
        18.0       0.93      0.89      0.91        72
        19.0       0.40      0.39      0.39        31
        20.0       0.99      0.93      0.96        94
        21.0       0.76      0.82      0.79        45
        22.0       1.00      0.76      0.86        25
        23.0       0.96      0.94      0.95       346
        24.0       1.00      0.83      0.91        30
        25.0       0.42      0.26      0.32        19
        26.0       0.77      0.60      0.68       167
        27.0       0.81      0.69      0.75        36
        28.0       0.97      0.97      0.97        60
        29.0       0.88      0.73      0.80        62
        30.0       0.33      0.09      0.14        11
        31.0       0.00      0.00      0.00        11
        32.0       0.94      0.38      0.54        40
        33.0       0.57      0.70      0.63        74
        34.0       0.93      1.00      0.97        56
        35.0       0.89      1.00      0.94        16
        36.0       0.58      0.43      0.49        51
        37.0       0.94      0.89      0.92        19
        38.0       1.00      0.66      0.79        29
        39.0       0.82      0.96      0.89       101
        40.0       0.78      0.58      0.67        12
        41.0       1.00      1.00      1.00        13
        42.0       0.71      0.91      0.80        67
        43.0       0.83      0.92      0.88        76
        44.0       1.00      1.00      1.00        12
        45.0       0.94      0.92      0.93        36
        46.0       0.89      0.90      0.90      1613
        47.0       1.00      0.95      0.97       299
        48.0       0.96      0.98      0.97       243
        49.0       0.91      0.92      0.91       169
        50.0       0.70      0.85      0.77      1024
        51.0       0.70      0.74      0.72       352
        52.0       0.92      0.91      0.91        86
        53.0       0.77      0.77      0.77       607
        54.0       0.97      0.90      0.93       543
        55.0       0.96      0.92      0.94        78
        56.0       0.84      0.88      0.86       954
        57.0       0.79      0.95      0.86       247
        58.0       1.00      0.97      0.99        34
        59.0       0.76      0.88      0.82       877
        60.0       1.00      0.82      0.90        77
        61.0       0.89      0.85      0.87       565
        62.0       0.88      0.58      0.70        24
        63.0       0.75      0.60      0.67        55
        64.0       0.99      0.98      0.99       255
        65.0       1.00      0.21      0.35        14
        66.0       0.98      0.91      0.95       457
        67.0       1.00      0.81      0.90        37
        68.0       0.89      0.83      0.86      1189
        69.0       0.91      0.80      0.85       224
        70.0       0.87      0.65      0.74        20
        71.0       0.94      0.94      0.94       358
        72.0       0.87      0.62      0.73        32
        73.0       0.00      0.00      0.00        13
        74.0       0.97      0.94      0.95       128
        75.0       1.00      0.69      0.82        13
        76.0       0.75      0.78      0.77       460
        77.0       0.96      0.87      0.91       104
        78.0       0.93      0.27      0.42        52
        79.0       0.80      0.54      0.64        84
        80.0       0.67      0.42      0.52        80
        81.0       1.00      0.81      0.89        83
        82.0       0.97      0.84      0.90       335
        83.0       1.00      0.25      0.40        24
        84.0       0.89      0.71      0.79       518
        85.0       0.30      0.16      0.21        88
        86.0       0.80      0.31      0.44        13
        87.0       0.50      0.80      0.61       480
        88.0       0.87      0.66      0.75       126
        89.0       1.00      1.00      1.00        25
        90.0       0.85      0.84      0.85       153
        91.0       0.83      0.25      0.38        20
        92.0       1.00      0.37      0.54        27
        93.0       0.81      0.62      0.70        42
        94.0       0.87      0.38      0.53        34
        95.0       0.53      0.58      0.55        99
        96.0       0.94      0.81      0.87       416
        97.0       0.70      0.53      0.60       118
        98.0       0.89      0.75      0.81        99
        99.0       0.68      0.75      0.71       253
       100.0       0.97      0.91      0.94       115
       101.0       0.84      0.80      0.82       423
       102.0       0.85      0.86      0.85        99
       103.0       0.76      0.67      0.71        61
       104.0       0.75      0.88      0.81       266
       105.0       0.94      0.83      0.88        36
       106.0       0.84      0.83      0.84       494
       107.0       1.00      0.86      0.92        14
       108.0       0.84      0.85      0.84       610
       109.0       0.92      0.87      0.89       206
       110.0       0.70      0.64      0.67        22
       111.0       0.87      0.86      0.86       535
       112.0       0.85      0.51      0.64        98
       113.0       0.71      0.57      0.63        86
       114.0       0.99      0.91      0.95       109
       115.0       0.80      0.91      0.85       858
       116.0       0.91      0.34      0.50        61
       117.0       0.93      0.89      0.91       208
       118.0       0.00      0.00      0.00        13
       119.0       0.67      0.75      0.71        65
       120.0       0.97      0.89      0.93       157
       121.0       0.95      0.99      0.97        84
       122.0       0.64      0.42      0.51        55
       123.0       0.93      0.78      0.85       154
       124.0       0.94      0.92      0.93        52
       125.0       0.96      0.91      0.94       147
       126.0       0.65      0.68      0.66        77
       127.0       1.00      0.83      0.91        18
       128.0       0.94      0.81      0.87       197
       129.0       0.92      0.93      0.93       449
       130.0       0.83      0.45      0.59        11
       131.0       1.00      0.63      0.77        43
       132.0       0.92      0.73      0.81        15
       133.0       0.99      0.98      0.99       204
       134.0       0.95      0.97      0.96        76
       135.0       0.95      0.82      0.88       255
       136.0       0.67      0.21      0.32        19
       137.0       0.91      0.77      0.83        13
       138.0       0.87      0.49      0.63        67
       139.0       0.92      0.99      0.96      1463
       140.0       0.99      0.82      0.90       147
       141.0       0.97      0.86      0.91        99
       142.0       0.94      0.89      0.92       455
       143.0       0.97      0.93      0.95        82
       144.0       0.98      0.91      0.95       410
       145.0       0.91      0.99      0.95       406
       146.0       1.00      0.25      0.40        12
       147.0       0.94      0.88      0.91       149
       148.0       0.88      0.98      0.93       702
       149.0       0.98      0.96      0.97       196
       150.0       0.81      0.81      0.81        32
       151.0       0.90      0.93      0.91        69
       152.0       0.94      0.91      0.93        93
       153.0       1.00      0.91      0.95        32
       154.0       0.93      0.84      0.88        49
       155.0       0.90      0.95      0.92       154

    accuracy                           0.84     28655
   macro avg       0.83      0.71      0.74     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[780   0   0 ...   0   0   0]
 [  3   3   0 ...   0   0   0]
 [  0   0  19 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   0]
 [  0   0   0 ...   0  41   8]
 [  0   0   0 ...   0   2 147]]

===multilabel confusion matrix===

[[[27569   261]
  [   45   780]]

 [[28641     0]
  [   11     3]]

 [[28622     2]
  [   12    19]]

 [[28642     1]
  [   12     0]]

 [[28594     9]
  [    9    43]]

 [[28431    48]
  [   39   137]]

 [[28446   107]
  [   36    66]]

 [[28488    70]
  [   61    36]]

 [[28639     2]
  [    7     7]]

 [[28546    39]
  [   48    22]]

 [[28522    29]
  [   23    81]]

 [[28636     1]
  [   17     1]]

 [[28634     7]
  [   10     4]]

 [[28603    10]
  [   12    30]]

 [[28617     4]
  [   13    21]]

 [[28581    10]
  [   16    48]]

 [[28641     0]
  [   13     1]]

 [[28633     3]
  [   12     7]]

 [[28578     5]
  [    8    64]]

 [[28606    18]
  [   19    12]]

 [[28560     1]
  [    7    87]]

 [[28598    12]
  [    8    37]]

 [[28630     0]
  [    6    19]]

 [[28294    15]
  [   22   324]]

 [[28625     0]
  [    5    25]]

 [[28629     7]
  [   14     5]]

 [[28457    31]
  [   66   101]]

 [[28613     6]
  [   11    25]]

 [[28593     2]
  [    2    58]]

 [[28587     6]
  [   17    45]]

 [[28642     2]
  [   10     1]]

 [[28644     0]
  [   11     0]]

 [[28614     1]
  [   25    15]]

 [[28541    40]
  [   22    52]]

 [[28595     4]
  [    0    56]]

 [[28637     2]
  [    0    16]]

 [[28588    16]
  [   29    22]]

 [[28635     1]
  [    2    17]]

 [[28626     0]
  [   10    19]]

 [[28533    21]
  [    4    97]]

 [[28641     2]
  [    5     7]]

 [[28642     0]
  [    0    13]]

 [[28563    25]
  [    6    61]]

 [[28565    14]
  [    6    70]]

 [[28643     0]
  [    0    12]]

 [[28617     2]
  [    3    33]]

 [[26861   181]
  [  157  1456]]

 [[28355     1]
  [   15   284]]

 [[28403     9]
  [    6   237]]

 [[28470    16]
  [   13   156]]

 [[27264   367]
  [  153   871]]

 [[28193   110]
  [   92   260]]

 [[28562     7]
  [    8    78]]

 [[27911   137]
  [  141   466]]

 [[28095    17]
  [   56   487]]

 [[28574     3]
  [    6    72]]

 [[27542   159]
  [  112   842]]

 [[28346    62]
  [   12   235]]

 [[28621     0]
  [    1    33]]

 [[27537   241]
  [  104   773]]

 [[28578     0]
  [   14    63]]

 [[28029    61]
  [   86   479]]

 [[28629     2]
  [   10    14]]

 [[28589    11]
  [   22    33]]

 [[28398     2]
  [    5   250]]

 [[28641     0]
  [   11     3]]

 [[28190     8]
  [   39   418]]

 [[28618     0]
  [    7    30]]

 [[27343   123]
  [  207   982]]

 [[28414    17]
  [   45   179]]

 [[28633     2]
  [    7    13]]

 [[28275    22]
  [   23   335]]

 [[28620     3]
  [   12    20]]

 [[28642     0]
  [   13     0]]

 [[28523     4]
  [    8   120]]

 [[28642     0]
  [    4     9]]

 [[28078   117]
  [  102   358]]

 [[28547     4]
  [   14    90]]

 [[28602     1]
  [   38    14]]

 [[28560    11]
  [   39    45]]

 [[28558    17]
  [   46    34]]

 [[28572     0]
  [   16    67]]

 [[28312     8]
  [   54   281]]

 [[28631     0]
  [   18     6]]

 [[28092    45]
  [  148   370]]

 [[28534    33]
  [   74    14]]

 [[28641     1]
  [    9     4]]

 [[27788   387]
  [   97   383]]

 [[28517    12]
  [   43    83]]

 [[28630     0]
  [    0    25]]

 [[28479    23]
  [   24   129]]

 [[28634     1]
  [   15     5]]

 [[28628     0]
  [   17    10]]

 [[28607     6]
  [   16    26]]

 [[28619     2]
  [   21    13]]

 [[28505    51]
  [   42    57]]

 [[28219    20]
  [   80   336]]

 [[28511    26]
  [   56    62]]

 [[28547     9]
  [   25    74]]

 [[28312    90]
  [   64   189]]

 [[28537     3]
  [   10   105]]

 [[28166    66]
  [   84   339]]

 [[28541    15]
  [   14    85]]

 [[28581    13]
  [   20    41]]

 [[28312    77]
  [   31   235]]

 [[28617     2]
  [    6    30]]

 [[28085    76]
  [   83   411]]

 [[28641     0]
  [    2    12]]

 [[27948    97]
  [   94   516]]

 [[28434    15]
  [   27   179]]

 [[28627     6]
  [    8    14]]

 [[28051    69]
  [   75   460]]

 [[28548     9]
  [   48    50]]

 [[28549    20]
  [   37    49]]

 [[28545     1]
  [   10    99]]

 [[27606   191]
  [   81   777]]

 [[28592     2]
  [   40    21]]

 [[28434    13]
  [   22   186]]

 [[28642     0]
  [   13     0]]

 [[28566    24]
  [   16    49]]

 [[28493     5]
  [   17   140]]

 [[28567     4]
  [    1    83]]

 [[28587    13]
  [   32    23]]

 [[28492     9]
  [   34   120]]

 [[28600     3]
  [    4    48]]

 [[28503     5]
  [   13   134]]

 [[28550    28]
  [   25    52]]

 [[28637     0]
  [    3    15]]

 [[28448    10]
  [   38   159]]

 [[28170    36]
  [   30   419]]

 [[28643     1]
  [    6     5]]

 [[28612     0]
  [   16    27]]

 [[28639     1]
  [    4    11]]

 [[28450     1]
  [    5   199]]

 [[28575     4]
  [    2    74]]

 [[28388    12]
  [   46   209]]

 [[28634     2]
  [   15     4]]

 [[28641     1]
  [    3    10]]

 [[28583     5]
  [   34    33]]

 [[27070   122]
  [   10  1453]]

 [[28507     1]
  [   26   121]]

 [[28553     3]
  [   14    85]]

 [[28174    26]
  [   48   407]]

 [[28571     2]
  [    6    76]]

 [[28239     6]
  [   36   374]]

 [[28210    39]
  [    6   400]]

 [[28643     0]
  [    9     3]]

 [[28497     9]
  [   18   131]]

 [[27862    91]
  [   16   686]]

 [[28456     3]
  [    8   188]]

 [[28617     6]
  [    6    26]]

 [[28579     7]
  [    5    64]]

 [[28557     5]
  [    8    85]]

 [[28623     0]
  [    3    29]]

 [[28603     3]
  [    8    41]]

 [[28484    17]
  [    7   147]]]

===scores report===
metrics	scores
Accuracy	0.8449
MCC	0.8417
log_loss	0.7141
f1 score weighted	0.8426
f1 score macro	0.7445
f1 score micro	0.8449
roc_auc ovr	0.9935
roc_auc ovo	0.9903
precision	0.8523
recall	0.8449

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbffc496430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbffc4962e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbffc4967c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbffc4965e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  51.,  96., 109.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.92      0.89       825
         1.0       0.50      0.07      0.12        14
         2.0       1.00      0.66      0.79        32
         3.0       0.00      0.00      0.00        12
         4.0       0.93      0.73      0.82        52
         5.0       0.84      0.77      0.80       176
         6.0       0.49      0.65      0.56       102
         7.0       0.33      0.39      0.36        97
         8.0       0.50      0.14      0.22        14
         9.0       0.52      0.46      0.49        69
        10.0       0.82      0.82      0.82       104
        11.0       0.62      0.28      0.38        18
        12.0       1.00      0.07      0.12        15
        13.0       0.67      0.71      0.69        42
        14.0       0.82      0.53      0.64        34
        15.0       1.00      0.70      0.83        64
        16.0       0.83      0.38      0.53        13
        17.0       0.78      0.37      0.50        19
        18.0       0.95      0.86      0.90        71
        19.0       0.90      0.29      0.44        31
        20.0       0.98      0.98      0.98        94
        21.0       0.80      0.76      0.78        46
        22.0       0.95      0.72      0.82        25
        23.0       0.94      0.95      0.95       346
        24.0       0.86      0.81      0.83        31
        25.0       0.88      0.35      0.50        20
        26.0       0.77      0.65      0.70       167
        27.0       0.96      0.64      0.77        36
        28.0       0.92      0.90      0.91        60
        29.0       0.81      0.90      0.85        62
        30.0       1.00      0.09      0.17        11
        31.0       1.00      0.08      0.15        12
        32.0       0.67      0.50      0.57        40
        33.0       0.94      0.68      0.79        74
        34.0       0.98      1.00      0.99        56
        35.0       0.93      0.88      0.90        16
        36.0       0.78      0.14      0.23        51
        37.0       0.81      0.89      0.85        19
        38.0       0.83      0.69      0.75        29
        39.0       0.78      0.94      0.85       101
        40.0       1.00      0.58      0.74        12
        41.0       1.00      1.00      1.00        13
        42.0       0.92      0.87      0.89        67
        43.0       0.97      0.80      0.88        76
        44.0       1.00      1.00      1.00        11
        45.0       0.94      0.81      0.87        37
        46.0       0.84      0.94      0.88      1613
        47.0       0.93      0.97      0.95       299
        48.0       0.98      0.95      0.97       243
        49.0       0.95      0.97      0.96       169
        50.0       0.82      0.86      0.84      1023
        51.0       0.75      0.80      0.77       352
        52.0       0.93      0.83      0.88        86
        53.0       0.74      0.84      0.79       606
        54.0       0.93      0.89      0.91       543
        55.0       0.94      0.82      0.88        79
        56.0       0.82      0.94      0.88       954
        57.0       0.83      0.94      0.88       247
        58.0       1.00      1.00      1.00        34
        59.0       0.94      0.79      0.86       877
        60.0       0.97      0.77      0.86        77
        61.0       0.73      0.88      0.80       566
        62.0       0.45      0.54      0.49        24
        63.0       0.84      0.76      0.80        55
        64.0       0.98      0.96      0.97       255
        65.0       1.00      0.23      0.38        13
        66.0       0.97      0.93      0.95       457
        67.0       0.91      0.81      0.86        37
        68.0       0.76      0.88      0.82      1189
        69.0       0.86      0.83      0.85       223
        70.0       0.89      0.42      0.57        19
        71.0       0.90      0.97      0.94       357
        72.0       0.67      0.44      0.53        32
        73.0       0.00      0.00      0.00        13
        74.0       0.96      0.95      0.96       128
        75.0       1.00      0.62      0.76        13
        76.0       0.89      0.76      0.82       460
        77.0       0.82      0.81      0.82       104
        78.0       0.70      0.43      0.53        53
        79.0       0.86      0.59      0.70        83
        80.0       0.37      0.54      0.44        79
        81.0       0.98      0.73      0.84        84
        82.0       0.83      0.87      0.85       334
        83.0       0.75      0.12      0.21        24
        84.0       0.81      0.76      0.79       518
        85.0       0.34      0.30      0.32        88
        86.0       1.00      0.15      0.27        13
        87.0       0.57      0.70      0.63       480
        88.0       0.89      0.69      0.77       127
        89.0       0.96      0.96      0.96        24
        90.0       0.85      0.76      0.81       153
        91.0       0.57      0.20      0.30        20
        92.0       1.00      0.59      0.74        27
        93.0       0.94      0.71      0.81        42
        94.0       0.48      0.41      0.44        34
        95.0       0.73      0.47      0.58        99
        96.0       0.87      0.83      0.85       416
        97.0       0.74      0.61      0.67       118
        98.0       0.86      0.79      0.82        99
        99.0       0.78      0.79      0.79       253
       100.0       1.00      0.94      0.97       115
       101.0       0.82      0.75      0.79       423
       102.0       0.80      0.73      0.77        98
       103.0       0.80      0.67      0.73        60
       104.0       0.72      0.86      0.78       265
       105.0       1.00      0.86      0.93        36
       106.0       0.89      0.86      0.87       495
       107.0       1.00      0.57      0.73        14
       108.0       0.96      0.83      0.89       610
       109.0       0.99      0.88      0.93       206
       110.0       0.92      0.50      0.65        22
       111.0       0.86      0.88      0.87       535
       112.0       0.72      0.65      0.68        98
       113.0       0.59      0.58      0.58        86
       114.0       0.93      0.91      0.92       110
       115.0       0.82      0.88      0.85       858
       116.0       0.59      0.52      0.56        61
       117.0       0.99      0.88      0.93       208
       118.0       0.00      0.00      0.00        13
       119.0       0.89      0.64      0.74        66
       120.0       0.99      0.93      0.96       157
       121.0       0.98      0.99      0.98        84
       122.0       0.68      0.65      0.67        55
       123.0       0.89      0.70      0.78       153
       124.0       0.93      0.96      0.94        52
       125.0       0.94      0.90      0.92       147
       126.0       0.69      0.57      0.62        76
       127.0       0.94      0.89      0.91        18
       128.0       0.76      0.86      0.81       197
       129.0       0.92      0.95      0.93       450
       130.0       1.00      0.17      0.29        12
       131.0       0.70      0.67      0.68        42
       132.0       0.87      0.87      0.87        15
       133.0       0.97      0.97      0.97       204
       134.0       0.99      0.91      0.95        76
       135.0       0.72      0.87      0.79       256
       136.0       1.00      0.42      0.59        19
       137.0       0.85      0.85      0.85        13
       138.0       0.83      0.57      0.67        67
       139.0       0.96      0.98      0.97      1464
       140.0       0.96      0.89      0.93       147
       141.0       0.86      0.88      0.87        98
       142.0       0.89      0.93      0.91       455
       143.0       1.00      0.93      0.96        82
       144.0       0.96      0.97      0.96       410
       145.0       0.93      0.96      0.94       406
       146.0       0.00      0.00      0.00        12
       147.0       0.95      0.87      0.91       149
       148.0       0.94      0.95      0.95       702
       149.0       0.99      0.94      0.96       196
       150.0       0.87      0.84      0.86        32
       151.0       0.96      0.68      0.80        69
       152.0       0.91      0.95      0.93        93
       153.0       0.94      0.88      0.91        33
       154.0       0.95      0.84      0.89        50
       155.0       0.79      0.96      0.87       154

    accuracy                           0.85     28655
   macro avg       0.83      0.71      0.74     28655
weighted avg       0.85      0.85      0.85     28655


===confusion_matrix===

[[757   0   0 ...   0   0   0]
 [  4   1   0 ...   0   0   0]
 [  0   0  21 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   3]
 [  0   0   0 ...   1  42   6]
 [  0   0   0 ...   0   1 148]]

===multilabel confusion matrix===

[[[27703   127]
  [   68   757]]

 [[28640     1]
  [   13     1]]

 [[28623     0]
  [   11    21]]

 [[28643     0]
  [   12     0]]

 [[28600     3]
  [   14    38]]

 [[28454    25]
  [   41   135]]

 [[28485    68]
  [   36    66]]

 [[28481    77]
  [   59    38]]

 [[28639     2]
  [   12     2]]

 [[28556    30]
  [   37    32]]

 [[28532    19]
  [   19    85]]

 [[28634     3]
  [   13     5]]

 [[28640     0]
  [   14     1]]

 [[28598    15]
  [   12    30]]

 [[28617     4]
  [   16    18]]

 [[28591     0]
  [   19    45]]

 [[28641     1]
  [    8     5]]

 [[28634     2]
  [   12     7]]

 [[28581     3]
  [   10    61]]

 [[28623     1]
  [   22     9]]

 [[28559     2]
  [    2    92]]

 [[28600     9]
  [   11    35]]

 [[28629     1]
  [    7    18]]

 [[28289    20]
  [   18   328]]

 [[28620     4]
  [    6    25]]

 [[28634     1]
  [   13     7]]

 [[28455    33]
  [   59   108]]

 [[28618     1]
  [   13    23]]

 [[28590     5]
  [    6    54]]

 [[28580    13]
  [    6    56]]

 [[28644     0]
  [   10     1]]

 [[28643     0]
  [   11     1]]

 [[28605    10]
  [   20    20]]

 [[28578     3]
  [   24    50]]

 [[28598     1]
  [    0    56]]

 [[28638     1]
  [    2    14]]

 [[28602     2]
  [   44     7]]

 [[28632     4]
  [    2    17]]

 [[28622     4]
  [    9    20]]

 [[28527    27]
  [    6    95]]

 [[28643     0]
  [    5     7]]

 [[28642     0]
  [    0    13]]

 [[28583     5]
  [    9    58]]

 [[28577     2]
  [   15    61]]

 [[28644     0]
  [    0    11]]

 [[28616     2]
  [    7    30]]

 [[26746   296]
  [  104  1509]]

 [[28335    21]
  [    8   291]]

 [[28408     4]
  [   11   232]]

 [[28478     8]
  [    5   164]]

 [[27439   193]
  [  146   877]]

 [[28210    93]
  [   72   280]]

 [[28564     5]
  [   15    71]]

 [[27867   182]
  [   94   512]]

 [[28076    36]
  [   60   483]]

 [[28572     4]
  [   14    65]]

 [[27509   192]
  [   61   893]]

 [[28360    48]
  [   16   231]]

 [[28621     0]
  [    0    34]]

 [[27733    45]
  [  185   692]]

 [[28576     2]
  [   18    59]]

 [[27904   185]
  [   69   497]]

 [[28615    16]
  [   11    13]]

 [[28592     8]
  [   13    42]]

 [[28396     4]
  [   11   244]]

 [[28642     0]
  [   10     3]]

 [[28187    11]
  [   30   427]]

 [[28615     3]
  [    7    30]]

 [[27133   333]
  [  141  1048]]

 [[28402    30]
  [   37   186]]

 [[28635     1]
  [   11     8]]

 [[28259    39]
  [    9   348]]

 [[28616     7]
  [   18    14]]

 [[28642     0]
  [   13     0]]

 [[28522     5]
  [    6   122]]

 [[28642     0]
  [    5     8]]

 [[28153    42]
  [  110   350]]

 [[28533    18]
  [   20    84]]

 [[28592    10]
  [   30    23]]

 [[28564     8]
  [   34    49]]

 [[28502    74]
  [   36    43]]

 [[28570     1]
  [   23    61]]

 [[28260    61]
  [   44   290]]

 [[28630     1]
  [   21     3]]

 [[28047    90]
  [  124   394]]

 [[28517    50]
  [   62    26]]

 [[28642     0]
  [   11     2]]

 [[27919   256]
  [  143   337]]

 [[28517    11]
  [   40    87]]

 [[28630     1]
  [    1    23]]

 [[28482    20]
  [   36   117]]

 [[28632     3]
  [   16     4]]

 [[28628     0]
  [   11    16]]

 [[28611     2]
  [   12    30]]

 [[28606    15]
  [   20    14]]

 [[28539    17]
  [   52    47]]

 [[28185    54]
  [   69   347]]

 [[28512    25]
  [   46    72]]

 [[28543    13]
  [   21    78]]

 [[28347    55]
  [   54   199]]

 [[28540     0]
  [    7   108]]

 [[28162    70]
  [  104   319]]

 [[28539    18]
  [   26    72]]

 [[28585    10]
  [   20    40]]

 [[28303    87]
  [   38   227]]

 [[28619     0]
  [    5    31]]

 [[28105    55]
  [   70   425]]

 [[28641     0]
  [    6     8]]

 [[28025    20]
  [  103   507]]

 [[28447     2]
  [   25   181]]

 [[28632     1]
  [   11    11]]

 [[28041    79]
  [   64   471]]

 [[28532    25]
  [   34    64]]

 [[28534    35]
  [   36    50]]

 [[28538     7]
  [   10   100]]

 [[27630   167]
  [  102   756]]

 [[28572    22]
  [   29    32]]

 [[28445     2]
  [   25   183]]

 [[28642     0]
  [   13     0]]

 [[28584     5]
  [   24    42]]

 [[28496     2]
  [   11   146]]

 [[28569     2]
  [    1    83]]

 [[28583    17]
  [   19    36]]

 [[28489    13]
  [   46   107]]

 [[28599     4]
  [    2    50]]

 [[28499     9]
  [   15   132]]

 [[28560    19]
  [   33    43]]

 [[28636     1]
  [    2    16]]

 [[28404    54]
  [   27   170]]

 [[28168    37]
  [   23   427]]

 [[28643     0]
  [   10     2]]

 [[28601    12]
  [   14    28]]

 [[28638     2]
  [    2    13]]

 [[28445     6]
  [    6   198]]

 [[28578     1]
  [    7    69]]

 [[28313    86]
  [   34   222]]

 [[28636     0]
  [   11     8]]

 [[28640     2]
  [    2    11]]

 [[28580     8]
  [   29    38]]

 [[27128    63]
  [   36  1428]]

 [[28503     5]
  [   16   131]]

 [[28543    14]
  [   12    86]]

 [[28150    50]
  [   32   423]]

 [[28573     0]
  [    6    76]]

 [[28227    18]
  [   14   396]]

 [[28220    29]
  [   17   389]]

 [[28643     0]
  [   12     0]]

 [[28499     7]
  [   19   130]]

 [[27913    40]
  [   34   668]]

 [[28457     2]
  [   12   184]]

 [[28619     4]
  [    5    27]]

 [[28584     2]
  [   22    47]]

 [[28553     9]
  [    5    88]]

 [[28620     2]
  [    4    29]]

 [[28603     2]
  [    8    42]]

 [[28462    39]
  [    6   148]]]

===scores report===
metrics	scores
Accuracy	0.8501
MCC	0.8470
log_loss	0.6885
f1 score weighted	0.8471
f1 score macro	0.7390
f1 score micro	0.8501
roc_auc ovr	0.9939
roc_auc ovo	0.9911
precision	0.8547
recall	0.8501

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbffc496430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbffc4962e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbffc4967c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbffc4965e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  96.,  46., 108.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.94      0.85       824
         1.0       0.00      0.00      0.00        14
         2.0       0.88      0.72      0.79        32
         3.0       0.00      0.00      0.00        12
         4.0       0.95      0.77      0.85        52
         5.0       0.83      0.72      0.77       175
         6.0       0.75      0.50      0.60       101
         7.0       0.47      0.27      0.34        98
         8.0       0.57      0.29      0.38        14
         9.0       0.47      0.40      0.43        70
        10.0       0.76      0.74      0.75       104
        11.0       0.20      0.06      0.09        18
        12.0       0.67      0.27      0.38        15
        13.0       0.77      0.55      0.64        42
        14.0       0.73      0.47      0.57        34
        15.0       0.95      0.86      0.90        65
        16.0       0.33      0.08      0.12        13
        17.0       1.00      0.47      0.64        19
        18.0       0.95      0.82      0.88        72
        19.0       0.82      0.30      0.44        30
        20.0       0.96      0.99      0.97        94
        21.0       0.79      0.80      0.80        46
        22.0       0.95      0.72      0.82        25
        23.0       0.89      0.95      0.92       345
        24.0       0.79      0.73      0.76        30
        25.0       0.50      0.15      0.23        20
        26.0       0.54      0.79      0.64       168
        27.0       0.66      0.71      0.68        35
        28.0       0.98      0.80      0.88        61
        29.0       0.89      0.76      0.82        63
        30.0       0.67      0.18      0.29        11
        31.0       0.00      0.00      0.00        12
        32.0       0.90      0.23      0.36        40
        33.0       0.57      0.78      0.66        74
        34.0       1.00      0.98      0.99        57
        35.0       0.75      0.75      0.75        16
        36.0       0.59      0.20      0.30        50
        37.0       0.89      0.85      0.87        20
        38.0       0.94      0.55      0.70        29
        39.0       0.93      0.85      0.89       101
        40.0       1.00      0.42      0.59        12
        41.0       1.00      1.00      1.00        14
        42.0       0.94      0.75      0.83        67
        43.0       0.88      0.93      0.90        76
        44.0       1.00      1.00      1.00        11
        45.0       1.00      0.92      0.96        37
        46.0       0.83      0.93      0.88      1613
        47.0       0.93      0.98      0.95       299
        48.0       0.98      0.98      0.98       243
        49.0       0.77      0.98      0.86       168
        50.0       0.77      0.86      0.81      1024
        51.0       0.76      0.75      0.75       353
        52.0       0.91      0.84      0.87        85
        53.0       0.70      0.85      0.76       606
        54.0       0.94      0.90      0.92       543
        55.0       0.91      0.87      0.89        79
        56.0       0.85      0.92      0.88       954
        57.0       0.84      0.91      0.87       247
        58.0       1.00      0.97      0.99        34
        59.0       0.89      0.86      0.88       876
        60.0       0.97      0.88      0.92        76
        61.0       0.73      0.85      0.78       566
        62.0       0.00      0.00      0.00        24
        63.0       0.93      0.67      0.78        55
        64.0       0.97      0.95      0.96       255
        65.0       1.00      0.38      0.56        13
        66.0       0.94      0.97      0.96       457
        67.0       0.96      0.59      0.73        37
        68.0       0.76      0.92      0.83      1189
        69.0       0.95      0.82      0.88       223
        70.0       0.82      0.47      0.60        19
        71.0       0.88      0.96      0.92       357
        72.0       0.88      0.68      0.76        31
        73.0       0.00      0.00      0.00        13
        74.0       0.98      0.98      0.98       128
        75.0       0.89      0.62      0.73        13
        76.0       0.81      0.76      0.79       461
        77.0       0.99      0.80      0.88       104
        78.0       0.56      0.17      0.26        53
        79.0       0.76      0.57      0.65        83
        80.0       0.72      0.58      0.64        79
        81.0       0.97      0.85      0.90        84
        82.0       0.83      0.89      0.86       334
        83.0       0.83      0.42      0.56        24
        84.0       0.64      0.81      0.71       518
        85.0       0.18      0.02      0.04        88
        86.0       1.00      0.08      0.15        12
        87.0       0.68      0.72      0.70       481
        88.0       0.83      0.62      0.71       126
        89.0       1.00      1.00      1.00        24
        90.0       0.92      0.74      0.82       152
        91.0       0.80      0.20      0.32        20
        92.0       0.78      0.26      0.39        27
        93.0       0.92      0.52      0.67        42
        94.0       0.83      0.15      0.26        33
        95.0       0.77      0.47      0.58       100
        96.0       0.72      0.84      0.78       415
        97.0       0.80      0.52      0.63       118
        98.0       0.93      0.74      0.82       100
        99.0       0.88      0.62      0.73       253
       100.0       0.90      0.97      0.93       116
       101.0       0.83      0.78      0.81       423
       102.0       0.87      0.72      0.78        99
       103.0       0.83      0.72      0.77        60
       104.0       0.77      0.85      0.80       265
       105.0       0.97      0.86      0.91        36
       106.0       0.94      0.85      0.89       495
       107.0       0.72      0.87      0.79        15
       108.0       0.77      0.89      0.82       611
       109.0       0.93      0.91      0.92       207
       110.0       1.00      0.55      0.71        22
       111.0       0.91      0.86      0.88       535
       112.0       0.66      0.67      0.67        98
       113.0       0.82      0.52      0.63        87
       114.0       0.95      0.93      0.94       110
       115.0       0.92      0.86      0.89       858
       116.0       0.73      0.32      0.44        60
       117.0       0.87      0.91      0.89       209
       118.0       0.00      0.00      0.00        12
       119.0       0.83      0.76      0.79        66
       120.0       0.96      0.88      0.92       157
       121.0       0.99      0.96      0.98        84
       122.0       0.89      0.56      0.69        55
       123.0       0.90      0.80      0.84       153
       124.0       1.00      0.82      0.90        51
       125.0       0.89      0.90      0.89       146
       126.0       0.68      0.49      0.57        77
       127.0       0.92      0.67      0.77        18
       128.0       0.90      0.90      0.90       197
       129.0       0.94      0.94      0.94       450
       130.0       0.57      0.36      0.44        11
       131.0       0.91      0.76      0.83        42
       132.0       1.00      0.67      0.80        15
       133.0       0.99      0.95      0.97       204
       134.0       1.00      0.97      0.99        76
       135.0       0.86      0.84      0.85       256
       136.0       1.00      0.05      0.10        20
       137.0       0.86      0.92      0.89        13
       138.0       0.82      0.60      0.69        67
       139.0       0.97      0.97      0.97      1464
       140.0       0.83      0.86      0.84       147
       141.0       0.86      0.90      0.88        98
       142.0       0.95      0.89      0.92       455
       143.0       0.99      0.96      0.98        82
       144.0       0.99      0.93      0.96       410
       145.0       0.97      0.93      0.95       406
       146.0       0.00      0.00      0.00        12
       147.0       0.97      0.92      0.94       148
       148.0       0.95      0.97      0.96       702
       149.0       0.99      0.94      0.97       196
       150.0       1.00      0.69      0.81        32
       151.0       0.87      0.86      0.86        69
       152.0       0.98      0.88      0.93        93
       153.0       0.94      0.91      0.92        33
       154.0       0.86      0.88      0.87        50
       155.0       0.85      0.95      0.90       153

    accuracy                           0.85     28655
   macro avg       0.81      0.69      0.72     28655
weighted avg       0.85      0.85      0.84     28655


===confusion_matrix===

[[772   0   1 ...   0   0   0]
 [  3   0   0 ...   0   0   0]
 [  0   0  23 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   1]
 [  0   0   0 ...   1  44   4]
 [  0   0   0 ...   1   4 146]]

===multilabel confusion matrix===

[[[27605   226]
  [   52   772]]

 [[28640     1]
  [   14     0]]

 [[28620     3]
  [    9    23]]

 [[28643     0]
  [   12     0]]

 [[28601     2]
  [   12    40]]

 [[28455    25]
  [   49   126]]

 [[28537    17]
  [   50    51]]

 [[28528    29]
  [   72    26]]

 [[28638     3]
  [   10     4]]

 [[28554    31]
  [   42    28]]

 [[28527    24]
  [   27    77]]

 [[28633     4]
  [   17     1]]

 [[28638     2]
  [   11     4]]

 [[28606     7]
  [   19    23]]

 [[28615     6]
  [   18    16]]

 [[28587     3]
  [    9    56]]

 [[28640     2]
  [   12     1]]

 [[28636     0]
  [   10     9]]

 [[28580     3]
  [   13    59]]

 [[28623     2]
  [   21     9]]

 [[28557     4]
  [    1    93]]

 [[28599    10]
  [    9    37]]

 [[28629     1]
  [    7    18]]

 [[28271    39]
  [   16   329]]

 [[28619     6]
  [    8    22]]

 [[28632     3]
  [   17     3]]

 [[28374   113]
  [   35   133]]

 [[28607    13]
  [   10    25]]

 [[28593     1]
  [   12    49]]

 [[28586     6]
  [   15    48]]

 [[28643     1]
  [    9     2]]

 [[28643     0]
  [   12     0]]

 [[28614     1]
  [   31     9]]

 [[28538    43]
  [   16    58]]

 [[28598     0]
  [    1    56]]

 [[28635     4]
  [    4    12]]

 [[28598     7]
  [   40    10]]

 [[28633     2]
  [    3    17]]

 [[28625     1]
  [   13    16]]

 [[28548     6]
  [   15    86]]

 [[28643     0]
  [    7     5]]

 [[28641     0]
  [    0    14]]

 [[28585     3]
  [   17    50]]

 [[28569    10]
  [    5    71]]

 [[28644     0]
  [    0    11]]

 [[28618     0]
  [    3    34]]

 [[26740   302]
  [  115  1498]]

 [[28335    21]
  [    7   292]]

 [[28408     4]
  [    4   239]]

 [[28437    50]
  [    4   164]]

 [[27367   264]
  [  141   883]]

 [[28220    82]
  [   90   263]]

 [[28563     7]
  [   14    71]]

 [[27823   226]
  [   91   515]]

 [[28080    32]
  [   54   489]]

 [[28569     7]
  [   10    69]]

 [[27545   156]
  [   76   878]]

 [[28364    44]
  [   21   226]]

 [[28621     0]
  [    1    33]]

 [[27689    90]
  [  122   754]]

 [[28577     2]
  [    9    67]]

 [[27907   182]
  [   86   480]]

 [[28631     0]
  [   24     0]]

 [[28597     3]
  [   18    37]]

 [[28393     7]
  [   12   243]]

 [[28642     0]
  [    8     5]]

 [[28172    26]
  [   12   445]]

 [[28617     1]
  [   15    22]]

 [[27116   350]
  [  100  1089]]

 [[28422    10]
  [   41   182]]

 [[28634     2]
  [   10     9]]

 [[28249    49]
  [   13   344]]

 [[28621     3]
  [   10    21]]

 [[28642     0]
  [   13     0]]

 [[28525     2]
  [    2   126]]

 [[28641     1]
  [    5     8]]

 [[28114    80]
  [  110   351]]

 [[28550     1]
  [   21    83]]

 [[28595     7]
  [   44     9]]

 [[28557    15]
  [   36    47]]

 [[28558    18]
  [   33    46]]

 [[28569     2]
  [   13    71]]

 [[28259    62]
  [   37   297]]

 [[28629     2]
  [   14    10]]

 [[27900   237]
  [  101   417]]

 [[28558     9]
  [   86     2]]

 [[28643     0]
  [   11     1]]

 [[28015   159]
  [  137   344]]

 [[28513    16]
  [   48    78]]

 [[28631     0]
  [    0    24]]

 [[28493    10]
  [   40   112]]

 [[28634     1]
  [   16     4]]

 [[28626     2]
  [   20     7]]

 [[28611     2]
  [   20    22]]

 [[28621     1]
  [   28     5]]

 [[28541    14]
  [   53    47]]

 [[28107   133]
  [   65   350]]

 [[28522    15]
  [   57    61]]

 [[28549     6]
  [   26    74]]

 [[28381    21]
  [   97   156]]

 [[28526    13]
  [    4   112]]

 [[28165    67]
  [   91   332]]

 [[28545    11]
  [   28    71]]

 [[28586     9]
  [   17    43]]

 [[28322    68]
  [   41   224]]

 [[28618     1]
  [    5    31]]

 [[28131    29]
  [   73   422]]

 [[28635     5]
  [    2    13]]

 [[27879   165]
  [   68   543]]

 [[28434    14]
  [   19   188]]

 [[28633     0]
  [   10    12]]

 [[28072    48]
  [   74   461]]

 [[28523    34]
  [   32    66]]

 [[28558    10]
  [   42    45]]

 [[28540     5]
  [    8   102]]

 [[27734    63]
  [  117   741]]

 [[28588     7]
  [   41    19]]

 [[28418    28]
  [   18   191]]

 [[28643     0]
  [   12     0]]

 [[28579    10]
  [   16    50]]

 [[28492     6]
  [   19   138]]

 [[28570     1]
  [    3    81]]

 [[28596     4]
  [   24    31]]

 [[28488    14]
  [   31   122]]

 [[28604     0]
  [    9    42]]

 [[28492    17]
  [   15   131]]

 [[28560    18]
  [   39    38]]

 [[28636     1]
  [    6    12]]

 [[28439    19]
  [   20   177]]

 [[28178    27]
  [   29   421]]

 [[28641     3]
  [    7     4]]

 [[28610     3]
  [   10    32]]

 [[28640     0]
  [    5    10]]

 [[28450     1]
  [   11   193]]

 [[28579     0]
  [    2    74]]

 [[28364    35]
  [   41   215]]

 [[28635     0]
  [   19     1]]

 [[28640     2]
  [    1    12]]

 [[28579     9]
  [   27    40]]

 [[27149    42]
  [   45  1419]]

 [[28482    26]
  [   21   126]]

 [[28543    14]
  [   10    88]]

 [[28180    20]
  [   50   405]]

 [[28572     1]
  [    3    79]]

 [[28240     5]
  [   29   381]]

 [[28238    11]
  [   29   377]]

 [[28643     0]
  [   12     0]]

 [[28503     4]
  [   12   136]]

 [[27916    37]
  [   23   679]]

 [[28458     1]
  [   11   185]]

 [[28623     0]
  [   10    22]]

 [[28577     9]
  [   10    59]]

 [[28560     2]
  [   11    82]]

 [[28620     2]
  [    3    30]]

 [[28598     7]
  [    6    44]]

 [[28476    26]
  [    7   146]]]

===scores report===
metrics	scores
Accuracy	0.8481
MCC	0.8449
log_loss	0.6825
f1 score weighted	0.8417
f1 score macro	0.7212
f1 score micro	0.8481
roc_auc ovr	0.9940
roc_auc ovo	0.9910
precision	0.8484
recall	0.8481

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbffc496430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbffc4962e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbffc4967c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbffc4965e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56., 115., ...,  96., 109.,  88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.95      0.82       824
         1.0       0.00      0.00      0.00        14
         2.0       0.80      0.88      0.84        32
         3.0       0.50      0.09      0.15        11
         4.0       0.97      0.67      0.79        51
         5.0       0.85      0.73      0.79       176
         6.0       0.70      0.52      0.60       102
         7.0       0.53      0.28      0.36        97
         8.0       1.00      0.29      0.44        14
         9.0       0.56      0.41      0.48        70
        10.0       0.90      0.87      0.89       103
        11.0       1.00      0.17      0.29        18
        12.0       0.50      0.07      0.12        15
        13.0       0.93      0.60      0.73        43
        14.0       0.81      0.50      0.62        34
        15.0       0.83      0.75      0.79        65
        16.0       1.00      0.38      0.56        13
        17.0       0.75      0.47      0.58        19
        18.0       0.98      0.89      0.93        72
        19.0       1.00      0.20      0.33        30
        20.0       1.00      0.97      0.98        94
        21.0       0.91      0.67      0.78        46
        22.0       1.00      0.40      0.57        25
        23.0       0.98      0.90      0.94       345
        24.0       1.00      0.57      0.72        30
        25.0       0.40      0.20      0.27        20
        26.0       0.68      0.68      0.68       168
        27.0       0.89      0.69      0.77        35
        28.0       0.98      0.85      0.91        61
        29.0       0.94      0.78      0.85        63
        30.0       0.50      0.27      0.35        11
        31.0       1.00      0.08      0.15        12
        32.0       0.91      0.25      0.39        40
        33.0       0.98      0.69      0.81        74
        34.0       0.98      1.00      0.99        57
        35.0       0.79      1.00      0.88        15
        36.0       0.91      0.20      0.33        50
        37.0       0.77      0.89      0.83        19
        38.0       0.94      0.59      0.72        29
        39.0       1.00      0.83      0.91       101
        40.0       0.91      0.77      0.83        13
        41.0       1.00      1.00      1.00        14
        42.0       0.73      0.88      0.80        66
        43.0       1.00      0.82      0.90        76
        44.0       1.00      0.91      0.95        11
        45.0       0.94      0.86      0.90        37
        46.0       0.95      0.88      0.91      1612
        47.0       0.97      1.00      0.98       299
        48.0       0.98      0.97      0.98       243
        49.0       0.90      0.91      0.91       168
        50.0       0.76      0.83      0.80      1024
        51.0       0.66      0.78      0.72       353
        52.0       0.94      0.87      0.90        85
        53.0       0.63      0.86      0.73       606
        54.0       0.98      0.88      0.93       543
        55.0       0.92      0.76      0.83        78
        56.0       0.94      0.86      0.90       954
        57.0       0.68      0.96      0.79       247
        58.0       1.00      0.85      0.92        34
        59.0       0.79      0.86      0.83       877
        60.0       0.79      0.82      0.81        76
        61.0       0.77      0.85      0.81       566
        62.0       0.82      0.38      0.51        24
        63.0       0.84      0.69      0.76        55
        64.0       0.98      0.98      0.98       255
        65.0       1.00      0.21      0.35        14
        66.0       0.97      0.93      0.95       457
        67.0       0.95      0.57      0.71        37
        68.0       0.90      0.85      0.88      1189
        69.0       0.96      0.82      0.88       224
        70.0       0.44      0.84      0.58        19
        71.0       0.97      0.94      0.95       357
        72.0       0.94      0.50      0.65        32
        73.0       1.00      0.08      0.15        12
        74.0       0.98      0.94      0.96       127
        75.0       1.00      0.33      0.50        12
        76.0       0.44      0.87      0.59       460
        77.0       0.96      0.83      0.89       103
        78.0       0.86      0.35      0.49        52
        79.0       0.59      0.60      0.60        83
        80.0       0.79      0.34      0.47        80
        81.0       0.96      0.79      0.86        84
        82.0       0.95      0.87      0.90       334
        83.0       0.56      0.22      0.31        23
        84.0       0.83      0.72      0.77       519
        85.0       0.30      0.27      0.29        88
        86.0       0.00      0.00      0.00        12
        87.0       0.49      0.79      0.61       480
        88.0       0.64      0.67      0.66       126
        89.0       1.00      0.96      0.98        25
        90.0       0.72      0.74      0.73       152
        91.0       0.67      0.10      0.17        20
        92.0       0.75      0.32      0.45        28
        93.0       0.87      0.79      0.82        42
        94.0       1.00      0.03      0.06        34
        95.0       0.40      0.62      0.49       100
        96.0       0.67      0.84      0.74       415
        97.0       0.59      0.58      0.59       118
        98.0       0.96      0.69      0.80        99
        99.0       0.82      0.77      0.79       253
       100.0       0.99      0.89      0.94       116
       101.0       0.69      0.80      0.74       423
       102.0       0.88      0.78      0.82        99
       103.0       0.76      0.78      0.77        60
       104.0       0.88      0.83      0.86       265
       105.0       0.78      0.76      0.77        37
       106.0       0.89      0.80      0.85       495
       107.0       0.92      0.80      0.86        15
       108.0       0.89      0.88      0.88       611
       109.0       0.95      0.90      0.93       206
       110.0       0.82      0.82      0.82        22
       111.0       0.92      0.86      0.89       534
       112.0       0.54      0.69      0.60        98
       113.0       0.94      0.51      0.66        87
       114.0       0.97      0.89      0.93       110
       115.0       0.83      0.89      0.86       858
       116.0       0.69      0.33      0.44        61
       117.0       0.92      0.95      0.93       209
       118.0       0.00      0.00      0.00        13
       119.0       0.88      0.69      0.78        65
       120.0       0.99      0.96      0.97       156
       121.0       0.95      0.96      0.96        85
       122.0       0.77      0.64      0.70        56
       123.0       0.91      0.72      0.80       154
       124.0       0.96      0.83      0.89        52
       125.0       0.97      0.88      0.92       146
       126.0       0.83      0.52      0.64        77
       127.0       1.00      0.78      0.88        18
       128.0       0.97      0.82      0.89       198
       129.0       0.97      0.93      0.95       450
       130.0       1.00      0.45      0.62        11
       131.0       0.88      0.65      0.75        43
       132.0       1.00      0.87      0.93        15
       133.0       0.99      0.98      0.98       205
       134.0       0.99      0.91      0.95        77
       135.0       0.96      0.73      0.83       255
       136.0       0.75      0.15      0.25        20
       137.0       0.82      0.75      0.78        12
       138.0       0.84      0.40      0.55        67
       139.0       0.98      0.98      0.98      1464
       140.0       0.97      0.87      0.92       147
       141.0       0.94      0.89      0.91        98
       142.0       0.98      0.86      0.92       455
       143.0       0.99      0.94      0.96        82
       144.0       0.98      0.92      0.95       411
       145.0       0.94      0.96      0.95       405
       146.0       0.71      0.45      0.56        11
       147.0       0.91      0.90      0.90       148
       148.0       0.93      0.95      0.94       702
       149.0       0.98      0.98      0.98       196
       150.0       0.96      0.69      0.80        32
       151.0       1.00      0.86      0.92        69
       152.0       0.93      0.85      0.89        93
       153.0       0.96      0.76      0.85        33
       154.0       0.82      0.84      0.83        50
       155.0       0.83      0.95      0.89       154

    accuracy                           0.84     28655
   macro avg       0.84      0.69      0.73     28655
weighted avg       0.86      0.84      0.84     28655


===confusion_matrix===

[[786   0   0 ...   0   0   0]
 [  3   0   0 ...   0   0   0]
 [  0   0  28 ...   0   0   0]
 ...
 [  0   0   0 ...  25   1   2]
 [  0   0   0 ...   0  42   8]
 [  0   0   0 ...   1   3 147]]

===multilabel confusion matrix===

[[[27523   308]
  [   38   786]]

 [[28640     1]
  [   14     0]]

 [[28616     7]
  [    4    28]]

 [[28643     1]
  [   10     1]]

 [[28603     1]
  [   17    34]]

 [[28457    22]
  [   48   128]]

 [[28530    23]
  [   49    53]]

 [[28534    24]
  [   70    27]]

 [[28641     0]
  [   10     4]]

 [[28562    23]
  [   41    29]]

 [[28542    10]
  [   13    90]]

 [[28637     0]
  [   15     3]]

 [[28639     1]
  [   14     1]]

 [[28610     2]
  [   17    26]]

 [[28617     4]
  [   17    17]]

 [[28580    10]
  [   16    49]]

 [[28642     0]
  [    8     5]]

 [[28633     3]
  [   10     9]]

 [[28582     1]
  [    8    64]]

 [[28625     0]
  [   24     6]]

 [[28561     0]
  [    3    91]]

 [[28606     3]
  [   15    31]]

 [[28630     0]
  [   15    10]]

 [[28303     7]
  [   35   310]]

 [[28625     0]
  [   13    17]]

 [[28629     6]
  [   16     4]]

 [[28434    53]
  [   54   114]]

 [[28617     3]
  [   11    24]]

 [[28593     1]
  [    9    52]]

 [[28589     3]
  [   14    49]]

 [[28641     3]
  [    8     3]]

 [[28643     0]
  [   11     1]]

 [[28614     1]
  [   30    10]]

 [[28580     1]
  [   23    51]]

 [[28597     1]
  [    0    57]]

 [[28636     4]
  [    0    15]]

 [[28604     1]
  [   40    10]]

 [[28631     5]
  [    2    17]]

 [[28625     1]
  [   12    17]]

 [[28554     0]
  [   17    84]]

 [[28641     1]
  [    3    10]]

 [[28641     0]
  [    0    14]]

 [[28568    21]
  [    8    58]]

 [[28579     0]
  [   14    62]]

 [[28644     0]
  [    1    10]]

 [[28616     2]
  [    5    32]]

 [[26962    81]
  [  192  1420]]

 [[28346    10]
  [    1   298]]

 [[28408     4]
  [    8   235]]

 [[28470    17]
  [   15   153]]

 [[27366   265]
  [  173   851]]

 [[28159   143]
  [   76   277]]

 [[28565     5]
  [   11    74]]

 [[27746   303]
  [   87   519]]

 [[28101    11]
  [   64   479]]

 [[28572     5]
  [   19    59]]

 [[27652    49]
  [  131   823]]

 [[28297   111]
  [   11   236]]

 [[28621     0]
  [    5    29]]

 [[27581   197]
  [  121   756]]

 [[28563    16]
  [   14    62]]

 [[27944   145]
  [   84   482]]

 [[28629     2]
  [   15     9]]

 [[28593     7]
  [   17    38]]

 [[28395     5]
  [    6   249]]

 [[28641     0]
  [   11     3]]

 [[28187    11]
  [   31   426]]

 [[28617     1]
  [   16    21]]

 [[27355   111]
  [  174  1015]]

 [[28423     8]
  [   40   184]]

 [[28616    20]
  [    3    16]]

 [[28288    10]
  [   22   335]]

 [[28622     1]
  [   16    16]]

 [[28643     0]
  [   11     1]]

 [[28526     2]
  [    7   120]]

 [[28643     0]
  [    8     4]]

 [[27693   502]
  [   60   400]]

 [[28548     4]
  [   18    85]]

 [[28600     3]
  [   34    18]]

 [[28537    35]
  [   33    50]]

 [[28568     7]
  [   53    27]]

 [[28568     3]
  [   18    66]]

 [[28305    16]
  [   45   289]]

 [[28628     4]
  [   18     5]]

 [[28058    78]
  [  147   372]]

 [[28512    55]
  [   64    24]]

 [[28643     0]
  [   12     0]]

 [[27787   388]
  [  100   380]]

 [[28481    48]
  [   41    85]]

 [[28630     0]
  [    1    24]]

 [[28458    45]
  [   39   113]]

 [[28634     1]
  [   18     2]]

 [[28624     3]
  [   19     9]]

 [[28608     5]
  [    9    33]]

 [[28621     0]
  [   33     1]]

 [[28462    93]
  [   38    62]]

 [[28066   174]
  [   66   349]]

 [[28489    48]
  [   49    69]]

 [[28553     3]
  [   31    68]]

 [[28359    43]
  [   58   195]]

 [[28538     1]
  [   13   103]]

 [[28079   153]
  [   86   337]]

 [[28545    11]
  [   22    77]]

 [[28580    15]
  [   13    47]]

 [[28361    29]
  [   45   220]]

 [[28610     8]
  [    9    28]]

 [[28113    47]
  [   97   398]]

 [[28639     1]
  [    3    12]]

 [[27974    70]
  [   71   540]]

 [[28440     9]
  [   20   186]]

 [[28629     4]
  [    4    18]]

 [[28083    38]
  [   77   457]]

 [[28498    59]
  [   30    68]]

 [[28565     3]
  [   43    44]]

 [[28542     3]
  [   12    98]]

 [[27640   157]
  [   95   763]]

 [[28585     9]
  [   41    20]]

 [[28428    18]
  [   10   199]]

 [[28642     0]
  [   13     0]]

 [[28584     6]
  [   20    45]]

 [[28497     2]
  [    7   149]]

 [[28566     4]
  [    3    82]]

 [[28588    11]
  [   20    36]]

 [[28490    11]
  [   43   111]]

 [[28601     2]
  [    9    43]]

 [[28505     4]
  [   17   129]]

 [[28570     8]
  [   37    40]]

 [[28637     0]
  [    4    14]]

 [[28452     5]
  [   35   163]]

 [[28193    12]
  [   33   417]]

 [[28644     0]
  [    6     5]]

 [[28608     4]
  [   15    28]]

 [[28640     0]
  [    2    13]]

 [[28447     3]
  [    4   201]]

 [[28577     1]
  [    7    70]]

 [[28392     8]
  [   68   187]]

 [[28634     1]
  [   17     3]]

 [[28641     2]
  [    3     9]]

 [[28583     5]
  [   40    27]]

 [[27156    35]
  [   30  1434]]

 [[28504     4]
  [   19   128]]

 [[28551     6]
  [   11    87]]

 [[28194     6]
  [   62   393]]

 [[28572     1]
  [    5    77]]

 [[28237     7]
  [   32   379]]

 [[28225    25]
  [   18   387]]

 [[28642     2]
  [    6     5]]

 [[28494    13]
  [   15   133]]

 [[27903    50]
  [   32   670]]

 [[28456     3]
  [    4   192]]

 [[28622     1]
  [   10    22]]

 [[28586     0]
  [   10    59]]

 [[28556     6]
  [   14    79]]

 [[28621     1]
  [    8    25]]

 [[28596     9]
  [    8    42]]

 [[28470    31]
  [    7   147]]]

===scores report===
metrics	scores
Accuracy	0.8402
MCC	0.8371
log_loss	0.7454
f1 score weighted	0.8399
f1 score macro	0.7286
f1 score micro	0.8402
roc_auc ovr	0.9931
roc_auc ovo	0.9903
precision	0.8590
recall	0.8402

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8424413735343383	0.8393947905714303	0.7065943412112335	0.8403766589844983	0.7228878262517018	0.8424413735343383	0.9942114955454453	0.991594354216995	0.8550584549765508	0.8424413735343383
1	0.8449136276391555	0.8417328703850377	0.7141447338092511	0.8426181687624097	0.7445185264341787	0.8449136276391555	0.9934567487086248	0.9902574064818208	0.8523308707910278	0.8449136276391555
2	0.850113418251614	0.8469891746061451	0.6885488515510667	0.8470679485030072	0.7389804068798974	0.850113418251614	0.9939088873263215	0.9911062275627631	0.8546664441608142	0.850113418251614
3	0.8480544407607747	0.8448750095075338	0.6825289492541596	0.841728195032433	0.721201578747048	0.8480544407607747	0.9940321030386081	0.9910440517605865	0.8484189550209026	0.8480544407607747
4	0.840167510033153	0.8370631353434087	0.7453525595857076	0.8399305307529551	0.7286233926971715	0.840167510033153	0.9930783025308685	0.9903379051277896	0.8589531383028338	0.840167510033153
mean	0.8451380740438073	0.8420109960827112	0.7074338870822837	0.8423443004070605	0.7312423462019995	0.8451380740438073	0.9937375074299737	0.990867989029991	0.8538855726504258	0.8451380740438073
std	0.0036135390194194364	0.0035885385712079647	0.022183176150959147	0.0025481498289507873	0.009095146802079908	0.0036135390194194364	0.00041332769898108775	0.0005038178361266329	0.003463138492384262	0.0036135390194194364

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 66159.7899 secs

