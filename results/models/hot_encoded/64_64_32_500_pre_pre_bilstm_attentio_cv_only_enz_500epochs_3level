/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_3level
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3198396400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f31983962b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3198396790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f31983965b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.95      0.92       825
         1.0       0.67      0.43      0.52        14
         2.0       0.92      0.71      0.80        31
         3.0       0.00      0.00      0.00        11
         4.0       0.98      0.85      0.91        52
         5.0       0.78      0.80      0.79       176
         6.0       0.63      0.69      0.66       102
         7.0       0.61      0.54      0.57        97
         8.0       1.00      0.36      0.53        14
         9.0       0.76      0.49      0.59        70
        10.0       0.79      0.88      0.83       104
        11.0       0.86      0.33      0.48        18
        12.0       0.80      0.57      0.67        14
        13.0       0.87      0.79      0.83        43
        14.0       0.82      0.68      0.74        34
        15.0       0.96      0.83      0.89        64
        16.0       0.71      0.38      0.50        13
        17.0       0.83      0.53      0.65        19
        18.0       0.91      0.89      0.90        72
        19.0       0.75      0.60      0.67        30
        20.0       0.99      1.00      0.99        94
        21.0       0.87      0.89      0.88        46
        22.0       0.79      0.76      0.78        25
        23.0       0.96      0.96      0.96       345
        24.0       0.96      0.87      0.91        30
        25.0       0.50      0.25      0.33        20
        26.0       0.87      0.83      0.85       167
        27.0       0.91      0.81      0.85        36
        28.0       1.00      0.93      0.97        61
        29.0       0.98      0.87      0.92        63
        30.0       1.00      0.64      0.78        11
        31.0       0.20      0.09      0.13        11
        32.0       0.67      0.60      0.63        40
        33.0       0.86      0.84      0.85        73
        34.0       1.00      1.00      1.00        57
        35.0       1.00      0.87      0.93        15
        36.0       0.64      0.36      0.46        50
        37.0       0.90      0.95      0.92        19
        38.0       0.88      0.72      0.79        29
        39.0       0.94      0.97      0.96       101
        40.0       1.00      0.67      0.80        12
        41.0       0.93      1.00      0.97        14
        42.0       0.94      0.91      0.92        67
        43.0       0.99      0.88      0.93        76
        44.0       1.00      1.00      1.00        11
        45.0       1.00      0.86      0.93        37
        46.0       0.89      0.93      0.91      1613
        47.0       1.00      0.98      0.99       299
        48.0       1.00      0.98      0.99       244
        49.0       0.92      0.98      0.95       168
        50.0       0.86      0.88      0.87      1024
        51.0       0.80      0.80      0.80       353
        52.0       0.91      0.81      0.86        86
        53.0       0.81      0.84      0.82       607
        54.0       0.97      0.93      0.95       543
        55.0       0.95      0.94      0.94        78
        56.0       0.90      0.94      0.92       954
        57.0       0.91      0.92      0.92       247
        58.0       1.00      0.94      0.97        34
        59.0       0.86      0.89      0.88       877
        60.0       0.93      0.87      0.90        77
        61.0       0.85      0.91      0.88       566
        62.0       0.79      0.62      0.70        24
        63.0       0.89      0.76      0.82        55
        64.0       0.98      1.00      0.99       254
        65.0       0.69      0.64      0.67        14
        66.0       0.97      0.96      0.97       456
        67.0       0.93      0.68      0.79        38
        68.0       0.81      0.93      0.86      1189
        69.0       0.94      0.92      0.93       224
        70.0       0.89      0.84      0.86        19
        71.0       0.98      0.97      0.97       358
        72.0       0.86      0.59      0.70        32
        73.0       0.50      0.15      0.24        13
        74.0       0.98      1.00      0.99       127
        75.0       1.00      0.92      0.96        12
        76.0       0.84      0.86      0.85       460
        77.0       0.91      0.88      0.90       103
        78.0       0.60      0.46      0.52        52
        79.0       0.81      0.80      0.80        83
        80.0       0.61      0.55      0.58        80
        81.0       0.97      0.86      0.91        84
        82.0       0.90      0.93      0.92       335
        83.0       0.55      0.48      0.51        23
        84.0       0.84      0.84      0.84       518
        85.0       0.36      0.24      0.29        87
        86.0       0.71      0.38      0.50        13
        87.0       0.64      0.83      0.72       480
        88.0       0.88      0.73      0.80       126
        89.0       0.96      0.96      0.96        25
        90.0       0.88      0.81      0.85       152
        91.0       0.91      0.50      0.65        20
        92.0       0.77      0.61      0.68        28
        93.0       1.00      0.64      0.78        42
        94.0       0.78      0.62      0.69        34
        95.0       0.74      0.59      0.66        99
        96.0       0.88      0.87      0.87       415
        97.0       0.88      0.68      0.77       118
        98.0       0.95      0.77      0.85        99
        99.0       0.86      0.82      0.84       253
       100.0       0.98      0.98      0.98       116
       101.0       0.88      0.86      0.87       423
       102.0       0.94      0.86      0.90        99
       103.0       0.86      0.90      0.88        60
       104.0       0.82      0.90      0.86       266
       105.0       0.89      0.89      0.89        37
       106.0       0.88      0.89      0.89       494
       107.0       0.93      1.00      0.97        14
       108.0       0.90      0.88      0.89       610
       109.0       0.95      0.88      0.92       206
       110.0       0.77      0.45      0.57        22
       111.0       0.89      0.93      0.91       534
       112.0       0.76      0.73      0.75        98
       113.0       0.89      0.78      0.83        86
       114.0       0.99      0.92      0.95       109
       115.0       0.88      0.93      0.91       858
       116.0       0.70      0.62      0.66        61
       117.0       0.98      0.95      0.96       209
       118.0       0.50      0.08      0.13        13
       119.0       0.90      0.80      0.85        65
       120.0       0.96      0.95      0.95       156
       121.0       0.99      0.95      0.97        84
       122.0       0.81      0.62      0.70        55
       123.0       0.91      0.85      0.88       154
       124.0       0.98      0.92      0.95        52
       125.0       1.00      0.90      0.95       147
       126.0       0.77      0.71      0.74        77
       127.0       1.00      0.84      0.91        19
       128.0       0.96      0.89      0.92       198
       129.0       0.97      0.94      0.95       450
       130.0       0.85      1.00      0.92        11
       131.0       0.97      0.70      0.81        43
       132.0       1.00      0.81      0.90        16
       133.0       0.98      0.98      0.98       204
       134.0       1.00      0.96      0.98        76
       135.0       0.88      0.86      0.87       255
       136.0       0.83      0.50      0.62        20
       137.0       0.91      0.77      0.83        13
       138.0       0.85      0.69      0.76        67
       139.0       0.96      0.99      0.97      1464
       140.0       0.95      0.90      0.92       146
       141.0       0.94      0.97      0.96        99
       142.0       0.94      0.92      0.93       455
       143.0       0.99      0.93      0.96        82
       144.0       0.98      0.98      0.98       411
       145.0       0.97      0.97      0.97       406
       146.0       0.50      0.33      0.40        12
       147.0       0.96      0.91      0.93       149
       148.0       0.95      0.97      0.96       703
       149.0       0.99      0.96      0.98       195
       150.0       1.00      0.70      0.82        33
       151.0       0.98      0.81      0.89        68
       152.0       0.98      0.91      0.94        93
       153.0       0.86      0.97      0.91        33
       154.0       0.89      0.96      0.92        49
       155.0       0.94      0.95      0.94       154

    accuracy                           0.89     28656
   macro avg       0.87      0.78      0.82     28656
weighted avg       0.89      0.89      0.89     28656


===confusion_matrix===

[[781   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0  22 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   0]
 [  0   0   0 ...   0  47   1]
 [  0   0   0 ...   1   5 146]]

===multilabel confusion matrix===

[[[27734    97]
  [   44   781]]

 [[28639     3]
  [    8     6]]

 [[28623     2]
  [    9    22]]

 [[28644     1]
  [   11     0]]

 [[28603     1]
  [    8    44]]

 [[28440    40]
  [   35   141]]

 [[28513    41]
  [   32    70]]

 [[28526    33]
  [   45    52]]

 [[28642     0]
  [    9     5]]

 [[28575    11]
  [   36    34]]

 [[28528    24]
  [   13    91]]

 [[28637     1]
  [   12     6]]

 [[28640     2]
  [    6     8]]

 [[28608     5]
  [    9    34]]

 [[28617     5]
  [   11    23]]

 [[28590     2]
  [   11    53]]

 [[28641     2]
  [    8     5]]

 [[28635     2]
  [    9    10]]

 [[28578     6]
  [    8    64]]

 [[28620     6]
  [   12    18]]

 [[28561     1]
  [    0    94]]

 [[28604     6]
  [    5    41]]

 [[28626     5]
  [    6    19]]

 [[28298    13]
  [   15   330]]

 [[28625     1]
  [    4    26]]

 [[28631     5]
  [   15     5]]

 [[28468    21]
  [   28   139]]

 [[28617     3]
  [    7    29]]

 [[28595     0]
  [    4    57]]

 [[28592     1]
  [    8    55]]

 [[28645     0]
  [    4     7]]

 [[28641     4]
  [   10     1]]

 [[28604    12]
  [   16    24]]

 [[28573    10]
  [   12    61]]

 [[28599     0]
  [    0    57]]

 [[28641     0]
  [    2    13]]

 [[28596    10]
  [   32    18]]

 [[28635     2]
  [    1    18]]

 [[28624     3]
  [    8    21]]

 [[28549     6]
  [    3    98]]

 [[28644     0]
  [    4     8]]

 [[28641     1]
  [    0    14]]

 [[28585     4]
  [    6    61]]

 [[28579     1]
  [    9    67]]

 [[28645     0]
  [    0    11]]

 [[28619     0]
  [    5    32]]

 [[26863   180]
  [  105  1508]]

 [[28356     1]
  [    6   293]]

 [[28412     0]
  [    5   239]]

 [[28473    15]
  [    3   165]]

 [[27487   145]
  [  118   906]]

 [[28232    71]
  [   70   283]]

 [[28563     7]
  [   16    70]]

 [[27926   123]
  [   95   512]]

 [[28097    16]
  [   39   504]]

 [[28574     4]
  [    5    73]]

 [[27604    98]
  [   55   899]]

 [[28387    22]
  [   19   228]]

 [[28622     0]
  [    2    32]]

 [[27649   130]
  [   93   784]]

 [[28574     5]
  [   10    67]]

 [[28002    88]
  [   53   513]]

 [[28628     4]
  [    9    15]]

 [[28596     5]
  [   13    42]]

 [[28396     6]
  [    1   253]]

 [[28638     4]
  [    5     9]]

 [[28187    13]
  [   17   439]]

 [[28616     2]
  [   12    26]]

 [[27209   258]
  [   89  1100]]

 [[28419    13]
  [   19   205]]

 [[28635     2]
  [    3    16]]

 [[28290     8]
  [   10   348]]

 [[28621     3]
  [   13    19]]

 [[28641     2]
  [   11     2]]

 [[28526     3]
  [    0   127]]

 [[28644     0]
  [    1    11]]

 [[28120    76]
  [   64   396]]

 [[28544     9]
  [   12    91]]

 [[28588    16]
  [   28    24]]

 [[28558    15]
  [   17    66]]

 [[28548    28]
  [   36    44]]

 [[28570     2]
  [   12    72]]

 [[28288    33]
  [   23   312]]

 [[28624     9]
  [   12    11]]

 [[28054    84]
  [   84   434]]

 [[28532    37]
  [   66    21]]

 [[28641     2]
  [    8     5]]

 [[27953   223]
  [   82   398]]

 [[28518    12]
  [   34    92]]

 [[28630     1]
  [    1    24]]

 [[28488    16]
  [   29   123]]

 [[28635     1]
  [   10    10]]

 [[28623     5]
  [   11    17]]

 [[28614     0]
  [   15    27]]

 [[28616     6]
  [   13    21]]

 [[28537    20]
  [   41    58]]

 [[28190    51]
  [   55   360]]

 [[28527    11]
  [   38    80]]

 [[28553     4]
  [   23    76]]

 [[28370    33]
  [   46   207]]

 [[28538     2]
  [    2   114]]

 [[28182    51]
  [   59   364]]

 [[28552     5]
  [   14    85]]

 [[28587     9]
  [    6    54]]

 [[28339    51]
  [   26   240]]

 [[28615     4]
  [    4    33]]

 [[28104    58]
  [   55   439]]

 [[28641     1]
  [    0    14]]

 [[27986    60]
  [   71   539]]

 [[28441     9]
  [   24   182]]

 [[28631     3]
  [   12    10]]

 [[28059    63]
  [   38   496]]

 [[28535    23]
  [   26    72]]

 [[28562     8]
  [   19    67]]

 [[28546     1]
  [    9   100]]

 [[27693   105]
  [   58   800]]

 [[28579    16]
  [   23    38]]

 [[28442     5]
  [   11   198]]

 [[28642     1]
  [   12     1]]

 [[28585     6]
  [   13    52]]

 [[28494     6]
  [    8   148]]

 [[28571     1]
  [    4    80]]

 [[28593     8]
  [   21    34]]

 [[28489    13]
  [   23   131]]

 [[28603     1]
  [    4    48]]

 [[28509     0]
  [   14   133]]

 [[28563    16]
  [   22    55]]

 [[28637     0]
  [    3    16]]

 [[28450     8]
  [   21   177]]

 [[28191    15]
  [   27   423]]

 [[28643     2]
  [    0    11]]

 [[28612     1]
  [   13    30]]

 [[28640     0]
  [    3    13]]

 [[28448     4]
  [    4   200]]

 [[28580     0]
  [    3    73]]

 [[28371    30]
  [   35   220]]

 [[28634     2]
  [   10    10]]

 [[28642     1]
  [    3    10]]

 [[28581     8]
  [   21    46]]

 [[27129    63]
  [   20  1444]]

 [[28503     7]
  [   15   131]]

 [[28551     6]
  [    3    96]]

 [[28172    29]
  [   36   419]]

 [[28573     1]
  [    6    76]]

 [[28235    10]
  [   10   401]]

 [[28236    14]
  [   12   394]]

 [[28640     4]
  [    8     4]]

 [[28502     5]
  [   14   135]]

 [[27916    37]
  [   22   681]]

 [[28460     1]
  [    7   188]]

 [[28623     0]
  [   10    23]]

 [[28587     1]
  [   13    55]]

 [[28561     2]
  [    8    85]]

 [[28618     5]
  [    1    32]]

 [[28601     6]
  [    2    47]]

 [[28492    10]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8914
MCC	0.8891
log_loss	0.5421
f1 score weighted	0.8895
f1 score macro	0.8151
f1 score micro	0.8914
roc_auc ovr	0.9965
roc_auc ovo	0.9947
precision	0.8915
recall	0.8914

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3198396400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f31983962b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3198396790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f31983965b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 1, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([56., 56., 56., ..., 98., 51., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.94      0.90       825
         1.0       0.80      0.29      0.42        14
         2.0       0.66      0.68      0.67        31
         3.0       0.50      0.17      0.25        12
         4.0       0.85      0.85      0.85        52
         5.0       0.82      0.82      0.82       176
         6.0       0.71      0.59      0.65       102
         7.0       0.58      0.56      0.57        97
         8.0       0.67      0.57      0.62        14
         9.0       0.61      0.54      0.58        70
        10.0       0.74      0.88      0.80       104
        11.0       1.00      0.33      0.50        18
        12.0       0.67      0.43      0.52        14
        13.0       0.72      0.67      0.69        42
        14.0       0.84      0.62      0.71        34
        15.0       0.88      0.80      0.84        64
        16.0       1.00      0.50      0.67        14
        17.0       0.86      0.63      0.73        19
        18.0       0.93      0.90      0.92        72
        19.0       0.78      0.45      0.57        31
        20.0       1.00      0.98      0.99        94
        21.0       0.83      0.84      0.84        45
        22.0       1.00      0.84      0.91        25
        23.0       0.96      0.96      0.96       346
        24.0       0.81      0.87      0.84        30
        25.0       0.67      0.53      0.59        19
        26.0       0.81      0.76      0.79       167
        27.0       0.93      0.72      0.81        36
        28.0       0.97      0.97      0.97        60
        29.0       0.91      0.82      0.86        62
        30.0       0.56      0.45      0.50        11
        31.0       0.00      0.00      0.00        11
        32.0       0.71      0.60      0.65        40
        33.0       0.81      0.70      0.75        74
        34.0       1.00      1.00      1.00        56
        35.0       1.00      0.94      0.97        16
        36.0       0.73      0.53      0.61        51
        37.0       0.88      0.79      0.83        19
        38.0       0.93      0.90      0.91        29
        39.0       0.90      0.94      0.92       101
        40.0       0.89      0.67      0.76        12
        41.0       1.00      1.00      1.00        13
        42.0       0.86      0.84      0.85        67
        43.0       0.95      0.93      0.94        76
        44.0       0.92      1.00      0.96        12
        45.0       1.00      0.86      0.93        36
        46.0       0.91      0.94      0.92      1613
        47.0       0.98      0.99      0.99       299
        48.0       0.99      0.99      0.99       243
        49.0       0.94      0.96      0.95       169
        50.0       0.86      0.86      0.86      1024
        51.0       0.82      0.78      0.80       352
        52.0       0.94      0.93      0.94        86
        53.0       0.83      0.88      0.86       607
        54.0       0.95      0.92      0.94       543
        55.0       0.91      0.92      0.92        78
        56.0       0.92      0.92      0.92       954
        57.0       0.86      0.93      0.89       247
        58.0       0.97      1.00      0.99        34
        59.0       0.87      0.90      0.88       877
        60.0       0.95      0.82      0.88        77
        61.0       0.84      0.89      0.86       565
        62.0       1.00      0.54      0.70        24
        63.0       0.92      0.80      0.85        55
        64.0       0.97      0.98      0.97       255
        65.0       0.92      0.79      0.85        14
        66.0       0.98      0.95      0.96       457
        67.0       0.97      0.78      0.87        37
        68.0       0.87      0.88      0.88      1189
        69.0       0.91      0.85      0.88       224
        70.0       0.83      0.75      0.79        20
        71.0       0.96      0.95      0.95       358
        72.0       0.81      0.66      0.72        32
        73.0       0.50      0.08      0.13        13
        74.0       0.97      0.98      0.97       128
        75.0       0.92      0.92      0.92        13
        76.0       0.80      0.85      0.83       460
        77.0       0.97      0.85      0.90       104
        78.0       0.68      0.50      0.58        52
        79.0       0.83      0.68      0.75        84
        80.0       0.76      0.53      0.62        80
        81.0       0.92      0.80      0.85        83
        82.0       0.89      0.92      0.90       335
        83.0       1.00      0.58      0.74        24
        84.0       0.78      0.84      0.81       518
        85.0       0.53      0.38      0.44        88
        86.0       0.88      0.54      0.67        13
        87.0       0.62      0.83      0.71       480
        88.0       0.89      0.70      0.78       126
        89.0       0.96      1.00      0.98        25
        90.0       0.88      0.88      0.88       153
        91.0       0.67      0.30      0.41        20
        92.0       0.88      0.56      0.68        27
        93.0       0.97      0.67      0.79        42
        94.0       0.73      0.56      0.63        34
        95.0       0.66      0.70      0.68        99
        96.0       0.84      0.86      0.85       416
        97.0       0.78      0.62      0.69       118
        98.0       0.84      0.82      0.83        99
        99.0       0.78      0.77      0.78       253
       100.0       0.96      0.95      0.96       115
       101.0       0.85      0.84      0.84       423
       102.0       0.88      0.87      0.87        99
       103.0       0.89      0.80      0.84        61
       104.0       0.89      0.91      0.90       266
       105.0       0.94      0.86      0.90        36
       106.0       0.87      0.85      0.86       494
       107.0       1.00      0.93      0.96        14
       108.0       0.86      0.88      0.87       610
       109.0       0.97      0.91      0.94       206
       110.0       0.74      0.64      0.68        22
       111.0       0.90      0.94      0.92       535
       112.0       0.80      0.77      0.78        98
       113.0       0.72      0.67      0.70        86
       114.0       0.96      0.91      0.93       109
       115.0       0.87      0.92      0.90       858
       116.0       0.71      0.61      0.65        61
       117.0       0.96      0.94      0.95       208
       118.0       0.50      0.08      0.13        13
       119.0       0.88      0.77      0.82        65
       120.0       0.94      0.94      0.94       157
       121.0       0.99      0.99      0.99        84
       122.0       0.76      0.62      0.68        55
       123.0       0.92      0.84      0.88       154
       124.0       0.96      0.94      0.95        52
       125.0       0.90      0.93      0.92       147
       126.0       0.80      0.68      0.73        77
       127.0       0.88      0.78      0.82        18
       128.0       0.92      0.86      0.89       197
       129.0       0.95      0.96      0.95       449
       130.0       0.89      0.73      0.80        11
       131.0       0.91      0.67      0.77        43
       132.0       0.92      0.73      0.81        15
       133.0       0.98      0.98      0.98       204
       134.0       0.97      0.97      0.97        76
       135.0       0.86      0.87      0.87       255
       136.0       0.70      0.37      0.48        19
       137.0       0.92      0.92      0.92        13
       138.0       0.84      0.64      0.73        67
       139.0       0.95      0.99      0.97      1463
       140.0       0.90      0.92      0.91       147
       141.0       0.98      0.86      0.91        99
       142.0       0.94      0.91      0.93       455
       143.0       0.99      0.94      0.96        82
       144.0       0.97      0.95      0.96       410
       145.0       0.94      0.98      0.96       406
       146.0       0.80      0.33      0.47        12
       147.0       0.91      0.93      0.92       149
       148.0       0.95      0.97      0.96       702
       149.0       0.99      0.96      0.97       196
       150.0       0.90      0.81      0.85        32
       151.0       0.90      0.94      0.92        69
       152.0       0.94      0.96      0.95        93
       153.0       0.97      0.91      0.94        32
       154.0       0.87      0.92      0.89        49
       155.0       0.95      0.93      0.94       154

    accuracy                           0.89     28655
   macro avg       0.86      0.78      0.81     28655
weighted avg       0.89      0.89      0.88     28655


===confusion_matrix===

[[779   1   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0  21 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   0]
 [  0   0   0 ...   0  45   4]
 [  0   0   0 ...   1   5 143]]

===multilabel confusion matrix===

[[[27710   120]
  [   46   779]]

 [[28640     1]
  [   10     4]]

 [[28613    11]
  [   10    21]]

 [[28641     2]
  [   10     2]]

 [[28595     8]
  [    8    44]]

 [[28447    32]
  [   31   145]]

 [[28529    24]
  [   42    60]]

 [[28519    39]
  [   43    54]]

 [[28637     4]
  [    6     8]]

 [[28561    24]
  [   32    38]]

 [[28519    32]
  [   13    91]]

 [[28637     0]
  [   12     6]]

 [[28638     3]
  [    8     6]]

 [[28602    11]
  [   14    28]]

 [[28617     4]
  [   13    21]]

 [[28584     7]
  [   13    51]]

 [[28641     0]
  [    7     7]]

 [[28634     2]
  [    7    12]]

 [[28578     5]
  [    7    65]]

 [[28620     4]
  [   17    14]]

 [[28561     0]
  [    2    92]]

 [[28602     8]
  [    7    38]]

 [[28630     0]
  [    4    21]]

 [[28294    15]
  [   13   333]]

 [[28619     6]
  [    4    26]]

 [[28631     5]
  [    9    10]]

 [[28459    29]
  [   40   127]]

 [[28617     2]
  [   10    26]]

 [[28593     2]
  [    2    58]]

 [[28588     5]
  [   11    51]]

 [[28640     4]
  [    6     5]]

 [[28640     4]
  [   11     0]]

 [[28605    10]
  [   16    24]]

 [[28569    12]
  [   22    52]]

 [[28599     0]
  [    0    56]]

 [[28639     0]
  [    1    15]]

 [[28594    10]
  [   24    27]]

 [[28634     2]
  [    4    15]]

 [[28624     2]
  [    3    26]]

 [[28544    10]
  [    6    95]]

 [[28642     1]
  [    4     8]]

 [[28642     0]
  [    0    13]]

 [[28579     9]
  [   11    56]]

 [[28575     4]
  [    5    71]]

 [[28642     1]
  [    0    12]]

 [[28619     0]
  [    5    31]]

 [[26890   152]
  [   98  1515]]

 [[28351     5]
  [    2   297]]

 [[28410     2]
  [    3   240]]

 [[28475    11]
  [    6   163]]

 [[27490   141]
  [  143   881]]

 [[28244    59]
  [   76   276]]

 [[28564     5]
  [    6    80]]

 [[27937   111]
  [   70   537]]

 [[28088    24]
  [   43   500]]

 [[28570     7]
  [    6    72]]

 [[27623    78]
  [   79   875]]

 [[28371    37]
  [   17   230]]

 [[28620     1]
  [    0    34]]

 [[27660   118]
  [   88   789]]

 [[28575     3]
  [   14    63]]

 [[27995    95]
  [   64   501]]

 [[28631     0]
  [   11    13]]

 [[28596     4]
  [   11    44]]

 [[28393     7]
  [    6   249]]

 [[28640     1]
  [    3    11]]

 [[28187    11]
  [   25   432]]

 [[28617     1]
  [    8    29]]

 [[27307   159]
  [  137  1052]]

 [[28413    18]
  [   34   190]]

 [[28632     3]
  [    5    15]]

 [[28284    13]
  [   19   339]]

 [[28618     5]
  [   11    21]]

 [[28641     1]
  [   12     1]]

 [[28523     4]
  [    3   125]]

 [[28641     1]
  [    1    12]]

 [[28097    98]
  [   68   392]]

 [[28548     3]
  [   16    88]]

 [[28591    12]
  [   26    26]]

 [[28559    12]
  [   27    57]]

 [[28562    13]
  [   38    42]]

 [[28566     6]
  [   17    66]]

 [[28281    39]
  [   26   309]]

 [[28631     0]
  [   10    14]]

 [[28015   122]
  [   84   434]]

 [[28538    29]
  [   55    33]]

 [[28641     1]
  [    6     7]]

 [[27930   245]
  [   81   399]]

 [[28518    11]
  [   38    88]]

 [[28629     1]
  [    0    25]]

 [[28483    19]
  [   18   135]]

 [[28632     3]
  [   14     6]]

 [[28626     2]
  [   12    15]]

 [[28612     1]
  [   14    28]]

 [[28614     7]
  [   15    19]]

 [[28521    35]
  [   30    69]]

 [[28173    66]
  [   58   358]]

 [[28517    20]
  [   45    73]]

 [[28541    15]
  [   18    81]]

 [[28348    54]
  [   58   195]]

 [[28536     4]
  [    6   109]]

 [[28167    65]
  [   68   355]]

 [[28544    12]
  [   13    86]]

 [[28588     6]
  [   12    49]]

 [[28358    31]
  [   25   241]]

 [[28617     2]
  [    5    31]]

 [[28100    61]
  [   73   421]]

 [[28641     0]
  [    1    13]]

 [[27955    90]
  [   71   539]]

 [[28443     6]
  [   19   187]]

 [[28628     5]
  [    8    14]]

 [[28066    54]
  [   32   503]]

 [[28538    19]
  [   23    75]]

 [[28547    22]
  [   28    58]]

 [[28542     4]
  [   10    99]]

 [[27679   118]
  [   65   793]]

 [[28579    15]
  [   24    37]]

 [[28438     9]
  [   13   195]]

 [[28641     1]
  [   12     1]]

 [[28583     7]
  [   15    50]]

 [[28488    10]
  [   10   147]]

 [[28570     1]
  [    1    83]]

 [[28589    11]
  [   21    34]]

 [[28489    12]
  [   24   130]]

 [[28601     2]
  [    3    49]]

 [[28493    15]
  [   10   137]]

 [[28565    13]
  [   25    52]]

 [[28635     2]
  [    4    14]]

 [[28444    14]
  [   28   169]]

 [[28183    23]
  [   19   430]]

 [[28643     1]
  [    3     8]]

 [[28609     3]
  [   14    29]]

 [[28639     1]
  [    4    11]]

 [[28446     5]
  [    5   199]]

 [[28577     2]
  [    2    74]]

 [[28364    36]
  [   32   223]]

 [[28633     3]
  [   12     7]]

 [[28641     1]
  [    1    12]]

 [[28580     8]
  [   24    43]]

 [[27120    72]
  [    9  1454]]

 [[28493    15]
  [   12   135]]

 [[28554     2]
  [   14    85]]

 [[28173    27]
  [   39   416]]

 [[28572     1]
  [    5    77]]

 [[28235    10]
  [   20   390]]

 [[28223    26]
  [    8   398]]

 [[28642     1]
  [    8     4]]

 [[28493    13]
  [   10   139]]

 [[27918    35]
  [   20   682]]

 [[28457     2]
  [    8   188]]

 [[28620     3]
  [    6    26]]

 [[28579     7]
  [    4    65]]

 [[28556     6]
  [    4    89]]

 [[28622     1]
  [    3    29]]

 [[28599     7]
  [    4    45]]

 [[28494     7]
  [   11   143]]]

===scores report===
metrics	scores
Accuracy	0.8850
MCC	0.8826
log_loss	0.5859
f1 score weighted	0.8832
f1 score macro	0.8087
f1 score micro	0.8850
roc_auc ovr	0.9958
roc_auc ovo	0.9937
precision	0.8853
recall	0.8850

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3198396400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f31983962b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3198396790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f31983965b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  51.,  96., 109.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.94      0.92       825
         1.0       0.67      0.14      0.24        14
         2.0       0.82      0.72      0.77        32
         3.0       0.67      0.17      0.27        12
         4.0       0.95      0.73      0.83        52
         5.0       0.85      0.82      0.84       176
         6.0       0.66      0.68      0.67       102
         7.0       0.58      0.55      0.56        97
         8.0       0.62      0.36      0.45        14
         9.0       0.74      0.58      0.65        69
        10.0       0.77      0.76      0.76       104
        11.0       0.33      0.06      0.10        18
        12.0       0.88      0.47      0.61        15
        13.0       0.80      0.83      0.81        42
        14.0       0.73      0.65      0.69        34
        15.0       0.84      0.88      0.85        64
        16.0       0.50      0.23      0.32        13
        17.0       0.93      0.74      0.82        19
        18.0       0.96      0.93      0.94        71
        19.0       0.81      0.55      0.65        31
        20.0       0.99      0.99      0.99        94
        21.0       0.82      0.89      0.85        46
        22.0       0.95      0.80      0.87        25
        23.0       0.97      0.96      0.96       346
        24.0       1.00      0.87      0.93        31
        25.0       0.62      0.25      0.36        20
        26.0       0.84      0.75      0.79       167
        27.0       0.86      0.83      0.85        36
        28.0       0.91      0.97      0.94        60
        29.0       0.83      0.85      0.84        62
        30.0       0.89      0.73      0.80        11
        31.0       0.17      0.08      0.11        12
        32.0       0.80      0.82      0.81        40
        33.0       0.89      0.85      0.87        74
        34.0       0.95      0.98      0.96        56
        35.0       0.93      0.88      0.90        16
        36.0       0.57      0.47      0.52        51
        37.0       0.82      0.95      0.88        19
        38.0       0.89      0.83      0.86        29
        39.0       0.92      0.94      0.93       101
        40.0       0.89      0.67      0.76        12
        41.0       1.00      1.00      1.00        13
        42.0       0.90      0.94      0.92        67
        43.0       0.95      0.93      0.94        76
        44.0       1.00      0.91      0.95        11
        45.0       0.97      0.84      0.90        37
        46.0       0.91      0.94      0.93      1613
        47.0       0.97      0.98      0.98       299
        48.0       0.98      0.97      0.98       243
        49.0       0.95      0.98      0.97       169
        50.0       0.86      0.89      0.88      1023
        51.0       0.81      0.84      0.82       352
        52.0       0.89      0.90      0.89        86
        53.0       0.82      0.89      0.86       606
        54.0       0.95      0.92      0.93       543
        55.0       0.95      0.90      0.92        79
        56.0       0.91      0.93      0.92       954
        57.0       0.91      0.94      0.92       247
        58.0       0.97      1.00      0.99        34
        59.0       0.89      0.90      0.90       877
        60.0       0.94      0.82      0.88        77
        61.0       0.84      0.91      0.87       566
        62.0       0.93      0.54      0.68        24
        63.0       0.92      0.84      0.88        55
        64.0       0.99      0.97      0.98       255
        65.0       0.90      0.69      0.78        13
        66.0       0.97      0.97      0.97       457
        67.0       0.94      0.81      0.87        37
        68.0       0.87      0.88      0.87      1189
        69.0       0.94      0.92      0.93       223
        70.0       0.62      0.53      0.57        19
        71.0       0.95      0.98      0.97       357
        72.0       1.00      0.72      0.84        32
        73.0       0.83      0.38      0.53        13
        74.0       0.99      0.95      0.97       128
        75.0       1.00      0.62      0.76        13
        76.0       0.82      0.82      0.82       460
        77.0       0.91      0.81      0.86       104
        78.0       0.73      0.62      0.67        53
        79.0       0.73      0.65      0.69        83
        80.0       0.61      0.68      0.65        79
        81.0       0.94      0.88      0.91        84
        82.0       0.88      0.89      0.88       334
        83.0       0.89      0.33      0.48        24
        84.0       0.82      0.84      0.83       518
        85.0       0.39      0.38      0.38        88
        86.0       1.00      0.54      0.70        13
        87.0       0.63      0.79      0.70       480
        88.0       0.85      0.74      0.79       127
        89.0       1.00      0.96      0.98        24
        90.0       0.87      0.83      0.85       153
        91.0       0.78      0.35      0.48        20
        92.0       0.90      0.67      0.77        27
        93.0       0.97      0.76      0.85        42
        94.0       0.81      0.50      0.62        34
        95.0       0.69      0.69      0.69        99
        96.0       0.86      0.85      0.86       416
        97.0       0.81      0.68      0.74       118
        98.0       0.91      0.86      0.89        99
        99.0       0.85      0.87      0.86       253
       100.0       0.97      0.97      0.97       115
       101.0       0.81      0.83      0.82       423
       102.0       0.86      0.74      0.80        98
       103.0       0.87      0.87      0.87        60
       104.0       0.89      0.87      0.88       265
       105.0       0.89      0.94      0.92        36
       106.0       0.89      0.87      0.88       495
       107.0       1.00      0.86      0.92        14
       108.0       0.90      0.88      0.89       610
       109.0       0.96      0.91      0.94       206
       110.0       0.90      0.82      0.86        22
       111.0       0.88      0.92      0.90       535
       112.0       0.79      0.72      0.76        98
       113.0       0.79      0.71      0.75        86
       114.0       0.94      0.94      0.94       110
       115.0       0.89      0.92      0.90       858
       116.0       0.67      0.56      0.61        61
       117.0       0.98      0.92      0.95       208
       118.0       1.00      0.15      0.27        13
       119.0       0.78      0.76      0.77        66
       120.0       0.96      0.94      0.95       157
       121.0       0.98      1.00      0.99        84
       122.0       0.79      0.75      0.77        55
       123.0       0.86      0.81      0.84       153
       124.0       0.96      0.94      0.95        52
       125.0       0.95      0.93      0.94       147
       126.0       0.86      0.66      0.75        76
       127.0       0.95      1.00      0.97        18
       128.0       0.89      0.84      0.86       197
       129.0       0.96      0.95      0.95       450
       130.0       1.00      0.83      0.91        12
       131.0       0.83      0.81      0.82        42
       132.0       0.93      0.87      0.90        15
       133.0       0.96      0.98      0.97       204
       134.0       0.96      0.92      0.94        76
       135.0       0.94      0.87      0.90       256
       136.0       0.75      0.63      0.69        19
       137.0       1.00      0.85      0.92        13
       138.0       0.79      0.78      0.78        67
       139.0       0.94      0.99      0.97      1464
       140.0       0.94      0.93      0.93       147
       141.0       0.98      0.93      0.95        98
       142.0       0.98      0.95      0.96       455
       143.0       1.00      0.95      0.97        82
       144.0       0.97      0.96      0.97       410
       145.0       0.94      0.98      0.96       406
       146.0       0.67      0.17      0.27        12
       147.0       0.96      0.95      0.96       149
       148.0       0.94      0.97      0.95       702
       149.0       0.99      0.98      0.98       196
       150.0       1.00      0.91      0.95        32
       151.0       0.95      0.91      0.93        69
       152.0       0.96      0.98      0.97        93
       153.0       0.94      0.91      0.92        33
       154.0       0.94      0.94      0.94        50
       155.0       0.91      0.95      0.93       154

    accuracy                           0.89     28655
   macro avg       0.87      0.79      0.82     28655
weighted avg       0.89      0.89      0.89     28655


===confusion_matrix===

[[773   0   0 ...   0   0   0]
 [  1   2   0 ...   0   0   0]
 [  0   0  23 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   2]
 [  0   0   0 ...   0  47   2]
 [  0   0   0 ...   0   2 146]]

===multilabel confusion matrix===

[[[27746    84]
  [   52   773]]

 [[28640     1]
  [   12     2]]

 [[28618     5]
  [    9    23]]

 [[28642     1]
  [   10     2]]

 [[28601     2]
  [   14    38]]

 [[28454    25]
  [   31   145]]

 [[28518    35]
  [   33    69]]

 [[28519    39]
  [   44    53]]

 [[28638     3]
  [    9     5]]

 [[28572    14]
  [   29    40]]

 [[28527    24]
  [   25    79]]

 [[28635     2]
  [   17     1]]

 [[28639     1]
  [    8     7]]

 [[28604     9]
  [    7    35]]

 [[28613     8]
  [   12    22]]

 [[28580    11]
  [    8    56]]

 [[28639     3]
  [   10     3]]

 [[28635     1]
  [    5    14]]

 [[28581     3]
  [    5    66]]

 [[28620     4]
  [   14    17]]

 [[28560     1]
  [    1    93]]

 [[28600     9]
  [    5    41]]

 [[28629     1]
  [    5    20]]

 [[28298    11]
  [   15   331]]

 [[28624     0]
  [    4    27]]

 [[28632     3]
  [   15     5]]

 [[28465    23]
  [   42   125]]

 [[28614     5]
  [    6    30]]

 [[28589     6]
  [    2    58]]

 [[28582    11]
  [    9    53]]

 [[28643     1]
  [    3     8]]

 [[28638     5]
  [   11     1]]

 [[28607     8]
  [    7    33]]

 [[28573     8]
  [   11    63]]

 [[28596     3]
  [    1    55]]

 [[28638     1]
  [    2    14]]

 [[28586    18]
  [   27    24]]

 [[28632     4]
  [    1    18]]

 [[28623     3]
  [    5    24]]

 [[28546     8]
  [    6    95]]

 [[28642     1]
  [    4     8]]

 [[28642     0]
  [    0    13]]

 [[28581     7]
  [    4    63]]

 [[28575     4]
  [    5    71]]

 [[28644     0]
  [    1    10]]

 [[28617     1]
  [    6    31]]

 [[26894   148]
  [   90  1523]]

 [[28348     8]
  [    5   294]]

 [[28407     5]
  [    7   236]]

 [[28477     9]
  [    3   166]]

 [[27489   143]
  [  114   909]]

 [[28233    70]
  [   58   294]]

 [[28559    10]
  [    9    77]]

 [[27934   115]
  [   67   539]]

 [[28083    29]
  [   44   499]]

 [[28572     4]
  [    8    71]]

 [[27614    87]
  [   65   889]]

 [[28386    22]
  [   16   231]]

 [[28620     1]
  [    0    34]]

 [[27681    97]
  [   88   789]]

 [[28574     4]
  [   14    63]]

 [[27991    98]
  [   53   513]]

 [[28630     1]
  [   11    13]]

 [[28596     4]
  [    9    46]]

 [[28398     2]
  [    8   247]]

 [[28641     1]
  [    4     9]]

 [[28182    16]
  [   14   443]]

 [[28616     2]
  [    7    30]]

 [[27302   164]
  [  137  1052]]

 [[28420    12]
  [   18   205]]

 [[28630     6]
  [    9    10]]

 [[28281    17]
  [    7   350]]

 [[28623     0]
  [    9    23]]

 [[28641     1]
  [    8     5]]

 [[28526     1]
  [    7   121]]

 [[28642     0]
  [    5     8]]

 [[28110    85]
  [   81   379]]

 [[28543     8]
  [   20    84]]

 [[28590    12]
  [   20    33]]

 [[28552    20]
  [   29    54]]

 [[28542    34]
  [   25    54]]

 [[28566     5]
  [   10    74]]

 [[28281    40]
  [   38   296]]

 [[28630     1]
  [   16     8]]

 [[28043    94]
  [   82   436]]

 [[28515    52]
  [   55    33]]

 [[28642     0]
  [    6     7]]

 [[27953   222]
  [  100   380]]

 [[28512    16]
  [   33    94]]

 [[28631     0]
  [    1    23]]

 [[28483    19]
  [   26   127]]

 [[28633     2]
  [   13     7]]

 [[28626     2]
  [    9    18]]

 [[28612     1]
  [   10    32]]

 [[28617     4]
  [   17    17]]

 [[28525    31]
  [   31    68]]

 [[28183    56]
  [   62   354]]

 [[28518    19]
  [   38    80]]

 [[28548     8]
  [   14    85]]

 [[28364    38]
  [   33   220]]

 [[28536     4]
  [    3   112]]

 [[28150    82]
  [   71   352]]

 [[28545    12]
  [   25    73]]

 [[28587     8]
  [    8    52]]

 [[28362    28]
  [   34   231]]

 [[28615     4]
  [    2    34]]

 [[28107    53]
  [   64   431]]

 [[28641     0]
  [    2    12]]

 [[27982    63]
  [   71   539]]

 [[28442     7]
  [   19   187]]

 [[28631     2]
  [    4    18]]

 [[28056    64]
  [   43   492]]

 [[28538    19]
  [   27    71]]

 [[28553    16]
  [   25    61]]

 [[28538     7]
  [    7   103]]

 [[27698    99]
  [   71   787]]

 [[28577    17]
  [   27    34]]

 [[28444     3]
  [   16   192]]

 [[28642     0]
  [   11     2]]

 [[28575    14]
  [   16    50]]

 [[28492     6]
  [    9   148]]

 [[28569     2]
  [    0    84]]

 [[28589    11]
  [   14    41]]

 [[28482    20]
  [   29   124]]

 [[28601     2]
  [    3    49]]

 [[28501     7]
  [   10   137]]

 [[28571     8]
  [   26    50]]

 [[28636     1]
  [    0    18]]

 [[28437    21]
  [   31   166]]

 [[28185    20]
  [   22   428]]

 [[28643     0]
  [    2    10]]

 [[28606     7]
  [    8    34]]

 [[28639     1]
  [    2    13]]

 [[28443     8]
  [    5   199]]

 [[28576     3]
  [    6    70]]

 [[28386    13]
  [   34   222]]

 [[28632     4]
  [    7    12]]

 [[28642     0]
  [    2    11]]

 [[28574    14]
  [   15    52]]

 [[27103    88]
  [   12  1452]]

 [[28499     9]
  [   11   136]]

 [[28555     2]
  [    7    91]]

 [[28190    10]
  [   24   431]]

 [[28573     0]
  [    4    78]]

 [[28233    12]
  [   15   395]]

 [[28225    24]
  [   10   396]]

 [[28642     1]
  [   10     2]]

 [[28500     6]
  [    7   142]]

 [[27908    45]
  [   23   679]]

 [[28457     2]
  [    4   192]]

 [[28623     0]
  [    3    29]]

 [[28583     3]
  [    6    63]]

 [[28558     4]
  [    2    91]]

 [[28620     2]
  [    3    30]]

 [[28602     3]
  [    3    47]]

 [[28487    14]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8905
MCC	0.8882
log_loss	0.5652
f1 score weighted	0.8888
f1 score macro	0.8160
f1 score micro	0.8905
roc_auc ovr	0.9961
roc_auc ovo	0.9941
precision	0.8906
recall	0.8905

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3198396400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f31983962b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3198396790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f31983965b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  96.,  46., 108.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.95      0.90       824
         1.0       0.57      0.29      0.38        14
         2.0       0.81      0.78      0.79        32
         3.0       0.50      0.17      0.25        12
         4.0       0.87      0.79      0.83        52
         5.0       0.78      0.86      0.82       175
         6.0       0.77      0.75      0.76       101
         7.0       0.52      0.47      0.49        98
         8.0       0.75      0.43      0.55        14
         9.0       0.59      0.46      0.52        70
        10.0       0.80      0.79      0.80       104
        11.0       0.83      0.56      0.67        18
        12.0       0.70      0.47      0.56        15
        13.0       0.79      0.79      0.79        42
        14.0       1.00      0.68      0.81        34
        15.0       0.87      0.91      0.89        65
        16.0       0.40      0.15      0.22        13
        17.0       0.87      0.68      0.76        19
        18.0       0.88      0.85      0.87        72
        19.0       0.68      0.43      0.53        30
        20.0       0.97      0.97      0.97        94
        21.0       0.95      0.91      0.93        46
        22.0       0.90      0.76      0.83        25
        23.0       0.97      0.97      0.97       345
        24.0       0.81      0.87      0.84        30
        25.0       0.67      0.40      0.50        20
        26.0       0.84      0.80      0.82       168
        27.0       0.89      0.71      0.79        35
        28.0       0.96      0.84      0.89        61
        29.0       0.95      0.84      0.89        63
        30.0       0.44      0.36      0.40        11
        31.0       0.00      0.00      0.00        12
        32.0       0.88      0.53      0.66        40
        33.0       0.86      0.84      0.85        74
        34.0       1.00      1.00      1.00        57
        35.0       0.92      0.75      0.83        16
        36.0       0.64      0.42      0.51        50
        37.0       0.80      1.00      0.89        20
        38.0       0.96      0.79      0.87        29
        39.0       0.98      0.95      0.96       101
        40.0       0.75      0.50      0.60        12
        41.0       1.00      1.00      1.00        14
        42.0       0.87      0.93      0.90        67
        43.0       0.91      0.95      0.93        76
        44.0       1.00      0.91      0.95        11
        45.0       1.00      0.95      0.97        37
        46.0       0.88      0.93      0.91      1613
        47.0       0.99      0.97      0.98       299
        48.0       0.98      0.99      0.99       243
        49.0       0.95      0.99      0.97       168
        50.0       0.85      0.90      0.88      1024
        51.0       0.78      0.82      0.80       353
        52.0       0.91      0.94      0.92        85
        53.0       0.81      0.86      0.84       606
        54.0       0.93      0.92      0.93       543
        55.0       0.97      0.80      0.88        79
        56.0       0.92      0.93      0.92       954
        57.0       0.86      0.94      0.90       247
        58.0       1.00      0.97      0.99        34
        59.0       0.91      0.90      0.91       876
        60.0       0.96      0.92      0.94        76
        61.0       0.89      0.87      0.88       566
        62.0       0.83      0.79      0.81        24
        63.0       0.84      0.78      0.81        55
        64.0       1.00      0.96      0.98       255
        65.0       1.00      0.62      0.76        13
        66.0       0.98      0.98      0.98       457
        67.0       0.81      0.70      0.75        37
        68.0       0.85      0.90      0.87      1189
        69.0       0.90      0.85      0.88       223
        70.0       0.94      0.89      0.92        19
        71.0       0.97      0.95      0.96       357
        72.0       0.91      0.68      0.78        31
        73.0       0.75      0.23      0.35        13
        74.0       0.98      1.00      0.99       128
        75.0       1.00      0.85      0.92        13
        76.0       0.79      0.82      0.80       461
        77.0       0.92      0.83      0.87       104
        78.0       0.52      0.47      0.50        53
        79.0       0.83      0.63      0.71        83
        80.0       0.70      0.61      0.65        79
        81.0       0.91      0.86      0.88        84
        82.0       0.94      0.88      0.91       334
        83.0       0.80      0.50      0.62        24
        84.0       0.81      0.80      0.80       518
        85.0       0.40      0.31      0.35        88
        86.0       1.00      0.67      0.80        12
        87.0       0.68      0.81      0.74       481
        88.0       0.82      0.68      0.74       126
        89.0       1.00      1.00      1.00        24
        90.0       0.88      0.83      0.85       152
        91.0       0.88      0.35      0.50        20
        92.0       0.71      0.63      0.67        27
        93.0       0.83      0.69      0.75        42
        94.0       0.78      0.55      0.64        33
        95.0       0.74      0.66      0.70       100
        96.0       0.86      0.84      0.85       415
        97.0       0.78      0.63      0.69       118
        98.0       0.85      0.85      0.85       100
        99.0       0.88      0.81      0.85       253
       100.0       0.93      0.96      0.94       116
       101.0       0.83      0.84      0.84       423
       102.0       0.93      0.81      0.86        99
       103.0       0.78      0.82      0.80        60
       104.0       0.85      0.87      0.86       265
       105.0       0.86      0.83      0.85        36
       106.0       0.92      0.89      0.91       495
       107.0       1.00      0.87      0.93        15
       108.0       0.88      0.90      0.89       611
       109.0       0.98      0.94      0.96       207
       110.0       0.72      0.59      0.65        22
       111.0       0.88      0.92      0.90       535
       112.0       0.83      0.76      0.79        98
       113.0       0.72      0.68      0.70        87
       114.0       0.96      0.95      0.96       110
       115.0       0.92      0.92      0.92       858
       116.0       0.72      0.57      0.64        60
       117.0       0.96      0.91      0.93       209
       118.0       1.00      0.33      0.50        12
       119.0       0.84      0.88      0.86        66
       120.0       0.97      0.92      0.94       157
       121.0       0.96      0.96      0.96        84
       122.0       0.75      0.75      0.75        55
       123.0       0.86      0.81      0.84       153
       124.0       0.96      0.90      0.93        51
       125.0       0.94      0.90      0.92       146
       126.0       0.73      0.69      0.71        77
       127.0       1.00      0.78      0.88        18
       128.0       0.90      0.93      0.92       197
       129.0       0.95      0.97      0.96       450
       130.0       0.91      0.91      0.91        11
       131.0       0.86      0.88      0.87        42
       132.0       1.00      0.73      0.85        15
       133.0       0.97      0.98      0.98       204
       134.0       1.00      0.97      0.99        76
       135.0       0.88      0.87      0.88       256
       136.0       0.88      0.35      0.50        20
       137.0       1.00      1.00      1.00        13
       138.0       0.80      0.67      0.73        67
       139.0       0.93      0.99      0.96      1464
       140.0       0.94      0.90      0.92       147
       141.0       0.96      0.89      0.92        98
       142.0       0.94      0.92      0.93       455
       143.0       0.99      0.95      0.97        82
       144.0       0.98      0.96      0.97       410
       145.0       0.96      0.96      0.96       406
       146.0       0.78      0.58      0.67        12
       147.0       0.93      0.93      0.93       148
       148.0       0.94      0.98      0.96       702
       149.0       0.97      0.97      0.97       196
       150.0       0.91      0.91      0.91        32
       151.0       0.97      0.91      0.94        69
       152.0       0.98      0.96      0.97        93
       153.0       0.94      0.94      0.94        33
       154.0       0.91      0.96      0.93        50
       155.0       0.92      0.95      0.94       153

    accuracy                           0.89     28655
   macro avg       0.86      0.79      0.81     28655
weighted avg       0.89      0.89      0.89     28655


===confusion_matrix===

[[781   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0  25 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   1]
 [  0   0   0 ...   0  48   1]
 [  0   0   0 ...   0   5 145]]

===multilabel confusion matrix===

[[[27710   121]
  [   43   781]]

 [[28638     3]
  [   10     4]]

 [[28617     6]
  [    7    25]]

 [[28641     2]
  [   10     2]]

 [[28597     6]
  [   11    41]]

 [[28438    42]
  [   25   150]]

 [[28531    23]
  [   25    76]]

 [[28515    42]
  [   52    46]]

 [[28639     2]
  [    8     6]]

 [[28563    22]
  [   38    32]]

 [[28531    20]
  [   22    82]]

 [[28635     2]
  [    8    10]]

 [[28637     3]
  [    8     7]]

 [[28604     9]
  [    9    33]]

 [[28621     0]
  [   11    23]]

 [[28581     9]
  [    6    59]]

 [[28639     3]
  [   11     2]]

 [[28634     2]
  [    6    13]]

 [[28575     8]
  [   11    61]]

 [[28619     6]
  [   17    13]]

 [[28558     3]
  [    3    91]]

 [[28607     2]
  [    4    42]]

 [[28628     2]
  [    6    19]]

 [[28300    10]
  [   12   333]]

 [[28619     6]
  [    4    26]]

 [[28631     4]
  [   12     8]]

 [[28462    25]
  [   33   135]]

 [[28617     3]
  [   10    25]]

 [[28592     2]
  [   10    51]]

 [[28589     3]
  [   10    53]]

 [[28639     5]
  [    7     4]]

 [[28637     6]
  [   12     0]]

 [[28612     3]
  [   19    21]]

 [[28571    10]
  [   12    62]]

 [[28598     0]
  [    0    57]]

 [[28638     1]
  [    4    12]]

 [[28593    12]
  [   29    21]]

 [[28630     5]
  [    0    20]]

 [[28625     1]
  [    6    23]]

 [[28552     2]
  [    5    96]]

 [[28641     2]
  [    6     6]]

 [[28641     0]
  [    0    14]]

 [[28579     9]
  [    5    62]]

 [[28572     7]
  [    4    72]]

 [[28644     0]
  [    1    10]]

 [[28618     0]
  [    2    35]]

 [[26846   196]
  [  111  1502]]

 [[28352     4]
  [    8   291]]

 [[28408     4]
  [    3   240]]

 [[28479     8]
  [    2   166]]

 [[27473   158]
  [   98   926]]

 [[28219    83]
  [   64   289]]

 [[28562     8]
  [    5    80]]

 [[27929   120]
  [   83   523]]

 [[28076    36]
  [   41   502]]

 [[28574     2]
  [   16    63]]

 [[27622    79]
  [   70   884]]

 [[28371    37]
  [   14   233]]

 [[28621     0]
  [    1    33]]

 [[27704    75]
  [   84   792]]

 [[28576     3]
  [    6    70]]

 [[28026    63]
  [   74   492]]

 [[28627     4]
  [    5    19]]

 [[28592     8]
  [   12    43]]

 [[28399     1]
  [    9   246]]

 [[28642     0]
  [    5     8]]

 [[28188    10]
  [   11   446]]

 [[28612     6]
  [   11    26]]

 [[27271   195]
  [  121  1068]]

 [[28412    20]
  [   33   190]]

 [[28635     1]
  [    2    17]]

 [[28287    11]
  [   19   338]]

 [[28622     2]
  [   10    21]]

 [[28641     1]
  [   10     3]]

 [[28525     2]
  [    0   128]]

 [[28642     0]
  [    2    11]]

 [[28095    99]
  [   85   376]]

 [[28544     7]
  [   18    86]]

 [[28579    23]
  [   28    25]]

 [[28561    11]
  [   31    52]]

 [[28555    21]
  [   31    48]]

 [[28564     7]
  [   12    72]]

 [[28302    19]
  [   39   295]]

 [[28628     3]
  [   12    12]]

 [[28038    99]
  [  104   414]]

 [[28527    40]
  [   61    27]]

 [[28643     0]
  [    4     8]]

 [[27990   184]
  [   91   390]]

 [[28510    19]
  [   40    86]]

 [[28631     0]
  [    0    24]]

 [[28485    18]
  [   26   126]]

 [[28634     1]
  [   13     7]]

 [[28621     7]
  [   10    17]]

 [[28607     6]
  [   13    29]]

 [[28617     5]
  [   15    18]]

 [[28532    23]
  [   34    66]]

 [[28181    59]
  [   65   350]]

 [[28516    21]
  [   44    74]]

 [[28540    15]
  [   15    85]]

 [[28375    27]
  [   47   206]]

 [[28531     8]
  [    5   111]]

 [[28160    72]
  [   68   355]]

 [[28550     6]
  [   19    80]]

 [[28581    14]
  [   11    49]]

 [[28349    41]
  [   35   230]]

 [[28614     5]
  [    6    30]]

 [[28121    39]
  [   53   442]]

 [[28640     0]
  [    2    13]]

 [[27967    77]
  [   63   548]]

 [[28444     4]
  [   13   194]]

 [[28628     5]
  [    9    13]]

 [[28055    65]
  [   42   493]]

 [[28542    15]
  [   24    74]]

 [[28545    23]
  [   28    59]]

 [[28541     4]
  [    5   105]]

 [[27727    70]
  [   67   791]]

 [[28582    13]
  [   26    34]]

 [[28438     8]
  [   19   190]]

 [[28643     0]
  [    8     4]]

 [[28578    11]
  [    8    58]]

 [[28493     5]
  [   13   144]]

 [[28568     3]
  [    3    81]]

 [[28586    14]
  [   14    41]]

 [[28482    20]
  [   29   124]]

 [[28602     2]
  [    5    46]]

 [[28500     9]
  [   14   132]]

 [[28558    20]
  [   24    53]]

 [[28637     0]
  [    4    14]]

 [[28437    21]
  [   13   184]]

 [[28182    23]
  [   12   438]]

 [[28643     1]
  [    1    10]]

 [[28607     6]
  [    5    37]]

 [[28640     0]
  [    4    11]]

 [[28445     6]
  [    4   200]]

 [[28579     0]
  [    2    74]]

 [[28370    29]
  [   34   222]]

 [[28634     1]
  [   13     7]]

 [[28642     0]
  [    0    13]]

 [[28577    11]
  [   22    45]]

 [[27083   108]
  [   10  1454]]

 [[28499     9]
  [   15   132]]

 [[28553     4]
  [   11    87]]

 [[28172    28]
  [   36   419]]

 [[28572     1]
  [    4    78]]

 [[28237     8]
  [   15   395]]

 [[28234    15]
  [   15   391]]

 [[28641     2]
  [    5     7]]

 [[28497    10]
  [   10   138]]

 [[27911    42]
  [   14   688]]

 [[28454     5]
  [    5   191]]

 [[28620     3]
  [    3    29]]

 [[28584     2]
  [    6    63]]

 [[28560     2]
  [    4    89]]

 [[28620     2]
  [    2    31]]

 [[28600     5]
  [    2    48]]

 [[28490    12]
  [    8   145]]]

===scores report===
metrics	scores
Accuracy	0.8878
MCC	0.8855
log_loss	0.5681
f1 score weighted	0.8859
f1 score macro	0.8140
f1 score micro	0.8878
roc_auc ovr	0.9962
roc_auc ovo	0.9941
precision	0.8871
recall	0.8878

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3198396400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f31983962b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3198396790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f31983965b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56., 115., ...,  96., 109.,  88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.94      0.90       824
         1.0       0.75      0.21      0.33        14
         2.0       0.84      0.84      0.84        32
         3.0       0.25      0.09      0.13        11
         4.0       0.91      0.78      0.84        51
         5.0       0.81      0.84      0.82       176
         6.0       0.75      0.75      0.75       102
         7.0       0.69      0.58      0.63        97
         8.0       0.77      0.71      0.74        14
         9.0       0.61      0.60      0.60        70
        10.0       0.82      0.91      0.86       103
        11.0       0.83      0.28      0.42        18
        12.0       0.54      0.47      0.50        15
        13.0       0.87      0.91      0.89        43
        14.0       0.86      0.71      0.77        34
        15.0       0.85      0.80      0.83        65
        16.0       0.78      0.54      0.64        13
        17.0       0.93      0.68      0.79        19
        18.0       0.90      0.90      0.90        72
        19.0       0.83      0.50      0.62        30
        20.0       0.96      0.99      0.97        94
        21.0       0.92      0.76      0.83        46
        22.0       0.95      0.76      0.84        25
        23.0       0.96      0.96      0.96       345
        24.0       0.88      0.73      0.80        30
        25.0       0.53      0.40      0.46        20
        26.0       0.82      0.80      0.81       168
        27.0       0.96      0.77      0.86        35
        28.0       1.00      0.95      0.97        61
        29.0       0.97      0.94      0.95        63
        30.0       0.62      0.73      0.67        11
        31.0       0.33      0.25      0.29        12
        32.0       0.72      0.53      0.61        40
        33.0       0.97      0.78      0.87        74
        34.0       1.00      1.00      1.00        57
        35.0       0.94      1.00      0.97        15
        36.0       0.45      0.40      0.43        50
        37.0       0.78      0.95      0.86        19
        38.0       0.83      0.69      0.75        29
        39.0       0.97      0.93      0.95       101
        40.0       0.86      0.92      0.89        13
        41.0       1.00      0.93      0.96        14
        42.0       0.94      0.91      0.92        66
        43.0       0.93      0.88      0.91        76
        44.0       0.91      0.91      0.91        11
        45.0       1.00      0.89      0.94        37
        46.0       0.91      0.94      0.92      1612
        47.0       0.97      0.99      0.98       299
        48.0       0.97      0.98      0.97       243
        49.0       0.95      0.98      0.96       168
        50.0       0.89      0.87      0.88      1024
        51.0       0.81      0.82      0.81       353
        52.0       0.89      0.89      0.89        85
        53.0       0.84      0.86      0.85       606
        54.0       0.96      0.91      0.94       543
        55.0       0.95      0.78      0.86        78
        56.0       0.92      0.94      0.93       954
        57.0       0.92      0.94      0.93       247
        58.0       1.00      0.97      0.99        34
        59.0       0.89      0.90      0.89       877
        60.0       0.99      0.87      0.92        76
        61.0       0.86      0.89      0.87       566
        62.0       0.94      0.71      0.81        24
        63.0       0.94      0.80      0.86        55
        64.0       0.96      0.98      0.97       255
        65.0       0.82      0.64      0.72        14
        66.0       0.96      0.95      0.95       457
        67.0       0.95      0.57      0.71        37
        68.0       0.85      0.94      0.89      1189
        69.0       0.91      0.90      0.91       224
        70.0       1.00      0.79      0.88        19
        71.0       0.92      0.97      0.94       357
        72.0       0.92      0.75      0.83        32
        73.0       1.00      0.33      0.50        12
        74.0       0.99      0.95      0.97       127
        75.0       1.00      0.92      0.96        12
        76.0       0.81      0.83      0.82       460
        77.0       0.94      0.84      0.89       103
        78.0       0.76      0.65      0.70        52
        79.0       0.81      0.69      0.75        83
        80.0       0.65      0.59      0.62        80
        81.0       0.99      0.87      0.92        84
        82.0       0.90      0.91      0.91       334
        83.0       0.83      0.43      0.57        23
        84.0       0.84      0.82      0.83       519
        85.0       0.57      0.43      0.49        88
        86.0       0.62      0.42      0.50        12
        87.0       0.65      0.82      0.73       480
        88.0       0.81      0.71      0.76       126
        89.0       1.00      1.00      1.00        25
        90.0       0.86      0.80      0.83       152
        91.0       0.69      0.55      0.61        20
        92.0       0.83      0.68      0.75        28
        93.0       0.87      0.79      0.82        42
        94.0       0.68      0.56      0.61        34
        95.0       0.67      0.66      0.67       100
        96.0       0.85      0.87      0.86       415
        97.0       0.75      0.58      0.65       118
        98.0       0.90      0.80      0.84        99
        99.0       0.84      0.85      0.84       253
       100.0       0.95      0.96      0.95       116
       101.0       0.86      0.83      0.84       423
       102.0       0.90      0.80      0.84        99
       103.0       0.89      0.90      0.89        60
       104.0       0.85      0.91      0.88       265
       105.0       0.94      0.81      0.87        37
       106.0       0.88      0.88      0.88       495
       107.0       0.93      0.93      0.93        15
       108.0       0.89      0.91      0.90       611
       109.0       0.95      0.94      0.95       206
       110.0       0.72      0.59      0.65        22
       111.0       0.88      0.91      0.90       534
       112.0       0.83      0.82      0.82        98
       113.0       0.77      0.75      0.76        87
       114.0       0.96      0.93      0.94       110
       115.0       0.89      0.94      0.92       858
       116.0       0.65      0.66      0.65        61
       117.0       0.99      0.95      0.97       209
       118.0       0.00      0.00      0.00        13
       119.0       0.80      0.86      0.83        65
       120.0       0.94      0.98      0.96       156
       121.0       0.98      0.96      0.97        85
       122.0       0.95      0.73      0.83        56
       123.0       0.88      0.77      0.82       154
       124.0       1.00      0.85      0.92        52
       125.0       0.91      0.92      0.92       146
       126.0       0.77      0.73      0.75        77
       127.0       0.82      0.78      0.80        18
       128.0       0.93      0.90      0.92       198
       129.0       0.96      0.97      0.96       450
       130.0       1.00      0.64      0.78        11
       131.0       0.91      0.74      0.82        43
       132.0       0.93      0.93      0.93        15
       133.0       0.98      0.98      0.98       205
       134.0       0.99      0.95      0.97        77
       135.0       0.92      0.85      0.88       255
       136.0       0.90      0.45      0.60        20
       137.0       1.00      1.00      1.00        12
       138.0       0.79      0.73      0.76        67
       139.0       0.96      0.99      0.98      1464
       140.0       0.97      0.93      0.95       147
       141.0       0.93      0.90      0.91        98
       142.0       0.97      0.92      0.95       455
       143.0       0.99      0.94      0.96        82
       144.0       0.98      0.96      0.97       411
       145.0       0.95      0.97      0.96       405
       146.0       0.83      0.45      0.59        11
       147.0       0.95      0.93      0.94       148
       148.0       0.95      0.96      0.96       702
       149.0       0.97      0.98      0.98       196
       150.0       1.00      0.94      0.97        32
       151.0       0.97      0.91      0.94        69
       152.0       0.94      0.88      0.91        93
       153.0       0.88      0.88      0.88        33
       154.0       0.83      0.98      0.90        50
       155.0       0.90      0.92      0.91       154

    accuracy                           0.89     28655
   macro avg       0.86      0.80      0.82     28655
weighted avg       0.89      0.89      0.89     28655


===confusion_matrix===

[[775   0   0 ...   0   0   0]
 [  0   3   0 ...   0   0   0]
 [  0   0  27 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   0]
 [  0   0   0 ...   0  49   0]
 [  0   0   0 ...   2   5 142]]

===multilabel confusion matrix===

[[[27699   132]
  [   49   775]]

 [[28640     1]
  [   11     3]]

 [[28618     5]
  [    5    27]]

 [[28641     3]
  [   10     1]]

 [[28600     4]
  [   11    40]]

 [[28444    35]
  [   29   147]]

 [[28527    26]
  [   25    77]]

 [[28533    25]
  [   41    56]]

 [[28638     3]
  [    4    10]]

 [[28558    27]
  [   28    42]]

 [[28531    21]
  [    9    94]]

 [[28636     1]
  [   13     5]]

 [[28634     6]
  [    8     7]]

 [[28606     6]
  [    4    39]]

 [[28617     4]
  [   10    24]]

 [[28581     9]
  [   13    52]]

 [[28640     2]
  [    6     7]]

 [[28635     1]
  [    6    13]]

 [[28576     7]
  [    7    65]]

 [[28622     3]
  [   15    15]]

 [[28557     4]
  [    1    93]]

 [[28606     3]
  [   11    35]]

 [[28629     1]
  [    6    19]]

 [[28297    13]
  [   15   330]]

 [[28622     3]
  [    8    22]]

 [[28628     7]
  [   12     8]]

 [[28457    30]
  [   34   134]]

 [[28619     1]
  [    8    27]]

 [[28594     0]
  [    3    58]]

 [[28590     2]
  [    4    59]]

 [[28639     5]
  [    3     8]]

 [[28637     6]
  [    9     3]]

 [[28607     8]
  [   19    21]]

 [[28579     2]
  [   16    58]]

 [[28598     0]
  [    0    57]]

 [[28639     1]
  [    0    15]]

 [[28581    24]
  [   30    20]]

 [[28631     5]
  [    1    18]]

 [[28622     4]
  [    9    20]]

 [[28551     3]
  [    7    94]]

 [[28640     2]
  [    1    12]]

 [[28641     0]
  [    1    13]]

 [[28585     4]
  [    6    60]]

 [[28574     5]
  [    9    67]]

 [[28643     1]
  [    1    10]]

 [[28618     0]
  [    4    33]]

 [[26896   147]
  [  100  1512]]

 [[28346    10]
  [    2   297]]

 [[28405     7]
  [    6   237]]

 [[28478     9]
  [    4   164]]

 [[27516   115]
  [  132   892]]

 [[28234    68]
  [   64   289]]

 [[28561     9]
  [    9    76]]

 [[27952    97]
  [   87   519]]

 [[28093    19]
  [   48   495]]

 [[28574     3]
  [   17    61]]

 [[27626    75]
  [   59   895]]

 [[28388    20]
  [   16   231]]

 [[28621     0]
  [    1    33]]

 [[27676   102]
  [   90   787]]

 [[28578     1]
  [   10    66]]

 [[28005    84]
  [   61   505]]

 [[28630     1]
  [    7    17]]

 [[28597     3]
  [   11    44]]

 [[28390    10]
  [    6   249]]

 [[28639     2]
  [    5     9]]

 [[28181    17]
  [   25   432]]

 [[28617     1]
  [   16    21]]

 [[27264   202]
  [   75  1114]]

 [[28412    19]
  [   23   201]]

 [[28636     0]
  [    4    15]]

 [[28266    32]
  [   11   346]]

 [[28621     2]
  [    8    24]]

 [[28643     0]
  [    8     4]]

 [[28527     1]
  [    6   121]]

 [[28643     0]
  [    1    11]]

 [[28106    89]
  [   79   381]]

 [[28546     6]
  [   16    87]]

 [[28592    11]
  [   18    34]]

 [[28559    13]
  [   26    57]]

 [[28550    25]
  [   33    47]]

 [[28570     1]
  [   11    73]]

 [[28288    33]
  [   30   304]]

 [[28630     2]
  [   13    10]]

 [[28054    82]
  [   93   426]]

 [[28538    29]
  [   50    38]]

 [[28640     3]
  [    7     5]]

 [[27963   212]
  [   86   394]]

 [[28508    21]
  [   36    90]]

 [[28630     0]
  [    0    25]]

 [[28483    20]
  [   30   122]]

 [[28630     5]
  [    9    11]]

 [[28623     4]
  [    9    19]]

 [[28608     5]
  [    9    33]]

 [[28612     9]
  [   15    19]]

 [[28523    32]
  [   34    66]]

 [[28178    62]
  [   56   359]]

 [[28514    23]
  [   50    68]]

 [[28547     9]
  [   20    79]]

 [[28362    40]
  [   39   214]]

 [[28533     6]
  [    5   111]]

 [[28175    57]
  [   72   351]]

 [[28547     9]
  [   20    79]]

 [[28588     7]
  [    6    54]]

 [[28348    42]
  [   23   242]]

 [[28616     2]
  [    7    30]]

 [[28103    57]
  [   60   435]]

 [[28639     1]
  [    1    14]]

 [[27977    67]
  [   54   557]]

 [[28439    10]
  [   12   194]]

 [[28628     5]
  [    9    13]]

 [[28057    64]
  [   49   485]]

 [[28541    16]
  [   18    80]]

 [[28549    19]
  [   22    65]]

 [[28541     4]
  [    8   102]]

 [[27700    97]
  [   52   806]]

 [[28572    22]
  [   21    40]]

 [[28443     3]
  [   11   198]]

 [[28642     0]
  [   13     0]]

 [[28576    14]
  [    9    56]]

 [[28489    10]
  [    3   153]]

 [[28568     2]
  [    3    82]]

 [[28597     2]
  [   15    41]]

 [[28485    16]
  [   35   119]]

 [[28603     0]
  [    8    44]]

 [[28496    13]
  [   11   135]]

 [[28561    17]
  [   21    56]]

 [[28634     3]
  [    4    14]]

 [[28443    14]
  [   19   179]]

 [[28185    20]
  [   13   437]]

 [[28644     0]
  [    4     7]]

 [[28609     3]
  [   11    32]]

 [[28639     1]
  [    1    14]]

 [[28445     5]
  [    5   200]]

 [[28577     1]
  [    4    73]]

 [[28380    20]
  [   37   218]]

 [[28634     1]
  [   11     9]]

 [[28643     0]
  [    0    12]]

 [[28575    13]
  [   18    49]]

 [[27136    55]
  [   14  1450]]

 [[28504     4]
  [   11   136]]

 [[28550     7]
  [   10    88]]

 [[28187    13]
  [   35   420]]

 [[28572     1]
  [    5    77]]

 [[28235     9]
  [   18   393]]

 [[28228    22]
  [   13   392]]

 [[28643     1]
  [    6     5]]

 [[28500     7]
  [   10   138]]

 [[27919    34]
  [   26   676]]

 [[28454     5]
  [    3   193]]

 [[28623     0]
  [    2    30]]

 [[28584     2]
  [    6    63]]

 [[28557     5]
  [   11    82]]

 [[28618     4]
  [    4    29]]

 [[28595    10]
  [    1    49]]

 [[28485    16]
  [   12   142]]]

===scores report===
metrics	scores
Accuracy	0.8923
MCC	0.8901
log_loss	0.5649
f1 score weighted	0.8909
f1 score macro	0.8221
f1 score micro	0.8923
roc_auc ovr	0.9963
roc_auc ovo	0.9946
precision	0.8925
recall	0.8923

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8913665549972083	0.8890914720458266	0.5420965767403929	0.8894565268821572	0.8150777435368656	0.8913665549972082	0.996477636902866	0.9947202704274457	0.8915321322193879	0.8913665549972083
1	0.885046239748735	0.8826495748304491	0.5858521887984617	0.8831843777815179	0.8086935500159058	0.885046239748735	0.9958375491727105	0.9937142033794892	0.8852769149492282	0.885046239748735
2	0.8904903158262083	0.8882010483723831	0.5652388676655332	0.8888381081038145	0.8160229397608	0.8904903158262082	0.9960738477079257	0.9941440294653535	0.8905667104927271	0.8904903158262083
3	0.8878380736346188	0.8854840659433096	0.5681214284564875	0.8858998264210964	0.814006326563621	0.8878380736346188	0.9962261177990919	0.9940675435100618	0.8871228898053183	0.8878380736346188
4	0.8923399057756064	0.8900970499780394	0.5649288719941622	0.8908703846967888	0.8220940311619079	0.8923399057756064	0.9962798978178135	0.9945901874888995	0.8924724275076532	0.8923399057756064
mean	0.8894162179964754	0.8871046422340015	0.5652475867310075	0.887649844777075	0.8151789182078201	0.8894162179964754	0.9961790098800816	0.9942472468542499	0.8893942149948628	0.8894162179964754
std	0.002649252736402817	0.0027047364497179093	0.013920341312714777	0.002758655725952033	0.004288971149645791	0.0026492527364027916	0.00021411685028564212	0.0003656342563165277	0.0027397775751974596	0.002649252736402817

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 259468.5657 secs

