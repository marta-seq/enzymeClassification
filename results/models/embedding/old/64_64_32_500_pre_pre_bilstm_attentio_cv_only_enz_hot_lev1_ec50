/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_hot_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcb38148e80>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcb38148ac0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcb38148f70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fcb38148e50>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.78      0.78      1793
         1.0       0.84      0.85      0.85      4921
         2.0       0.78      0.82      0.80      3576
         3.0       0.72      0.67      0.70       943
         4.0       0.84      0.74      0.79       695
         5.0       0.90      0.83      0.86      1073
         6.0       0.93      0.91      0.92       471

    accuracy                           0.82     13472
   macro avg       0.83      0.80      0.81     13472
weighted avg       0.82      0.82      0.82     13472


===confusion_matrix===

[[1401  145  166   42   15   10   14]
 [ 140 4183  421   92   38   42    5]
 [ 117  384 2936   75   17   34   13]
 [  51  116  113  634   22    7    0]
 [  30   62   63   16  516    8    0]
 [  30   74   51   15    8  893    2]
 [  12   14   16    1    0    1  427]]

===multilabel confusion matrix===

[[[11299   380]
  [  392  1401]]

 [[ 7756   795]
  [  738  4183]]

 [[ 9066   830]
  [  640  2936]]

 [[12288   241]
  [  309   634]]

 [[12677   100]
  [  179   516]]

 [[12297   102]
  [  180   893]]

 [[12967    34]
  [   44   427]]]

===scores report===
metrics	scores
Accuracy	0.8158
MCC	0.7575
log_loss	0.6738
f1 score weighted	0.8156
f1 score macro	0.8134
f1 score micro	0.8158
roc_auc ovr	0.9583
roc_auc ovo	0.9644
precision	0.8164
recall	0.8158

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcb38148e80>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcb38148ac0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcb38148f70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fcb38148e50>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.80      0.77      1792
         1.0       0.84      0.84      0.84      4921
         2.0       0.78      0.80      0.79      3576
         3.0       0.75      0.69      0.72       943
         4.0       0.84      0.74      0.79       696
         5.0       0.88      0.86      0.87      1072
         6.0       0.93      0.91      0.92       471

    accuracy                           0.81     13471
   macro avg       0.83      0.80      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1431  145  143   35   14   13   11]
 [ 201 4114  436   74   33   53   10]
 [ 149  421 2851   70   40   37    8]
 [  53  113  109  653    7    7    1]
 [  32   57   59   25  513   10    0]
 [  33   54   48   11    2  924    0]
 [   8   17   16    0    0    2  428]]

===multilabel confusion matrix===

[[[11203   476]
  [  361  1431]]

 [[ 7743   807]
  [  807  4114]]

 [[ 9084   811]
  [  725  2851]]

 [[12313   215]
  [  290   653]]

 [[12679    96]
  [  183   513]]

 [[12277   122]
  [  148   924]]

 [[12970    30]
  [   43   428]]]

===scores report===
metrics	scores
Accuracy	0.8102
MCC	0.7508
log_loss	0.6985
f1 score weighted	0.8102
f1 score macro	0.8141
f1 score micro	0.8102
roc_auc ovr	0.9558
roc_auc ovo	0.9637
precision	0.8110
recall	0.8102

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcb38148e80>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcb38148ac0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcb38148f70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fcb38148e50>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.78      0.77      1792
         1.0       0.84      0.86      0.85      4921
         2.0       0.81      0.79      0.80      3576
         3.0       0.76      0.70      0.73       943
         4.0       0.78      0.77      0.77       695
         5.0       0.86      0.89      0.87      1072
         6.0       0.94      0.91      0.92       472

    accuracy                           0.82     13471
   macro avg       0.82      0.81      0.82     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1402  168  130   38   23   22    9]
 [ 169 4223  345   78   42   61    3]
 [ 141  401 2837   71   56   59   11]
 [  54  104   96  658   25    6    0]
 [  29   57   51   15  533    7    3]
 [  24   61   22    6    6  952    1]
 [  11   15   13    1    1    2  429]]

===multilabel confusion matrix===

[[[11251   428]
  [  390  1402]]

 [[ 7744   806]
  [  698  4223]]

 [[ 9238   657]
  [  739  2837]]

 [[12319   209]
  [  285   658]]

 [[12623   153]
  [  162   533]]

 [[12242   157]
  [  120   952]]

 [[12972    27]
  [   43   429]]]

===scores report===
metrics	scores
Accuracy	0.8191
MCC	0.7626
log_loss	0.6729
f1 score weighted	0.8187
f1 score macro	0.8174
f1 score micro	0.8191
roc_auc ovr	0.9607
roc_auc ovo	0.9670
precision	0.8187
recall	0.8191

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcb38148e80>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcb38148ac0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcb38148f70>]