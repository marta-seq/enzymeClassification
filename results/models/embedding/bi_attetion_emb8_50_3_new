/home/amsequeira/enzymeClassification/models/embedding/bi_attetion_emb8_50_3_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efb782d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efb782d0850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efb782d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efb782d0460>, 'x_test': array([[13, 13,  2, ...,  0,  0,  0],
       [13, 16,  8, ...,  0,  0,  0],
       [13,  3, 15, ...,  0,  0,  0],
       ...,
       [13,  4, 11, ...,  0,  0,  0],
       [17, 19, 16, ...,  6, 14,  4],
       [13, 15,  3, ...,  0,  0,  0]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.70      0.74       358
         1.0       1.00      0.25      0.40        12
         2.0       0.70      0.37      0.48        19
         3.0       0.55      0.38      0.44        80
         4.0       0.11      0.09      0.10        54
         5.0       0.22      0.03      0.06        58
         6.0       0.33      0.36      0.34        45
         7.0       0.38      0.58      0.46        48
         8.0       0.00      0.00      0.00        11
         9.0       0.32      0.33      0.33        21
        10.0       0.33      0.07      0.11        15
        11.0       0.58      0.61      0.59        36
        12.0       0.00      0.00      0.00        12
        13.0       0.81      0.68      0.74        25
        14.0       0.62      0.26      0.37        19
        15.0       0.87      0.59      0.70        22
        16.0       0.72      0.57      0.63        23
        17.0       0.95      0.60      0.73       119
        18.0       0.62      0.28      0.38        18
        19.0       0.00      0.00      0.00        12
        20.0       0.71      0.33      0.45        90
        21.0       1.00      0.08      0.15        12
        22.0       0.64      0.84      0.72        25
        23.0       1.00      0.08      0.15        12
        24.0       1.00      0.09      0.17        22
        25.0       0.46      0.32      0.37        38
        26.0       1.00      0.82      0.90        17
        27.0       0.44      0.20      0.27        35
        28.0       0.00      0.00      0.00        11
        29.0       0.32      0.58      0.41        36
        30.0       0.84      0.50      0.63        32
        31.0       0.87      0.68      0.76        38
        32.0       0.95      0.72      0.82       747
        33.0       0.75      0.85      0.80        74
        34.0       0.57      0.93      0.71        59
        35.0       0.71      0.46      0.56        48
        36.0       0.51      0.78      0.62       502
        37.0       0.52      0.68      0.59       241
        38.0       0.67      0.36      0.47        33
        39.0       0.76      0.64      0.70       344
        40.0       0.92      0.59      0.72       191
        41.0       0.88      0.44      0.58        32
        42.0       0.70      0.69      0.70       384
        43.0       0.85      0.58      0.69       118
        44.0       0.72      0.72      0.72       436
        45.0       0.95      0.75      0.84        48
        46.0       0.75      0.83      0.79       402
        47.0       0.00      0.00      0.00        17
        48.0       0.84      0.64      0.73        42
        49.0       0.82      0.94      0.87        78
        50.0       0.82      0.85      0.83       172
        51.0       1.00      0.35      0.52        20
        52.0       0.76      0.52      0.61       499
        53.0       0.73      0.79      0.76       100
        54.0       0.00      0.00      0.00        11
        55.0       0.58      0.79      0.67       103
        56.0       0.41      0.50      0.45        18
        57.0       0.50      0.10      0.17        10
        58.0       1.00      0.88      0.94        34
        59.0       0.71      0.56      0.63       231
        60.0       0.69      0.57      0.62        58
        61.0       0.33      0.03      0.06        30
        62.0       0.42      0.35      0.39        48
        63.0       0.32      0.16      0.21        50
        64.0       0.44      0.56      0.49        34
        65.0       0.34      0.85      0.49       155
        66.0       0.00      0.00      0.00        14
        67.0       0.28      0.76      0.41       314
        68.0       0.09      0.06      0.07        63
        69.0       0.61      0.59      0.60       308
        70.0       0.71      0.44      0.55        68
        71.0       0.83      0.36      0.51        66
        72.0       0.00      0.00      0.00        14
        73.0       0.73      0.32      0.44        25
        74.0       0.00      0.00      0.00        18
        75.0       0.18      0.35      0.24        60
        76.0       0.80      0.66      0.72       205
        77.0       0.43      0.29      0.34        77
        78.0       0.86      0.61      0.71        59
        79.0       0.67      0.38      0.49       139
        80.0       0.46      0.93      0.62        42
        81.0       0.28      0.42      0.34       175
        82.0       0.24      0.26      0.25        43
        83.0       0.67      0.15      0.25        26
        84.0       0.29      0.64      0.40       106
        85.0       0.33      0.36      0.34        14
        86.0       0.26      0.83      0.39       242
        87.0       0.80      0.72      0.76       309
        88.0       0.88      0.62      0.73        58
        89.0       0.50      0.18      0.27        11
        90.0       0.81      0.27      0.41       187
        91.0       0.82      0.30      0.44        46
        92.0       0.25      0.03      0.05        40
        93.0       0.88      0.22      0.35        32
        94.0       0.65      0.54      0.59       289
        95.0       0.00      0.00      0.00        31
        96.0       0.93      0.55      0.69        74
        97.0       0.77      0.37      0.50        27
        98.0       1.00      0.57      0.72        37
        99.0       0.95      0.79      0.86        24
       100.0       0.00      0.00      0.00        25
       101.0       0.72      0.48      0.57        65
       102.0       0.53      0.73      0.62        22
       103.0       0.95      0.62      0.75        64
       104.0       0.93      0.35      0.51        40
       105.0       1.00      0.75      0.86        12
       106.0       0.80      0.78      0.79       114
       107.0       0.91      0.71      0.80       161
       108.0       1.00      0.42      0.59        24
       109.0       0.60      0.58      0.59        52
       110.0       1.00      0.60      0.75        15
       111.0       0.49      0.61      0.55       123
       112.0       0.50      0.45      0.48        42
       113.0       0.94      0.80      0.86       430
       114.0       0.77      0.72      0.75        65
       115.0       0.78      0.58      0.67        31
       116.0       0.82      0.66      0.73       173
       117.0       0.72      0.90      0.80        31
       118.0       0.92      0.74      0.82       117
       119.0       0.94      0.61      0.74       136
       120.0       0.90      0.29      0.44        62
       121.0       0.80      0.79      0.80       224
       122.0       0.86      0.69      0.76        35
       123.0       0.82      0.73      0.77        37
       124.0       0.80      0.13      0.22        31
       125.0       0.55      0.73      0.63        15
       126.0       0.86      0.57      0.69        21
       127.0       0.60      1.00      0.75        73

    accuracy                           0.62     12227
   macro avg       0.62      0.48      0.51     12227
weighted avg       0.69      0.62      0.62     12227


===confusion_matrix===

[[252   0   0 ...   0   0   0]
 [  0   3   0 ...   0   0   0]
 [  0   0   7 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   3]
 [  0   0   0 ...   1  12   6]
 [  0   0   0 ...   0   0  73]]

===multilabel confusion matrix===

[[[11794    75]
  [  106   252]]

 [[12215     0]
  [    9     3]]

 [[12205     3]
  [   12     7]]

 [[12122    25]
  [   50    30]]

 [[12131    42]
  [   49     5]]

 [[12162     7]
  [   56     2]]

 [[12149    33]
  [   29    16]]

 [[12134    45]
  [   20    28]]

 [[12214     2]
  [   11     0]]

 [[12191    15]
  [   14     7]]

 [[12210     2]
  [   14     1]]

 [[12175    16]
  [   14    22]]

 [[12214     1]
  [   12     0]]

 [[12198     4]
  [    8    17]]

 [[12205     3]
  [   14     5]]

 [[12203     2]
  [    9    13]]

 [[12199     5]
  [   10    13]]

 [[12104     4]
  [   48    71]]

 [[12206     3]
  [   13     5]]

 [[12213     2]
  [   12     0]]

 [[12125    12]
  [   60    30]]

 [[12215     0]
  [   11     1]]

 [[12190    12]
  [    4    21]]

 [[12215     0]
  [   11     1]]

 [[12205     0]
  [   20     2]]

 [[12175    14]
  [   26    12]]

 [[12210     0]
  [    3    14]]

 [[12183     9]
  [   28     7]]

 [[12214     2]
  [   11     0]]

 [[12146    45]
  [   15    21]]

 [[12192     3]
  [   16    16]]

 [[12185     4]
  [   12    26]]

 [[11451    29]
  [  208   539]]

 [[12132    21]
  [   11    63]]

 [[12126    42]
  [    4    55]]

 [[12170     9]
  [   26    22]]

 [[11350   375]
  [  111   391]]

 [[11837   149]
  [   78   163]]

 [[12188     6]
  [   21    12]]

 [[11813    70]
  [  123   221]]

 [[12026    10]
  [   78   113]]

 [[12193     2]
  [   18    14]]

 [[11730   113]
  [  119   265]]

 [[12097    12]
  [   49    69]]

 [[11672   119]
  [  124   312]]

 [[12177     2]
  [   12    36]]

 [[11713   112]
  [   67   335]]

 [[12210     0]
  [   17     0]]

 [[12180     5]
  [   15    27]]

 [[12133    16]
  [    5    73]]

 [[12023    32]
  [   26   146]]

 [[12207     0]
  [   13     7]]

 [[11648    80]
  [  242   257]]

 [[12098    29]
  [   21    79]]

 [[12214     2]
  [   11     0]]

 [[12065    59]
  [   22    81]]

 [[12196    13]
  [    9     9]]

 [[12216     1]
  [    9     1]]

 [[12193     0]
  [    4    30]]

 [[11942    54]
  [  101   130]]

 [[12154    15]
  [   25    33]]

 [[12195     2]
  [   29     1]]

 [[12156    23]
  [   31    17]]

 [[12160    17]
  [   42     8]]

 [[12169    24]
  [   15    19]]

 [[11815   257]
  [   23   132]]

 [[12213     0]
  [   14     0]]

 [[11297   616]
  [   75   239]]

 [[12123    41]
  [   59     4]]

 [[11804   115]
  [  126   182]]

 [[12147    12]
  [   38    30]]

 [[12156     5]
  [   42    24]]

 [[12213     0]
  [   14     0]]

 [[12199     3]
  [   17     8]]

 [[12209     0]
  [   18     0]]

 [[12071    96]
  [   39    21]]

 [[11988    34]
  [   70   135]]

 [[12121    29]
  [   55    22]]

 [[12162     6]
  [   23    36]]

 [[12062    26]
  [   86    53]]

 [[12140    45]
  [    3    39]]

 [[11868   184]
  [  102    73]]

 [[12150    34]
  [   32    11]]

 [[12199     2]
  [   22     4]]

 [[11952   169]
  [   38    68]]

 [[12203    10]
  [    9     5]]

 [[11407   578]
  [   41   201]]

 [[11863    55]
  [   88   221]]

 [[12164     5]
  [   22    36]]

 [[12214     2]
  [    9     2]]

 [[12028    12]
  [  136    51]]

 [[12178     3]
  [   32    14]]

 [[12184     3]
  [   39     1]]

 [[12194     1]
  [   25     7]]

 [[11852    86]
  [  132   157]]

 [[12195     1]
  [   31     0]]

 [[12150     3]
  [   33    41]]

 [[12197     3]
  [   17    10]]

 [[12190     0]
  [   16    21]]

 [[12202     1]
  [    5    19]]

 [[12201     1]
  [   25     0]]

 [[12150    12]
  [   34    31]]

 [[12191    14]
  [    6    16]]

 [[12161     2]
  [   24    40]]

 [[12186     1]
  [   26    14]]

 [[12215     0]
  [    3     9]]

 [[12091    22]
  [   25    89]]

 [[12054    12]
  [   46   115]]

 [[12203     0]
  [   14    10]]

 [[12155    20]
  [   22    30]]

 [[12212     0]
  [    6     9]]

 [[12027    77]
  [   48    75]]

 [[12166    19]
  [   23    19]]

 [[11774    23]
  [   85   345]]

 [[12148    14]
  [   18    47]]

 [[12191     5]
  [   13    18]]

 [[12029    25]
  [   59   114]]

 [[12185    11]
  [    3    28]]

 [[12102     8]
  [   30    87]]

 [[12086     5]
  [   53    83]]

 [[12163     2]
  [   44    18]]

 [[11959    44]
  [   46   178]]

 [[12188     4]
  [   11    24]]

 [[12184     6]
  [   10    27]]

 [[12195     1]
  [   27     4]]

 [[12203     9]
  [    4    11]]

 [[12204     2]
  [    9    12]]

 [[12105    49]
  [    0    73]]]

===scores report===
metrics	scores
Accuracy	0.6190
MCC	0.6124
log_loss	1.8208
f1 score weighted	0.6234
f1 score macro	0.5053
f1 score micro	0.6190
roc_auc ovr	0.9665
roc_auc ovo	0.9622
precision	0.6854
recall	0.6190

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efb782d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efb782d0850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efb782d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efb782d0460>, 'x_test': array([[13,  7, 17, ...,  0,  0,  0],
       [13,  1, 11, ...,  0,  0,  0],
       [13,  3, 17, ...,  0,  0,  0],
       ...,
       [13,  1,  8, ...,  0,  0,  0],
       [13,  1, 20, ...,  0,  0,  0],
       [12, 12, 11, ..., 16,  9, 20]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.82      0.73       357
         1.0       1.00      0.17      0.29        12
         2.0       0.67      0.21      0.32        19
         3.0       0.38      0.29      0.33        80
         4.0       0.11      0.09      0.10        54
         5.0       0.18      0.10      0.13        58
         6.0       0.26      0.18      0.21        44
         7.0       0.68      0.62      0.65        48
         8.0       0.00      0.00      0.00        11
         9.0       0.50      0.19      0.28        21
        10.0       0.00      0.00      0.00        15
        11.0       0.96      0.75      0.84        36
        12.0       0.50      0.17      0.25        12
        13.0       0.79      0.60      0.68        25
        14.0       0.60      0.15      0.24        20
        15.0       0.93      0.57      0.70        23
        16.0       0.48      0.61      0.54        23
        17.0       0.82      0.83      0.83       119
        18.0       0.77      0.59      0.67        17
        19.0       0.00      0.00      0.00        13
        20.0       0.60      0.47      0.52        90
        21.0       1.00      0.25      0.40        12
        22.0       0.83      0.60      0.70        25
        23.0       1.00      0.17      0.29        12
        24.0       0.58      0.32      0.41        22
        25.0       0.80      0.43      0.56        37
        26.0       0.90      1.00      0.95        18
        27.0       0.32      0.17      0.22        35
        28.0       0.00      0.00      0.00        12
        29.0       0.58      0.57      0.58        37
        30.0       0.77      0.75      0.76        32
        31.0       0.77      0.69      0.73        39
        32.0       0.74      0.82      0.78       746
        33.0       0.85      0.85      0.85        74
        34.0       0.78      0.78      0.78        58
        35.0       0.72      0.60      0.66        48
        36.0       0.62      0.73      0.67       502
        37.0       0.62      0.71      0.66       241
        38.0       0.43      0.27      0.33        33
        39.0       0.52      0.72      0.60       344
        40.0       0.79      0.69      0.74       191
        41.0       0.63      0.61      0.62        31
        42.0       0.67      0.72      0.70       384
        43.0       0.84      0.84      0.84       118
        44.0       0.68      0.72      0.70       436
        45.0       0.83      0.81      0.82        48
        46.0       0.76      0.85      0.80       402
        47.0       1.00      0.47      0.64        17
        48.0       0.89      0.60      0.71        42
        49.0       0.85      0.88      0.87        77
        50.0       0.87      0.79      0.83       172
        51.0       1.00      0.65      0.79        20
        52.0       0.64      0.66      0.65       499
        53.0       0.83      0.48      0.61        99
        54.0       0.75      0.27      0.40        11
        55.0       0.72      0.71      0.71       103
        56.0       0.67      0.33      0.44        18
        57.0       0.00      0.00      0.00        11
        58.0       0.94      0.91      0.93        34
        59.0       0.52      0.66      0.59       231
        60.0       0.88      0.62      0.73        58
        61.0       0.00      0.00      0.00        30
        62.0       0.38      0.29      0.33        48
        63.0       0.37      0.14      0.21        49
        64.0       0.75      0.62      0.68        34
        65.0       0.84      0.62      0.72       154
        66.0       0.00      0.00      0.00        14
        67.0       0.55      0.61      0.58       314
        68.0       0.06      0.02      0.03        63
        69.0       0.46      0.66      0.54       308
        70.0       0.25      0.28      0.26        69
        71.0       0.46      0.48      0.47        66
        72.0       0.33      0.07      0.12        14
        73.0       0.65      0.52      0.58        25
        74.0       0.00      0.00      0.00        18
        75.0       0.17      0.07      0.10        59
        76.0       0.70      0.66      0.68       205
        77.0       0.45      0.27      0.34        77
        78.0       0.67      0.49      0.57        59
        79.0       0.53      0.54      0.53       139
        80.0       0.73      0.80      0.77        41
        81.0       0.42      0.49      0.45       175
        82.0       0.40      0.44      0.42        43
        83.0       0.33      0.04      0.07        26
        84.0       0.51      0.41      0.45       105
        85.0       1.00      0.43      0.60        14
        86.0       0.59      0.65      0.62       242
        87.0       0.73      0.76      0.74       309
        88.0       0.86      0.55      0.67        58
        89.0       1.00      0.27      0.43        11
        90.0       0.57      0.58      0.57       187
        91.0       0.50      0.15      0.23        46
        92.0       0.08      0.03      0.04        40
        93.0       0.68      0.52      0.59        33
        94.0       0.44      0.69      0.53       289
        95.0       0.11      0.03      0.05        32
        96.0       0.75      0.61      0.67        74
        97.0       0.45      0.33      0.38        27
        98.0       0.73      0.51      0.60        37
        99.0       0.95      0.75      0.84        24
       100.0       0.00      0.00      0.00        26
       101.0       0.52      0.42      0.46        65
       102.0       0.64      0.41      0.50        22
       103.0       0.76      0.80      0.78        64
       104.0       0.39      0.28      0.32        40
       105.0       1.00      0.62      0.76        13
       106.0       0.83      0.80      0.81       113
       107.0       0.83      0.77      0.80       162
       108.0       0.57      0.33      0.42        24
       109.0       0.71      0.62      0.66        52
       110.0       1.00      0.80      0.89        15
       111.0       0.64      0.71      0.67       123
       112.0       0.80      0.49      0.61        41
       113.0       0.85      0.92      0.88       430
       114.0       0.82      0.82      0.82        65
       115.0       0.76      0.52      0.62        31
       116.0       0.82      0.72      0.76       173
       117.0       0.78      0.70      0.74        30
       118.0       0.86      0.86      0.86       118
       119.0       0.65      0.75      0.69       136
       120.0       0.73      0.66      0.69        61
       121.0       0.73      0.86      0.79       225
       122.0       0.94      0.91      0.93        35
       123.0       0.73      0.63      0.68        38
       124.0       0.94      0.52      0.67        31
       125.0       0.82      0.88      0.85        16
       126.0       0.61      0.67      0.64        21
       127.0       0.70      0.82      0.75        73

    accuracy                           0.66     12227
   macro avg       0.62      0.51      0.54     12227
weighted avg       0.65      0.66      0.64     12227


===confusion_matrix===

[[292   0   0 ...   0   0   0]
 [  1   2   0 ...   0   0   0]
 [  0   0   4 ...   0   0   0]
 ...
 [  0   0   0 ...  14   1   0]
 [  0   0   0 ...   0  14   2]
 [  0   0   0 ...   2   4  60]]

===multilabel confusion matrix===

[[[11718   152]
  [   65   292]]

 [[12215     0]
  [   10     2]]

 [[12206     2]
  [   15     4]]

 [[12110    37]
  [   57    23]]

 [[12133    40]
  [   49     5]]

 [[12142    27]
  [   52     6]]

 [[12160    23]
  [   36     8]]

 [[12165    14]
  [   18    30]]

 [[12216     0]
  [   11     0]]

 [[12202     4]
  [   17     4]]

 [[12212     0]
  [   15     0]]

 [[12190     1]
  [    9    27]]

 [[12213     2]
  [   10     2]]

 [[12198     4]
  [   10    15]]

 [[12205     2]
  [   17     3]]

 [[12203     1]
  [   10    13]]

 [[12189    15]
  [    9    14]]

 [[12087    21]
  [   20    99]]

 [[12207     3]
  [    7    10]]

 [[12212     2]
  [   13     0]]

 [[12109    28]
  [   48    42]]

 [[12215     0]
  [    9     3]]

 [[12199     3]
  [   10    15]]

 [[12215     0]
  [   10     2]]

 [[12200     5]
  [   15     7]]

 [[12186     4]
  [   21    16]]

 [[12207     2]
  [    0    18]]

 [[12179    13]
  [   29     6]]

 [[12215     0]
  [   12     0]]

 [[12175    15]
  [   16    21]]

 [[12188     7]
  [    8    24]]

 [[12180     8]
  [   12    27]]

 [[11260   221]
  [  133   613]]

 [[12142    11]
  [   11    63]]

 [[12156    13]
  [   13    45]]

 [[12168    11]
  [   19    29]]

 [[11502   223]
  [  137   365]]

 [[11884   102]
  [   71   170]]

 [[12182    12]
  [   24     9]]

 [[11654   229]
  [   96   248]]

 [[12002    34]
  [   60   131]]

 [[12185    11]
  [   12    19]]

 [[11707   136]
  [  107   277]]

 [[12090    19]
  [   19    99]]

 [[11645   146]
  [  124   312]]

 [[12171     8]
  [    9    39]]

 [[11715   110]
  [   61   341]]

 [[12210     0]
  [    9     8]]

 [[12182     3]
  [   17    25]]

 [[12138    12]
  [    9    68]]

 [[12035    20]
  [   36   136]]

 [[12207     0]
  [    7    13]]

 [[11542   186]
  [  172   327]]

 [[12118    10]
  [   51    48]]

 [[12215     1]
  [    8     3]]

 [[12095    29]
  [   30    73]]

 [[12206     3]
  [   12     6]]

 [[12216     0]
  [   11     0]]

 [[12191     2]
  [    3    31]]

 [[11857   139]
  [   78   153]]

 [[12164     5]
  [   22    36]]

 [[12193     4]
  [   30     0]]

 [[12156    23]
  [   34    14]]

 [[12166    12]
  [   42     7]]

 [[12186     7]
  [   13    21]]

 [[12055    18]
  [   58    96]]

 [[12213     0]
  [   14     0]]

 [[11759   154]
  [  122   192]]

 [[12149    15]
  [   62     1]]

 [[11679   240]
  [  104   204]]

 [[12101    57]
  [   50    19]]

 [[12123    38]
  [   34    32]]

 [[12211     2]
  [   13     1]]

 [[12195     7]
  [   12    13]]

 [[12209     0]
  [   18     0]]

 [[12149    19]
  [   55     4]]

 [[11963    59]
  [   69   136]]

 [[12124    26]
  [   56    21]]

 [[12154    14]
  [   30    29]]

 [[12021    67]
  [   64    75]]

 [[12174    12]
  [    8    33]]

 [[11936   116]
  [   90    85]]

 [[12155    29]
  [   24    19]]

 [[12199     2]
  [   25     1]]

 [[12080    42]
  [   62    43]]

 [[12213     0]
  [    8     6]]

 [[11873   112]
  [   84   158]]

 [[11832    86]
  [   75   234]]

 [[12164     5]
  [   26    32]]

 [[12216     0]
  [    8     3]]

 [[11959    81]
  [   79   108]]

 [[12174     7]
  [   39     7]]

 [[12176    11]
  [   39     1]]

 [[12186     8]
  [   16    17]]

 [[11681   257]
  [   90   199]]

 [[12187     8]
  [   31     1]]

 [[12138    15]
  [   29    45]]

 [[12189    11]
  [   18     9]]

 [[12183     7]
  [   18    19]]

 [[12202     1]
  [    6    18]]

 [[12200     1]
  [   26     0]]

 [[12137    25]
  [   38    27]]

 [[12200     5]
  [   13     9]]

 [[12147    16]
  [   13    51]]

 [[12170    17]
  [   29    11]]

 [[12214     0]
  [    5     8]]

 [[12095    19]
  [   23    90]]

 [[12040    25]
  [   37   125]]

 [[12197     6]
  [   16     8]]

 [[12162    13]
  [   20    32]]

 [[12212     0]
  [    3    12]]

 [[12054    50]
  [   36    87]]

 [[12181     5]
  [   21    20]]

 [[11729    68]
  [   35   395]]

 [[12150    12]
  [   12    53]]

 [[12191     5]
  [   15    16]]

 [[12026    28]
  [   49   124]]

 [[12191     6]
  [    9    21]]

 [[12092    17]
  [   17   101]]

 [[12035    56]
  [   34   102]]

 [[12151    15]
  [   21    40]]

 [[11931    71]
  [   31   194]]

 [[12190     2]
  [    3    32]]

 [[12180     9]
  [   14    24]]

 [[12195     1]
  [   15    16]]

 [[12208     3]
  [    2    14]]

 [[12197     9]
  [    7    14]]

 [[12128    26]
  [   13    60]]]

===scores report===
metrics	scores
Accuracy	0.6554
MCC	0.6475
log_loss	1.6229
f1 score weighted	0.6431
f1 score macro	0.5378
f1 score micro	0.6554
roc_auc ovr	0.9676
roc_auc ovo	0.9620
precision	0.6491
recall	0.6554

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efb782d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efb782d0850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efb782d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efb782d0460>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13, 16,  7, ...,  0,  0,  0],
       [13, 16, 16, ...,  0,  0,  0],
       ...,
       [13, 16, 16, ...,  0,  0,  0],
       [ 6, 17,  1, ...,  4,  6, 11],
       [13,  6, 12, ...,  0,  0,  0]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.80      0.79       357
         1.0       0.30      0.46      0.36        13
         2.0       1.00      0.05      0.10        19
         3.0       0.43      0.44      0.44        79
         4.0       0.30      0.15      0.20        55
         5.0       0.23      0.10      0.14        59
         6.0       0.34      0.25      0.29        44
         7.0       0.78      0.52      0.62        48
         8.0       0.50      0.10      0.17        10
         9.0       0.50      0.29      0.36        21
        10.0       1.00      0.27      0.42        15
        11.0       0.57      0.78      0.66        36
        12.0       0.00      0.00      0.00        12
        13.0       0.48      0.60      0.54        25
        14.0       0.14      0.05      0.07        20
        15.0       0.70      0.64      0.67        22
        16.0       0.55      0.52      0.53        23
        17.0       0.70      0.82      0.75       118
        18.0       0.60      0.67      0.63        18
        19.0       0.00      0.00      0.00        13
        20.0       0.56      0.49      0.52        89
        21.0       0.29      0.17      0.21        12
        22.0       0.90      0.79      0.84        24
        23.0       0.25      0.08      0.12        12
        24.0       0.22      0.26      0.24        23
        25.0       0.52      0.46      0.49        37
        26.0       0.88      0.88      0.88        17
        27.0       0.31      0.14      0.19        36
        28.0       1.00      0.17      0.29        12
        29.0       0.69      0.49      0.57        37
        30.0       0.34      0.56      0.42        32
        31.0       0.54      0.79      0.65        39
        32.0       0.73      0.83      0.78       746
        33.0       0.89      0.84      0.86        74
        34.0       0.84      0.79      0.81        58
        35.0       0.81      0.54      0.65        48
        36.0       0.78      0.58      0.67       502
        37.0       0.61      0.72      0.67       240
        38.0       0.58      0.33      0.42        33
        39.0       0.70      0.67      0.69       344
        40.0       0.90      0.68      0.77       191
        41.0       0.82      0.29      0.43        31
        42.0       0.86      0.62      0.73       384
        43.0       0.89      0.70      0.78       117
        44.0       0.79      0.67      0.73       436
        45.0       0.64      0.73      0.69        49
        46.0       0.68      0.82      0.74       402
        47.0       0.62      0.29      0.40        17
        48.0       0.58      0.60      0.59        42
        49.0       0.97      0.79      0.87        77
        50.0       0.86      0.94      0.90       172
        51.0       0.64      0.37      0.47        19
        52.0       0.74      0.57      0.64       499
        53.0       0.72      0.69      0.70        99
        54.0       0.67      0.18      0.29        11
        55.0       0.79      0.73      0.76       103
        56.0       0.50      0.50      0.50        18
        57.0       0.00      0.00      0.00        11
        58.0       0.97      0.94      0.96        35
        59.0       0.54      0.67      0.60       231
        60.0       0.78      0.67      0.72        57
        61.0       0.00      0.00      0.00        29
        62.0       0.60      0.25      0.35        48
        63.0       0.25      0.27      0.26        49
        64.0       0.60      0.44      0.51        34
        65.0       0.58      0.73      0.65       155
        66.0       0.33      0.14      0.20        14
        67.0       0.59      0.61      0.60       315
        68.0       0.14      0.02      0.03        63
        69.0       0.44      0.70      0.54       307
        70.0       0.61      0.43      0.51        69
        71.0       0.28      0.48      0.35        66
        72.0       0.31      0.33      0.32        15
        73.0       0.31      0.44      0.37        25
        74.0       0.00      0.00      0.00        18
        75.0       0.19      0.05      0.08        59
        76.0       0.55      0.60      0.57       206
        77.0       0.35      0.43      0.39        76
        78.0       0.76      0.49      0.60        59
        79.0       0.27      0.49      0.34       140
        80.0       0.58      0.81      0.67        42
        81.0       0.63      0.34      0.44       175
        82.0       0.50      0.42      0.46        43
        83.0       0.33      0.32      0.33        25
        84.0       0.58      0.36      0.45       105
        85.0       0.88      0.50      0.64        14
        86.0       0.68      0.67      0.68       242
        87.0       0.69      0.75      0.72       310
        88.0       0.51      0.58      0.54        59
        89.0       0.00      0.00      0.00        11
        90.0       0.78      0.41      0.54       187
        91.0       0.71      0.26      0.38        46
        92.0       0.18      0.05      0.08        40
        93.0       0.74      0.42      0.54        33
        94.0       0.73      0.54      0.62       289
        95.0       0.13      0.19      0.15        32
        96.0       0.96      0.71      0.82        75
        97.0       0.45      0.18      0.26        28
        98.0       0.88      0.57      0.69        37
        99.0       0.78      0.78      0.78        23
       100.0       0.50      0.12      0.19        25
       101.0       0.66      0.53      0.59        66
       102.0       0.82      0.67      0.74        21
       103.0       0.70      0.74      0.72        65
       104.0       0.80      0.30      0.44        40
       105.0       0.83      0.83      0.83        12
       106.0       0.33      0.89      0.48       113
       107.0       0.90      0.74      0.81       162
       108.0       0.75      0.38      0.50        24
       109.0       0.38      0.85      0.52        53
       110.0       0.90      0.64      0.75        14
       111.0       0.55      0.58      0.56       123
       112.0       0.13      0.83      0.23        41
       113.0       0.68      0.92      0.78       429
       114.0       0.82      0.63      0.71        65
       115.0       0.37      0.65      0.47        31
       116.0       0.96      0.68      0.80       173
       117.0       0.96      0.77      0.85        30
       118.0       0.63      0.89      0.74       117
       119.0       0.77      0.76      0.77       136
       120.0       0.37      0.67      0.47        61
       121.0       0.77      0.88      0.82       225
       122.0       0.76      0.74      0.75        35
       123.0       0.86      0.63      0.73        38
       124.0       0.60      0.70      0.65        30
       125.0       0.50      0.81      0.62        16
       126.0       0.57      0.77      0.65        22
       127.0       0.88      0.59      0.70        73

    accuracy                           0.64     12226
   macro avg       0.59      0.51      0.52     12226
weighted avg       0.67      0.64      0.64     12226


===confusion_matrix===

[[285   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0   1 ...   0   0   0]
 ...
 [  0   0   0 ...  13   2   0]
 [  0   0   0 ...   1  17   1]
 [  0   0   0 ...   2   8  43]]

===multilabel confusion matrix===

[[[11788    81]
  [   72   285]]

 [[12199    14]
  [    7     6]]

 [[12207     0]
  [   18     1]]

 [[12101    46]
  [   44    35]]

 [[12152    19]
  [   47     8]]

 [[12147    20]
  [   53     6]]

 [[12161    21]
  [   33    11]]

 [[12171     7]
  [   23    25]]

 [[12215     1]
  [    9     1]]

 [[12199     6]
  [   15     6]]

 [[12211     0]
  [   11     4]]

 [[12169    21]
  [    8    28]]

 [[12214     0]
  [   12     0]]

 [[12185    16]
  [   10    15]]

 [[12200     6]
  [   19     1]]

 [[12198     6]
  [    8    14]]

 [[12193    10]
  [   11    12]]

 [[12066    42]
  [   21    97]]

 [[12200     8]
  [    6    12]]

 [[12212     1]
  [   13     0]]

 [[12102    35]
  [   45    44]]

 [[12209     5]
  [   10     2]]

 [[12200     2]
  [    5    19]]

 [[12211     3]
  [   11     1]]

 [[12182    21]
  [   17     6]]

 [[12173    16]
  [   20    17]]

 [[12207     2]
  [    2    15]]

 [[12179    11]
  [   31     5]]

 [[12214     0]
  [   10     2]]

 [[12181     8]
  [   19    18]]

 [[12159    35]
  [   14    18]]

 [[12161    26]
  [    8    31]]

 [[11251   229]
  [  129   617]]

 [[12144     8]
  [   12    62]]

 [[12159     9]
  [   12    46]]

 [[12172     6]
  [   22    26]]

 [[11643    81]
  [  209   293]]

 [[11877   109]
  [   66   174]]

 [[12185     8]
  [   22    11]]

 [[11783    99]
  [  112   232]]

 [[12021    14]
  [   62   129]]

 [[12193     2]
  [   22     9]]

 [[11804    38]
  [  144   240]]

 [[12099    10]
  [   35    82]]

 [[11710    80]
  [  142   294]]

 [[12157    20]
  [   13    36]]

 [[11666   158]
  [   71   331]]

 [[12206     3]
  [   12     5]]

 [[12166    18]
  [   17    25]]

 [[12147     2]
  [   16    61]]

 [[12028    26]
  [   10   162]]

 [[12203     4]
  [   12     7]]

 [[11627   100]
  [  214   285]]

 [[12101    26]
  [   31    68]]

 [[12214     1]
  [    9     2]]

 [[12103    20]
  [   28    75]]

 [[12199     9]
  [    9     9]]

 [[12208     7]
  [   11     0]]

 [[12190     1]
  [    2    33]]

 [[11865   130]
  [   76   155]]

 [[12158    11]
  [   19    38]]

 [[12196     1]
  [   29     0]]

 [[12170     8]
  [   36    12]]

 [[12139    38]
  [   36    13]]

 [[12182    10]
  [   19    15]]

 [[11989    82]
  [   42   113]]

 [[12208     4]
  [   12     2]]

 [[11780   131]
  [  123   192]]

 [[12157     6]
  [   62     1]]

 [[11648   271]
  [   91   216]]

 [[12138    19]
  [   39    30]]

 [[12076    84]
  [   34    32]]

 [[12200    11]
  [   10     5]]

 [[12177    24]
  [   14    11]]

 [[12197    11]
  [   18     0]]

 [[12154    13]
  [   56     3]]

 [[11920   100]
  [   83   123]]

 [[12088    62]
  [   43    33]]

 [[12158     9]
  [   30    29]]

 [[11899   187]
  [   72    68]]

 [[12159    25]
  [    8    34]]

 [[12017    34]
  [  116    59]]

 [[12165    18]
  [   25    18]]

 [[12185    16]
  [   17     8]]

 [[12094    27]
  [   67    38]]

 [[12211     1]
  [    7     7]]

 [[11908    76]
  [   80   162]]

 [[11811   105]
  [   78   232]]

 [[12134    33]
  [   25    34]]

 [[12214     1]
  [   11     0]]

 [[12017    22]
  [  110    77]]

 [[12175     5]
  [   34    12]]

 [[12177     9]
  [   38     2]]

 [[12188     5]
  [   19    14]]

 [[11878    59]
  [  132   157]]

 [[12153    41]
  [   26     6]]

 [[12149     2]
  [   22    53]]

 [[12192     6]
  [   23     5]]

 [[12186     3]
  [   16    21]]

 [[12198     5]
  [    5    18]]

 [[12198     3]
  [   22     3]]

 [[12142    18]
  [   31    35]]

 [[12202     3]
  [    7    14]]

 [[12140    21]
  [   17    48]]

 [[12183     3]
  [   28    12]]

 [[12212     2]
  [    2    10]]

 [[11908   205]
  [   12   101]]

 [[12050    14]
  [   42   120]]

 [[12199     3]
  [   15     9]]

 [[12098    75]
  [    8    45]]

 [[12211     1]
  [    5     9]]

 [[12044    59]
  [   52    71]]

 [[11967   218]
  [    7    34]]

 [[11610   187]
  [   36   393]]

 [[12152     9]
  [   24    41]]

 [[12161    34]
  [   11    20]]

 [[12048     5]
  [   55   118]]

 [[12195     1]
  [    7    23]]

 [[12048    61]
  [   13   104]]

 [[12059    31]
  [   32   104]]

 [[12094    71]
  [   20    41]]

 [[11943    58]
  [   27   198]]

 [[12183     8]
  [    9    26]]

 [[12184     4]
  [   14    24]]

 [[12182    14]
  [    9    21]]

 [[12197    13]
  [    3    13]]

 [[12191    13]
  [    5    17]]

 [[12147     6]
  [   30    43]]]

===scores report===
metrics	scores
Accuracy	0.6383
MCC	0.6311
log_loss	1.7997
f1 score weighted	0.6353
f1 score macro	0.5180
f1 score micro	0.6383
roc_auc ovr	0.9680
roc_auc ovo	0.9637
precision	0.6663
recall	0.6383

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efb782d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efb782d0850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efb782d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efb782d0460>, 'x_test': array([[13, 12, 12, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       [13,  3, 12, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [20,  6, 15, ...,  4,  2,  3],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.68      0.85      0.76       358
         1.0       0.60      0.25      0.35        12
         2.0       0.60      0.33      0.43        18
         3.0       0.34      0.54      0.42        79
         4.0       0.31      0.35      0.33        55
         5.0       0.27      0.24      0.26        58
         6.0       0.35      0.20      0.25        45
         7.0       0.68      0.45      0.54        47
         8.0       0.17      0.10      0.12        10
         9.0       0.39      0.33      0.36        21
        10.0       0.57      0.27      0.36        15
        11.0       0.71      0.81      0.75        36
        12.0       0.60      0.25      0.35        12
        13.0       0.83      0.40      0.54        25
        14.0       0.67      0.20      0.31        20
        15.0       0.86      0.82      0.84        22
        16.0       0.70      0.70      0.70        23
        17.0       0.76      0.79      0.77       118
        18.0       0.64      0.50      0.56        18
        19.0       0.00      0.00      0.00        13
        20.0       0.44      0.47      0.46        89
        21.0       1.00      0.15      0.27        13
        22.0       0.68      0.76      0.72        25
        23.0       1.00      0.08      0.15        12
        24.0       0.67      0.26      0.38        23
        25.0       0.74      0.62      0.68        37
        26.0       0.71      0.88      0.79        17
        27.0       0.40      0.17      0.24        36
        28.0       0.57      0.33      0.42        12
        29.0       0.69      0.81      0.74        36
        30.0       0.64      0.66      0.65        32
        31.0       0.59      0.85      0.69        39
        32.0       0.72      0.83      0.77       747
        33.0       0.93      0.84      0.88        74
        34.0       0.84      0.79      0.81        58
        35.0       0.74      0.68      0.71        47
        36.0       0.70      0.66      0.68       502
        37.0       0.64      0.73      0.68       240
        38.0       0.62      0.53      0.57        34
        39.0       0.65      0.72      0.68       344
        40.0       0.80      0.68      0.73       191
        41.0       0.79      0.59      0.68        32
        42.0       0.65      0.78      0.71       384
        43.0       0.80      0.82      0.81       117
        44.0       0.62      0.78      0.69       437
        45.0       0.97      0.73      0.84        49
        46.0       0.77      0.87      0.82       401
        47.0       1.00      0.76      0.87        17
        48.0       0.67      0.48      0.56        42
        49.0       0.85      0.88      0.87        77
        50.0       0.87      0.85      0.86       171
        51.0       0.69      0.45      0.55        20
        52.0       0.70      0.60      0.65       499
        53.0       0.70      0.53      0.60       100
        54.0       0.67      0.18      0.29        11
        55.0       0.76      0.85      0.80       104
        56.0       1.00      0.16      0.27        19
        57.0       0.50      0.09      0.15        11
        58.0       0.94      0.91      0.93        35
        59.0       0.63      0.64      0.64       230
        60.0       0.87      0.78      0.82        58
        61.0       0.09      0.03      0.05        29
        62.0       0.50      0.22      0.31        49
        63.0       0.28      0.16      0.20        50
        64.0       0.81      0.62      0.70        34
        65.0       0.85      0.77      0.81       155
        66.0       0.20      0.07      0.11        14
        67.0       0.63      0.68      0.65       314
        68.0       0.03      0.02      0.02        62
        69.0       0.54      0.69      0.60       307
        70.0       0.51      0.31      0.39        68
        71.0       0.38      0.32      0.35        66
        72.0       0.50      0.40      0.44        15
        73.0       0.75      0.36      0.49        25
        74.0       0.00      0.00      0.00        19
        75.0       0.27      0.19      0.22        59
        76.0       0.82      0.69      0.75       206
        77.0       0.50      0.40      0.45        77
        78.0       0.70      0.53      0.60        59
        79.0       0.44      0.50      0.47       139
        80.0       0.79      0.79      0.79        42
        81.0       0.40      0.48      0.44       174
        82.0       0.38      0.35      0.37        43
        83.0       0.35      0.24      0.29        25
        84.0       0.49      0.47      0.48       105
        85.0       0.62      0.53      0.57        15
        86.0       0.60      0.65      0.62       242
        87.0       0.79      0.77      0.78       309
        88.0       0.70      0.56      0.62        59
        89.0       0.75      0.27      0.40        11
        90.0       0.57      0.55      0.56       188
        91.0       0.45      0.38      0.41        47
        92.0       0.25      0.17      0.21        40
        93.0       0.58      0.58      0.58        33
        94.0       0.61      0.61      0.61       288
        95.0       0.33      0.06      0.11        32
        96.0       0.81      0.81      0.81        75
        97.0       0.35      0.30      0.32        27
        98.0       0.75      0.47      0.58        38
        99.0       0.84      0.91      0.87        23
       100.0       0.14      0.04      0.06        25
       101.0       0.64      0.44      0.52        66
       102.0       0.78      0.64      0.70        22
       103.0       0.75      0.70      0.73        64
       104.0       0.50      0.36      0.42        39
       105.0       0.64      0.58      0.61        12
       106.0       0.77      0.79      0.78       113
       107.0       0.76      0.81      0.78       161
       108.0       0.67      0.35      0.46        23
       109.0       0.85      0.75      0.80        53
       110.0       0.64      0.64      0.64        14
       111.0       0.74      0.63      0.68       123
       112.0       0.49      0.54      0.51        41
       113.0       0.77      0.91      0.84       429
       114.0       0.80      0.82      0.81        65
       115.0       0.61      0.45      0.52        31
       116.0       0.78      0.76      0.77       173
       117.0       0.90      0.90      0.90        31
       118.0       0.79      0.79      0.79       117
       119.0       0.75      0.73      0.74       135
       120.0       0.63      0.74      0.68        62
       121.0       0.75      0.88      0.81       224
       122.0       0.96      0.74      0.84        35
       123.0       0.80      0.65      0.72        37
       124.0       0.69      0.60      0.64        30
       125.0       0.91      0.62      0.74        16
       126.0       0.71      0.77      0.74        22
       127.0       0.72      0.88      0.79        73

    accuracy                           0.67     12226
   macro avg       0.63      0.54      0.56     12226
weighted avg       0.67      0.67      0.66     12226


===confusion_matrix===

[[306   0   0 ...   0   0   0]
 [  0   3   0 ...   0   0   0]
 [  0   0   6 ...   0   0   0]
 ...
 [  0   0   0 ...  10   0   3]
 [  0   0   0 ...   0  17   5]
 [  0   0   0 ...   0   1  64]]

===multilabel confusion matrix===

[[[11726   142]
  [   52   306]]

 [[12212     2]
  [    9     3]]

 [[12204     4]
  [   12     6]]

 [[12065    82]
  [   36    43]]

 [[12129    42]
  [   36    19]]

 [[12131    37]
  [   44    14]]

 [[12164    17]
  [   36     9]]

 [[12169    10]
  [   26    21]]

 [[12211     5]
  [    9     1]]

 [[12194    11]
  [   14     7]]

 [[12208     3]
  [   11     4]]

 [[12178    12]
  [    7    29]]

 [[12212     2]
  [    9     3]]

 [[12199     2]
  [   15    10]]

 [[12204     2]
  [   16     4]]

 [[12201     3]
  [    4    18]]

 [[12196     7]
  [    7    16]]

 [[12078    30]
  [   25    93]]

 [[12203     5]
  [    9     9]]

 [[12213     0]
  [   13     0]]

 [[12084    53]
  [   47    42]]

 [[12213     0]
  [   11     2]]

 [[12192     9]
  [    6    19]]

 [[12214     0]
  [   11     1]]

 [[12200     3]
  [   17     6]]

 [[12181     8]
  [   14    23]]

 [[12203     6]
  [    2    15]]

 [[12181     9]
  [   30     6]]

 [[12211     3]
  [    8     4]]

 [[12177    13]
  [    7    29]]

 [[12182    12]
  [   11    21]]

 [[12164    23]
  [    6    33]]

 [[11236   243]
  [  125   622]]

 [[12147     5]
  [   12    62]]

 [[12159     9]
  [   12    46]]

 [[12168    11]
  [   15    32]]

 [[11585   139]
  [  173   329]]

 [[11888    98]
  [   64   176]]

 [[12181    11]
  [   16    18]]

 [[11749   133]
  [   96   248]]

 [[12002    33]
  [   62   129]]

 [[12189     5]
  [   13    19]]

 [[11685   157]
  [   86   298]]

 [[12085    24]
  [   21    96]]

 [[11577   212]
  [   96   341]]

 [[12176     1]
  [   13    36]]

 [[11723   102]
  [   54   347]]

 [[12209     0]
  [    4    13]]

 [[12174    10]
  [   22    20]]

 [[12137    12]
  [    9    68]]

 [[12033    22]
  [   26   145]]

 [[12202     4]
  [   11     9]]

 [[11598   129]
  [  198   301]]

 [[12103    23]
  [   47    53]]

 [[12214     1]
  [    9     2]]

 [[12094    28]
  [   16    88]]

 [[12207     0]
  [   16     3]]

 [[12214     1]
  [   10     1]]

 [[12189     2]
  [    3    32]]

 [[11911    85]
  [   83   147]]

 [[12161     7]
  [   13    45]]

 [[12187    10]
  [   28     1]]

 [[12166    11]
  [   38    11]]

 [[12155    21]
  [   42     8]]

 [[12187     5]
  [   13    21]]

 [[12050    21]
  [   35   120]]

 [[12208     4]
  [   13     1]]

 [[11786   126]
  [  101   213]]

 [[12134    30]
  [   61     1]]

 [[11737   182]
  [   96   211]]

 [[12138    20]
  [   47    21]]

 [[12126    34]
  [   45    21]]

 [[12205     6]
  [    9     6]]

 [[12198     3]
  [   16     9]]

 [[12204     3]
  [   19     0]]

 [[12137    30]
  [   48    11]]

 [[11988    32]
  [   63   143]]

 [[12118    31]
  [   46    31]]

 [[12154    13]
  [   28    31]]

 [[11999    88]
  [   69    70]]

 [[12175     9]
  [    9    33]]

 [[11927   125]
  [   90    84]]

 [[12159    24]
  [   28    15]]

 [[12190    11]
  [   19     6]]

 [[12070    51]
  [   56    49]]

 [[12206     5]
  [    7     8]]

 [[11878   106]
  [   85   157]]

 [[11854    63]
  [   71   238]]

 [[12153    14]
  [   26    33]]

 [[12214     1]
  [    8     3]]

 [[11960    78]
  [   85   103]]

 [[12157    22]
  [   29    18]]

 [[12165    21]
  [   33     7]]

 [[12179    14]
  [   14    19]]

 [[11824   114]
  [  111   177]]

 [[12190     4]
  [   30     2]]

 [[12137    14]
  [   14    61]]

 [[12184    15]
  [   19     8]]

 [[12182     6]
  [   20    18]]

 [[12199     4]
  [    2    21]]

 [[12195     6]
  [   24     1]]

 [[12144    16]
  [   37    29]]

 [[12200     4]
  [    8    14]]

 [[12147    15]
  [   19    45]]

 [[12173    14]
  [   25    14]]

 [[12210     4]
  [    5     7]]

 [[12087    26]
  [   24    89]]

 [[12023    42]
  [   30   131]]

 [[12199     4]
  [   15     8]]

 [[12166     7]
  [   13    40]]

 [[12207     5]
  [    5     9]]

 [[12076    27]
  [   46    77]]

 [[12162    23]
  [   19    22]]

 [[11684   113]
  [   40   389]]

 [[12148    13]
  [   12    53]]

 [[12186     9]
  [   17    14]]

 [[12015    38]
  [   41   132]]

 [[12192     3]
  [    3    28]]

 [[12084    25]
  [   25    92]]

 [[12059    32]
  [   37    98]]

 [[12137    27]
  [   16    46]]

 [[11937    65]
  [   28   196]]

 [[12190     1]
  [    9    26]]

 [[12183     6]
  [   13    24]]

 [[12188     8]
  [   12    18]]

 [[12209     1]
  [    6    10]]

 [[12197     7]
  [    5    17]]

 [[12128    25]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6727
MCC	0.6654
log_loss	1.5881
f1 score weighted	0.6630
f1 score macro	0.5634
f1 score micro	0.6727
roc_auc ovr	0.9711
roc_auc ovo	0.9660
precision	0.6681
recall	0.6727

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efb782d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efb782d0850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efb782d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efb782d0460>, 'x_test': array([[13, 17, 12, ...,  0,  0,  0],
       [13,  4, 12, ...,  0,  0,  0],
       [13,  7,  1, ...,  0,  0,  0],
       ...,
       [20, 19, 11, ...,  1, 19,  5],
       [20, 20, 20, ...,  1,  7,  1],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.71      0.77      0.74       358
         1.0       0.50      0.58      0.54        12
         2.0       0.64      0.47      0.55        19
         3.0       0.30      0.47      0.36        79
         4.0       0.16      0.18      0.17        55
         5.0       0.16      0.09      0.11        58
         6.0       0.38      0.24      0.30        45
         7.0       0.22      0.49      0.31        47
         8.0       0.00      0.00      0.00        10
         9.0       0.37      0.33      0.35        21
        10.0       0.33      0.13      0.19        15
        11.0       0.77      0.67      0.72        36
        12.0       0.38      0.25      0.30        12
        13.0       0.88      0.60      0.71        25
        14.0       0.26      0.26      0.26        19
        15.0       0.76      0.59      0.67        22
        16.0       0.79      0.48      0.59        23
        17.0       0.85      0.74      0.79       118
        18.0       0.47      0.39      0.42        18
        19.0       0.00      0.00      0.00        12
        20.0       0.74      0.36      0.48        90
        21.0       1.00      0.23      0.38        13
        22.0       0.72      0.72      0.72        25
        23.0       0.40      0.15      0.22        13
        24.0       0.50      0.05      0.08        22
        25.0       0.50      0.37      0.42        38
        26.0       0.52      0.82      0.64        17
        27.0       0.75      0.09      0.15        35
        28.0       0.33      0.08      0.13        12
        29.0       0.40      0.53      0.46        36
        30.0       0.59      0.53      0.56        32
        31.0       0.78      0.76      0.77        38
        32.0       0.92      0.74      0.82       747
        33.0       0.80      0.79      0.79        75
        34.0       0.84      0.73      0.78        59
        35.0       0.75      0.19      0.31        47
        36.0       0.69      0.64      0.66       501
        37.0       0.36      0.78      0.49       241
        38.0       0.47      0.45      0.46        33
        39.0       0.68      0.56      0.61       344
        40.0       0.85      0.73      0.79       192
        41.0       0.33      0.31      0.32        32
        42.0       0.60      0.79      0.68       384
        43.0       0.73      0.80      0.77       117
        44.0       0.81      0.69      0.74       436
        45.0       0.93      0.82      0.87        49
        46.0       0.70      0.88      0.78       401
        47.0       0.78      0.41      0.54        17
        48.0       0.45      0.71      0.56        42
        49.0       0.88      0.88      0.88        77
        50.0       0.92      0.78      0.85       172
        51.0       0.73      0.40      0.52        20
        52.0       0.72      0.60      0.65       499
        53.0       0.82      0.46      0.59       100
        54.0       0.00      0.00      0.00        11
        55.0       0.85      0.62      0.72       104
        56.0       0.19      0.22      0.21        18
        57.0       1.00      0.10      0.18        10
        58.0       0.69      0.83      0.75        35
        59.0       0.61      0.60      0.61       230
        60.0       0.83      0.69      0.75        58
        61.0       1.00      0.03      0.07        29
        62.0       0.62      0.47      0.53        49
        63.0       0.33      0.10      0.15        50
        64.0       1.00      0.65      0.79        34
        65.0       0.82      0.66      0.73       155
        66.0       0.27      0.21      0.24        14
        67.0       0.61      0.66      0.63       314
        68.0       0.14      0.05      0.07        62
        69.0       0.54      0.54      0.54       307
        70.0       0.51      0.29      0.37        68
        71.0       0.52      0.35      0.42        66
        72.0       0.33      0.07      0.12        14
        73.0       0.65      0.54      0.59        24
        74.0       0.40      0.11      0.17        19
        75.0       0.00      0.00      0.00        60
        76.0       0.57      0.67      0.61       206
        77.0       0.48      0.17      0.25        77
        78.0       0.56      0.75      0.64        59
        79.0       0.41      0.41      0.41       139
        80.0       0.90      0.64      0.75        42
        81.0       0.45      0.46      0.46       174
        82.0       0.24      0.58      0.34        43
        83.0       1.00      0.12      0.21        26
        84.0       0.29      0.50      0.37       106
        85.0       1.00      0.53      0.70        15
        86.0       0.43      0.78      0.55       241
        87.0       0.84      0.63      0.72       309
        88.0       0.48      0.46      0.47        59
        89.0       0.60      0.30      0.40        10
        90.0       0.36      0.61      0.45       188
        91.0       0.53      0.17      0.26        46
        92.0       0.20      0.02      0.04        41
        93.0       0.50      0.50      0.50        32
        94.0       0.53      0.63      0.58       288
        95.0       0.30      0.10      0.15        31
        96.0       0.89      0.63      0.73        75
        97.0       0.50      0.15      0.23        27
        98.0       0.62      0.42      0.50        38
        99.0       0.62      0.96      0.75        24
       100.0       0.00      0.00      0.00        25
       101.0       0.45      0.46      0.46        65
       102.0       0.52      0.77      0.62        22
       103.0       0.58      0.78      0.67        64
       104.0       0.57      0.33      0.41        40
       105.0       0.91      0.83      0.87        12
       106.0       0.57      0.65      0.61       113
       107.0       0.81      0.75      0.78       161
       108.0       0.00      0.00      0.00        24
       109.0       0.92      0.63      0.75        52
       110.0       0.86      0.80      0.83        15
       111.0       0.72      0.55      0.62       124
       112.0       0.70      0.39      0.50        41
       113.0       0.86      0.86      0.86       430
       114.0       0.79      0.80      0.79        65
       115.0       0.85      0.35      0.50        31
       116.0       0.43      0.83      0.56       173
       117.0       0.68      0.87      0.76        31
       118.0       0.80      0.77      0.79       117
       119.0       0.74      0.72      0.73       136
       120.0       0.91      0.65      0.75        62
       121.0       0.60      0.87      0.71       224
       122.0       0.93      0.71      0.81        35
       123.0       0.68      0.57      0.62        37
       124.0       0.64      0.68      0.66        31
       125.0       0.63      0.80      0.71        15
       126.0       0.77      0.48      0.59        21
       127.0       0.63      0.88      0.74        73

    accuracy                           0.63     12226
   macro avg       0.59      0.49      0.51     12226
weighted avg       0.65      0.63      0.62     12226


===confusion_matrix===

[[277   0   0 ...   0   0   0]
 [  0   7   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   0  10   6]
 [  0   0   0 ...   1   0  64]]

===multilabel confusion matrix===

[[[11753   115]
  [   81   277]]

 [[12207     7]
  [    5     7]]

 [[12202     5]
  [   10     9]]

 [[12060    87]
  [   42    37]]

 [[12117    54]
  [   45    10]]

 [[12142    26]
  [   53     5]]

 [[12163    18]
  [   34    11]]

 [[12099    80]
  [   24    23]]

 [[12216     0]
  [   10     0]]

 [[12193    12]
  [   14     7]]

 [[12207     4]
  [   13     2]]

 [[12183     7]
  [   12    24]]

 [[12209     5]
  [    9     3]]

 [[12199     2]
  [   10    15]]

 [[12193    14]
  [   14     5]]

 [[12200     4]
  [    9    13]]

 [[12200     3]
  [   12    11]]

 [[12093    15]
  [   31    87]]

 [[12200     8]
  [   11     7]]

 [[12210     4]
  [   12     0]]

 [[12125    11]
  [   58    32]]

 [[12213     0]
  [   10     3]]

 [[12194     7]
  [    7    18]]

 [[12210     3]
  [   11     2]]

 [[12203     1]
  [   21     1]]

 [[12174    14]
  [   24    14]]

 [[12196    13]
  [    3    14]]

 [[12190     1]
  [   32     3]]

 [[12212     2]
  [   11     1]]

 [[12162    28]
  [   17    19]]

 [[12182    12]
  [   15    17]]

 [[12180     8]
  [    9    29]]

 [[11430    49]
  [  191   556]]

 [[12136    15]
  [   16    59]]

 [[12159     8]
  [   16    43]]

 [[12176     3]
  [   38     9]]

 [[11579   146]
  [  182   319]]

 [[11647   338]
  [   54   187]]

 [[12176    17]
  [   18    15]]

 [[11793    89]
  [  152   192]]

 [[12010    24]
  [   51   141]]

 [[12174    20]
  [   22    10]]

 [[11637   205]
  [   80   304]]

 [[12075    34]
  [   23    94]]

 [[11721    69]
  [  137   299]]

 [[12174     3]
  [    9    40]]

 [[11672   153]
  [   49   352]]

 [[12207     2]
  [   10     7]]

 [[12148    36]
  [   12    30]]

 [[12140     9]
  [    9    68]]

 [[12043    11]
  [   37   135]]

 [[12203     3]
  [   12     8]]

 [[11609   118]
  [  201   298]]

 [[12116    10]
  [   54    46]]

 [[12210     5]
  [   11     0]]

 [[12111    11]
  [   40    64]]

 [[12191    17]
  [   14     4]]

 [[12216     0]
  [    9     1]]

 [[12178    13]
  [    6    29]]

 [[11909    87]
  [   92   138]]

 [[12160     8]
  [   18    40]]

 [[12197     0]
  [   28     1]]

 [[12163    14]
  [   26    23]]

 [[12166    10]
  [   45     5]]

 [[12192     0]
  [   12    22]]

 [[12048    23]
  [   52   103]]

 [[12204     8]
  [   11     3]]

 [[11782   130]
  [  108   206]]

 [[12146    18]
  [   59     3]]

 [[11776   143]
  [  141   166]]

 [[12139    19]
  [   48    20]]

 [[12139    21]
  [   43    23]]

 [[12210     2]
  [   13     1]]

 [[12195     7]
  [   11    13]]

 [[12204     3]
  [   17     2]]

 [[12148    18]
  [   60     0]]

 [[11916   104]
  [   69   137]]

 [[12135    14]
  [   64    13]]

 [[12133    34]
  [   15    44]]

 [[12006    81]
  [   82    57]]

 [[12181     3]
  [   15    27]]

 [[11956    96]
  [   94    80]]

 [[12102    81]
  [   18    25]]

 [[12200     0]
  [   23     3]]

 [[11990   130]
  [   53    53]]

 [[12211     0]
  [    7     8]]

 [[11732   253]
  [   52   189]]

 [[11881    36]
  [  113   196]]

 [[12138    29]
  [   32    27]]

 [[12214     2]
  [    7     3]]

 [[11838   200]
  [   74   114]]

 [[12173     7]
  [   38     8]]

 [[12181     4]
  [   40     1]]

 [[12178    16]
  [   16    16]]

 [[11779   159]
  [  106   182]]

 [[12188     7]
  [   28     3]]

 [[12145     6]
  [   28    47]]

 [[12195     4]
  [   23     4]]

 [[12178    10]
  [   22    16]]

 [[12188    14]
  [    1    23]]

 [[12201     0]
  [   25     0]]

 [[12125    36]
  [   35    30]]

 [[12188    16]
  [    5    17]]

 [[12126    36]
  [   14    50]]

 [[12176    10]
  [   27    13]]

 [[12213     1]
  [    2    10]]

 [[12058    55]
  [   40    73]]

 [[12036    29]
  [   40   121]]

 [[12202     0]
  [   24     0]]

 [[12171     3]
  [   19    33]]

 [[12209     2]
  [    3    12]]

 [[12076    26]
  [   56    68]]

 [[12178     7]
  [   25    16]]

 [[11737    59]
  [   61   369]]

 [[12147    14]
  [   13    52]]

 [[12193     2]
  [   20    11]]

 [[11860   193]
  [   30   143]]

 [[12182    13]
  [    4    27]]

 [[12087    22]
  [   27    90]]

 [[12055    35]
  [   38    98]]

 [[12160     4]
  [   22    40]]

 [[11870   132]
  [   30   194]]

 [[12189     2]
  [   10    25]]

 [[12179    10]
  [   16    21]]

 [[12183    12]
  [   10    21]]

 [[12204     7]
  [    3    12]]

 [[12202     3]
  [   11    10]]

 [[12116    37]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6283
MCC	0.6208
log_loss	1.7618
f1 score weighted	0.6231
f1 score macro	0.5075
f1 score micro	0.6283
roc_auc ovr	0.9665
roc_auc ovo	0.9612
precision	0.6549
recall	0.6283

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6190398298846814	0.6124259946458384	1.820842136924863	0.6233686590349008	0.5052857720272697	0.6190398298846814	0.9664803638698004	0.9621966899001635	0.685420538419266	0.6190398298846814
1	0.6554346937106403	0.6475326721619608	1.6228598498236217	0.6431258965550701	0.5378019718695164	0.6554346937106403	0.9676463873245423	0.9619617905425474	0.6490895344250934	0.6554346937106403
2	0.6383117945362342	0.6310644425942916	1.799682520430296	0.6353095711402755	0.5179550420448795	0.6383117945362342	0.9679956096719173	0.9637073001219042	0.6663460109922152	0.6383117945362342
3	0.6727466055946344	0.6653999074425041	1.5880764546746984	0.662976893717925	0.5634266757644504	0.6727466055946344	0.9710699106466842	0.9660036763371068	0.6681427713255419	0.6727466055946344
4	0.6282512677899559	0.6208357283636211	1.7618147113337441	0.6231111831975238	0.5074563360075701	0.6282512677899559	0.9664602473884452	0.9611898112474355	0.6548890249632271	0.6282512677899559
mean	0.6427568383032293	0.6354517490416431	1.7186551346374443	0.6375784407291392	0.5263851595427372	0.6427568383032293	0.9679305037802779	0.9630118536298315	0.6647775760250687	0.6427568383032293
std	0.019249834483731916	0.01900475087372285	0.0949714672929622	0.014779870675073472	0.021803526883003983	0.019249834483731916	0.0016855501195793552	0.001704207250999395	0.01252049931440389	0.019249834483731916

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 37880.2996 secs

