/home/amsequeira/enzymeClassification/models/embedding/bi_attetion_emb5_50_3_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f59985d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f59985d0670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f59985d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f59985d0460>, 'x_test': array([[13, 13,  2, ...,  0,  0,  0],
       [13, 16,  8, ...,  0,  0,  0],
       [13,  3, 15, ...,  0,  0,  0],
       ...,
       [13,  4, 11, ...,  0,  0,  0],
       [17, 19, 16, ...,  6, 14,  4],
       [13, 15,  3, ...,  0,  0,  0]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.75      0.74       358
         1.0       1.00      0.25      0.40        12
         2.0       0.67      0.11      0.18        19
         3.0       0.26      0.41      0.32        80
         4.0       0.20      0.04      0.06        54
         5.0       0.00      0.00      0.00        58
         6.0       0.33      0.07      0.11        45
         7.0       1.00      0.29      0.45        48
         8.0       0.00      0.00      0.00        11
         9.0       0.75      0.14      0.24        21
        10.0       0.00      0.00      0.00        15
        11.0       0.70      0.53      0.60        36
        12.0       0.00      0.00      0.00        12
        13.0       1.00      0.72      0.84        25
        14.0       0.00      0.00      0.00        19
        15.0       0.88      0.68      0.77        22
        16.0       0.68      0.65      0.67        23
        17.0       0.87      0.82      0.84       119
        18.0       0.67      0.11      0.19        18
        19.0       1.00      0.08      0.15        12
        20.0       0.58      0.29      0.39        90
        21.0       1.00      0.17      0.29        12
        22.0       0.80      0.80      0.80        25
        23.0       0.00      0.00      0.00        12
        24.0       0.00      0.00      0.00        22
        25.0       0.71      0.39      0.51        38
        26.0       1.00      0.82      0.90        17
        27.0       0.00      0.00      0.00        35
        28.0       0.00      0.00      0.00        11
        29.0       0.44      0.33      0.38        36
        30.0       0.71      0.69      0.70        32
        31.0       0.76      0.76      0.76        38
        32.0       0.90      0.74      0.81       747
        33.0       0.81      0.80      0.80        74
        34.0       0.67      0.85      0.75        59
        35.0       0.74      0.52      0.61        48
        36.0       0.52      0.63      0.57       502
        37.0       0.57      0.66      0.61       241
        38.0       0.44      0.36      0.40        33
        39.0       0.86      0.39      0.53       344
        40.0       0.58      0.65      0.61       191
        41.0       1.00      0.12      0.22        32
        42.0       0.73      0.73      0.73       384
        43.0       0.86      0.68      0.76       118
        44.0       0.76      0.63      0.69       436
        45.0       0.95      0.81      0.88        48
        46.0       0.89      0.81      0.85       402
        47.0       1.00      0.12      0.21        17
        48.0       0.89      0.57      0.70        42
        49.0       0.72      0.91      0.80        78
        50.0       0.82      0.87      0.85       172
        51.0       1.00      0.25      0.40        20
        52.0       0.54      0.69      0.60       499
        53.0       0.88      0.66      0.75       100
        54.0       0.67      0.18      0.29        11
        55.0       0.46      0.67      0.55       103
        56.0       0.00      0.00      0.00        18
        57.0       0.33      0.10      0.15        10
        58.0       0.91      0.94      0.93        34
        59.0       0.57      0.56      0.56       231
        60.0       0.22      0.71      0.33        58
        61.0       0.00      0.00      0.00        30
        62.0       0.64      0.33      0.44        48
        63.0       0.23      0.10      0.14        50
        64.0       0.67      0.59      0.62        34
        65.0       0.40      0.82      0.54       155
        66.0       0.00      0.00      0.00        14
        67.0       0.32      0.66      0.43       314
        68.0       0.00      0.00      0.00        63
        69.0       0.62      0.58      0.60       308
        70.0       0.56      0.35      0.43        68
        71.0       0.33      0.20      0.25        66
        72.0       0.00      0.00      0.00        14
        73.0       0.80      0.16      0.27        25
        74.0       0.00      0.00      0.00        18
        75.0       0.00      0.00      0.00        60
        76.0       0.57      0.69      0.63       205
        77.0       0.68      0.17      0.27        77
        78.0       0.86      0.54      0.67        59
        79.0       0.37      0.27      0.32       139
        80.0       0.73      0.86      0.79        42
        81.0       0.25      0.47      0.32       175
        82.0       0.18      0.28      0.22        43
        83.0       0.60      0.12      0.19        26
        84.0       0.22      0.45      0.29       106
        85.0       0.33      0.29      0.31        14
        86.0       0.47      0.71      0.57       242
        87.0       0.79      0.71      0.75       309
        88.0       0.75      0.67      0.71        58
        89.0       0.00      0.00      0.00        11
        90.0       0.60      0.44      0.51       187
        91.0       0.22      0.39      0.28        46
        92.0       0.29      0.05      0.09        40
        93.0       0.75      0.28      0.41        32
        94.0       0.38      0.73      0.50       289
        95.0       0.00      0.00      0.00        31
        96.0       0.92      0.49      0.64        74
        97.0       0.29      0.33      0.31        27
        98.0       0.88      0.41      0.56        37
        99.0       0.92      0.96      0.94        24
       100.0       0.00      0.00      0.00        25
       101.0       0.55      0.28      0.37        65
       102.0       0.83      0.45      0.59        22
       103.0       0.71      0.75      0.73        64
       104.0       0.64      0.35      0.45        40
       105.0       0.91      0.83      0.87        12
       106.0       0.39      0.78      0.52       114
       107.0       0.86      0.77      0.81       161
       108.0       0.25      0.08      0.12        24
       109.0       0.38      0.73      0.50        52
       110.0       1.00      0.80      0.89        15
       111.0       0.61      0.55      0.58       123
       112.0       0.26      0.43      0.32        42
       113.0       0.94      0.78      0.85       430
       114.0       1.00      0.57      0.73        65
       115.0       0.95      0.58      0.72        31
       116.0       0.91      0.68      0.78       173
       117.0       0.97      0.90      0.93        31
       118.0       0.89      0.69      0.78       117
       119.0       0.41      0.74      0.53       136
       120.0       0.91      0.66      0.77        62
       121.0       0.79      0.79      0.79       224
       122.0       0.93      0.74      0.83        35
       123.0       0.85      0.59      0.70        37
       124.0       0.55      0.58      0.56        31
       125.0       0.83      0.67      0.74        15
       126.0       0.71      0.48      0.57        21
       127.0       0.69      0.78      0.73        73

    accuracy                           0.60     12227
   macro avg       0.57      0.45      0.47     12227
weighted avg       0.64      0.60      0.60     12227


===confusion_matrix===

[[270   0   0 ...   0   0   0]
 [  1   3   0 ...   0   0   0]
 [  0   0   2 ...   0   0   0]
 ...
 [  0   0   0 ...  10   0   1]
 [  0   0   0 ...   1  10   7]
 [  0   0   0 ...   1   3  57]]

===multilabel confusion matrix===

[[[11772    97]
  [   88   270]]

 [[12215     0]
  [    9     3]]

 [[12207     1]
  [   17     2]]

 [[12054    93]
  [   47    33]]

 [[12165     8]
  [   52     2]]

 [[12161     8]
  [   58     0]]

 [[12176     6]
  [   42     3]]

 [[12179     0]
  [   34    14]]

 [[12216     0]
  [   11     0]]

 [[12205     1]
  [   18     3]]

 [[12211     1]
  [   15     0]]

 [[12183     8]
  [   17    19]]

 [[12214     1]
  [   12     0]]

 [[12202     0]
  [    7    18]]

 [[12208     0]
  [   19     0]]

 [[12203     2]
  [    7    15]]

 [[12197     7]
  [    8    15]]

 [[12093    15]
  [   22    97]]

 [[12208     1]
  [   16     2]]

 [[12215     0]
  [   11     1]]

 [[12118    19]
  [   64    26]]

 [[12215     0]
  [   10     2]]

 [[12197     5]
  [    5    20]]

 [[12215     0]
  [   12     0]]

 [[12204     1]
  [   22     0]]

 [[12183     6]
  [   23    15]]

 [[12210     0]
  [    3    14]]

 [[12190     2]
  [   35     0]]

 [[12216     0]
  [   11     0]]

 [[12176    15]
  [   24    12]]

 [[12186     9]
  [   10    22]]

 [[12180     9]
  [    9    29]]

 [[11417    63]
  [  195   552]]

 [[12139    14]
  [   15    59]]

 [[12143    25]
  [    9    50]]

 [[12170     9]
  [   23    25]]

 [[11439   286]
  [  186   316]]

 [[11868   118]
  [   83   158]]

 [[12179    15]
  [   21    12]]

 [[11861    22]
  [  211   133]]

 [[11944    92]
  [   66   125]]

 [[12195     0]
  [   28     4]]

 [[11738   105]
  [  104   280]]

 [[12096    13]
  [   38    80]]

 [[11703    88]
  [  160   276]]

 [[12177     2]
  [    9    39]]

 [[11785    40]
  [   78   324]]

 [[12210     0]
  [   15     2]]

 [[12182     3]
  [   18    24]]

 [[12121    28]
  [    7    71]]

 [[12023    32]
  [   22   150]]

 [[12207     0]
  [   15     5]]

 [[11436   292]
  [  157   342]]

 [[12118     9]
  [   34    66]]

 [[12215     1]
  [    9     2]]

 [[12043    81]
  [   34    69]]

 [[12208     1]
  [   18     0]]

 [[12215     2]
  [    9     1]]

 [[12190     3]
  [    2    32]]

 [[11896   100]
  [  101   130]]

 [[12023   146]
  [   17    41]]

 [[12197     0]
  [   30     0]]

 [[12170     9]
  [   32    16]]

 [[12160    17]
  [   45     5]]

 [[12183    10]
  [   14    20]]

 [[11884   188]
  [   28   127]]

 [[12213     0]
  [   14     0]]

 [[11482   431]
  [  108   206]]

 [[12163     1]
  [   63     0]]

 [[11808   111]
  [  130   178]]

 [[12140    19]
  [   44    24]]

 [[12135    26]
  [   53    13]]

 [[12213     0]
  [   14     0]]

 [[12201     1]
  [   21     4]]

 [[12209     0]
  [   18     0]]

 [[12146    21]
  [   60     0]]

 [[11916   106]
  [   63   142]]

 [[12144     6]
  [   64    13]]

 [[12163     5]
  [   27    32]]

 [[12024    64]
  [  101    38]]

 [[12172    13]
  [    6    36]]

 [[11798   254]
  [   92    83]]

 [[12128    56]
  [   31    12]]

 [[12199     2]
  [   23     3]]

 [[11948   173]
  [   58    48]]

 [[12205     8]
  [   10     4]]

 [[11793   192]
  [   69   173]]

 [[11861    57]
  [   90   219]]

 [[12156    13]
  [   19    39]]

 [[12216     0]
  [   11     0]]

 [[11986    54]
  [  105    82]]

 [[12116    65]
  [   28    18]]

 [[12182     5]
  [   38     2]]

 [[12192     3]
  [   23     9]]

 [[11591   347]
  [   79   210]]

 [[12196     0]
  [   31     0]]

 [[12150     3]
  [   38    36]]

 [[12178    22]
  [   18     9]]

 [[12188     2]
  [   22    15]]

 [[12201     2]
  [    1    23]]

 [[12202     0]
  [   25     0]]

 [[12147    15]
  [   47    18]]

 [[12203     2]
  [   12    10]]

 [[12143    20]
  [   16    48]]

 [[12179     8]
  [   26    14]]

 [[12214     1]
  [    2    10]]

 [[11976   137]
  [   25    89]]

 [[12045    21]
  [   37   124]]

 [[12197     6]
  [   22     2]]

 [[12113    62]
  [   14    38]]

 [[12212     0]
  [    3    12]]

 [[12060    44]
  [   55    68]]

 [[12134    51]
  [   24    18]]

 [[11775    22]
  [   93   337]]

 [[12162     0]
  [   28    37]]

 [[12195     1]
  [   13    18]]

 [[12043    11]
  [   55   118]]

 [[12195     1]
  [    3    28]]

 [[12100    10]
  [   36    81]]

 [[11948   143]
  [   35   101]]

 [[12161     4]
  [   21    41]]

 [[11956    47]
  [   46   178]]

 [[12190     2]
  [    9    26]]

 [[12186     4]
  [   15    22]]

 [[12181    15]
  [   13    18]]

 [[12210     2]
  [    5    10]]

 [[12202     4]
  [   11    10]]

 [[12128    26]
  [   16    57]]]

===scores report===
metrics	scores
Accuracy	0.6033
MCC	0.5954
log_loss	1.7954
f1 score weighted	0.5977
f1 score macro	0.4686
f1 score micro	0.6033
roc_auc ovr	0.9631
roc_auc ovo	0.9579
precision	0.6397
recall	0.6033

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f59985d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f59985d0670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f59985d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f59985d0460>, 'x_test': array([[13,  7, 17, ...,  0,  0,  0],
       [13,  1, 11, ...,  0,  0,  0],
       [13,  3, 17, ...,  0,  0,  0],
       ...,
       [13,  1,  8, ...,  0,  0,  0],
       [13,  1, 20, ...,  0,  0,  0],
       [12, 12, 11, ..., 16,  9, 20]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.74      0.77       357
         1.0       0.80      0.33      0.47        12
         2.0       0.86      0.32      0.46        19
         3.0       0.43      0.46      0.44        80
         4.0       0.48      0.28      0.35        54
         5.0       0.16      0.12      0.14        58
         6.0       0.67      0.23      0.34        44
         7.0       0.69      0.50      0.58        48
         8.0       0.00      0.00      0.00        11
         9.0       0.60      0.14      0.23        21
        10.0       0.00      0.00      0.00        15
        11.0       1.00      0.67      0.80        36
        12.0       0.00      0.00      0.00        12
        13.0       0.73      0.64      0.68        25
        14.0       0.50      0.20      0.29        20
        15.0       0.92      0.48      0.63        23
        16.0       0.62      0.70      0.65        23
        17.0       0.97      0.77      0.86       119
        18.0       0.82      0.53      0.64        17
        19.0       0.00      0.00      0.00        13
        20.0       0.63      0.29      0.40        90
        21.0       0.00      0.00      0.00        12
        22.0       0.83      0.60      0.70        25
        23.0       0.00      0.00      0.00        12
        24.0       1.00      0.09      0.17        22
        25.0       0.79      0.41      0.54        37
        26.0       0.89      0.94      0.92        18
        27.0       0.30      0.09      0.13        35
        28.0       0.33      0.08      0.13        12
        29.0       0.75      0.65      0.70        37
        30.0       0.70      0.50      0.58        32
        31.0       0.84      0.67      0.74        39
        32.0       0.88      0.79      0.84       746
        33.0       0.88      0.89      0.89        74
        34.0       0.80      0.78      0.79        58
        35.0       0.80      0.50      0.62        48
        36.0       0.65      0.63      0.64       502
        37.0       0.57      0.78      0.66       241
        38.0       0.50      0.18      0.27        33
        39.0       0.59      0.77      0.67       344
        40.0       0.90      0.66      0.77       191
        41.0       0.93      0.42      0.58        31
        42.0       0.77      0.72      0.75       384
        43.0       0.77      0.87      0.82       118
        44.0       0.69      0.74      0.71       436
        45.0       0.89      0.81      0.85        48
        46.0       0.78      0.86      0.82       402
        47.0       0.00      0.00      0.00        17
        48.0       0.81      0.62      0.70        42
        49.0       0.85      0.86      0.85        77
        50.0       0.82      0.87      0.84       172
        51.0       1.00      0.60      0.75        20
        52.0       0.44      0.78      0.57       499
        53.0       0.78      0.68      0.72        99
        54.0       0.00      0.00      0.00        11
        55.0       0.77      0.77      0.77       103
        56.0       0.48      0.56      0.51        18
        57.0       0.00      0.00      0.00        11
        58.0       1.00      0.82      0.90        34
        59.0       0.62      0.55      0.58       231
        60.0       0.61      0.69      0.65        58
        61.0       0.00      0.00      0.00        30
        62.0       0.49      0.35      0.41        48
        63.0       0.17      0.16      0.16        49
        64.0       0.95      0.62      0.75        34
        65.0       0.64      0.77      0.70       154
        66.0       1.00      0.07      0.13        14
        67.0       0.60      0.63      0.61       314
        68.0       0.09      0.05      0.06        63
        69.0       0.48      0.69      0.56       308
        70.0       0.66      0.30      0.42        69
        71.0       0.61      0.38      0.47        66
        72.0       0.00      0.00      0.00        14
        73.0       0.59      0.52      0.55        25
        74.0       0.00      0.00      0.00        18
        75.0       0.16      0.08      0.11        59
        76.0       0.66      0.66      0.66       205
        77.0       0.66      0.30      0.41        77
        78.0       0.75      0.36      0.48        59
        79.0       0.73      0.37      0.50       139
        80.0       0.83      0.73      0.78        41
        81.0       0.25      0.59      0.36       175
        82.0       0.59      0.44      0.51        43
        83.0       0.43      0.12      0.18        26
        84.0       0.47      0.47      0.47       105
        85.0       0.88      0.50      0.64        14
        86.0       0.75      0.59      0.66       242
        87.0       0.92      0.69      0.79       309
        88.0       0.83      0.52      0.64        58
        89.0       1.00      0.27      0.43        11
        90.0       0.33      0.62      0.43       187
        91.0       0.44      0.26      0.33        46
        92.0       0.25      0.07      0.12        40
        93.0       0.55      0.36      0.44        33
        94.0       0.54      0.62      0.58       289
        95.0       0.13      0.06      0.09        32
        96.0       0.94      0.59      0.73        74
        97.0       0.78      0.26      0.39        27
        98.0       0.81      0.59      0.69        37
        99.0       1.00      0.83      0.91        24
       100.0       1.00      0.04      0.07        26
       101.0       0.86      0.46      0.60        65
       102.0       1.00      0.55      0.71        22
       103.0       1.00      0.62      0.77        64
       104.0       0.38      0.20      0.26        40
       105.0       1.00      0.69      0.82        13
       106.0       0.61      0.82      0.70       113
       107.0       0.78      0.77      0.77       162
       108.0       0.86      0.25      0.39        24
       109.0       0.86      0.81      0.83        52
       110.0       1.00      0.87      0.93        15
       111.0       0.57      0.74      0.64       123
       112.0       0.74      0.41      0.53        41
       113.0       0.74      0.94      0.83       430
       114.0       0.59      0.83      0.69        65
       115.0       0.47      0.48      0.48        31
       116.0       0.75      0.76      0.75       173
       117.0       0.92      0.73      0.81        30
       118.0       0.77      0.84      0.80       118
       119.0       0.57      0.81      0.67       136
       120.0       1.00      0.51      0.67        61
       121.0       0.80      0.89      0.84       225
       122.0       0.97      0.97      0.97        35
       123.0       0.67      0.68      0.68        38
       124.0       0.92      0.39      0.55        31
       125.0       1.00      0.56      0.72        16
       126.0       0.75      0.71      0.73        21
       127.0       0.57      0.86      0.68        73

    accuracy                           0.66     12227
   macro avg       0.64      0.50      0.53     12227
weighted avg       0.68      0.66      0.65     12227


===confusion_matrix===

[[264   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0   6 ...   0   0   0]
 ...
 [  0   0   0 ...   9   2   5]
 [  0   0   0 ...   0  15   3]
 [  0   0   0 ...   0   2  63]]

===multilabel confusion matrix===

[[[11808    62]
  [   93   264]]

 [[12214     1]
  [    8     4]]

 [[12207     1]
  [   13     6]]

 [[12097    50]
  [   43    37]]

 [[12157    16]
  [   39    15]]

 [[12132    37]
  [   51     7]]

 [[12178     5]
  [   34    10]]

 [[12168    11]
  [   24    24]]

 [[12216     0]
  [   11     0]]

 [[12204     2]
  [   18     3]]

 [[12211     1]
  [   15     0]]

 [[12191     0]
  [   12    24]]

 [[12213     2]
  [   12     0]]

 [[12196     6]
  [    9    16]]

 [[12203     4]
  [   16     4]]

 [[12203     1]
  [   12    11]]

 [[12194    10]
  [    7    16]]

 [[12105     3]
  [   27    92]]

 [[12208     2]
  [    8     9]]

 [[12214     0]
  [   13     0]]

 [[12122    15]
  [   64    26]]

 [[12215     0]
  [   12     0]]

 [[12199     3]
  [   10    15]]

 [[12215     0]
  [   12     0]]

 [[12205     0]
  [   20     2]]

 [[12186     4]
  [   22    15]]

 [[12207     2]
  [    1    17]]

 [[12185     7]
  [   32     3]]

 [[12213     2]
  [   11     1]]

 [[12182     8]
  [   13    24]]

 [[12188     7]
  [   16    16]]

 [[12183     5]
  [   13    26]]

 [[11403    78]
  [  153   593]]

 [[12144     9]
  [    8    66]]

 [[12158    11]
  [   13    45]]

 [[12173     6]
  [   24    24]]

 [[11557   168]
  [  184   318]]

 [[11845   141]
  [   52   189]]

 [[12188     6]
  [   27     6]]

 [[11697   186]
  [   79   265]]

 [[12022    14]
  [   64   127]]

 [[12195     1]
  [   18    13]]

 [[11762    81]
  [  106   278]]

 [[12078    31]
  [   15   103]]

 [[11643   148]
  [  112   324]]

 [[12174     5]
  [    9    39]]

 [[11726    99]
  [   56   346]]

 [[12210     0]
  [   17     0]]

 [[12179     6]
  [   16    26]]

 [[12138    12]
  [   11    66]]

 [[12022    33]
  [   23   149]]

 [[12207     0]
  [    8    12]]

 [[11234   494]
  [  108   391]]

 [[12109    19]
  [   32    67]]

 [[12216     0]
  [   11     0]]

 [[12101    23]
  [   24    79]]

 [[12198    11]
  [    8    10]]

 [[12216     0]
  [   11     0]]

 [[12193     0]
  [    6    28]]

 [[11918    78]
  [  104   127]]

 [[12143    26]
  [   18    40]]

 [[12197     0]
  [   30     0]]

 [[12161    18]
  [   31    17]]

 [[12138    40]
  [   41     8]]

 [[12192     1]
  [   13    21]]

 [[12008    65]
  [   36   118]]

 [[12213     0]
  [   13     1]]

 [[11779   134]
  [  116   198]]

 [[12133    31]
  [   60     3]]

 [[11688   231]
  [   97   211]]

 [[12147    11]
  [   48    21]]

 [[12145    16]
  [   41    25]]

 [[12212     1]
  [   14     0]]

 [[12193     9]
  [   12    13]]

 [[12209     0]
  [   18     0]]

 [[12142    26]
  [   54     5]]

 [[11951    71]
  [   69   136]]

 [[12138    12]
  [   54    23]]

 [[12161     7]
  [   38    21]]

 [[12069    19]
  [   87    52]]

 [[12180     6]
  [   11    30]]

 [[11748   304]
  [   71   104]]

 [[12171    13]
  [   24    19]]

 [[12197     4]
  [   23     3]]

 [[12067    55]
  [   56    49]]

 [[12212     1]
  [    7     7]]

 [[11938    47]
  [   99   143]]

 [[11899    19]
  [   97   212]]

 [[12163     6]
  [   28    30]]

 [[12216     0]
  [    8     3]]

 [[11809   231]
  [   71   116]]

 [[12166    15]
  [   34    12]]

 [[12178     9]
  [   37     3]]

 [[12184    10]
  [   21    12]]

 [[11786   152]
  [  109   180]]

 [[12182    13]
  [   30     2]]

 [[12150     3]
  [   30    44]]

 [[12198     2]
  [   20     7]]

 [[12185     5]
  [   15    22]]

 [[12203     0]
  [    4    20]]

 [[12201     0]
  [   25     1]]

 [[12157     5]
  [   35    30]]

 [[12205     0]
  [   10    12]]

 [[12163     0]
  [   24    40]]

 [[12174    13]
  [   32     8]]

 [[12214     0]
  [    4     9]]

 [[12055    59]
  [   20    93]]

 [[12029    36]
  [   37   125]]

 [[12202     1]
  [   18     6]]

 [[12168     7]
  [   10    42]]

 [[12212     0]
  [    2    13]]

 [[12035    69]
  [   32    91]]

 [[12180     6]
  [   24    17]]

 [[11658   139]
  [   27   403]]

 [[12124    38]
  [   11    54]]

 [[12179    17]
  [   16    15]]

 [[12010    44]
  [   42   131]]

 [[12195     2]
  [    8    22]]

 [[12080    29]
  [   19    99]]

 [[12007    84]
  [   26   110]]

 [[12166     0]
  [   30    31]]

 [[11952    50]
  [   25   200]]

 [[12191     1]
  [    1    34]]

 [[12176    13]
  [   12    26]]

 [[12195     1]
  [   19    12]]

 [[12211     0]
  [    7     9]]

 [[12201     5]
  [    6    15]]

 [[12106    48]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.6559
MCC	0.6486
log_loss	1.5905
f1 score weighted	0.6476
f1 score macro	0.5303
f1 score micro	0.6559
roc_auc ovr	0.9699
roc_auc ovo	0.9643
precision	0.6767
recall	0.6559

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f59985d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f59985d0670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f59985d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f59985d0460>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13, 16,  7, ...,  0,  0,  0],
       [13, 16, 16, ...,  0,  0,  0],
       ...,
       [13, 16, 16, ...,  0,  0,  0],
       [ 6, 17,  1, ...,  4,  6, 11],
       [13,  6, 12, ...,  0,  0,  0]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.80      0.78       357
         1.0       0.62      0.38      0.48        13
         2.0       0.67      0.32      0.43        19
         3.0       0.64      0.35      0.46        79
         4.0       0.30      0.11      0.16        55
         5.0       0.25      0.07      0.11        59
         6.0       0.40      0.23      0.29        44
         7.0       0.91      0.42      0.57        48
         8.0       0.00      0.00      0.00        10
         9.0       0.53      0.38      0.44        21
        10.0       1.00      0.07      0.12        15
        11.0       0.76      0.72      0.74        36
        12.0       0.67      0.17      0.27        12
        13.0       0.81      0.68      0.74        25
        14.0       0.00      0.00      0.00        20
        15.0       0.91      0.45      0.61        22
        16.0       0.82      0.61      0.70        23
        17.0       0.89      0.81      0.84       118
        18.0       0.50      0.28      0.36        18
        19.0       0.00      0.00      0.00        13
        20.0       0.61      0.48      0.54        89
        21.0       1.00      0.08      0.15        12
        22.0       0.84      0.67      0.74        24
        23.0       0.00      0.00      0.00        12
        24.0       0.50      0.09      0.15        23
        25.0       1.00      0.27      0.43        37
        26.0       0.94      0.88      0.91        17
        27.0       0.43      0.08      0.14        36
        28.0       0.00      0.00      0.00        12
        29.0       0.58      0.30      0.39        37
        30.0       0.51      0.59      0.55        32
        31.0       0.93      0.69      0.79        39
        32.0       0.94      0.76      0.84       746
        33.0       0.74      0.77      0.75        74
        34.0       0.77      0.71      0.74        58
        35.0       0.59      0.48      0.53        48
        36.0       0.41      0.73      0.53       502
        37.0       0.60      0.65      0.62       240
        38.0       0.50      0.03      0.06        33
        39.0       0.69      0.57      0.62       344
        40.0       0.87      0.64      0.74       191
        41.0       1.00      0.16      0.28        31
        42.0       0.77      0.64      0.70       384
        43.0       0.59      0.75      0.66       117
        44.0       0.45      0.78      0.57       436
        45.0       0.95      0.71      0.81        49
        46.0       0.50      0.91      0.65       402
        47.0       0.00      0.00      0.00        17
        48.0       0.74      0.69      0.72        42
        49.0       0.70      0.90      0.78        77
        50.0       0.85      0.91      0.88       172
        51.0       1.00      0.05      0.10        19
        52.0       0.74      0.54      0.62       499
        53.0       0.91      0.70      0.79        99
        54.0       0.00      0.00      0.00        11
        55.0       0.81      0.65      0.72       103
        56.0       1.00      0.11      0.20        18
        57.0       0.00      0.00      0.00        11
        58.0       1.00      0.89      0.94        35
        59.0       0.35      0.74      0.48       231
        60.0       0.67      0.68      0.68        57
        61.0       0.00      0.00      0.00        29
        62.0       0.23      0.31      0.26        48
        63.0       0.00      0.00      0.00        49
        64.0       0.70      0.62      0.66        34
        65.0       0.84      0.63      0.72       155
        66.0       0.00      0.00      0.00        14
        67.0       0.64      0.60      0.62       315
        68.0       0.00      0.00      0.00        63
        69.0       0.60      0.52      0.55       307
        70.0       0.60      0.22      0.32        69
        71.0       0.44      0.48      0.46        66
        72.0       0.00      0.00      0.00        15
        73.0       0.56      0.36      0.44        25
        74.0       0.00      0.00      0.00        18
        75.0       0.00      0.00      0.00        59
        76.0       0.59      0.62      0.61       206
        77.0       0.40      0.24      0.30        76
        78.0       0.79      0.39      0.52        59
        79.0       0.49      0.36      0.41       140
        80.0       0.58      0.90      0.70        42
        81.0       0.23      0.50      0.31       175
        82.0       0.61      0.33      0.42        43
        83.0       0.36      0.16      0.22        25
        84.0       0.28      0.50      0.36       105
        85.0       0.44      0.29      0.35        14
        86.0       0.54      0.74      0.63       242
        87.0       0.84      0.68      0.75       310
        88.0       0.82      0.53      0.64        59
        89.0       0.00      0.00      0.00        11
        90.0       0.35      0.55      0.43       187
        91.0       0.29      0.33      0.31        46
        92.0       0.00      0.00      0.00        40
        93.0       0.86      0.36      0.51        33
        94.0       0.64      0.50      0.56       289
        95.0       0.00      0.00      0.00        32
        96.0       0.61      0.68      0.64        75
        97.0       0.24      0.36      0.29        28
        98.0       1.00      0.46      0.63        37
        99.0       0.86      0.83      0.84        23
       100.0       0.00      0.00      0.00        25
       101.0       0.42      0.55      0.48        66
       102.0       1.00      0.57      0.73        21
       103.0       0.60      0.77      0.67        65
       104.0       0.59      0.33      0.42        40
       105.0       0.83      0.83      0.83        12
       106.0       0.81      0.73      0.77       113
       107.0       0.87      0.71      0.78       162
       108.0       0.00      0.00      0.00        24
       109.0       0.88      0.70      0.78        53
       110.0       0.67      0.57      0.62        14
       111.0       0.71      0.60      0.65       123
       112.0       0.88      0.34      0.49        41
       113.0       0.94      0.83      0.88       429
       114.0       0.51      0.74      0.60        65
       115.0       0.86      0.39      0.53        31
       116.0       0.74      0.77      0.75       173
       117.0       0.64      0.77      0.70        30
       118.0       0.95      0.75      0.84       117
       119.0       0.62      0.82      0.71       136
       120.0       0.92      0.54      0.68        61
       121.0       0.68      0.91      0.78       225
       122.0       0.86      0.69      0.76        35
       123.0       0.69      0.53      0.60        38
       124.0       0.66      0.63      0.64        30
       125.0       1.00      0.81      0.90        16
       126.0       0.89      0.36      0.52        22
       127.0       0.58      0.84      0.69        73

    accuracy                           0.62     12226
   macro avg       0.58      0.45      0.48     12226
weighted avg       0.65      0.62      0.61     12226


===confusion_matrix===

[[284   0   0 ...   0   0   0]
 [  0   5   0 ...   0   0   0]
 [  0   0   6 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   3]
 [  0   0   0 ...   0   8  11]
 [  0   0   0 ...   0   1  61]]

===multilabel confusion matrix===

[[[11782    87]
  [   73   284]]

 [[12210     3]
  [    8     5]]

 [[12204     3]
  [   13     6]]

 [[12131    16]
  [   51    28]]

 [[12157    14]
  [   49     6]]

 [[12155    12]
  [   55     4]]

 [[12167    15]
  [   34    10]]

 [[12176     2]
  [   28    20]]

 [[12216     0]
  [   10     0]]

 [[12198     7]
  [   13     8]]

 [[12211     0]
  [   14     1]]

 [[12182     8]
  [   10    26]]

 [[12213     1]
  [   10     2]]

 [[12197     4]
  [    8    17]]

 [[12204     2]
  [   20     0]]

 [[12203     1]
  [   12    10]]

 [[12200     3]
  [    9    14]]

 [[12096    12]
  [   23    95]]

 [[12203     5]
  [   13     5]]

 [[12212     1]
  [   13     0]]

 [[12109    28]
  [   46    43]]

 [[12214     0]
  [   11     1]]

 [[12199     3]
  [    8    16]]

 [[12214     0]
  [   12     0]]

 [[12201     2]
  [   21     2]]

 [[12189     0]
  [   27    10]]

 [[12208     1]
  [    2    15]]

 [[12186     4]
  [   33     3]]

 [[12214     0]
  [   12     0]]

 [[12181     8]
  [   26    11]]

 [[12176    18]
  [   13    19]]

 [[12185     2]
  [   12    27]]

 [[11441    39]
  [  178   568]]

 [[12132    20]
  [   17    57]]

 [[12156    12]
  [   17    41]]

 [[12162    16]
  [   25    23]]

 [[11195   529]
  [  134   368]]

 [[11880   106]
  [   84   156]]

 [[12192     1]
  [   32     1]]

 [[11793    89]
  [  148   196]]

 [[12017    18]
  [   68   123]]

 [[12195     0]
  [   26     5]]

 [[11770    72]
  [  139   245]]

 [[12049    60]
  [   29    88]]

 [[11378   412]
  [   95   341]]

 [[12175     2]
  [   14    35]]

 [[11461   363]
  [   36   366]]

 [[12209     0]
  [   17     0]]

 [[12174    10]
  [   13    29]]

 [[12119    30]
  [    8    69]]

 [[12026    28]
  [   16   156]]

 [[12207     0]
  [   18     1]]

 [[11633    94]
  [  231   268]]

 [[12120     7]
  [   30    69]]

 [[12210     5]
  [   11     0]]

 [[12107    16]
  [   36    67]]

 [[12208     0]
  [   16     2]]

 [[12215     0]
  [   11     0]]

 [[12191     0]
  [    4    31]]

 [[11683   312]
  [   61   170]]

 [[12150    19]
  [   18    39]]

 [[12196     1]
  [   29     0]]

 [[12127    51]
  [   33    15]]

 [[12174     3]
  [   49     0]]

 [[12183     9]
  [   13    21]]

 [[12052    19]
  [   57    98]]

 [[12212     0]
  [   14     0]]

 [[11803   108]
  [  125   190]]

 [[12163     0]
  [   63     0]]

 [[11811   108]
  [  148   159]]

 [[12147    10]
  [   54    15]]

 [[12120    40]
  [   34    32]]

 [[12210     1]
  [   15     0]]

 [[12194     7]
  [   16     9]]

 [[12208     0]
  [   18     0]]

 [[12163     4]
  [   59     0]]

 [[11932    88]
  [   78   128]]

 [[12123    27]
  [   58    18]]

 [[12161     6]
  [   36    23]]

 [[12033    53]
  [   90    50]]

 [[12156    28]
  [    4    38]]

 [[11753   298]
  [   87    88]]

 [[12174     9]
  [   29    14]]

 [[12194     7]
  [   21     4]]

 [[11987   134]
  [   53    52]]

 [[12207     5]
  [   10     4]]

 [[11833   151]
  [   63   179]]

 [[11875    41]
  [   99   211]]

 [[12160     7]
  [   28    31]]

 [[12214     1]
  [   11     0]]

 [[11845   194]
  [   84   103]]

 [[12144    36]
  [   31    15]]

 [[12186     0]
  [   40     0]]

 [[12191     2]
  [   21    12]]

 [[11856    81]
  [  144   145]]

 [[12194     0]
  [   32     0]]

 [[12118    33]
  [   24    51]]

 [[12166    32]
  [   18    10]]

 [[12189     0]
  [   20    17]]

 [[12200     3]
  [    4    19]]

 [[12198     3]
  [   25     0]]

 [[12111    49]
  [   30    36]]

 [[12205     0]
  [    9    12]]

 [[12127    34]
  [   15    50]]

 [[12177     9]
  [   27    13]]

 [[12212     2]
  [    2    10]]

 [[12094    19]
  [   31    82]]

 [[12047    17]
  [   47   115]]

 [[12202     0]
  [   24     0]]

 [[12168     5]
  [   16    37]]

 [[12208     4]
  [    6     8]]

 [[12073    30]
  [   49    74]]

 [[12183     2]
  [   27    14]]

 [[11774    23]
  [   72   357]]

 [[12114    47]
  [   17    48]]

 [[12193     2]
  [   19    12]]

 [[12005    48]
  [   39   134]]

 [[12183    13]
  [    7    23]]

 [[12104     5]
  [   29    88]]

 [[12022    68]
  [   24   112]]

 [[12162     3]
  [   28    33]]

 [[11906    95]
  [   20   205]]

 [[12187     4]
  [   11    24]]

 [[12179     9]
  [   18    20]]

 [[12186    10]
  [   11    19]]

 [[12210     0]
  [    3    13]]

 [[12203     1]
  [   14     8]]

 [[12109    44]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.6184
MCC	0.6108
log_loss	1.7403
f1 score weighted	0.6090
f1 score macro	0.4778
f1 score micro	0.6184
roc_auc ovr	0.9646
roc_auc ovo	0.9589
precision	0.6454
recall	0.6184

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f59985d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f59985d0670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f59985d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f59985d0460>, 'x_test': array([[13, 12, 12, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       [13,  3, 12, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [20,  6, 15, ...,  4,  2,  3],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.70      0.74       358
         1.0       0.33      0.42      0.37        12
         2.0       0.00      0.00      0.00        18
         3.0       0.39      0.30      0.34        79
         4.0       0.36      0.07      0.12        55
         5.0       0.00      0.00      0.00        58
         6.0       0.42      0.18      0.25        45
         7.0       0.49      0.57      0.53        47
         8.0       0.00      0.00      0.00        10
         9.0       1.00      0.29      0.44        21
        10.0       0.00      0.00      0.00        15
        11.0       0.92      0.67      0.77        36
        12.0       0.00      0.00      0.00        12
        13.0       0.71      0.60      0.65        25
        14.0       1.00      0.15      0.26        20
        15.0       0.62      0.82      0.71        22
        16.0       0.35      0.74      0.47        23
        17.0       0.64      0.85      0.73       118
        18.0       0.00      0.00      0.00        18
        19.0       0.00      0.00      0.00        13
        20.0       0.52      0.17      0.25        89
        21.0       0.00      0.00      0.00        13
        22.0       0.89      0.64      0.74        25
        23.0       0.00      0.00      0.00        12
        24.0       0.29      0.09      0.13        23
        25.0       0.86      0.32      0.47        37
        26.0       0.94      0.94      0.94        17
        27.0       0.55      0.17      0.26        36
        28.0       0.33      0.17      0.22        12
        29.0       0.35      0.17      0.23        36
        30.0       0.57      0.62      0.60        32
        31.0       0.96      0.62      0.75        39
        32.0       0.92      0.74      0.82       747
        33.0       0.70      0.77      0.73        74
        34.0       0.59      0.83      0.69        58
        35.0       0.16      0.83      0.27        47
        36.0       0.53      0.66      0.59       502
        37.0       0.70      0.45      0.54       240
        38.0       0.68      0.50      0.58        34
        39.0       0.47      0.78      0.59       344
        40.0       0.87      0.72      0.79       191
        41.0       0.85      0.53      0.65        32
        42.0       0.87      0.62      0.72       384
        43.0       0.73      0.76      0.74       117
        44.0       0.70      0.70      0.70       437
        45.0       0.83      0.71      0.77        49
        46.0       0.86      0.81      0.83       401
        47.0       1.00      0.41      0.58        17
        48.0       0.50      0.48      0.49        42
        49.0       0.48      0.91      0.63        77
        50.0       0.86      0.83      0.84       171
        51.0       0.86      0.60      0.71        20
        52.0       0.50      0.70      0.58       499
        53.0       0.78      0.50      0.61       100
        54.0       0.00      0.00      0.00        11
        55.0       0.89      0.68      0.77       104
        56.0       0.33      0.11      0.16        19
        57.0       0.00      0.00      0.00        11
        58.0       0.82      0.91      0.86        35
        59.0       0.38      0.67      0.48       230
        60.0       0.61      0.69      0.65        58
        61.0       0.00      0.00      0.00        29
        62.0       0.31      0.22      0.26        49
        63.0       0.08      0.02      0.03        50
        64.0       0.95      0.62      0.75        34
        65.0       0.80      0.76      0.78       155
        66.0       0.33      0.07      0.12        14
        67.0       0.55      0.63      0.59       314
        68.0       0.00      0.00      0.00        62
        69.0       0.48      0.59      0.53       307
        70.0       0.73      0.16      0.27        68
        71.0       0.39      0.32      0.35        66
        72.0       0.33      0.07      0.11        15
        73.0       0.61      0.44      0.51        25
        74.0       0.00      0.00      0.00        19
        75.0       0.09      0.03      0.05        59
        76.0       0.77      0.65      0.70       206
        77.0       0.56      0.35      0.43        77
        78.0       0.86      0.42      0.57        59
        79.0       0.56      0.42      0.48       139
        80.0       0.91      0.71      0.80        42
        81.0       0.42      0.29      0.35       174
        82.0       0.70      0.16      0.26        43
        83.0       0.14      0.04      0.06        25
        84.0       0.39      0.37      0.38       105
        85.0       0.70      0.47      0.56        15
        86.0       0.67      0.62      0.64       242
        87.0       0.44      0.89      0.59       309
        88.0       0.86      0.63      0.73        59
        89.0       0.00      0.00      0.00        11
        90.0       0.33      0.63      0.43       188
        91.0       0.48      0.28      0.35        47
        92.0       0.17      0.03      0.04        40
        93.0       1.00      0.30      0.47        33
        94.0       0.58      0.51      0.54       288
        95.0       0.00      0.00      0.00        32
        96.0       0.94      0.68      0.79        75
        97.0       0.58      0.26      0.36        27
        98.0       0.87      0.53      0.66        38
        99.0       0.60      0.91      0.72        23
       100.0       0.00      0.00      0.00        25
       101.0       0.85      0.26      0.40        66
       102.0       0.71      0.55      0.62        22
       103.0       0.70      0.58      0.63        64
       104.0       0.82      0.23      0.36        39
       105.0       1.00      0.58      0.74        12
       106.0       0.89      0.50      0.64       113
       107.0       0.78      0.75      0.76       161
       108.0       0.00      0.00      0.00        23
       109.0       0.49      0.66      0.56        53
       110.0       1.00      0.79      0.88        14
       111.0       0.79      0.45      0.57       123
       112.0       0.59      0.41      0.49        41
       113.0       0.81      0.90      0.85       429
       114.0       0.24      0.86      0.38        65
       115.0       0.82      0.29      0.43        31
       116.0       0.52      0.73      0.61       173
       117.0       0.63      0.71      0.67        31
       118.0       0.65      0.77      0.71       117
       119.0       0.62      0.81      0.70       135
       120.0       0.73      0.53      0.62        62
       121.0       0.78      0.84      0.81       224
       122.0       0.68      0.77      0.72        35
       123.0       0.54      0.57      0.55        37
       124.0       0.83      0.50      0.62        30
       125.0       0.87      0.81      0.84        16
       126.0       0.83      0.86      0.84        22
       127.0       0.68      0.84      0.75        73

    accuracy                           0.61     12226
   macro avg       0.55      0.46      0.47     12226
weighted avg       0.64      0.61      0.60     12226


===confusion_matrix===

[[252   2   0 ...   0   0   0]
 [  0   5   0 ...   0   0   0]
 [  0   0   0 ...   0   0   0]
 ...
 [  0   0   0 ...  13   2   0]
 [  0   0   0 ...   1  19   2]
 [  0   0   0 ...   1   2  61]]

===multilabel confusion matrix===

[[[11795    73]
  [  106   252]]

 [[12204    10]
  [    7     5]]

 [[12208     0]
  [   18     0]]

 [[12109    38]
  [   55    24]]

 [[12164     7]
  [   51     4]]

 [[12162     6]
  [   58     0]]

 [[12170    11]
  [   37     8]]

 [[12151    28]
  [   20    27]]

 [[12216     0]
  [   10     0]]

 [[12205     0]
  [   15     6]]

 [[12211     0]
  [   15     0]]

 [[12188     2]
  [   12    24]]

 [[12214     0]
  [   12     0]]

 [[12195     6]
  [   10    15]]

 [[12206     0]
  [   17     3]]

 [[12193    11]
  [    4    18]]

 [[12171    32]
  [    6    17]]

 [[12051    57]
  [   18   100]]

 [[12204     4]
  [   18     0]]

 [[12213     0]
  [   13     0]]

 [[12123    14]
  [   74    15]]

 [[12213     0]
  [   13     0]]

 [[12199     2]
  [    9    16]]

 [[12211     3]
  [   12     0]]

 [[12198     5]
  [   21     2]]

 [[12187     2]
  [   25    12]]

 [[12208     1]
  [    1    16]]

 [[12185     5]
  [   30     6]]

 [[12210     4]
  [   10     2]]

 [[12179    11]
  [   30     6]]

 [[12179    15]
  [   12    20]]

 [[12186     1]
  [   15    24]]

 [[11431    48]
  [  197   550]]

 [[12127    25]
  [   17    57]]

 [[12134    34]
  [   10    48]]

 [[11978   201]
  [    8    39]]

 [[11435   289]
  [  172   330]]

 [[11940    46]
  [  133   107]]

 [[12184     8]
  [   17    17]]

 [[11582   300]
  [   74   270]]

 [[12014    21]
  [   54   137]]

 [[12191     3]
  [   15    17]]

 [[11807    35]
  [  147   237]]

 [[12076    33]
  [   28    89]]

 [[11660   129]
  [  130   307]]

 [[12170     7]
  [   14    35]]

 [[11772    53]
  [   78   323]]

 [[12209     0]
  [   10     7]]

 [[12164    20]
  [   22    20]]

 [[12073    76]
  [    7    70]]

 [[12031    24]
  [   29   142]]

 [[12204     2]
  [    8    12]]

 [[11371   356]
  [  148   351]]

 [[12112    14]
  [   50    50]]

 [[12213     2]
  [   11     0]]

 [[12113     9]
  [   33    71]]

 [[12203     4]
  [   17     2]]

 [[12215     0]
  [   11     0]]

 [[12184     7]
  [    3    32]]

 [[11738   258]
  [   75   155]]

 [[12142    26]
  [   18    40]]

 [[12197     0]
  [   29     0]]

 [[12152    25]
  [   38    11]]

 [[12165    11]
  [   49     1]]

 [[12191     1]
  [   13    21]]

 [[12041    30]
  [   37   118]]

 [[12210     2]
  [   13     1]]

 [[11753   159]
  [  116   198]]

 [[12158     6]
  [   62     0]]

 [[11720   199]
  [  126   181]]

 [[12154     4]
  [   57    11]]

 [[12127    33]
  [   45    21]]

 [[12209     2]
  [   14     1]]

 [[12194     7]
  [   14    11]]

 [[12207     0]
  [   19     0]]

 [[12146    21]
  [   57     2]]

 [[11979    41]
  [   72   134]]

 [[12128    21]
  [   50    27]]

 [[12163     4]
  [   34    25]]

 [[12041    46]
  [   81    58]]

 [[12181     3]
  [   12    30]]

 [[11982    70]
  [  123    51]]

 [[12180     3]
  [   36     7]]

 [[12195     6]
  [   24     1]]

 [[12060    61]
  [   66    39]]

 [[12208     3]
  [    8     7]]

 [[11912    72]
  [   93   149]]

 [[11572   345]
  [   34   275]]

 [[12161     6]
  [   22    37]]

 [[12214     1]
  [   11     0]]

 [[11799   239]
  [   70   118]]

 [[12165    14]
  [   34    13]]

 [[12181     5]
  [   39     1]]

 [[12193     0]
  [   23    10]]

 [[11834   104]
  [  142   146]]

 [[12189     5]
  [   32     0]]

 [[12148     3]
  [   24    51]]

 [[12194     5]
  [   20     7]]

 [[12185     3]
  [   18    20]]

 [[12189    14]
  [    2    21]]

 [[12201     0]
  [   25     0]]

 [[12157     3]
  [   49    17]]

 [[12199     5]
  [   10    12]]

 [[12146    16]
  [   27    37]]

 [[12185     2]
  [   30     9]]

 [[12214     0]
  [    5     7]]

 [[12106     7]
  [   56    57]]

 [[12032    33]
  [   41   120]]

 [[12200     3]
  [   23     0]]

 [[12137    36]
  [   18    35]]

 [[12212     0]
  [    3    11]]

 [[12088    15]
  [   68    55]]

 [[12173    12]
  [   24    17]]

 [[11707    90]
  [   42   387]]

 [[11986   175]
  [    9    56]]

 [[12193     2]
  [   22     9]]

 [[11938   115]
  [   46   127]]

 [[12182    13]
  [    9    22]]

 [[12061    48]
  [   27    90]]

 [[12023    68]
  [   25   110]]

 [[12152    12]
  [   29    33]]

 [[11949    53]
  [   35   189]]

 [[12178    13]
  [    8    27]]

 [[12171    18]
  [   16    21]]

 [[12193     3]
  [   15    15]]

 [[12208     2]
  [    3    13]]

 [[12200     4]
  [    3    19]]

 [[12124    29]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.6132
MCC	0.6053
log_loss	1.8092
f1 score weighted	0.6021
f1 score macro	0.4717
f1 score micro	0.6132
roc_auc ovr	0.9643
roc_auc ovo	0.9576
precision	0.6363
recall	0.6132

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f59985d0910>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f59985d0670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f59985d0940>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f59985d0460>, 'x_test': array([[13, 17, 12, ...,  0,  0,  0],
       [13,  4, 12, ...,  0,  0,  0],
       [13,  7,  1, ...,  0,  0,  0],
       ...,
       [20, 19, 11, ...,  1, 19,  5],
       [20, 20, 20, ...,  1,  7,  1],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.76      0.76       358
         1.0       1.00      0.33      0.50        12
         2.0       0.53      0.42      0.47        19
         3.0       0.54      0.35      0.43        79
         4.0       0.14      0.33      0.19        55
         5.0       0.15      0.28      0.19        58
         6.0       0.35      0.16      0.22        45
         7.0       0.68      0.64      0.66        47
         8.0       1.00      0.10      0.18        10
         9.0       0.22      0.10      0.13        21
        10.0       0.00      0.00      0.00        15
        11.0       0.85      0.64      0.73        36
        12.0       0.31      0.42      0.36        12
        13.0       0.55      0.68      0.61        25
        14.0       0.78      0.37      0.50        19
        15.0       0.68      0.77      0.72        22
        16.0       0.62      0.57      0.59        23
        17.0       0.84      0.80      0.82       118
        18.0       0.50      0.22      0.31        18
        19.0       0.00      0.00      0.00        12
        20.0       0.83      0.27      0.40        90
        21.0       1.00      0.38      0.56        13
        22.0       0.82      0.72      0.77        25
        23.0       0.00      0.00      0.00        13
        24.0       0.67      0.18      0.29        22
        25.0       0.92      0.32      0.47        38
        26.0       0.94      1.00      0.97        17
        27.0       0.50      0.11      0.19        35
        28.0       0.67      0.17      0.27        12
        29.0       0.61      0.39      0.47        36
        30.0       0.42      0.47      0.44        32
        31.0       0.54      0.82      0.65        38
        32.0       0.58      0.87      0.69       747
        33.0       0.64      0.89      0.74        75
        34.0       0.66      0.81      0.73        59
        35.0       0.73      0.40      0.52        47
        36.0       0.84      0.53      0.65       501
        37.0       0.43      0.76      0.55       241
        38.0       0.90      0.27      0.42        33
        39.0       0.54      0.62      0.58       344
        40.0       0.90      0.72      0.80       192
        41.0       0.49      0.56      0.52        32
        42.0       0.61      0.76      0.68       384
        43.0       0.68      0.80      0.74       117
        44.0       0.80      0.69      0.74       436
        45.0       0.93      0.82      0.87        49
        46.0       0.75      0.87      0.81       401
        47.0       1.00      0.06      0.11        17
        48.0       0.90      0.62      0.73        42
        49.0       0.97      0.81      0.88        77
        50.0       0.84      0.86      0.85       172
        51.0       0.90      0.45      0.60        20
        52.0       0.81      0.56      0.66       499
        53.0       0.75      0.50      0.60       100
        54.0       0.00      0.00      0.00        11
        55.0       0.94      0.71      0.81       104
        56.0       0.35      0.33      0.34        18
        57.0       0.00      0.00      0.00        10
        58.0       0.96      0.71      0.82        35
        59.0       0.60      0.58      0.59       230
        60.0       0.42      0.76      0.54        58
        61.0       0.09      0.03      0.05        29
        62.0       0.64      0.14      0.23        49
        63.0       0.31      0.36      0.33        50
        64.0       0.95      0.62      0.75        34
        65.0       0.85      0.68      0.76       155
        66.0       0.00      0.00      0.00        14
        67.0       0.62      0.64      0.63       314
        68.0       0.04      0.02      0.02        62
        69.0       0.60      0.54      0.57       307
        70.0       0.40      0.25      0.31        68
        71.0       0.82      0.21      0.34        66
        72.0       0.00      0.00      0.00        14
        73.0       0.71      0.50      0.59        24
        74.0       0.00      0.00      0.00        19
        75.0       0.35      0.15      0.21        60
        76.0       0.90      0.57      0.70       206
        77.0       0.35      0.44      0.39        77
        78.0       0.66      0.59      0.62        59
        79.0       0.38      0.36      0.37       139
        80.0       0.74      0.67      0.70        42
        81.0       0.58      0.39      0.47       174
        82.0       0.44      0.19      0.26        43
        83.0       0.50      0.12      0.19        26
        84.0       0.44      0.41      0.42       106
        85.0       0.62      0.33      0.43        15
        86.0       0.35      0.74      0.47       241
        87.0       0.69      0.78      0.73       309
        88.0       0.78      0.53      0.63        59
        89.0       1.00      0.20      0.33        10
        90.0       0.51      0.45      0.48       188
        91.0       0.61      0.30      0.41        46
        92.0       0.29      0.05      0.08        41
        93.0       0.63      0.38      0.47        32
        94.0       0.78      0.51      0.62       288
        95.0       0.00      0.00      0.00        31
        96.0       0.76      0.72      0.74        75
        97.0       0.86      0.22      0.35        27
        98.0       0.63      0.45      0.52        38
        99.0       0.88      0.92      0.90        24
       100.0       0.00      0.00      0.00        25
       101.0       0.73      0.49      0.59        65
       102.0       0.43      0.73      0.54        22
       103.0       0.77      0.69      0.73        64
       104.0       0.69      0.28      0.39        40
       105.0       0.83      0.83      0.83        12
       106.0       0.80      0.65      0.72       113
       107.0       0.62      0.84      0.71       161
       108.0       0.32      0.25      0.28        24
       109.0       0.91      0.58      0.71        52
       110.0       0.73      0.73      0.73        15
       111.0       0.64      0.59      0.61       124
       112.0       0.66      0.51      0.58        41
       113.0       0.70      0.93      0.80       430
       114.0       0.95      0.57      0.71        65
       115.0       0.50      0.42      0.46        31
       116.0       0.43      0.81      0.56       173
       117.0       0.84      0.84      0.84        31
       118.0       0.91      0.78      0.84       117
       119.0       0.87      0.55      0.68       136
       120.0       0.97      0.61      0.75        62
       121.0       0.42      0.92      0.58       224
       122.0       1.00      0.71      0.83        35
       123.0       0.85      0.62      0.72        37
       124.0       0.57      0.84      0.68        31
       125.0       0.67      0.67      0.67        15
       126.0       0.94      0.71      0.81        21
       127.0       0.73      0.84      0.78        73

    accuracy                           0.63     12226
   macro avg       0.61      0.49      0.51     12226
weighted avg       0.66      0.63      0.62     12226


===confusion_matrix===

[[273   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0   8 ...   0   0   0]
 ...
 [  0   0   0 ...  10   0   2]
 [  0   0   0 ...   1  15   3]
 [  0   0   0 ...   1   0  61]]

===multilabel confusion matrix===

[[[11777    91]
  [   85   273]]

 [[12214     0]
  [    8     4]]

 [[12200     7]
  [   11     8]]

 [[12123    24]
  [   51    28]]

 [[12056   115]
  [   37    18]]

 [[12074    94]
  [   42    16]]

 [[12168    13]
  [   38     7]]

 [[12165    14]
  [   17    30]]

 [[12216     0]
  [    9     1]]

 [[12198     7]
  [   19     2]]

 [[12210     1]
  [   15     0]]

 [[12186     4]
  [   13    23]]

 [[12203    11]
  [    7     5]]

 [[12187    14]
  [    8    17]]

 [[12205     2]
  [   12     7]]

 [[12196     8]
  [    5    17]]

 [[12195     8]
  [   10    13]]

 [[12090    18]
  [   24    94]]

 [[12204     4]
  [   14     4]]

 [[12214     0]
  [   12     0]]

 [[12131     5]
  [   66    24]]

 [[12213     0]
  [    8     5]]

 [[12197     4]
  [    7    18]]

 [[12213     0]
  [   13     0]]

 [[12202     2]
  [   18     4]]

 [[12187     1]
  [   26    12]]

 [[12208     1]
  [    0    17]]

 [[12187     4]
  [   31     4]]

 [[12213     1]
  [   10     2]]

 [[12181     9]
  [   22    14]]

 [[12173    21]
  [   17    15]]

 [[12162    26]
  [    7    31]]

 [[11006   473]
  [   98   649]]

 [[12113    38]
  [    8    67]]

 [[12142    25]
  [   11    48]]

 [[12172     7]
  [   28    19]]

 [[11674    51]
  [  236   265]]

 [[11748   237]
  [   59   182]]

 [[12192     1]
  [   24     9]]

 [[11700   182]
  [  129   215]]

 [[12019    15]
  [   53   139]]

 [[12175    19]
  [   14    18]]

 [[11658   184]
  [   94   290]]

 [[12065    44]
  [   23    94]]

 [[11715    75]
  [  136   300]]

 [[12174     3]
  [    9    40]]

 [[11711   114]
  [   53   348]]

 [[12209     0]
  [   16     1]]

 [[12181     3]
  [   16    26]]

 [[12147     2]
  [   15    62]]

 [[12025    29]
  [   24   148]]

 [[12205     1]
  [   11     9]]

 [[11661    66]
  [  222   277]]

 [[12109    17]
  [   50    50]]

 [[12215     0]
  [   11     0]]

 [[12117     5]
  [   30    74]]

 [[12197    11]
  [   12     6]]

 [[12216     0]
  [   10     0]]

 [[12190     1]
  [   10    25]]

 [[11907    89]
  [   97   133]]

 [[12106    62]
  [   14    44]]

 [[12187    10]
  [   28     1]]

 [[12173     4]
  [   42     7]]

 [[12136    40]
  [   32    18]]

 [[12191     1]
  [   13    21]]

 [[12052    19]
  [   49   106]]

 [[12212     0]
  [   14     0]]

 [[11787   125]
  [  113   201]]

 [[12142    22]
  [   61     1]]

 [[11809   110]
  [  140   167]]

 [[12132    26]
  [   51    17]]

 [[12157     3]
  [   52    14]]

 [[12212     0]
  [   14     0]]

 [[12197     5]
  [   12    12]]

 [[12191    16]
  [   19     0]]

 [[12149    17]
  [   51     9]]

 [[12007    13]
  [   88   118]]

 [[12086    63]
  [   43    34]]

 [[12149    18]
  [   24    35]]

 [[12005    82]
  [   89    50]]

 [[12174    10]
  [   14    28]]

 [[12003    49]
  [  106    68]]

 [[12173    10]
  [   35     8]]

 [[12197     3]
  [   23     3]]

 [[12065    55]
  [   63    43]]

 [[12208     3]
  [   10     5]]

 [[11653   332]
  [   63   178]]

 [[11807   110]
  [   69   240]]

 [[12158     9]
  [   28    31]]

 [[12216     0]
  [    8     2]]

 [[11957    81]
  [  104    84]]

 [[12171     9]
  [   32    14]]

 [[12180     5]
  [   39     2]]

 [[12187     7]
  [   20    12]]

 [[11896    42]
  [  140   148]]

 [[12195     0]
  [   31     0]]

 [[12134    17]
  [   21    54]]

 [[12198     1]
  [   21     6]]

 [[12178    10]
  [   21    17]]

 [[12199     3]
  [    2    22]]

 [[12199     2]
  [   25     0]]

 [[12149    12]
  [   33    32]]

 [[12183    21]
  [    6    16]]

 [[12149    13]
  [   20    44]]

 [[12181     5]
  [   29    11]]

 [[12212     2]
  [    2    10]]

 [[12095    18]
  [   39    74]]

 [[11980    85]
  [   25   136]]

 [[12189    13]
  [   18     6]]

 [[12171     3]
  [   22    30]]

 [[12207     4]
  [    4    11]]

 [[12061    41]
  [   51    73]]

 [[12174    11]
  [   20    21]]

 [[11624   172]
  [   32   398]]

 [[12159     2]
  [   28    37]]

 [[12182    13]
  [   18    13]]

 [[11870   183]
  [   33   140]]

 [[12190     5]
  [    5    26]]

 [[12100     9]
  [   26    91]]

 [[12079    11]
  [   61    75]]

 [[12163     1]
  [   24    38]]

 [[11722   280]
  [   18   206]]

 [[12191     0]
  [   10    25]]

 [[12185     4]
  [   14    23]]

 [[12175    20]
  [    5    26]]

 [[12206     5]
  [    5    10]]

 [[12204     1]
  [    6    15]]

 [[12131    22]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.6278
MCC	0.6201
log_loss	1.7384
f1 score weighted	0.6189
f1 score macro	0.5125
f1 score micro	0.6278
roc_auc ovr	0.9671
roc_auc ovo	0.9611
precision	0.6589
recall	0.6278

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.60333687740247	0.5954215973386286	1.7954478272544665	0.597743846521453	0.4686213581897638	0.60333687740247	0.9630569401287578	0.9579048234097304	0.639741771117403	0.60333687740247
1	0.6559254109757094	0.6486126909219039	1.5905075255562588	0.6476210995757197	0.5302906109875289	0.6559254109757094	0.9699408060671545	0.9642548487021345	0.676725849818234	0.6559254109757094
2	0.6184361197448062	0.6107954267685116	1.7403047856596245	0.6090436119386895	0.47780719549870376	0.6184361197448062	0.9645898665795173	0.9589064904701882	0.6454124638710848	0.6184361197448062
3	0.6132013741207263	0.605305997271321	1.8092370740332646	0.6020604782952724	0.4716955975455125	0.6132013741207263	0.9642742568231802	0.9576073873876285	0.6363440920864565	0.6132013741207263
4	0.6277605103876983	0.6200604543449381	1.7383999520667077	0.6189399188508848	0.5124847407715598	0.6277605103876983	0.9670939547675123	0.9610951866207845	0.6588710290522883	0.6277605103876983
mean	0.6237320585262821	0.6160392333290606	1.7347794329140644	0.6150817910364038	0.4921799005986138	0.6237320585262821	0.9657911648732244	0.9599537473180932	0.6514190411890933	0.6237320585262821
std	0.01793067796282369	0.018138286222026973	0.07756624952572466	0.017778134113407996	0.024681568121521395	0.01793067796282369	0.0024550721424441363	0.0024739683833293253	0.014803096864890508	0.01793067796282369

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 27517.9539 secs

