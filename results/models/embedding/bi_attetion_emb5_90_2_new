/home/amsequeira/enzymeClassification/models/embedding/bi_attetion_emb5_90_2_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe2f45a2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe2f45a2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe2f45a2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe2f45a26a0>, 'x_test': array([[13,  2,  3, ...,  0,  0,  0],
       [13, 13,  2, ...,  0,  0,  0],
       [13,  7,  1, ...,  0,  0,  0],
       ...,
       [13,  4, 11, ...,  0,  0,  0],
       [13,  1, 20, ...,  0,  0,  0],
       [13,  6, 12, ...,  0,  0,  0]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.87      0.87       911
         1.0       0.91      0.60      0.73        53
         2.0       0.97      0.69      0.81       179
         3.0       1.00      0.08      0.15        25
         4.0       0.53      0.48      0.51       112
         5.0       0.59      0.72      0.65       491
         6.0       1.00      0.70      0.83        64
         7.0       0.00      0.00      0.00        37
         8.0       0.94      0.83      0.88       206
         9.0       0.88      0.75      0.81        71
        10.0       0.98      0.84      0.90       404
        11.0       1.00      0.25      0.40        16
        12.0       0.85      0.73      0.79       378
        13.0       0.76      0.73      0.75       191
        14.0       0.17      0.01      0.02        76
        15.0       0.83      0.67      0.74        66
        16.0       0.91      0.76      0.83       141
        17.0       0.76      0.74      0.75       182
        18.0       1.00      0.67      0.80        12
        19.0       1.00      0.84      0.91        38
        20.0       0.63      0.97      0.76      2162
        21.0       0.99      0.86      0.92       168
        22.0       0.78      0.78      0.78      1470
        23.0       0.79      0.86      0.82      1259
        24.0       0.93      0.86      0.89       956
        25.0       0.97      0.87      0.92       283
        26.0       0.94      0.83      0.88      3919
        27.0       0.94      0.91      0.92       531
        28.0       1.00      0.67      0.80        12
        29.0       0.61      0.84      0.71      2345
        30.0       0.73      0.54      0.62       615
        31.0       0.91      0.66      0.76        32
        32.0       0.85      0.65      0.73      1449
        33.0       0.83      0.74      0.78       893
        34.0       0.91      0.84      0.87      1377
        35.0       0.82      0.64      0.72        22
        36.0       0.77      0.83      0.80       844
        37.0       0.96      0.83      0.89      1142
        38.0       0.99      0.84      0.91       314
        39.0       0.89      0.45      0.60        56
        40.0       0.97      0.73      0.83       154
        41.0       0.81      0.92      0.86        52
        42.0       0.89      0.68      0.77       247
        43.0       0.98      0.64      0.78       198
        44.0       0.95      0.88      0.92       529
        45.0       0.77      0.87      0.82       540
        46.0       1.00      0.25      0.40        20
        47.0       0.70      0.68      0.69        80
        48.0       0.96      0.97      0.96      1466
        49.0       0.99      0.78      0.87       148
        50.0       0.98      0.90      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.94      0.91      0.92       151
        53.0       0.96      0.96      0.96       903
        54.0       1.00      0.58      0.74       108
        55.0       0.82      0.97      0.89        93
        56.0       0.96      0.82      0.89        33
        57.0       0.91      0.80      0.85        49
        58.0       0.83      0.93      0.88       154

    accuracy                           0.83     29892
   macro avg       0.84      0.71      0.75     29892
weighted avg       0.84      0.83      0.83     29892


===confusion_matrix===

[[795   0   0 ...   0   0   0]
 [  0  32   0 ...   0   0   0]
 [  0   0 124 ...   0   0   0]
 ...
 [  0   0   0 ...  27   1   1]
 [  0   0   0 ...   0  39   6]
 [  0   0   0 ...   0   2 143]]

===multilabel confusion matrix===

[[[28851   130]
  [  116   795]]

 [[29836     3]
  [   21    32]]

 [[29709     4]
  [   55   124]]

 [[29867     0]
  [   23     2]]

 [[29733    47]
  [   58    54]]

 [[29155   246]
  [  137   354]]

 [[29828     0]
  [   19    45]]

 [[29855     0]
  [   37     0]]

 [[29676    10]
  [   36   170]]

 [[29814     7]
  [   18    53]]

 [[29480     8]
  [   66   338]]

 [[29876     0]
  [   12     4]]

 [[29465    49]
  [  101   277]]

 [[29658    43]
  [   52   139]]

 [[29811     5]
  [   75     1]]

 [[29817     9]
  [   22    44]]

 [[29740    11]
  [   34   107]]

 [[29667    43]
  [   48   134]]

 [[29880     0]
  [    4     8]]

 [[29854     0]
  [    6    32]]

 [[26506  1224]
  [   73  2089]]

 [[29722     2]
  [   24   144]]

 [[28094   328]
  [  317  1153]]

 [[28352   281]
  [  180  1079]]

 [[28875    61]
  [  138   818]]

 [[29601     8]
  [   37   246]]

 [[25774   199]
  [  663  3256]]

 [[29330    31]
  [   48   483]]

 [[29880     0]
  [    4     8]]

 [[26281  1266]
  [  378  1967]]

 [[29152   125]
  [  282   333]]

 [[29858     2]
  [   11    21]]

 [[28277   166]
  [  513   936]]

 [[28859   140]
  [  232   661]]

 [[28399   116]
  [  220  1157]]

 [[29867     3]
  [    8    14]]

 [[28845   203]
  [  147   697]]

 [[28711    39]
  [  195   947]]

 [[29574     4]
  [   49   265]]

 [[29833     3]
  [   31    25]]

 [[29734     4]
  [   42   112]]

 [[29829    11]
  [    4    48]]

 [[29624    21]
  [   79   168]]

 [[29692     2]
  [   71   127]]

 [[29340    23]
  [   63   466]]

 [[29212   140]
  [   68   472]]

 [[29872     0]
  [   15     5]]

 [[29789    23]
  [   26    54]]

 [[28364    62]
  [   49  1417]]

 [[29743     1]
  [   33   115]]

 [[28419    20]
  [  144  1309]]

 [[29880     0]
  [   12     0]]

 [[29732     9]
  [   14   137]]

 [[28953    36]
  [   37   866]]

 [[29784     0]
  [   45    63]]

 [[29779    20]
  [    3    90]]

 [[29858     1]
  [    6    27]]

 [[29839     4]
  [   10    39]]

 [[29709    29]
  [   11   143]]]

===scores report===
metrics	scores
Accuracy	0.8253
MCC	0.8169
log_loss	0.7485
f1 score weighted	0.8263
f1 score macro	0.7483
f1 score micro	0.8253
roc_auc ovr	0.9882
roc_auc ovo	0.9846
precision	0.8442
recall	0.8253

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe2f45a2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe2f45a2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe2f45a2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe2f45a26a0>, 'x_test': array([[13, 12,  3, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [20, 20, 20, ...,  1,  7,  1],
       [13, 16, 11, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.57      0.93      0.71       912
         1.0       1.00      0.64      0.78        53
         2.0       0.90      0.73      0.81       179
         3.0       1.00      0.12      0.21        25
         4.0       0.91      0.36      0.51       112
         5.0       0.67      0.72      0.69       492
         6.0       0.95      0.65      0.77        65
         7.0       0.33      0.11      0.16        38
         8.0       0.99      0.78      0.87       206
         9.0       0.56      0.79      0.65        71
        10.0       0.89      0.84      0.87       405
        11.0       0.73      0.47      0.57        17
        12.0       0.60      0.79      0.68       377
        13.0       0.85      0.68      0.76       191
        14.0       0.21      0.18      0.19        76
        15.0       0.65      0.65      0.65        66
        16.0       0.73      0.76      0.75       140
        17.0       0.85      0.70      0.77       182
        18.0       1.00      1.00      1.00        11
        19.0       1.00      0.73      0.84        37
        20.0       0.91      0.92      0.91      2163
        21.0       0.96      0.91      0.93       169
        22.0       0.85      0.74      0.79      1469
        23.0       0.65      0.91      0.76      1259
        24.0       0.75      0.90      0.82       956
        25.0       0.89      0.84      0.86       282
        26.0       0.88      0.87      0.88      3919
        27.0       0.98      0.89      0.93       531
        28.0       1.00      0.58      0.74        12
        29.0       0.81      0.71      0.76      2346
        30.0       0.66      0.56      0.61       615
        31.0       0.89      0.78      0.83        32
        32.0       0.88      0.68      0.77      1450
        33.0       0.96      0.57      0.72       893
        34.0       0.96      0.83      0.89      1376
        35.0       1.00      0.36      0.53        22
        36.0       0.55      0.86      0.67       843
        37.0       0.85      0.82      0.83      1142
        38.0       0.75      0.88      0.81       314
        39.0       0.75      0.43      0.55        56
        40.0       0.97      0.66      0.79       154
        41.0       0.92      0.88      0.90        52
        42.0       0.71      0.83      0.77       247
        43.0       1.00      0.63      0.77       198
        44.0       0.52      0.91      0.66       529
        45.0       0.99      0.88      0.93       539
        46.0       1.00      0.05      0.10        19
        47.0       1.00      0.41      0.58        80
        48.0       0.99      0.94      0.96      1466
        49.0       0.96      0.78      0.86       148
        50.0       0.97      0.91      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.71      0.94      0.81       151
        53.0       0.95      0.94      0.94       903
        54.0       0.90      0.74      0.81       108
        55.0       0.89      0.94      0.91        93
        56.0       0.96      0.82      0.89        33
        57.0       0.81      0.90      0.85        49
        58.0       0.82      0.90      0.86       154

    accuracy                           0.82     29892
   macro avg       0.82      0.71      0.73     29892
weighted avg       0.84      0.82      0.82     29892


===confusion_matrix===

[[848   0   0 ...   0   0   0]
 [  1  34   0 ...   0   0   0]
 [  1   0 131 ...   0   0   0]
 ...
 [  0   0   0 ...  27   2   0]
 [  0   0   0 ...   0  44   5]
 [  0   0   0 ...   0   4 139]]

===multilabel confusion matrix===

[[[28349   631]
  [   64   848]]

 [[29839     0]
  [   19    34]]

 [[29699    14]
  [   48   131]]

 [[29867     0]
  [   22     3]]

 [[29776     4]
  [   72    40]]

 [[29223   177]
  [  139   353]]

 [[29825     2]
  [   23    42]]

 [[29846     8]
  [   34     4]]

 [[29684     2]
  [   46   160]]

 [[29777    44]
  [   15    56]]

 [[29444    43]
  [   63   342]]

 [[29872     3]
  [    9     8]]

 [[29320   195]
  [   80   297]]

 [[29678    23]
  [   61   130]]

 [[29762    54]
  [   62    14]]

 [[29803    23]
  [   23    43]]

 [[29712    40]
  [   33   107]]

 [[29688    22]
  [   54   128]]

 [[29881     0]
  [    0    11]]

 [[29855     0]
  [   10    27]]

 [[27524   205]
  [  173  1990]]

 [[29716     7]
  [   15   154]]

 [[28229   194]
  [  377  1092]]

 [[28017   616]
  [  116  1143]]

 [[28651   285]
  [   99   857]]

 [[29581    29]
  [   45   237]]

 [[25527   446]
  [  518  3401]]

 [[29353     8]
  [   60   471]]

 [[29880     0]
  [    5     7]]

 [[27146   400]
  [  678  1668]]

 [[29101   176]
  [  270   345]]

 [[29857     3]
  [    7    25]]

 [[28305   137]
  [  464   986]]

 [[28977    22]
  [  382   511]]

 [[28472    44]
  [  239  1137]]

 [[29870     0]
  [   14     8]]

 [[28464   585]
  [  121   722]]

 [[28579   171]
  [  202   940]]

 [[29488    90]
  [   38   276]]

 [[29828     8]
  [   32    24]]

 [[29735     3]
  [   52   102]]

 [[29836     4]
  [    6    46]]

 [[29563    82]
  [   43   204]]

 [[29694     0]
  [   73   125]]

 [[28928   435]
  [   50   479]]

 [[29347     6]
  [   63   476]]

 [[29873     0]
  [   18     1]]

 [[29812     0]
  [   47    33]]

 [[28406    20]
  [   90  1376]]

 [[29739     5]
  [   33   115]]

 [[28393    46]
  [  137  1316]]

 [[29880     0]
  [   12     0]]

 [[29683    58]
  [    9   142]]

 [[28940    49]
  [   56   847]]

 [[29775     9]
  [   28    80]]

 [[29788    11]
  [    6    87]]

 [[29858     1]
  [    6    27]]

 [[29833    10]
  [    5    44]]

 [[29707    31]
  [   15   139]]]

===scores report===
metrics	scores
Accuracy	0.8166
MCC	0.8077
log_loss	0.7783
f1 score weighted	0.8182
f1 score macro	0.7319
f1 score micro	0.8166
roc_auc ovr	0.9878
roc_auc ovo	0.9852
precision	0.8402
recall	0.8166

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe2f45a2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe2f45a2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe2f45a2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe2f45a26a0>, 'x_test': array([[13, 16,  8, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       [13, 19,  3, ...,  0,  0,  0],
       ...,
       [13,  1, 17, ...,  0,  0,  0],
       [ 9,  5,  1, ...,  8, 11, 15],
       [20,  6, 15, ...,  4,  2,  3]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.88      0.87       912
         1.0       0.98      0.77      0.86        52
         2.0       0.97      0.69      0.80       179
         3.0       0.00      0.00      0.00        25
         4.0       0.61      0.22      0.33       112
         5.0       0.74      0.69      0.72       492
         6.0       0.98      0.68      0.80        65
         7.0       0.44      0.11      0.17        38
         8.0       1.00      0.73      0.84       205
         9.0       0.76      0.77      0.77        71
        10.0       0.97      0.84      0.90       405
        11.0       1.00      0.24      0.38        17
        12.0       0.84      0.73      0.78       377
        13.0       0.90      0.76      0.82       190
        14.0       0.00      0.00      0.00        76
        15.0       0.59      0.72      0.64        67
        16.0       0.89      0.76      0.82       140
        17.0       0.79      0.70      0.74       183
        18.0       0.92      0.92      0.92        12
        19.0       0.89      0.86      0.88        37
        20.0       0.56      0.96      0.70      2162
        21.0       0.93      0.92      0.93       169
        22.0       0.60      0.80      0.69      1470
        23.0       0.84      0.84      0.84      1259
        24.0       0.57      0.94      0.71       956
        25.0       0.90      0.89      0.89       282
        26.0       0.87      0.87      0.87      3918
        27.0       0.96      0.86      0.91       531
        28.0       0.90      0.69      0.78        13
        29.0       0.74      0.72      0.73      2346
        30.0       0.89      0.39      0.55       615
        31.0       1.00      0.75      0.86        32
        32.0       0.97      0.53      0.68      1450
        33.0       0.97      0.56      0.71       893
        34.0       0.87      0.88      0.88      1376
        35.0       0.92      0.50      0.65        22
        36.0       0.80      0.81      0.80       843
        37.0       0.94      0.84      0.89      1142
        38.0       0.88      0.87      0.87       314
        39.0       1.00      0.29      0.45        55
        40.0       0.95      0.64      0.76       154
        41.0       0.93      0.83      0.88        52
        42.0       0.93      0.73      0.82       247
        43.0       0.95      0.79      0.86       197
        44.0       0.99      0.82      0.90       530
        45.0       0.96      0.84      0.89       540
        46.0       0.00      0.00      0.00        19
        47.0       0.94      0.37      0.53        79
        48.0       0.98      0.96      0.97      1465
        49.0       0.98      0.81      0.88       149
        50.0       0.96      0.90      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.95      0.89      0.92       152
        53.0       0.91      0.95      0.93       903
        54.0       0.93      0.74      0.82       108
        55.0       0.88      0.91      0.89        93
        56.0       0.94      0.97      0.95        32
        57.0       0.92      0.92      0.92        50
        58.0       0.90      0.91      0.91       154

    accuracy                           0.81     29892
   macro avg       0.82      0.69      0.73     29892
weighted avg       0.84      0.81      0.81     29892


===confusion_matrix===

[[800   0   0 ...   0   0   0]
 [  0  40   0 ...   0   0   0]
 [  0   0 123 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   1  46   2]
 [  0   0   0 ...   0   3 140]]

===multilabel confusion matrix===

[[[28854   126]
  [  112   800]]

 [[29839     1]
  [   12    40]]

 [[29709     4]
  [   56   123]]

 [[29867     0]
  [   25     0]]

 [[29764    16]
  [   87    25]]

 [[29283   117]
  [  151   341]]

 [[29826     1]
  [   21    44]]

 [[29849     5]
  [   34     4]]

 [[29687     0]
  [   56   149]]

 [[29804    17]
  [   16    55]]

 [[29475    12]
  [   64   341]]

 [[29875     0]
  [   13     4]]

 [[29464    51]
  [  102   275]]

 [[29685    17]
  [   45   145]]

 [[29815     1]
  [   76     0]]

 [[29791    34]
  [   19    48]]

 [[29739    13]
  [   33   107]]

 [[29674    35]
  [   54   129]]

 [[29879     1]
  [    1    11]]

 [[29851     4]
  [    5    32]]

 [[26084  1646]
  [   94  2068]]

 [[29712    11]
  [   14   155]]

 [[27644   778]
  [  296  1174]]

 [[28429   204]
  [  203  1056]]

 [[28249   687]
  [   53   903]]

 [[29582    28]
  [   31   251]]

 [[25465   509]
  [  502  3416]]

 [[29344    17]
  [   73   458]]

 [[29878     1]
  [    4     9]]

 [[26934   612]
  [  648  1698]]

 [[29247    30]
  [  373   242]]

 [[29860     0]
  [    8    24]]

 [[28415    27]
  [  682   768]]

 [[28986    13]
  [  394   499]]

 [[28339   177]
  [  165  1211]]

 [[29869     1]
  [   11    11]]

 [[28876   173]
  [  162   681]]

 [[28685    65]
  [  179   963]]

 [[29539    39]
  [   40   274]]

 [[29837     0]
  [   39    16]]

 [[29733     5]
  [   56    98]]

 [[29837     3]
  [    9    43]]

 [[29632    13]
  [   67   180]]

 [[29686     9]
  [   41   156]]

 [[29356     6]
  [   95   435]]

 [[29331    21]
  [   89   451]]

 [[29873     0]
  [   19     0]]

 [[29811     2]
  [   50    29]]

 [[28405    22]
  [   61  1404]]

 [[29740     3]
  [   29   120]]

 [[28381    58]
  [  147  1306]]

 [[29880     0]
  [   12     0]]

 [[29733     7]
  [   17   135]]

 [[28901    88]
  [   49   854]]

 [[29778     6]
  [   28    80]]

 [[29787    12]
  [    8    85]]

 [[29858     2]
  [    1    31]]

 [[29838     4]
  [    4    46]]

 [[29723    15]
  [   14   140]]]

===scores report===
metrics	scores
Accuracy	0.8077
MCC	0.7986
log_loss	0.8149
f1 score weighted	0.8064
f1 score macro	0.7322
f1 score micro	0.8077
roc_auc ovr	0.9873
roc_auc ovo	0.9834
precision	0.8362
recall	0.8077

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe2f45a2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe2f45a2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe2f45a2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe2f45a26a0>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       [13, 12, 12, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [20,  2,  1, ...,  7,  6,  6],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.86      0.84       912
         1.0       0.97      0.69      0.81        52
         2.0       0.89      0.56      0.69       179
         3.0       0.00      0.00      0.00        24
         4.0       0.57      0.37      0.45       112
         5.0       0.76      0.61      0.68       492
         6.0       0.94      0.69      0.79        64
         7.0       0.71      0.26      0.38        38
         8.0       0.98      0.80      0.88       205
         9.0       0.77      0.67      0.72        70
        10.0       0.90      0.87      0.89       405
        11.0       0.67      0.35      0.46        17
        12.0       0.70      0.76      0.73       378
        13.0       0.83      0.77      0.80       191
        14.0       0.30      0.04      0.07        76
        15.0       0.72      0.69      0.70        67
        16.0       0.95      0.76      0.85       140
        17.0       0.85      0.72      0.78       183
        18.0       1.00      0.83      0.91        12
        19.0       1.00      0.86      0.93        37
        20.0       0.90      0.93      0.91      2162
        21.0       0.99      0.87      0.92       168
        22.0       0.72      0.83      0.77      1470
        23.0       0.95      0.78      0.86      1259
        24.0       0.82      0.92      0.87       955
        25.0       0.91      0.89      0.90       282
        26.0       0.87      0.90      0.88      3918
        27.0       0.91      0.90      0.90       532
        28.0       0.90      0.69      0.78        13
        29.0       0.66      0.82      0.73      2346
        30.0       0.75      0.60      0.67       616
        31.0       1.00      0.75      0.86        32
        32.0       0.83      0.71      0.77      1449
        33.0       0.63      0.83      0.71       893
        34.0       0.93      0.88      0.91      1377
        35.0       0.82      0.41      0.55        22
        36.0       0.91      0.81      0.86       844
        37.0       0.83      0.88      0.85      1142
        38.0       0.89      0.89      0.89       314
        39.0       0.85      0.50      0.63        56
        40.0       0.96      0.71      0.82       153
        41.0       0.97      0.71      0.82        51
        42.0       0.89      0.70      0.78       246
        43.0       0.62      0.91      0.74       197
        44.0       0.91      0.87      0.89       530
        45.0       0.93      0.87      0.90       540
        46.0       0.70      0.35      0.47        20
        47.0       0.73      0.54      0.62        80
        48.0       0.99      0.93      0.96      1465
        49.0       0.91      0.84      0.88       148
        50.0       0.91      0.93      0.92      1453
        51.0       0.00      0.00      0.00        13
        52.0       0.97      0.85      0.90       151
        53.0       0.97      0.92      0.94       904
        54.0       0.84      0.82      0.83       108
        55.0       0.94      0.86      0.90        93
        56.0       0.81      0.91      0.86        33
        57.0       0.93      0.74      0.82        50
        58.0       0.86      0.91      0.88       153

    accuracy                           0.84     29892
   macro avg       0.82      0.72      0.75     29892
weighted avg       0.85      0.84      0.84     29892


===confusion_matrix===

[[785   0   0 ...   0   0   0]
 [  0  36   0 ...   0   0   0]
 [  0   0 101 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   1]
 [  0   0   0 ...   1  37  10]
 [  0   0   0 ...   3   2 139]]

===multilabel confusion matrix===

[[[28804   176]
  [  127   785]]

 [[29839     1]
  [   16    36]]

 [[29701    12]
  [   78   101]]

 [[29868     0]
  [   24     0]]

 [[29749    31]
  [   71    41]]

 [[29307    93]
  [  192   300]]

 [[29825     3]
  [   20    44]]

 [[29850     4]
  [   28    10]]

 [[29683     4]
  [   41   164]]

 [[29808    14]
  [   23    47]]

 [[29448    39]
  [   52   353]]

 [[29872     3]
  [   11     6]]

 [[29393   121]
  [   91   287]]

 [[29671    30]
  [   43   148]]

 [[29809     7]
  [   73     3]]

 [[29807    18]
  [   21    46]]

 [[29746     6]
  [   33   107]]

 [[29686    23]
  [   52   131]]

 [[29880     0]
  [    2    10]]

 [[29855     0]
  [    5    32]]

 [[27504   226]
  [  151  2011]]

 [[29722     2]
  [   22   146]]

 [[27942   480]
  [  254  1216]]

 [[28584    49]
  [  281   978]]

 [[28744   193]
  [   79   876]]

 [[29586    24]
  [   32   250]]

 [[25443   531]
  [  399  3519]]

 [[29310    50]
  [   52   480]]

 [[29878     1]
  [    4     9]]

 [[26569   977]
  [  418  1928]]

 [[29155   121]
  [  248   368]]

 [[29860     0]
  [    8    24]]

 [[28225   218]
  [  414  1035]]

 [[28556   443]
  [  150   743]]

 [[28427    88]
  [  166  1211]]

 [[29868     2]
  [   13     9]]

 [[28977    71]
  [  159   685]]

 [[28543   207]
  [  137  1005]]

 [[29542    36]
  [   33   281]]

 [[29831     5]
  [   28    28]]

 [[29734     5]
  [   44   109]]

 [[29840     1]
  [   15    36]]

 [[29624    22]
  [   74   172]]

 [[29584   111]
  [   17   180]]

 [[29319    43]
  [   68   462]]

 [[29319    33]
  [   69   471]]

 [[29869     3]
  [   13     7]]

 [[29796    16]
  [   37    43]]

 [[28417    10]
  [  102  1363]]

 [[29732    12]
  [   23   125]]

 [[28309   130]
  [  100  1353]]

 [[29879     0]
  [   13     0]]

 [[29737     4]
  [   23   128]]

 [[28960    28]
  [   71   833]]

 [[29767    17]
  [   19    89]]

 [[29794     5]
  [   13    80]]

 [[29852     7]
  [    3    30]]

 [[29839     3]
  [   13    37]]

 [[29716    23]
  [   14   139]]]

===scores report===
metrics	scores
Accuracy	0.8400
MCC	0.8315
log_loss	0.6570
f1 score weighted	0.8391
f1 score macro	0.7542
f1 score micro	0.8400
roc_auc ovr	0.9896
roc_auc ovo	0.9869
precision	0.8467
recall	0.8400

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe2f45a2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe2f45a2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe2f45a2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe2f45a26a0>, 'x_test': array([[13, 11,  3, ...,  0,  0,  0],
       [13, 17,  4, ...,  0,  0,  0],
       [13,  1, 11, ...,  0,  0,  0],
       ...,
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0],
       [15,  8, 19, ...,  8,  8,  9]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.85      0.87       911
         1.0       0.92      0.68      0.78        53
         2.0       0.65      0.80      0.72       180
         3.0       0.00      0.00      0.00        25
         4.0       0.45      0.46      0.46       111
         5.0       0.70      0.66      0.68       491
         6.0       1.00      0.73      0.85        64
         7.0       0.00      0.00      0.00        37
         8.0       0.95      0.76      0.85       205
         9.0       0.88      0.72      0.79        71
        10.0       0.95      0.86      0.91       404
        11.0       1.00      0.24      0.38        17
        12.0       0.90      0.72      0.80       378
        13.0       0.86      0.76      0.81       191
        14.0       0.79      0.20      0.32        76
        15.0       0.86      0.65      0.74        66
        16.0       0.72      0.76      0.74       140
        17.0       0.91      0.65      0.76       182
        18.0       1.00      0.92      0.96        12
        19.0       1.00      0.65      0.79        37
        20.0       0.96      0.89      0.92      2162
        21.0       0.97      0.88      0.92       168
        22.0       0.93      0.72      0.81      1470
        23.0       0.74      0.90      0.81      1259
        24.0       0.80      0.87      0.84       955
        25.0       0.92      0.90      0.91       283
        26.0       0.73      0.95      0.83      3919
        27.0       0.91      0.91      0.91       532
        28.0       1.00      0.77      0.87        13
        29.0       0.74      0.79      0.77      2345
        30.0       0.67      0.63      0.65       616
        31.0       1.00      0.81      0.90        32
        32.0       0.84      0.67      0.75      1449
        33.0       0.87      0.71      0.78       893
        34.0       0.95      0.86      0.90      1377
        35.0       0.76      0.59      0.67        22
        36.0       0.82      0.83      0.83       844
        37.0       0.97      0.83      0.89      1142
        38.0       0.95      0.83      0.89       314
        39.0       0.90      0.50      0.64        56
        40.0       1.00      0.55      0.71       153
        41.0       0.89      0.77      0.82        52
        42.0       0.99      0.74      0.84       247
        43.0       0.94      0.75      0.84       197
        44.0       0.95      0.84      0.89       529
        45.0       0.95      0.89      0.92       540
        46.0       1.00      0.05      0.10        20
        47.0       0.68      0.69      0.68        80
        48.0       0.98      0.97      0.97      1466
        49.0       0.98      0.87      0.92       148
        50.0       0.69      0.95      0.80      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.98      0.83      0.90       151
        53.0       0.96      0.95      0.95       904
        54.0       0.92      0.64      0.75       108
        55.0       0.79      0.98      0.88        93
        56.0       0.91      0.88      0.89        33
        57.0       0.91      0.86      0.89        50
        58.0       0.86      0.86      0.86       154

    accuracy                           0.83     29892
   macro avg       0.83      0.71      0.75     29892
weighted avg       0.85      0.83      0.83     29892


===confusion_matrix===

[[773   0   2 ...   0   0   0]
 [  0  36   1 ...   0   0   0]
 [  0   0 144 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   0]
 [  0   0   0 ...   0  43   4]
 [  0   0   0 ...   1   3 133]]

===multilabel confusion matrix===

[[[28890    91]
  [  138   773]]

 [[29836     3]
  [   17    36]]

 [[29634    78]
  [   36   144]]

 [[29864     3]
  [   25     0]]

 [[29719    62]
  [   60    51]]

 [[29260   141]
  [  166   325]]

 [[29828     0]
  [   17    47]]

 [[29855     0]
  [   37     0]]

 [[29679     8]
  [   49   156]]

 [[29814     7]
  [   20    51]]

 [[29471    17]
  [   56   348]]

 [[29875     0]
  [   13     4]]

 [[29483    31]
  [  104   274]]

 [[29677    24]
  [   45   146]]

 [[29812     4]
  [   61    15]]

 [[29819     7]
  [   23    43]]

 [[29711    41]
  [   34   106]]

 [[29698    12]
  [   63   119]]

 [[29880     0]
  [    1    11]]

 [[29855     0]
  [   13    24]]

 [[27660    70]
  [  247  1915]]

 [[29720     4]
  [   21   147]]

 [[28340    82]
  [  417  1053]]

 [[28227   406]
  [  129  1130]]

 [[28729   208]
  [  121   834]]

 [[29586    23]
  [   27   256]]

 [[24624  1349]
  [  204  3715]]

 [[29312    48]
  [   49   483]]

 [[29879     0]
  [    3    10]]

 [[26897   650]
  [  482  1863]]

 [[29087   189]
  [  226   390]]

 [[29860     0]
  [    6    26]]

 [[28260   183]
  [  472   977]]

 [[28903    96]
  [  263   630]]

 [[28450    65]
  [  195  1182]]

 [[29866     4]
  [    9    13]]

 [[28895   153]
  [  142   702]]

 [[28717    33]
  [  194   948]]

 [[29563    15]
  [   52   262]]

 [[29833     3]
  [   28    28]]

 [[29739     0]
  [   69    84]]

 [[29835     5]
  [   12    40]]

 [[29643     2]
  [   65   182]]

 [[29686     9]
  [   49   148]]

 [[29341    22]
  [   84   445]]

 [[29325    27]
  [   59   481]]

 [[29872     0]
  [   19     1]]

 [[29786    26]
  [   25    55]]

 [[28391    35]
  [   51  1415]]

 [[29742     2]
  [   19   129]]

 [[27830   609]
  [   69  1384]]

 [[29880     0]
  [   12     0]]

 [[29739     2]
  [   26   125]]

 [[28950    38]
  [   48   856]]

 [[29778     6]
  [   39    69]]

 [[29775    24]
  [    2    91]]

 [[29856     3]
  [    4    29]]

 [[29838     4]
  [    7    43]]

 [[29717    21]
  [   21   133]]]

===scores report===
metrics	scores
Accuracy	0.8346
MCC	0.8259
log_loss	0.6963
f1 score weighted	0.8332
f1 score macro	0.7506
f1 score micro	0.8346
roc_auc ovr	0.9895
roc_auc ovo	0.9855
precision	0.8469
recall	0.8346

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8253044292787368	0.8168767660694098	0.7484667217020963	0.8262863296424007	0.7483123228984089	0.8253044292787367	0.9882475682341202	0.9845849404362714	0.8441564616505373	0.8253044292787368
1	0.8166399036531513	0.8076744214234305	0.7782762707517938	0.8182256022967092	0.7318843985717964	0.8166399036531513	0.9877947340561577	0.9851855676353453	0.8402003006772621	0.8166399036531513
2	0.8076742941255185	0.7985863818417791	0.8148500548406497	0.8064368259928757	0.7321723834740093	0.8076742941255184	0.9873180638625405	0.9833592720709017	0.8362302950454776	0.8076742941255185
3	0.8400240867121638	0.8314655294186694	0.6569899970730835	0.8390725133704029	0.7542305972117418	0.8400240867121638	0.9895929391773411	0.986944501446287	0.846689503544429	0.8400240867121638
4	0.8345711227084169	0.8259238631044977	0.6962598981579544	0.8331873547593479	0.7505951826356522	0.8345711227084169	0.9894984389895072	0.98554636921755	0.8468755000910033	0.8345711227084169
mean	0.8248427672955975	0.8161053923715572	0.7389685885051156	0.8246417252123474	0.7434389769583216	0.8248427672955974	0.9884903488639333	0.985124130161271	0.8428304122017417	0.8248427672955975
std	0.011724930131825176	0.01192416199229152	0.056458528205070926	0.01145918970790076	0.00950646367976185	0.011724930131825207	0.0009109363995362148	0.0011748414052854886	0.004086386234102625	0.011724930131825176

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 87306.2057 secs

