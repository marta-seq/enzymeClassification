/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_emb_20_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe90c592820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe90c592670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe90c592850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe90c592580>, 'x_test': array([[13,  2,  3, ...,  0,  0,  0],
       [13, 13,  2, ...,  0,  0,  0],
       [13,  7,  1, ...,  0,  0,  0],
       ...,
       [13,  4, 11, ...,  0,  0,  0],
       [13,  1, 20, ...,  0,  0,  0],
       [13,  6, 12, ...,  0,  0,  0]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.90      0.85       911
         1.0       0.97      0.60      0.74        53
         2.0       0.75      0.73      0.74       179
         3.0       0.00      0.00      0.00        25
         4.0       0.64      0.40      0.49       112
         5.0       0.68      0.64      0.66       491
         6.0       0.91      0.80      0.85        64
         7.0       0.83      0.14      0.23        37
         8.0       0.87      0.78      0.82       206
         9.0       0.89      0.72      0.80        71
        10.0       0.87      0.86      0.87       404
        11.0       1.00      0.25      0.40        16
        12.0       0.73      0.70      0.71       378
        13.0       0.84      0.71      0.77       191
        14.0       0.40      0.03      0.05        76
        15.0       0.78      0.65      0.71        66
        16.0       0.85      0.74      0.79       141
        17.0       0.79      0.59      0.68       182
        18.0       1.00      0.67      0.80        12
        19.0       0.97      0.79      0.87        38
        20.0       0.92      0.91      0.91      2162
        21.0       0.97      0.92      0.94       168
        22.0       0.77      0.78      0.77      1470
        23.0       0.89      0.84      0.86      1259
        24.0       0.89      0.84      0.86       956
        25.0       0.89      0.87      0.88       283
        26.0       0.87      0.90      0.88      3919
        27.0       0.93      0.89      0.91       531
        28.0       1.00      0.67      0.80        12
        29.0       0.68      0.80      0.73      2345
        30.0       0.67      0.65      0.66       615
        31.0       0.91      0.66      0.76        32
        32.0       0.72      0.77      0.74      1449
        33.0       0.66      0.79      0.72       893
        34.0       0.91      0.83      0.87      1377
        35.0       1.00      0.05      0.09        22
        36.0       0.81      0.81      0.81       844
        37.0       0.85      0.87      0.86      1142
        38.0       0.93      0.81      0.87       314
        39.0       0.69      0.45      0.54        56
        40.0       0.92      0.74      0.82       154
        41.0       0.98      0.85      0.91        52
        42.0       0.83      0.71      0.77       247
        43.0       0.85      0.80      0.83       198
        44.0       0.86      0.88      0.87       529
        45.0       0.93      0.83      0.88       540
        46.0       1.00      0.05      0.10        20
        47.0       0.74      0.60      0.66        80
        48.0       0.96      0.96      0.96      1466
        49.0       0.94      0.86      0.90       148
        50.0       0.91      0.94      0.92      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.92      0.89      0.90       151
        53.0       0.94      0.95      0.94       903
        54.0       0.90      0.65      0.75       108
        55.0       0.85      0.90      0.88        93
        56.0       1.00      0.88      0.94        33
        57.0       0.91      0.84      0.87        49
        58.0       0.80      0.86      0.83       154

    accuracy                           0.83     29892
   macro avg       0.83      0.69      0.73     29892
weighted avg       0.84      0.83      0.83     29892


===confusion_matrix===

[[820   0   0 ...   0   0   0]
 [  0  32   0 ...   0   0   0]
 [  0   0 131 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   1]
 [  0   0   0 ...   0  41   5]
 [  0   0   0 ...   0   4 133]]

===multilabel confusion matrix===

[[[28793   188]
  [   91   820]]

 [[29838     1]
  [   21    32]]

 [[29670    43]
  [   48   131]]

 [[29867     0]
  [   25     0]]

 [[29755    25]
  [   67    45]]

 [[29254   147]
  [  176   315]]

 [[29823     5]
  [   13    51]]

 [[29854     1]
  [   32     5]]

 [[29663    23]
  [   46   160]]

 [[29815     6]
  [   20    51]]

 [[29436    52]
  [   56   348]]

 [[29876     0]
  [   12     4]]

 [[29415    99]
  [  114   264]]

 [[29675    26]
  [   55   136]]

 [[29813     3]
  [   74     2]]

 [[29814    12]
  [   23    43]]

 [[29733    18]
  [   37   104]]

 [[29682    28]
  [   75   107]]

 [[29880     0]
  [    4     8]]

 [[29853     1]
  [    8    30]]

 [[27553   177]
  [  200  1962]]

 [[29720     4]
  [   14   154]]

 [[28070   352]
  [  320  1150]]

 [[28498   135]
  [  204  1055]]

 [[28832   104]
  [  151   805]]

 [[29578    31]
  [   36   247]]

 [[25425   548]
  [  401  3518]]

 [[29325    36]
  [   61   470]]

 [[29880     0]
  [    4     8]]

 [[26673   874]
  [  476  1869]]

 [[29081   196]
  [  217   398]]

 [[29858     2]
  [   11    21]]

 [[28003   440]
  [  335  1114]]

 [[28627   372]
  [  184   709]]

 [[28400   115]
  [  239  1138]]

 [[29870     0]
  [   21     1]]

 [[28882   166]
  [  157   687]]

 [[28575   175]
  [  153   989]]

 [[29559    19]
  [   60   254]]

 [[29825    11]
  [   31    25]]

 [[29728    10]
  [   40   114]]

 [[29839     1]
  [    8    44]]

 [[29609    36]
  [   71   176]]

 [[29667    27]
  [   40   158]]

 [[29289    74]
  [   66   463]]

 [[29317    35]
  [   92   448]]

 [[29872     0]
  [   19     1]]

 [[29795    17]
  [   32    48]]

 [[28363    63]
  [   65  1401]]

 [[29736     8]
  [   20   128]]

 [[28302   137]
  [   88  1365]]

 [[29880     0]
  [   12     0]]

 [[29729    12]
  [   17   134]]

 [[28936    53]
  [   47   856]]

 [[29776     8]
  [   38    70]]

 [[29784    15]
  [    9    84]]

 [[29859     0]
  [    4    29]]

 [[29839     4]
  [    8    41]]

 [[29704    34]
  [   21   133]]]

===scores report===
metrics	scores
Accuracy	0.8338
MCC	0.8247
log_loss	0.7381
f1 score weighted	0.8318
f1 score macro	0.7293
f1 score micro	0.8338
roc_auc ovr	0.9876
roc_auc ovo	0.9832
precision	0.8362
recall	0.8338

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe90c592820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe90c592670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe90c592850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe90c592580>, 'x_test': array([[13, 12,  3, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [20, 20, 20, ...,  1,  7,  1],
       [13, 16, 11, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.89      0.80       912
         1.0       0.97      0.72      0.83        53
         2.0       0.77      0.74      0.75       179
         3.0       0.67      0.32      0.43        25
         4.0       0.78      0.41      0.54       112
         5.0       0.83      0.62      0.71       492
         6.0       0.60      0.75      0.67        65
         7.0       0.50      0.03      0.05        38
         8.0       0.86      0.82      0.84       206
         9.0       0.83      0.69      0.75        71
        10.0       0.92      0.81      0.86       405
        11.0       0.80      0.47      0.59        17
        12.0       0.78      0.69      0.73       377
        13.0       0.95      0.64      0.77       191
        14.0       0.26      0.14      0.18        76
        15.0       0.63      0.67      0.65        66
        16.0       0.85      0.71      0.77       140
        17.0       0.63      0.81      0.71       182
        18.0       1.00      1.00      1.00        11
        19.0       1.00      0.68      0.81        37
        20.0       0.92      0.90      0.91      2163
        21.0       0.94      0.91      0.93       169
        22.0       0.78      0.78      0.78      1469
        23.0       0.73      0.89      0.80      1259
        24.0       0.84      0.85      0.85       956
        25.0       1.00      0.72      0.84       282
        26.0       0.85      0.88      0.86      3919
        27.0       0.99      0.86      0.92       531
        28.0       1.00      0.75      0.86        12
        29.0       0.69      0.78      0.73      2346
        30.0       0.56      0.69      0.62       615
        31.0       0.92      0.75      0.83        32
        32.0       0.63      0.78      0.70      1450
        33.0       0.81      0.74      0.77       893
        34.0       0.87      0.85      0.86      1376
        35.0       1.00      0.27      0.43        22
        36.0       0.89      0.68      0.77       843
        37.0       0.82      0.82      0.82      1142
        38.0       0.99      0.78      0.87       314
        39.0       0.94      0.52      0.67        56
        40.0       0.94      0.69      0.79       154
        41.0       0.98      0.88      0.93        52
        42.0       0.73      0.78      0.75       247
        43.0       0.98      0.70      0.82       198
        44.0       0.91      0.81      0.86       529
        45.0       0.91      0.89      0.90       539
        46.0       0.86      0.32      0.46        19
        47.0       0.97      0.41      0.58        80
        48.0       0.98      0.92      0.95      1466
        49.0       0.93      0.80      0.86       148
        50.0       0.94      0.93      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.98      0.78      0.87       151
        53.0       0.90      0.95      0.92       903
        54.0       0.88      0.76      0.82       108
        55.0       1.00      0.45      0.62        93
        56.0       0.95      0.61      0.74        33
        57.0       0.78      0.86      0.82        49
        58.0       0.66      0.93      0.77       154

    accuracy                           0.82     29892
   macro avg       0.83      0.70      0.74     29892
weighted avg       0.83      0.82      0.82     29892


===confusion_matrix===

[[814   0   0 ...   0   0   0]
 [  0  38   0 ...   0   0   0]
 [  0   0 132 ...   0   0   0]
 ...
 [  0   0   0 ...  20   7   5]
 [  0   0   0 ...   0  42   5]
 [  0   0   0 ...   0   2 143]]

===multilabel confusion matrix===

[[[28679   301]
  [   98   814]]

 [[29838     1]
  [   15    38]]

 [[29673    40]
  [   47   132]]

 [[29863     4]
  [   17     8]]

 [[29767    13]
  [   66    46]]

 [[29339    61]
  [  189   303]]

 [[29795    32]
  [   16    49]]

 [[29853     1]
  [   37     1]]

 [[29658    28]
  [   38   168]]

 [[29811    10]
  [   22    49]]

 [[29458    29]
  [   78   327]]

 [[29873     2]
  [    9     8]]

 [[29444    71]
  [  118   259]]

 [[29695     6]
  [   68   123]]

 [[29784    32]
  [   65    11]]

 [[29800    26]
  [   22    44]]

 [[29735    17]
  [   41    99]]

 [[29622    88]
  [   34   148]]

 [[29881     0]
  [    0    11]]

 [[29855     0]
  [   12    25]]

 [[27563   166]
  [  224  1939]]

 [[29714     9]
  [   15   154]]

 [[28099   324]
  [  323  1146]]

 [[28211   422]
  [  139  1120]]

 [[28781   155]
  [  141   815]]

 [[29609     1]
  [   79   203]]

 [[25370   603]
  [  474  3445]]

 [[29357     4]
  [   74   457]]

 [[29880     0]
  [    3     9]]

 [[26719   827]
  [  524  1822]]

 [[28946   331]
  [  189   426]]

 [[29858     2]
  [    8    24]]

 [[27792   650]
  [  323  1127]]

 [[28841   158]
  [  233   660]]

 [[28343   173]
  [  201  1175]]

 [[29870     0]
  [   16     6]]

 [[28979    70]
  [  267   576]]

 [[28549   201]
  [  208   934]]

 [[29575     3]
  [   70   244]]

 [[29834     2]
  [   27    29]]

 [[29731     7]
  [   48   106]]

 [[29839     1]
  [    6    46]]

 [[29573    72]
  [   54   193]]

 [[29691     3]
  [   59   139]]

 [[29322    41]
  [  101   428]]

 [[29306    47]
  [   59   480]]

 [[29872     1]
  [   13     6]]

 [[29811     1]
  [   47    33]]

 [[28396    30]
  [  118  1348]]

 [[29735     9]
  [   29   119]]

 [[28346    93]
  [  108  1345]]

 [[29880     0]
  [   12     0]]

 [[29738     3]
  [   33   118]]

 [[28889   100]
  [   44   859]]

 [[29773    11]
  [   26    82]]

 [[29799     0]
  [   51    42]]

 [[29858     1]
  [   13    20]]

 [[29831    12]
  [    7    42]]

 [[29664    74]
  [   11   143]]]

===scores report===
metrics	scores
Accuracy	0.8204
MCC	0.8107
log_loss	0.7526
f1 score weighted	0.8202
f1 score macro	0.7397
f1 score micro	0.8204
roc_auc ovr	0.9867
roc_auc ovo	0.9835
precision	0.8305
recall	0.8204

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe90c592820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe90c592670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe90c592850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe90c592580>, 'x_test': array([[13, 16,  8, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       [13, 19,  3, ...,  0,  0,  0],
       ...,
       [13,  1, 17, ...,  0,  0,  0],
       [ 9,  5,  1, ...,  8, 11, 15],
       [20,  6, 15, ...,  4,  2,  3]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.82      0.87       912
         1.0       0.91      0.83      0.87        52
         2.0       0.86      0.66      0.74       179
         3.0       0.71      0.20      0.31        25
         4.0       0.42      0.46      0.44       112
         5.0       0.66      0.72      0.69       492
         6.0       0.93      0.78      0.85        65
         7.0       0.78      0.18      0.30        38
         8.0       0.99      0.72      0.83       205
         9.0       0.83      0.68      0.74        71
        10.0       0.94      0.84      0.89       405
        11.0       1.00      0.29      0.45        17
        12.0       0.87      0.62      0.73       377
        13.0       0.97      0.71      0.82       190
        14.0       1.00      0.08      0.15        76
        15.0       0.44      0.72      0.54        67
        16.0       0.71      0.83      0.76       140
        17.0       0.85      0.68      0.76       183
        18.0       0.90      0.75      0.82        12
        19.0       1.00      0.73      0.84        37
        20.0       0.90      0.89      0.89      2162
        21.0       0.95      0.86      0.90       169
        22.0       0.67      0.81      0.73      1470
        23.0       0.70      0.88      0.78      1259
        24.0       0.87      0.87      0.87       956
        25.0       0.62      0.92      0.74       282
        26.0       0.94      0.80      0.87      3918
        27.0       0.89      0.91      0.90       531
        28.0       1.00      0.77      0.87        13
        29.0       0.55      0.87      0.67      2346
        30.0       0.75      0.59      0.66       615
        31.0       0.95      0.66      0.78        32
        32.0       0.87      0.65      0.74      1450
        33.0       0.84      0.71      0.77       893
        34.0       0.93      0.81      0.87      1376
        35.0       0.91      0.45      0.61        22
        36.0       0.69      0.84      0.75       843
        37.0       0.90      0.83      0.86      1142
        38.0       0.95      0.84      0.90       314
        39.0       0.60      0.38      0.47        55
        40.0       0.95      0.66      0.78       154
        41.0       0.75      0.85      0.79        52
        42.0       0.78      0.74      0.76       247
        43.0       0.97      0.75      0.84       197
        44.0       0.91      0.87      0.89       530
        45.0       0.79      0.91      0.84       540
        46.0       0.00      0.00      0.00        19
        47.0       0.87      0.51      0.64        79
        48.0       0.97      0.96      0.96      1465
        49.0       0.92      0.83      0.87       149
        50.0       0.96      0.91      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.97      0.88      0.92       152
        53.0       0.95      0.94      0.94       903
        54.0       0.91      0.69      0.79       108
        55.0       0.98      0.85      0.91        93
        56.0       0.97      0.97      0.97        32
        57.0       0.88      0.92      0.90        50
        58.0       0.82      0.93      0.87       154

    accuracy                           0.82     29892
   macro avg       0.82      0.71      0.74     29892
weighted avg       0.84      0.82      0.82     29892


===confusion_matrix===

[[751   0   1 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  0   0 118 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  46   4]
 [  0   0   0 ...   0   6 143]]

===multilabel confusion matrix===

[[[28911    69]
  [  161   751]]

 [[29836     4]
  [    9    43]]

 [[29693    20]
  [   61   118]]

 [[29865     2]
  [   20     5]]

 [[29708    72]
  [   60    52]]

 [[29222   178]
  [  140   352]]

 [[29823     4]
  [   14    51]]

 [[29852     2]
  [   31     7]]

 [[29686     1]
  [   58   147]]

 [[29811    10]
  [   23    48]]

 [[29466    21]
  [   66   339]]

 [[29875     0]
  [   12     5]]

 [[29479    36]
  [  142   235]]

 [[29698     4]
  [   56   134]]

 [[29816     0]
  [   70     6]]

 [[29763    62]
  [   19    48]]

 [[29704    48]
  [   24   116]]

 [[29687    22]
  [   58   125]]

 [[29879     1]
  [    3     9]]

 [[29855     0]
  [   10    27]]

 [[27509   221]
  [  239  1923]]

 [[29715     8]
  [   24   145]]

 [[27850   572]
  [  286  1184]]

 [[28158   475]
  [  150  1109]]

 [[28811   125]
  [  127   829]]

 [[29451   159]
  [   22   260]]

 [[25790   184]
  [  767  3151]]

 [[29301    60]
  [   49   482]]

 [[29879     0]
  [    3    10]]

 [[25859  1687]
  [  296  2050]]

 [[29156   121]
  [  255   360]]

 [[29859     1]
  [   11    21]]

 [[28298   144]
  [  514   936]]

 [[28877   122]
  [  262   631]]

 [[28429    87]
  [  256  1120]]

 [[29869     1]
  [   12    10]]

 [[28729   320]
  [  138   705]]

 [[28642   108]
  [  193   949]]

 [[29565    13]
  [   49   265]]

 [[29823    14]
  [   34    21]]

 [[29733     5]
  [   52   102]]

 [[29825    15]
  [    8    44]]

 [[29592    53]
  [   63   184]]

 [[29690     5]
  [   50   147]]

 [[29318    44]
  [   70   460]]

 [[29223   129]
  [   51   489]]

 [[29873     0]
  [   19     0]]

 [[29807     6]
  [   39    40]]

 [[28380    47]
  [   59  1406]]

 [[29733    10]
  [   26   123]]

 [[28377    62]
  [  136  1317]]

 [[29880     0]
  [   12     0]]

 [[29736     4]
  [   19   133]]

 [[28945    44]
  [   58   845]]

 [[29777     7]
  [   33    75]]

 [[29797     2]
  [   14    79]]

 [[29859     1]
  [    1    31]]

 [[29836     6]
  [    4    46]]

 [[29707    31]
  [   11   143]]]

===scores report===
metrics	scores
Accuracy	0.8177
MCC	0.8092
log_loss	0.7555
f1 score weighted	0.8204
f1 score macro	0.7398
f1 score micro	0.8177
roc_auc ovr	0.9878
roc_auc ovo	0.9846
precision	0.8419
recall	0.8177

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe90c592820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe90c592670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe90c592850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe90c592580>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       [13, 12, 12, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [20,  2,  1, ...,  7,  6,  6],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.85      0.83       912
         1.0       0.93      0.73      0.82        52
         2.0       0.94      0.57      0.71       179
         3.0       1.00      0.17      0.29        24
         4.0       0.94      0.28      0.43       112
         5.0       0.85      0.54      0.66       492
         6.0       0.90      0.70      0.79        64
         7.0       0.00      0.00      0.00        38
         8.0       0.62      0.83      0.71       205
         9.0       0.66      0.70      0.68        70
        10.0       0.67      0.89      0.77       405
        11.0       0.86      0.35      0.50        17
        12.0       0.75      0.73      0.74       378
        13.0       0.78      0.72      0.75       191
        14.0       0.21      0.07      0.10        76
        15.0       0.70      0.58      0.63        67
        16.0       0.78      0.75      0.77       140
        17.0       0.84      0.64      0.73       183
        18.0       1.00      0.92      0.96        12
        19.0       1.00      0.92      0.96        37
        20.0       0.94      0.89      0.92      2162
        21.0       0.92      0.90      0.91       168
        22.0       0.77      0.80      0.79      1470
        23.0       0.78      0.85      0.81      1259
        24.0       0.89      0.84      0.87       955
        25.0       0.92      0.91      0.92       282
        26.0       0.74      0.92      0.82      3918
        27.0       0.80      0.89      0.84       532
        28.0       1.00      0.77      0.87        13
        29.0       0.76      0.73      0.74      2346
        30.0       0.59      0.63      0.61       616
        31.0       0.96      0.75      0.84        32
        32.0       0.72      0.75      0.73      1449
        33.0       0.81      0.72      0.76       893
        34.0       0.85      0.88      0.86      1377
        35.0       0.78      0.32      0.45        22
        36.0       0.88      0.78      0.82       844
        37.0       0.86      0.83      0.84      1142
        38.0       0.90      0.85      0.87       314
        39.0       0.90      0.48      0.63        56
        40.0       0.97      0.67      0.80       153
        41.0       0.97      0.69      0.80        51
        42.0       0.88      0.66      0.75       246
        43.0       0.97      0.73      0.83       197
        44.0       0.89      0.86      0.87       530
        45.0       0.97      0.81      0.88       540
        46.0       1.00      0.05      0.10        20
        47.0       0.63      0.59      0.61        80
        48.0       0.97      0.92      0.94      1465
        49.0       0.92      0.83      0.87       148
        50.0       0.92      0.92      0.92      1453
        51.0       0.00      0.00      0.00        13
        52.0       0.86      0.82      0.84       151
        53.0       0.97      0.91      0.94       904
        54.0       0.92      0.75      0.83       108
        55.0       0.96      0.81      0.88        93
        56.0       0.94      0.91      0.92        33
        57.0       0.82      1.00      0.90        50
        58.0       0.77      0.91      0.83       153

    accuracy                           0.82     29892
   macro avg       0.82      0.70      0.73     29892
weighted avg       0.83      0.82      0.82     29892


===confusion_matrix===

[[776   0   0 ...   0   0   0]
 [  0  38   0 ...   0   0   0]
 [  2   0 102 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   2]
 [  0   0   0 ...   0  50   0]
 [  0   0   0 ...   1   5 139]]

===multilabel confusion matrix===

[[[28792   188]
  [  136   776]]

 [[29837     3]
  [   14    38]]

 [[29706     7]
  [   77   102]]

 [[29868     0]
  [   20     4]]

 [[29778     2]
  [   81    31]]

 [[29355    45]
  [  227   265]]

 [[29823     5]
  [   19    45]]

 [[29854     0]
  [   38     0]]

 [[29585   102]
  [   35   170]]

 [[29797    25]
  [   21    49]]

 [[29313   174]
  [   45   360]]

 [[29874     1]
  [   11     6]]

 [[29424    90]
  [  102   276]]

 [[29662    39]
  [   53   138]]

 [[29797    19]
  [   71     5]]

 [[29808    17]
  [   28    39]]

 [[29723    29]
  [   35   105]]

 [[29687    22]
  [   66   117]]

 [[29880     0]
  [    1    11]]

 [[29855     0]
  [    3    34]]

 [[27607   123]
  [  230  1932]]

 [[29711    13]
  [   16   152]]

 [[28073   349]
  [  287  1183]]

 [[28332   301]
  [  187  1072]]

 [[28840    97]
  [  149   806]]

 [[29587    23]
  [   24   258]]

 [[24714  1260]
  [  325  3593]]

 [[29239   121]
  [   56   476]]

 [[29879     0]
  [    3    10]]

 [[26989   557]
  [  627  1719]]

 [[29011   265]
  [  227   389]]

 [[29859     1]
  [    8    24]]

 [[28017   426]
  [  366  1083]]

 [[28844   155]
  [  247   646]]

 [[28296   219]
  [  163  1214]]

 [[29868     2]
  [   15     7]]

 [[28956    92]
  [  189   655]]

 [[28600   150]
  [  198   944]]

 [[29549    29]
  [   48   266]]

 [[29833     3]
  [   29    27]]

 [[29736     3]
  [   50   103]]

 [[29840     1]
  [   16    35]]

 [[29623    23]
  [   84   162]]

 [[29691     4]
  [   53   144]]

 [[29304    58]
  [   75   455]]

 [[29338    14]
  [  105   435]]

 [[29872     0]
  [   19     1]]

 [[29784    28]
  [   33    47]]

 [[28386    41]
  [  123  1342]]

 [[29733    11]
  [   25   123]]

 [[28318   121]
  [  122  1331]]

 [[29878     1]
  [   13     0]]

 [[29720    21]
  [   27   124]]

 [[28965    23]
  [   84   820]]

 [[29777     7]
  [   27    81]]

 [[29796     3]
  [   18    75]]

 [[29857     2]
  [    3    30]]

 [[29831    11]
  [    0    50]]

 [[29697    42]
  [   14   139]]]

===scores report===
metrics	scores
Accuracy	0.8204
MCC	0.8106
log_loss	0.7561
f1 score weighted	0.8181
f1 score macro	0.7330
f1 score micro	0.8204
roc_auc ovr	0.9870
roc_auc ovo	0.9846
precision	0.8263
recall	0.8204

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe90c592820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe90c592670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe90c592850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe90c592580>, 'x_test': array([[13, 11,  3, ...,  0,  0,  0],
       [13, 17,  4, ...,  0,  0,  0],
       [13,  1, 11, ...,  0,  0,  0],
       ...,
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0],
       [15,  8, 19, ...,  8,  8,  9]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.88      0.87       911
         1.0       0.82      0.62      0.71        53
         2.0       0.90      0.71      0.80       180
         3.0       0.88      0.28      0.42        25
         4.0       0.72      0.50      0.59       111
         5.0       0.75      0.67      0.71       491
         6.0       0.96      0.81      0.88        64
         7.0       0.73      0.22      0.33        37
         8.0       0.89      0.82      0.85       205
         9.0       0.98      0.69      0.81        71
        10.0       0.86      0.90      0.88       404
        11.0       0.60      0.35      0.44        17
        12.0       0.86      0.72      0.78       378
        13.0       0.88      0.72      0.79       191
        14.0       0.17      0.01      0.02        76
        15.0       0.65      0.62      0.64        66
        16.0       0.83      0.74      0.78       140
        17.0       0.86      0.67      0.75       182
        18.0       1.00      1.00      1.00        12
        19.0       0.96      0.62      0.75        37
        20.0       0.93      0.91      0.92      2162
        21.0       0.97      0.89      0.93       168
        22.0       0.83      0.78      0.81      1470
        23.0       0.84      0.87      0.85      1259
        24.0       0.94      0.84      0.88       955
        25.0       0.90      0.91      0.90       283
        26.0       0.92      0.85      0.89      3919
        27.0       0.96      0.90      0.93       532
        28.0       1.00      0.92      0.96        13
        29.0       0.61      0.87      0.72      2345
        30.0       0.60      0.70      0.64       616
        31.0       0.89      0.78      0.83        32
        32.0       0.75      0.75      0.75      1449
        33.0       0.76      0.79      0.78       893
        34.0       0.93      0.85      0.89      1377
        35.0       0.88      0.64      0.74        22
        36.0       0.75      0.86      0.80       844
        37.0       0.87      0.87      0.87      1142
        38.0       0.88      0.87      0.87       314
        39.0       0.82      0.48      0.61        56
        40.0       0.95      0.69      0.80       153
        41.0       0.95      0.81      0.88        52
        42.0       0.72      0.78      0.75       247
        43.0       0.84      0.80      0.82       197
        44.0       0.87      0.87      0.87       529
        45.0       0.90      0.89      0.90       540
        46.0       0.00      0.00      0.00        20
        47.0       0.71      0.56      0.63        80
        48.0       0.96      0.97      0.97      1466
        49.0       0.89      0.88      0.88       148
        50.0       0.96      0.92      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.97      0.77      0.86       151
        53.0       0.94      0.95      0.95       904
        54.0       0.87      0.80      0.83       108
        55.0       0.89      0.99      0.94        93
        56.0       0.91      0.88      0.89        33
        57.0       0.82      0.90      0.86        50
        58.0       0.92      0.91      0.91       154

    accuracy                           0.84     29892
   macro avg       0.82      0.73      0.76     29892
weighted avg       0.85      0.84      0.84     29892


===confusion_matrix===

[[799   0   0 ...   0   0   0]
 [  0  33   0 ...   0   0   0]
 [  1   0 128 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   0]
 [  0   0   0 ...   0  45   4]
 [  0   0   0 ...   1   4 140]]

===multilabel confusion matrix===

[[[28849   132]
  [  112   799]]

 [[29832     7]
  [   20    33]]

 [[29698    14]
  [   52   128]]

 [[29866     1]
  [   18     7]]

 [[29759    22]
  [   55    56]]

 [[29291   110]
  [  162   329]]

 [[29826     2]
  [   12    52]]

 [[29852     3]
  [   29     8]]

 [[29667    20]
  [   37   168]]

 [[29820     1]
  [   22    49]]

 [[29428    60]
  [   42   362]]

 [[29871     4]
  [   11     6]]

 [[29469    45]
  [  106   272]]

 [[29682    19]
  [   53   138]]

 [[29811     5]
  [   75     1]]

 [[29804    22]
  [   25    41]]

 [[29731    21]
  [   36   104]]

 [[29690    20]
  [   60   122]]

 [[29880     0]
  [    0    12]]

 [[29854     1]
  [   14    23]]

 [[27592   138]
  [  190  1972]]

 [[29719     5]
  [   19   149]]

 [[28194   228]
  [  326  1144]]

 [[28424   209]
  [  166  1093]]

 [[28884    53]
  [  156   799]]

 [[29579    30]
  [   25   258]]

 [[25691   282]
  [  582  3337]]

 [[29339    21]
  [   55   477]]

 [[29879     0]
  [    1    12]]

 [[26226  1321]
  [  302  2043]]

 [[28983   293]
  [  185   431]]

 [[29857     3]
  [    7    25]]

 [[28082   361]
  [  358  1091]]

 [[28782   217]
  [  188   705]]

 [[28422    93]
  [  200  1177]]

 [[29868     2]
  [    8    14]]

 [[28806   242]
  [  117   727]]

 [[28605   145]
  [  148   994]]

 [[29539    39]
  [   40   274]]

 [[29830     6]
  [   29    27]]

 [[29733     6]
  [   47   106]]

 [[29838     2]
  [   10    42]]

 [[29572    73]
  [   55   192]]

 [[29666    29]
  [   40   157]]

 [[29294    69]
  [   71   458]]

 [[29301    51]
  [   57   483]]

 [[29872     0]
  [   20     0]]

 [[29794    18]
  [   35    45]]

 [[28368    58]
  [   39  1427]]

 [[29728    16]
  [   18   130]]

 [[28377    62]
  [  119  1334]]

 [[29880     0]
  [   12     0]]

 [[29738     3]
  [   34   117]]

 [[28935    53]
  [   41   863]]

 [[29771    13]
  [   22    86]]

 [[29788    11]
  [    1    92]]

 [[29856     3]
  [    4    29]]

 [[29832    10]
  [    5    45]]

 [[29725    13]
  [   14   140]]]

===scores report===
metrics	scores
Accuracy	0.8432
MCC	0.8353
log_loss	0.6836
f1 score weighted	0.8438
f1 score macro	0.7638
f1 score micro	0.8432
roc_auc ovr	0.9895
roc_auc ovo	0.9861
precision	0.8522
recall	0.8432

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8337682323029573	0.824703343263041	0.7381415007333141	0.8318081960845177	0.7292678130603116	0.8337682323029573	0.9876148317760288	0.9832006148244574	0.836175660743862	0.8337682323029573
1	0.8203867255452963	0.8106726551097652	0.7525968605173751	0.820240105412193	0.7397440560848543	0.8203867255452963	0.9867179990017502	0.9834878771159	0.8304920932957869	0.8203867255452963
2	0.8177104241937642	0.8091722112652732	0.7555088065467256	0.8203684809667344	0.7397682694560681	0.8177104241937642	0.9877942366261256	0.9845561361266959	0.8419202895721237	0.8177104241937642
3	0.8204201793121906	0.8106289247559454	0.7561372655621112	0.8180543861303018	0.7329596893204475	0.8204201793121905	0.9870273856825883	0.9846372694437828	0.826301970703877	0.8204201793121906
4	0.8432021945671082	0.8352668185460135	0.683577349859442	0.8438256507848652	0.7638282369337235	0.8432021945671082	0.9894773022744023	0.9860502888493212	0.8521710204450785	0.8432021945671082
mean	0.8270975511842632	0.8180887905880077	0.7371923566437937	0.8268593638757225	0.741113612971081	0.8270975511842632	0.987726351072179	0.9843864372720315	0.8374122069521457	0.8270975511842632
std	0.009814256508633063	0.010285825218225839	0.02759409530153108	0.00975519972483094	0.012053623715950267	0.009814256508633077	0.0009579354496206535	0.0010073432168101397	0.00906641884827976	0.009814256508633063

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 59701.5943 secs

