/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_emb8_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c78352820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c78352670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c78352850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c78352580>, 'x_test': array([[13,  2,  3, ...,  0,  0,  0],
       [13, 13,  2, ...,  0,  0,  0],
       [13,  7,  1, ...,  0,  0,  0],
       ...,
       [13,  4, 11, ...,  0,  0,  0],
       [13,  1, 20, ...,  0,  0,  0],
       [13,  6, 12, ...,  0,  0,  0]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.90      0.78       911
         1.0       0.78      0.60      0.68        53
         2.0       0.98      0.48      0.64       179
         3.0       0.00      0.00      0.00        25
         4.0       0.86      0.11      0.19       112
         5.0       0.43      0.68      0.52       491
         6.0       0.98      0.64      0.77        64
         7.0       0.00      0.00      0.00        37
         8.0       0.95      0.67      0.78       206
         9.0       0.72      0.68      0.70        71
        10.0       0.89      0.82      0.85       404
        11.0       1.00      0.19      0.32        16
        12.0       0.74      0.66      0.70       378
        13.0       0.54      0.73      0.62       191
        14.0       0.43      0.04      0.07        76
        15.0       0.92      0.50      0.65        66
        16.0       0.93      0.67      0.78       141
        17.0       0.88      0.54      0.67       182
        18.0       0.69      0.75      0.72        12
        19.0       0.94      0.79      0.86        38
        20.0       0.91      0.87      0.89      2162
        21.0       0.94      0.95      0.94       168
        22.0       0.54      0.78      0.64      1470
        23.0       0.89      0.78      0.83      1259
        24.0       0.96      0.74      0.84       956
        25.0       0.78      0.88      0.83       283
        26.0       0.79      0.89      0.84      3919
        27.0       0.69      0.89      0.78       531
        28.0       1.00      0.58      0.74        12
        29.0       0.75      0.68      0.72      2345
        30.0       0.76      0.54      0.63       615
        31.0       1.00      0.66      0.79        32
        32.0       0.58      0.73      0.65      1449
        33.0       0.74      0.75      0.74       893
        34.0       0.88      0.77      0.82      1377
        35.0       0.86      0.27      0.41        22
        36.0       0.77      0.80      0.78       844
        37.0       0.97      0.77      0.86      1142
        38.0       0.96      0.77      0.85       314
        39.0       0.82      0.50      0.62        56
        40.0       0.98      0.56      0.72       154
        41.0       0.95      0.75      0.84        52
        42.0       0.85      0.66      0.74       247
        43.0       0.92      0.61      0.73       198
        44.0       0.97      0.83      0.90       529
        45.0       0.80      0.84      0.82       540
        46.0       0.00      0.00      0.00        20
        47.0       0.38      0.66      0.49        80
        48.0       0.95      0.96      0.96      1466
        49.0       0.81      0.80      0.81       148
        50.0       0.96      0.88      0.92      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.92      0.87      0.89       151
        53.0       0.98      0.91      0.94       903
        54.0       0.81      0.70      0.75       108
        55.0       0.90      0.90      0.90        93
        56.0       0.86      0.76      0.81        33
        57.0       0.86      0.86      0.86        49
        58.0       0.79      0.92      0.85       154

    accuracy                           0.79     29892
   macro avg       0.77      0.65      0.69     29892
weighted avg       0.81      0.79      0.79     29892


===confusion_matrix===

[[817   0   0 ...   0   0   0]
 [  0  32   0 ...   0   0   0]
 [  1   0  86 ...   0   0   0]
 ...
 [  0   0   0 ...  25   1   1]
 [  0   0   0 ...   0  42   6]
 [  0   0   0 ...   0   3 142]]

===multilabel confusion matrix===

[[[28611   370]
  [   94   817]]

 [[29830     9]
  [   21    32]]

 [[29711     2]
  [   93    86]]

 [[29867     0]
  [   25     0]]

 [[29778     2]
  [  100    12]]

 [[28956   445]
  [  158   333]]

 [[29827     1]
  [   23    41]]

 [[29855     0]
  [   37     0]]

 [[29678     8]
  [   68   138]]

 [[29802    19]
  [   23    48]]

 [[29446    42]
  [   72   332]]

 [[29876     0]
  [   13     3]]

 [[29428    86]
  [  128   250]]

 [[29581   120]
  [   52   139]]

 [[29812     4]
  [   73     3]]

 [[29823     3]
  [   33    33]]

 [[29744     7]
  [   46    95]]

 [[29697    13]
  [   84    98]]

 [[29876     4]
  [    3     9]]

 [[29852     2]
  [    8    30]]

 [[27549   181]
  [  271  1891]]

 [[29713    11]
  [    8   160]]

 [[27437   985]
  [  322  1148]]

 [[28511   122]
  [  278   981]]

 [[28906    30]
  [  247   709]]

 [[29539    70]
  [   34   249]]

 [[25049   924]
  [  437  3482]]

 [[29145   216]
  [   58   473]]

 [[29880     0]
  [    5     7]]

 [[27022   525]
  [  743  1602]]

 [[29171   106]
  [  285   330]]

 [[29860     0]
  [   11    21]]

 [[27668   775]
  [  390  1059]]

 [[28763   236]
  [  226   667]]

 [[28375   140]
  [  313  1064]]

 [[29869     1]
  [   16     6]]

 [[28842   206]
  [  169   675]]

 [[28719    31]
  [  257   885]]

 [[29567    11]
  [   72   242]]

 [[29830     6]
  [   28    28]]

 [[29736     2]
  [   67    87]]

 [[29838     2]
  [   13    39]]

 [[29616    29]
  [   84   163]]

 [[29683    11]
  [   77   121]]

 [[29351    12]
  [   90   439]]

 [[29235   117]
  [   86   454]]

 [[29872     0]
  [   20     0]]

 [[29727    85]
  [   27    53]]

 [[28353    73]
  [   59  1407]]

 [[29717    27]
  [   30   118]]

 [[28387    52]
  [  173  1280]]

 [[29880     0]
  [   12     0]]

 [[29729    12]
  [   19   132]]

 [[28968    21]
  [   82   821]]

 [[29766    18]
  [   32    76]]

 [[29790     9]
  [    9    84]]

 [[29855     4]
  [    8    25]]

 [[29836     7]
  [    7    42]]

 [[29701    37]
  [   12   142]]]

===scores report===
metrics	scores
Accuracy	0.7915
MCC	0.7805
log_loss	0.8437
f1 score weighted	0.7922
f1 score macro	0.6852
f1 score micro	0.7915
roc_auc ovr	0.9829
roc_auc ovo	0.9786
precision	0.8112
recall	0.7915

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c78352820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c78352670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c78352850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c78352580>, 'x_test': array([[13, 12,  3, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [20, 20, 20, ...,  1,  7,  1],
       [13, 16, 11, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.82      0.84       912
         1.0       1.00      0.70      0.82        53
         2.0       0.82      0.60      0.69       179
         3.0       1.00      0.12      0.21        25
         4.0       0.81      0.26      0.39       112
         5.0       0.89      0.58      0.70       492
         6.0       0.98      0.65      0.78        65
         7.0       0.00      0.00      0.00        38
         8.0       0.96      0.78      0.86       206
         9.0       0.97      0.54      0.69        71
        10.0       0.97      0.76      0.85       405
        11.0       1.00      0.18      0.30        17
        12.0       0.94      0.62      0.75       377
        13.0       0.95      0.64      0.76       191
        14.0       1.00      0.03      0.05        76
        15.0       0.79      0.45      0.58        66
        16.0       0.98      0.43      0.60       140
        17.0       0.79      0.67      0.72       182
        18.0       1.00      0.73      0.84        11
        19.0       1.00      0.65      0.79        37
        20.0       0.96      0.87      0.91      2163
        21.0       0.99      0.89      0.93       169
        22.0       0.85      0.73      0.79      1469
        23.0       0.86      0.81      0.83      1259
        24.0       0.93      0.85      0.88       956
        25.0       0.92      0.86      0.89       282
        26.0       0.88      0.86      0.87      3919
        27.0       0.97      0.86      0.91       531
        28.0       1.00      0.25      0.40        12
        29.0       0.47      0.89      0.62      2346
        30.0       0.60      0.71      0.65       615
        31.0       1.00      0.78      0.88        32
        32.0       0.63      0.72      0.67      1450
        33.0       0.63      0.79      0.70       893
        34.0       0.94      0.81      0.87      1376
        35.0       1.00      0.09      0.17        22
        36.0       0.79      0.79      0.79       843
        37.0       0.88      0.82      0.85      1142
        38.0       0.99      0.82      0.90       314
        39.0       0.78      0.45      0.57        56
        40.0       0.82      0.64      0.72       154
        41.0       0.83      0.92      0.87        52
        42.0       0.65      0.82      0.73       247
        43.0       0.96      0.65      0.77       198
        44.0       0.94      0.82      0.87       529
        45.0       0.93      0.87      0.90       539
        46.0       0.00      0.00      0.00        19
        47.0       1.00      0.42      0.60        80
        48.0       0.99      0.91      0.95      1466
        49.0       0.97      0.78      0.87       148
        50.0       0.94      0.90      0.92      1453
        51.0       0.00      0.00      0.00        12
        52.0       1.00      0.66      0.79       151
        53.0       0.90      0.93      0.92       903
        54.0       0.94      0.76      0.84       108
        55.0       0.97      0.94      0.95        93
        56.0       1.00      0.76      0.86        33
        57.0       0.87      0.84      0.85        49
        58.0       0.87      0.92      0.89       154

    accuracy                           0.81     29892
   macro avg       0.85      0.65      0.71     29892
weighted avg       0.84      0.81      0.81     29892


===confusion_matrix===

[[745   0   0 ...   0   0   0]
 [  0  37   0 ...   0   0   0]
 [  0   0 108 ...   0   0   0]
 ...
 [  0   0   0 ...  25   3   1]
 [  0   0   0 ...   0  41   6]
 [  0   0   0 ...   0   2 141]]

===multilabel confusion matrix===

[[[28858   122]
  [  167   745]]

 [[29839     0]
  [   16    37]]

 [[29689    24]
  [   71   108]]

 [[29867     0]
  [   22     3]]

 [[29773     7]
  [   83    29]]

 [[29363    37]
  [  205   287]]

 [[29826     1]
  [   23    42]]

 [[29854     0]
  [   38     0]]

 [[29680     6]
  [   46   160]]

 [[29820     1]
  [   33    38]]

 [[29478     9]
  [   96   309]]

 [[29875     0]
  [   14     3]]

 [[29501    14]
  [  144   233]]

 [[29695     6]
  [   69   122]]

 [[29816     0]
  [   74     2]]

 [[29818     8]
  [   36    30]]

 [[29751     1]
  [   80    60]]

 [[29677    33]
  [   60   122]]

 [[29881     0]
  [    3     8]]

 [[29855     0]
  [   13    24]]

 [[27642    87]
  [  273  1890]]

 [[29721     2]
  [   19   150]]

 [[28226   197]
  [  390  1079]]

 [[28462   171]
  [  237  1022]]

 [[28871    65]
  [  147   809]]

 [[29590    20]
  [   40   242]]

 [[25530   443]
  [  565  3354]]

 [[29348    13]
  [   73   458]]

 [[29880     0]
  [    9     3]]

 [[25225  2321]
  [  267  2079]]

 [[28988   289]
  [  181   434]]

 [[29860     0]
  [    7    25]]

 [[27817   625]
  [  400  1050]]

 [[28586   413]
  [  184   709]]

 [[28449    67]
  [  258  1118]]

 [[29870     0]
  [   20     2]]

 [[28874   175]
  [  178   665]]

 [[28627   123]
  [  208   934]]

 [[29576     2]
  [   56   258]]

 [[29829     7]
  [   31    25]]

 [[29716    22]
  [   56    98]]

 [[29830    10]
  [    4    48]]

 [[29537   108]
  [   45   202]]

 [[29689     5]
  [   70   128]]

 [[29333    30]
  [   96   433]]

 [[29316    37]
  [   69   470]]

 [[29873     0]
  [   19     0]]

 [[29812     0]
  [   46    34]]

 [[28414    12]
  [  136  1330]]

 [[29741     3]
  [   32   116]]

 [[28351    88]
  [  140  1313]]

 [[29880     0]
  [   12     0]]

 [[29741     0]
  [   52    99]]

 [[28894    95]
  [   61   842]]

 [[29779     5]
  [   26    82]]

 [[29796     3]
  [    6    87]]

 [[29859     0]
  [    8    25]]

 [[29837     6]
  [    8    41]]

 [[29716    22]
  [   13   141]]]

===scores report===
metrics	scores
Accuracy	0.8081
MCC	0.7993
log_loss	0.8071
f1 score weighted	0.8132
f1 score macro	0.7055
f1 score micro	0.8081
roc_auc ovr	0.9862
roc_auc ovo	0.9813
precision	0.8435
recall	0.8081

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c78352820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c78352670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c78352850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c78352580>, 'x_test': array([[13, 16,  8, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       [13, 19,  3, ...,  0,  0,  0],
       ...,
       [13,  1, 17, ...,  0,  0,  0],
       [ 9,  5,  1, ...,  8, 11, 15],
       [20,  6, 15, ...,  4,  2,  3]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.87      0.87       912
         1.0       1.00      0.75      0.86        52
         2.0       0.72      0.75      0.74       179
         3.0       0.00      0.00      0.00        25
         4.0       0.78      0.31      0.45       112
         5.0       0.34      0.78      0.47       492
         6.0       1.00      0.55      0.71        65
         7.0       0.20      0.05      0.08        38
         8.0       0.95      0.72      0.82       205
         9.0       0.69      0.76      0.72        71
        10.0       0.98      0.82      0.89       405
        11.0       1.00      0.24      0.38        17
        12.0       0.53      0.79      0.64       377
        13.0       0.92      0.70      0.79       190
        14.0       0.00      0.00      0.00        76
        15.0       0.44      0.61      0.51        67
        16.0       0.82      0.70      0.75       140
        17.0       0.68      0.74      0.71       183
        18.0       1.00      0.75      0.86        12
        19.0       1.00      0.73      0.84        37
        20.0       0.98      0.83      0.90      2162
        21.0       0.97      0.92      0.95       169
        22.0       0.88      0.67      0.76      1470
        23.0       0.56      0.92      0.69      1259
        24.0       0.87      0.85      0.86       956
        25.0       0.96      0.83      0.89       282
        26.0       0.84      0.88      0.86      3918
        27.0       0.84      0.90      0.87       531
        28.0       1.00      0.62      0.76        13
        29.0       0.73      0.77      0.75      2346
        30.0       0.69      0.58      0.63       615
        31.0       1.00      0.69      0.81        32
        32.0       0.77      0.74      0.75      1450
        33.0       0.98      0.51      0.68       893
        34.0       0.83      0.89      0.86      1376
        35.0       0.00      0.00      0.00        22
        36.0       0.79      0.81      0.80       843
        37.0       0.94      0.81      0.87      1142
        38.0       0.89      0.84      0.86       314
        39.0       1.00      0.31      0.47        55
        40.0       1.00      0.61      0.76       154
        41.0       0.91      0.81      0.86        52
        42.0       0.95      0.70      0.81       247
        43.0       0.87      0.84      0.86       197
        44.0       0.70      0.90      0.79       530
        45.0       0.97      0.79      0.87       540
        46.0       0.00      0.00      0.00        19
        47.0       1.00      0.32      0.48        79
        48.0       0.95      0.97      0.96      1465
        49.0       0.96      0.80      0.87       149
        50.0       0.89      0.92      0.91      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.97      0.82      0.89       152
        53.0       0.90      0.94      0.92       903
        54.0       0.77      0.82      0.79       108
        55.0       0.88      0.87      0.88        93
        56.0       0.86      0.97      0.91        32
        57.0       0.97      0.78      0.87        50
        58.0       0.94      0.72      0.82       154

    accuracy                           0.81     29892
   macro avg       0.78      0.67      0.70     29892
weighted avg       0.83      0.81      0.81     29892


===confusion_matrix===

[[792   0   0 ...   0   0   0]
 [  0  39   0 ...   0   0   0]
 [  0   0 135 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  39   2]
 [  0   0   0 ...   3   1 111]]

===multilabel confusion matrix===

[[[28866   114]
  [  120   792]]

 [[29840     0]
  [   13    39]]

 [[29660    53]
  [   44   135]]

 [[29867     0]
  [   25     0]]

 [[29770    10]
  [   77    35]]

 [[28654   746]
  [  110   382]]

 [[29827     0]
  [   29    36]]

 [[29846     8]
  [   36     2]]

 [[29680     7]
  [   58   147]]

 [[29797    24]
  [   17    54]]

 [[29479     8]
  [   72   333]]

 [[29875     0]
  [   13     4]]

 [[29257   258]
  [   81   296]]

 [[29690    12]
  [   57   133]]

 [[29814     2]
  [   76     0]]

 [[29772    53]
  [   26    41]]

 [[29730    22]
  [   42    98]]

 [[29645    64]
  [   48   135]]

 [[29880     0]
  [    3     9]]

 [[29855     0]
  [   10    27]]

 [[27693    37]
  [  360  1802]]

 [[29718     5]
  [   13   156]]

 [[28286   136]
  [  478   992]]

 [[27715   918]
  [  102  1157]]

 [[28817   119]
  [  141   815]]

 [[29599    11]
  [   48   234]]

 [[25319   655]
  [  472  3446]]

 [[29267    94]
  [   53   478]]

 [[29879     0]
  [    5     8]]

 [[26871   675]
  [  548  1798]]

 [[29115   162]
  [  261   354]]

 [[29860     0]
  [   10    22]]

 [[28117   325]
  [  382  1068]]

 [[28991     8]
  [  434   459]]

 [[28274   242]
  [  154  1222]]

 [[29870     0]
  [   22     0]]

 [[28872   177]
  [  164   679]]

 [[28693    57]
  [  212   930]]

 [[29545    33]
  [   50   264]]

 [[29837     0]
  [   38    17]]

 [[29738     0]
  [   60    94]]

 [[29836     4]
  [   10    42]]

 [[29636     9]
  [   73   174]]

 [[29671    24]
  [   31   166]]

 [[29155   207]
  [   53   477]]

 [[29341    11]
  [  112   428]]

 [[29873     0]
  [   19     0]]

 [[29813     0]
  [   54    25]]

 [[28355    72]
  [   37  1428]]

 [[29738     5]
  [   30   119]]

 [[28279   160]
  [  112  1341]]

 [[29880     0]
  [   12     0]]

 [[29736     4]
  [   27   125]]

 [[28899    90]
  [   52   851]]

 [[29757    27]
  [   19    89]]

 [[29788    11]
  [   12    81]]

 [[29855     5]
  [    1    31]]

 [[29841     1]
  [   11    39]]

 [[29731     7]
  [   43   111]]]

===scores report===
metrics	scores
Accuracy	0.8103
MCC	0.8007
log_loss	0.7929
f1 score weighted	0.8118
f1 score macro	0.7011
f1 score micro	0.8103
roc_auc ovr	0.9866
roc_auc ovo	0.9820
precision	0.8340
recall	0.8103

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c78352820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c78352670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c78352850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c78352580>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       [13, 12, 12, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [20,  2,  1, ...,  7,  6,  6],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.84      0.84       912
         1.0       0.96      0.88      0.92        52
         2.0       0.93      0.55      0.69       179
         3.0       0.00      0.00      0.00        24
         4.0       0.79      0.13      0.23       112
         5.0       0.79      0.52      0.63       492
         6.0       0.98      0.72      0.83        64
         7.0       1.00      0.03      0.05        38
         8.0       0.82      0.80      0.81       205
         9.0       0.78      0.71      0.75        70
        10.0       0.80      0.86      0.83       405
        11.0       0.67      0.12      0.20        17
        12.0       0.81      0.70      0.75       378
        13.0       0.97      0.64      0.77       191
        14.0       0.29      0.05      0.09        76
        15.0       0.81      0.45      0.58        67
        16.0       0.98      0.61      0.75       140
        17.0       0.66      0.69      0.67       183
        18.0       1.00      0.75      0.86        12
        19.0       1.00      0.86      0.93        37
        20.0       0.96      0.88      0.92      2162
        21.0       0.93      0.82      0.87       168
        22.0       0.77      0.77      0.77      1470
        23.0       0.85      0.83      0.84      1259
        24.0       0.87      0.84      0.86       955
        25.0       0.92      0.90      0.91       282
        26.0       0.69      0.93      0.79      3918
        27.0       0.96      0.86      0.91       532
        28.0       1.00      0.85      0.92        13
        29.0       0.74      0.75      0.75      2346
        30.0       0.86      0.42      0.57       616
        31.0       1.00      0.69      0.81        32
        32.0       0.59      0.78      0.67      1449
        33.0       0.84      0.68      0.75       893
        34.0       0.71      0.89      0.79      1377
        35.0       0.83      0.23      0.36        22
        36.0       0.88      0.77      0.82       844
        37.0       0.95      0.82      0.88      1142
        38.0       0.98      0.82      0.89       314
        39.0       1.00      0.52      0.68        56
        40.0       0.86      0.69      0.77       153
        41.0       1.00      0.80      0.89        51
        42.0       0.94      0.69      0.80       246
        43.0       0.96      0.72      0.82       197
        44.0       0.90      0.85      0.88       530
        45.0       0.99      0.75      0.85       540
        46.0       0.00      0.00      0.00        20
        47.0       0.97      0.38      0.54        80
        48.0       0.99      0.92      0.95      1465
        49.0       0.88      0.82      0.85       148
        50.0       0.90      0.92      0.91      1453
        51.0       0.00      0.00      0.00        13
        52.0       0.99      0.79      0.88       151
        53.0       0.82      0.96      0.88       904
        54.0       0.80      0.70      0.75       108
        55.0       0.99      0.84      0.91        93
        56.0       0.97      0.91      0.94        33
        57.0       0.89      0.98      0.93        50
        58.0       0.81      0.90      0.85       153

    accuracy                           0.81     29892
   macro avg       0.83      0.67      0.72     29892
weighted avg       0.83      0.81      0.81     29892


===confusion_matrix===

[[767   0   0 ...   0   0   0]
 [  0  46   0 ...   0   0   0]
 [  0   0  99 ...   0   0   0]
 ...
 [  0   0   0 ...  30   2   0]
 [  0   0   0 ...   0  49   1]
 [  0   0   0 ...   1   3 137]]

===multilabel confusion matrix===

[[[28835   145]
  [  145   767]]

 [[29838     2]
  [    6    46]]

 [[29706     7]
  [   80    99]]

 [[29867     1]
  [   24     0]]

 [[29776     4]
  [   97    15]]

 [[29333    67]
  [  234   258]]

 [[29827     1]
  [   18    46]]

 [[29854     0]
  [   37     1]]

 [[29651    36]
  [   42   163]]

 [[29808    14]
  [   20    50]]

 [[29401    86]
  [   58   347]]

 [[29874     1]
  [   15     2]]

 [[29451    63]
  [  112   266]]

 [[29697     4]
  [   69   122]]

 [[29806    10]
  [   72     4]]

 [[29818     7]
  [   37    30]]

 [[29750     2]
  [   55    85]]

 [[29643    66]
  [   57   126]]

 [[29880     0]
  [    3     9]]

 [[29855     0]
  [    5    32]]

 [[27661    69]
  [  267  1895]]

 [[29714    10]
  [   31   137]]

 [[28083   339]
  [  338  1132]]

 [[28448   185]
  [  215  1044]]

 [[28822   115]
  [  152   803]]

 [[29587    23]
  [   28   254]]

 [[24349  1625]
  [  268  3650]]

 [[29341    19]
  [   74   458]]

 [[29879     0]
  [    2    11]]

 [[26943   603]
  [  589  1757]]

 [[29232    44]
  [  355   261]]

 [[29860     0]
  [   10    22]]

 [[27658   785]
  [  315  1134]]

 [[28882   117]
  [  282   611]]

 [[28016   499]
  [  148  1229]]

 [[29869     1]
  [   17     5]]

 [[28961    87]
  [  192   652]]

 [[28696    54]
  [  206   936]]

 [[29572     6]
  [   55   259]]

 [[29836     0]
  [   27    29]]

 [[29722    17]
  [   47   106]]

 [[29841     0]
  [   10    41]]

 [[29636    10]
  [   76   170]]

 [[29689     6]
  [   55   142]]

 [[29314    48]
  [   77   453]]

 [[29346     6]
  [  134   406]]

 [[29872     0]
  [   20     0]]

 [[29811     1]
  [   50    30]]

 [[28410    17]
  [  114  1351]]

 [[29728    16]
  [   27   121]]

 [[28287   152]
  [  112  1341]]

 [[29879     0]
  [   13     0]]

 [[29740     1]
  [   32   119]]

 [[28793   195]
  [   34   870]]

 [[29765    19]
  [   32    76]]

 [[29798     1]
  [   15    78]]

 [[29858     1]
  [    3    30]]

 [[29836     6]
  [    1    49]]

 [[29707    32]
  [   16   137]]]

===scores report===
metrics	scores
Accuracy	0.8118
MCC	0.8018
log_loss	0.7569
f1 score weighted	0.8086
f1 score macro	0.7177
f1 score micro	0.8118
roc_auc ovr	0.9867
roc_auc ovo	0.9832
precision	0.8265
recall	0.8118

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c78352820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c78352670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c78352850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c78352580>, 'x_test': array([[13, 11,  3, ...,  0,  0,  0],
       [13, 17,  4, ...,  0,  0,  0],
       [13,  1, 11, ...,  0,  0,  0],
       ...,
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0],
       [15,  8, 19, ...,  8,  8,  9]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.65      0.92      0.77       911
         1.0       0.84      0.72      0.78        53
         2.0       0.95      0.63      0.76       180
         3.0       0.25      0.04      0.07        25
         4.0       0.80      0.36      0.50       111
         5.0       0.65      0.66      0.66       491
         6.0       0.89      0.73      0.80        64
         7.0       0.64      0.19      0.29        37
         8.0       0.81      0.86      0.83       205
         9.0       0.63      0.73      0.68        71
        10.0       0.89      0.85      0.87       404
        11.0       1.00      0.18      0.30        17
        12.0       0.75      0.75      0.75       378
        13.0       0.95      0.72      0.82       191
        14.0       0.00      0.00      0.00        76
        15.0       0.46      0.74      0.57        66
        16.0       0.87      0.69      0.77       140
        17.0       0.68      0.68      0.68       182
        18.0       0.92      0.92      0.92        12
        19.0       0.86      0.68      0.76        37
        20.0       0.94      0.88      0.91      2162
        21.0       0.99      0.92      0.95       168
        22.0       0.63      0.83      0.72      1470
        23.0       0.71      0.88      0.79      1259
        24.0       0.73      0.91      0.81       955
        25.0       0.84      0.95      0.89       283
        26.0       0.92      0.85      0.88      3919
        27.0       0.99      0.87      0.92       532
        28.0       1.00      0.38      0.56        13
        29.0       0.86      0.69      0.76      2345
        30.0       0.65      0.63      0.64       616
        31.0       0.89      0.75      0.81        32
        32.0       0.64      0.76      0.70      1449
        33.0       0.88      0.68      0.77       893
        34.0       0.89      0.85      0.87      1377
        35.0       0.91      0.45      0.61        22
        36.0       0.87      0.73      0.80       844
        37.0       0.76      0.87      0.81      1142
        38.0       0.89      0.85      0.87       314
        39.0       0.96      0.39      0.56        56
        40.0       0.90      0.78      0.84       153
        41.0       0.94      0.88      0.91        52
        42.0       0.89      0.72      0.79       247
        43.0       1.00      0.75      0.85       197
        44.0       0.72      0.88      0.79       529
        45.0       0.94      0.84      0.89       540
        46.0       0.36      0.20      0.26        20
        47.0       0.97      0.45      0.62        80
        48.0       0.90      0.99      0.94      1466
        49.0       0.94      0.86      0.90       148
        50.0       0.97      0.89      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       1.00      0.85      0.92       151
        53.0       0.93      0.95      0.94       904
        54.0       0.81      0.67      0.73       108
        55.0       0.90      0.98      0.94        93
        56.0       1.00      0.79      0.88        33
        57.0       0.76      0.96      0.85        50
        58.0       0.82      0.84      0.83       154

    accuracy                           0.82     29892
   macro avg       0.80      0.70      0.73     29892
weighted avg       0.83      0.82      0.82     29892


===confusion_matrix===

[[841   0   0 ...   0   0   0]
 [  0  38   0 ...   0   0   0]
 [  2   0 113 ...   0   0   0]
 ...
 [  0   0   0 ...  26   3   1]
 [  0   0   0 ...   0  48   1]
 [  0   0   0 ...   0   9 130]]

===multilabel confusion matrix===

[[[28535   446]
  [   70   841]]

 [[29832     7]
  [   15    38]]

 [[29706     6]
  [   67   113]]

 [[29864     3]
  [   24     1]]

 [[29771    10]
  [   71    40]]

 [[29228   173]
  [  165   326]]

 [[29822     6]
  [   17    47]]

 [[29851     4]
  [   30     7]]

 [[29645    42]
  [   28   177]]

 [[29791    30]
  [   19    52]]

 [[29445    43]
  [   60   344]]

 [[29875     0]
  [   14     3]]

 [[29417    97]
  [   93   285]]

 [[29694     7]
  [   53   138]]

 [[29809     7]
  [   76     0]]

 [[29769    57]
  [   17    49]]

 [[29738    14]
  [   44    96]]

 [[29651    59]
  [   59   123]]

 [[29879     1]
  [    1    11]]

 [[29851     4]
  [   12    25]]

 [[27614   116]
  [  249  1913]]

 [[29722     2]
  [   14   154]]

 [[27693   729]
  [  244  1226]]

 [[28185   448]
  [  145  1114]]

 [[28623   314]
  [   86   869]]

 [[29559    50]
  [   14   269]]

 [[25667   306]
  [  599  3320]]

 [[29353     7]
  [   70   462]]

 [[29879     0]
  [    8     5]]

 [[27287   260]
  [  734  1611]]

 [[29067   209]
  [  228   388]]

 [[29857     3]
  [    8    24]]

 [[27833   610]
  [  341  1108]]

 [[28919    80]
  [  287   606]]

 [[28364   151]
  [  209  1168]]

 [[29869     1]
  [   12    10]]

 [[28957    91]
  [  224   620]]

 [[28439   311]
  [  144   998]]

 [[29544    34]
  [   48   266]]

 [[29835     1]
  [   34    22]]

 [[29726    13]
  [   34   119]]

 [[29837     3]
  [    6    46]]

 [[29622    23]
  [   70   177]]

 [[29695     0]
  [   50   147]]

 [[29181   182]
  [   66   463]]

 [[29324    28]
  [   86   454]]

 [[29865     7]
  [   16     4]]

 [[29811     1]
  [   44    36]]

 [[28260   166]
  [   16  1450]]

 [[29736     8]
  [   20   128]]

 [[28397    42]
  [  154  1299]]

 [[29880     0]
  [   12     0]]

 [[29741     0]
  [   23   128]]

 [[28926    62]
  [   44   860]]

 [[29767    17]
  [   36    72]]

 [[29789    10]
  [    2    91]]

 [[29859     0]
  [    7    26]]

 [[29827    15]
  [    2    48]]

 [[29709    29]
  [   24   130]]]

===scores report===
metrics	scores
Accuracy	0.8212
MCC	0.8123
log_loss	0.7378
f1 score weighted	0.8207
f1 score macro	0.7287
f1 score micro	0.8212
roc_auc ovr	0.9875
roc_auc ovo	0.9834
precision	0.8335
recall	0.8212

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7915495784825372	0.780545459153232	0.8437451382304525	0.7922201084161236	0.6851600182033621	0.7915495784825372	0.9828726820973674	0.9786320425240858	0.8112391626702502	0.7915495784825372
1	0.8081426468620366	0.7993454590488487	0.8070536529850856	0.8132282504209047	0.7054757112781042	0.8081426468620366	0.9862079850659742	0.9812580210066184	0.8434728007586393	0.8081426468620366
2	0.8102502341763682	0.8007401706479618	0.7928748886342499	0.8117553711967472	0.7011137083081095	0.8102502341763682	0.9865797739879795	0.9820253327497939	0.8339657326297276	0.8102502341763682
3	0.8118225612203934	0.801776235278023	0.7568675093957002	0.8085796557817913	0.7176680223400393	0.8118225612203934	0.9867338396410877	0.9832218184400919	0.8264963904260362	0.8118225612203934
4	0.821189615950756	0.8123152857505992	0.7377688735588145	0.8206649596471828	0.7286870040143386	0.821189615950756	0.9875219070718878	0.9834262825875667	0.8335166301035924	0.821189615950756
mean	0.8085909273384184	0.798944521975733	0.7876620125608605	0.80928966909255	0.7076208928287907	0.8085909273384184	0.9859832375728594	0.9817126994616313	0.8297381433176492	0.8085909273384184
std	0.009618027216571927	0.010283059287844768	0.03737954928791078	0.009411305600570874	0.014806498540225437	0.009618027216571927	0.0016132470231435513	0.0017325545565902594	0.010709916298530214	0.009618027216571927

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 65104.3797 secs

