/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_post_terminals_bilstm_attentio_cv_only_enz_emb20_lev2_ec90_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff7b438e7f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff7b438e640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff7b438e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff7b438e550>, 'x_test': array([[13,  2,  3, ...,  0,  0,  0],
       [13, 13,  2, ...,  0,  0,  0],
       [13,  7,  1, ...,  0,  0,  0],
       ...,
       [13,  4, 11, ...,  0,  0,  0],
       [13,  1, 20, ...,  0,  0,  0],
       [13,  6, 12, ...,  0,  0,  0]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.91      0.83       911
         1.0       0.97      0.64      0.77        53
         2.0       0.84      0.82      0.83       179
         3.0       0.29      0.20      0.24        25
         4.0       0.64      0.64      0.64       112
         5.0       0.66      0.79      0.72       491
         6.0       0.96      0.80      0.87        64
         7.0       0.45      0.24      0.32        37
         8.0       0.92      0.83      0.87       206
         9.0       0.80      0.80      0.80        71
        10.0       0.92      0.87      0.89       404
        11.0       0.58      0.44      0.50        16
        12.0       0.78      0.76      0.77       378
        13.0       0.71      0.78      0.74       191
        14.0       0.51      0.33      0.40        76
        15.0       0.59      0.77      0.67        66
        16.0       0.91      0.82      0.86       141
        17.0       0.74      0.75      0.74       182
        18.0       1.00      0.75      0.86        12
        19.0       0.94      0.89      0.92        38
        20.0       0.87      0.94      0.90      2162
        21.0       0.94      0.92      0.93       168
        22.0       0.82      0.83      0.82      1470
        23.0       0.83      0.87      0.85      1259
        24.0       0.90      0.88      0.89       956
        25.0       0.91      0.89      0.90       283
        26.0       0.87      0.91      0.89      3919
        27.0       0.98      0.90      0.94       531
        28.0       0.89      0.67      0.76        12
        29.0       0.80      0.79      0.80      2345
        30.0       0.69      0.64      0.67       615
        31.0       0.95      0.66      0.78        32
        32.0       0.84      0.73      0.78      1449
        33.0       0.87      0.81      0.84       893
        34.0       0.88      0.87      0.88      1377
        35.0       0.81      0.59      0.68        22
        36.0       0.82      0.84      0.83       844
        37.0       0.89      0.87      0.88      1142
        38.0       0.97      0.84      0.90       314
        39.0       0.80      0.66      0.73        56
        40.0       0.90      0.73      0.81       154
        41.0       0.90      0.88      0.89        52
        42.0       0.83      0.78      0.80       247
        43.0       0.85      0.81      0.83       198
        44.0       0.86      0.90      0.88       529
        45.0       0.87      0.88      0.87       540
        46.0       0.86      0.30      0.44        20
        47.0       0.87      0.68      0.76        80
        48.0       0.95      0.98      0.96      1466
        49.0       0.92      0.87      0.90       148
        50.0       0.97      0.93      0.95      1453
        51.0       0.67      0.17      0.27        12
        52.0       0.90      0.95      0.93       151
        53.0       0.95      0.96      0.95       903
        54.0       0.89      0.80      0.84       108
        55.0       0.87      0.96      0.91        93
        56.0       0.96      0.79      0.87        33
        57.0       0.91      0.84      0.87        49
        58.0       0.89      0.94      0.91       154

    accuracy                           0.86     29892
   macro avg       0.83      0.76      0.79     29892
weighted avg       0.86      0.86      0.86     29892


===confusion_matrix===

[[830   0   2 ...   0   0   0]
 [  0  34   0 ...   0   0   0]
 [  0   0 147 ...   0   0   0]
 ...
 [  0   0   0 ...  26   1   1]
 [  0   0   0 ...   0  41   6]
 [  0   0   0 ...   1   2 144]]

===multilabel confusion matrix===

[[[28717   264]
  [   81   830]]

 [[29838     1]
  [   19    34]]

 [[29685    28]
  [   32   147]]

 [[29855    12]
  [   20     5]]

 [[29740    40]
  [   40    72]]

 [[29205   196]
  [  102   389]]

 [[29826     2]
  [   13    51]]

 [[29844    11]
  [   28     9]]

 [[29671    15]
  [   35   171]]

 [[29807    14]
  [   14    57]]

 [[29456    32]
  [   51   353]]

 [[29871     5]
  [    9     7]]

 [[29432    82]
  [   91   287]]

 [[29640    61]
  [   42   149]]

 [[29792    24]
  [   51    25]]

 [[29791    35]
  [   15    51]]

 [[29739    12]
  [   26   115]]

 [[29661    49]
  [   45   137]]

 [[29880     0]
  [    3     9]]

 [[29852     2]
  [    4    34]]

 [[27420   310]
  [  137  2025]]

 [[29714    10]
  [   13   155]]

 [[28155   267]
  [  257  1213]]

 [[28415   218]
  [  167  1092]]

 [[28842    94]
  [  117   839]]

 [[29584    25]
  [   32   251]]

 [[25427   546]
  [  350  3569]]

 [[29350    11]
  [   52   479]]

 [[29879     1]
  [    4     8]]

 [[27096   451]
  [  495  1850]]

 [[29100   177]
  [  220   395]]

 [[29859     1]
  [   11    21]]

 [[28244   199]
  [  392  1057]]

 [[28891   108]
  [  168   725]]

 [[28356   159]
  [  176  1201]]

 [[29867     3]
  [    9    13]]

 [[28894   154]
  [  135   709]]

 [[28631   119]
  [  154   988]]

 [[29571     7]
  [   51   263]]

 [[29827     9]
  [   19    37]]

 [[29725    13]
  [   41   113]]

 [[29835     5]
  [    6    46]]

 [[29605    40]
  [   55   192]]

 [[29665    29]
  [   37   161]]

 [[29283    80]
  [   55   474]]

 [[29278    74]
  [   65   475]]

 [[29871     1]
  [   14     6]]

 [[29804     8]
  [   26    54]]

 [[28350    76]
  [   32  1434]]

 [[29733    11]
  [   19   129]]

 [[28396    43]
  [  107  1346]]

 [[29879     1]
  [   10     2]]

 [[29725    16]
  [    7   144]]

 [[28942    47]
  [   39   864]]

 [[29773    11]
  [   22    86]]

 [[29786    13]
  [    4    89]]

 [[29858     1]
  [    7    26]]

 [[29839     4]
  [    8    41]]

 [[29721    17]
  [   10   144]]]

===scores report===
metrics	scores
Accuracy	0.8580
MCC	0.8504
log_loss	0.7182
f1 score weighted	0.8571
f1 score macro	0.7887
f1 score micro	0.8580
roc_auc ovr	0.9908
roc_auc ovo	0.9880
precision	0.8591
recall	0.8580

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff7b438e7f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff7b438e640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff7b438e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff7b438e550>, 'x_test': array([[13, 12,  3, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [20, 20, 20, ...,  1,  7,  1],
       [13, 16, 11, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.90      0.88       912
         1.0       0.85      0.74      0.79        53
         2.0       0.84      0.74      0.79       179
         3.0       0.56      0.20      0.29        25
         4.0       0.69      0.59      0.64       112
         5.0       0.75      0.72      0.74       492
         6.0       0.96      0.72      0.82        65
         7.0       0.69      0.24      0.35        38
         8.0       0.92      0.84      0.88       206
         9.0       0.86      0.77      0.81        71
        10.0       0.92      0.86      0.89       405
        11.0       0.67      0.59      0.62        17
        12.0       0.84      0.77      0.80       377
        13.0       0.88      0.76      0.82       191
        14.0       0.53      0.37      0.43        76
        15.0       0.78      0.71      0.75        66
        16.0       0.86      0.77      0.82       140
        17.0       0.83      0.81      0.82       182
        18.0       1.00      1.00      1.00        11
        19.0       0.90      0.76      0.82        37
        20.0       0.92      0.93      0.92      2163
        21.0       0.94      0.90      0.92       169
        22.0       0.82      0.81      0.82      1469
        23.0       0.87      0.88      0.88      1259
        24.0       0.93      0.87      0.90       956
        25.0       0.94      0.87      0.90       282
        26.0       0.87      0.90      0.89      3919
        27.0       0.95      0.91      0.93       531
        28.0       0.91      0.83      0.87        12
        29.0       0.74      0.84      0.78      2346
        30.0       0.68      0.73      0.70       615
        31.0       0.93      0.81      0.87        32
        32.0       0.75      0.80      0.77      1450
        33.0       0.79      0.80      0.79       893
        34.0       0.88      0.89      0.89      1376
        35.0       0.80      0.55      0.65        22
        36.0       0.84      0.85      0.84       843
        37.0       0.90      0.85      0.87      1142
        38.0       0.95      0.85      0.90       314
        39.0       0.90      0.64      0.75        56
        40.0       0.85      0.70      0.77       154
        41.0       0.92      0.92      0.92        52
        42.0       0.85      0.83      0.84       247
        43.0       0.94      0.80      0.87       198
        44.0       0.90      0.88      0.89       529
        45.0       0.90      0.91      0.91       539
        46.0       0.70      0.37      0.48        19
        47.0       0.69      0.64      0.66        80
        48.0       0.97      0.96      0.97      1466
        49.0       0.94      0.88      0.91       148
        50.0       0.95      0.94      0.94      1453
        51.0       0.50      0.08      0.14        12
        52.0       0.95      0.92      0.94       151
        53.0       0.94      0.94      0.94       903
        54.0       0.81      0.85      0.83       108
        55.0       0.94      0.95      0.94        93
        56.0       1.00      0.82      0.90        33
        57.0       0.93      0.84      0.88        49
        58.0       0.87      0.86      0.87       154

    accuracy                           0.86     29892
   macro avg       0.85      0.77      0.80     29892
weighted avg       0.86      0.86      0.86     29892


===confusion_matrix===

[[820   0   0 ...   0   0   0]
 [  0  39   0 ...   0   0   0]
 [  0   0 133 ...   0   0   0]
 ...
 [  0   0   0 ...  27   1   0]
 [  0   0   0 ...   0  41   7]
 [  0   0   0 ...   0   2 133]]

===multilabel confusion matrix===

[[[28846   134]
  [   92   820]]

 [[29832     7]
  [   14    39]]

 [[29687    26]
  [   46   133]]

 [[29863     4]
  [   20     5]]

 [[29751    29]
  [   46    66]]

 [[29284   116]
  [  137   355]]

 [[29825     2]
  [   18    47]]

 [[29850     4]
  [   29     9]]

 [[29671    15]
  [   33   173]]

 [[29812     9]
  [   16    55]]

 [[29458    29]
  [   57   348]]

 [[29870     5]
  [    7    10]]

 [[29459    56]
  [   87   290]]

 [[29682    19]
  [   45   146]]

 [[29791    25]
  [   48    28]]

 [[29813    13]
  [   19    47]]

 [[29735    17]
  [   32   108]]

 [[29679    31]
  [   34   148]]

 [[29881     0]
  [    0    11]]

 [[29852     3]
  [    9    28]]

 [[27553   176]
  [  162  2001]]

 [[29713    10]
  [   17   152]]

 [[28164   259]
  [  277  1192]]

 [[28469   164]
  [  147  1112]]

 [[28872    64]
  [  120   836]]

 [[29594    16]
  [   38   244]]

 [[25456   517]
  [  374  3545]]

 [[29335    26]
  [   49   482]]

 [[29879     1]
  [    2    10]]

 [[26851   695]
  [  383  1963]]

 [[29070   207]
  [  169   446]]

 [[29858     2]
  [    6    26]]

 [[28054   388]
  [  290  1160]]

 [[28811   188]
  [  181   712]]

 [[28352   164]
  [  148  1228]]

 [[29867     3]
  [   10    12]]

 [[28913   136]
  [  127   716]]

 [[28642   108]
  [  173   969]]

 [[29563    15]
  [   46   268]]

 [[29832     4]
  [   20    36]]

 [[29719    19]
  [   46   108]]

 [[29836     4]
  [    4    48]]

 [[29610    35]
  [   43   204]]

 [[29684    10]
  [   39   159]]

 [[29309    54]
  [   65   464]]

 [[29299    54]
  [   48   491]]

 [[29870     3]
  [   12     7]]

 [[29789    23]
  [   29    51]]

 [[28390    36]
  [   63  1403]]

 [[29736     8]
  [   18   130]]

 [[28365    74]
  [   88  1365]]

 [[29879     1]
  [   11     1]]

 [[29734     7]
  [   12   139]]

 [[28939    50]
  [   54   849]]

 [[29762    22]
  [   16    92]]

 [[29793     6]
  [    5    88]]

 [[29859     0]
  [    6    27]]

 [[29840     3]
  [    8    41]]

 [[29718    20]
  [   21   133]]]

===scores report===
metrics	scores
Accuracy	0.8623
MCC	0.8548
log_loss	0.7188
f1 score weighted	0.8620
f1 score macro	0.8002
f1 score micro	0.8623
roc_auc ovr	0.9908
roc_auc ovo	0.9885
precision	0.8640
recall	0.8623

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff7b438e7f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff7b438e640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff7b438e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff7b438e550>, 'x_test': array([[13, 16,  8, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       [13, 19,  3, ...,  0,  0,  0],
       ...,
       [13,  1, 17, ...,  0,  0,  0],
       [ 9,  5,  1, ...,  8, 11, 15],
       [20,  6, 15, ...,  4,  2,  3]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.90      0.90       912
         1.0       0.88      0.87      0.87        52
         2.0       0.90      0.80      0.85       179
         3.0       0.33      0.08      0.13        25
         4.0       0.70      0.62      0.66       112
         5.0       0.84      0.76      0.80       492
         6.0       0.95      0.82      0.88        65
         7.0       0.60      0.39      0.48        38
         8.0       0.94      0.83      0.88       205
         9.0       0.88      0.79      0.83        71
        10.0       0.94      0.88      0.91       405
        11.0       0.73      0.65      0.69        17
        12.0       0.88      0.78      0.83       377
        13.0       0.91      0.83      0.87       190
        14.0       0.45      0.22      0.30        76
        15.0       0.78      0.76      0.77        67
        16.0       0.91      0.86      0.88       140
        17.0       0.80      0.80      0.80       183
        18.0       0.79      0.92      0.85        12
        19.0       0.97      0.86      0.91        37
        20.0       0.93      0.92      0.93      2162
        21.0       0.97      0.89      0.93       169
        22.0       0.81      0.83      0.82      1470
        23.0       0.82      0.90      0.85      1259
        24.0       0.95      0.88      0.91       956
        25.0       0.94      0.91      0.92       282
        26.0       0.90      0.90      0.90      3918
        27.0       0.96      0.91      0.93       531
        28.0       1.00      0.92      0.96        13
        29.0       0.71      0.86      0.78      2346
        30.0       0.71      0.67      0.69       615
        31.0       0.93      0.78      0.85        32
        32.0       0.73      0.83      0.78      1450
        33.0       0.87      0.79      0.83       893
        34.0       0.87      0.90      0.89      1376
        35.0       0.81      0.59      0.68        22
        36.0       0.87      0.84      0.86       843
        37.0       0.92      0.88      0.90      1142
        38.0       0.96      0.91      0.94       314
        39.0       0.65      0.47      0.55        55
        40.0       0.88      0.69      0.78       154
        41.0       0.96      0.85      0.90        52
        42.0       0.89      0.78      0.83       247
        43.0       0.87      0.88      0.88       197
        44.0       0.94      0.89      0.92       530
        45.0       0.93      0.89      0.91       540
        46.0       1.00      0.37      0.54        19
        47.0       0.78      0.62      0.69        79
        48.0       0.98      0.97      0.98      1465
        49.0       0.89      0.84      0.87       149
        50.0       0.95      0.93      0.94      1453
        51.0       0.50      0.25      0.33        12
        52.0       0.95      0.93      0.94       152
        53.0       0.96      0.94      0.95       903
        54.0       0.90      0.86      0.88       108
        55.0       0.95      0.94      0.94        93
        56.0       0.94      0.94      0.94        32
        57.0       0.92      0.94      0.93        50
        58.0       0.90      0.92      0.91       154

    accuracy                           0.87     29892
   macro avg       0.86      0.79      0.81     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[821   0   0 ...   0   0   0]
 [  0  45   0 ...   0   0   0]
 [  0   0 143 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   1]
 [  0   0   0 ...   1  47   2]
 [  0   0   0 ...   0   3 142]]

===multilabel confusion matrix===

[[[28898    82]
  [   91   821]]

 [[29834     6]
  [    7    45]]

 [[29697    16]
  [   36   143]]

 [[29863     4]
  [   23     2]]

 [[29750    30]
  [   42    70]]

 [[29326    74]
  [  116   376]]

 [[29824     3]
  [   12    53]]

 [[29844    10]
  [   23    15]]

 [[29677    10]
  [   35   170]]

 [[29813     8]
  [   15    56]]

 [[29466    21]
  [   50   355]]

 [[29871     4]
  [    6    11]]

 [[29476    39]
  [   82   295]]

 [[29687    15]
  [   32   158]]

 [[29795    21]
  [   59    17]]

 [[29811    14]
  [   16    51]]

 [[29740    12]
  [   20   120]]

 [[29672    37]
  [   36   147]]

 [[29877     3]
  [    1    11]]

 [[29854     1]
  [    5    32]]

 [[27589   141]
  [  166  1996]]

 [[29719     4]
  [   18   151]]

 [[28136   286]
  [  243  1227]]

 [[28378   255]
  [  132  1127]]

 [[28887    49]
  [  110   846]]

 [[29593    17]
  [   26   256]]

 [[25577   397]
  [  385  3533]]

 [[29340    21]
  [   49   482]]

 [[29879     0]
  [    1    12]]

 [[26730   816]
  [  330  2016]]

 [[29107   170]
  [  204   411]]

 [[29858     2]
  [    7    25]]

 [[28002   440]
  [  249  1201]]

 [[28898   101]
  [  187   706]]

 [[28334   182]
  [  131  1245]]

 [[29867     3]
  [    9    13]]

 [[28948   101]
  [  138   705]]

 [[28668    82]
  [  132  1010]]

 [[29566    12]
  [   27   287]]

 [[29823    14]
  [   29    26]]

 [[29723    15]
  [   47   107]]

 [[29838     2]
  [    8    44]]

 [[29620    25]
  [   54   193]]

 [[29670    25]
  [   24   173]]

 [[29334    28]
  [   56   474]]

 [[29314    38]
  [   58   482]]

 [[29873     0]
  [   12     7]]

 [[29799    14]
  [   30    49]]

 [[28401    26]
  [   42  1423]]

 [[29728    15]
  [   24   125]]

 [[28363    76]
  [  101  1352]]

 [[29877     3]
  [    9     3]]

 [[29733     7]
  [   11   141]]

 [[28955    34]
  [   54   849]]

 [[29774    10]
  [   15    93]]

 [[29794     5]
  [    6    87]]

 [[29858     2]
  [    2    30]]

 [[29838     4]
  [    3    47]]

 [[29722    16]
  [   12   142]]]

===scores report===
metrics	scores
Accuracy	0.8713
MCC	0.8644
log_loss	0.6313
f1 score weighted	0.8713
f1 score macro	0.8141
f1 score micro	0.8713
roc_auc ovr	0.9922
roc_auc ovo	0.9899
precision	0.8747
recall	0.8713

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff7b438e7f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff7b438e640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff7b438e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff7b438e550>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       [13, 12, 12, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [20,  2,  1, ...,  7,  6,  6],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.87      0.86       912
         1.0       0.98      0.90      0.94        52
         2.0       0.86      0.66      0.75       179
         3.0       0.50      0.21      0.29        24
         4.0       0.56      0.58      0.57       112
         5.0       0.79      0.68      0.73       492
         6.0       0.88      0.81      0.85        64
         7.0       0.50      0.26      0.34        38
         8.0       0.93      0.83      0.88       205
         9.0       0.93      0.74      0.83        70
        10.0       0.86      0.87      0.87       405
        11.0       0.73      0.47      0.57        17
        12.0       0.72      0.82      0.76       378
        13.0       0.74      0.79      0.76       191
        14.0       0.27      0.17      0.21        76
        15.0       0.78      0.76      0.77        67
        16.0       0.81      0.79      0.80       140
        17.0       0.75      0.78      0.76       183
        18.0       1.00      0.92      0.96        12
        19.0       0.92      0.95      0.93        37
        20.0       0.93      0.93      0.93      2162
        21.0       0.97      0.91      0.94       168
        22.0       0.81      0.84      0.82      1470
        23.0       0.83      0.87      0.85      1259
        24.0       0.95      0.88      0.91       955
        25.0       0.84      0.93      0.88       282
        26.0       0.88      0.91      0.89      3918
        27.0       0.91      0.89      0.90       532
        28.0       1.00      1.00      1.00        13
        29.0       0.81      0.80      0.81      2346
        30.0       0.60      0.73      0.66       616
        31.0       0.80      0.75      0.77        32
        32.0       0.74      0.82      0.78      1449
        33.0       0.80      0.82      0.81       893
        34.0       0.92      0.87      0.89      1377
        35.0       0.59      0.45      0.51        22
        36.0       0.82      0.86      0.84       844
        37.0       0.91      0.87      0.89      1142
        38.0       0.92      0.90      0.91       314
        39.0       0.93      0.66      0.77        56
        40.0       0.94      0.75      0.84       153
        41.0       0.89      0.78      0.83        51
        42.0       0.86      0.75      0.80       246
        43.0       0.93      0.88      0.90       197
        44.0       0.90      0.89      0.89       530
        45.0       0.91      0.89      0.90       540
        46.0       0.88      0.35      0.50        20
        47.0       0.63      0.76      0.69        80
        48.0       0.97      0.96      0.97      1465
        49.0       0.97      0.83      0.89       148
        50.0       0.96      0.93      0.94      1453
        51.0       0.46      0.46      0.46        13
        52.0       0.86      0.83      0.84       151
        53.0       0.95      0.94      0.94       904
        54.0       0.90      0.80      0.84       108
        55.0       0.98      0.91      0.94        93
        56.0       0.97      0.97      0.97        33
        57.0       0.89      0.96      0.92        50
        58.0       0.93      0.89      0.91       153

    accuracy                           0.86     29892
   macro avg       0.83      0.78      0.80     29892
weighted avg       0.86      0.86      0.86     29892


===confusion_matrix===

[[792   0   1 ...   0   0   0]
 [  0  47   0 ...   0   0   0]
 [  0   0 119 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   0]
 [  0   0   0 ...   0  48   2]
 [  0   0   0 ...   0   4 136]]

===multilabel confusion matrix===

[[[28851   129]
  [  120   792]]

 [[29839     1]
  [    5    47]]

 [[29694    19]
  [   60   119]]

 [[29863     5]
  [   19     5]]

 [[29728    52]
  [   47    65]]

 [[29311    89]
  [  155   337]]

 [[29821     7]
  [   12    52]]

 [[29844    10]
  [   28    10]]

 [[29674    13]
  [   35   170]]

 [[29818     4]
  [   18    52]]

 [[29431    56]
  [   51   354]]

 [[29872     3]
  [    9     8]]

 [[29391   123]
  [   69   309]]

 [[29647    54]
  [   40   151]]

 [[29781    35]
  [   63    13]]

 [[29811    14]
  [   16    51]]

 [[29726    26]
  [   29   111]]

 [[29661    48]
  [   40   143]]

 [[29880     0]
  [    1    11]]

 [[29852     3]
  [    2    35]]

 [[27574   156]
  [  154  2008]]

 [[29720     4]
  [   15   153]]

 [[28133   289]
  [  239  1231]]

 [[28409   224]
  [  158  1101]]

 [[28891    46]
  [  115   840]]

 [[29560    50]
  [   19   263]]

 [[25468   506]
  [  370  3548]]

 [[29315    45]
  [   58   474]]

 [[29879     0]
  [    0    13]]

 [[27118   428]
  [  477  1869]]

 [[28975   301]
  [  165   451]]

 [[29854     6]
  [    8    24]]

 [[28027   416]
  [  262  1187]]

 [[28820   179]
  [  158   735]]

 [[28415   100]
  [  184  1193]]

 [[29863     7]
  [   12    10]]

 [[28890   158]
  [  120   724]]

 [[28652    98]
  [  153   989]]

 [[29553    25]
  [   32   282]]

 [[29833     3]
  [   19    37]]

 [[29732     7]
  [   38   115]]

 [[29836     5]
  [   11    40]]

 [[29615    31]
  [   61   185]]

 [[29682    13]
  [   24   173]]

 [[29308    54]
  [   60   470]]

 [[29303    49]
  [   61   479]]

 [[29871     1]
  [   13     7]]

 [[29776    36]
  [   19    61]]

 [[28382    45]
  [   55  1410]]

 [[29740     4]
  [   25   123]]

 [[28378    61]
  [  102  1351]]

 [[29872     7]
  [    7     6]]

 [[29721    20]
  [   26   125]]

 [[28939    49]
  [   55   849]]

 [[29774    10]
  [   22    86]]

 [[29797     2]
  [    8    85]]

 [[29858     1]
  [    1    32]]

 [[29836     6]
  [    2    48]]

 [[29728    11]
  [   17   136]]]

===scores report===
metrics	scores
Accuracy	0.8614
MCC	0.8539
log_loss	0.7157
f1 score weighted	0.8614
f1 score macro	0.8002
f1 score micro	0.8614
roc_auc ovr	0.9911
roc_auc ovo	0.9895
precision	0.8638
recall	0.8614

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff7b438e7f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff7b438e640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff7b438e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff7b438e550>, 'x_test': array([[13, 11,  3, ...,  0,  0,  0],
       [13, 17,  4, ...,  0,  0,  0],
       [13,  1, 11, ...,  0,  0,  0],
       ...,
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0],
       [15,  8, 19, ...,  8,  8,  9]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.90      0.89       911
         1.0       0.84      0.77      0.80        53
         2.0       0.82      0.79      0.81       180
         3.0       0.43      0.24      0.31        25
         4.0       0.61      0.54      0.57       111
         5.0       0.72      0.75      0.74       491
         6.0       0.89      0.86      0.87        64
         7.0       0.65      0.46      0.54        37
         8.0       0.91      0.87      0.89       205
         9.0       0.83      0.75      0.79        71
        10.0       0.94      0.87      0.90       404
        11.0       0.75      0.35      0.48        17
        12.0       0.83      0.82      0.82       378
        13.0       0.87      0.75      0.81       191
        14.0       0.47      0.32      0.38        76
        15.0       0.69      0.67      0.68        66
        16.0       0.83      0.78      0.80       140
        17.0       0.79      0.75      0.77       182
        18.0       1.00      0.92      0.96        12
        19.0       0.96      0.68      0.79        37
        20.0       0.94      0.92      0.93      2162
        21.0       0.92      0.92      0.92       168
        22.0       0.83      0.82      0.83      1470
        23.0       0.85      0.87      0.86      1259
        24.0       0.91      0.88      0.90       955
        25.0       0.92      0.93      0.92       283
        26.0       0.88      0.90      0.89      3919
        27.0       0.95      0.91      0.93       532
        28.0       1.00      0.92      0.96        13
        29.0       0.74      0.83      0.78      2345
        30.0       0.75      0.71      0.73       616
        31.0       1.00      0.78      0.88        32
        32.0       0.74      0.80      0.77      1449
        33.0       0.85      0.77      0.81       893
        34.0       0.88      0.90      0.89      1377
        35.0       0.85      0.77      0.81        22
        36.0       0.85      0.85      0.85       844
        37.0       0.90      0.87      0.88      1142
        38.0       0.92      0.90      0.91       314
        39.0       0.65      0.62      0.64        56
        40.0       0.86      0.75      0.80       153
        41.0       0.85      0.88      0.87        52
        42.0       0.85      0.77      0.81       247
        43.0       0.86      0.83      0.84       197
        44.0       0.91      0.91      0.91       529
        45.0       0.91      0.89      0.90       540
        46.0       0.50      0.15      0.23        20
        47.0       0.69      0.78      0.73        80
        48.0       0.97      0.97      0.97      1466
        49.0       0.95      0.86      0.90       148
        50.0       0.95      0.93      0.94      1453
        51.0       1.00      0.08      0.15        12
        52.0       0.96      0.85      0.90       151
        53.0       0.94      0.96      0.95       904
        54.0       0.89      0.77      0.83       108
        55.0       0.92      0.97      0.94        93
        56.0       0.85      0.88      0.87        33
        57.0       0.89      0.94      0.91        50
        58.0       0.91      0.91      0.91       154

    accuracy                           0.86     29892
   macro avg       0.84      0.78      0.80     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[816   0   0 ...   0   0   0]
 [  0  41   1 ...   0   0   0]
 [  1   0 143 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   3]
 [  0   0   0 ...   0  47   1]
 [  0   0   0 ...   3   4 140]]

===multilabel confusion matrix===

[[[28877   104]
  [   95   816]]

 [[29831     8]
  [   12    41]]

 [[29680    32]
  [   37   143]]

 [[29859     8]
  [   19     6]]

 [[29742    39]
  [   51    60]]

 [[29261   140]
  [  123   368]]

 [[29821     7]
  [    9    55]]

 [[29846     9]
  [   20    17]]

 [[29670    17]
  [   26   179]]

 [[29810    11]
  [   18    53]]

 [[29465    23]
  [   52   352]]

 [[29873     2]
  [   11     6]]

 [[29450    64]
  [   68   310]]

 [[29680    21]
  [   47   144]]

 [[29789    27]
  [   52    24]]

 [[29806    20]
  [   22    44]]

 [[29730    22]
  [   31   109]]

 [[29673    37]
  [   45   137]]

 [[29880     0]
  [    1    11]]

 [[29854     1]
  [   12    25]]

 [[27593   137]
  [  176  1986]]

 [[29711    13]
  [   13   155]]

 [[28178   244]
  [  264  1206]]

 [[28446   187]
  [  169  1090]]

 [[28850    87]
  [  111   844]]

 [[29586    23]
  [   20   263]]

 [[25498   475]
  [  375  3544]]

 [[29334    26]
  [   49   483]]

 [[29879     0]
  [    1    12]]

 [[26862   685]
  [  396  1949]]

 [[29128   148]
  [  179   437]]

 [[29860     0]
  [    7    25]]

 [[28041   402]
  [  290  1159]]

 [[28879   120]
  [  207   686]]

 [[28353   162]
  [  132  1245]]

 [[29867     3]
  [    5    17]]

 [[28917   131]
  [  128   716]]

 [[28634   116]
  [  151   991]]

 [[29555    23]
  [   31   283]]

 [[29817    19]
  [   21    35]]

 [[29720    19]
  [   38   115]]

 [[29832     8]
  [    6    46]]

 [[29612    33]
  [   57   190]]

 [[29669    26]
  [   34   163]]

 [[29314    49]
  [   49   480]]

 [[29303    49]
  [   58   482]]

 [[29869     3]
  [   17     3]]

 [[29784    28]
  [   18    62]]

 [[28379    47]
  [   44  1422]]

 [[29737     7]
  [   21   127]]

 [[28366    73]
  [  103  1350]]

 [[29880     0]
  [   11     1]]

 [[29735     6]
  [   22   129]]

 [[28929    59]
  [   40   864]]

 [[29774    10]
  [   25    83]]

 [[29791     8]
  [    3    90]]

 [[29854     5]
  [    4    29]]

 [[29836     6]
  [    3    47]]

 [[29724    14]
  [   14   140]]]

===scores report===
metrics	scores
Accuracy	0.8647
MCC	0.8574
log_loss	0.7176
f1 score weighted	0.8644
f1 score macro	0.7973
f1 score micro	0.8647
roc_auc ovr	0.9910
roc_auc ovo	0.9885
precision	0.8659
recall	0.8647

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8580222133012178	0.8503776486747928	0.7182281736084573	0.8570855863756397	0.7887076223338445	0.8580222133012178	0.9908047421064085	0.987991280284765	0.8590815450000979	0.8580222133012178
1	0.8623042954636692	0.8548060861270346	0.7187937832161997	0.8620071096400105	0.8001510736906082	0.8623042954636692	0.9908217917216551	0.9885193009097748	0.8640193887775179	0.8623042954636692
2	0.871269904991302	0.8643606643037667	0.631262272875521	0.8713481085135274	0.814113998969533	0.871269904991302	0.9921859107332925	0.989935713879247	0.8746594888620813	0.871269904991302
3	0.8613675899906329	0.8539153905508763	0.7156510685393875	0.8614407487898921	0.8002375237161483	0.8613675899906328	0.9911244123973053	0.9895470120461289	0.8637800279451806	0.8613675899906329
4	0.8647464204469423	0.8574228610596655	0.7175888752160451	0.8643736849778925	0.7973211775776579	0.8647464204469423	0.9910399330916392	0.9885183529848035	0.8659064339529289	0.8647464204469423
mean	0.8635420848387527	0.856176530143227	0.700304834691122	0.8632510476593925	0.8001062792575585	0.8635420848387527	0.9911953580100601	0.9889023320209438	0.8654893769075613	0.8635420848387527
std	0.004424910411291005	0.0046722861225217335	0.034537537803852096	0.004683165289820249	0.00817216757305305	0.004424910411291016	0.0005103954229333971	0.0007221715029348279	0.005107013580743409	0.004424910411291005

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 82220.0169 secs

