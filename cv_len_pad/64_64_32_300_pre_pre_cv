/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_300_pre_pre_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f699419c4c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f699419c6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f699419c9d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f699419c5e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.79      0.75      4541
         1.0       0.88      0.86      0.87      3813
         2.0       0.90      0.89      0.89     10869
         3.0       0.83      0.83      0.83      6897
         4.0       0.94      0.85      0.89      2585
         5.0       0.91      0.85      0.88      1617
         6.0       0.93      0.94      0.94      3258
         7.0       0.95      0.94      0.95      1372

    accuracy                           0.87     34952
   macro avg       0.88      0.87      0.88     34952
weighted avg       0.87      0.87      0.87     34952


===confusion_matrix===

[[3609   75  322  406   17   28   48   36]
 [ 114 3280  194  149   23   15   29    9]
 [ 535  136 9676  380   32   33   72    5]
 [ 557  139  291 5756   48   37   62    7]
 [  58   52  125  126 2188   15   21    0]
 [  61   30   74   57    8 1373   11    3]
 [  38   17   59   50    8    9 3075    2]
 [  48    7   15   13    2    1    1 1285]]

===multilabel confusion matrix===

[[[29000  1411]
  [  932  3609]]

 [[30683   456]
  [  533  3280]]

 [[23003  1080]
  [ 1193  9676]]

 [[26874  1181]
  [ 1141  5756]]

 [[32229   138]
  [  397  2188]]

 [[33197   138]
  [  244  1373]]

 [[31450   244]
  [  183  3075]]

 [[33518    62]
  [   87  1285]]]

===scores report===
metrics	scores
Accuracy	0.8652
MCC	0.8353
log_loss	0.4346
f1 score weighted	0.8662
f1 score macro	0.8750
f1 score micro	0.8652
roc_auc ovr	0.9808
roc_auc ovo	0.9841
precision	0.8681
recall	0.8652

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f699419c4c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f699419c6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f699419c9d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f699419c5e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.76      0.75      4541
         1.0       0.87      0.85      0.86      3813
         2.0       0.88      0.89      0.89     10869
         3.0       0.83      0.82      0.83      6897
         4.0       0.88      0.87      0.88      2585
         5.0       0.90      0.84      0.87      1616
         6.0       0.94      0.93      0.94      3258
         7.0       0.96      0.95      0.96      1372

    accuracy                           0.86     34951
   macro avg       0.88      0.87      0.87     34951
weighted avg       0.86      0.86      0.86     34951


===confusion_matrix===

[[3436   98  446  427   46   36   21   31]
 [  94 3253  189  173   60   16   20    8]
 [ 492  132 9722  355   71   36   59    2]
 [ 460  146  423 5680   82   38   58   10]
 [  62   45  109   95 2255   13    6    0]
 [  51   31   63   70   23 1362   15    1]
 [  45   25   79   48   16   10 3035    0]
 [  32    8    6   16    3    1    1 1305]]

===multilabel confusion matrix===

[[[29174  1236]
  [ 1105  3436]]

 [[30653   485]
  [  560  3253]]

 [[22767  1315]
  [ 1147  9722]]

 [[26870  1184]
  [ 1217  5680]]

 [[32065   301]
  [  330  2255]]

 [[33185   150]
  [  254  1362]]

 [[31513   180]
  [  223  3035]]

 [[33527    52]
  [   67  1305]]]

===scores report===
metrics	scores
Accuracy	0.8597
MCC	0.8282
log_loss	0.4409
f1 score weighted	0.8599
f1 score macro	0.8704
f1 score micro	0.8597
roc_auc ovr	0.9795
roc_auc ovo	0.9829
precision	0.8604
recall	0.8597

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f699419c4c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f699419c6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f699419c9d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f699419c5e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.74      0.74      4542
         1.0       0.83      0.84      0.84      3814
         2.0       0.85      0.90      0.87     10869
         3.0       0.84      0.78      0.81      6896
         4.0       0.86      0.86      0.86      2584
         5.0       0.88      0.81      0.85      1616
         6.0       0.96      0.92      0.94      3258
         7.0       0.89      0.94      0.92      1372

    accuracy                           0.85     34951
   macro avg       0.86      0.85      0.85     34951
weighted avg       0.85      0.85      0.85     34951


===confusion_matrix===

[[3341  147  472  373   62   39   17   91]
 [  89 3214  255  130   70   24   14   18]
 [ 469  153 9811  261   76   35   36   28]
 [ 486  211  598 5379  112   52   45   13]
 [  26   60  161  105 2214    7   11    0]
 [  46   41  108   62   29 1313   12    5]
 [  43   22  140   43   12   12 2985    1]
 [  26   15   14   14    1    3    3 1296]]

===multilabel confusion matrix===

[[[29224  1185]
  [ 1201  3341]]

 [[30488   649]
  [  600  3214]]

 [[22334  1748]
  [ 1058  9811]]

 [[27067   988]
  [ 1517  5379]]

 [[32005   362]
  [  370  2214]]

 [[33163   172]
  [  303  1313]]

 [[31555   138]
  [  273  2985]]

 [[33423   156]
  [   76  1296]]]

===scores report===
metrics	scores
Accuracy	0.8456
MCC	0.8108
log_loss	0.4891
f1 score weighted	0.8451
f1 score macro	0.8523
f1 score micro	0.8456
roc_auc ovr	0.9752
roc_auc ovo	0.9791
precision	0.8459
recall	0.8456

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f699419c4c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f699419c6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f699419c9d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f699419c5e0>, 'x_test': array([[[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.77      0.75      4542
         1.0       0.84      0.85      0.84      3813
         2.0       0.87      0.89      0.88     10868
         3.0       0.81      0.82      0.81      6897
         4.0       0.91      0.85      0.88      2585
         5.0       0.94      0.81      0.87      1616
         6.0       0.93      0.93      0.93      3258
         7.0       0.94      0.94      0.94      1372

    accuracy                           0.85     34951
   macro avg       0.87      0.86      0.86     34951
weighted avg       0.85      0.85      0.85     34951


===confusion_matrix===

[[3486  102  379  444   21   13   41   56]
 [  89 3238  207  182   46   10   28   13]
 [ 493  187 9624  409   65   17   66    7]
 [ 519  176  425 5633   50   30   58    6]
 [  46   73  157  102 2187    9   10    1]
 [  50   40  101   84   16 1311   13    1]
 [  29   25   92   64    7    1 3038    2]
 [  24   10   17   30    2    2    0 1287]]

===multilabel confusion matrix===

[[[29159  1250]
  [ 1056  3486]]

 [[30525   613]
  [  575  3238]]

 [[22705  1378]
  [ 1244  9624]]

 [[26739  1315]
  [ 1264  5633]]

 [[32159   207]
  [  398  2187]]

 [[33253    82]
  [  305  1311]]

 [[31477   216]
  [  220  3038]]

 [[33493    86]
  [   85  1287]]]

===scores report===
metrics	scores
Accuracy	0.8527
MCC	0.8196
log_loss	0.4511
f1 score weighted	0.8531
f1 score macro	0.8639
f1 score micro	0.8527
roc_auc ovr	0.9779
roc_auc ovo	0.9816
precision	0.8543
recall	0.8527

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f699419c4c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f699419c6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f699419c9d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f699419c5e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.80      0.74      4542
         1.0       0.83      0.86      0.84      3813
         2.0       0.89      0.87      0.88     10868
         3.0       0.85      0.77      0.81      6897
         4.0       0.80      0.89      0.84      2585
         5.0       0.93      0.82      0.87      1616
         6.0       0.95      0.93      0.94      3258
         7.0       0.91      0.94      0.93      1372

    accuracy                           0.85     34951
   macro avg       0.86      0.86      0.86     34951
weighted avg       0.85      0.85      0.85     34951


===confusion_matrix===

[[3627  137  326  294   54   29   19   56]
 [ 113 3261  166  134   86   14   23   16]
 [ 582  195 9504  312  180   28   38   29]
 [ 688  200  444 5277  194   21   54   19]
 [  56   60   89   65 2302    8    5    0]
 [  62   36   59   61   53 1325   17    3]
 [  57   35   83   52   13    4 3014    0]
 [  32   11   17   16    2    0    0 1294]]

===multilabel confusion matrix===

[[[28819  1590]
  [  915  3627]]

 [[30464   674]
  [  552  3261]]

 [[22899  1184]
  [ 1364  9504]]

 [[27120   934]
  [ 1620  5277]]

 [[31784   582]
  [  283  2302]]

 [[33231   104]
  [  291  1325]]

 [[31537   156]
  [  244  3014]]

 [[33456   123]
  [   78  1294]]]

===scores report===
metrics	scores
Accuracy	0.8470
MCC	0.8139
log_loss	0.4683
f1 score weighted	0.8479
f1 score macro	0.8562
f1 score micro	0.8470
roc_auc ovr	0.9770
roc_auc ovo	0.9808
precision	0.8513
recall	0.8470

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8652437628747998	0.8353061965055125	0.43463618724427855	0.8661530319471133	0.8750236760226138	0.8652437628747998	0.980830204430888	0.9840625410172377	0.8680758493024001	0.8652437628747998
1	0.8597178907613516	0.828219395334405	0.44088690177153494	0.8599426068202676	0.8703604072937692	0.8597178907613516	0.9794829236131597	0.9829432856053162	0.8603626424173502	0.8597178907613516
2	0.8455552058596321	0.8108168345182133	0.48914112762258416	0.8450809980154952	0.8523250754953786	0.845555205859632	0.9752049580537546	0.9791362971931612	0.8459166386214784	0.8455552058596321
3	0.8527366885067666	0.8196208210539386	0.45105049107119577	0.8531312203992835	0.8638631027337521	0.8527366885067666	0.9779099823712638	0.9816169307642271	0.8542772250686625	0.8527366885067666
4	0.8470143915767789	0.8139127578247388	0.4683154049786594	0.8478502649691804	0.8562314051367546	0.8470143915767789	0.9769553667772192	0.9808375826934741	0.8513010703141687	0.8470143915767789
mean	0.8540535879158657	0.8215752010473617	0.45680602253765057	0.854431624430268	0.8635607333364537	0.8540535879158657	0.978076687049257	0.9817193274546833	0.855986685144812	0.8540535879158657
std	0.0074941490386106775	0.00906598744395612	0.019779135726264028	0.007748572493399538	0.008457956102806693	0.007494149038610703	0.0019540387033197505	0.001699925150841331	0.00763649093701276	0.0074941490386106775

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 51605.3054 secs

