/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_700_pre_pre_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c28727160>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c28727310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c28727370>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c28727130>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.80      0.80      4541
         1.0       0.82      0.91      0.86      3813
         2.0       0.90      0.91      0.91     10869
         3.0       0.88      0.85      0.86      6897
         4.0       0.92      0.86      0.89      2585
         5.0       0.93      0.85      0.89      1617
         6.0       0.95      0.96      0.95      3258
         7.0       0.97      0.94      0.96      1372

    accuracy                           0.88     34952
   macro avg       0.90      0.88      0.89     34952
weighted avg       0.88      0.88      0.88     34952


===confusion_matrix===

[[3622  147  342  325   38   21   25   21]
 [  67 3464  123   81   33   18   23    4]
 [ 327  250 9910  257   38   17   69    1]
 [ 353  196  333 5878   61   31   38    7]
 [  47   85  111  100 2218   15    9    0]
 [  41   63   67   40   18 1372   15    1]
 [  15   29   46   20    2    7 3139    0]
 [  30   13   23   15    0    0    3 1288]]

===multilabel confusion matrix===

[[[29531   880]
  [  919  3622]]

 [[30356   783]
  [  349  3464]]

 [[23038  1045]
  [  959  9910]]

 [[27217   838]
  [ 1019  5878]]

 [[32177   190]
  [  367  2218]]

 [[33226   109]
  [  245  1372]]

 [[31512   182]
  [  119  3139]]

 [[33546    34]
  [   84  1288]]]

===scores report===
metrics	scores
Accuracy	0.8838
MCC	0.8580
log_loss	0.3776
f1 score weighted	0.8838
f1 score macro	0.8896
f1 score micro	0.8838
roc_auc ovr	0.9857
roc_auc ovo	0.9877
precision	0.8848
recall	0.8838

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c28727160>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c28727310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c28727370>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c28727130>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.82      0.77      4541
         1.0       0.81      0.88      0.84      3813
         2.0       0.86      0.91      0.88     10869
         3.0       0.91      0.74      0.81      6897
         4.0       0.85      0.85      0.85      2585
         5.0       0.95      0.80      0.87      1616
         6.0       0.96      0.94      0.95      3258
         7.0       0.96      0.95      0.95      1372

    accuracy                           0.86     34951
   macro avg       0.88      0.86      0.87     34951
weighted avg       0.86      0.86      0.86     34951


===confusion_matrix===

[[3729  149  372  198   35   10   16   32]
 [  98 3346  212   76   50    8   16    7]
 [ 487  197 9871  152   94   11   48    9]
 [ 633  270  687 5102  143   19   33   10]
 [  76   74  170   45 2202   12    4    2]
 [  68   49  110   37   47 1297    8    0]
 [  28   33   99   11   16    5 3066    0]
 [  29   16   10   11    2    1    0 1303]]

===multilabel confusion matrix===

[[[28991  1419]
  [  812  3729]]

 [[30350   788]
  [  467  3346]]

 [[22422  1660]
  [  998  9871]]

 [[27524   530]
  [ 1795  5102]]

 [[31979   387]
  [  383  2202]]

 [[33269    66]
  [  319  1297]]

 [[31568   125]
  [  192  3066]]

 [[33519    60]
  [   69  1303]]]

===scores report===
metrics	scores
Accuracy	0.8559
MCC	0.8246
log_loss	0.4424
f1 score weighted	0.8559
f1 score macro	0.8667
f1 score micro	0.8559
roc_auc ovr	0.9797
roc_auc ovo	0.9828
precision	0.8614
recall	0.8559

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c28727160>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c28727310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c28727370>]/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_700_pre_pre_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa9b07dc4c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa9b07dc490>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa9b07dc9d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c28727130>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.83      0.78      4542
         1.0       0.93      0.80      0.86      3814
         2.0       0.89      0.90      0.89     10869
         3.0       0.83      0.84      0.83      6896
         4.0       0.97      0.70      0.81      2584
         5.0       0.71      0.86      0.78      1616
         6.0       0.89      0.96      0.93      3258
         7.0       0.97      0.94      0.95      1372

    accuracy                           0.86     34951
   macro avg       0.87      0.85      0.86     34951
weighted avg       0.86      0.86      0.86     34951


===confusion_matrix===

[[3766   39  238  389   10   42   34   24]
 [ 159 3049  208  192   16  114   71    5]
 [ 486   65 9733  338   18   93  131    5]
 [ 519   54  389 5779   10   59   81    5]
 [  54   38  224  191 1818  234   24    1]
 [  45   20   80   40    8 1392   31    0]
 [  22    7   54   24    0   13 3138    0]
 [  48    5   14   13    0    1    4 1287]]

===multilabel confusion matrix===

[[[29076  1333]
  [  776  3766]]

 [[30909   228]
  [  765  3049]]

 [[22875  1207]
  [ 1136  9733]]

 [[26868  1187]
  [ 1117  5779]]

 [[32305    62]
  [  766  1818]]

 [[32779   556]
  [  224  1392]]

 [[31317   376]
  [  120  3138]]

 [[33539    40]
  [   85  1287]]]

===scores report===
metrics	scores
Accuracy	0.8573
MCC	0.8258
log_loss	0.4510
f1 score weighted	0.8576
f1 score macro	0.8555
f1 score micro	0.8573
roc_auc ovr	0.9807
roc_auc ovo	0.9831
precision	0.8637
recall	0.8573

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c28727160>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c28727310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c28727370>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c28727130>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.81      0.75      4542
         1.0       0.84      0.78      0.81      3813
         2.0       0.89      0.83      0.86     10868
         3.0       0.77      0.82      0.79      6897
         4.0       0.87      0.79      0.83      2585
         5.0       0.84      0.79      0.81      1616
         6.0       0.85      0.95      0.90      3258
         7.0       0.98      0.83      0.90      1372

    accuracy                           0.83     34951
   macro avg       0.84      0.82      0.83     34951
weighted avg       0.83      0.83      0.83     34951


===confusion_matrix===

[[3663   71  222  490   17   21   47   11]
 [ 150 2967  211  259   57   49  115    5]
 [ 643  238 8982  600  131   64  208    2]
 [ 526  125  340 5671   68   59  104    4]
 [  69   77  133  198 2041   28   38    1]
 [  48   39   80   94   35 1274   45    1]
 [  34   19   35   52    8    8 3102    0]
 [ 115   14   37   48    0   20    0 1138]]

===multilabel confusion matrix===

[[[28824  1585]
  [  879  3663]]

 [[30555   583]
  [  846  2967]]

 [[23025  1058]
  [ 1886  8982]]

 [[26313  1741]
  [ 1226  5671]]

 [[32050   316]
  [  544  2041]]

 [[33086   249]
  [  342  1274]]

 [[31136   557]
  [  156  3102]]

 [[33555    24]
  [  234  1138]]]

===scores report===
metrics	scores
Accuracy	0.8251
MCC	0.7875
log_loss	0.5229
f1 score weighted	0.8262
f1 score macro	0.8299
f1 score micro	0.8251
roc_auc ovr	0.9718
roc_auc ovo	0.9757
precision	0.8312
recall	0.8251

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f0c28727160>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f0c28727310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f0c28727370>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f0c28727130>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.77      0.78      4542
         1.0       0.88      0.88      0.88      3813
         2.0       0.92      0.90      0.91     10868
         3.0       0.82      0.86      0.84      6897
         4.0       0.85      0.88      0.87      2585
         5.0       0.92      0.86      0.89      1616
         6.0       0.94      0.96      0.95      3258
         7.0       0.95      0.94      0.95      1372

    accuracy                           0.88     34951
   macro avg       0.88      0.88      0.88     34951
weighted avg       0.88      0.88      0.88     34951


===confusion_matrix===

[[3475  128  275  521   55   32   23   33]
 [  64 3354  113  170   64   15   21   12]
 [ 325  130 9755  409  127   26   86   10]
 [ 350  113  307 5935  109   32   40   11]
 [  37   49   85  110 2278   11   14    1]
 [  30   24   53   70   25 1394   18    2]
 [  17   14   39   37   15   11 3125    0]
 [  33   11   18   10    2    0    4 1294]]

===multilabel confusion matrix===

[[[29553   856]
  [ 1067  3475]]

 [[30669   469]
  [  459  3354]]

 [[23193   890]
  [ 1113  9755]]

 [[26727  1327]
  [  962  5935]]

 [[31969   397]
  [  307  2278]]

 [[33208   127]
  [  222  1394]]

 [[31487   206]
  [  133  3125]]

 [[33510    69]
  [   78  1294]]]

===scores report===
metrics	scores
Accuracy	0.8758
MCC	0.8483
log_loss	0.4017
f1 score weighted	0.8758
f1 score macro	0.8821
f1 score micro	0.8758
roc_auc ovr	0.9840
roc_auc ovo	0.9865
precision	0.8763
recall	0.8758

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8838120851453422	0.8579502887331653	0.3775927814171761	0.8838379472920713	0.8896249484895008	0.8838120851453423	0.9856669620120974	0.9876882267505376	0.8848478356049847	0.8838120851453422
1	0.8559411747875597	0.8245795109669742	0.4424336164323835	0.855918992460346	0.8666508950814159	0.8559411747875597	0.9796707971787817	0.9827733203464221	0.8613798164973477	0.8559411747875597
2	0.8572573030814569	0.825758524385907	0.4510499576798479	0.8576099911716925	0.8554590369327298	0.8572573030814569	0.9807254837488174	0.9830503143241336	0.8637117843336576	0.8572573030814569
3	0.825097994334926	0.7874514453767693	0.5228569043178422	0.8262369130828059	0.8298608656109424	0.8250979943349261	0.9718359768688132	0.9756655826172536	0.8312403840753835	0.825097994334926
4	0.875797545134617	0.8483008474044591	0.4017260641562326	0.875775795085965	0.8820856076144217	0.875797545134617	0.9840324350610387	0.9865212831917776	0.8762856612611282	0.875797545134617
mean	0.8595812204967803	0.828808123373455	0.43913186480069644	0.8598759278185761	0.8647362707458022	0.8595812204967803	0.9803863309739096	0.9831397454460248	0.8634930963545002	0.8595812204967803
std	0.020287175248539086	0.02435893316133623	0.04969723825203626	0.019896528717738768	0.02110200230546883	0.020287175248539076	0.0047940527263451785	0.004198305729067865	0.018245140892264075	0.020287175248539086

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 115688.5172 secs

