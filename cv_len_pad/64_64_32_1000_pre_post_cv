/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_1000_pre_post_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd8c01d0e20>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd8c01d0ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd8c01d0cd0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd8c01d0d00>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.70      0.74      4541
         1.0       0.72      0.84      0.78      3813
         2.0       0.83      0.89      0.86     10869
         3.0       0.81      0.78      0.79      6897
         4.0       0.90      0.73      0.80      2585
         5.0       0.82      0.77      0.79      1617
         6.0       0.93      0.95      0.94      3258
         7.0       0.93      0.93      0.93      1372

    accuracy                           0.83     34952
   macro avg       0.84      0.82      0.83     34952
weighted avg       0.83      0.83      0.83     34952


===confusion_matrix===

[[3181  214  470  518   18   58   35   47]
 [  54 3212  266  180   29   33   33    6]
 [ 360  341 9681  290   61   41   80   15]
 [ 305  351  670 5352   67   71   60   21]
 [  35  135  281  166 1880   66   20    2]
 [  27  108  120   61   31 1249   19    2]
 [  16   53   81   15    7    7 3079    0]
 [  28   17   30   16    1    2    0 1278]]

===multilabel confusion matrix===

[[[29586   825]
  [ 1360  3181]]

 [[29920  1219]
  [  601  3212]]

 [[22165  1918]
  [ 1188  9681]]

 [[26809  1246]
  [ 1545  5352]]

 [[32153   214]
  [  705  1880]]

 [[33057   278]
  [  368  1249]]

 [[31447   247]
  [  179  3079]]

 [[33487    93]
  [   94  1278]]]

===scores report===
metrics	scores
Accuracy	0.8272
MCC	0.7883
log_loss	0.5264
f1 score weighted	0.8262
f1 score macro	0.8305
f1 score micro	0.8272
roc_auc ovr	0.9713
roc_auc ovo	0.9748
precision	0.8290
recall	0.8272

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd8c01d0e20>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd8c01d0ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd8c01d0cd0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd8c01d0d00>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.74      0.74      4541
         1.0       0.87      0.79      0.83      3813
         2.0       0.78      0.91      0.84     10869
         3.0       0.86      0.72      0.78      6897
         4.0       0.94      0.70      0.80      2585
         5.0       0.87      0.71      0.78      1616
         6.0       0.78      0.97      0.86      3258
         7.0       0.97      0.93      0.95      1372

    accuracy                           0.82     34951
   macro avg       0.85      0.81      0.82     34951
weighted avg       0.83      0.82      0.82     34951


===confusion_matrix===

[[3368   73  599  273   12   82  117   17]
 [  96 2998  439  123   20    9  124    4]
 [ 384  101 9920  204   25   21  209    5]
 [ 516  154 1011 4947   30   30  204    5]
 [  64   62  432   93 1813   34   85    2]
 [  35   29  172   69   17 1146  147    1]
 [  14   11   73   10    2    2 3146    0]
 [  33    2   33   20    3    0    4 1277]]

===multilabel confusion matrix===

[[[29268  1142]
  [ 1173  3368]]

 [[30706   432]
  [  815  2998]]

 [[21323  2759]
  [  949  9920]]

 [[27262   792]
  [ 1950  4947]]

 [[32257   109]
  [  772  1813]]

 [[33157   178]
  [  470  1146]]

 [[30803   890]
  [  112  3146]]

 [[33545    34]
  [   95  1277]]]

===scores report===
metrics	scores
Accuracy	0.8187
MCC	0.7784
log_loss	0.5521
f1 score weighted	0.8169
f1 score macro	0.8245
f1 score micro	0.8187
roc_auc ovr	0.9710
roc_auc ovo	0.9743
precision	0.8265
recall	0.8187

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd8c01d0e20>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd8c01d0ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd8c01d0cd0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd8c01d0d00>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.80      0.78      4542
         1.0       0.75      0.89      0.82      3814
         2.0       0.87      0.90      0.89     10869
         3.0       0.91      0.73      0.81      6896
         4.0       0.85      0.83      0.84      2584
         5.0       0.92      0.77      0.84      1616
         6.0       0.89      0.96      0.93      3258
         7.0       0.90      0.96      0.93      1372

    accuracy                           0.85     34951
   macro avg       0.86      0.86      0.85     34951
weighted avg       0.86      0.85      0.85     34951


===confusion_matrix===

[[3616  182  377  181   54   22   39   71]
 [  85 3397  157   52   53   16   36   18]
 [ 355  293 9836  135   96   15  118   21]
 [ 570  369  614 5057  134   35   91   26]
 [  34  133  175   65 2136   16   20    5]
 [  47   83   85   42   45 1242   69    3]
 [  15   43   44   14    1    1 3140    0]
 [  18   12    9    5    0    1    7 1320]]

===multilabel confusion matrix===

[[[29285  1124]
  [  926  3616]]

 [[30022  1115]
  [  417  3397]]

 [[22621  1461]
  [ 1033  9836]]

 [[27561   494]
  [ 1839  5057]]

 [[31984   383]
  [  448  2136]]

 [[33229   106]
  [  374  1242]]

 [[31313   380]
  [  118  3140]]

 [[33435   144]
  [   52  1320]]]

===scores report===
metrics	scores
Accuracy	0.8510
MCC	0.8190
log_loss	0.4752
f1 score weighted	0.8502
f1 score macro	0.8535
f1 score micro	0.8510
roc_auc ovr	0.9790
roc_auc ovo	0.9818
precision	0.8556
recall	0.8510

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd8c01d0e20>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd8c01d0ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd8c01d0cd0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd8c01d0d00>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.83      0.78      4542
         1.0       0.88      0.84      0.86      3813
         2.0       0.87      0.92      0.89     10868
         3.0       0.93      0.73      0.82      6897
         4.0       0.75      0.89      0.81      2585
         5.0       0.91      0.82      0.86      1616
         6.0       0.97      0.95      0.96      3258
         7.0       0.94      0.97      0.95      1372

    accuracy                           0.86     34951
   macro avg       0.87      0.87      0.87     34951
weighted avg       0.87      0.86      0.86     34951


===confusion_matrix===

[[ 3761    82   386   155    75    22    11    50]
 [  122  3205   243    68   114    31    15    15]
 [  418   110 10018    94   181    14    25     8]
 [  695   155   614  5052   300    42    25    14]
 [   56    39   137    43  2295    12     2     1]
 [   44    39    86    23    65  1331    25     3]
 [   20    25    80    12    13    10  3098     0]
 [   28     3     9     2     4     1     0  1325]]

===multilabel confusion matrix===

[[[29026  1383]
  [  781  3761]]

 [[30685   453]
  [  608  3205]]

 [[22528  1555]
  [  850 10018]]

 [[27657   397]
  [ 1845  5052]]

 [[31614   752]
  [  290  2295]]

 [[33203   132]
  [  285  1331]]

 [[31590   103]
  [  160  3098]]

 [[33488    91]
  [   47  1325]]]

===scores report===
metrics	scores
Accuracy	0.8608
MCC	0.8310
log_loss	0.4409
f1 score weighted	0.8606
f1 score macro	0.8669
f1 score micro	0.8608
roc_auc ovr	0.9823
roc_auc ovo	0.9849
precision	0.8674
recall	0.8608

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd8c01d0e20>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd8c01d0ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd8c01d0cd0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd8c01d0d00>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.83      0.79      4542
         1.0       0.83      0.89      0.86      3813
         2.0       0.91      0.90      0.91     10868
         3.0       0.86      0.84      0.85      6897
         4.0       0.93      0.82      0.87      2585
         5.0       0.88      0.87      0.87      1616
         6.0       0.95      0.97      0.96      3258
         7.0       0.96      0.93      0.95      1372

    accuracy                           0.88     34951
   macro avg       0.89      0.88      0.88     34951
weighted avg       0.88      0.88      0.88     34951


===confusion_matrix===

[[3757   93  257  366   15   22   10   22]
 [ 112 3380  126  136   19   14   20    6]
 [ 413  236 9775  277   62   44   57    4]
 [ 456  185  306 5820   48   31   38   13]
 [  74  102  125   96 2121   60    7    0]
 [  66   46   52   18   18 1400   14    2]
 [  19   25   32   19    1   15 3147    0]
 [  45    2   20   24    0    2    7 1272]]

===multilabel confusion matrix===

[[[29224  1185]
  [  785  3757]]

 [[30449   689]
  [  433  3380]]

 [[23165   918]
  [ 1093  9775]]

 [[27118   936]
  [ 1077  5820]]

 [[32203   163]
  [  464  2121]]

 [[33147   188]
  [  216  1400]]

 [[31540   153]
  [  111  3147]]

 [[33532    47]
  [  100  1272]]]

===scores report===
metrics	scores
Accuracy	0.8776
MCC	0.8506
log_loss	0.3887
f1 score weighted	0.8781
f1 score macro	0.8824
f1 score micro	0.8776
roc_auc ovr	0.9842
roc_auc ovo	0.9864
precision	0.8799
recall	0.8776

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.827191577019913	0.7883205288988949	0.5263686399415856	0.8261636430086582	0.8304717080166623	0.8271915770199129	0.97131629507745	0.9748103848265309	0.82897984701208	0.827191577019913
1	0.8187176332579897	0.7783824516547234	0.552095618530838	0.8168556606340998	0.8245325892606972	0.8187176332579897	0.9709893347585199	0.974328085316056	0.8264739246330683	0.8187176332579897
2	0.8510199994277703	0.8190327053047413	0.4752463946251312	0.8501593964569452	0.8534772486070115	0.8510199994277703	0.9790402010216742	0.9818343517992899	0.8556399859899851	0.8510199994277703
3	0.8607765156933993	0.8309804779418877	0.4408570071948691	0.8606291327361061	0.8668922205208212	0.8607765156933993	0.9822707408860177	0.9848532273714523	0.8674457697297848	0.8607765156933993
4	0.8775714571829132	0.8505689392747291	0.38868440476453486	0.8781282580589659	0.8824340915094256	0.8775714571829132	0.9842411063300845	0.9863687964507964	0.8798593754543809	0.8775714571829132
mean	0.8470554365163971	0.8134570206149953	0.4766504130113917	0.8463872181789549	0.8515615715829237	0.8470554365163971	0.9775715356147492	0.9804389691528252	0.8516797805638598	0.8470554365163971
std	0.021600080082200167	0.026748917460697484	0.05862599918025289	0.02238598202256187	0.021758489527302624	0.02160008008220019	0.005498655909894567	0.00501237434594085	0.021018855183144915	0.021600080082200167

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 151388.3229 secs

