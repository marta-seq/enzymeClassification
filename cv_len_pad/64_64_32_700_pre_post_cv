/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_700_pre_post_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f19b07df1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f19b07df370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f19b07df3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f19b07df190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.77      0.79      4541
         1.0       0.87      0.88      0.88      3813
         2.0       0.93      0.89      0.91     10869
         3.0       0.84      0.88      0.86      6897
         4.0       0.84      0.89      0.87      2585
         5.0       0.90      0.87      0.88      1617
         6.0       0.95      0.97      0.96      3258
         7.0       0.96      0.95      0.95      1372

    accuracy                           0.88     34952
   macro avg       0.89      0.89      0.89     34952
weighted avg       0.88      0.88      0.88     34952


===confusion_matrix===

[[3516   97  294  478   70   27   26   33]
 [  79 3367  111  130   77   25   18    6]
 [ 374  173 9727  363  134   33   59    6]
 [ 289  124  207 6072  115   44   34   12]
 [  41   44   71   85 2310   18   16    0]
 [  25   32   41   57   37 1409   15    1]
 [  17   18   29   20    8   12 3154    0]
 [  31    8   13    8    5    1    1 1305]]

===multilabel confusion matrix===

[[[29555   856]
  [ 1025  3516]]

 [[30643   496]
  [  446  3367]]

 [[23317   766]
  [ 1142  9727]]

 [[26914  1141]
  [  825  6072]]

 [[31921   446]
  [  275  2310]]

 [[33175   160]
  [  208  1409]]

 [[31525   169]
  [  104  3154]]

 [[33522    58]
  [   67  1305]]]

===scores report===
metrics	scores
Accuracy	0.8829
MCC	0.8572
log_loss	0.3815
f1 score weighted	0.8829
f1 score macro	0.8875
f1 score micro	0.8829
roc_auc ovr	0.9854
roc_auc ovo	0.9879
precision	0.8835
recall	0.8829

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f19b07df1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f19b07df370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f19b07df3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f19b07df190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.75      0.75      4541
         1.0       0.85      0.82      0.84      3813
         2.0       0.85      0.88      0.86     10869
         3.0       0.82      0.80      0.81      6897
         4.0       0.88      0.79      0.83      2585
         5.0       0.82      0.84      0.83      1616
         6.0       0.92      0.94      0.93      3258
         7.0       0.95      0.92      0.94      1372

    accuracy                           0.84     34951
   macro avg       0.85      0.84      0.85     34951
weighted avg       0.84      0.84      0.84     34951


===confusion_matrix===

[[3424  105  445  450   19   38   29   31]
 [  80 3130  262  186   58   45   44    8]
 [ 496  180 9562  363   85   78   98    7]
 [ 417  108  601 5540   88   70   59   14]
 [  65   81  205  120 2039   55   20    0]
 [  54   35   75   58   21 1351   22    0]
 [  17   19   93   34    7   16 3070    2]
 [  39   14   23   23    0    0   11 1262]]

===multilabel confusion matrix===

[[[29242  1168]
  [ 1117  3424]]

 [[30596   542]
  [  683  3130]]

 [[22378  1704]
  [ 1307  9562]]

 [[26820  1234]
  [ 1357  5540]]

 [[32088   278]
  [  546  2039]]

 [[33033   302]
  [  265  1351]]

 [[31410   283]
  [  188  3070]]

 [[33517    62]
  [  110  1262]]]

===scores report===
metrics	scores
Accuracy	0.8405
MCC	0.8046
log_loss	0.4826
f1 score weighted	0.8403
f1 score macro	0.8480
f1 score micro	0.8405
roc_auc ovr	0.9748
roc_auc ovo	0.9788
precision	0.8408
recall	0.8405

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f19b07df1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f19b07df370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f19b07df3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f19b07df190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.78      0.79      4542
         1.0       0.78      0.92      0.85      3814
         2.0       0.92      0.89      0.91     10869
         3.0       0.87      0.84      0.86      6896
         4.0       0.93      0.84      0.88      2584
         5.0       0.85      0.88      0.86      1616
         6.0       0.90      0.98      0.94      3258
         7.0       0.95      0.96      0.96      1372

    accuracy                           0.88     34951
   macro avg       0.88      0.89      0.88     34951
weighted avg       0.88      0.88      0.88     34951


===confusion_matrix===

[[3528  194  316  338   25   60   43   38]
 [  55 3515   76   75   21   29   33   10]
 [ 339  297 9726  264   45   70  125    3]
 [ 340  291  259 5814   47   25  111    9]
 [  32   98   86  109 2175   57   26    1]
 [  28   54   35   31   20 1418   30    0]
 [  10   18   16   14    2    7 3189    2]
 [  17   11   10    5    0    1    5 1323]]

===multilabel confusion matrix===

[[[29588   821]
  [ 1014  3528]]

 [[30174   963]
  [  299  3515]]

 [[23284   798]
  [ 1143  9726]]

 [[27219   836]
  [ 1082  5814]]

 [[32207   160]
  [  409  2175]]

 [[33086   249]
  [  198  1418]]

 [[31320   373]
  [   69  3189]]

 [[33516    63]
  [   49  1323]]]

===scores report===
metrics	scores
Accuracy	0.8780
MCC	0.8517
log_loss	0.4096
f1 score weighted	0.8779
f1 score macro	0.8815
f1 score micro	0.8780
roc_auc ovr	0.9846
roc_auc ovo	0.9873
precision	0.8801
recall	0.8780

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f19b07df1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f19b07df370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f19b07df3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f19b07df190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.70      0.75      4542
         1.0       0.97      0.71      0.82      3813
         2.0       0.92      0.86      0.89     10868
         3.0       0.67      0.93      0.78      6897
         4.0       0.89      0.82      0.85      2585
         5.0       0.95      0.77      0.85      1616
         6.0       0.92      0.95      0.93      3258
         7.0       0.92      0.96      0.94      1372

    accuracy                           0.84     34951
   macro avg       0.88      0.84      0.85     34951
weighted avg       0.86      0.84      0.84     34951


===confusion_matrix===

[[3177   29  229  983   24   13   34   53]
 [  74 2705  197  634   98   11   65   29]
 [ 347   25 9304  997   71   17   83   24]
 [ 201   12  192 6403   26    8   45   10]
 [  34   15   98  294 2119    9   16    0]
 [  35   10   76  185   36 1241   32    1]
 [  10    3   50   84   11    4 3095    1]
 [  16    0    9   22    1    0    6 1318]]

===multilabel confusion matrix===

[[[29692   717]
  [ 1365  3177]]

 [[31044    94]
  [ 1108  2705]]

 [[23232   851]
  [ 1564  9304]]

 [[24855  3199]
  [  494  6403]]

 [[32099   267]
  [  466  2119]]

 [[33273    62]
  [  375  1241]]

 [[31412   281]
  [  163  3095]]

 [[33461   118]
  [   54  1318]]]

===scores report===
metrics	scores
Accuracy	0.8401
MCC	0.8076
log_loss	0.5074
f1 score weighted	0.8417
f1 score macro	0.8509
f1 score micro	0.8401
roc_auc ovr	0.9795
roc_auc ovo	0.9822
precision	0.8591
recall	0.8401

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f19b07df1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f19b07df370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f19b07df3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f19b07df190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.77      0.75      4542
         1.0       0.87      0.81      0.84      3813
         2.0       0.88      0.87      0.88     10868
         3.0       0.77      0.84      0.80      6897
         4.0       0.87      0.77      0.82      2585
         5.0       0.90      0.78      0.84      1616
         6.0       0.93      0.95      0.94      3258
         7.0       0.95      0.92      0.93      1372

    accuracy                           0.84     34951
   macro avg       0.86      0.84      0.85     34951
weighted avg       0.85      0.84      0.84     34951


===confusion_matrix===

[[3506   75  337  533   12   20   25   34]
 [ 114 3086  213  279   53   28   31    9]
 [ 500  153 9488  507  101   32   78    9]
 [ 442  103  448 5762   72   18   39   13]
 [  68   68  165  227 2003   37   12    5]
 [  55   45   67  108   48 1261   31    1]
 [  19   20   73   43    4    5 3094    0]
 [  58    2   13   15    7    2    9 1266]]

===multilabel confusion matrix===

[[[29153  1256]
  [ 1036  3506]]

 [[30672   466]
  [  727  3086]]

 [[22767  1316]
  [ 1380  9488]]

 [[26342  1712]
  [ 1135  5762]]

 [[32069   297]
  [  582  2003]]

 [[33193   142]
  [  355  1261]]

 [[31468   225]
  [  164  3094]]

 [[33508    71]
  [  106  1266]]]

===scores report===
metrics	scores
Accuracy	0.8431
MCC	0.8079
log_loss	0.4846
f1 score weighted	0.8435
f1 score macro	0.8500
f1 score micro	0.8431
roc_auc ovr	0.9750
roc_auc ovo	0.9781
precision	0.8457
recall	0.8431

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8829251544975967	0.8572390631569453	0.38151623862585093	0.8829357552787205	0.8874878518464197	0.8829251544975967	0.9854486461379646	0.9878970252381712	0.8835422966885026	0.8829251544975967
1	0.8405481960458928	0.8045811014656448	0.4825527953793647	0.8403400422283116	0.8480010299240052	0.8405481960458927	0.9748040360798798	0.9787869097160646	0.8408393253968566	0.8405481960458928
2	0.8780292409373123	0.8516900885454867	0.4096369091298494	0.8779362902078595	0.8814807513058611	0.8780292409373123	0.9845920388069307	0.9873127878597545	0.8800978448413659	0.8780292409373123
3	0.8400904122914938	0.8076055361048801	0.5074427848123231	0.8417343291327182	0.8509197999521196	0.8400904122914938	0.9795431173122054	0.9822037365746505	0.8591455544845196	0.8400904122914938
4	0.8430660066950874	0.8078745674429155	0.48461575844522703	0.8435415093785359	0.8500148301124104	0.8430660066950874	0.9749958604535406	0.9781021540922064	0.8457003600086445	0.8430660066950874
mean	0.8569318020934766	0.8257980713431745	0.453152897278523	0.8572975852452291	0.8635808526281632	0.8569318020934766	0.9798767397581042	0.9828605226961695	0.8618650762839778	0.8569318020934766
std	0.019313578304337633	0.02350026664649412	0.04863560345475891	0.018985651078881408	0.017198959744996356	0.019313578304337654	0.004537549892948602	0.004119630697884063	0.017396044292773343	0.019313578304337633

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 101352.5210 secs

