/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_300_pre_terminal_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb21005c2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb21005c460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb21005c4c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb21005c280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.70      0.73      4541
         1.0       0.77      0.88      0.82      3813
         2.0       0.86      0.89      0.88     10869
         3.0       0.82      0.78      0.80      6897
         4.0       0.91      0.80      0.86      2585
         5.0       0.88      0.83      0.85      1617
         6.0       0.90      0.95      0.93      3258
         7.0       0.95      0.93      0.94      1372

    accuracy                           0.84     34952
   macro avg       0.86      0.85      0.85     34952
weighted avg       0.84      0.84      0.84     34952


===confusion_matrix===

[[3173  191  530  496   34   34   51   32]
 [  61 3365  172  114   41   23   30    7]
 [ 382  285 9696  329   42   25  102    8]
 [ 422  320  511 5391   59   77   99   18]
 [  36  119  171  122 2079   19   39    0]
 [  32   64   87   58   17 1337   20    2]
 [  17   30   67   31    2    3 3105    3]
 [  52   24   13    3    0    6    2 1272]]

===multilabel confusion matrix===

[[[29409  1002]
  [ 1368  3173]]

 [[30106  1033]
  [  448  3365]]

 [[22532  1551]
  [ 1173  9696]]

 [[26902  1153]
  [ 1506  5391]]

 [[32172   195]
  [  506  2079]]

 [[33148   187]
  [  280  1337]]

 [[31351   343]
  [  153  3105]]

 [[33510    70]
  [  100  1272]]]

===scores report===
metrics	scores
Accuracy	0.8417
MCC	0.8064
log_loss	0.4822
f1 score weighted	0.8408
f1 score macro	0.8496
f1 score micro	0.8417
roc_auc ovr	0.9761
roc_auc ovo	0.9801
precision	0.8422
recall	0.8417

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb21005c2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb21005c460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb21005c4c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb21005c280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.75      0.75      4541
         1.0       0.91      0.85      0.88      3813
         2.0       0.86      0.92      0.89     10869
         3.0       0.85      0.81      0.83      6897
         4.0       0.88      0.87      0.88      2585
         5.0       0.95      0.85      0.90      1616
         6.0       0.95      0.94      0.95      3258
         7.0       0.94      0.94      0.94      1372

    accuracy                           0.87     34951
   macro avg       0.89      0.87      0.88     34951
weighted avg       0.87      0.87      0.87     34951


===confusion_matrix===

[[ 3407    68   536   410    47    12    19    42]
 [  115  3242   232   129    52     8    25    10]
 [  386    81 10016   247    79    14    42     4]
 [  507    93   523  5610    88    21    39    16]
 [   55    31   139    88  2258     8     5     1]
 [   40    27    87    48    25  1379    10     0]
 [   30    18    84    38    13     1  3072     2]
 [   39     4    14    19     3     2     5  1286]]

===multilabel confusion matrix===

[[[29238  1172]
  [ 1134  3407]]

 [[30816   322]
  [  571  3242]]

 [[22467  1615]
  [  853 10016]]

 [[27075   979]
  [ 1287  5610]]

 [[32059   307]
  [  327  2258]]

 [[33269    66]
  [  237  1379]]

 [[31548   145]
  [  186  3072]]

 [[33504    75]
  [   86  1286]]]

===scores report===
metrics	scores
Accuracy	0.8661
MCC	0.8357
log_loss	0.4498
f1 score weighted	0.8659
f1 score macro	0.8770
f1 score micro	0.8661
roc_auc ovr	0.9811
roc_auc ovo	0.9839
precision	0.8671
recall	0.8661

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb21005c2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb21005c460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb21005c4c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb21005c280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.81      0.73      4542
         1.0       0.92      0.80      0.85      3814
         2.0       0.94      0.80      0.87     10869
         3.0       0.76      0.84      0.80      6896
         4.0       0.85      0.84      0.84      2584
         5.0       0.83      0.86      0.84      1616
         6.0       0.88      0.95      0.92      3258
         7.0       0.95      0.92      0.93      1372

    accuracy                           0.83     34951
   macro avg       0.85      0.85      0.85     34951
weighted avg       0.85      0.83      0.84     34951


===confusion_matrix===

[[3691   42  154  534   29   32   39   21]
 [ 202 3040  114  250   86   49   58   15]
 [ 849  112 8743  723  177   75  173   17]
 [ 641   51  186 5795   68   63   78   14]
 [  79   39   68  174 2163   39   20    2]
 [  52   15   18  104   19 1383   25    0]
 [  42   13   22   50    8   24 3099    0]
 [  58    7    8   26    2    2   12 1257]]

===multilabel confusion matrix===

[[[28486  1923]
  [  851  3691]]

 [[30858   279]
  [  774  3040]]

 [[23512   570]
  [ 2126  8743]]

 [[26194  1861]
  [ 1101  5795]]

 [[31978   389]
  [  421  2163]]

 [[33051   284]
  [  233  1383]]

 [[31288   405]
  [  159  3099]]

 [[33510    69]
  [  115  1257]]]

===scores report===
metrics	scores
Accuracy	0.8346
MCC	0.8011
log_loss	0.5148
f1 score weighted	0.8373
f1 score macro	0.8469
f1 score micro	0.8346
roc_auc ovr	0.9755
roc_auc ovo	0.9798
precision	0.8474
recall	0.8346

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb21005c2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb21005c460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb21005c4c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb21005c280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.66      0.71      4542
         1.0       0.95      0.76      0.85      3813
         2.0       0.80      0.93      0.86     10868
         3.0       0.81      0.82      0.82      6897
         4.0       0.90      0.83      0.87      2585
         5.0       0.94      0.83      0.88      1616
         6.0       0.96      0.93      0.95      3258
         7.0       0.94      0.95      0.95      1372

    accuracy                           0.85     34951
   macro avg       0.89      0.84      0.86     34951
weighted avg       0.85      0.85      0.84     34951


===confusion_matrix===

[[ 3020    28   866   530    35    11    14    38]
 [  117  2908   462   201    64    21    24    16]
 [  301    55 10114   300    51    12    27     8]
 [  371    30   691  5684    56    18    32    15]
 [   46    18   216   128  2153    16     7     1]
 [   27    17   125    74    23  1343     6     1]
 [   23     7   134    57     6     4  3027     0]
 [   27     3    23    13     2     0     1  1303]]

===multilabel confusion matrix===

[[[29497   912]
  [ 1522  3020]]

 [[30980   158]
  [  905  2908]]

 [[21566  2517]
  [  754 10114]]

 [[26751  1303]
  [ 1213  5684]]

 [[32129   237]
  [  432  2153]]

 [[33253    82]
  [  273  1343]]

 [[31582   111]
  [  231  3027]]

 [[33500    79]
  [   69  1303]]]

===scores report===
metrics	scores
Accuracy	0.8455
MCC	0.8104
log_loss	0.4841
f1 score weighted	0.8443
f1 score macro	0.8599
f1 score micro	0.8455
roc_auc ovr	0.9775
roc_auc ovo	0.9809
precision	0.8499
recall	0.8455

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb21005c2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb21005c460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb21005c4c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb21005c280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.67      0.72      4542
         1.0       0.81      0.85      0.83      3813
         2.0       0.92      0.85      0.88     10868
         3.0       0.78      0.82      0.80      6897
         4.0       0.82      0.86      0.84      2585
         5.0       0.61      0.92      0.73      1616
         6.0       0.96      0.93      0.94      3258
         7.0       0.90      0.93      0.92      1372

    accuracy                           0.83     34951
   macro avg       0.82      0.85      0.83     34951
weighted avg       0.84      0.83      0.83     34951


===confusion_matrix===

[[3047  174  271  674   89  199   31   57]
 [  57 3237  112  162   88  124   13   20]
 [ 369  247 9212  545  150  271   44   30]
 [ 380  185  299 5624  127  231   28   23]
 [  31   62   75  108 2225   78    6    0]
 [  13   17   25   44   19 1491    6    1]
 [  22   41   50   68   14   43 3016    4]
 [  31   11   14   18    3   11    2 1282]]

===multilabel confusion matrix===

[[[29506   903]
  [ 1495  3047]]

 [[30401   737]
  [  576  3237]]

 [[23237   846]
  [ 1656  9212]]

 [[26435  1619]
  [ 1273  5624]]

 [[31876   490]
  [  360  2225]]

 [[32378   957]
  [  125  1491]]

 [[31563   130]
  [  242  3016]]

 [[33444   135]
  [   90  1282]]]

===scores report===
metrics	scores
Accuracy	0.8336
MCC	0.7987
log_loss	0.5177
f1 score weighted	0.8346
f1 score macro	0.8324
f1 score micro	0.8336
roc_auc ovr	0.9757
roc_auc ovo	0.9804
precision	0.8408
recall	0.8336

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8416685740444038	0.8063772117252743	0.48220254234887844	0.8407558760315847	0.8496466587248821	0.8416685740444038	0.976087313346003	0.9801261974358956	0.8422050798687415	0.8416685740444038
1	0.866069640353638	0.8357448372744355	0.44975974613012076	0.8659146294739672	0.8770323556532091	0.866069640353638	0.9810995110901434	0.9838977386568627	0.8670600067431964	0.866069640353638
2	0.8346256187233555	0.8011491480301005	0.5148018915136486	0.8372998567186071	0.8469141028924154	0.8346256187233555	0.975488717513324	0.9797902990629835	0.8473561083291771	0.8346256187233555
3	0.8455265943749821	0.810406277299284	0.48409801968479604	0.844334531794828	0.8599257227958359	0.845526594374982	0.9775053562954924	0.9808691650309385	0.8499361608036801	0.8455265943749821
4	0.8335669937913078	0.798671390308992	0.5176899180574731	0.834616752932504	0.832441448793213	0.8335669937913078	0.975702541651468	0.9803829951198556	0.8407801814076609	0.8335669937913078
mean	0.8442914842575375	0.8104697729276173	0.48971042354698335	0.8445843293902981	0.8531920577719113	0.8442914842575375	0.9771766879792863	0.9810132790613071	0.8494675074304912	0.8442914842575375
std	0.011757013993524312	0.013278989777247584	0.024885167715119318	0.011154526239733413	0.014807244122941548	0.01175701399352431	0.0020835379911378904	0.0014846365040262035	0.009406233696154596	0.011757013993524312

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 50189.9174 secs

