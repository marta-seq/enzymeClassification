/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_100_pre_terminal_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab3a11aa00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab3a11ac40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab3a11ac70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab3a11aa30>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.59      0.62      0.60      4541
         1.0       0.78      0.77      0.78      3813
         2.0       0.77      0.85      0.81     10869
         3.0       0.77      0.68      0.72      6897
         4.0       0.84      0.78      0.81      2585
         5.0       0.87      0.78      0.82      1617
         6.0       0.93      0.89      0.91      3258
         7.0       0.90      0.86      0.88      1372

    accuracy                           0.77     34952
   macro avg       0.81      0.78      0.79     34952
weighted avg       0.78      0.77      0.77     34952


===confusion_matrix===

[[2817  168  860  538   61   25   33   39]
 [ 181 2923  407  161   75   30   24   12]
 [ 762  214 9233  435  100   43   50   32]
 [ 814  208  929 4697   92   58   67   32]
 [  76   88  247  110 2023   22   15    4]
 [  58   47  140   69   20 1265   16    2]
 [  54   56  162   57   24   14 2886    5]
 [  53   25   76   32    6    2    3 1175]]

===multilabel confusion matrix===

[[[28413  1998]
  [ 1724  2817]]

 [[30333   806]
  [  890  2923]]

 [[21262  2821]
  [ 1636  9233]]

 [[26653  1402]
  [ 2200  4697]]

 [[31989   378]
  [  562  2023]]

 [[33141   194]
  [  352  1265]]

 [[31486   208]
  [  372  2886]]

 [[33454   126]
  [  197  1175]]]

===scores report===
metrics	scores
Accuracy	0.7730
MCC	0.7213
log_loss	0.7165
f1 score weighted	0.7732
f1 score macro	0.7909
f1 score micro	0.7730
roc_auc ovr	0.9519
roc_auc ovo	0.9597
precision	0.7765
recall	0.7730

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab3a11aa00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab3a11ac40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab3a11ac70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab3a11aa30>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.60      0.55      0.57      4541
         1.0       0.71      0.77      0.74      3813
         2.0       0.77      0.83      0.80     10869
         3.0       0.75      0.70      0.72      6897
         4.0       0.80      0.76      0.78      2585
         5.0       0.79      0.80      0.79      1616
         6.0       0.91      0.90      0.90      3258
         7.0       0.96      0.82      0.88      1372

    accuracy                           0.76     34951
   macro avg       0.79      0.77      0.77     34951
weighted avg       0.76      0.76      0.76     34951


===confusion_matrix===

[[2512  312  892  618   92   55   41   19]
 [ 128 2949  387  197   59   49   38    6]
 [ 662  379 8985  497  149  106   82    9]
 [ 659  257  836 4821  131   91   87   15]
 [  73   99  229  148 1977   36   22    1]
 [  57   47  111   69   23 1297   12    0]
 [  40   54  147   56   30   14 2917    0]
 [  70   37   83   42    8    4    5 1123]]

===multilabel confusion matrix===

[[[28721  1689]
  [ 2029  2512]]

 [[29953  1185]
  [  864  2949]]

 [[21397  2685]
  [ 1884  8985]]

 [[26427  1627]
  [ 2076  4821]]

 [[31874   492]
  [  608  1977]]

 [[32980   355]
  [  319  1297]]

 [[31406   287]
  [  341  2917]]

 [[33529    50]
  [  249  1123]]]

===scores report===
metrics	scores
Accuracy	0.7605
MCC	0.7062
log_loss	0.7256
f1 score weighted	0.7595
f1 score macro	0.7748
f1 score micro	0.7605
roc_auc ovr	0.9476
roc_auc ovo	0.9560
precision	0.7605
recall	0.7605

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab3a11aa00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab3a11ac40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab3a11ac70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab3a11aa30>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.55      0.66      0.60      4542
         1.0       0.81      0.74      0.77      3814
         2.0       0.79      0.81      0.80     10869
         3.0       0.74      0.69      0.71      6896
         4.0       0.79      0.78      0.78      2584
         5.0       0.90      0.77      0.83      1616
         6.0       0.93      0.88      0.91      3258
         7.0       0.87      0.88      0.87      1372

    accuracy                           0.76     34951
   macro avg       0.80      0.78      0.78     34951
weighted avg       0.77      0.76      0.77     34951


===confusion_matrix===

[[3018  133  725  517   59   22   27   41]
 [ 229 2809  355  258   91   18   35   19]
 [ 943  236 8811  539  177   38   72   53]
 [ 983  158  752 4740  123   31   55   54]
 [ 115   45  229  147 2006   16   21    5]
 [  84   47  125   78   34 1238    7    3]
 [  65   25  146   87   30   10 2883   12]
 [  60   20   45   31    7    1    4 1204]]

===multilabel confusion matrix===

[[[27930  2479]
  [ 1524  3018]]

 [[30473   664]
  [ 1005  2809]]

 [[21705  2377]
  [ 2058  8811]]

 [[26398  1657]
  [ 2156  4740]]

 [[31846   521]
  [  578  2006]]

 [[33199   136]
  [  378  1238]]

 [[31472   221]
  [  375  2883]]

 [[33392   187]
  [  168  1204]]]

===scores report===
metrics	scores
Accuracy	0.7642
MCC	0.7116
log_loss	0.6941
f1 score weighted	0.7664
f1 score macro	0.7844
f1 score micro	0.7642
roc_auc ovr	0.9486
roc_auc ovo	0.9574
precision	0.7716
recall	0.7642

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab3a11aa00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab3a11ac40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab3a11ac70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab3a11aa30>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.57      0.63      0.60      4542
         1.0       0.78      0.77      0.78      3813
         2.0       0.80      0.83      0.81     10868
         3.0       0.76      0.71      0.74      6897
         4.0       0.85      0.78      0.82      2585
         5.0       0.85      0.78      0.81      1616
         6.0       0.93      0.89      0.91      3258
         7.0       0.88      0.87      0.87      1372

    accuracy                           0.78     34951
   macro avg       0.80      0.78      0.79     34951
weighted avg       0.78      0.78      0.78     34951


===confusion_matrix===

[[2862  181  750  566   54   46   33   50]
 [ 197 2945  350  198   50   30   25   18]
 [ 832  245 9004  508  120   50   60   49]
 [ 823  224  686 4928   82   58   54   42]
 [ 107   85  204  115 2029   26   18    1]
 [  78   33  113   91   21 1261   14    5]
 [  72   38  141   65   28   13 2898    3]
 [  59   21   53   35    5    3    2 1194]]

===multilabel confusion matrix===

[[[28241  2168]
  [ 1680  2862]]

 [[30311   827]
  [  868  2945]]

 [[21786  2297]
  [ 1864  9004]]

 [[26476  1578]
  [ 1969  4928]]

 [[32006   360]
  [  556  2029]]

 [[33109   226]
  [  355  1261]]

 [[31487   206]
  [  360  2898]]

 [[33411   168]
  [  178  1194]]]

===scores report===
metrics	scores
Accuracy	0.7760
MCC	0.7255
log_loss	0.7009
f1 score weighted	0.7773
f1 score macro	0.7919
f1 score micro	0.7760
roc_auc ovr	0.9530
roc_auc ovo	0.9608
precision	0.7798
recall	0.7760

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab3a11aa00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab3a11ac40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab3a11ac70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab3a11aa30>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.60      0.62      0.61      4542
         1.0       0.81      0.77      0.79      3813
         2.0       0.81      0.82      0.81     10868
         3.0       0.72      0.74      0.73      6897
         4.0       0.81      0.80      0.81      2585
         5.0       0.87      0.79      0.83      1616
         6.0       0.91      0.91      0.91      3258
         7.0       0.90      0.86      0.88      1372

    accuracy                           0.78     34951
   macro avg       0.80      0.79      0.80     34951
weighted avg       0.78      0.78      0.78     34951


===confusion_matrix===

[[2798  160  650  709   89   31   60   45]
 [ 151 2922  349  248   72   28   27   16]
 [ 798  230 8894  635  134   58   84   35]
 [ 697  151  657 5137  108   47   73   27]
 [  83   64  168  162 2060   19   25    4]
 [  52   34  118   89   33 1275   13    2]
 [  35   29  109  101   22    4 2955    3]
 [  57   14   54   46   11    2    6 1182]]

===multilabel confusion matrix===

[[[28536  1873]
  [ 1744  2798]]

 [[30456   682]
  [  891  2922]]

 [[21978  2105]
  [ 1974  8894]]

 [[26064  1990]
  [ 1760  5137]]

 [[31897   469]
  [  525  2060]]

 [[33146   189]
  [  341  1275]]

 [[31405   288]
  [  303  2955]]

 [[33447   132]
  [  190  1182]]]

===scores report===
metrics	scores
Accuracy	0.7789
MCC	0.7291
log_loss	0.6938
f1 score weighted	0.7796
f1 score macro	0.7955
f1 score micro	0.7789
roc_auc ovr	0.9539
roc_auc ovo	0.9618
precision	0.7807
recall	0.7789

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7730315861753262	0.7213318425223121	0.7165444795514679	0.7732183064964108	0.7909414594631291	0.7730315861753262	0.9518741074199126	0.9597033390966596	0.7765091941668006	0.7730315861753262
1	0.7605218734800149	0.706195828872789	0.7256153345245866	0.7595132718916258	0.7747632110172882	0.7605218734800149	0.9475611370558396	0.9559894393545397	0.7604536657387004	0.7605218734800149
2	0.764184143515207	0.711555417627473	0.6940745095409834	0.7664424859804969	0.7844008631334067	0.7641841435152071	0.94861933235101	0.9573777512764666	0.7716199316454402	0.764184143515207
3	0.7759720751909817	0.7255037564426065	0.7009046750584206	0.7772538471350388	0.791909249741467	0.7759720751909817	0.9529780192449051	0.9607683622300465	0.7798038768993448	0.7759720751909817
4	0.7788904466252754	0.7290516577456709	0.6938125922903008	0.7795614017086772	0.795518801820833	0.7788904466252754	0.9539347650268064	0.9617952819236351	0.7807302198124625	0.7788904466252754
mean	0.770520024997361	0.7187277006421703	0.7061903181931519	0.7711978626424498	0.7875067170352248	0.7705200249973612	0.9509934722196947	0.9591268347762695	0.7738233776525497	0.770520024997361
std	0.007017167192153688	0.008576363228135644	0.012747382932040249	0.00734641675192861	0.007313228103593905	0.0070171671921536675	0.0024812341050943175	0.002147096779970058	0.0074066027458836855	0.007017167192153688

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 22137.6263 secs

