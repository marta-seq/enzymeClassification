/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_100_pre_middle_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff44279aa30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff44279a760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff44279abe0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff44279aa00>, 'x_test': array([[[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.63      0.63      0.63      4541
         1.0       0.71      0.79      0.75      3813
         2.0       0.83      0.80      0.82     10869
         3.0       0.76      0.74      0.75      6897
         4.0       0.77      0.84      0.80      2585
         5.0       0.89      0.76      0.82      1617
         6.0       0.86      0.88      0.87      3258
         7.0       0.89      0.90      0.90      1372

    accuracy                           0.78     34952
   macro avg       0.79      0.79      0.79     34952
weighted avg       0.78      0.78      0.78     34952


===confusion_matrix===

[[2869  286  595  522   91   21  100   57]
 [ 148 3010  216  247   94   21   59   18]
 [ 759  374 8740  572  220   46  123   35]
 [ 556  329  562 5091  177   43  113   26]
 [  52   78  146  111 2161   11   23    3]
 [  76   57  103   89   33 1227   22   10]
 [  50   69  121   89   39    8 2877    5]
 [  55   15   30   18    7    1   10 1236]]

===multilabel confusion matrix===

[[[28715  1696]
  [ 1672  2869]]

 [[29931  1208]
  [  803  3010]]

 [[22310  1773]
  [ 2129  8740]]

 [[26407  1648]
  [ 1806  5091]]

 [[31706   661]
  [  424  2161]]

 [[33184   151]
  [  390  1227]]

 [[31244   450]
  [  381  2877]]

 [[33426   154]
  [  136  1236]]]

===scores report===
metrics	scores
Accuracy	0.7785
MCC	0.7301
log_loss	0.6666
f1 score weighted	0.7788
f1 score macro	0.7914
f1 score micro	0.7785
roc_auc ovr	0.9544
roc_auc ovo	0.9620
precision	0.7804
recall	0.7785

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff44279aa30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff44279a760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff44279abe0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff44279aa00>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.60      0.65      0.62      4541
         1.0       0.85      0.71      0.78      3813
         2.0       0.89      0.73      0.80     10869
         3.0       0.63      0.82      0.72      6897
         4.0       0.86      0.80      0.83      2585
         5.0       0.69      0.83      0.76      1616
         6.0       0.88      0.88      0.88      3258
         7.0       0.92      0.88      0.90      1372

    accuracy                           0.77     34951
   macro avg       0.79      0.79      0.79     34951
weighted avg       0.79      0.77      0.77     34951


===confusion_matrix===

[[2930   92  342  882   46  136   76   37]
 [ 184 2724  175  532   47   79   60   12]
 [ 924  183 7982 1285  148  164  149   34]
 [ 586  108  246 5680   69  115   80   13]
 [  93   35   92  235 2061   36   28    5]
 [  56   20   54  118   15 1341   10    2]
 [  66   29   67  160   16   52 2867    1]
 [  59    6   13   57    8   10    5 1214]]

===multilabel confusion matrix===

[[[28442  1968]
  [ 1611  2930]]

 [[30665   473]
  [ 1089  2724]]

 [[23093   989]
  [ 2887  7982]]

 [[24785  3269]
  [ 1217  5680]]

 [[32017   349]
  [  524  2061]]

 [[32743   592]
  [  275  1341]]

 [[31285   408]
  [  391  2867]]

 [[33475   104]
  [  158  1214]]]

===scores report===
metrics	scores
Accuracy	0.7668
MCC	0.7198
log_loss	0.7075
f1 score weighted	0.7704
f1 score macro	0.7851
f1 score micro	0.7668
roc_auc ovr	0.9520
roc_auc ovo	0.9608
precision	0.7857
recall	0.7668

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff44279aa30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff44279a760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff44279abe0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff44279aa00>, 'x_test': array([[[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.60      0.67      0.63      4542
         1.0       0.82      0.75      0.78      3814
         2.0       0.81      0.82      0.82     10869
         3.0       0.77      0.74      0.75      6896
         4.0       0.84      0.80      0.82      2584
         5.0       0.83      0.78      0.80      1616
         6.0       0.85      0.90      0.87      3258
         7.0       0.93      0.88      0.91      1372

    accuracy                           0.78     34951
   macro avg       0.81      0.79      0.80     34951
weighted avg       0.79      0.78      0.78     34951


===confusion_matrix===

[[3041  139  653  498   45   52   95   19]
 [ 197 2865  319  250   67   41   64   11]
 [ 890  171 8925  509  118   72  158   26]
 [ 674  185  626 5087  106   62  132   24]
 [  78   63  174  140 2076   20   28    5]
 [  87   23  125   62   25 1259   32    3]
 [  44   42  140   66   18   12 2932    4]
 [  61   16   37   25    4    3   13 1213]]

===multilabel confusion matrix===

[[[28378  2031]
  [ 1501  3041]]

 [[30498   639]
  [  949  2865]]

 [[22008  2074]
  [ 1944  8925]]

 [[26505  1550]
  [ 1809  5087]]

 [[31984   383]
  [  508  2076]]

 [[33073   262]
  [  357  1259]]

 [[31171   522]
  [  326  2932]]

 [[33487    92]
  [  159  1213]]]

===scores report===
metrics	scores
Accuracy	0.7839
MCC	0.7357
log_loss	0.6554
f1 score weighted	0.7848
f1 score macro	0.7987
f1 score micro	0.7839
roc_auc ovr	0.9559
roc_auc ovo	0.9632
precision	0.7870
recall	0.7839

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff44279aa30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff44279a760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff44279abe0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff44279aa00>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.62      0.61      0.62      4542
         1.0       0.85      0.74      0.79      3813
         2.0       0.82      0.84      0.83     10868
         3.0       0.71      0.80      0.75      6897
         4.0       0.88      0.82      0.85      2585
         5.0       0.80      0.81      0.80      1616
         6.0       0.93      0.88      0.90      3258
         7.0       0.96      0.89      0.92      1372

    accuracy                           0.79     34951
   macro avg       0.82      0.80      0.81     34951
weighted avg       0.80      0.79      0.79     34951


===confusion_matrix===

[[2771  138  651  792   36   76   51   27]
 [ 165 2821  313  379   56   48   23    8]
 [ 758  136 9091  628   96   91   58   10]
 [ 515  132  537 5533   59   71   45    5]
 [  64   43  149  188 2108   21   10    2]
 [  60   24   97  104   17 1301   13    0]
 [  65   19  157  118   18   20 2858    3]
 [  60    7   35   36    3    5    2 1224]]

===multilabel confusion matrix===

[[[28722  1687]
  [ 1771  2771]]

 [[30639   499]
  [  992  2821]]

 [[22144  1939]
  [ 1777  9091]]

 [[25809  2245]
  [ 1364  5533]]

 [[32081   285]
  [  477  2108]]

 [[33003   332]
  [  315  1301]]

 [[31491   202]
  [  400  2858]]

 [[33524    55]
  [  148  1224]]]

===scores report===
metrics	scores
Accuracy	0.7927
MCC	0.7459
log_loss	0.6532
f1 score weighted	0.7936
f1 score macro	0.8084
f1 score micro	0.7927
roc_auc ovr	0.9590
roc_auc ovo	0.9656
precision	0.7968
recall	0.7927

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff44279aa30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff44279a760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff44279abe0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff44279aa00>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.51      0.59      4542
         1.0       0.70      0.80      0.75      3813
         2.0       0.82      0.81      0.81     10868
         3.0       0.70      0.77      0.73      6897
         4.0       0.95      0.75      0.84      2585
         5.0       0.87      0.78      0.82      1616
         6.0       0.73      0.93      0.82      3258
         7.0       0.90      0.88      0.89      1372

    accuracy                           0.77     34951
   macro avg       0.79      0.78      0.78     34951
weighted avg       0.77      0.77      0.77     34951


===confusion_matrix===

[[2323  329  685  850   13   44  239   59]
 [  64 3055  253  264   12   20  131   14]
 [ 512  377 8769  734   40   58  347   31]
 [ 335  350  602 5296   21   42  233   18]
 [  40  107  177  213 1939   20   87    2]
 [  41   50   85  113    5 1262   50   10]
 [  23   44   71   88    3    8 3019    2]
 [  34   27   48   38    1    4   18 1202]]

===multilabel confusion matrix===

[[[29360  1049]
  [ 2219  2323]]

 [[29854  1284]
  [  758  3055]]

 [[22162  1921]
  [ 2099  8769]]

 [[25754  2300]
  [ 1601  5296]]

 [[32271    95]
  [  646  1939]]

 [[33139   196]
  [  354  1262]]

 [[30588  1105]
  [  239  3019]]

 [[33443   136]
  [  170  1202]]]

===scores report===
metrics	scores
Accuracy	0.7686
MCC	0.7181
log_loss	0.7034
f1 score weighted	0.7664
f1 score macro	0.7808
f1 score micro	0.7686
roc_auc ovr	0.9534
roc_auc ovo	0.9611
precision	0.7730
recall	0.7686

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7785248340581369	0.7300876721893637	0.6665719607175675	0.7788150388308394	0.7914308486846524	0.778524834058137	0.9543921424250988	0.9620113418923185	0.780438266912145	0.7785248340581369
1	0.7667591771337015	0.7198292538500346	0.7074972293661462	0.7703628181552157	0.7850965415167303	0.7667591771337015	0.9519683050285085	0.960765205020724	0.7857068067674469	0.7667591771337015
2	0.7838974564390147	0.7356810390303039	0.6554326571116966	0.7848229289287137	0.7986959564302614	0.7838974564390147	0.9558930477743017	0.9632119701775194	0.7870100493176374	0.7838974564390147
3	0.7927384051958456	0.7458751596963175	0.6531845928966128	0.793551481634919	0.8083818864177299	0.7927384051958456	0.9590493573443023	0.9656298750336773	0.7967554426778822	0.7927384051958456
4	0.7686475351205974	0.7180621958405294	0.7034301406562529	0.766369181583573	0.7808260232449007	0.7686475351205974	0.9533562884157563	0.9611376387458034	0.7730236588466176	0.7686475351205974
mean	0.7781134815894591	0.7299070641213097	0.6772233161496553	0.7787842898266522	0.792886251258855	0.7781134815894593	0.9549318281975936	0.9625512061740086	0.7845868449043458	0.7781134815894591
std	0.009654391111114295	0.010297714758813	0.023534875744923023	0.009793795580963756	0.009819513811016744	0.009654391111114297	0.002426274727211748	0.001754664495115251	0.007824563593460336	0.009654391111114295

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 22506.5459 secs

