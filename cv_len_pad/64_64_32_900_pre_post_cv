/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_900_pre_post_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc82869b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc82869b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc82869b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc82869b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.70      0.77      4541
         1.0       0.84      0.88      0.86      3813
         2.0       0.94      0.83      0.89     10869
         3.0       0.70      0.93      0.80      6897
         4.0       0.86      0.86      0.86      2585
         5.0       0.93      0.84      0.88      1617
         6.0       0.98      0.94      0.96      3258
         7.0       0.97      0.95      0.96      1372

    accuracy                           0.86     34952
   macro avg       0.88      0.87      0.87     34952
weighted avg       0.87      0.86      0.86     34952


===confusion_matrix===

[[3180  128  245  859   63   28   11   27]
 [  36 3338   96  266   51   14    6    6]
 [ 262  233 9075 1137  110   22   28    2]
 [ 173  115  110 6382   75   24   14    4]
 [  36   61   53  183 2226   13   11    2]
 [  25   43   20  125   44 1351    6    3]
 [  13   27   25  104    7    7 3075    0]
 [  32   10    8   19    0    0    2 1301]]

===multilabel confusion matrix===

[[[29834   577]
  [ 1361  3180]]

 [[30522   617]
  [  475  3338]]

 [[23526   557]
  [ 1794  9075]]

 [[25362  2693]
  [  515  6382]]

 [[32017   350]
  [  359  2226]]

 [[33227   108]
  [  266  1351]]

 [[31616    78]
  [  183  3075]]

 [[33536    44]
  [   71  1301]]]

===scores report===
metrics	scores
Accuracy	0.8563
MCC	0.8275
log_loss	0.4444
f1 score weighted	0.8578
f1 score macro	0.8710
f1 score micro	0.8563
roc_auc ovr	0.9824
roc_auc ovo	0.9854
precision	0.8694
recall	0.8563

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc82869b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc82869b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc82869b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc82869b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.55      0.64      4541
         1.0       0.93      0.31      0.47      3813
         2.0       0.52      0.93      0.67     10869
         3.0       0.68      0.63      0.66      6897
         4.0       0.85      0.37      0.51      2585
         5.0       0.98      0.35      0.51      1616
         6.0       0.99      0.55      0.71      3258
         7.0       0.96      0.79      0.87      1372

    accuracy                           0.65     34951
   macro avg       0.83      0.56      0.63     34951
weighted avg       0.73      0.65      0.63     34951


===confusion_matrix===

[[ 2509     7  1425   566    13     0     3    18]
 [   83  1196  2079   411    33     2     3     6]
 [  249    20 10102   462    26     4     2     4]
 [  304    27  2187  4333    26     4     5    11]
 [   45    12  1320   251   954     1     1     1]
 [   67    12   729   169    67   562     9     1]
 [   11     5  1356    85     0     1  1800     0]
 [   39    12   174    56     1     0     2  1088]]

===multilabel confusion matrix===

[[[29612   798]
  [ 2032  2509]]

 [[31043    95]
  [ 2617  1196]]

 [[14812  9270]
  [  767 10102]]

 [[26054  2000]
  [ 2564  4333]]

 [[32200   166]
  [ 1631   954]]

 [[33323    12]
  [ 1054   562]]

 [[31668    25]
  [ 1458  1800]]

 [[33538    41]
  [  284  1088]]]

===scores report===
metrics	scores
Accuracy	0.6450
MCC	0.5665
log_loss	1.0824
f1 score weighted	0.6332
f1 score macro	0.6297
f1 score micro	0.6450
roc_auc ovr	0.9191
roc_auc ovo	0.9244
precision	0.7349
recall	0.6450

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc82869b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc82869b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc82869b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc82869b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.79      0.80      4542
         1.0       0.91      0.85      0.88      3814
         2.0       0.88      0.92      0.90     10869
         3.0       0.86      0.86      0.86      6896
         4.0       0.91      0.85      0.88      2584
         5.0       0.89      0.85      0.87      1616
         6.0       0.96      0.96      0.96      3258
         7.0       0.96      0.95      0.96      1372

    accuracy                           0.88     34951
   macro avg       0.90      0.88      0.89     34951
weighted avg       0.88      0.88      0.88     34951


===confusion_matrix===

[[ 3610    72   373   374    31    36    18    28]
 [  100  3244   221   152    42    21    21    13]
 [  346    78 10028   268    70    35    43     1]
 [  338    82   442  5912    50    44    17    11]
 [   39    38   179    99  2187    33     9     0]
 [   37    30    68    65    23  1380    12     1]
 [    9    20    47    31     6     6  3138     1]
 [   27    10    16     7     1     1     4  1306]]

===multilabel confusion matrix===

[[[29513   896]
  [  932  3610]]

 [[30807   330]
  [  570  3244]]

 [[22736  1346]
  [  841 10028]]

 [[27059   996]
  [  984  5912]]

 [[32144   223]
  [  397  2187]]

 [[33159   176]
  [  236  1380]]

 [[31569   124]
  [  120  3138]]

 [[33524    55]
  [   66  1306]]]

===scores report===
metrics	scores
Accuracy	0.8814
MCC	0.8545
log_loss	0.3811
f1 score weighted	0.8812
f1 score macro	0.8873
f1 score micro	0.8814
roc_auc ovr	0.9844
roc_auc ovo	0.9868
precision	0.8816
recall	0.8814

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc82869b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc82869b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc82869b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc82869b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.77      0.79      4542
         1.0       0.89      0.84      0.87      3813
         2.0       0.89      0.91      0.90     10868
         3.0       0.82      0.86      0.84      6897
         4.0       0.86      0.86      0.86      2585
         5.0       0.95      0.81      0.88      1616
         6.0       0.93      0.96      0.94      3258
         7.0       0.94      0.96      0.95      1372

    accuracy                           0.87     34951
   macro avg       0.89      0.87      0.88     34951
weighted avg       0.87      0.87      0.87     34951


===confusion_matrix===

[[3479   88  351  495   46   11   24   48]
 [  68 3201  226  184   62   15   48    9]
 [ 344   98 9912  349   67   17   77    4]
 [ 298  103  395 5920  108   13   49   11]
 [  36   50  128  130 2225    6    9    1]
 [  41   29   67   77   50 1310   41    1]
 [  23   10   68   19    8    3 3124    3]
 [  14    3   12   16    8    0    2 1317]]

===multilabel confusion matrix===

[[[29585   824]
  [ 1063  3479]]

 [[30757   381]
  [  612  3201]]

 [[22836  1247]
  [  956  9912]]

 [[26784  1270]
  [  977  5920]]

 [[32017   349]
  [  360  2225]]

 [[33270    65]
  [  306  1310]]

 [[31443   250]
  [  134  3124]]

 [[33502    77]
  [   55  1317]]]

===scores report===
metrics	scores
Accuracy	0.8723
MCC	0.8435
log_loss	0.4007
f1 score weighted	0.8719
f1 score macro	0.8782
f1 score micro	0.8723
roc_auc ovr	0.9830
roc_auc ovo	0.9856
precision	0.8726
recall	0.8723

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc82869b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc82869b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc82869b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc82869b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.69      0.71      4542
         1.0       0.89      0.67      0.77      3813
         2.0       0.85      0.80      0.83     10868
         3.0       0.64      0.83      0.72      6897
         4.0       0.72      0.69      0.71      2585
         5.0       0.69      0.69      0.69      1616
         6.0       0.91      0.93      0.92      3258
         7.0       0.96      0.87      0.91      1372

    accuracy                           0.78     34951
   macro avg       0.80      0.77      0.78     34951
weighted avg       0.79      0.78      0.78     34951


===confusion_matrix===

[[3121   64  330  925   42   25   16   19]
 [  94 2568  323  544  205   23   46   10]
 [ 451   95 8717 1103  197  156  143    6]
 [ 345   81  473 5721  123   91   55    8]
 [  62   55  164  334 1787  166   16    1]
 [  52   12   98  197  105 1121   31    0]
 [  16    7   86   73   14   43 3018    1]
 [  63    6   59   43    1    3    6 1191]]

===multilabel confusion matrix===

[[[29326  1083]
  [ 1421  3121]]

 [[30818   320]
  [ 1245  2568]]

 [[22550  1533]
  [ 2151  8717]]

 [[24835  3219]
  [ 1176  5721]]

 [[31679   687]
  [  798  1787]]

 [[32828   507]
  [  495  1121]]

 [[31380   313]
  [  240  3018]]

 [[33534    45]
  [  181  1191]]]

===scores report===
metrics	scores
Accuracy	0.7795
MCC	0.7318
log_loss	0.6591
f1 score weighted	0.7811
f1 score macro	0.7819
f1 score micro	0.7795
roc_auc ovr	0.9559
roc_auc ovo	0.9607
precision	0.7917
recall	0.7795

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8562600137331197	0.8274626774410968	0.44441331712923277	0.8577848569625904	0.8710429841451723	0.8562600137331197	0.9824283914813062	0.9854254403176684	0.8694247361691783	0.8562600137331197
1	0.6450173099482132	0.5665342359381697	1.0823826773364966	0.6332168021305151	0.6297116967902081	0.6450173099482132	0.9190588014733099	0.9243807326187724	0.734859087658654	0.6450173099482132
2	0.881376784641355	0.8545183323081055	0.381134704894849	0.8811640890103632	0.8873318739676966	0.881376784641355	0.9844459965539597	0.9867512175799158	0.8816341130611033	0.881376784641355
3	0.8723069440073246	0.8434982344213099	0.4007229114805653	0.8718805505765821	0.8782206097689736	0.8723069440073246	0.983046620738225	0.9855703267185955	0.872617701208752	0.8723069440073246
4	0.7794912878029241	0.7318279230727848	0.6590515443271013	0.7810909202780769	0.781898629914737	0.7794912878029241	0.955858301778865	0.9606656745371636	0.7917497167936941	0.7794912878029241
mean	0.8068904680265871	0.7647682806362933	0.5935410310336491	0.8050274437916256	0.8096411589173576	0.8068904680265871	0.9649676224051331	0.9685586783544231	0.8300570709782763	0.8068904680265871
std	0.08856468045337065	0.1082274165104124	0.2637393153013699	0.09288845463498012	0.09762523411728741	0.08856468045337065	0.025305079563452966	0.024161302619451167	0.05753524309665868	0.08856468045337065

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 123504.6182 secs

