/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_500_pre_eliminate_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_500_pre_eliminate_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c6db1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fee2c6db370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fee2c6db3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fee2c6db1c0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.75      0.80      2805
         1.0       0.79      0.93      0.85      3048
         2.0       0.93      0.90      0.91      8795
         3.0       0.90      0.81      0.85      5129
         4.0       0.70      0.92      0.79      2201
         5.0       0.88      0.88      0.88      1393
         6.0       0.99      0.93      0.96      1850
         7.0       0.97      0.96      0.97      1005

    accuracy                           0.87     26226
   macro avg       0.88      0.88      0.88     26226
weighted avg       0.88      0.87      0.88     26226


===confusion_matrix===

[[2099  165  163  196  100   61    4   17]
 [  28 2822   53   54   73   11    3    4]
 [ 139  244 7938  141  292   27    7    7]
 [ 153  209  271 4150  300   41    2    3]
 [  17   59   54   41 2015   14    1    0]
 [   9   38   29   23   63 1229    0    2]
 [   3   28   43    4   42   18 1712    0]
 [   9   10    8    8    1    0    0  969]]

===multilabel confusion matrix===

[[[23063   358]
  [  706  2099]]

 [[22425   753]
  [  226  2822]]

 [[16810   621]
  [  857  7938]]

 [[20630   467]
  [  979  4150]]

 [[23154   871]
  [  186  2015]]

 [[24661   172]
  [  164  1229]]

 [[24359    17]
  [  138  1712]]

 [[25188    33]
  [   36   969]]]

===scores report===
metrics	scores
Accuracy	0.8745
MCC	0.8463
log_loss	0.4167
f1 score weighted	0.8754
f1 score macro	0.8763
f1 score micro	0.8745
roc_auc ovr	0.9858
roc_auc ovo	0.9879
precision	0.8820
recall	0.8745

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c6db1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fee2c6db370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fee2c6db3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fee2c6db1c0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.79      0.81      2805
         1.0       0.88      0.90      0.89      3049
         2.0       0.91      0.95      0.93      8795
         3.0       0.91      0.86      0.88      5129
         4.0       0.85      0.90      0.87      2200
         5.0       0.91      0.89      0.90      1393
         6.0       0.96      0.95      0.96      1851
         7.0       0.97      0.95      0.96      1004

    accuracy                           0.90     26226
   macro avg       0.90      0.90      0.90     26226
weighted avg       0.90      0.90      0.90     26226


===confusion_matrix===

[[2227   78  216  178   56   22   11   17]
 [  58 2738  121   59   33   22   12    6]
 [ 132   97 8312  117   96   22   16    3]
 [ 180  113  260 4393  131   23   24    5]
 [  28   31   84   60 1975   19    3    0]
 [  26   25   45   24   30 1235    8    0]
 [  13   10   39   10    7    7 1765    0]
 [  22    9   10    6    1    0    5  951]]

===multilabel confusion matrix===

[[[22962   459]
  [  578  2227]]

 [[22814   363]
  [  311  2738]]

 [[16656   775]
  [  483  8312]]

 [[20643   454]
  [  736  4393]]

 [[23672   354]
  [  225  1975]]

 [[24718   115]
  [  158  1235]]

 [[24296    79]
  [   86  1765]]

 [[25191    31]
  [   53   951]]]

===scores report===
metrics	scores
Accuracy	0.8997
MCC	0.8758
log_loss	0.3780
f1 score weighted	0.8994
f1 score macro	0.8997
f1 score micro	0.8997
roc_auc ovr	0.9888
roc_auc ovo	0.9901
precision	0.8997
recall	0.8997

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c6db1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fee2c6db370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fee2c6db3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fee2c6db1c0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.69      0.76      2805
         1.0       0.97      0.76      0.86      3049
         2.0       0.92      0.91      0.92      8795
         3.0       0.74      0.93      0.83      5128
         4.0       0.93      0.81      0.87      2200
         5.0       0.70      0.91      0.79      1394
         6.0       0.94      0.95      0.94      1851
         7.0       0.98      0.95      0.96      1004

    accuracy                           0.87     26226
   macro avg       0.88      0.86      0.87     26226
weighted avg       0.88      0.87      0.87     26226


===confusion_matrix===

[[1922   19  211  523   15   90   19    6]
 [  62 2327  152  310   36  130   30    2]
 [  87   11 7982  501   44  124   40    6]
 [  94   13  156 4760   22   63   15    5]
 [  16   14   86  188 1792   99    5    0]
 [  12    2   19   69   10 1274    7    1]
 [   5    3   27   28    2   32 1754    0]
 [  23    0    5   18    0    6    2  950]]

===multilabel confusion matrix===

[[[23122   299]
  [  883  1922]]

 [[23115    62]
  [  722  2327]]

 [[16775   656]
  [  813  7982]]

 [[19461  1637]
  [  368  4760]]

 [[23897   129]
  [  408  1792]]

 [[24288   544]
  [  120  1274]]

 [[24257   118]
  [   97  1754]]

 [[25202    20]
  [   54   950]]]

===scores report===
metrics	scores
Accuracy	0.8679
MCC	0.8381
log_loss	0.4475
f1 score weighted	0.8684
f1 score macro	0.8663
f1 score micro	0.8679
roc_auc ovr	0.9846
roc_auc ovo	0.9862
precision	0.8803
recall	0.8679

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c6db1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fee2c6db370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fee2c6db3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fee2c6db1c0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.73      0.74      2805
         1.0       0.73      0.87      0.80      3049
         2.0       0.94      0.82      0.88      8795
         3.0       0.77      0.85      0.81      5128
         4.0       0.81      0.84      0.82      2200
         5.0       0.84      0.82      0.83      1394
         6.0       0.95      0.93      0.94      1851
         7.0       0.95      0.94      0.94      1004

    accuracy                           0.84     26226
   macro avg       0.84      0.85      0.84     26226
weighted avg       0.85      0.84      0.84     26226


===confusion_matrix===

[[2061  154  122  348   48   35   12   25]
 [  61 2666   63  153   57   25   13   11]
 [ 307  425 7241  527  180   67   43    5]
 [ 224  200  151 4375  107   45   14   12]
 [  38   91   57  142 1842   25    5    0]
 [  26   68   21   79   43 1147    9    1]
 [  13   33   30   36    8   18 1713    0]
 [  23   14    4   18    1    1    2  941]]

===multilabel confusion matrix===

[[[22729   692]
  [  744  2061]]

 [[22192   985]
  [  383  2666]]

 [[16983   448]
  [ 1554  7241]]

 [[19795  1303]
  [  753  4375]]

 [[23582   444]
  [  358  1842]]

 [[24616   216]
  [  247  1147]]

 [[24277    98]
  [  138  1713]]

 [[25168    54]
  [   63   941]]]

===scores report===
metrics	scores
Accuracy	0.8383
MCC	0.8031
log_loss	0.4984
f1 score weighted	0.8400
f1 score macro	0.8445
f1 score micro	0.8383
roc_auc ovr	0.9767
roc_auc ovo	0.9802
precision	0.8467
recall	0.8383

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c6db1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fee2c6db370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fee2c6db3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fee2c6db1c0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.78      0.81      2805
         1.0       0.92      0.89      0.91      3048
         2.0       0.94      0.93      0.94      8794
         3.0       0.87      0.89      0.88      5129
         4.0       0.84      0.91      0.88      2201
         5.0       0.83      0.91      0.87      1393
         6.0       0.98      0.94      0.96      1851
         7.0       0.96      0.96      0.96      1005

    accuracy                           0.90     26226
   macro avg       0.90      0.90      0.90     26226
weighted avg       0.90      0.90      0.90     26226


===confusion_matrix===

[[2190   66  144  290   51   43    4   17]
 [  46 2727   75  101   60   25    7    7]
 [ 155   65 8188  190  116   68   11    1]
 [ 165   60  137 4583  102   71    3    8]
 [  15   27   53   62 2009   31    3    1]
 [  24    5   43   31   23 1266    0    1]
 [  10    9   30   14   18   21 1748    1]
 [  19    1    1   10    6    0    2  966]]

===multilabel confusion matrix===

[[[22987   434]
  [  615  2190]]

 [[22945   233]
  [  321  2727]]

 [[16949   483]
  [  606  8188]]

 [[20399   698]
  [  546  4583]]

 [[23649   376]
  [  192  2009]]

 [[24574   259]
  [  127  1266]]

 [[24345    30]
  [  103  1748]]

 [[25185    36]
  [   39   966]]]

===scores report===
metrics	scores
Accuracy	0.9028
MCC	0.8800
log_loss	0.3382
f1 score weighted	0.9029
f1 score macro	0.9003
f1 score micro	0.9028
roc_auc ovr	0.9898
roc_auc ovo	0.9909
precision	0.9038
recall	0.9028

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8744757111263631	0.8463439387616206	0.4167379829839068	0.8754179022035804	0.87633886973646	0.8744757111263631	0.9858467187500183	0.9878935428696606	0.882018342586662	0.8744757111263631
1	0.8997178372607336	0.8757995334046227	0.3779779084848183	0.8993574633350786	0.8996994732806128	0.8997178372607335	0.9888032845507397	0.9901018050582067	0.8996870156092526	0.8997178372607336
2	0.867879203843514	0.8380920367123377	0.44749495206615897	0.868380142360835	0.8662684678714627	0.867879203843514	0.984562628811334	0.9862408557963137	0.8803030263938332	0.867879203843514
3	0.8383283764203462	0.803143360250954	0.49837339750598386	0.8399844763209467	0.8445061622287351	0.8383283764203462	0.9767478457456825	0.9802010799092902	0.8467266834414515	0.8383283764203462
4	0.9028063753527035	0.8799620968521044	0.33816335483938276	0.9028992246609808	0.9003197810807195	0.9028063753527035	0.9898472132938109	0.9908958827684738	0.903815363851641	0.9028063753527035
mean	0.8766415008007321	0.8486681931963279	0.4157495191760502	0.8772078417762843	0.8774265508395981	0.876641500800732	0.9851615382303172	0.9870666332803889	0.882510086376568	0.8766415008007321
std	0.023522253112330003	0.02794704165692876	0.0552842876612259	0.022879527906803296	0.021116916995303128	0.023522253112329982	0.004622472349850892	0.0038046532135347197	0.02017189429624153	0.023522253112330003

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 59037.8287 secs

