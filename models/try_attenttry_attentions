/home/amsequeira/enzymeClassification/models/try_attenttry_attentions
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f24372023a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2437202160>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f24372026d0>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f108c9db880>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f108c9db790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f108c9db820>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f511f6658b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f63b071ba60>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f63b071bb20>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5045fdd100>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5045fdd250>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5045fdd2b0>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.670510858297348)
('Validation Accuracy mean: ', 0.5270075649023056)
('Training Loss mean: ', 1.0051958739757538)
('Validation Loss mean: ', 1.4422008275985718)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500, 21)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 128)          44032     
_________________________________________________________________
bidirectional_1 (Bidirection (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_2 (Bidirection (None, 500, 64)           41216     
_________________________________________________________________
attention (attention)        (None, 64)                564       
_________________________________________________________________
dense (Dense)                (None, 32)                2080      
_________________________________________________________________
batch_normalization (BatchNo (None, 32)                128       
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                528       
_________________________________________________________________
batch_normalization_1 (Batch (None, 16)                64        
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 7)                 119       
=================================================================
Total params: 187,547
Trainable params: 187,451
Non-trainable params: 96
_________________________________________________________________Finished run_model in 2267.5843 secs


===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5045fdd100>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5045fdd250>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5045fdd2b0>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f638cba7190>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f638cba7f40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f63a640e370>]
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f638cba7190>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f638cba7f40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f63a640e370>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f636f070c70>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f636f070280>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f636f0701c0>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.46673426032066345)
('Validation Accuracy mean: ', 0.46719281673431395)
('Training Loss mean: ', 1.4736257791519165)
('Validation Loss mean: ', 1.4589394330978394)
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_4 (Masking)          (None, 500, 21)           0         
_________________________________________________________________
bidirectional_12 (Bidirectio (None, 500, 128)          44032     
_________________________________________________________________
bidirectional_13 (Bidirectio (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_14 (Bidirectio (None, 500, 64)           41216     
_________________________________________________________________
attention_4 (attention)      (None, 64)                564       
_________________________________________________________________
dense_12 (Dense)             (None, 32)                2080      
_________________________________________________________________
batch_normalization_8 (Batch (None, 32)                128       
_________________________________________________________________
dropout_8 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_13 (Dense)             (None, 16)                528       
_________________________________________________________________
batch_normalization_9 (Batch (None, 16)                64        
_________________________________________________________________
dropout_9 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 7)                 119       
=================================================================
Total params: 187,547
Trainable params: 187,451
Non-trainable params: 96
_________________________________________________________________Finished run_model in 625.9692 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f63a8f37e80>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.72      0.23      0.35      3813
           1       0.51      0.73      0.60     10869
           2       0.76      0.21      0.33      6897
           3       0.53      0.38      0.44      2585
           4       0.53      0.07      0.13      1616
           5       0.34      0.89      0.49      3258
           6       0.96      0.75      0.84      1372

    accuracy                           0.50     30410
   macro avg       0.62      0.46      0.45     30410
weighted avg       0.60      0.50      0.47     30410


===confusion_matrix===

[[ 872 1789  139  124   12  867   10]
 [ 159 7934  140  290   18 2323    5]
 [  82 3743 1429  284   63 1267   29]
 [  47  944   63  970   11  549    1]
 [  35  589   74  138  120  657    3]
 [   7  317   13   11    1 2909    0]
 [   2  275   20    3    1   48 1023]]

===multilabel confusion matrix===

[[[26265   332]
  [ 2941   872]]

 [[11884  7657]
  [ 2935  7934]]

 [[23064   449]
  [ 5468  1429]]

 [[26975   850]
  [ 1615   970]]

 [[28688   106]
  [ 1496   120]]

 [[21441  5711]
  [  349  2909]]

 [[28990    48]
  [  349  1023]]]

===scores report===
metrics	scores
Accuracy	0.5017
MCC	0.3687
log_loss	1.3504
f1 score weighted	0.4664
f1 score macro	0.4530
f1 score micro	0.5017
roc_auc ovr	0.8119
roc_auc ovo	0.8398
precision	0.5980
recall	0.5017
