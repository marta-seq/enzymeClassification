/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_hot_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f85a810e490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f85a810e340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f85a810e820>]/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_hot_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83c014e490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83c014e340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83c014e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83c014e7f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.93      0.87       911
         1.0       0.97      0.62      0.76        53
         2.0       0.91      0.83      0.87       179
         3.0       0.67      0.16      0.26        25
         4.0       0.79      0.56      0.66       112
         5.0       0.76      0.71      0.73       491
         6.0       1.00      0.81      0.90        64
         7.0       0.71      0.27      0.39        37
         8.0       0.88      0.85      0.87       206
         9.0       0.89      0.80      0.84        71
        10.0       0.93      0.93      0.93       404
        11.0       0.80      0.50      0.62        16
        12.0       0.80      0.81      0.81       378
        13.0       0.88      0.81      0.84       191
        14.0       0.56      0.13      0.21        76
        15.0       0.85      0.76      0.80        66
        16.0       0.93      0.85      0.89       141
        17.0       0.82      0.79      0.80       182
        18.0       1.00      0.75      0.86        12
        19.0       1.00      0.92      0.96        38
        20.0       0.94      0.92      0.93      2162
        21.0       0.95      0.97      0.96       168
        22.0       0.87      0.82      0.84      1470
        23.0       0.92      0.87      0.89      1259
        24.0       0.94      0.90      0.92       956
        25.0       0.93      0.92      0.93       283
        26.0       0.86      0.93      0.89      3919
        27.0       0.95      0.94      0.94       531
        28.0       1.00      0.67      0.80        12
        29.0       0.80      0.84      0.82      2345
        30.0       0.64      0.79      0.71       615
        31.0       0.95      0.66      0.78        32
        32.0       0.86      0.77      0.81      1449
        33.0       0.77      0.89      0.82       893
        34.0       0.95      0.85      0.90      1377
        35.0       1.00      0.64      0.78        22
        36.0       0.83      0.89      0.86       844
        37.0       0.90      0.89      0.90      1142
        38.0       0.95      0.87      0.91       314
        39.0       0.88      0.62      0.73        56
        40.0       0.92      0.80      0.85       154
        41.0       0.98      0.90      0.94        52
        42.0       0.85      0.78      0.82       247
        43.0       0.93      0.84      0.88       198
        44.0       0.93      0.94      0.93       529
        45.0       0.93      0.88      0.90       540
        46.0       1.00      0.10      0.18        20
        47.0       0.85      0.66      0.75        80
        48.0       0.94      0.99      0.96      1466
        49.0       0.96      0.91      0.93       148
        50.0       0.93      0.96      0.95      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.94      0.95      0.94       151
        53.0       0.97      0.97      0.97       903
        54.0       0.90      0.81      0.85       108
        55.0       0.97      0.96      0.96        93
        56.0       1.00      0.88      0.94        33
        57.0       0.82      0.86      0.84        49
        58.0       0.87      0.92      0.90       154

    accuracy                           0.88     29892
   macro avg       0.87      0.77      0.80     29892
weighted avg       0.88      0.88      0.88     29892


===confusion_matrix===

[[845   0   0 ...   0   0   0]
 [  1  33   0 ...   0   0   0]
 [  0   0 148 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   0]
 [  0   0   0 ...   0  42   6]
 [  0   0   0 ...   0   7 142]]

===multilabel confusion matrix===

[[[28798   183]
  [   66   845]]

 [[29838     1]
  [   20    33]]

 [[29699    14]
  [   31   148]]

 [[29865     2]
  [   21     4]]

 [[29763    17]
  [   49    63]]

 [[29293   108]
  [  144   347]]

 [[29828     0]
  [   12    52]]

 [[29851     4]
  [   27    10]]

 [[29662    24]
  [   30   176]]

 [[29814     7]
  [   14    57]]

 [[29459    29]
  [   30   374]]

 [[29874     2]
  [    8     8]]

 [[29439    75]
  [   70   308]]

 [[29679    22]
  [   36   155]]

 [[29808     8]
  [   66    10]]

 [[29817     9]
  [   16    50]]

 [[29742     9]
  [   21   120]]

 [[29678    32]
  [   38   144]]

 [[29880     0]
  [    3     9]]

 [[29854     0]
  [    3    35]]

 [[27605   125]
  [  166  1996]]

 [[29716     8]
  [    5   163]]

 [[28240   182]
  [  264  1206]]

 [[28534    99]
  [  165  1094]]

 [[28883    53]
  [   99   857]]

 [[29589    20]
  [   22   261]]

 [[25367   606]
  [  270  3649]]

 [[29333    28]
  [   34   497]]

 [[29880     0]
  [    4     8]]

 [[27055   492]
  [  373  1972]]

 [[29010   267]
  [  132   483]]

 [[29859     1]
  [   11    21]]

 [[28257   186]
  [  340  1109]]

 [[28761   238]
  [   99   794]]

 [[28456    59]
  [  203  1174]]

 [[29870     0]
  [    8    14]]

 [[28893   155]
  [   96   748]]

 [[28643   107]
  [  128  1014]]

 [[29563    15]
  [   42   272]]

 [[29831     5]
  [   21    35]]

 [[29727    11]
  [   31   123]]

 [[29839     1]
  [    5    47]]

 [[29612    33]
  [   54   193]]

 [[29681    13]
  [   31   167]]

 [[29324    39]
  [   31   498]]

 [[29314    38]
  [   63   477]]

 [[29872     0]
  [   18     2]]

 [[29803     9]
  [   27    53]]

 [[28327    99]
  [   14  1452]]

 [[29738     6]
  [   13   135]]

 [[28339   100]
  [   51  1402]]

 [[29880     0]
  [   12     0]]

 [[29731    10]
  [    7   144]]

 [[28962    27]
  [   29   874]]

 [[29774    10]
  [   21    87]]

 [[29796     3]
  [    4    89]]

 [[29859     0]
  [    4    29]]

 [[29834     9]
  [    7    42]]

 [[29717    21]
  [   12   142]]]

===scores report===
metrics	scores
Accuracy	0.8789
MCC	0.8723
log_loss	0.5003
f1 score weighted	0.8774
f1 score macro	0.8047
f1 score micro	0.8789
roc_auc ovr	0.9935
roc_auc ovo	0.9910
precision	0.8806
recall	0.8789

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83c014e490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83c014e340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83c014e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83c014e7f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.92      0.85       912
         1.0       0.95      0.77      0.85        53
         2.0       0.95      0.79      0.86       179
         3.0       0.53      0.40      0.45        25
         4.0       0.80      0.61      0.69       112
         5.0       0.84      0.75      0.80       492
         6.0       0.94      0.78      0.86        65
         7.0       0.88      0.58      0.70        38
         8.0       0.89      0.85      0.87       206
         9.0       0.71      0.73      0.72        71
        10.0       0.91      0.87      0.89       405
        11.0       1.00      0.59      0.74        17
        12.0       0.80      0.82      0.81       377
        13.0       0.90      0.75      0.82       191
        14.0       0.50      0.18      0.27        76
        15.0       0.75      0.80      0.77        66
        16.0       0.91      0.81      0.86       140
        17.0       0.77      0.82      0.80       182
        18.0       1.00      1.00      1.00        11
        19.0       0.94      0.89      0.92        37
        20.0       0.96      0.93      0.94      2163
        21.0       0.96      0.92      0.94       169
        22.0       0.87      0.85      0.86      1469
        23.0       0.85      0.92      0.88      1259
        24.0       0.91      0.91      0.91       956
        25.0       0.94      0.90      0.92       282
        26.0       0.88      0.93      0.90      3919
        27.0       0.98      0.93      0.95       531
        28.0       1.00      0.92      0.96        12
        29.0       0.83      0.81      0.82      2346
        30.0       0.67      0.76      0.71       615
        31.0       0.96      0.81      0.88        32
        32.0       0.75      0.83      0.79      1450
        33.0       0.90      0.80      0.85       893
        34.0       0.95      0.89      0.92      1376
        35.0       1.00      0.41      0.58        22
        36.0       0.87      0.87      0.87       843
        37.0       0.85      0.89      0.87      1142
        38.0       0.96      0.90      0.93       314
        39.0       0.86      0.57      0.69        56
        40.0       0.93      0.75      0.83       154
        41.0       0.98      0.90      0.94        52
        42.0       0.90      0.86      0.88       247
        43.0       0.89      0.84      0.86       198
        44.0       0.93      0.92      0.92       529
        45.0       0.96      0.91      0.93       539
        46.0       0.78      0.37      0.50        19
        47.0       0.86      0.68      0.76        80
        48.0       0.96      0.99      0.97      1466
        49.0       0.92      0.93      0.92       148
        50.0       0.94      0.95      0.94      1453
        51.0       1.00      0.08      0.15        12
        52.0       0.90      0.93      0.92       151
        53.0       0.97      0.96      0.96       903
        54.0       0.93      0.85      0.89       108
        55.0       0.94      0.97      0.95        93
        56.0       0.93      0.82      0.87        33
        57.0       0.82      0.94      0.88        49
        58.0       0.94      0.93      0.93       154

    accuracy                           0.88     29892
   macro avg       0.88      0.80      0.83     29892
weighted avg       0.88      0.88      0.88     29892


===confusion_matrix===

[[840   0   0 ...   0   0   0]
 [  0  41   0 ...   0   0   0]
 [  0   0 141 ...   0   0   0]
 ...
 [  0   0   0 ...  27   3   0]
 [  0   0   0 ...   0  46   3]
 [  0   0   0 ...   1   5 143]]

===multilabel confusion matrix===

[[[28745   235]
  [   72   840]]

 [[29837     2]
  [   12    41]]

 [[29705     8]
  [   38   141]]

 [[29858     9]
  [   15    10]]

 [[29763    17]
  [   44    68]]

 [[29330    70]
  [  121   371]]

 [[29824     3]
  [   14    51]]

 [[29851     3]
  [   16    22]]

 [[29664    22]
  [   31   175]]

 [[29800    21]
  [   19    52]]

 [[29452    35]
  [   52   353]]

 [[29875     0]
  [    7    10]]

 [[29439    76]
  [   67   310]]

 [[29685    16]
  [   47   144]]

 [[29802    14]
  [   62    14]]

 [[29808    18]
  [   13    53]]

 [[29741    11]
  [   27   113]]

 [[29665    45]
  [   32   150]]

 [[29881     0]
  [    0    11]]

 [[29853     2]
  [    4    33]]

 [[27636    93]
  [  159  2004]]

 [[29716     7]
  [   13   156]]

 [[28232   191]
  [  225  1244]]

 [[28430   203]
  [  106  1153]]

 [[28855    81]
  [   86   870]]

 [[29593    17]
  [   27   255]]

 [[25487   486]
  [  285  3634]]

 [[29351    10]
  [   38   493]]

 [[29880     0]
  [    1    11]]

 [[27157   389]
  [  435  1911]]

 [[29046   231]
  [  149   466]]

 [[29859     1]
  [    6    26]]

 [[28028   414]
  [  240  1210]]

 [[28924    75]
  [  182   711]]

 [[28450    66]
  [  149  1227]]

 [[29870     0]
  [   13     9]]

 [[28940   109]
  [  107   736]]

 [[28572   178]
  [  128  1014]]

 [[29566    12]
  [   32   282]]

 [[29831     5]
  [   24    32]]

 [[29729     9]
  [   38   116]]

 [[29839     1]
  [    5    47]]

 [[29621    24]
  [   35   212]]

 [[29674    20]
  [   32   166]]

 [[29327    36]
  [   44   485]]

 [[29330    23]
  [   48   491]]

 [[29871     2]
  [   12     7]]

 [[29803     9]
  [   26    54]]

 [[28364    62]
  [   18  1448]]

 [[29732    12]
  [   11   137]]

 [[28353    86]
  [   75  1378]]

 [[29880     0]
  [   11     1]]

 [[29725    16]
  [   10   141]]

 [[28960    29]
  [   36   867]]

 [[29777     7]
  [   16    92]]

 [[29793     6]
  [    3    90]]

 [[29857     2]
  [    6    27]]

 [[29833    10]
  [    3    46]]

 [[29729     9]
  [   11   143]]]

===scores report===
metrics	scores
Accuracy	0.8816
MCC	0.8753
log_loss	0.5022
f1 score weighted	0.8810
f1 score macro	0.8257
f1 score micro	0.8816
roc_auc ovr	0.9937
roc_auc ovo	0.9918
precision	0.8838
recall	0.8816

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83c014e490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83c014e340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83c014e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83c014e7f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.87      0.87       912
         1.0       0.96      0.83      0.89        52
         2.0       0.68      0.80      0.74       179
         3.0       0.46      0.24      0.32        25
         4.0       0.63      0.50      0.56       112
         5.0       0.85      0.70      0.77       492
         6.0       0.93      0.78      0.85        65
         7.0       0.75      0.39      0.52        38
         8.0       0.99      0.76      0.86       205
         9.0       0.88      0.72      0.79        71
        10.0       0.97      0.88      0.93       405
        11.0       1.00      0.65      0.79        17
        12.0       0.88      0.71      0.79       377
        13.0       0.96      0.77      0.86       190
        14.0       0.56      0.07      0.12        76
        15.0       0.69      0.63      0.66        67
        16.0       0.77      0.90      0.83       140
        17.0       0.90      0.72      0.80       183
        18.0       0.92      0.92      0.92        12
        19.0       0.91      0.86      0.89        37
        20.0       0.94      0.90      0.92      2162
        21.0       0.99      0.95      0.97       169
        22.0       0.88      0.76      0.81      1470
        23.0       0.87      0.86      0.87      1259
        24.0       0.83      0.93      0.88       956
        25.0       0.65      0.96      0.77       282
        26.0       0.88      0.89      0.89      3918
        27.0       0.98      0.88      0.93       531
        28.0       0.92      0.92      0.92        13
        29.0       0.84      0.71      0.77      2346
        30.0       0.58      0.71      0.64       615
        31.0       0.92      0.69      0.79        32
        32.0       0.90      0.67      0.77      1450
        33.0       0.66      0.84      0.74       893
        34.0       0.96      0.84      0.90      1376
        35.0       1.00      0.36      0.53        22
        36.0       0.43      0.93      0.59       843
        37.0       0.85      0.89      0.87      1142
        38.0       0.95      0.91      0.93       314
        39.0       0.62      0.42      0.50        55
        40.0       0.78      0.77      0.78       154
        41.0       0.98      0.83      0.90        52
        42.0       0.86      0.81      0.83       247
        43.0       0.97      0.81      0.88       197
        44.0       0.84      0.91      0.87       530
        45.0       0.92      0.89      0.91       540
        46.0       0.00      0.00      0.00        19
        47.0       1.00      0.46      0.63        79
        48.0       0.98      0.97      0.98      1465
        49.0       0.94      0.85      0.89       149
        50.0       0.88      0.95      0.91      1453
        51.0       0.50      0.08      0.14        12
        52.0       0.98      0.88      0.92       152
        53.0       0.88      0.97      0.92       903
        54.0       0.97      0.72      0.83       108
        55.0       0.95      0.83      0.89        93
        56.0       0.86      0.97      0.91        32
        57.0       0.98      0.96      0.97        50
        58.0       0.88      0.93      0.90       154

    accuracy                           0.84     29892
   macro avg       0.84      0.75      0.78     29892
weighted avg       0.86      0.84      0.84     29892


===confusion_matrix===

[[790   0   0 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  0   0 143 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  48   2]
 [  0   0   0 ...   2   0 143]]

===multilabel confusion matrix===

[[[28868   112]
  [  122   790]]

 [[29838     2]
  [    9    43]]

 [[29647    66]
  [   36   143]]

 [[29860     7]
  [   19     6]]

 [[29747    33]
  [   56    56]]

 [[29338    62]
  [  147   345]]

 [[29823     4]
  [   14    51]]

 [[29849     5]
  [   23    15]]

 [[29685     2]
  [   49   156]]

 [[29814     7]
  [   20    51]]

 [[29477    10]
  [   47   358]]

 [[29875     0]
  [    6    11]]

 [[29480    35]
  [  110   267]]

 [[29696     6]
  [   43   147]]

 [[29812     4]
  [   71     5]]

 [[29806    19]
  [   25    42]]

 [[29715    37]
  [   14   126]]

 [[29694    15]
  [   52   131]]

 [[29879     1]
  [    1    11]]

 [[29852     3]
  [    5    32]]

 [[27612   118]
  [  227  1935]]

 [[29722     1]
  [    9   160]]

 [[28268   154]
  [  359  1111]]

 [[28474   159]
  [  171  1088]]

 [[28753   183]
  [   70   886]]

 [[29462   148]
  [   12   270]]

 [[25493   481]
  [  416  3502]]

 [[29352     9]
  [   62   469]]

 [[29878     1]
  [    1    12]]

 [[27220   326]
  [  684  1662]]

 [[28958   319]
  [  180   435]]

 [[29858     2]
  [   10    22]]

 [[28338   104]
  [  482   968]]

 [[28611   388]
  [  140   753]]

 [[28464    52]
  [  218  1158]]

 [[29870     0]
  [   14     8]]

 [[28001  1048]
  [   60   783]]

 [[28573   177]
  [  122  1020]]

 [[29562    16]
  [   28   286]]

 [[29823    14]
  [   32    23]]

 [[29705    33]
  [   35   119]]

 [[29839     1]
  [    9    43]]

 [[29613    32]
  [   48   199]]

 [[29690     5]
  [   37   160]]

 [[29269    93]
  [   47   483]]

 [[29311    41]
  [   57   483]]

 [[29873     0]
  [   19     0]]

 [[29813     0]
  [   43    36]]

 [[28396    31]
  [   39  1426]]

 [[29735     8]
  [   22   127]]

 [[28255   184]
  [   76  1377]]

 [[29879     1]
  [   11     1]]

 [[29737     3]
  [   19   133]]

 [[28869   120]
  [   26   877]]

 [[29782     2]
  [   30    78]]

 [[29795     4]
  [   16    77]]

 [[29855     5]
  [    1    31]]

 [[29841     1]
  [    2    48]]

 [[29718    20]
  [   11   143]]]

===scores report===
metrics	scores
Accuracy	0.8423
MCC	0.8347
log_loss	0.6408
f1 score weighted	0.8447
f1 score macro	0.7754
f1 score micro	0.8423
roc_auc ovr	0.9907
roc_auc ovo	0.9889
precision	0.8617
recall	0.8423

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83c014e490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83c014e340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83c014e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83c014e7f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.92      0.86       912
         1.0       0.98      0.85      0.91        52
         2.0       0.61      0.77      0.68       179
         3.0       0.83      0.21      0.33        24
         4.0       0.50      0.59      0.54       112
         5.0       0.68      0.68      0.68       492
         6.0       0.88      0.77      0.82        64
         7.0       0.90      0.50      0.64        38
         8.0       0.96      0.83      0.89       205
         9.0       0.78      0.77      0.78        70
        10.0       0.93      0.89      0.91       405
        11.0       1.00      0.41      0.58        17
        12.0       0.77      0.80      0.78       378
        13.0       0.73      0.83      0.77       191
        14.0       0.23      0.11      0.14        76
        15.0       0.83      0.67      0.74        67
        16.0       0.53      0.89      0.66       140
        17.0       0.70      0.83      0.76       183
        18.0       0.79      0.92      0.85        12
        19.0       1.00      0.95      0.97        37
        20.0       0.83      0.95      0.89      2162
        21.0       0.95      0.92      0.93       168
        22.0       0.94      0.76      0.84      1470
        23.0       0.97      0.78      0.86      1259
        24.0       0.96      0.87      0.91       955
        25.0       0.81      0.94      0.87       282
        26.0       0.96      0.83      0.89      3918
        27.0       0.79      0.92      0.85       532
        28.0       1.00      0.85      0.92        13
        29.0       0.74      0.84      0.78      2346
        30.0       0.71      0.68      0.69       616
        31.0       0.96      0.75      0.84        32
        32.0       0.80      0.80      0.80      1449
        33.0       0.83      0.79      0.81       893
        34.0       0.91      0.88      0.90      1377
        35.0       0.55      0.55      0.55        22
        36.0       0.93      0.79      0.85       844
        37.0       0.91      0.88      0.89      1142
        38.0       0.91      0.91      0.91       314
        39.0       0.77      0.48      0.59        56
        40.0       0.98      0.70      0.82       153
        41.0       0.94      0.88      0.91        51
        42.0       0.84      0.80      0.82       246
        43.0       0.78      0.88      0.83       197
        44.0       0.87      0.92      0.89       530
        45.0       0.92      0.89      0.90       540
        46.0       1.00      0.10      0.18        20
        47.0       0.69      0.59      0.64        80
        48.0       0.89      0.98      0.93      1465
        49.0       0.96      0.87      0.91       148
        50.0       0.75      0.97      0.85      1453
        51.0       1.00      0.23      0.38        13
        52.0       0.95      0.90      0.93       151
        53.0       0.95      0.95      0.95       904
        54.0       0.97      0.77      0.86       108
        55.0       0.87      0.88      0.88        93
        56.0       0.80      0.97      0.88        33
        57.0       0.96      0.94      0.95        50
        58.0       0.92      0.89      0.90       153

    accuracy                           0.85     29892
   macro avg       0.84      0.77      0.78     29892
weighted avg       0.86      0.85      0.85     29892


===confusion_matrix===

[[837   0   0 ...   0   0   0]
 [  0  44   1 ...   0   0   0]
 [  1   0 137 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   0]
 [  0   0   0 ...   0  47   2]
 [  0   0   0 ...   1   2 136]]

===multilabel confusion matrix===

[[[28781   199]
  [   75   837]]

 [[29839     1]
  [    8    44]]

 [[29626    87]
  [   42   137]]

 [[29867     1]
  [   19     5]]

 [[29714    66]
  [   46    66]]

 [[29242   158]
  [  156   336]]

 [[29821     7]
  [   15    49]]

 [[29852     2]
  [   19    19]]

 [[29679     8]
  [   35   170]]

 [[29807    15]
  [   16    54]]

 [[29459    28]
  [   45   360]]

 [[29875     0]
  [   10     7]]

 [[29423    91]
  [   77   301]]

 [[29642    59]
  [   33   158]]

 [[29789    27]
  [   68     8]]

 [[29816     9]
  [   22    45]]

 [[29641   111]
  [   16   124]]

 [[29644    65]
  [   32   151]]

 [[29877     3]
  [    1    11]]

 [[29855     0]
  [    2    35]]

 [[27299   431]
  [  103  2059]]

 [[29716     8]
  [   14   154]]

 [[28347    75]
  [  352  1118]]

 [[28600    33]
  [  275   984]]

 [[28903    34]
  [  123   832]]

 [[29548    62]
  [   17   265]]

 [[25825   149]
  [  677  3241]]

 [[29229   131]
  [   45   487]]

 [[29879     0]
  [    2    11]]

 [[26842   704]
  [  377  1969]]

 [[29103   173]
  [  197   419]]

 [[29859     1]
  [    8    24]]

 [[28152   291]
  [  296  1153]]

 [[28854   145]
  [  189   704]]

 [[28400   115]
  [  164  1213]]

 [[29860    10]
  [   10    12]]

 [[28999    49]
  [  178   666]]

 [[28649   101]
  [  141  1001]]

 [[29548    30]
  [   28   286]]

 [[29828     8]
  [   29    27]]

 [[29737     2]
  [   46   107]]

 [[29838     3]
  [    6    45]]

 [[29607    39]
  [   48   198]]

 [[29647    48]
  [   24   173]]

 [[29288    74]
  [   42   488]]

 [[29312    40]
  [   62   478]]

 [[29872     0]
  [   18     2]]

 [[29791    21]
  [   33    47]]

 [[28242   185]
  [   23  1442]]

 [[29739     5]
  [   19   129]]

 [[27976   463]
  [   48  1405]]

 [[29879     0]
  [   10     3]]

 [[29734     7]
  [   15   136]]

 [[28944    44]
  [   42   862]]

 [[29781     3]
  [   25    83]]

 [[29787    12]
  [   11    82]]

 [[29851     8]
  [    1    32]]

 [[29840     2]
  [    3    47]]

 [[29727    12]
  [   17   136]]]

===scores report===
metrics	scores
Accuracy	0.8510
MCC	0.8436
log_loss	0.6116
f1 score weighted	0.8508
f1 score macro	0.7842
f1 score micro	0.8510
roc_auc ovr	0.9916
roc_auc ovo	0.9903
precision	0.8603
recall	0.8510

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83c014e490>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83c014e340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83c014e820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83c014e7f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.92      0.85       911
         1.0       0.93      0.77      0.85        53
         2.0       0.89      0.78      0.83       180
         3.0       0.25      0.04      0.07        25
         4.0       0.51      0.59      0.55       111
         5.0       0.74      0.68      0.71       491
         6.0       0.98      0.88      0.93        64
         7.0       0.94      0.41      0.57        37
         8.0       0.97      0.81      0.88       205
         9.0       0.94      0.72      0.82        71
        10.0       0.93      0.90      0.92       404
        11.0       1.00      0.18      0.30        17
        12.0       0.76      0.81      0.78       378
        13.0       0.91      0.75      0.82       191
        14.0       0.67      0.13      0.22        76
        15.0       0.80      0.68      0.74        66
        16.0       0.88      0.80      0.84       140
        17.0       0.96      0.69      0.80       182
        18.0       1.00      0.83      0.91        12
        19.0       0.96      0.70      0.81        37
        20.0       0.84      0.95      0.89      2162
        21.0       0.97      0.91      0.94       168
        22.0       0.85      0.77      0.81      1470
        23.0       0.91      0.86      0.88      1259
        24.0       0.86      0.90      0.88       955
        25.0       0.92      0.94      0.93       283
        26.0       0.87      0.90      0.89      3919
        27.0       0.96      0.90      0.93       532
        28.0       1.00      0.85      0.92        13
        29.0       0.77      0.79      0.78      2345
        30.0       0.79      0.68      0.73       616
        31.0       0.96      0.81      0.88        32
        32.0       0.87      0.74      0.80      1449
        33.0       0.52      0.90      0.66       893
        34.0       0.96      0.84      0.89      1377
        35.0       1.00      0.64      0.78        22
        36.0       0.85      0.85      0.85       844
        37.0       0.86      0.90      0.88      1142
        38.0       0.91      0.88      0.90       314
        39.0       0.77      0.54      0.63        56
        40.0       0.97      0.68      0.80       153
        41.0       0.98      0.87      0.92        52
        42.0       0.92      0.75      0.83       247
        43.0       0.97      0.82      0.89       197
        44.0       0.89      0.89      0.89       529
        45.0       0.89      0.93      0.91       540
        46.0       1.00      0.25      0.40        20
        47.0       0.90      0.54      0.67        80
        48.0       0.97      0.98      0.98      1466
        49.0       0.99      0.89      0.94       148
        50.0       0.94      0.93      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.98      0.86      0.92       151
        53.0       0.98      0.94      0.96       904
        54.0       0.77      0.83      0.80       108
        55.0       0.92      1.00      0.96        93
        56.0       0.91      0.91      0.91        33
        57.0       0.89      0.80      0.84        50
        58.0       0.93      0.82      0.87       154

    accuracy                           0.86     29892
   macro avg       0.87      0.75      0.79     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[834   0   0 ...   0   0   0]
 [  0  41   0 ...   0   0   0]
 [  0   0 140 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   1]
 [  0   0   0 ...   1  40   5]
 [  0   0   0 ...   2   3 126]]

===multilabel confusion matrix===

[[[28753   228]
  [   77   834]]

 [[29836     3]
  [   12    41]]

 [[29695    17]
  [   40   140]]

 [[29864     3]
  [   24     1]]

 [[29719    62]
  [   46    65]]

 [[29284   117]
  [  158   333]]

 [[29827     1]
  [    8    56]]

 [[29854     1]
  [   22    15]]

 [[29682     5]
  [   39   166]]

 [[29818     3]
  [   20    51]]

 [[29462    26]
  [   41   363]]

 [[29875     0]
  [   14     3]]

 [[29417    97]
  [   72   306]]

 [[29687    14]
  [   48   143]]

 [[29811     5]
  [   66    10]]

 [[29815    11]
  [   21    45]]

 [[29737    15]
  [   28   112]]

 [[29705     5]
  [   57   125]]

 [[29880     0]
  [    2    10]]

 [[29854     1]
  [   11    26]]

 [[27353   377]
  [  117  2045]]

 [[29720     4]
  [   15   153]]

 [[28228   194]
  [  336  1134]]

 [[28524   109]
  [  181  1078]]

 [[28802   135]
  [   91   864]]

 [[29586    23]
  [   17   266]]

 [[25455   518]
  [  377  3542]]

 [[29341    19]
  [   52   480]]

 [[29879     0]
  [    2    11]]

 [[26990   557]
  [  485  1860]]

 [[29168   108]
  [  199   417]]

 [[29859     1]
  [    6    26]]

 [[28287   156]
  [  371  1078]]

 [[28268   731]
  [   93   800]]

 [[28468    47]
  [  225  1152]]

 [[29870     0]
  [    8    14]]

 [[28919   129]
  [  124   720]]

 [[28584   166]
  [  118  1024]]

 [[29552    26]
  [   38   276]]

 [[29827     9]
  [   26    30]]

 [[29736     3]
  [   49   104]]

 [[29839     1]
  [    7    45]]

 [[29629    16]
  [   61   186]]

 [[29690     5]
  [   35   162]]

 [[29306    57]
  [   58   471]]

 [[29287    65]
  [   39   501]]

 [[29872     0]
  [   15     5]]

 [[29807     5]
  [   37    43]]

 [[28385    41]
  [   29  1437]]

 [[29743     1]
  [   17   131]]

 [[28355    84]
  [   95  1358]]

 [[29880     0]
  [   12     0]]

 [[29739     2]
  [   21   130]]

 [[28969    19]
  [   54   850]]

 [[29757    27]
  [   18    90]]

 [[29791     8]
  [    0    93]]

 [[29856     3]
  [    3    30]]

 [[29837     5]
  [   10    40]]

 [[29728    10]
  [   28   126]]]

===scores report===
metrics	scores
Accuracy	0.8570
MCC	0.8495
log_loss	0.5747
f1 score weighted	0.8570
f1 score macro	0.7873
f1 score micro	0.8570
roc_auc ovr	0.9918
roc_auc ovo	0.9894
precision	0.8660
recall	0.8570

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8788639100762746	0.8723321977610249	0.5003094056643982	0.8773587965954528	0.804674844776145	0.8788639100762746	0.9934601328001138	0.9909908293457949	0.8805530751173616	0.8788639100762746
1	0.8816405727284893	0.8752680928398092	0.5021878276601643	0.8810484689592318	0.8256888082929519	0.8816405727284893	0.9937324549816755	0.991783148957894	0.8838247633210407	0.8816405727284893
2	0.8422989428609662	0.8347106104961057	0.6407677362696517	0.8447061306954108	0.7754482801720576	0.8422989428609662	0.9907477714127241	0.9889039507857093	0.8617071043400766	0.8422989428609662
3	0.8509634684865516	0.8435693031823763	0.6116035610731948	0.8508209329017898	0.7842410852047629	0.8509634684865517	0.9915656061241335	0.9903326049927854	0.8602570280104836	0.8509634684865516
4	0.856985146527499	0.8494892356626128	0.5747462245348244	0.8569851240692593	0.7872830385065069	0.856985146527499	0.9917629516824902	0.9894452283644519	0.8660436087626416	0.856985146527499
mean	0.8621504081359561	0.8550738879883859	0.5659229510404467	0.8621838906442288	0.7954672113904848	0.8621504081359562	0.9922537834002274	0.990291152489327	0.8704771159103208	0.8621504081359561
std	0.01552492114453671	0.016024119627459404	0.05680424887847916	0.014475953585290033	0.017843147894699762	0.015524921144536696	0.0011510277464389096	0.0010351073052878843	0.009805140800559508	0.01552492114453671

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 63789.7731 secs

