/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_middle_bilstm_attentio_cv_only_enz_hot_lev3_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83205d6580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83205d6730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83205d6880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83205d6610>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.93      0.87       825
         1.0       1.00      0.21      0.35        14
         2.0       0.87      0.65      0.74        31
         3.0       0.00      0.00      0.00        11
         4.0       0.98      0.77      0.86        52
         5.0       0.75      0.77      0.76       176
         6.0       0.69      0.58      0.63       102
         7.0       0.59      0.36      0.45        97
         8.0       1.00      0.21      0.35        14
         9.0       0.68      0.40      0.50        70
        10.0       0.81      0.78      0.79       104
        11.0       0.67      0.11      0.19        18
        12.0       1.00      0.21      0.35        14
        13.0       0.84      0.74      0.79        43
        14.0       0.95      0.62      0.75        34
        15.0       0.84      0.83      0.83        64
        16.0       0.75      0.23      0.35        13
        17.0       0.69      0.58      0.63        19
        18.0       0.97      0.89      0.93        72
        19.0       0.50      0.47      0.48        30
        20.0       1.00      0.98      0.99        94
        21.0       0.81      0.76      0.79        46
        22.0       0.94      0.64      0.76        25
        23.0       0.97      0.95      0.96       345
        24.0       0.85      0.57      0.68        30
        25.0       0.38      0.25      0.30        20
        26.0       0.75      0.77      0.76       167
        27.0       0.94      0.86      0.90        36
        28.0       0.98      0.87      0.92        61
        29.0       0.89      0.89      0.89        63
        30.0       0.67      0.36      0.47        11
        31.0       1.00      0.09      0.17        11
        32.0       0.77      0.42      0.55        40
        33.0       0.81      0.68      0.74        73
        34.0       1.00      1.00      1.00        57
        35.0       1.00      0.93      0.97        15
        36.0       0.58      0.14      0.23        50
        37.0       1.00      0.68      0.81        19
        38.0       1.00      0.62      0.77        29
        39.0       0.99      0.89      0.94       101
        40.0       0.75      0.75      0.75        12
        41.0       1.00      1.00      1.00        14
        42.0       0.65      0.88      0.75        67
        43.0       0.83      0.88      0.85        76
        44.0       0.92      1.00      0.96        11
        45.0       1.00      0.89      0.94        37
        46.0       0.85      0.93      0.89      1613
        47.0       1.00      0.97      0.98       299
        48.0       0.99      0.98      0.99       244
        49.0       0.93      0.96      0.94       168
        50.0       0.71      0.87      0.78      1024
        51.0       0.69      0.71      0.70       353
        52.0       0.93      0.81      0.87        86
        53.0       0.76      0.80      0.78       607
        54.0       0.95      0.90      0.93       543
        55.0       0.92      0.92      0.92        78
        56.0       0.94      0.91      0.92       954
        57.0       0.88      0.91      0.89       247
        58.0       0.97      1.00      0.99        34
        59.0       0.74      0.87      0.80       877
        60.0       0.59      0.70      0.64        77
        61.0       0.66      0.87      0.75       566
        62.0       0.80      0.33      0.47        24
        63.0       0.59      0.55      0.57        55
        64.0       0.97      0.97      0.97       254
        65.0       1.00      0.21      0.35        14
        66.0       0.96      0.95      0.95       456
        67.0       1.00      0.66      0.79        38
        68.0       0.90      0.86      0.88      1189
        69.0       0.91      0.87      0.89       224
        70.0       0.71      0.79      0.75        19
        71.0       0.95      0.97      0.96       358
        72.0       1.00      0.62      0.77        32
        73.0       0.00      0.00      0.00        13
        74.0       0.99      0.98      0.99       127
        75.0       1.00      0.92      0.96        12
        76.0       0.59      0.89      0.71       460
        77.0       0.95      0.86      0.90       103
        78.0       0.67      0.42      0.52        52
        79.0       0.75      0.69      0.72        83
        80.0       0.86      0.47      0.61        80
        81.0       0.96      0.83      0.89        84
        82.0       0.94      0.87      0.91       335
        83.0       0.92      0.48      0.63        23
        84.0       0.75      0.73      0.74       518
        85.0       0.28      0.08      0.12        87
        86.0       1.00      0.38      0.56        13
        87.0       0.61      0.80      0.69       480
        88.0       0.72      0.67      0.69       126
        89.0       0.96      0.92      0.94        25
        90.0       0.88      0.85      0.86       152
        91.0       0.83      0.25      0.38        20
        92.0       0.78      0.25      0.38        28
        93.0       0.94      0.69      0.79        42
        94.0       0.75      0.26      0.39        34
        95.0       0.46      0.48      0.47        99
        96.0       0.85      0.84      0.85       415
        97.0       0.73      0.55      0.63       118
        98.0       0.92      0.73      0.81        99
        99.0       0.89      0.74      0.81       253
       100.0       0.93      0.95      0.94       116
       101.0       0.68      0.79      0.73       423
       102.0       0.96      0.81      0.88        99
       103.0       0.79      0.83      0.81        60
       104.0       0.84      0.88      0.86       266
       105.0       1.00      0.89      0.94        37
       106.0       0.91      0.84      0.87       494
       107.0       0.92      0.79      0.85        14
       108.0       0.89      0.92      0.90       610
       109.0       0.89      0.90      0.89       206
       110.0       0.85      0.50      0.63        22
       111.0       0.90      0.90      0.90       534
       112.0       0.88      0.50      0.64        98
       113.0       0.76      0.72      0.74        86
       114.0       1.00      0.86      0.93       109
       115.0       0.91      0.90      0.90       858
       116.0       0.62      0.57      0.60        61
       117.0       0.92      0.92      0.92       209
       118.0       0.00      0.00      0.00        13
       119.0       0.77      0.82      0.79        65
       120.0       0.98      0.92      0.95       156
       121.0       0.96      0.95      0.96        84
       122.0       0.65      0.51      0.57        55
       123.0       0.83      0.68      0.75       154
       124.0       0.98      0.90      0.94        52
       125.0       0.91      0.92      0.91       147
       126.0       0.91      0.55      0.68        77
       127.0       0.94      0.79      0.86        19
       128.0       0.90      0.81      0.85       198
       129.0       0.98      0.92      0.95       450
       130.0       0.75      0.55      0.63        11
       131.0       0.78      0.58      0.67        43
       132.0       1.00      0.75      0.86        16
       133.0       0.96      0.95      0.95       204
       134.0       0.99      0.96      0.97        76
       135.0       0.96      0.79      0.86       255
       136.0       0.80      0.20      0.32        20
       137.0       1.00      0.77      0.87        13
       138.0       0.88      0.64      0.74        67
       139.0       0.99      0.98      0.98      1464
       140.0       0.95      0.82      0.88       146
       141.0       0.92      0.94      0.93        99
       142.0       0.96      0.89      0.93       455
       143.0       0.99      0.91      0.95        82
       144.0       0.95      0.98      0.96       411
       145.0       0.96      0.95      0.95       406
       146.0       0.50      0.08      0.14        12
       147.0       0.91      0.88      0.89       149
       148.0       0.96      0.94      0.95       703
       149.0       0.99      0.95      0.97       195
       150.0       0.88      0.64      0.74        33
       151.0       0.82      0.79      0.81        68
       152.0       0.91      0.91      0.91        93
       153.0       0.89      0.94      0.91        33
       154.0       0.91      0.86      0.88        49
       155.0       0.85      0.95      0.90       154

    accuracy                           0.86     28656
   macro avg       0.84      0.71      0.75     28656
weighted avg       0.86      0.86      0.85     28656


===confusion_matrix===

[[764   0   0 ...   0   0   0]
 [  0   3   0 ...   0   0   0]
 [  2   0  20 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   1]
 [  0   0   0 ...   0  42   6]
 [  0   0   0 ...   1   3 147]]

===multilabel confusion matrix===

[[[27665   166]
  [   61   764]]

 [[28642     0]
  [   11     3]]

 [[28622     3]
  [   11    20]]

 [[28645     0]
  [   11     0]]

 [[28603     1]
  [   12    40]]

 [[28435    45]
  [   41   135]]

 [[28527    27]
  [   43    59]]

 [[28535    24]
  [   62    35]]

 [[28642     0]
  [   11     3]]

 [[28573    13]
  [   42    28]]

 [[28533    19]
  [   23    81]]

 [[28637     1]
  [   16     2]]

 [[28642     0]
  [   11     3]]

 [[28607     6]
  [   11    32]]

 [[28621     1]
  [   13    21]]

 [[28582    10]
  [   11    53]]

 [[28642     1]
  [   10     3]]

 [[28632     5]
  [    8    11]]

 [[28582     2]
  [    8    64]]

 [[28612    14]
  [   16    14]]

 [[28562     0]
  [    2    92]]

 [[28602     8]
  [   11    35]]

 [[28630     1]
  [    9    16]]

 [[28300    11]
  [   16   329]]

 [[28623     3]
  [   13    17]]

 [[28628     8]
  [   15     5]]

 [[28447    42]
  [   38   129]]

 [[28618     2]
  [    5    31]]

 [[28594     1]
  [    8    53]]

 [[28586     7]
  [    7    56]]

 [[28643     2]
  [    7     4]]

 [[28645     0]
  [   10     1]]

 [[28611     5]
  [   23    17]]

 [[28571    12]
  [   23    50]]

 [[28599     0]
  [    0    57]]

 [[28641     0]
  [    1    14]]

 [[28601     5]
  [   43     7]]

 [[28637     0]
  [    6    13]]

 [[28627     0]
  [   11    18]]

 [[28554     1]
  [   11    90]]

 [[28641     3]
  [    3     9]]

 [[28642     0]
  [    0    14]]

 [[28557    32]
  [    8    59]]

 [[28566    14]
  [    9    67]]

 [[28644     1]
  [    0    11]]

 [[28619     0]
  [    4    33]]

 [[26781   262]
  [  117  1496]]

 [[28356     1]
  [    8   291]]

 [[28409     3]
  [    4   240]]

 [[28476    12]
  [    7   161]]

 [[27271   361]
  [  134   890]]

 [[28193   110]
  [  104   249]]

 [[28565     5]
  [   16    70]]

 [[27900   149]
  [  123   484]]

 [[28089    24]
  [   52   491]]

 [[28572     6]
  [    6    72]]

 [[27649    53]
  [   89   865]]

 [[28378    31]
  [   23   224]]

 [[28621     1]
  [    0    34]]

 [[27513   266]
  [  117   760]]

 [[28541    38]
  [   23    54]]

 [[27834   256]
  [   73   493]]

 [[28630     2]
  [   16     8]]

 [[28580    21]
  [   25    30]]

 [[28395     7]
  [    7   247]]

 [[28642     0]
  [   11     3]]

 [[28181    19]
  [   24   432]]

 [[28618     0]
  [   13    25]]

 [[27356   111]
  [  161  1028]]

 [[28412    20]
  [   30   194]]

 [[28631     6]
  [    4    15]]

 [[28278    20]
  [    9   349]]

 [[28624     0]
  [   12    20]]

 [[28643     0]
  [   13     0]]

 [[28528     1]
  [    2   125]]

 [[28644     0]
  [    1    11]]

 [[27911   285]
  [   51   409]]

 [[28548     5]
  [   14    89]]

 [[28593    11]
  [   30    22]]

 [[28554    19]
  [   26    57]]

 [[28570     6]
  [   42    38]]

 [[28569     3]
  [   14    70]]

 [[28303    18]
  [   43   292]]

 [[28632     1]
  [   12    11]]

 [[28008   130]
  [  138   380]]

 [[28551    18]
  [   80     7]]

 [[28643     0]
  [    8     5]]

 [[27929   247]
  [   95   385]]

 [[28498    32]
  [   42    84]]

 [[28630     1]
  [    2    23]]

 [[28486    18]
  [   23   129]]

 [[28635     1]
  [   15     5]]

 [[28626     2]
  [   21     7]]

 [[28612     2]
  [   13    29]]

 [[28619     3]
  [   25     9]]

 [[28501    56]
  [   51    48]]

 [[28180    61]
  [   65   350]]

 [[28514    24]
  [   53    65]]

 [[28551     6]
  [   27    72]]

 [[28381    22]
  [   66   187]]

 [[28532     8]
  [    6   110]]

 [[28075   158]
  [   87   336]]

 [[28554     3]
  [   19    80]]

 [[28583    13]
  [   10    50]]

 [[28347    43]
  [   33   233]]

 [[28619     0]
  [    4    33]]

 [[28122    40]
  [   81   413]]

 [[28641     1]
  [    3    11]]

 [[27973    73]
  [   46   564]]

 [[28427    23]
  [   21   185]]

 [[28632     2]
  [   11    11]]

 [[28066    56]
  [   54   480]]

 [[28551     7]
  [   49    49]]

 [[28550    20]
  [   24    62]]

 [[28547     0]
  [   15    94]]

 [[27718    80]
  [   86   772]]

 [[28574    21]
  [   26    35]]

 [[28431    16]
  [   17   192]]

 [[28643     0]
  [   13     0]]

 [[28575    16]
  [   12    53]]

 [[28497     3]
  [   12   144]]

 [[28569     3]
  [    4    80]]

 [[28586    15]
  [   27    28]]

 [[28480    22]
  [   49   105]]

 [[28603     1]
  [    5    47]]

 [[28495    14]
  [   12   135]]

 [[28575     4]
  [   35    42]]

 [[28636     1]
  [    4    15]]

 [[28440    18]
  [   38   160]]

 [[28198     8]
  [   38   412]]

 [[28643     2]
  [    5     6]]

 [[28606     7]
  [   18    25]]

 [[28640     0]
  [    4    12]]

 [[28443     9]
  [   10   194]]

 [[28579     1]
  [    3    73]]

 [[28392     9]
  [   54   201]]

 [[28635     1]
  [   16     4]]

 [[28643     0]
  [    3    10]]

 [[28583     6]
  [   24    43]]

 [[27172    20]
  [   26  1438]]

 [[28504     6]
  [   26   120]]

 [[28549     8]
  [    6    93]]

 [[28184    17]
  [   48   407]]

 [[28573     1]
  [    7    75]]

 [[28224    21]
  [    9   402]]

 [[28232    18]
  [   19   387]]

 [[28643     1]
  [   11     1]]

 [[28494    13]
  [   18   131]]

 [[27926    27]
  [   42   661]]

 [[28460     1]
  [   10   185]]

 [[28620     3]
  [   12    21]]

 [[28576    12]
  [   14    54]]

 [[28555     8]
  [    8    85]]

 [[28619     4]
  [    2    31]]

 [[28603     4]
  [    7    42]]

 [[28477    25]
  [    7   147]]]

===scores report===
metrics	scores
Accuracy	0.8554
MCC	0.8524
log_loss	0.6616
f1 score weighted	0.8524
f1 score macro	0.7517
f1 score micro	0.8554
roc_auc ovr	0.9943
roc_auc ovo	0.9916
precision	0.8609
recall	0.8554

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83205d6580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83205d6730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83205d6880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83205d6610>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([56., 56., 56., ..., 98., 51., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.95      0.88       825
         1.0       1.00      0.14      0.25        14
         2.0       0.74      0.74      0.74        31
         3.0       0.00      0.00      0.00        12
         4.0       0.78      0.75      0.76        52
         5.0       0.59      0.81      0.68       176
         6.0       0.67      0.60      0.63       102
         7.0       0.41      0.42      0.41        97
         8.0       1.00      0.50      0.67        14
         9.0       0.54      0.43      0.48        70
        10.0       0.80      0.74      0.77       104
        11.0       0.00      0.00      0.00        18
        12.0       0.00      0.00      0.00        14
        13.0       0.70      0.74      0.72        42
        14.0       0.64      0.68      0.66        34
        15.0       0.91      0.77      0.83        64
        16.0       0.75      0.21      0.33        14
        17.0       0.50      0.16      0.24        19
        18.0       0.98      0.89      0.93        72
        19.0       0.78      0.23      0.35        31
        20.0       1.00      0.93      0.96        94
        21.0       0.76      0.87      0.81        45
        22.0       1.00      0.76      0.86        25
        23.0       0.99      0.92      0.95       346
        24.0       0.76      0.83      0.79        30
        25.0       0.00      0.00      0.00        19
        26.0       0.66      0.74      0.70       167
        27.0       0.81      0.61      0.70        36
        28.0       1.00      0.92      0.96        60
        29.0       0.94      0.71      0.81        62
        30.0       1.00      0.18      0.31        11
        31.0       0.00      0.00      0.00        11
        32.0       0.93      0.35      0.51        40
        33.0       0.86      0.69      0.77        74
        34.0       1.00      1.00      1.00        56
        35.0       1.00      0.75      0.86        16
        36.0       0.65      0.25      0.37        51
        37.0       1.00      0.79      0.88        19
        38.0       0.87      0.69      0.77        29
        39.0       0.87      0.89      0.88       101
        40.0       0.70      0.58      0.64        12
        41.0       1.00      0.92      0.96        13
        42.0       0.89      0.82      0.85        67
        43.0       0.97      0.82      0.89        76
        44.0       1.00      1.00      1.00        12
        45.0       1.00      0.83      0.91        36
        46.0       0.87      0.92      0.89      1613
        47.0       1.00      0.96      0.98       299
        48.0       0.99      0.97      0.98       243
        49.0       0.97      0.91      0.94       169
        50.0       0.69      0.85      0.76      1024
        51.0       0.85      0.60      0.70       352
        52.0       0.94      0.86      0.90        86
        53.0       0.92      0.67      0.77       607
        54.0       0.98      0.90      0.94       543
        55.0       0.99      0.85      0.91        78
        56.0       0.90      0.86      0.88       954
        57.0       0.96      0.89      0.92       247
        58.0       0.87      1.00      0.93        34
        59.0       0.77      0.86      0.81       877
        60.0       0.90      0.35      0.50        77
        61.0       0.76      0.85      0.80       565
        62.0       0.50      0.04      0.08        24
        63.0       0.65      0.67      0.66        55
        64.0       0.98      0.96      0.97       255
        65.0       1.00      0.14      0.25        14
        66.0       0.98      0.93      0.96       457
        67.0       1.00      0.73      0.84        37
        68.0       0.75      0.87      0.80      1189
        69.0       0.88      0.88      0.88       224
        70.0       0.75      0.60      0.67        20
        71.0       0.93      0.94      0.93       358
        72.0       0.80      0.38      0.51        32
        73.0       1.00      0.15      0.27        13
        74.0       1.00      0.92      0.96       128
        75.0       1.00      0.85      0.92        13
        76.0       0.85      0.72      0.78       460
        77.0       0.98      0.76      0.85       104
        78.0       0.15      0.73      0.25        52
        79.0       0.91      0.49      0.64        84
        80.0       0.51      0.42      0.46        80
        81.0       0.99      0.80      0.88        83
        82.0       0.99      0.83      0.90       335
        83.0       1.00      0.17      0.29        24
        84.0       0.68      0.75      0.71       518
        85.0       0.23      0.10      0.14        88
        86.0       1.00      0.54      0.70        13
        87.0       0.76      0.62      0.69       480
        88.0       0.95      0.56      0.70       126
        89.0       1.00      1.00      1.00        25
        90.0       0.62      0.87      0.73       153
        91.0       0.50      0.30      0.37        20
        92.0       1.00      0.22      0.36        27
        93.0       1.00      0.67      0.80        42
        94.0       0.50      0.24      0.32        34
        95.0       0.28      0.65      0.39        99
        96.0       0.94      0.77      0.84       416
        97.0       0.81      0.41      0.54       118
        98.0       0.81      0.76      0.78        99
        99.0       0.88      0.77      0.82       253
       100.0       0.92      0.86      0.89       115
       101.0       0.39      0.88      0.54       423
       102.0       0.98      0.81      0.88        99
       103.0       0.58      0.85      0.69        61
       104.0       0.85      0.83      0.84       266
       105.0       0.84      0.86      0.85        36
       106.0       0.87      0.81      0.84       494
       107.0       1.00      0.93      0.96        14
       108.0       0.96      0.86      0.91       610
       109.0       0.86      0.91      0.88       206
       110.0       0.80      0.18      0.30        22
       111.0       0.93      0.88      0.90       535
       112.0       0.74      0.56      0.64        98
       113.0       0.85      0.62      0.72        86
       114.0       0.94      0.93      0.94       109
       115.0       0.92      0.91      0.91       858
       116.0       0.81      0.21      0.34        61
       117.0       0.96      0.90      0.93       208
       118.0       0.00      0.00      0.00        13
       119.0       0.75      0.63      0.68        65
       120.0       1.00      0.90      0.95       157
       121.0       1.00      0.99      0.99        84
       122.0       1.00      0.38      0.55        55
       123.0       0.87      0.64      0.74       154
       124.0       0.98      0.92      0.95        52
       125.0       0.91      0.86      0.89       147
       126.0       0.95      0.52      0.67        77
       127.0       1.00      0.83      0.91        18
       128.0       0.74      0.86      0.80       197
       129.0       0.87      0.95      0.91       449
       130.0       1.00      0.55      0.71        11
       131.0       1.00      0.44      0.61        43
       132.0       0.92      0.73      0.81        15
       133.0       0.96      0.97      0.97       204
       134.0       0.97      0.93      0.95        76
       135.0       0.77      0.85      0.81       255
       136.0       0.75      0.32      0.44        19
       137.0       0.83      0.77      0.80        13
       138.0       0.89      0.36      0.51        67
       139.0       0.92      0.99      0.95      1463
       140.0       0.98      0.86      0.92       147
       141.0       0.69      0.94      0.79        99
       142.0       0.97      0.91      0.94       455
       143.0       0.94      0.94      0.94        82
       144.0       1.00      0.89      0.94       410
       145.0       0.75      1.00      0.85       406
       146.0       0.00      0.00      0.00        12
       147.0       0.96      0.87      0.92       149
       148.0       0.98      0.94      0.96       702
       149.0       0.97      0.96      0.96       196
       150.0       0.83      0.78      0.81        32
       151.0       0.79      0.91      0.85        69
       152.0       0.92      0.96      0.94        93
       153.0       1.00      0.94      0.97        32
       154.0       0.95      0.84      0.89        49
       155.0       0.93      0.81      0.87       154

    accuracy                           0.83     28655
   macro avg       0.81      0.68      0.72     28655
weighted avg       0.85      0.83      0.83     28655


===confusion_matrix===

[[781   0   0 ...   0   0   0]
 [  0   2   0 ...   0   0   0]
 [  0   0  23 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   0]
 [  0   0   0 ...   0  41   5]
 [  0   0   0 ...   0   2 125]]

===multilabel confusion matrix===

[[[27659   171]
  [   44   781]]

 [[28641     0]
  [   12     2]]

 [[28616     8]
  [    8    23]]

 [[28643     0]
  [   12     0]]

 [[28592    11]
  [   13    39]]

 [[28379   100]
  [   34   142]]

 [[28523    30]
  [   41    61]]

 [[28498    60]
  [   56    41]]

 [[28641     0]
  [    7     7]]

 [[28559    26]
  [   40    30]]

 [[28532    19]
  [   27    77]]

 [[28637     0]
  [   18     0]]

 [[28641     0]
  [   14     0]]

 [[28600    13]
  [   11    31]]

 [[28608    13]
  [   11    23]]

 [[28586     5]
  [   15    49]]

 [[28640     1]
  [   11     3]]

 [[28633     3]
  [   16     3]]

 [[28582     1]
  [    8    64]]

 [[28622     2]
  [   24     7]]

 [[28561     0]
  [    7    87]]

 [[28598    12]
  [    6    39]]

 [[28630     0]
  [    6    19]]

 [[28307     2]
  [   29   317]]

 [[28617     8]
  [    5    25]]

 [[28636     0]
  [   19     0]]

 [[28425    63]
  [   43   124]]

 [[28614     5]
  [   14    22]]

 [[28595     0]
  [    5    55]]

 [[28590     3]
  [   18    44]]

 [[28644     0]
  [    9     2]]

 [[28643     1]
  [   11     0]]

 [[28614     1]
  [   26    14]]

 [[28573     8]
  [   23    51]]

 [[28599     0]
  [    0    56]]

 [[28639     0]
  [    4    12]]

 [[28597     7]
  [   38    13]]

 [[28636     0]
  [    4    15]]

 [[28623     3]
  [    9    20]]

 [[28541    13]
  [   11    90]]

 [[28640     3]
  [    5     7]]

 [[28642     0]
  [    1    12]]

 [[28581     7]
  [   12    55]]

 [[28577     2]
  [   14    62]]

 [[28643     0]
  [    0    12]]

 [[28619     0]
  [    6    30]]

 [[26815   227]
  [  132  1481]]

 [[28356     0]
  [   13   286]]

 [[28409     3]
  [    7   236]]

 [[28481     5]
  [   15   154]]

 [[27247   384]
  [  157   867]]

 [[28265    38]
  [  140   212]]

 [[28564     5]
  [   12    74]]

 [[28011    37]
  [  201   406]]

 [[28103     9]
  [   55   488]]

 [[28576     1]
  [   12    66]]

 [[27612    89]
  [  134   820]]

 [[28400     8]
  [   28   219]]

 [[28616     5]
  [    0    34]]

 [[27547   231]
  [  123   754]]

 [[28575     3]
  [   50    27]]

 [[27940   150]
  [   84   481]]

 [[28630     1]
  [   23     1]]

 [[28580    20]
  [   18    37]]

 [[28396     4]
  [    9   246]]

 [[28641     0]
  [   12     2]]

 [[28191     7]
  [   31   426]]

 [[28618     0]
  [   10    27]]

 [[27115   351]
  [  152  1037]]

 [[28404    27]
  [   28   196]]

 [[28631     4]
  [    8    12]]

 [[28272    25]
  [   23   335]]

 [[28620     3]
  [   20    12]]

 [[28642     0]
  [   11     2]]

 [[28527     0]
  [   10   118]]

 [[28642     0]
  [    2    11]]

 [[28139    56]
  [  131   329]]

 [[28549     2]
  [   25    79]]

 [[28383   220]
  [   14    38]]

 [[28567     4]
  [   43    41]]

 [[28542    33]
  [   46    34]]

 [[28571     1]
  [   17    66]]

 [[28316     4]
  [   56   279]]

 [[28631     0]
  [   20     4]]

 [[27952   185]
  [  129   389]]

 [[28537    30]
  [   79     9]]

 [[28642     0]
  [    6     7]]

 [[28083    92]
  [  182   298]]

 [[28525     4]
  [   56    70]]

 [[28630     0]
  [    0    25]]

 [[28422    80]
  [   20   133]]

 [[28629     6]
  [   14     6]]

 [[28628     0]
  [   21     6]]

 [[28613     0]
  [   14    28]]

 [[28613     8]
  [   26     8]]

 [[28390   166]
  [   35    64]]

 [[28218    21]
  [   97   319]]

 [[28526    11]
  [   70    48]]

 [[28538    18]
  [   24    75]]

 [[28375    27]
  [   58   195]]

 [[28531     9]
  [   16    99]]

 [[27656   576]
  [   51   372]]

 [[28554     2]
  [   19    80]]

 [[28556    38]
  [    9    52]]

 [[28349    40]
  [   45   221]]

 [[28613     6]
  [    5    31]]

 [[28103    58]
  [   92   402]]

 [[28641     0]
  [    1    13]]

 [[28021    24]
  [   86   524]]

 [[28418    31]
  [   18   188]]

 [[28632     1]
  [   18     4]]

 [[28083    37]
  [   66   469]]

 [[28538    19]
  [   43    55]]

 [[28560     9]
  [   33    53]]

 [[28540     6]
  [    8   101]]

 [[27730    67]
  [   80   778]]

 [[28591     3]
  [   48    13]]

 [[28439     8]
  [   21   187]]

 [[28642     0]
  [   13     0]]

 [[28576    14]
  [   24    41]]

 [[28498     0]
  [   16   141]]

 [[28571     0]
  [    1    83]]

 [[28600     0]
  [   34    21]]

 [[28486    15]
  [   55    99]]

 [[28602     1]
  [    4    48]]

 [[28496    12]
  [   20   127]]

 [[28576     2]
  [   37    40]]

 [[28637     0]
  [    3    15]]

 [[28398    60]
  [   27   170]]

 [[28142    64]
  [   22   427]]

 [[28644     0]
  [    5     6]]

 [[28612     0]
  [   24    19]]

 [[28639     1]
  [    4    11]]

 [[28443     8]
  [    6   198]]

 [[28577     2]
  [    5    71]]

 [[28335    65]
  [   37   218]]

 [[28634     2]
  [   13     6]]

 [[28640     2]
  [    3    10]]

 [[28585     3]
  [   43    24]]

 [[27064   128]
  [   18  1445]]

 [[28506     2]
  [   21   126]]

 [[28514    42]
  [    6    93]]

 [[28188    12]
  [   42   413]]

 [[28568     5]
  [    5    77]]

 [[28244     1]
  [   46   364]]

 [[28112   137]
  [    1   405]]

 [[28643     0]
  [   12     0]]

 [[28501     5]
  [   19   130]]

 [[27939    14]
  [   45   657]]

 [[28453     6]
  [    8   188]]

 [[28618     5]
  [    7    25]]

 [[28569    17]
  [    6    63]]

 [[28554     8]
  [    4    89]]

 [[28623     0]
  [    2    30]]

 [[28604     2]
  [    8    41]]

 [[28492     9]
  [   29   125]]]

===scores report===
metrics	scores
Accuracy	0.8330
MCC	0.8298
log_loss	0.7579
f1 score weighted	0.8329
f1 score macro	0.7170
f1 score micro	0.8330
roc_auc ovr	0.9935
roc_auc ovo	0.9908
precision	0.8534
recall	0.8330

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83205d6580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83205d6730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83205d6880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83205d6610>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  51.,  96., 109.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.90      0.89       825
         1.0       0.00      0.00      0.00        14
         2.0       0.68      0.72      0.70        32
         3.0       0.00      0.00      0.00        12
         4.0       0.92      0.67      0.78        52
         5.0       0.77      0.85      0.81       176
         6.0       0.71      0.51      0.59       102
         7.0       0.42      0.30      0.35        97
         8.0       1.00      0.29      0.44        14
         9.0       0.52      0.38      0.44        69
        10.0       0.71      0.74      0.73       104
        11.0       1.00      0.06      0.11        18
        12.0       1.00      0.13      0.24        15
        13.0       0.83      0.71      0.77        42
        14.0       0.87      0.59      0.70        34
        15.0       1.00      0.80      0.89        64
        16.0       0.20      0.08      0.11        13
        17.0       0.69      0.47      0.56        19
        18.0       0.98      0.86      0.92        71
        19.0       0.69      0.29      0.41        31
        20.0       0.98      0.97      0.97        94
        21.0       0.76      0.76      0.76        46
        22.0       1.00      0.80      0.89        25
        23.0       0.91      0.94      0.93       346
        24.0       1.00      0.58      0.73        31
        25.0       1.00      0.05      0.10        20
        26.0       0.81      0.60      0.69       167
        27.0       0.96      0.75      0.84        36
        28.0       1.00      0.90      0.95        60
        29.0       0.93      0.84      0.88        62
        30.0       1.00      0.09      0.17        11
        31.0       1.00      0.08      0.15        12
        32.0       0.73      0.28      0.40        40
        33.0       0.85      0.77      0.81        74
        34.0       1.00      1.00      1.00        56
        35.0       0.93      0.81      0.87        16
        36.0       0.44      0.08      0.13        51
        37.0       0.67      0.95      0.78        19
        38.0       0.91      0.69      0.78        29
        39.0       0.96      0.87      0.91       101
        40.0       0.83      0.42      0.56        12
        41.0       1.00      1.00      1.00        13
        42.0       0.84      0.78      0.81        67
        43.0       0.94      0.87      0.90        76
        44.0       0.92      1.00      0.96        11
        45.0       1.00      0.78      0.88        37
        46.0       0.87      0.90      0.89      1613
        47.0       0.99      0.97      0.98       299
        48.0       0.98      0.97      0.98       243
        49.0       0.96      0.95      0.95       169
        50.0       0.81      0.79      0.80      1023
        51.0       0.76      0.69      0.73       352
        52.0       0.92      0.80      0.86        86
        53.0       0.65      0.85      0.74       606
        54.0       0.88      0.89      0.88       543
        55.0       0.98      0.75      0.85        79
        56.0       0.88      0.90      0.89       954
        57.0       0.90      0.92      0.91       247
        58.0       1.00      0.94      0.97        34
        59.0       0.73      0.88      0.80       877
        60.0       0.79      0.48      0.60        77
        61.0       0.70      0.86      0.77       566
        62.0       1.00      0.04      0.08        24
        63.0       0.64      0.55      0.59        55
        64.0       0.98      0.96      0.97       255
        65.0       0.50      0.08      0.13        13
        66.0       0.98      0.94      0.96       457
        67.0       0.84      0.73      0.78        37
        68.0       0.72      0.88      0.79      1189
        69.0       0.78      0.85      0.81       223
        70.0       0.83      0.26      0.40        19
        71.0       0.98      0.95      0.96       357
        72.0       0.79      0.59      0.68        32
        73.0       0.00      0.00      0.00        13
        74.0       0.98      0.95      0.96       128
        75.0       1.00      0.54      0.70        13
        76.0       0.66      0.85      0.74       460
        77.0       0.94      0.79      0.86       104
        78.0       0.65      0.21      0.31        53
        79.0       0.72      0.58      0.64        83
        80.0       0.63      0.46      0.53        79
        81.0       0.91      0.86      0.88        84
        82.0       0.81      0.84      0.82       334
        83.0       0.75      0.12      0.21        24
        84.0       0.49      0.81      0.61       518
        85.0       0.24      0.14      0.18        88
        86.0       0.80      0.31      0.44        13
        87.0       0.74      0.67      0.70       480
        88.0       0.68      0.72      0.70       127
        89.0       1.00      0.96      0.98        24
        90.0       0.94      0.72      0.81       153
        91.0       1.00      0.05      0.10        20
        92.0       0.50      0.15      0.23        27
        93.0       0.97      0.76      0.85        42
        94.0       0.45      0.15      0.22        34
        95.0       0.39      0.34      0.37        99
        96.0       0.87      0.81      0.84       416
        97.0       0.93      0.45      0.61       118
        98.0       0.79      0.63      0.70        99
        99.0       0.92      0.70      0.79       253
       100.0       0.95      0.95      0.95       115
       101.0       0.78      0.74      0.75       423
       102.0       1.00      0.70      0.83        98
       103.0       0.98      0.72      0.83        60
       104.0       0.81      0.86      0.83       265
       105.0       0.94      0.89      0.91        36
       106.0       0.63      0.88      0.74       495
       107.0       0.90      0.64      0.75        14
       108.0       0.65      0.95      0.77       610
       109.0       0.95      0.89      0.92       206
       110.0       0.80      0.73      0.76        22
       111.0       0.93      0.85      0.89       535
       112.0       0.91      0.53      0.67        98
       113.0       0.82      0.53      0.65        86
       114.0       0.99      0.91      0.95       110
       115.0       0.94      0.84      0.89       858
       116.0       0.77      0.28      0.41        61
       117.0       0.97      0.90      0.93       208
       118.0       0.00      0.00      0.00        13
       119.0       0.90      0.68      0.78        66
       120.0       0.97      0.92      0.94       157
       121.0       0.99      0.99      0.99        84
       122.0       0.97      0.58      0.73        55
       123.0       0.78      0.66      0.72       153
       124.0       1.00      0.94      0.97        52
       125.0       0.95      0.90      0.93       147
       126.0       0.89      0.63      0.74        76
       127.0       1.00      0.72      0.84        18
       128.0       0.83      0.86      0.84       197
       129.0       0.95      0.90      0.92       450
       130.0       1.00      0.58      0.74        12
       131.0       1.00      0.64      0.78        42
       132.0       1.00      0.87      0.93        15
       133.0       0.98      0.96      0.97       204
       134.0       1.00      0.93      0.97        76
       135.0       0.97      0.79      0.87       256
       136.0       0.50      0.05      0.10        19
       137.0       1.00      0.85      0.92        13
       138.0       0.83      0.64      0.72        67
       139.0       0.99      0.94      0.96      1464
       140.0       0.85      0.91      0.88       147
       141.0       0.97      0.86      0.91        98
       142.0       0.92      0.91      0.92       455
       143.0       0.96      0.95      0.96        82
       144.0       0.99      0.95      0.97       410
       145.0       0.95      0.96      0.95       406
       146.0       0.33      0.08      0.13        12
       147.0       0.91      0.90      0.91       149
       148.0       0.92      0.96      0.94       702
       149.0       0.97      0.96      0.97       196
       150.0       1.00      0.78      0.88        32
       151.0       0.84      0.86      0.85        69
       152.0       0.91      0.97      0.94        93
       153.0       1.00      0.79      0.88        33
       154.0       0.86      0.50      0.63        50
       155.0       0.78      0.94      0.85       154

    accuracy                           0.83     28655
   macro avg       0.83      0.67      0.71     28655
weighted avg       0.84      0.83      0.83     28655


===confusion_matrix===

[[742   0   2 ...   0   0   0]
 [  3   0   2 ...   0   0   0]
 [  0   0  23 ...   0   0   0]
 ...
 [  0   0   0 ...  26   1   2]
 [  0   0   0 ...   0  25  23]
 [  0   0   0 ...   0   3 144]]

===multilabel confusion matrix===

[[[27731    99]
  [   83   742]]

 [[28641     0]
  [   14     0]]

 [[28612    11]
  [    9    23]]

 [[28643     0]
  [   12     0]]

 [[28600     3]
  [   17    35]]

 [[28434    45]
  [   26   150]]

 [[28532    21]
  [   50    52]]

 [[28518    40]
  [   68    29]]

 [[28641     0]
  [   10     4]]

 [[28562    24]
  [   43    26]]

 [[28520    31]
  [   27    77]]

 [[28637     0]
  [   17     1]]

 [[28640     0]
  [   13     2]]

 [[28607     6]
  [   12    30]]

 [[28618     3]
  [   14    20]]

 [[28591     0]
  [   13    51]]

 [[28638     4]
  [   12     1]]

 [[28632     4]
  [   10     9]]

 [[28583     1]
  [   10    61]]

 [[28620     4]
  [   22     9]]

 [[28559     2]
  [    3    91]]

 [[28598    11]
  [   11    35]]

 [[28630     0]
  [    5    20]]

 [[28277    32]
  [   20   326]]

 [[28624     0]
  [   13    18]]

 [[28635     0]
  [   19     1]]

 [[28464    24]
  [   66   101]]

 [[28618     1]
  [    9    27]]

 [[28595     0]
  [    6    54]]

 [[28589     4]
  [   10    52]]

 [[28644     0]
  [   10     1]]

 [[28643     0]
  [   11     1]]

 [[28611     4]
  [   29    11]]

 [[28571    10]
  [   17    57]]

 [[28599     0]
  [    0    56]]

 [[28638     1]
  [    3    13]]

 [[28599     5]
  [   47     4]]

 [[28627     9]
  [    1    18]]

 [[28624     2]
  [    9    20]]

 [[28550     4]
  [   13    88]]

 [[28642     1]
  [    7     5]]

 [[28642     0]
  [    0    13]]

 [[28578    10]
  [   15    52]]

 [[28575     4]
  [   10    66]]

 [[28643     1]
  [    0    11]]

 [[28618     0]
  [    8    29]]

 [[26830   212]
  [  156  1457]]

 [[28352     4]
  [    8   291]]

 [[28408     4]
  [    7   236]]

 [[28479     7]
  [    9   160]]

 [[27441   191]
  [  212   811]]

 [[28228    75]
  [  108   244]]

 [[28563     6]
  [   17    69]]

 [[27776   273]
  [   93   513]]

 [[28045    67]
  [   59   484]]

 [[28575     1]
  [   20    59]]

 [[27581   120]
  [   93   861]]

 [[28384    24]
  [   19   228]]

 [[28621     0]
  [    2    32]]

 [[27492   286]
  [  102   775]]

 [[28568    10]
  [   40    37]]

 [[27879   210]
  [   77   489]]

 [[28631     0]
  [   23     1]]

 [[28583    17]
  [   25    30]]

 [[28396     4]
  [   11   244]]

 [[28641     1]
  [   12     1]]

 [[28187    11]
  [   26   431]]

 [[28613     5]
  [   10    27]]

 [[27067   399]
  [  146  1043]]

 [[28379    53]
  [   34   189]]

 [[28635     1]
  [   14     5]]

 [[28290     8]
  [   17   340]]

 [[28618     5]
  [   13    19]]

 [[28642     0]
  [   13     0]]

 [[28525     2]
  [    7   121]]

 [[28642     0]
  [    6     7]]

 [[27991   204]
  [   71   389]]

 [[28546     5]
  [   22    82]]

 [[28596     6]
  [   42    11]]

 [[28553    19]
  [   35    48]]

 [[28555    21]
  [   43    36]]

 [[28564     7]
  [   12    72]]

 [[28254    67]
  [   54   280]]

 [[28630     1]
  [   21     3]]

 [[27702   435]
  [  101   417]]

 [[28530    37]
  [   76    12]]

 [[28641     1]
  [    9     4]]

 [[28063   112]
  [  158   322]]

 [[28485    43]
  [   36    91]]

 [[28631     0]
  [    1    23]]

 [[28495     7]
  [   43   110]]

 [[28635     0]
  [   19     1]]

 [[28624     4]
  [   23     4]]

 [[28612     1]
  [   10    32]]

 [[28615     6]
  [   29     5]]

 [[28503    53]
  [   65    34]]

 [[28187    52]
  [   78   338]]

 [[28533     4]
  [   65    53]]

 [[28540    16]
  [   37    62]]

 [[28387    15]
  [   77   176]]

 [[28534     6]
  [    6   109]]

 [[28142    90]
  [  112   311]]

 [[28557     0]
  [   29    69]]

 [[28594     1]
  [   17    43]]

 [[28336    54]
  [   38   227]]

 [[28617     2]
  [    4    32]]

 [[27908   252]
  [   57   438]]

 [[28640     1]
  [    5     9]]

 [[27733   312]
  [   32   578]]

 [[28440     9]
  [   22   184]]

 [[28629     4]
  [    6    16]]

 [[28085    35]
  [   81   454]]

 [[28552     5]
  [   46    52]]

 [[28559    10]
  [   40    46]]

 [[28544     1]
  [   10   100]]

 [[27754    43]
  [  140   718]]

 [[28589     5]
  [   44    17]]

 [[28441     6]
  [   21   187]]

 [[28642     0]
  [   13     0]]

 [[28584     5]
  [   21    45]]

 [[28494     4]
  [   13   144]]

 [[28570     1]
  [    1    83]]

 [[28599     1]
  [   23    32]]

 [[28474    28]
  [   52   101]]

 [[28603     0]
  [    3    49]]

 [[28501     7]
  [   14   133]]

 [[28573     6]
  [   28    48]]

 [[28637     0]
  [    5    13]]

 [[28422    36]
  [   27   170]]

 [[28184    21]
  [   46   404]]

 [[28643     0]
  [    5     7]]

 [[28613     0]
  [   15    27]]

 [[28640     0]
  [    2    13]]

 [[28447     4]
  [    8   196]]

 [[28579     0]
  [    5    71]]

 [[28392     7]
  [   54   202]]

 [[28635     1]
  [   18     1]]

 [[28642     0]
  [    2    11]]

 [[28579     9]
  [   24    43]]

 [[27176    15]
  [   92  1372]]

 [[28485    23]
  [   13   134]]

 [[28554     3]
  [   14    84]]

 [[28165    35]
  [   41   414]]

 [[28570     3]
  [    4    78]]

 [[28240     5]
  [   21   389]]

 [[28229    20]
  [   17   389]]

 [[28641     2]
  [   11     1]]

 [[28493    13]
  [   15   134]]

 [[27893    60]
  [   31   671]]

 [[28454     5]
  [    7   189]]

 [[28623     0]
  [    7    25]]

 [[28575    11]
  [   10    59]]

 [[28553     9]
  [    3    90]]

 [[28622     0]
  [    7    26]]

 [[28601     4]
  [   25    25]]

 [[28461    40]
  [   10   144]]]

===scores report===
metrics	scores
Accuracy	0.8343
MCC	0.8310
log_loss	0.7436
f1 score weighted	0.8301
f1 score macro	0.7126
f1 score micro	0.8343
roc_auc ovr	0.9932
roc_auc ovo	0.9903
precision	0.8442
recall	0.8343

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83205d6580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83205d6730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83205d6880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83205d6610>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  96.,  46., 108.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.91      0.85       824
         1.0       0.00      0.00      0.00        14
         2.0       0.95      0.66      0.78        32
         3.0       0.00      0.00      0.00        12
         4.0       0.93      0.79      0.85        52
         5.0       0.86      0.84      0.85       175
         6.0       0.65      0.55      0.60       101
         7.0       0.61      0.19      0.29        98
         8.0       0.50      0.36      0.42        14
         9.0       0.76      0.36      0.49        70
        10.0       0.85      0.65      0.74       104
        11.0       0.56      0.28      0.37        18
        12.0       0.71      0.33      0.45        15
        13.0       0.81      0.69      0.74        42
        14.0       0.92      0.32      0.48        34
        15.0       0.86      0.91      0.88        65
        16.0       1.00      0.08      0.14        13
        17.0       0.88      0.37      0.52        19
        18.0       1.00      0.85      0.92        72
        19.0       1.00      0.40      0.57        30
        20.0       0.83      0.98      0.90        94
        21.0       0.77      0.96      0.85        46
        22.0       0.90      0.76      0.83        25
        23.0       0.78      0.98      0.87       345
        24.0       0.86      0.80      0.83        30
        25.0       0.67      0.10      0.17        20
        26.0       0.64      0.74      0.69       168
        27.0       0.96      0.63      0.76        35
        28.0       0.98      0.87      0.92        61
        29.0       0.92      0.71      0.80        63
        30.0       0.78      0.64      0.70        11
        31.0       0.14      0.08      0.11        12
        32.0       0.50      0.35      0.41        40
        33.0       0.94      0.68      0.79        74
        34.0       1.00      1.00      1.00        57
        35.0       0.86      0.75      0.80        16
        36.0       0.37      0.20      0.26        50
        37.0       1.00      0.90      0.95        20
        38.0       0.91      0.69      0.78        29
        39.0       0.87      0.92      0.89       101
        40.0       1.00      0.17      0.29        12
        41.0       1.00      1.00      1.00        14
        42.0       0.91      0.73      0.81        67
        43.0       0.90      0.91      0.90        76
        44.0       1.00      0.91      0.95        11
        45.0       0.94      0.92      0.93        37
        46.0       0.82      0.94      0.88      1613
        47.0       0.85      0.99      0.91       299
        48.0       1.00      0.96      0.98       243
        49.0       0.99      0.91      0.95       168
        50.0       0.78      0.83      0.80      1024
        51.0       0.67      0.70      0.68       353
        52.0       0.87      0.80      0.83        85
        53.0       0.88      0.70      0.78       606
        54.0       0.88      0.91      0.90       543
        55.0       0.91      0.76      0.83        79
        56.0       0.90      0.88      0.89       954
        57.0       0.87      0.88      0.88       247
        58.0       0.91      0.88      0.90        34
        59.0       0.94      0.83      0.88       876
        60.0       0.89      0.67      0.77        76
        61.0       0.86      0.81      0.83       566
        62.0       0.86      0.25      0.39        24
        63.0       0.97      0.51      0.67        55
        64.0       0.98      0.97      0.98       255
        65.0       0.80      0.31      0.44        13
        66.0       0.94      0.96      0.95       457
        67.0       0.93      0.68      0.78        37
        68.0       0.72      0.90      0.80      1189
        69.0       0.88      0.81      0.84       223
        70.0       0.54      0.74      0.62        19
        71.0       0.95      0.93      0.94       357
        72.0       0.94      0.48      0.64        31
        73.0       0.00      0.00      0.00        13
        74.0       1.00      0.98      0.99       128
        75.0       0.92      0.85      0.88        13
        76.0       0.81      0.77      0.79       461
        77.0       0.94      0.81      0.87       104
        78.0       0.73      0.21      0.32        53
        79.0       0.83      0.48      0.61        83
        80.0       0.64      0.59      0.62        79
        81.0       0.91      0.80      0.85        84
        82.0       0.84      0.87      0.86       334
        83.0       0.58      0.58      0.58        24
        84.0       0.88      0.69      0.77       518
        85.0       0.73      0.09      0.16        88
        86.0       1.00      0.42      0.59        12
        87.0       0.68      0.72      0.70       481
        88.0       0.89      0.56      0.68       126
        89.0       1.00      1.00      1.00        24
        90.0       0.90      0.80      0.85       152
        91.0       0.67      0.20      0.31        20
        92.0       0.86      0.22      0.35        27
        93.0       0.88      0.71      0.79        42
        94.0       1.00      0.12      0.22        33
        95.0       0.66      0.42      0.51       100
        96.0       0.68      0.84      0.75       415
        97.0       0.84      0.50      0.63       118
        98.0       0.91      0.79      0.84       100
        99.0       0.76      0.82      0.79       253
       100.0       0.97      0.97      0.97       116
       101.0       0.79      0.80      0.80       423
       102.0       0.76      0.77      0.76        99
       103.0       0.77      0.68      0.73        60
       104.0       0.57      0.87      0.69       265
       105.0       0.91      0.89      0.90        36
       106.0       0.86      0.86      0.86       495
       107.0       1.00      0.73      0.85        15
       108.0       0.89      0.89      0.89       611
       109.0       0.99      0.89      0.94       207
       110.0       0.91      0.45      0.61        22
       111.0       0.68      0.91      0.77       535
       112.0       0.72      0.59      0.65        98
       113.0       0.72      0.68      0.70        87
       114.0       0.96      0.87      0.91       110
       115.0       0.79      0.91      0.85       858
       116.0       0.52      0.43      0.47        60
       117.0       0.99      0.87      0.93       209
       118.0       0.00      0.00      0.00        12
       119.0       0.96      0.70      0.81        66
       120.0       0.99      0.89      0.94       157
       121.0       0.98      0.98      0.98        84
       122.0       0.84      0.56      0.67        55
       123.0       0.82      0.71      0.76       153
       124.0       0.98      0.84      0.91        51
       125.0       0.85      0.92      0.88       146
       126.0       0.80      0.48      0.60        77
       127.0       1.00      0.83      0.91        18
       128.0       0.86      0.88      0.87       197
       129.0       0.97      0.94      0.95       450
       130.0       0.40      0.18      0.25        11
       131.0       0.92      0.57      0.71        42
       132.0       1.00      0.80      0.89        15
       133.0       0.98      0.97      0.98       204
       134.0       1.00      0.96      0.98        76
       135.0       0.73      0.90      0.80       256
       136.0       0.80      0.20      0.32        20
       137.0       0.59      0.77      0.67        13
       138.0       0.58      0.73      0.64        67
       139.0       0.98      0.97      0.97      1464
       140.0       0.91      0.84      0.88       147
       141.0       0.96      0.82      0.88        98
       142.0       0.97      0.90      0.93       455
       143.0       0.93      0.93      0.93        82
       144.0       0.94      0.96      0.95       410
       145.0       0.91      0.97      0.94       406
       146.0       0.75      0.25      0.38        12
       147.0       0.83      0.95      0.89       148
       148.0       0.83      0.97      0.89       702
       149.0       0.96      0.97      0.96       196
       150.0       0.86      0.75      0.80        32
       151.0       0.89      0.96      0.92        69
       152.0       0.89      0.97      0.93        93
       153.0       0.97      0.88      0.92        33
       154.0       0.93      0.84      0.88        50
       155.0       0.95      0.90      0.92       153

    accuracy                           0.84     28655
   macro avg       0.82      0.69      0.73     28655
weighted avg       0.85      0.84      0.84     28655


===confusion_matrix===

[[751   0   0 ...   0   0   0]
 [  4   0   0 ...   0   0   0]
 [  1   0  21 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   2]
 [  0   0   0 ...   0  42   4]
 [  0   0   0 ...   0   3 137]]

===multilabel confusion matrix===

[[[27637   194]
  [   73   751]]

 [[28641     0]
  [   14     0]]

 [[28622     1]
  [   11    21]]

 [[28643     0]
  [   12     0]]

 [[28600     3]
  [   11    41]]

 [[28456    24]
  [   28   147]]

 [[28524    30]
  [   45    56]]

 [[28545    12]
  [   79    19]]

 [[28636     5]
  [    9     5]]

 [[28577     8]
  [   45    25]]

 [[28539    12]
  [   36    68]]

 [[28633     4]
  [   13     5]]

 [[28638     2]
  [   10     5]]

 [[28606     7]
  [   13    29]]

 [[28620     1]
  [   23    11]]

 [[28580    10]
  [    6    59]]

 [[28642     0]
  [   12     1]]

 [[28635     1]
  [   12     7]]

 [[28583     0]
  [   11    61]]

 [[28625     0]
  [   18    12]]

 [[28542    19]
  [    2    92]]

 [[28596    13]
  [    2    44]]

 [[28628     2]
  [    6    19]]

 [[28215    95]
  [    8   337]]

 [[28621     4]
  [    6    24]]

 [[28634     1]
  [   18     2]]

 [[28418    69]
  [   44   124]]

 [[28619     1]
  [   13    22]]

 [[28593     1]
  [    8    53]]

 [[28588     4]
  [   18    45]]

 [[28642     2]
  [    4     7]]

 [[28637     6]
  [   11     1]]

 [[28601    14]
  [   26    14]]

 [[28578     3]
  [   24    50]]

 [[28598     0]
  [    0    57]]

 [[28637     2]
  [    4    12]]

 [[28588    17]
  [   40    10]]

 [[28635     0]
  [    2    18]]

 [[28624     2]
  [    9    20]]

 [[28540    14]
  [    8    93]]

 [[28643     0]
  [   10     2]]

 [[28641     0]
  [    0    14]]

 [[28583     5]
  [   18    49]]

 [[28571     8]
  [    7    69]]

 [[28644     0]
  [    1    10]]

 [[28616     2]
  [    3    34]]

 [[26713   329]
  [  102  1511]]

 [[28304    52]
  [    4   295]]

 [[28411     1]
  [   10   233]]

 [[28485     2]
  [   15   153]]

 [[27389   242]
  [  179   845]]

 [[28179   123]
  [  106   247]]

 [[28560    10]
  [   17    68]]

 [[27992    57]
  [  179   427]]

 [[28047    65]
  [   49   494]]

 [[28570     6]
  [   19    60]]

 [[27606    95]
  [  111   843]]

 [[28376    32]
  [   30   217]]

 [[28618     3]
  [    4    30]]

 [[27734    45]
  [  148   728]]

 [[28573     6]
  [   25    51]]

 [[28014    75]
  [  108   458]]

 [[28630     1]
  [   18     6]]

 [[28599     1]
  [   27    28]]

 [[28395     5]
  [    7   248]]

 [[28641     1]
  [    9     4]]

 [[28170    28]
  [   18   439]]

 [[28616     2]
  [   12    25]]

 [[27052   414]
  [  120  1069]]

 [[28407    25]
  [   43   180]]

 [[28624    12]
  [    5    14]]

 [[28279    19]
  [   24   333]]

 [[28623     1]
  [   16    15]]

 [[28640     2]
  [   13     0]]

 [[28527     0]
  [    3   125]]

 [[28641     1]
  [    2    11]]

 [[28110    84]
  [  107   354]]

 [[28546     5]
  [   20    84]]

 [[28598     4]
  [   42    11]]

 [[28564     8]
  [   43    40]]

 [[28550    26]
  [   32    47]]

 [[28564     7]
  [   17    67]]

 [[28266    55]
  [   42   292]]

 [[28621    10]
  [   10    14]]

 [[28088    49]
  [  162   356]]

 [[28564     3]
  [   80     8]]

 [[28643     0]
  [    7     5]]

 [[28009   165]
  [  136   345]]

 [[28520     9]
  [   56    70]]

 [[28631     0]
  [    0    24]]

 [[28490    13]
  [   31   121]]

 [[28633     2]
  [   16     4]]

 [[28627     1]
  [   21     6]]

 [[28609     4]
  [   12    30]]

 [[28622     0]
  [   29     4]]

 [[28533    22]
  [   58    42]]

 [[28077   163]
  [   66   349]]

 [[28526    11]
  [   59    59]]

 [[28547     8]
  [   21    79]]

 [[28337    65]
  [   46   207]]

 [[28535     4]
  [    4   112]]

 [[28142    90]
  [   84   339]]

 [[28532    24]
  [   23    76]]

 [[28583    12]
  [   19    41]]

 [[28220   170]
  [   35   230]]

 [[28616     3]
  [    4    32]]

 [[28092    68]
  [   68   427]]

 [[28640     0]
  [    4    11]]

 [[27977    67]
  [   69   542]]

 [[28446     2]
  [   23   184]]

 [[28632     1]
  [   12    10]]

 [[27887   233]
  [   50   485]]

 [[28535    22]
  [   40    58]]

 [[28545    23]
  [   28    59]]

 [[28541     4]
  [   14    96]]

 [[27590   207]
  [   78   780]]

 [[28571    24]
  [   34    26]]

 [[28445     1]
  [   28   181]]

 [[28642     1]
  [   12     0]]

 [[28587     2]
  [   20    46]]

 [[28497     1]
  [   17   140]]

 [[28569     2]
  [    2    82]]

 [[28594     6]
  [   24    31]]

 [[28479    23]
  [   45   108]]

 [[28603     1]
  [    8    43]]

 [[28485    24]
  [   12   134]]

 [[28569     9]
  [   40    37]]

 [[28637     0]
  [    3    15]]

 [[28431    27]
  [   24   173]]

 [[28190    15]
  [   29   421]]

 [[28641     3]
  [    9     2]]

 [[28611     2]
  [   18    24]]

 [[28640     0]
  [    3    12]]

 [[28448     3]
  [    7   197]]

 [[28579     0]
  [    3    73]]

 [[28313    86]
  [   26   230]]

 [[28634     1]
  [   16     4]]

 [[28635     7]
  [    3    10]]

 [[28552    36]
  [   18    49]]

 [[27160    31]
  [   43  1421]]

 [[28496    12]
  [   23   124]]

 [[28554     3]
  [   18    80]]

 [[28186    14]
  [   45   410]]

 [[28567     6]
  [    6    76]]

 [[28218    27]
  [   15   395]]

 [[28209    40]
  [   13   393]]

 [[28642     1]
  [    9     3]]

 [[28479    28]
  [    8   140]]

 [[27813   140]
  [   22   680]]

 [[28451     8]
  [    6   190]]

 [[28619     4]
  [    8    24]]

 [[28578     8]
  [    3    66]]

 [[28551    11]
  [    3    90]]

 [[28621     1]
  [    4    29]]

 [[28602     3]
  [    8    42]]

 [[28495     7]
  [   16   137]]]

===scores report===
metrics	scores
Accuracy	0.8424
MCC	0.8392
log_loss	0.7164
f1 score weighted	0.8367
f1 score macro	0.7303
f1 score micro	0.8424
roc_auc ovr	0.9938
roc_auc ovo	0.9904
precision	0.8474
recall	0.8424

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f83205d6580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f83205d6730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f83205d6880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f83205d6610>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56., 115., ...,  96., 109.,  88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.94      0.79       824
         1.0       0.00      0.00      0.00        14
         2.0       0.92      0.72      0.81        32
         3.0       0.00      0.00      0.00        11
         4.0       0.89      0.76      0.82        51
         5.0       0.98      0.65      0.78       176
         6.0       0.67      0.28      0.40       102
         7.0       0.80      0.04      0.08        97
         8.0       0.83      0.36      0.50        14
         9.0       0.53      0.27      0.36        70
        10.0       0.73      0.86      0.79       103
        11.0       0.00      0.00      0.00        18
        12.0       0.00      0.00      0.00        15
        13.0       0.88      0.51      0.65        43
        14.0       1.00      0.41      0.58        34
        15.0       0.81      0.78      0.80        65
        16.0       0.00      0.00      0.00        13
        17.0       0.80      0.42      0.55        19
        18.0       1.00      0.85      0.92        72
        19.0       1.00      0.03      0.06        30
        20.0       0.78      0.99      0.87        94
        21.0       0.94      0.65      0.77        46
        22.0       0.88      0.28      0.42        25
        23.0       0.92      0.94      0.93       345
        24.0       0.92      0.40      0.56        30
        25.0       0.00      0.00      0.00        20
        26.0       0.81      0.52      0.63       168
        27.0       1.00      0.69      0.81        35
        28.0       0.98      0.85      0.91        61
        29.0       0.88      0.79      0.83        63
        30.0       1.00      0.27      0.43        11
        31.0       1.00      0.08      0.15        12
        32.0       0.91      0.25      0.39        40
        33.0       0.81      0.65      0.72        74
        34.0       1.00      1.00      1.00        57
        35.0       0.94      1.00      0.97        15
        36.0       0.69      0.18      0.29        50
        37.0       0.94      0.89      0.92        19
        38.0       0.85      0.59      0.69        29
        39.0       0.98      0.90      0.94       101
        40.0       1.00      0.08      0.14        13
        41.0       1.00      0.79      0.88        14
        42.0       0.82      0.80      0.81        66
        43.0       0.90      0.86      0.88        76
        44.0       0.69      1.00      0.81        11
        45.0       1.00      0.78      0.88        37
        46.0       0.93      0.89      0.91      1612
        47.0       0.95      0.99      0.97       299
        48.0       1.00      0.96      0.98       243
        49.0       0.85      0.91      0.88       168
        50.0       0.87      0.75      0.81      1024
        51.0       0.87      0.64      0.73       353
        52.0       0.91      0.82      0.86        85
        53.0       0.52      0.85      0.65       606
        54.0       0.88      0.88      0.88       543
        55.0       0.97      0.76      0.85        78
        56.0       0.96      0.84      0.89       954
        57.0       0.92      0.88      0.90       247
        58.0       0.97      1.00      0.99        34
        59.0       0.91      0.80      0.85       877
        60.0       0.65      0.61      0.63        76
        61.0       0.90      0.76      0.83       566
        62.0       0.00      0.00      0.00        24
        63.0       0.78      0.45      0.57        55
        64.0       0.99      0.97      0.98       255
        65.0       1.00      0.50      0.67        14
        66.0       0.97      0.95      0.96       457
        67.0       1.00      0.46      0.63        37
        68.0       0.47      0.95      0.63      1189
        69.0       0.83      0.81      0.82       224
        70.0       0.56      0.74      0.64        19
        71.0       1.00      0.92      0.96       357
        72.0       0.65      0.41      0.50        32
        73.0       0.00      0.00      0.00        12
        74.0       0.98      0.96      0.97       127
        75.0       1.00      0.42      0.59        12
        76.0       0.84      0.71      0.77       460
        77.0       0.95      0.82      0.88       103
        78.0       0.93      0.27      0.42        52
        79.0       0.95      0.43      0.60        83
        80.0       0.57      0.39      0.46        80
        81.0       0.91      0.82      0.86        84
        82.0       0.98      0.82      0.89       334
        83.0       0.86      0.26      0.40        23
        84.0       0.69      0.66      0.67       519
        85.0       0.00      0.00      0.00        88
        86.0       0.67      0.17      0.27        12
        87.0       0.70      0.65      0.67       480
        88.0       0.97      0.56      0.71       126
        89.0       1.00      1.00      1.00        25
        90.0       0.97      0.73      0.83       152
        91.0       0.60      0.15      0.24        20
        92.0       1.00      0.29      0.44        28
        93.0       0.94      0.74      0.83        42
        94.0       0.35      0.26      0.30        34
        95.0       0.83      0.10      0.18       100
        96.0       0.90      0.75      0.81       415
        97.0       0.98      0.37      0.54       118
        98.0       0.85      0.81      0.83        99
        99.0       0.82      0.80      0.81       253
       100.0       0.96      0.93      0.94       116
       101.0       0.40      0.88      0.55       423
       102.0       0.86      0.77      0.81        99
       103.0       0.93      0.70      0.80        60
       104.0       0.72      0.88      0.79       265
       105.0       1.00      0.76      0.86        37
       106.0       1.00      0.70      0.82       495
       107.0       1.00      0.60      0.75        15
       108.0       0.95      0.82      0.88       611
       109.0       1.00      0.83      0.90       206
       110.0       1.00      0.36      0.53        22
       111.0       0.66      0.89      0.76       534
       112.0       0.74      0.62      0.68        98
       113.0       0.95      0.41      0.58        87
       114.0       0.94      0.88      0.91       110
       115.0       0.93      0.84      0.88       858
       116.0       0.56      0.54      0.55        61
       117.0       0.99      0.84      0.91       209
       118.0       0.00      0.00      0.00        13
       119.0       1.00      0.58      0.74        65
       120.0       0.96      0.97      0.97       156
       121.0       0.97      0.98      0.97        85
       122.0       0.86      0.43      0.57        56
       123.0       0.94      0.66      0.77       154
       124.0       1.00      0.81      0.89        52
       125.0       0.68      0.92      0.78       146
       126.0       0.76      0.53      0.63        77
       127.0       1.00      0.78      0.88        18
       128.0       0.90      0.84      0.87       198
       129.0       0.66      0.96      0.78       450
       130.0       1.00      0.45      0.62        11
       131.0       0.94      0.37      0.53        43
       132.0       1.00      0.80      0.89        15
       133.0       0.97      0.96      0.96       205
       134.0       1.00      0.94      0.97        77
       135.0       0.87      0.67      0.76       255
       136.0       0.50      0.05      0.09        20
       137.0       1.00      0.83      0.91        12
       138.0       0.76      0.46      0.57        67
       139.0       0.87      0.99      0.93      1464
       140.0       0.60      0.88      0.72       147
       141.0       0.91      0.79      0.84        98
       142.0       0.91      0.90      0.90       455
       143.0       0.99      0.93      0.96        82
       144.0       0.97      0.92      0.95       411
       145.0       0.96      0.95      0.96       405
       146.0       0.00      0.00      0.00        11
       147.0       0.98      0.84      0.91       148
       148.0       0.96      0.95      0.96       702
       149.0       0.99      0.97      0.98       196
       150.0       0.86      0.56      0.68        32
       151.0       0.89      0.81      0.85        69
       152.0       0.85      0.95      0.90        93
       153.0       0.86      0.94      0.90        33
       154.0       0.76      0.96      0.85        50
       155.0       0.95      0.85      0.90       154

    accuracy                           0.81     28655
   macro avg       0.81      0.64      0.68     28655
weighted avg       0.84      0.81      0.81     28655


===confusion_matrix===

[[774   0   0 ...   0   0   0]
 [  2   0   0 ...   0   0   0]
 [  0   0  23 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  48   0]
 [  0   0   0 ...   1  13 131]]

===multilabel confusion matrix===

[[[27479   352]
  [   50   774]]

 [[28640     1]
  [   14     0]]

 [[28621     2]
  [    9    23]]

 [[28644     0]
  [   11     0]]

 [[28599     5]
  [   12    39]]

 [[28477     2]
  [   61   115]]

 [[28539    14]
  [   73    29]]

 [[28557     1]
  [   93     4]]

 [[28640     1]
  [    9     5]]

 [[28568    17]
  [   51    19]]

 [[28519    33]
  [   14    89]]

 [[28637     0]
  [   18     0]]

 [[28640     0]
  [   15     0]]

 [[28609     3]
  [   21    22]]

 [[28621     0]
  [   20    14]]

 [[28578    12]
  [   14    51]]

 [[28642     0]
  [   13     0]]

 [[28634     2]
  [   11     8]]

 [[28583     0]
  [   11    61]]

 [[28625     0]
  [   29     1]]

 [[28535    26]
  [    1    93]]

 [[28607     2]
  [   16    30]]

 [[28629     1]
  [   18     7]]

 [[28282    28]
  [   21   324]]

 [[28624     1]
  [   18    12]]

 [[28635     0]
  [   20     0]]

 [[28467    20]
  [   81    87]]

 [[28620     0]
  [   11    24]]

 [[28593     1]
  [    9    52]]

 [[28585     7]
  [   13    50]]

 [[28644     0]
  [    8     3]]

 [[28643     0]
  [   11     1]]

 [[28614     1]
  [   30    10]]

 [[28570    11]
  [   26    48]]

 [[28598     0]
  [    0    57]]

 [[28639     1]
  [    0    15]]

 [[28601     4]
  [   41     9]]

 [[28635     1]
  [    2    17]]

 [[28623     3]
  [   12    17]]

 [[28552     2]
  [   10    91]]

 [[28642     0]
  [   12     1]]

 [[28641     0]
  [    3    11]]

 [[28577    12]
  [   13    53]]

 [[28572     7]
  [   11    65]]

 [[28639     5]
  [    0    11]]

 [[28618     0]
  [    8    29]]

 [[26935   108]
  [  179  1433]]

 [[28341    15]
  [    2   297]]

 [[28411     1]
  [    9   234]]

 [[28459    28]
  [   15   153]]

 [[27517   114]
  [  255   769]]

 [[28267    35]
  [  128   225]]

 [[28563     7]
  [   15    70]]

 [[27580   469]
  [   89   517]]

 [[28046    66]
  [   63   480]]

 [[28575     2]
  [   19    59]]

 [[27665    36]
  [  154   800]]

 [[28390    18]
  [   30   217]]

 [[28620     1]
  [    0    34]]

 [[27705    73]
  [  176   701]]

 [[28554    25]
  [   30    46]]

 [[28043    46]
  [  135   431]]

 [[28631     0]
  [   24     0]]

 [[28593     7]
  [   30    25]]

 [[28398     2]
  [    7   248]]

 [[28641     0]
  [    7     7]]

 [[28185    13]
  [   25   432]]

 [[28618     0]
  [   20    17]]

 [[26187  1279]
  [   59  1130]]

 [[28394    37]
  [   42   182]]

 [[28625    11]
  [    5    14]]

 [[28297     1]
  [   27   330]]

 [[28616     7]
  [   19    13]]

 [[28643     0]
  [   12     0]]

 [[28526     2]
  [    5   122]]

 [[28643     0]
  [    7     5]]

 [[28132    63]
  [  134   326]]

 [[28548     4]
  [   19    84]]

 [[28602     1]
  [   38    14]]

 [[28570     2]
  [   47    36]]

 [[28552    23]
  [   49    31]]

 [[28564     7]
  [   15    69]]

 [[28315     6]
  [   61   273]]

 [[28631     1]
  [   17     6]]

 [[27982   154]
  [  178   341]]

 [[28567     0]
  [   88     0]]

 [[28642     1]
  [   10     2]]

 [[28043   132]
  [  170   310]]

 [[28527     2]
  [   55    71]]

 [[28630     0]
  [    0    25]]

 [[28500     3]
  [   41   111]]

 [[28633     2]
  [   17     3]]

 [[28627     0]
  [   20     8]]

 [[28611     2]
  [   11    31]]

 [[28604    17]
  [   25     9]]

 [[28553     2]
  [   90    10]]

 [[28204    36]
  [  105   310]]

 [[28536     1]
  [   74    44]]

 [[28542    14]
  [   19    80]]

 [[28358    44]
  [   50   203]]

 [[28534     5]
  [    8   108]]

 [[27666   566]
  [   51   372]]

 [[28544    12]
  [   23    76]]

 [[28592     3]
  [   18    42]]

 [[28299    91]
  [   33   232]]

 [[28618     0]
  [    9    28]]

 [[28159     1]
  [  149   346]]

 [[28640     0]
  [    6     9]]

 [[28019    25]
  [  107   504]]

 [[28449     0]
  [   36   170]]

 [[28633     0]
  [   14     8]]

 [[27872   249]
  [   59   475]]

 [[28536    21]
  [   37    61]]

 [[28566     2]
  [   51    36]]

 [[28539     6]
  [   13    97]]

 [[27746    51]
  [  139   719]]

 [[28568    26]
  [   28    33]]

 [[28445     1]
  [   33   176]]

 [[28642     0]
  [   13     0]]

 [[28590     0]
  [   27    38]]

 [[28493     6]
  [    4   152]]

 [[28567     3]
  [    2    83]]

 [[28595     4]
  [   32    24]]

 [[28494     7]
  [   53   101]]

 [[28603     0]
  [   10    42]]

 [[28445    64]
  [   11   135]]

 [[28565    13]
  [   36    41]]

 [[28637     0]
  [    4    14]]

 [[28439    18]
  [   32   166]]

 [[27979   226]
  [   17   433]]

 [[28644     0]
  [    6     5]]

 [[28611     1]
  [   27    16]]

 [[28640     0]
  [    3    12]]

 [[28444     6]
  [    9   196]]

 [[28578     0]
  [    5    72]]

 [[28375    25]
  [   83   172]]

 [[28634     1]
  [   19     1]]

 [[28643     0]
  [    2    10]]

 [[28578    10]
  [   36    31]]

 [[26982   209]
  [   15  1449]]

 [[28422    86]
  [   17   130]]

 [[28549     8]
  [   21    77]]

 [[28159    41]
  [   47   408]]

 [[28572     1]
  [    6    76]]

 [[28234    10]
  [   32   379]]

 [[28233    17]
  [   19   386]]

 [[28644     0]
  [   11     0]]

 [[28505     2]
  [   23   125]]

 [[27924    29]
  [   33   669]]

 [[28457     2]
  [    5   191]]

 [[28620     3]
  [   14    18]]

 [[28579     7]
  [   13    56]]

 [[28547    15]
  [    5    88]]

 [[28617     5]
  [    2    31]]

 [[28590    15]
  [    2    48]]

 [[28494     7]
  [   23   131]]]

===scores report===
metrics	scores
Accuracy	0.8116
MCC	0.8085
log_loss	0.8899
f1 score weighted	0.8089
f1 score macro	0.6841
f1 score micro	0.8116
roc_auc ovr	0.9921
roc_auc ovo	0.9887
precision	0.8434
recall	0.8116

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8553531546621999	0.8523793672840668	0.6616009617811699	0.852410047988458	0.7517400113130664	0.8553531546621999	0.9943310339962085	0.9916482234963735	0.8608531105527583	0.8553531546621999
1	0.8330483336241493	0.8297674695273288	0.7578518873968626	0.8328914769220733	0.716957442033064	0.8330483336241493	0.9934854712839198	0.9907647342823445	0.8534357086076159	0.8330483336241493
2	0.8343395567963706	0.8309905573084726	0.7435698224308651	0.8301269206230937	0.7125543446635147	0.8343395567963706	0.9932033928460995	0.9903201685035433	0.8442407121016808	0.8343395567963706
3	0.8424358750654336	0.8391840143645349	0.7163643741854334	0.8366937147625777	0.730300469611746	0.8424358750654336	0.9938375536418297	0.9903649419839395	0.8473811268547956	0.8424358750654336
4	0.8116210085499913	0.8085349649328304	0.8898562762128734	0.808928557712418	0.6841293993037775	0.8116210085499913	0.9921244493920982	0.9886889089488818	0.8434398056078432	0.8116210085499913
mean	0.835359585739629	0.8321712746834468	0.7538486644014408	0.8322101436017242	0.7191363333850338	0.835359585739629	0.9933963802320311	0.9903573954430167	0.8498700927449387	0.835359585739629
std	0.014280889757006516	0.014306593135790028	0.07554397594642777	0.013964059740497229	0.022186452302911296	0.014280889757006516	0.0007390806511649472	0.0009609840758067397	0.006520333840249826	0.014280889757006516

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 72685.3923 secs

