/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_middle_bilstm_attentio_cv_only_enz_hot_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f02a054e670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f02a054e7c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f02a054e880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f02a054e5b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.93      0.84       911
         1.0       1.00      0.55      0.71        53
         2.0       1.00      0.69      0.81       179
         3.0       0.67      0.16      0.26        25
         4.0       0.94      0.40      0.56       112
         5.0       0.95      0.57      0.72       491
         6.0       1.00      0.80      0.89        64
         7.0       0.90      0.24      0.38        37
         8.0       0.91      0.83      0.87       206
         9.0       0.93      0.77      0.85        71
        10.0       0.92      0.88      0.90       404
        11.0       0.86      0.38      0.52        16
        12.0       0.89      0.68      0.77       378
        13.0       0.99      0.66      0.79       191
        14.0       0.67      0.05      0.10        76
        15.0       0.73      0.73      0.73        66
        16.0       0.91      0.77      0.83       141
        17.0       0.99      0.58      0.73       182
        18.0       1.00      0.75      0.86        12
        19.0       1.00      0.87      0.93        38
        20.0       0.90      0.92      0.91      2162
        21.0       0.97      0.96      0.96       168
        22.0       0.71      0.81      0.76      1470
        23.0       0.82      0.90      0.86      1259
        24.0       0.61      0.94      0.74       956
        25.0       0.97      0.87      0.92       283
        26.0       0.78      0.93      0.85      3919
        27.0       0.96      0.91      0.93       531
        28.0       1.00      0.67      0.80        12
        29.0       0.83      0.73      0.77      2345
        30.0       0.88      0.52      0.65       615
        31.0       1.00      0.66      0.79        32
        32.0       0.85      0.69      0.76      1449
        33.0       0.80      0.83      0.82       893
        34.0       0.86      0.91      0.89      1377
        35.0       1.00      0.45      0.62        22
        36.0       0.90      0.84      0.87       844
        37.0       0.80      0.89      0.84      1142
        38.0       0.91      0.85      0.88       314
        39.0       0.70      0.55      0.62        56
        40.0       0.93      0.72      0.81       154
        41.0       0.91      0.92      0.91        52
        42.0       0.82      0.76      0.79       247
        43.0       0.98      0.73      0.83       198
        44.0       0.96      0.86      0.91       529
        45.0       0.97      0.87      0.91       540
        46.0       1.00      0.05      0.10        20
        47.0       0.96      0.57      0.72        80
        48.0       1.00      0.94      0.97      1466
        49.0       0.97      0.89      0.93       148
        50.0       0.93      0.96      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.99      0.94      0.97       151
        53.0       0.95      0.96      0.95       903
        54.0       0.93      0.64      0.76       108
        55.0       0.77      0.96      0.85        93
        56.0       0.88      0.91      0.90        33
        57.0       0.80      0.84      0.82        49
        58.0       0.86      0.77      0.81       154

    accuracy                           0.84     29892
   macro avg       0.88      0.72      0.77     29892
weighted avg       0.86      0.84      0.84     29892


===confusion_matrix===

[[844   0   0 ...   0   0   0]
 [  0  29   0 ...   0   0   0]
 [  4   0 123 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   0]
 [  0   0   0 ...   0  41   4]
 [  0   0   0 ...   1   9 118]]

===multilabel confusion matrix===

[[[28715   266]
  [   67   844]]

 [[29839     0]
  [   24    29]]

 [[29713     0]
  [   56   123]]

 [[29865     2]
  [   21     4]]

 [[29777     3]
  [   67    45]]

 [[29386    15]
  [  209   282]]

 [[29828     0]
  [   13    51]]

 [[29854     1]
  [   28     9]]

 [[29669    17]
  [   35   171]]

 [[29817     4]
  [   16    55]]

 [[29459    29]
  [   48   356]]

 [[29875     1]
  [   10     6]]

 [[29482    32]
  [  120   258]]

 [[29700     1]
  [   65   126]]

 [[29814     2]
  [   72     4]]

 [[29808    18]
  [   18    48]]

 [[29740    11]
  [   33   108]]

 [[29709     1]
  [   76   106]]

 [[29880     0]
  [    3     9]]

 [[29854     0]
  [    5    33]]

 [[27521   209]
  [  174  1988]]

 [[29719     5]
  [    7   161]]

 [[27935   487]
  [  279  1191]]

 [[28381   252]
  [  128  1131]]

 [[28366   570]
  [   53   903]]

 [[29601     8]
  [   37   246]]

 [[24920  1053]
  [  267  3652]]

 [[29341    20]
  [   50   481]]

 [[29880     0]
  [    4     8]]

 [[27187   360]
  [  635  1710]]

 [[29232    45]
  [  294   321]]

 [[29860     0]
  [   11    21]]

 [[28271   172]
  [  455   994]]

 [[28816   183]
  [  148   745]]

 [[28310   205]
  [  118  1259]]

 [[29870     0]
  [   12    10]]

 [[28965    83]
  [  134   710]]

 [[28489   261]
  [  120  1022]]

 [[29553    25]
  [   47   267]]

 [[29823    13]
  [   25    31]]

 [[29729     9]
  [   43   111]]

 [[29835     5]
  [    4    48]]

 [[29605    40]
  [   59   188]]

 [[29691     3]
  [   54   144]]

 [[29346    17]
  [   74   455]]

 [[29335    17]
  [   71   469]]

 [[29872     0]
  [   19     1]]

 [[29810     2]
  [   34    46]]

 [[28423     3]
  [   92  1374]]

 [[29740     4]
  [   17   131]]

 [[28337   102]
  [   64  1389]]

 [[29880     0]
  [   12     0]]

 [[29740     1]
  [    9   142]]

 [[28946    43]
  [   39   864]]

 [[29779     5]
  [   39    69]]

 [[29772    27]
  [    4    89]]

 [[29855     4]
  [    3    30]]

 [[29833    10]
  [    8    41]]

 [[29719    19]
  [   36   118]]]

===scores report===
metrics	scores
Accuracy	0.8439
MCC	0.8357
log_loss	0.6411
f1 score weighted	0.8408
f1 score macro	0.7657
f1 score micro	0.8439
roc_auc ovr	0.9909
roc_auc ovo	0.9877
precision	0.8553
recall	0.8439

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f02a054e670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f02a054e7c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f02a054e880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f02a054e5b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.92      0.90       912
         1.0       0.97      0.74      0.84        53
         2.0       0.97      0.77      0.86       179
         3.0       0.55      0.24      0.33        25
         4.0       0.82      0.58      0.68       112
         5.0       0.80      0.75      0.78       492
         6.0       0.98      0.75      0.85        65
         7.0       0.84      0.55      0.67        38
         8.0       0.91      0.86      0.89       206
         9.0       0.83      0.70      0.76        71
        10.0       0.96      0.87      0.92       405
        11.0       0.88      0.41      0.56        17
        12.0       0.85      0.78      0.81       377
        13.0       0.90      0.77      0.83       191
        14.0       0.62      0.30      0.41        76
        15.0       0.85      0.68      0.76        66
        16.0       0.93      0.80      0.86       140
        17.0       0.90      0.80      0.85       182
        18.0       1.00      1.00      1.00        11
        19.0       0.97      0.81      0.88        37
        20.0       0.94      0.94      0.94      2163
        21.0       0.96      0.94      0.95       169
        22.0       0.85      0.83      0.84      1469
        23.0       0.81      0.92      0.86      1259
        24.0       0.93      0.89      0.91       956
        25.0       0.93      0.89      0.91       282
        26.0       0.84      0.93      0.88      3919
        27.0       0.96      0.93      0.95       531
        28.0       0.92      1.00      0.96        12
        29.0       0.77      0.83      0.80      2346
        30.0       0.73      0.76      0.74       615
        31.0       1.00      0.81      0.90        32
        32.0       0.82      0.79      0.80      1450
        33.0       0.85      0.84      0.84       893
        34.0       0.93      0.91      0.92      1376
        35.0       1.00      0.50      0.67        22
        36.0       0.87      0.87      0.87       843
        37.0       0.93      0.88      0.90      1142
        38.0       0.98      0.88      0.92       314
        39.0       0.89      0.59      0.71        56
        40.0       0.92      0.69      0.79       154
        41.0       1.00      0.94      0.97        52
        42.0       0.86      0.84      0.85       247
        43.0       0.99      0.83      0.90       198
        44.0       0.94      0.87      0.91       529
        45.0       0.94      0.91      0.93       539
        46.0       1.00      0.42      0.59        19
        47.0       0.95      0.76      0.85        80
        48.0       0.97      0.99      0.98      1466
        49.0       0.92      0.89      0.90       148
        50.0       0.96      0.96      0.96      1453
        51.0       0.67      0.33      0.44        12
        52.0       0.98      0.91      0.95       151
        53.0       0.97      0.97      0.97       903
        54.0       0.84      0.85      0.84       108
        55.0       0.96      0.95      0.95        93
        56.0       0.97      0.88      0.92        33
        57.0       0.86      0.86      0.86        49
        58.0       0.88      0.84      0.86       154

    accuracy                           0.88     29892
   macro avg       0.90      0.79      0.83     29892
weighted avg       0.88      0.88      0.88     29892


===confusion_matrix===

[[840   0   0 ...   0   0   0]
 [  0  39   0 ...   0   0   0]
 [  0   0 138 ...   0   0   0]
 ...
 [  0   0   0 ...  29   1   1]
 [  0   0   0 ...   0  42   7]
 [  0   0   0 ...   1   6 129]]

===multilabel confusion matrix===

[[[28869   111]
  [   72   840]]

 [[29838     1]
  [   14    39]]

 [[29709     4]
  [   41   138]]

 [[29862     5]
  [   19     6]]

 [[29766    14]
  [   47    65]]

 [[29308    92]
  [  122   370]]

 [[29826     1]
  [   16    49]]

 [[29850     4]
  [   17    21]]

 [[29669    17]
  [   29   177]]

 [[29811    10]
  [   21    50]]

 [[29474    13]
  [   52   353]]

 [[29874     1]
  [   10     7]]

 [[29463    52]
  [   82   295]]

 [[29685    16]
  [   44   147]]

 [[29802    14]
  [   53    23]]

 [[29818     8]
  [   21    45]]

 [[29743     9]
  [   28   112]]

 [[29693    17]
  [   36   146]]

 [[29881     0]
  [    0    11]]

 [[29854     1]
  [    7    30]]

 [[27596   133]
  [  126  2037]]

 [[29717     6]
  [   10   159]]

 [[28208   215]
  [  253  1216]]

 [[28369   264]
  [  104  1155]]

 [[28875    61]
  [  106   850]]

 [[29591    19]
  [   32   250]]

 [[25270   703]
  [  258  3661]]

 [[29340    21]
  [   36   495]]

 [[29879     1]
  [    0    12]]

 [[26958   588]
  [  395  1951]]

 [[29106   171]
  [  149   466]]

 [[29860     0]
  [    6    26]]

 [[28186   256]
  [  309  1141]]

 [[28865   134]
  [  144   749]]

 [[28415   101]
  [  117  1259]]

 [[29870     0]
  [   11    11]]

 [[28941   108]
  [  113   730]]

 [[28669    81]
  [  137  1005]]

 [[29571     7]
  [   38   276]]

 [[29832     4]
  [   23    33]]

 [[29729     9]
  [   48   106]]

 [[29840     0]
  [    3    49]]

 [[29612    33]
  [   40   207]]

 [[29692     2]
  [   34   164]]

 [[29336    27]
  [   68   461]]

 [[29321    32]
  [   46   493]]

 [[29873     0]
  [   11     8]]

 [[29809     3]
  [   19    61]]

 [[28375    51]
  [   20  1446]]

 [[29732    12]
  [   16   132]]

 [[28377    62]
  [   64  1389]]

 [[29878     2]
  [    8     4]]

 [[29738     3]
  [   13   138]]

 [[28961    28]
  [   29   874]]

 [[29766    18]
  [   16    92]]

 [[29795     4]
  [    5    88]]

 [[29858     1]
  [    4    29]]

 [[29836     7]
  [    7    42]]

 [[29721    17]
  [   25   129]]]

===scores report===
metrics	scores
Accuracy	0.8804
MCC	0.8739
log_loss	0.5083
f1 score weighted	0.8797
f1 score macro	0.8325
f1 score micro	0.8804
roc_auc ovr	0.9932
roc_auc ovo	0.9908
precision	0.8825
recall	0.8804

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f02a054e670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f02a054e7c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f02a054e880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f02a054e5b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.83      0.87       912
         1.0       0.91      0.77      0.83        52
         2.0       0.72      0.83      0.77       179
         3.0       0.50      0.08      0.14        25
         4.0       0.93      0.37      0.53       112
         5.0       0.88      0.69      0.77       492
         6.0       1.00      0.85      0.92        65
         7.0       0.70      0.42      0.52        38
         8.0       0.69      0.86      0.77       205
         9.0       0.88      0.72      0.79        71
        10.0       0.98      0.85      0.91       405
        11.0       0.82      0.53      0.64        17
        12.0       0.76      0.75      0.76       377
        13.0       0.99      0.70      0.82       190
        14.0       1.00      0.01      0.03        76
        15.0       0.84      0.70      0.76        67
        16.0       0.97      0.81      0.88       140
        17.0       0.94      0.64      0.77       183
        18.0       1.00      0.92      0.96        12
        19.0       1.00      0.86      0.93        37
        20.0       0.94      0.90      0.92      2162
        21.0       0.99      0.94      0.96       169
        22.0       0.74      0.81      0.77      1470
        23.0       0.92      0.82      0.87      1259
        24.0       0.85      0.91      0.88       956
        25.0       0.86      0.95      0.90       282
        26.0       0.68      0.96      0.80      3918
        27.0       0.90      0.91      0.90       531
        28.0       1.00      0.77      0.87        13
        29.0       0.88      0.66      0.76      2346
        30.0       0.69      0.72      0.70       615
        31.0       0.96      0.75      0.84        32
        32.0       0.93      0.72      0.81      1450
        33.0       0.92      0.72      0.81       893
        34.0       0.93      0.88      0.90      1376
        35.0       1.00      0.45      0.62        22
        36.0       0.59      0.90      0.71       843
        37.0       0.88      0.89      0.89      1142
        38.0       0.89      0.90      0.90       314
        39.0       0.81      0.40      0.54        55
        40.0       0.70      0.71      0.70       154
        41.0       1.00      0.75      0.86        52
        42.0       0.88      0.74      0.81       247
        43.0       0.98      0.79      0.87       197
        44.0       0.92      0.89      0.91       530
        45.0       0.95      0.84      0.89       540
        46.0       1.00      0.05      0.10        19
        47.0       1.00      0.53      0.69        79
        48.0       0.99      0.97      0.98      1465
        49.0       0.84      0.89      0.86       149
        50.0       0.98      0.91      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.99      0.89      0.94       152
        53.0       0.90      0.97      0.93       903
        54.0       0.94      0.82      0.88       108
        55.0       0.98      0.90      0.94        93
        56.0       0.97      0.97      0.97        32
        57.0       0.97      0.74      0.84        50
        58.0       0.84      0.97      0.90       154

    accuracy                           0.84     29892
   macro avg       0.87      0.74      0.77     29892
weighted avg       0.86      0.84      0.84     29892


===confusion_matrix===

[[753   0   0 ...   0   0   0]
 [  0  40   1 ...   0   0   1]
 [  1   0 149 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  37  13]
 [  0   0   0 ...   1   0 149]]

===multilabel confusion matrix===

[[[28908    72]
  [  159   753]]

 [[29836     4]
  [   12    40]]

 [[29656    57]
  [   30   149]]

 [[29865     2]
  [   23     2]]

 [[29777     3]
  [   71    41]]

 [[29353    47]
  [  152   340]]

 [[29827     0]
  [   10    55]]

 [[29847     7]
  [   22    16]]

 [[29609    78]
  [   28   177]]

 [[29814     7]
  [   20    51]]

 [[29481     6]
  [   62   343]]

 [[29873     2]
  [    8     9]]

 [[29425    90]
  [   93   284]]

 [[29701     1]
  [   57   133]]

 [[29816     0]
  [   75     1]]

 [[29816     9]
  [   20    47]]

 [[29748     4]
  [   27   113]]

 [[29702     7]
  [   65   118]]

 [[29880     0]
  [    1    11]]

 [[29855     0]
  [    5    32]]

 [[27614   116]
  [  224  1938]]

 [[29721     2]
  [   10   159]]

 [[28001   421]
  [  282  1188]]

 [[28544    89]
  [  228  1031]]

 [[28777   159]
  [   88   868]]

 [[29565    45]
  [   15   267]]

 [[24220  1754]
  [  142  3776]]

 [[29306    55]
  [   47   484]]

 [[29879     0]
  [    3    10]]

 [[27342   204]
  [  789  1557]]

 [[29079   198]
  [  175   440]]

 [[29859     1]
  [    8    24]]

 [[28358    84]
  [  401  1049]]

 [[28943    56]
  [  253   640]]

 [[28422    94]
  [  172  1204]]

 [[29870     0]
  [   12    10]]

 [[28512   537]
  [   84   759]]

 [[28617   133]
  [  126  1016]]

 [[29543    35]
  [   30   284]]

 [[29832     5]
  [   33    22]]

 [[29691    47]
  [   45   109]]

 [[29840     0]
  [   13    39]]

 [[29619    26]
  [   63   184]]

 [[29692     3]
  [   42   155]]

 [[29320    42]
  [   56   474]]

 [[29329    23]
  [   87   453]]

 [[29873     0]
  [   18     1]]

 [[29813     0]
  [   37    42]]

 [[28418     9]
  [   44  1421]]

 [[29717    26]
  [   17   132]]

 [[28410    29]
  [  138  1315]]

 [[29880     0]
  [   12     0]]

 [[29738     2]
  [   16   136]]

 [[28891    98]
  [   30   873]]

 [[29778     6]
  [   19    89]]

 [[29797     2]
  [    9    84]]

 [[29859     1]
  [    1    31]]

 [[29841     1]
  [   13    37]]

 [[29710    28]
  [    5   149]]]

===scores report===
metrics	scores
Accuracy	0.8419
MCC	0.8343
log_loss	0.6414
f1 score weighted	0.8412
f1 score macro	0.7749
f1 score micro	0.8419
roc_auc ovr	0.9911
roc_auc ovo	0.9889
precision	0.8614
recall	0.8419

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f02a054e670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f02a054e7c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f02a054e880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f02a054e5b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.91      0.85       912
         1.0       0.83      0.83      0.83        52
         2.0       0.76      0.78      0.77       179
         3.0       1.00      0.12      0.22        24
         4.0       0.57      0.53      0.55       112
         5.0       0.58      0.78      0.67       492
         6.0       0.96      0.78      0.86        64
         7.0       0.57      0.32      0.41        38
         8.0       0.96      0.80      0.87       205
         9.0       0.98      0.69      0.81        70
        10.0       0.94      0.86      0.90       405
        11.0       0.89      0.47      0.62        17
        12.0       0.69      0.82      0.75       378
        13.0       0.89      0.73      0.80       191
        14.0       0.25      0.01      0.03        76
        15.0       0.76      0.63      0.69        67
        16.0       0.93      0.89      0.91       140
        17.0       0.67      0.74      0.70       183
        18.0       1.00      0.92      0.96        12
        19.0       0.97      0.92      0.94        37
        20.0       0.91      0.94      0.92      2162
        21.0       1.00      0.93      0.97       168
        22.0       0.75      0.85      0.80      1470
        23.0       0.72      0.92      0.81      1259
        24.0       0.96      0.87      0.91       955
        25.0       0.83      0.96      0.89       282
        26.0       0.93      0.85      0.89      3918
        27.0       0.94      0.91      0.92       532
        28.0       1.00      0.92      0.96        13
        29.0       0.80      0.78      0.79      2346
        30.0       0.70      0.75      0.72       616
        31.0       0.96      0.75      0.84        32
        32.0       0.72      0.83      0.77      1449
        33.0       0.78      0.83      0.80       893
        34.0       0.98      0.84      0.91      1377
        35.0       0.82      0.64      0.72        22
        36.0       0.87      0.86      0.87       844
        37.0       0.93      0.87      0.90      1142
        38.0       0.99      0.87      0.92       314
        39.0       0.97      0.55      0.70        56
        40.0       0.95      0.69      0.80       153
        41.0       0.96      0.86      0.91        51
        42.0       0.86      0.77      0.81       246
        43.0       0.97      0.87      0.91       197
        44.0       0.94      0.89      0.92       530
        45.0       0.92      0.89      0.90       540
        46.0       1.00      0.15      0.26        20
        47.0       0.76      0.62      0.68        80
        48.0       0.97      0.98      0.97      1465
        49.0       0.93      0.86      0.89       148
        50.0       0.94      0.94      0.94      1453
        51.0       0.00      0.00      0.00        13
        52.0       0.97      0.87      0.92       151
        53.0       0.98      0.95      0.96       904
        54.0       0.99      0.75      0.85       108
        55.0       0.80      0.97      0.88        93
        56.0       0.97      1.00      0.99        33
        57.0       0.96      0.96      0.96        50
        58.0       0.91      0.83      0.87       153

    accuracy                           0.86     29892
   macro avg       0.85      0.76      0.79     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[826   1   0 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  0   0 139 ...   0   0   0]
 ...
 [  0   0   0 ...  33   0   0]
 [  0   0   0 ...   0  48   2]
 [  0   0   0 ...   1   2 127]]

===multilabel confusion matrix===

[[[28785   195]
  [   86   826]]

 [[29831     9]
  [    9    43]]

 [[29669    44]
  [   40   139]]

 [[29868     0]
  [   21     3]]

 [[29735    45]
  [   53    59]]

 [[29127   273]
  [  109   383]]

 [[29826     2]
  [   14    50]]

 [[29845     9]
  [   26    12]]

 [[29680     7]
  [   41   164]]

 [[29821     1]
  [   22    48]]

 [[29466    21]
  [   57   348]]

 [[29874     1]
  [    9     8]]

 [[29372   142]
  [   68   310]]

 [[29684    17]
  [   51   140]]

 [[29813     3]
  [   75     1]]

 [[29812    13]
  [   25    42]]

 [[29742    10]
  [   15   125]]

 [[29643    66]
  [   48   135]]

 [[29880     0]
  [    1    11]]

 [[29854     1]
  [    3    34]]

 [[27525   205]
  [  136  2026]]

 [[29724     0]
  [   11   157]]

 [[27997   425]
  [  215  1255]]

 [[28181   452]
  [   97  1162]]

 [[28898    39]
  [  127   828]]

 [[29553    57]
  [   12   270]]

 [[25727   247]
  [  579  3339]]

 [[29330    30]
  [   50   482]]

 [[29879     0]
  [    1    12]]

 [[27078   468]
  [  523  1823]]

 [[29080   196]
  [  156   460]]

 [[29859     1]
  [    8    24]]

 [[27979   464]
  [  241  1208]]

 [[28784   215]
  [  151   742]]

 [[28495    20]
  [  214  1163]]

 [[29867     3]
  [    8    14]]

 [[28942   106]
  [  117   727]]

 [[28680    70]
  [  145   997]]

 [[29574     4]
  [   41   273]]

 [[29835     1]
  [   25    31]]

 [[29733     6]
  [   48   105]]

 [[29839     2]
  [    7    44]]

 [[29614    32]
  [   56   190]]

 [[29689     6]
  [   26   171]]

 [[29330    32]
  [   56   474]]

 [[29311    41]
  [   62   478]]

 [[29872     0]
  [   17     3]]

 [[29796    16]
  [   30    50]]

 [[28375    52]
  [   29  1436]]

 [[29735     9]
  [   21   127]]

 [[28359    80]
  [   84  1369]]

 [[29879     0]
  [   13     0]]

 [[29737     4]
  [   20   131]]

 [[28967    21]
  [   45   859]]

 [[29783     1]
  [   27    81]]

 [[29777    22]
  [    3    90]]

 [[29858     1]
  [    0    33]]

 [[29840     2]
  [    2    48]]

 [[29726    13]
  [   26   127]]]

===scores report===
metrics	scores
Accuracy	0.8594
MCC	0.8522
log_loss	0.5737
f1 score weighted	0.8596
f1 score macro	0.7893
f1 score micro	0.8594
roc_auc ovr	0.9916
roc_auc ovo	0.9900
precision	0.8668
recall	0.8594

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f02a054e670>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f02a054e7c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f02a054e880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f02a054e5b0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.89      0.89       911
         1.0       0.93      0.70      0.80        53
         2.0       0.94      0.78      0.85       180
         3.0       0.62      0.20      0.30        25
         4.0       0.86      0.40      0.54       111
         5.0       0.71      0.73      0.72       491
         6.0       0.36      0.95      0.52        64
         7.0       0.55      0.30      0.39        37
         8.0       0.89      0.86      0.88       205
         9.0       0.91      0.72      0.80        71
        10.0       0.81      0.90      0.85       404
        11.0       0.44      0.41      0.42        17
        12.0       0.81      0.76      0.79       378
        13.0       0.63      0.79      0.70       191
        14.0       0.17      0.01      0.02        76
        15.0       0.77      0.65      0.70        66
        16.0       0.83      0.79      0.81       140
        17.0       0.88      0.76      0.82       182
        18.0       1.00      1.00      1.00        12
        19.0       0.93      0.70      0.80        37
        20.0       0.97      0.90      0.93      2162
        21.0       0.99      0.93      0.96       168
        22.0       0.73      0.82      0.78      1470
        23.0       0.93      0.82      0.87      1259
        24.0       0.80      0.93      0.86       955
        25.0       0.86      0.94      0.90       283
        26.0       0.85      0.90      0.88      3919
        27.0       0.96      0.92      0.94       532
        28.0       1.00      0.85      0.92        13
        29.0       0.87      0.75      0.80      2345
        30.0       0.65      0.76      0.70       616
        31.0       1.00      0.81      0.90        32
        32.0       0.73      0.80      0.77      1449
        33.0       0.72      0.86      0.78       893
        34.0       0.90      0.89      0.89      1377
        35.0       1.00      0.59      0.74        22
        36.0       0.96      0.80      0.87       844
        37.0       0.89      0.90      0.89      1142
        38.0       0.97      0.90      0.94       314
        39.0       0.64      0.61      0.62        56
        40.0       0.98      0.65      0.78       153
        41.0       0.88      0.87      0.87        52
        42.0       0.88      0.76      0.82       247
        43.0       0.77      0.87      0.82       197
        44.0       0.98      0.83      0.90       529
        45.0       0.80      0.95      0.87       540
        46.0       1.00      0.20      0.33        20
        47.0       0.66      0.84      0.74        80
        48.0       0.98      0.98      0.98      1466
        49.0       0.96      0.88      0.92       148
        50.0       0.93      0.95      0.94      1453
        51.0       1.00      0.08      0.15        12
        52.0       0.95      0.88      0.91       151
        53.0       0.96      0.96      0.96       904
        54.0       0.88      0.75      0.81       108
        55.0       0.97      0.95      0.96        93
        56.0       1.00      0.88      0.94        33
        57.0       0.87      0.90      0.88        50
        58.0       0.87      0.93      0.90       154

    accuracy                           0.86     29892
   macro avg       0.84      0.76      0.78     29892
weighted avg       0.86      0.86      0.86     29892


===confusion_matrix===

[[813   0   0 ...   0   0   0]
 [  0  37   0 ...   0   0   0]
 [  0   0 141 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   2]
 [  0   0   0 ...   0  45   3]
 [  0   0   0 ...   0   5 143]]

===multilabel confusion matrix===

[[[28882    99]
  [   98   813]]

 [[29836     3]
  [   16    37]]

 [[29703     9]
  [   39   141]]

 [[29864     3]
  [   20     5]]

 [[29774     7]
  [   67    44]]

 [[29254   147]
  [  135   356]]

 [[29719   109]
  [    3    61]]

 [[29846     9]
  [   26    11]]

 [[29665    22]
  [   28   177]]

 [[29816     5]
  [   20    51]]

 [[29403    85]
  [   42   362]]

 [[29866     9]
  [   10     7]]

 [[29447    67]
  [   90   288]]

 [[29612    89]
  [   40   151]]

 [[29811     5]
  [   75     1]]

 [[29813    13]
  [   23    43]]

 [[29730    22]
  [   30   110]]

 [[29691    19]
  [   43   139]]

 [[29880     0]
  [    0    12]]

 [[29853     2]
  [   11    26]]

 [[27666    64]
  [  218  1944]]

 [[29723     1]
  [   12   156]]

 [[27986   436]
  [  263  1207]]

 [[28553    80]
  [  224  1035]]

 [[28720   217]
  [   69   886]]

 [[29564    45]
  [   16   267]]

 [[25348   625]
  [  384  3535]]

 [[29338    22]
  [   42   490]]

 [[29879     0]
  [    2    11]]

 [[27278   269]
  [  585  1760]]

 [[29027   249]
  [  147   469]]

 [[29860     0]
  [    6    26]]

 [[28020   423]
  [  288  1161]]

 [[28706   293]
  [  127   766]]

 [[28380   135]
  [  156  1221]]

 [[29870     0]
  [    9    13]]

 [[29017    31]
  [  167   677]]

 [[28621   129]
  [  119  1023]]

 [[29570     8]
  [   31   283]]

 [[29817    19]
  [   22    34]]

 [[29737     2]
  [   53   100]]

 [[29834     6]
  [    7    45]]

 [[29619    26]
  [   59   188]]

 [[29644    51]
  [   26   171]]

 [[29352    11]
  [   88   441]]

 [[29228   124]
  [   29   511]]

 [[29872     0]
  [   16     4]]

 [[29777    35]
  [   13    67]]

 [[28401    25]
  [   36  1430]]

 [[29738     6]
  [   18   130]]

 [[28341    98]
  [   71  1382]]

 [[29880     0]
  [   11     1]]

 [[29734     7]
  [   18   133]]

 [[28955    33]
  [   37   867]]

 [[29773    11]
  [   27    81]]

 [[29796     3]
  [    5    88]]

 [[29859     0]
  [    4    29]]

 [[29835     7]
  [    5    45]]

 [[29716    22]
  [   11   143]]]

===scores report===
metrics	scores
Accuracy	0.8583
MCC	0.8508
log_loss	0.5705
f1 score weighted	0.8579
f1 score macro	0.7801
f1 score micro	0.8583
roc_auc ovr	0.9916
roc_auc ovo	0.9892
precision	0.8647
recall	0.8583

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8439381774387796	0.8356873303129473	0.6411474879081163	0.8408164097301251	0.765668363177169	0.8439381774387797	0.9909219925569429	0.9877129048979933	0.855298384293329	0.8439381774387796
1	0.8804362371202997	0.8738891955847543	0.5082518298920263	0.8796785176620833	0.8324928133900814	0.8804362371202997	0.9931753147279982	0.9908389498867877	0.8824819500558745	0.8804362371202997
2	0.8418640438913422	0.8343183278505085	0.6413824230095727	0.8411723596708081	0.7748613128199504	0.8418640438913422	0.9911089153369704	0.9888590465417287	0.8613642610959151	0.8418640438913422
3	0.8594272715107721	0.852225955815367	0.5736947882306634	0.8595884551820743	0.7892652663053054	0.8594272715107721	0.9916158615021213	0.9900420703064061	0.8668112081954302	0.8594272715107721
4	0.8582563896694768	0.8508082015539833	0.5705364998892037	0.8579080217304412	0.780133788570133	0.8582563896694768	0.991628989603016	0.9892416940657306	0.864663220707662	0.8582563896694768
mean	0.8567844239261341	0.8493858022235121	0.5870026057859166	0.8558327527951064	0.7884843088525277	0.8567844239261342	0.9916902147454097	0.9893389331397294	0.8661238048696422	0.8567844239261341
std	0.0138289795941233	0.014319098401520064	0.05007743630954072	0.014334923991907162	0.02329481896528133	0.013828979594123278	0.0007928269942727328	0.0010609586744066387	0.009055801797173729	0.0138289795941233

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 74556.8718 secs

