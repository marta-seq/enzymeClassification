/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_1level
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f03241dc5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f03241dc760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f03241dc7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f03241dc580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.91      0.91      3813
         1.0       0.93      0.95      0.94     10869
         2.0       0.91      0.90      0.90      6897
         3.0       0.93      0.90      0.91      2585
         4.0       0.93      0.91      0.92      1616
         5.0       0.96      0.97      0.96      3258
         6.0       0.98      0.97      0.97      1372

    accuracy                           0.93     30410
   macro avg       0.94      0.93      0.93     30410
weighted avg       0.93      0.93      0.93     30410


===confusion_matrix===

[[ 3469   148   120    35    17    21     3]
 [   95 10325   318    53    23    42    13]
 [  108   423  6186    70    43    53    14]
 [   48   114    76  2316    16    14     1]
 [   26    53    46    12  1471     8     0]
 [   12    49    28     4     4  3161     0]
 [   14     8    15     1     0     1  1333]]

===multilabel confusion matrix===

[[[26294   303]
  [  344  3469]]

 [[18746   795]
  [  544 10325]]

 [[22910   603]
  [  711  6186]]

 [[27650   175]
  [  269  2316]]

 [[28691   103]
  [  145  1471]]

 [[27013   139]
  [   97  3161]]

 [[29007    31]
  [   39  1333]]]

===scores report===
metrics	scores
Accuracy	0.9293
MCC	0.9094
log_loss	0.2961
f1 score weighted	0.9292
f1 score macro	0.9330
f1 score micro	0.9293
roc_auc ovr	0.9927
roc_auc ovo	0.9941
precision	0.9292
recall	0.9293

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f03241dc5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f03241dc760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f03241dc7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f03241dc580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.91      0.92      3813
         1.0       0.93      0.95      0.94     10869
         2.0       0.90      0.91      0.90      6897
         3.0       0.94      0.91      0.92      2585
         4.0       0.95      0.91      0.93      1616
         5.0       0.97      0.97      0.97      3258
         6.0       0.98      0.97      0.97      1372

    accuracy                           0.93     30410
   macro avg       0.94      0.93      0.94     30410
weighted avg       0.93      0.93      0.93     30410


===confusion_matrix===

[[ 3460   143   141    30    16    14     9]
 [  103 10279   367    54    18    40     8]
 [   91   393  6292    47    26    38    10]
 [   28    85    95  2352    14     9     2]
 [   19    52    59    14  1468     4     0]
 [   13    43    44     7     5  3146     0]
 [    9     9    16     4     2     0  1332]]

===multilabel confusion matrix===

[[[26334   263]
  [  353  3460]]

 [[18816   725]
  [  590 10279]]

 [[22791   722]
  [  605  6292]]

 [[27669   156]
  [  233  2352]]

 [[28713    81]
  [  148  1468]]

 [[27047   105]
  [  112  3146]]

 [[29009    29]
  [   40  1332]]]

===scores report===
metrics	scores
Accuracy	0.9316
MCC	0.9123
log_loss	0.2908
f1 score weighted	0.9316
f1 score macro	0.9365
f1 score micro	0.9316
roc_auc ovr	0.9929
roc_auc ovo	0.9943
precision	0.9318
recall	0.9316

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f03241dc5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f03241dc760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f03241dc7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f03241dc580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.91      0.91      3814
         1.0       0.93      0.94      0.94     10869
         2.0       0.90      0.91      0.90      6896
         3.0       0.92      0.89      0.91      2584
         4.0       0.95      0.89      0.92      1617
         5.0       0.96      0.96      0.96      3258
         6.0       0.98      0.97      0.98      1372

    accuracy                           0.93     30410
   macro avg       0.94      0.93      0.93     30410
weighted avg       0.93      0.93      0.93     30410


===confusion_matrix===

[[ 3485   131   130    35     5    18    10]
 [  128 10224   372    70    29    43     3]
 [  111   393  6261    60    34    30     7]
 [   42   112    98  2305    12    14     1]
 [   27    61    58    19  1445     6     1]
 [   14    52    45     4     3  3140     0]
 [    8    17    10     2     0     4  1331]]

===multilabel confusion matrix===

[[[26266   330]
  [  329  3485]]

 [[18775   766]
  [  645 10224]]

 [[22801   713]
  [  635  6261]]

 [[27636   190]
  [  279  2305]]

 [[28710    83]
  [  172  1445]]

 [[27037   115]
  [  118  3140]]

 [[29016    22]
  [   41  1331]]]

===scores report===
metrics	scores
Accuracy	0.9270
MCC	0.9065
log_loss	0.2980
f1 score weighted	0.9270
f1 score macro	0.9314
f1 score micro	0.9270
roc_auc ovr	0.9921
roc_auc ovo	0.9935
precision	0.9272
recall	0.9270

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f03241dc5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f03241dc760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f03241dc7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f03241dc580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.91      0.90      3813
         1.0       0.93      0.94      0.94     10868
         2.0       0.91      0.91      0.91      6897
         3.0       0.92      0.89      0.91      2585
         4.0       0.94      0.88      0.91      1616
         5.0       0.96      0.96      0.96      3258
         6.0       0.98      0.97      0.97      1372

    accuracy                           0.93     30409
   macro avg       0.93      0.92      0.93     30409
weighted avg       0.93      0.93      0.93     30409


===confusion_matrix===

[[ 3472   131   128    44    10    14    14]
 [  150 10263   299    63    31    50    12]
 [  128   366  6251    70    24    53     5]
 [   65   114    79  2307    16     4     0]
 [   35    69    56    18  1430     7     1]
 [   16    54    35     5     6  3140     2]
 [   11     9    16     2     1     1  1332]]

===multilabel confusion matrix===

[[[26191   405]
  [  341  3472]]

 [[18798   743]
  [  605 10263]]

 [[22899   613]
  [  646  6251]]

 [[27622   202]
  [  278  2307]]

 [[28705    88]
  [  186  1430]]

 [[27022   129]
  [  118  3140]]

 [[29003    34]
  [   40  1332]]]

===scores report===
metrics	scores
Accuracy	0.9272
MCC	0.9067
log_loss	0.3105
f1 score weighted	0.9271
f1 score macro	0.9290
f1 score micro	0.9272
roc_auc ovr	0.9923
roc_auc ovo	0.9934
precision	0.9272
recall	0.9272

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f03241dc5b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f03241dc760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f03241dc7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f03241dc580>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.91      0.91      3813
         1.0       0.93      0.94      0.94     10868
         2.0       0.90      0.90      0.90      6897
         3.0       0.92      0.91      0.92      2585
         4.0       0.93      0.91      0.92      1616
         5.0       0.96      0.97      0.96      3258
         6.0       0.97      0.97      0.97      1372

    accuracy                           0.93     30409
   macro avg       0.93      0.93      0.93     30409
weighted avg       0.93      0.93      0.93     30409


===confusion_matrix===

[[ 3462   147   114    38    17    27     8]
 [  121 10220   377    61    31    45    13]
 [  111   419  6175    84    39    54    15]
 [   45    84    77  2352    15    11     1]
 [   25    52    46    14  1470     8     1]
 [   13    36    39     2     6  3161     1]
 [   12    17    10     3     1     3  1326]]

===multilabel confusion matrix===

[[[26269   327]
  [  351  3462]]

 [[18786   755]
  [  648 10220]]

 [[22849   663]
  [  722  6175]]

 [[27622   202]
  [  233  2352]]

 [[28684   109]
  [  146  1470]]

 [[27003   148]
  [   97  3161]]

 [[28998    39]
  [   46  1326]]]

===scores report===
metrics	scores
Accuracy	0.9262
MCC	0.9055
log_loss	0.2950
f1 score weighted	0.9262
f1 score macro	0.9304
f1 score micro	0.9262
roc_auc ovr	0.9922
roc_auc ovo	0.9939
precision	0.9261
recall	0.9262

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9293324564288064	0.9094306202042877	0.2961467950963282	0.9291883806866282	0.9330015269051106	0.9293324564288064	0.9927177802557986	0.9941214298552933	0.9292434635715189	0.9293324564288064
1	0.9315685629727063	0.912280958224504	0.29082235222791747	0.9315797493884027	0.9364897792587996	0.9315685629727062	0.9929291384936325	0.9942878051535117	0.9317601726021655	0.9315685629727063
2	0.9270305820453798	0.9064715104517206	0.2980168898941283	0.9270223028783713	0.9313664106369464	0.9270305820453798	0.9921082722209499	0.9934557572729131	0.9271774985592214	0.9270305820453798
3	0.9271926074517413	0.9067138482031324	0.31054106394656555	0.927130430450107	0.9290497477468079	0.9271926074517413	0.9923486986351888	0.9933648026096425	0.9272432326658926	0.9271926074517413
4	0.926238942418363	0.9055451046262991	0.29496997532061336	0.9261549383470472	0.930417412375696	0.926238942418363	0.992237653013019	0.9938813397815404	0.9261285833815779	0.926238942418363
mean	0.9282726302633992	0.9080884083419887	0.2980994152971106	0.9282151603501113	0.9320649753846721	0.9282726302633992	0.9924683085237177	0.9938222269345802	0.9283105901560752	0.9282726302633992
std	0.0019406917955098698	0.002463784704628279	0.006653768837082317	0.0019550795291117737	0.0025592996056882874	0.001940691795509832	0.00030715957925463004	0.00036147387743775257	0.0019977073861943643	0.0019406917955098698

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 150808.8710 secs

