/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_hot_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f570c6fe5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f570c6fe790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f570c6fe7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f570c6fe580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.73      0.77      1793
         1.0       0.83      0.86      0.84      4921
         2.0       0.79      0.81      0.80      3576
         3.0       0.69      0.70      0.69       943
         4.0       0.79      0.73      0.76       695
         5.0       0.88      0.85      0.86      1073
         6.0       0.93      0.90      0.91       471

    accuracy                           0.81     13472
   macro avg       0.81      0.80      0.81     13472
weighted avg       0.81      0.81      0.81     13472


===confusion_matrix===

[[1311  204  154   61   21   27   15]
 [ 103 4232  388  110   40   43    5]
 [ 104  412 2880   86   49   36    9]
 [  47  109   98  660   19    8    2]
 [  26   59   66   25  508    9    2]
 [  28   73   39   16   10  907    0]
 [   7   16   17    3    0    3  425]]

===multilabel confusion matrix===

[[[11364   315]
  [  482  1311]]

 [[ 7678   873]
  [  689  4232]]

 [[ 9134   762]
  [  696  2880]]

 [[12228   301]
  [  283   660]]

 [[12638   139]
  [  187   508]]

 [[12273   126]
  [  166   907]]

 [[12968    33]
  [   46   425]]]

===scores report===
metrics	scores
Accuracy	0.8108
MCC	0.7509
log_loss	0.6898
f1 score weighted	0.8104
f1 score macro	0.8051
f1 score micro	0.8108
roc_auc ovr	0.9564
roc_auc ovo	0.9621
precision	0.8110
recall	0.8108

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f570c6fe5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f570c6fe790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f570c6fe7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f570c6fe580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.75      0.78      1792
         1.0       0.85      0.82      0.84      4921
         2.0       0.75      0.83      0.79      3576
         3.0       0.70      0.68      0.69       943
         4.0       0.78      0.74      0.76       696
         5.0       0.85      0.88      0.86      1072
         6.0       0.91      0.90      0.91       471

    accuracy                           0.81     13471
   macro avg       0.81      0.80      0.80     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1343  147  184   56   22   27   13]
 [ 139 4047  523   93   40   66   13]
 [  97  324 2955   89   47   50   14]
 [  34  104  128  637   31    8    1]
 [  24   57   72   16  513   14    0]
 [  14   47   54   11    4  941    1]
 [  10   11   19    2    0    4  425]]

===multilabel confusion matrix===

[[[11361   318]
  [  449  1343]]

 [[ 7860   690]
  [  874  4047]]

 [[ 8915   980]
  [  621  2955]]

 [[12261   267]
  [  306   637]]

 [[12631   144]
  [  183   513]]

 [[12230   169]
  [  131   941]]

 [[12958    42]
  [   46   425]]]

===scores report===
metrics	scores
Accuracy	0.8063
MCC	0.7464
log_loss	0.6645
f1 score weighted	0.8063
f1 score macro	0.8028
f1 score micro	0.8063
roc_auc ovr	0.9568
roc_auc ovo	0.9638
precision	0.8079
recall	0.8063

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f570c6fe5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f570c6fe790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f570c6fe7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f570c6fe580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.76      0.77      1792
         1.0       0.79      0.89      0.84      4921
         2.0       0.85      0.71      0.78      3576
         3.0       0.67      0.70      0.68       943
         4.0       0.83      0.71      0.76       695
         5.0       0.83      0.89      0.86      1072
         6.0       0.93      0.91      0.92       472

    accuracy                           0.80     13471
   macro avg       0.81      0.79      0.80     13471
weighted avg       0.81      0.80      0.80     13471


===confusion_matrix===

[[1358  221   91   73   12   30    7]
 [ 136 4379  224   80   33   62    7]
 [ 151  618 2555  126   35   75   16]
 [  40  164   60  656   14    8    1]
 [  35   82   39   31  491   16    1]
 [  17   73   20    3    8  951    0]
 [  13   19    6    4    0    2  428]]

===multilabel confusion matrix===

[[[11287   392]
  [  434  1358]]

 [[ 7373  1177]
  [  542  4379]]

 [[ 9455   440]
  [ 1021  2555]]

 [[12211   317]
  [  287   656]]

 [[12674   102]
  [  204   491]]

 [[12206   193]
  [  121   951]]

 [[12967    32]
  [   44   428]]]

===scores report===
metrics	scores
Accuracy	0.8031
MCC	0.7422
log_loss	0.7085
f1 score weighted	0.8016
f1 score macro	0.8006
f1 score micro	0.8031
roc_auc ovr	0.9574
roc_auc ovo	0.9639
precision	0.8063
recall	0.8031

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f570c6fe5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f570c6fe790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f570c6fe7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f570c6fe580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.69      0.77      1792
         1.0       0.84      0.84      0.84      4920
         2.0       0.76      0.82      0.79      3576
         3.0       0.65      0.77      0.71       944
         4.0       0.78      0.75      0.76       695
         5.0       0.87      0.89      0.88      1072
         6.0       0.91      0.86      0.89       472

    accuracy                           0.81     13471
   macro avg       0.81      0.80      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1239  184  220   83   21   36    9]
 [  68 4127  473  129   53   56   14]
 [  47  399 2922  117   43   37   11]
 [  20   81   93  723   17    9    1]
 [  18   46   65   36  519    8    3]
 [  10   43   40   15    7  957    0]
 [  12   13   35    3    2    2  405]]

===multilabel confusion matrix===

[[[11504   175]
  [  553  1239]]

 [[ 7785   766]
  [  793  4127]]

 [[ 8969   926]
  [  654  2922]]

 [[12144   383]
  [  221   723]]

 [[12633   143]
  [  176   519]]

 [[12251   148]
  [  115   957]]

 [[12961    38]
  [   67   405]]]

===scores report===
metrics	scores
Accuracy	0.8086
MCC	0.7493
log_loss	0.6828
f1 score weighted	0.8089
f1 score macro	0.8051
f1 score micro	0.8086
roc_auc ovr	0.9564
roc_auc ovo	0.9645
precision	0.8134
recall	0.8086

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f570c6fe5e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f570c6fe790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f570c6fe7f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f570c6fe580>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.76      0.78      1792
         1.0       0.80      0.89      0.84      4920
         2.0       0.81      0.76      0.79      3576
         3.0       0.79      0.67      0.72       944
         4.0       0.88      0.66      0.75       695
         5.0       0.84      0.90      0.87      1073
         6.0       0.93      0.91      0.92       471

    accuracy                           0.81     13471
   macro avg       0.83      0.79      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1362  214  120   42   13   31   10]
 [ 120 4367  288   41   22   71   11]
 [ 121  571 2729   67   21   57   10]
 [  52  149   94  634    5   10    0]
 [  23   98   84   17  458   13    2]
 [  15   56   28    5    3  965    1]
 [  16   12   12    1    1    2  427]]

===multilabel confusion matrix===

[[[11332   347]
  [  430  1362]]

 [[ 7451  1100]
  [  553  4367]]

 [[ 9269   626]
  [  847  2729]]

 [[12354   173]
  [  310   634]]

 [[12711    65]
  [  237   458]]

 [[12214   184]
  [  108   965]]

 [[12966    34]
  [   44   427]]]

===scores report===
metrics	scores
Accuracy	0.8123
MCC	0.7524
log_loss	0.7105
f1 score weighted	0.8104
f1 score macro	0.8096
f1 score micro	0.8123
roc_auc ovr	0.9574
roc_auc ovo	0.9640
precision	0.8132
recall	0.8123

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8107927553444181	0.7509190424360221	0.6897991781808561	0.8104319318053449	0.8051097298197052	0.8107927553444181	0.9563840699885514	0.962132589851105	0.8109732862373921	0.8107927553444181
1	0.806250463959617	0.746437400408563	0.6645192110584442	0.8062857875488271	0.8027941220161907	0.806250463959617	0.9568487619088801	0.9638120800498844	0.8079493077371848	0.806250463959617
2	0.803058421794967	0.7421836321166065	0.7084593039507334	0.8015611443454427	0.8006178011126307	0.803058421794967	0.9574168623860901	0.9639283255572435	0.8062725872911634	0.803058421794967
3	0.8085517036597134	0.7492896569188298	0.6827754714308231	0.8088633488357626	0.8051367899291232	0.8085517036597135	0.9563839428551152	0.964477547265224	0.8134028395896545	0.8085517036597134
4	0.812263380595353	0.7523971758163146	0.7105305756335341	0.810421459354017	0.8096435388229875	0.812263380595353	0.9573954515363282	0.9639984238945157	0.813203115089985	0.812263380595353
mean	0.8081833450708137	0.7482453815392672	0.6912167480508782	0.8075127343778788	0.8046603963401274	0.8081833450708137	0.9568858177349929	0.9636697933235945	0.810360227189076	0.8081833450708137
std	0.0032739049430564426	0.003619115118650686	0.017066650559657295	0.0033386636984486075	0.003002869176556143	0.0032739049430564452	0.00045754504986563903	0.0008013168445140407	0.002836782535638785	0.0032739049430564426

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 32541.5723 secs

