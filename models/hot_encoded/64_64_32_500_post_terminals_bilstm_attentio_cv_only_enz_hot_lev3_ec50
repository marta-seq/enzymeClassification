/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_terminals_bilstm_attentio_cv_only_enz_hot_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff62c1106a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff62c110880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff62c1108e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff62c1105e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.71      0.78      0.75       358
         1.0       0.59      0.83      0.69        12
         2.0       1.00      0.47      0.64        19
         3.0       0.41      0.70      0.52        80
         4.0       0.53      0.15      0.23        54
         5.0       0.00      0.00      0.00        58
         6.0       0.54      0.49      0.51        45
         7.0       0.74      0.58      0.65        48
         8.0       0.00      0.00      0.00        11
         9.0       0.69      0.43      0.53        21
        10.0       0.00      0.00      0.00        15
        11.0       0.67      0.72      0.69        36
        12.0       0.75      0.50      0.60        12
        13.0       0.79      0.60      0.68        25
        14.0       1.00      0.05      0.10        19
        15.0       0.32      0.68      0.43        22
        16.0       0.63      0.52      0.57        23
        17.0       0.64      0.87      0.74       119
        18.0       0.30      0.44      0.36        18
        19.0       0.50      0.08      0.14        12
        20.0       0.74      0.31      0.44        90
        21.0       0.00      0.00      0.00        12
        22.0       0.94      0.68      0.79        25
        23.0       0.00      0.00      0.00        12
        24.0       0.08      0.05      0.06        22
        25.0       0.93      0.66      0.77        38
        26.0       0.85      1.00      0.92        17
        27.0       0.78      0.20      0.32        35
        28.0       0.20      0.09      0.13        11
        29.0       0.74      0.47      0.58        36
        30.0       0.77      0.72      0.74        32
        31.0       0.85      0.61      0.71        38
        32.0       0.85      0.76      0.80       747
        33.0       0.71      0.82      0.76        74
        34.0       0.79      0.95      0.86        59
        35.0       0.43      0.90      0.58        48
        36.0       0.85      0.57      0.68       502
        37.0       0.90      0.68      0.78       241
        38.0       0.76      0.48      0.59        33
        39.0       0.65      0.71      0.68       344
        40.0       0.76      0.68      0.72       191
        41.0       0.92      0.69      0.79        32
        42.0       0.86      0.70      0.77       384
        43.0       0.73      0.70      0.72       118
        44.0       0.79      0.69      0.73       436
        45.0       0.97      0.69      0.80        48
        46.0       0.85      0.88      0.86       402
        47.0       1.00      0.18      0.30        17
        48.0       0.67      0.48      0.56        42
        49.0       0.74      0.82      0.78        78
        50.0       0.79      0.88      0.83       172
        51.0       0.88      0.35      0.50        20
        52.0       0.68      0.63      0.65       499
        53.0       0.72      0.71      0.72       100
        54.0       0.50      0.09      0.15        11
        55.0       0.71      0.73      0.72       103
        56.0       1.00      0.28      0.43        18
        57.0       0.38      0.30      0.33        10
        58.0       0.91      0.94      0.93        34
        59.0       0.48      0.67      0.56       231
        60.0       0.95      0.62      0.75        58
        61.0       0.38      0.10      0.16        30
        62.0       0.83      0.42      0.56        48
        63.0       0.24      0.14      0.18        50
        64.0       0.71      0.50      0.59        34
        65.0       0.78      0.75      0.76       155
        66.0       0.80      0.29      0.42        14
        67.0       0.39      0.72      0.51       314
        68.0       0.00      0.00      0.00        63
        69.0       0.50      0.72      0.59       308
        70.0       0.75      0.40      0.52        68
        71.0       0.36      0.70      0.47        66
        72.0       0.00      0.00      0.00        14
        73.0       0.71      0.68      0.69        25
        74.0       0.00      0.00      0.00        18
        75.0       0.28      0.30      0.29        60
        76.0       0.70      0.67      0.68       205
        77.0       0.65      0.19      0.30        77
        78.0       0.86      0.73      0.79        59
        79.0       0.85      0.29      0.44       139
        80.0       0.69      0.74      0.71        42
        81.0       0.30      0.43      0.36       175
        82.0       0.45      0.44      0.45        43
        83.0       0.40      0.23      0.29        26
        84.0       0.85      0.27      0.41       106
        85.0       0.71      0.36      0.48        14
        86.0       0.78      0.71      0.74       242
        87.0       0.54      0.83      0.65       309
        88.0       0.75      0.78      0.76        58
        89.0       0.25      0.09      0.13        11
        90.0       0.52      0.56      0.54       187
        91.0       0.37      0.33      0.34        46
        92.0       0.23      0.07      0.11        40
        93.0       0.44      0.25      0.32        32
        94.0       0.67      0.69      0.68       289
        95.0       0.43      0.10      0.16        31
        96.0       0.85      0.59      0.70        74
        97.0       0.54      0.26      0.35        27
        98.0       0.73      0.59      0.66        37
        99.0       0.45      0.92      0.60        24
       100.0       0.00      0.00      0.00        25
       101.0       0.49      0.54      0.51        65
       102.0       0.85      0.77      0.81        22
       103.0       0.24      0.80      0.37        64
       104.0       0.53      0.42      0.47        40
       105.0       0.77      0.83      0.80        12
       106.0       0.59      0.87      0.70       114
       107.0       0.70      0.84      0.77       161
       108.0       0.92      0.50      0.65        24
       109.0       0.32      0.87      0.47        52
       110.0       1.00      0.53      0.70        15
       111.0       0.69      0.67      0.68       123
       112.0       0.22      0.76      0.34        42
       113.0       0.89      0.90      0.89       430
       114.0       0.51      0.75      0.60        65
       115.0       0.71      0.48      0.58        31
       116.0       0.88      0.70      0.78       173
       117.0       1.00      0.90      0.95        31
       118.0       0.94      0.79      0.86       117
       119.0       0.61      0.86      0.72       136
       120.0       0.44      0.76      0.56        62
       121.0       0.98      0.78      0.87       224
       122.0       0.94      0.49      0.64        35
       123.0       0.95      0.49      0.64        37
       124.0       0.74      0.55      0.63        31
       125.0       0.81      0.87      0.84        15
       126.0       0.89      0.76      0.82        21
       127.0       0.70      0.89      0.78        73

    accuracy                           0.66     12227
   macro avg       0.62      0.54      0.54     12227
weighted avg       0.69      0.66      0.66     12227


===confusion_matrix===

[[281   0   0 ...   0   0   0]
 [  0  10   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  16   4]
 [  0   0   0 ...   0   1  65]]

===multilabel confusion matrix===

[[[11755   114]
  [   77   281]]

 [[12208     7]
  [    2    10]]

 [[12208     0]
  [   10     9]]

 [[12067    80]
  [   24    56]]

 [[12166     7]
  [   46     8]]

 [[12166     3]
  [   58     0]]

 [[12163    19]
  [   23    22]]

 [[12169    10]
  [   20    28]]

 [[12216     0]
  [   11     0]]

 [[12202     4]
  [   12     9]]

 [[12212     0]
  [   15     0]]

 [[12178    13]
  [   10    26]]

 [[12213     2]
  [    6     6]]

 [[12198     4]
  [   10    15]]

 [[12208     0]
  [   18     1]]

 [[12173    32]
  [    7    15]]

 [[12197     7]
  [   11    12]]

 [[12050    58]
  [   15   104]]

 [[12190    19]
  [   10     8]]

 [[12214     1]
  [   11     1]]

 [[12127    10]
  [   62    28]]

 [[12215     0]
  [   12     0]]

 [[12201     1]
  [    8    17]]

 [[12215     0]
  [   12     0]]

 [[12193    12]
  [   21     1]]

 [[12187     2]
  [   13    25]]

 [[12207     3]
  [    0    17]]

 [[12190     2]
  [   28     7]]

 [[12212     4]
  [   10     1]]

 [[12185     6]
  [   19    17]]

 [[12188     7]
  [    9    23]]

 [[12185     4]
  [   15    23]]

 [[11379   101]
  [  183   564]]

 [[12128    25]
  [   13    61]]

 [[12153    15]
  [    3    56]]

 [[12122    57]
  [    5    43]]

 [[11673    52]
  [  218   284]]

 [[11968    18]
  [   76   165]]

 [[12189     5]
  [   17    16]]

 [[11754   129]
  [  101   243]]

 [[11996    40]
  [   62   129]]

 [[12193     2]
  [   10    22]]

 [[11798    45]
  [  114   270]]

 [[12078    31]
  [   35    83]]

 [[11709    82]
  [  136   300]]

 [[12178     1]
  [   15    33]]

 [[11762    63]
  [   49   353]]

 [[12210     0]
  [   14     3]]

 [[12175    10]
  [   22    20]]

 [[12127    22]
  [   14    64]]

 [[12016    39]
  [   21   151]]

 [[12206     1]
  [   13     7]]

 [[11576   152]
  [  183   316]]

 [[12100    27]
  [   29    71]]

 [[12215     1]
  [   10     1]]

 [[12093    31]
  [   28    75]]

 [[12209     0]
  [   13     5]]

 [[12212     5]
  [    7     3]]

 [[12190     3]
  [    2    32]]

 [[11829   167]
  [   77   154]]

 [[12167     2]
  [   22    36]]

 [[12192     5]
  [   27     3]]

 [[12175     4]
  [   28    20]]

 [[12155    22]
  [   43     7]]

 [[12186     7]
  [   17    17]]

 [[12039    33]
  [   39   116]]

 [[12212     1]
  [   10     4]]

 [[11561   352]
  [   89   225]]

 [[12158     6]
  [   63     0]]

 [[11693   226]
  [   85   223]]

 [[12150     9]
  [   41    27]]

 [[12079    82]
  [   20    46]]

 [[12211     2]
  [   14     0]]

 [[12195     7]
  [    8    17]]

 [[12206     3]
  [   18     0]]

 [[12121    46]
  [   42    18]]

 [[11963    59]
  [   68   137]]

 [[12142     8]
  [   62    15]]

 [[12161     7]
  [   16    43]]

 [[12081     7]
  [   98    41]]

 [[12171    14]
  [   11    31]]

 [[11877   175]
  [   99    76]]

 [[12161    23]
  [   24    19]]

 [[12192     9]
  [   20     6]]

 [[12116     5]
  [   77    29]]

 [[12211     2]
  [    9     5]]

 [[11937    48]
  [   70   172]]

 [[11697   221]
  [   51   258]]

 [[12154    15]
  [   13    45]]

 [[12213     3]
  [   10     1]]

 [[11943    97]
  [   82   105]]

 [[12155    26]
  [   31    15]]

 [[12177    10]
  [   37     3]]

 [[12185    10]
  [   24     8]]

 [[11841    97]
  [   89   200]]

 [[12192     4]
  [   28     3]]

 [[12145     8]
  [   30    44]]

 [[12194     6]
  [   20     7]]

 [[12182     8]
  [   15    22]]

 [[12176    27]
  [    2    22]]

 [[12201     1]
  [   25     0]]

 [[12126    36]
  [   30    35]]

 [[12202     3]
  [    5    17]]

 [[12003   160]
  [   13    51]]

 [[12172    15]
  [   23    17]]

 [[12212     3]
  [    2    10]]

 [[12043    70]
  [   15    99]]

 [[12009    57]
  [   25   136]]

 [[12202     1]
  [   12    12]]

 [[12080    95]
  [    7    45]]

 [[12212     0]
  [    7     8]]

 [[12067    37]
  [   40    83]]

 [[12073   112]
  [   10    32]]

 [[11748    49]
  [   44   386]]

 [[12114    48]
  [   16    49]]

 [[12190     6]
  [   16    15]]

 [[12037    17]
  [   52   121]]

 [[12196     0]
  [    3    28]]

 [[12104     6]
  [   24    93]]

 [[12017    74]
  [   19   117]]

 [[12106    59]
  [   15    47]]

 [[11999     4]
  [   49   175]]

 [[12191     1]
  [   18    17]]

 [[12189     1]
  [   19    18]]

 [[12190     6]
  [   14    17]]

 [[12209     3]
  [    2    13]]

 [[12204     2]
  [    5    16]]

 [[12126    28]
  [    8    65]]]

===scores report===
metrics	scores
Accuracy	0.6610
MCC	0.6544
log_loss	1.5857
f1 score weighted	0.6566
f1 score macro	0.5427
f1 score micro	0.6610
roc_auc ovr	0.9727
roc_auc ovo	0.9699
precision	0.6935
recall	0.6610

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff62c1106a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff62c110880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff62c1108e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff62c1105e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.62      0.71       357
         1.0       0.67      0.33      0.44        12
         2.0       1.00      0.68      0.81        19
         3.0       0.32      0.56      0.41        80
         4.0       0.17      0.20      0.19        54
         5.0       0.17      0.07      0.10        58
         6.0       0.24      0.30      0.26        44
         7.0       0.38      0.75      0.51        48
         8.0       0.00      0.00      0.00        11
         9.0       0.57      0.76      0.65        21
        10.0       0.07      0.07      0.07        15
        11.0       0.93      0.72      0.81        36
        12.0       0.20      0.08      0.12        12
        13.0       0.93      0.52      0.67        25
        14.0       0.10      0.20      0.13        20
        15.0       0.91      0.43      0.59        23
        16.0       0.71      0.22      0.33        23
        17.0       0.75      0.82      0.79       119
        18.0       0.75      0.35      0.48        17
        19.0       0.00      0.00      0.00        13
        20.0       0.60      0.29      0.39        90
        21.0       0.08      0.17      0.11        12
        22.0       0.67      0.56      0.61        25
        23.0       0.00      0.00      0.00        12
        24.0       1.00      0.05      0.09        22
        25.0       0.32      0.81      0.45        37
        26.0       0.69      1.00      0.82        18
        27.0       1.00      0.03      0.06        35
        28.0       0.00      0.00      0.00        12
        29.0       0.59      0.65      0.62        37
        30.0       0.71      0.47      0.57        32
        31.0       0.58      0.67      0.62        39
        32.0       0.61      0.83      0.70       746
        33.0       0.65      0.88      0.75        74
        34.0       0.82      0.84      0.83        58
        35.0       0.75      0.69      0.72        48
        36.0       0.84      0.52      0.64       502
        37.0       0.54      0.77      0.64       241
        38.0       0.60      0.27      0.37        33
        39.0       0.55      0.69      0.61       344
        40.0       0.88      0.70      0.78       191
        41.0       0.82      0.45      0.58        31
        42.0       0.64      0.76      0.70       384
        43.0       0.85      0.73      0.79       118
        44.0       0.95      0.56      0.70       436
        45.0       0.95      0.77      0.85        48
        46.0       0.79      0.90      0.85       402
        47.0       0.00      0.00      0.00        17
        48.0       0.37      0.55      0.44        42
        49.0       0.98      0.79      0.88        77
        50.0       0.93      0.80      0.86       172
        51.0       0.84      0.80      0.82        20
        52.0       0.55      0.68      0.61       499
        53.0       0.84      0.64      0.72        99
        54.0       0.50      0.18      0.27        11
        55.0       0.87      0.70      0.77       103
        56.0       0.64      0.39      0.48        18
        57.0       0.00      0.00      0.00        11
        58.0       0.65      0.88      0.75        34
        59.0       0.78      0.41      0.54       231
        60.0       0.41      0.71      0.52        58
        61.0       0.12      0.03      0.05        30
        62.0       0.76      0.33      0.46        48
        63.0       0.20      0.06      0.09        49
        64.0       0.83      0.59      0.69        34
        65.0       0.88      0.73      0.80       154
        66.0       0.40      0.14      0.21        14
        67.0       0.78      0.52      0.62       314
        68.0       0.00      0.00      0.00        63
        69.0       0.43      0.67      0.52       308
        70.0       0.51      0.33      0.40        69
        71.0       0.59      0.29      0.39        66
        72.0       0.00      0.00      0.00        14
        73.0       0.84      0.64      0.73        25
        74.0       0.00      0.00      0.00        18
        75.0       0.21      0.24      0.22        59
        76.0       0.81      0.53      0.64       205
        77.0       0.37      0.36      0.37        77
        78.0       0.67      0.47      0.55        59
        79.0       0.60      0.53      0.56       139
        80.0       0.70      0.73      0.71        41
        81.0       0.77      0.19      0.30       175
        82.0       0.70      0.53      0.61        43
        83.0       0.38      0.12      0.18        26
        84.0       0.54      0.50      0.52       105
        85.0       0.86      0.43      0.57        14
        86.0       0.86      0.57      0.69       242
        87.0       0.58      0.77      0.66       309
        88.0       0.80      0.76      0.78        58
        89.0       0.50      0.27      0.35        11
        90.0       0.48      0.43      0.46       187
        91.0       0.42      0.30      0.35        46
        92.0       0.00      0.00      0.00        40
        93.0       0.31      0.42      0.36        33
        94.0       0.85      0.54      0.66       289
        95.0       0.17      0.03      0.05        32
        96.0       0.59      0.65      0.62        74
        97.0       0.70      0.26      0.38        27
        98.0       0.65      0.46      0.54        37
        99.0       0.84      0.88      0.86        24
       100.0       0.12      0.04      0.06        26
       101.0       0.51      0.51      0.51        65
       102.0       0.67      0.18      0.29        22
       103.0       0.79      0.59      0.68        64
       104.0       0.24      0.20      0.22        40
       105.0       1.00      0.69      0.82        13
       106.0       0.44      0.88      0.59       113
       107.0       0.74      0.75      0.74       162
       108.0       0.73      0.46      0.56        24
       109.0       0.95      0.71      0.81        52
       110.0       0.73      0.73      0.73        15
       111.0       0.92      0.54      0.68       123
       112.0       0.74      0.49      0.59        41
       113.0       0.39      0.99      0.56       430
       114.0       0.83      0.62      0.71        65
       115.0       0.42      0.61      0.50        31
       116.0       0.82      0.72      0.77       173
       117.0       0.96      0.77      0.85        30
       118.0       0.81      0.85      0.83       118
       119.0       0.76      0.82      0.79       136
       120.0       0.40      0.64      0.49        61
       121.0       0.82      0.85      0.84       225
       122.0       0.94      0.94      0.94        35
       123.0       0.58      0.50      0.54        38
       124.0       0.67      0.65      0.66        31
       125.0       0.65      0.81      0.72        16
       126.0       0.58      0.90      0.70        21
       127.0       0.67      0.70      0.68        73

    accuracy                           0.63     12227
   macro avg       0.59      0.50      0.51     12227
weighted avg       0.67      0.63      0.62     12227


===confusion_matrix===

[[223   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0  13 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  19   1]
 [  0   0   0 ...   0   8  51]]

===multilabel confusion matrix===

[[[11826    44]
  [  134   223]]

 [[12213     2]
  [    8     4]]

 [[12208     0]
  [    6    13]]

 [[12053    94]
  [   35    45]]

 [[12121    52]
  [   43    11]]

 [[12150    19]
  [   54     4]]

 [[12141    42]
  [   31    13]]

 [[12121    58]
  [   12    36]]

 [[12214     2]
  [   11     0]]

 [[12194    12]
  [    5    16]]

 [[12198    14]
  [   14     1]]

 [[12189     2]
  [   10    26]]

 [[12211     4]
  [   11     1]]

 [[12201     1]
  [   12    13]]

 [[12169    38]
  [   16     4]]

 [[12203     1]
  [   13    10]]

 [[12202     2]
  [   18     5]]

 [[12076    32]
  [   21    98]]

 [[12208     2]
  [   11     6]]

 [[12214     0]
  [   13     0]]

 [[12120    17]
  [   64    26]]

 [[12193    22]
  [   10     2]]

 [[12195     7]
  [   11    14]]

 [[12215     0]
  [   12     0]]

 [[12205     0]
  [   21     1]]

 [[12125    65]
  [    7    30]]

 [[12201     8]
  [    0    18]]

 [[12192     0]
  [   34     1]]

 [[12215     0]
  [   12     0]]

 [[12173    17]
  [   13    24]]

 [[12189     6]
  [   17    15]]

 [[12169    19]
  [   13    26]]

 [[11078   403]
  [  125   621]]

 [[12118    35]
  [    9    65]]

 [[12158    11]
  [    9    49]]

 [[12168    11]
  [   15    33]]

 [[11675    50]
  [  241   261]]

 [[11830   156]
  [   55   186]]

 [[12188     6]
  [   24     9]]

 [[11686   197]
  [  106   238]]

 [[12018    18]
  [   58   133]]

 [[12193     3]
  [   17    14]]

 [[11677   166]
  [   91   293]]

 [[12094    15]
  [   32    86]]

 [[11777    14]
  [  194   242]]

 [[12177     2]
  [   11    37]]

 [[11731    94]
  [   39   363]]

 [[12210     0]
  [   17     0]]

 [[12146    39]
  [   19    23]]

 [[12149     1]
  [   16    61]]

 [[12045    10]
  [   35   137]]

 [[12204     3]
  [    4    16]]

 [[11456   272]
  [  162   337]]

 [[12116    12]
  [   36    63]]

 [[12214     2]
  [    9     2]]

 [[12113    11]
  [   31    72]]

 [[12205     4]
  [   11     7]]

 [[12216     0]
  [   11     0]]

 [[12177    16]
  [    4    30]]

 [[11969    27]
  [  136    95]]

 [[12111    58]
  [   17    41]]

 [[12190     7]
  [   29     1]]

 [[12174     5]
  [   32    16]]

 [[12166    12]
  [   46     3]]

 [[12189     4]
  [   14    20]]

 [[12058    15]
  [   41   113]]

 [[12210     3]
  [   12     2]]

 [[11868    45]
  [  152   162]]

 [[12136    28]
  [   63     0]]

 [[11643   276]
  [  102   206]]

 [[12136    22]
  [   46    23]]

 [[12148    13]
  [   47    19]]

 [[12209     4]
  [   14     0]]

 [[12199     3]
  [    9    16]]

 [[12208     1]
  [   18     0]]

 [[12114    54]
  [   45    14]]

 [[11997    25]
  [   97   108]]

 [[12102    48]
  [   49    28]]

 [[12154    14]
  [   31    28]]

 [[12038    50]
  [   65    74]]

 [[12173    13]
  [   11    30]]

 [[12042    10]
  [  142    33]]

 [[12174    10]
  [   20    23]]

 [[12196     5]
  [   23     3]]

 [[12076    46]
  [   52    53]]

 [[12212     1]
  [    8     6]]

 [[11962    23]
  [  103   139]]

 [[11746   172]
  [   70   239]]

 [[12158    11]
  [   14    44]]

 [[12213     3]
  [    8     3]]

 [[11953    87]
  [  106    81]]

 [[12162    19]
  [   32    14]]

 [[12187     0]
  [   40     0]]

 [[12163    31]
  [   19    14]]

 [[11910    28]
  [  134   155]]

 [[12190     5]
  [   31     1]]

 [[12120    33]
  [   26    48]]

 [[12197     3]
  [   20     7]]

 [[12181     9]
  [   20    17]]

 [[12199     4]
  [    3    21]]

 [[12194     7]
  [   25     1]]

 [[12130    32]
  [   32    33]]

 [[12203     2]
  [   18     4]]

 [[12153    10]
  [   26    38]]

 [[12161    26]
  [   32     8]]

 [[12214     0]
  [    4     9]]

 [[11987   127]
  [   13   100]]

 [[12023    42]
  [   41   121]]

 [[12199     4]
  [   13    11]]

 [[12173     2]
  [   15    37]]

 [[12208     4]
  [    4    11]]

 [[12098     6]
  [   56    67]]

 [[12179     7]
  [   21    20]]

 [[11143   654]
  [    4   426]]

 [[12154     8]
  [   25    40]]

 [[12170    26]
  [   12    19]]

 [[12027    27]
  [   49   124]]

 [[12196     1]
  [    7    23]]

 [[12086    23]
  [   18   100]]

 [[12056    35]
  [   25   111]]

 [[12108    58]
  [   22    39]]

 [[11961    41]
  [   33   192]]

 [[12190     2]
  [    2    33]]

 [[12175    14]
  [   19    19]]

 [[12186    10]
  [   11    20]]

 [[12204     7]
  [    3    13]]

 [[12192    14]
  [    2    19]]

 [[12129    25]
  [   22    51]]]

===scores report===
metrics	scores
Accuracy	0.6259
MCC	0.6186
log_loss	1.8037
f1 score weighted	0.6181
f1 score macro	0.5109
f1 score micro	0.6259
roc_auc ovr	0.9666
roc_auc ovo	0.9631
precision	0.6660
recall	0.6259

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff62c1106a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff62c110880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff62c1108e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff62c1105e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.79      0.78       357
         1.0       0.67      0.15      0.25        13
         2.0       0.77      0.53      0.62        19
         3.0       0.41      0.51      0.45        79
         4.0       0.17      0.31      0.22        55
         5.0       0.11      0.05      0.07        59
         6.0       0.35      0.55      0.42        44
         7.0       0.55      0.69      0.61        48
         8.0       0.00      0.00      0.00        10
         9.0       0.77      0.48      0.59        21
        10.0       0.33      0.20      0.25        15
        11.0       0.86      0.69      0.77        36
        12.0       0.88      0.58      0.70        12
        13.0       0.76      0.64      0.70        25
        14.0       1.00      0.10      0.18        20
        15.0       1.00      0.27      0.43        22
        16.0       0.80      0.70      0.74        23
        17.0       0.87      0.82      0.84       118
        18.0       0.80      0.44      0.57        18
        19.0       1.00      0.08      0.14        13
        20.0       0.74      0.36      0.48        89
        21.0       0.62      0.42      0.50        12
        22.0       0.73      0.79      0.76        24
        23.0       0.50      0.08      0.14        12
        24.0       0.75      0.26      0.39        23
        25.0       0.73      0.59      0.66        37
        26.0       1.00      0.82      0.90        17
        27.0       0.25      0.08      0.12        36
        28.0       0.00      0.00      0.00        12
        29.0       0.70      0.62      0.66        37
        30.0       0.83      0.47      0.60        32
        31.0       0.74      0.79      0.77        39
        32.0       0.62      0.87      0.73       746
        33.0       0.96      0.74      0.84        74
        34.0       0.76      0.78      0.77        58
        35.0       0.81      0.71      0.76        48
        36.0       0.67      0.60      0.63       502
        37.0       0.75      0.66      0.70       240
        38.0       1.00      0.42      0.60        33
        39.0       0.59      0.69      0.64       344
        40.0       0.90      0.71      0.80       191
        41.0       0.86      0.39      0.53        31
        42.0       0.74      0.72      0.73       384
        43.0       0.55      0.79      0.65       117
        44.0       0.77      0.67      0.72       436
        45.0       0.94      0.59      0.72        49
        46.0       0.94      0.77      0.85       402
        47.0       1.00      0.24      0.38        17
        48.0       0.67      0.48      0.56        42
        49.0       0.96      0.88      0.92        77
        50.0       0.89      0.91      0.90       172
        51.0       0.67      0.21      0.32        19
        52.0       0.66      0.61      0.63       499
        53.0       0.76      0.61      0.67        99
        54.0       0.67      0.18      0.29        11
        55.0       0.80      0.77      0.78       103
        56.0       0.58      0.39      0.47        18
        57.0       1.00      0.18      0.31        11
        58.0       1.00      0.83      0.91        35
        59.0       0.53      0.48      0.50       231
        60.0       0.88      0.74      0.80        57
        61.0       0.25      0.07      0.11        29
        62.0       0.62      0.31      0.42        48
        63.0       0.22      0.22      0.22        49
        64.0       1.00      0.53      0.69        34
        65.0       0.84      0.69      0.76       155
        66.0       0.60      0.21      0.32        14
        67.0       0.51      0.58      0.55       315
        68.0       0.11      0.03      0.05        63
        69.0       0.54      0.66      0.59       307
        70.0       0.66      0.39      0.49        69
        71.0       0.37      0.44      0.40        66
        72.0       0.50      0.07      0.12        15
        73.0       0.92      0.48      0.63        25
        74.0       0.00      0.00      0.00        18
        75.0       0.50      0.24      0.32        59
        76.0       0.48      0.67      0.56       206
        77.0       0.96      0.33      0.49        76
        78.0       0.58      0.58      0.58        59
        79.0       0.60      0.39      0.48       140
        80.0       0.68      0.76      0.72        42
        81.0       0.30      0.53      0.39       175
        82.0       0.67      0.42      0.51        43
        83.0       0.30      0.32      0.31        25
        84.0       0.45      0.50      0.47       105
        85.0       0.50      0.29      0.36        14
        86.0       0.60      0.74      0.67       242
        87.0       0.86      0.68      0.76       310
        88.0       0.84      0.78      0.81        59
        89.0       0.80      0.36      0.50        11
        90.0       0.41      0.59      0.48       187
        91.0       0.65      0.33      0.43        46
        92.0       0.00      0.00      0.00        40
        93.0       0.67      0.30      0.42        33
        94.0       0.39      0.75      0.51       289
        95.0       0.38      0.19      0.25        32
        96.0       0.59      0.77      0.67        75
        97.0       0.70      0.25      0.37        28
        98.0       0.90      0.73      0.81        37
        99.0       0.87      0.87      0.87        23
       100.0       0.29      0.08      0.12        25
       101.0       0.55      0.55      0.55        66
       102.0       0.89      0.76      0.82        21
       103.0       0.94      0.74      0.83        65
       104.0       0.41      0.28      0.33        40
       105.0       1.00      0.67      0.80        12
       106.0       0.63      0.80      0.71       113
       107.0       0.58      0.81      0.68       162
       108.0       0.67      0.33      0.44        24
       109.0       0.89      0.79      0.84        53
       110.0       1.00      0.57      0.73        14
       111.0       0.59      0.65      0.62       123
       112.0       0.68      0.41      0.52        41
       113.0       0.69      0.98      0.81       429
       114.0       1.00      0.51      0.67        65
       115.0       0.40      0.68      0.51        31
       116.0       0.92      0.76      0.83       173
       117.0       0.96      0.87      0.91        30
       118.0       0.95      0.68      0.80       117
       119.0       0.72      0.83      0.77       136
       120.0       0.94      0.28      0.43        61
       121.0       0.89      0.79      0.84       225
       122.0       0.85      0.63      0.72        35
       123.0       0.78      0.47      0.59        38
       124.0       0.77      0.77      0.77        30
       125.0       0.91      0.62      0.74        16
       126.0       1.00      0.59      0.74        22
       127.0       0.72      0.86      0.79        73

    accuracy                           0.65     12226
   macro avg       0.68      0.52      0.56     12226
weighted avg       0.68      0.65      0.65     12226


===confusion_matrix===

[[281   0   0 ...   0   0   0]
 [  0   2   0 ...   0   0   0]
 [  0   0  10 ...   0   0   0]
 ...
 [  0   0   0 ...  10   0   2]
 [  0   0   0 ...   0  13   8]
 [  0   0   0 ...   1   0  63]]

===multilabel confusion matrix===

[[[11782    87]
  [   76   281]]

 [[12212     1]
  [   11     2]]

 [[12204     3]
  [    9    10]]

 [[12090    57]
  [   39    40]]

 [[12086    85]
  [   38    17]]

 [[12142    25]
  [   56     3]]

 [[12137    45]
  [   20    24]]

 [[12151    27]
  [   15    33]]

 [[12215     1]
  [   10     0]]

 [[12202     3]
  [   11    10]]

 [[12205     6]
  [   12     3]]

 [[12186     4]
  [   11    25]]

 [[12213     1]
  [    5     7]]

 [[12196     5]
  [    9    16]]

 [[12206     0]
  [   18     2]]

 [[12204     0]
  [   16     6]]

 [[12199     4]
  [    7    16]]

 [[12093    15]
  [   21    97]]

 [[12206     2]
  [   10     8]]

 [[12213     0]
  [   12     1]]

 [[12126    11]
  [   57    32]]

 [[12211     3]
  [    7     5]]

 [[12195     7]
  [    5    19]]

 [[12213     1]
  [   11     1]]

 [[12201     2]
  [   17     6]]

 [[12181     8]
  [   15    22]]

 [[12209     0]
  [    3    14]]

 [[12181     9]
  [   33     3]]

 [[12214     0]
  [   12     0]]

 [[12179    10]
  [   14    23]]

 [[12191     3]
  [   17    15]]

 [[12176    11]
  [    8    31]]

 [[11087   393]
  [   98   648]]

 [[12150     2]
  [   19    55]]

 [[12154    14]
  [   13    45]]

 [[12170     8]
  [   14    34]]

 [[11576   148]
  [  200   302]]

 [[11932    54]
  [   81   159]]

 [[12193     0]
  [   19    14]]

 [[11716   166]
  [  106   238]]

 [[12020    15]
  [   55   136]]

 [[12193     2]
  [   19    12]]

 [[11746    96]
  [  109   275]]

 [[12034    75]
  [   25    92]]

 [[11705    85]
  [  145   291]]

 [[12175     2]
  [   20    29]]

 [[11804    20]
  [   93   309]]

 [[12209     0]
  [   13     4]]

 [[12174    10]
  [   22    20]]

 [[12146     3]
  [    9    68]]

 [[12034    20]
  [   16   156]]

 [[12205     2]
  [   15     4]]

 [[11574   153]
  [  196   303]]

 [[12108    19]
  [   39    60]]

 [[12214     1]
  [    9     2]]

 [[12103    20]
  [   24    79]]

 [[12203     5]
  [   11     7]]

 [[12215     0]
  [    9     2]]

 [[12191     0]
  [    6    29]]

 [[11897    98]
  [  121   110]]

 [[12163     6]
  [   15    42]]

 [[12191     6]
  [   27     2]]

 [[12169     9]
  [   33    15]]

 [[12139    38]
  [   38    11]]

 [[12192     0]
  [   16    18]]

 [[12050    21]
  [   48   107]]

 [[12210     2]
  [   11     3]]

 [[11737   174]
  [  131   184]]

 [[12147    16]
  [   61     2]]

 [[11744   175]
  [  103   204]]

 [[12143    14]
  [   42    27]]

 [[12110    50]
  [   37    29]]

 [[12210     1]
  [   14     1]]

 [[12200     1]
  [   13    12]]

 [[12208     0]
  [   18     0]]

 [[12153    14]
  [   45    14]]

 [[11868   152]
  [   68   138]]

 [[12149     1]
  [   51    25]]

 [[12142    25]
  [   25    34]]

 [[12050    36]
  [   85    55]]

 [[12169    15]
  [   10    32]]

 [[11838   213]
  [   82    93]]

 [[12174     9]
  [   25    18]]

 [[12182    19]
  [   17     8]]

 [[12057    64]
  [   53    52]]

 [[12208     4]
  [   10     4]]

 [[11865   119]
  [   62   180]]

 [[11883    33]
  [  100   210]]

 [[12158     9]
  [   13    46]]

 [[12214     1]
  [    7     4]]

 [[11882   157]
  [   77   110]]

 [[12172     8]
  [   31    15]]

 [[12186     0]
  [   40     0]]

 [[12188     5]
  [   23    10]]

 [[11599   338]
  [   72   217]]

 [[12184    10]
  [   26     6]]

 [[12110    41]
  [   17    58]]

 [[12195     3]
  [   21     7]]

 [[12186     3]
  [   10    27]]

 [[12200     3]
  [    3    20]]

 [[12196     5]
  [   23     2]]

 [[12131    29]
  [   30    36]]

 [[12203     2]
  [    5    16]]

 [[12158     3]
  [   17    48]]

 [[12170    16]
  [   29    11]]

 [[12214     0]
  [    4     8]]

 [[12061    52]
  [   23    90]]

 [[11969    95]
  [   31   131]]

 [[12198     4]
  [   16     8]]

 [[12168     5]
  [   11    42]]

 [[12212     0]
  [    6     8]]

 [[12048    55]
  [   43    80]]

 [[12177     8]
  [   24    17]]

 [[11604   193]
  [    9   420]]

 [[12161     0]
  [   32    33]]

 [[12164    31]
  [   10    21]]

 [[12041    12]
  [   41   132]]

 [[12195     1]
  [    4    26]]

 [[12105     4]
  [   37    80]]

 [[12045    45]
  [   23   113]]

 [[12164     1]
  [   44    17]]

 [[11980    21]
  [   47   178]]

 [[12187     4]
  [   13    22]]

 [[12183     5]
  [   20    18]]

 [[12189     7]
  [    7    23]]

 [[12209     1]
  [    6    10]]

 [[12204     0]
  [    9    13]]

 [[12129    24]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.6512
MCC	0.6436
log_loss	1.6322
f1 score weighted	0.6456
f1 score macro	0.5576
f1 score micro	0.6512
roc_auc ovr	0.9683
roc_auc ovo	0.9640
precision	0.6769
recall	0.6512

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff62c1106a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff62c110880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff62c1108e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff62c1105e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.77      0.78       358
         1.0       0.80      0.33      0.47        12
         2.0       1.00      0.50      0.67        18
         3.0       0.53      0.39      0.45        79
         4.0       0.33      0.24      0.28        55
         5.0       0.50      0.07      0.12        58
         6.0       0.63      0.27      0.38        45
         7.0       0.83      0.51      0.63        47
         8.0       0.00      0.00      0.00        10
         9.0       0.79      0.52      0.63        21
        10.0       0.50      0.07      0.12        15
        11.0       0.70      0.78      0.74        36
        12.0       1.00      0.17      0.29        12
        13.0       0.86      0.48      0.62        25
        14.0       1.00      0.05      0.10        20
        15.0       0.79      1.00      0.88        22
        16.0       0.86      0.52      0.65        23
        17.0       0.96      0.72      0.82       118
        18.0       0.73      0.44      0.55        18
        19.0       0.00      0.00      0.00        13
        20.0       0.51      0.55      0.53        89
        21.0       1.00      0.23      0.38        13
        22.0       0.73      0.88      0.80        25
        23.0       0.80      0.33      0.47        12
        24.0       0.54      0.30      0.39        23
        25.0       0.76      0.59      0.67        37
        26.0       0.84      0.94      0.89        17
        27.0       0.86      0.17      0.28        36
        28.0       1.00      0.42      0.59        12
        29.0       0.54      0.56      0.55        36
        30.0       0.59      0.69      0.64        32
        31.0       0.97      0.79      0.87        39
        32.0       0.84      0.82      0.83       747
        33.0       0.86      0.88      0.87        74
        34.0       0.94      0.79      0.86        58
        35.0       0.89      0.72      0.80        47
        36.0       0.50      0.77      0.61       502
        37.0       0.73      0.70      0.72       240
        38.0       0.61      0.56      0.58        34
        39.0       0.73      0.54      0.62       344
        40.0       0.80      0.74      0.77       191
        41.0       0.93      0.41      0.57        32
        42.0       0.81      0.70      0.75       384
        43.0       0.79      0.76      0.77       117
        44.0       0.78      0.73      0.75       437
        45.0       0.97      0.59      0.73        49
        46.0       0.94      0.87      0.90       401
        47.0       0.75      0.18      0.29        17
        48.0       0.46      0.45      0.46        42
        49.0       0.78      0.94      0.85        77
        50.0       0.86      0.81      0.84       171
        51.0       1.00      0.50      0.67        20
        52.0       0.60      0.68      0.64       499
        53.0       0.87      0.55      0.67       100
        54.0       0.29      0.18      0.22        11
        55.0       0.76      0.87      0.81       104
        56.0       0.50      0.11      0.17        19
        57.0       0.00      0.00      0.00        11
        58.0       0.87      0.94      0.90        35
        59.0       0.55      0.47      0.51       230
        60.0       1.00      0.81      0.90        58
        61.0       0.00      0.00      0.00        29
        62.0       0.59      0.39      0.47        49
        63.0       0.19      0.20      0.19        50
        64.0       0.95      0.62      0.75        34
        65.0       0.78      0.85      0.81       155
        66.0       0.50      0.21      0.30        14
        67.0       0.58      0.65      0.62       314
        68.0       0.07      0.05      0.06        62
        69.0       0.57      0.54      0.56       307
        70.0       0.45      0.31      0.37        68
        71.0       0.72      0.20      0.31        66
        72.0       0.33      0.07      0.11        15
        73.0       0.78      0.56      0.65        25
        74.0       0.00      0.00      0.00        19
        75.0       0.60      0.10      0.17        59
        76.0       0.66      0.76      0.70       206
        77.0       0.58      0.49      0.53        77
        78.0       0.78      0.59      0.67        59
        79.0       0.70      0.45      0.55       139
        80.0       0.91      0.74      0.82        42
        81.0       0.23      0.54      0.32       174
        82.0       0.35      0.63      0.45        43
        83.0       0.35      0.32      0.33        25
        84.0       0.41      0.64      0.50       105
        85.0       0.80      0.53      0.64        15
        86.0       0.72      0.64      0.68       242
        87.0       0.78      0.75      0.76       309
        88.0       0.87      0.78      0.82        59
        89.0       0.00      0.00      0.00        11
        90.0       0.42      0.56      0.48       188
        91.0       0.26      0.36      0.30        47
        92.0       0.19      0.40      0.26        40
        93.0       0.49      0.76      0.60        33
        94.0       0.34      0.78      0.48       288
        95.0       0.50      0.19      0.27        32
        96.0       0.88      0.57      0.69        75
        97.0       0.43      0.22      0.29        27
        98.0       0.78      0.55      0.65        38
        99.0       0.85      0.96      0.90        23
       100.0       0.00      0.00      0.00        25
       101.0       0.89      0.36      0.52        66
       102.0       0.85      0.77      0.81        22
       103.0       0.78      0.62      0.70        64
       104.0       0.50      0.33      0.40        39
       105.0       1.00      0.67      0.80        12
       106.0       0.91      0.76      0.83       113
       107.0       0.73      0.82      0.77       161
       108.0       0.33      0.48      0.39        23
       109.0       0.83      0.83      0.83        53
       110.0       0.90      0.64      0.75        14
       111.0       0.66      0.71      0.68       123
       112.0       0.85      0.56      0.68        41
       113.0       0.89      0.94      0.92       429
       114.0       0.52      0.69      0.59        65
       115.0       0.58      0.58      0.58        31
       116.0       0.91      0.76      0.83       173
       117.0       0.88      0.97      0.92        31
       118.0       0.90      0.70      0.79       117
       119.0       0.69      0.87      0.77       135
       120.0       0.70      0.63      0.66        62
       121.0       0.89      0.83      0.86       224
       122.0       0.93      0.74      0.83        35
       123.0       0.40      0.62      0.49        37
       124.0       0.67      0.60      0.63        30
       125.0       0.48      0.81      0.60        16
       126.0       0.83      0.68      0.75        22
       127.0       0.76      0.74      0.75        73

    accuracy                           0.67     12226
   macro avg       0.66      0.54      0.57     12226
weighted avg       0.70      0.67      0.67     12226


===confusion_matrix===

[[276   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   3  15   4]
 [  0   0   0 ...   6   1  54]]

===multilabel confusion matrix===

[[[11790    78]
  [   82   276]]

 [[12213     1]
  [    8     4]]

 [[12208     0]
  [    9     9]]

 [[12120    27]
  [   48    31]]

 [[12145    26]
  [   42    13]]

 [[12164     4]
  [   54     4]]

 [[12174     7]
  [   33    12]]

 [[12174     5]
  [   23    24]]

 [[12216     0]
  [   10     0]]

 [[12202     3]
  [   10    11]]

 [[12210     1]
  [   14     1]]

 [[12178    12]
  [    8    28]]

 [[12214     0]
  [   10     2]]

 [[12199     2]
  [   13    12]]

 [[12206     0]
  [   19     1]]

 [[12198     6]
  [    0    22]]

 [[12201     2]
  [   11    12]]

 [[12104     4]
  [   33    85]]

 [[12205     3]
  [   10     8]]

 [[12207     6]
  [   13     0]]

 [[12089    48]
  [   40    49]]

 [[12213     0]
  [   10     3]]

 [[12193     8]
  [    3    22]]

 [[12213     1]
  [    8     4]]

 [[12197     6]
  [   16     7]]

 [[12182     7]
  [   15    22]]

 [[12206     3]
  [    1    16]]

 [[12189     1]
  [   30     6]]

 [[12214     0]
  [    7     5]]

 [[12173    17]
  [   16    20]]

 [[12179    15]
  [   10    22]]

 [[12186     1]
  [    8    31]]

 [[11364   115]
  [  135   612]]

 [[12141    11]
  [    9    65]]

 [[12165     3]
  [   12    46]]

 [[12175     4]
  [   13    34]]

 [[11340   384]
  [  114   388]]

 [[11923    63]
  [   71   169]]

 [[12180    12]
  [   15    19]]

 [[11814    68]
  [  159   185]]

 [[12000    35]
  [   49   142]]

 [[12193     1]
  [   19    13]]

 [[11779    63]
  [  114   270]]

 [[12085    24]
  [   28    89]]

 [[11698    91]
  [  117   320]]

 [[12176     1]
  [   20    29]]

 [[11801    24]
  [   52   349]]

 [[12208     1]
  [   14     3]]

 [[12162    22]
  [   23    19]]

 [[12129    20]
  [    5    72]]

 [[12033    22]
  [   32   139]]

 [[12206     0]
  [   10    10]]

 [[11497   230]
  [  159   340]]

 [[12118     8]
  [   45    55]]

 [[12210     5]
  [    9     2]]

 [[12093    29]
  [   14    90]]

 [[12205     2]
  [   17     2]]

 [[12215     0]
  [   11     0]]

 [[12186     5]
  [    2    33]]

 [[11908    88]
  [  121   109]]

 [[12168     0]
  [   11    47]]

 [[12194     3]
  [   29     0]]

 [[12164    13]
  [   30    19]]

 [[12132    44]
  [   40    10]]

 [[12191     1]
  [   13    21]]

 [[12033    38]
  [   24   131]]

 [[12209     3]
  [   11     3]]

 [[11766   146]
  [  109   205]]

 [[12127    37]
  [   59     3]]

 [[11795   124]
  [  141   166]]

 [[12132    26]
  [   47    21]]

 [[12155     5]
  [   53    13]]

 [[12209     2]
  [   14     1]]

 [[12197     4]
  [   11    14]]

 [[12207     0]
  [   19     0]]

 [[12163     4]
  [   53     6]]

 [[11939    81]
  [   50   156]]

 [[12121    28]
  [   39    38]]

 [[12157    10]
  [   24    35]]

 [[12060    27]
  [   76    63]]

 [[12181     3]
  [   11    31]]

 [[11739   313]
  [   80    94]]

 [[12133    50]
  [   16    27]]

 [[12186    15]
  [   17     8]]

 [[12024    97]
  [   38    67]]

 [[12209     2]
  [    7     8]]

 [[11925    59]
  [   88   154]]

 [[11853    64]
  [   78   231]]

 [[12160     7]
  [   13    46]]

 [[12215     0]
  [   11     0]]

 [[11894   144]
  [   82   106]]

 [[12131    48]
  [   30    17]]

 [[12117    69]
  [   24    16]]

 [[12167    26]
  [    8    25]]

 [[11503   435]
  [   62   226]]

 [[12188     6]
  [   26     6]]

 [[12145     6]
  [   32    43]]

 [[12191     8]
  [   21     6]]

 [[12182     6]
  [   17    21]]

 [[12199     4]
  [    1    22]]

 [[12201     0]
  [   25     0]]

 [[12157     3]
  [   42    24]]

 [[12201     3]
  [    5    17]]

 [[12151    11]
  [   24    40]]

 [[12174    13]
  [   26    13]]

 [[12214     0]
  [    4     8]]

 [[12104     9]
  [   27    86]]

 [[12015    50]
  [   29   132]]

 [[12181    22]
  [   12    11]]

 [[12164     9]
  [    9    44]]

 [[12211     1]
  [    5     9]]

 [[12058    45]
  [   36    87]]

 [[12181     4]
  [   18    23]]

 [[11746    51]
  [   24   405]]

 [[12119    42]
  [   20    45]]

 [[12182    13]
  [   13    18]]

 [[12040    13]
  [   42   131]]

 [[12191     4]
  [    1    30]]

 [[12100     9]
  [   35    82]]

 [[12037    54]
  [   17   118]]

 [[12147    17]
  [   23    39]]

 [[11979    23]
  [   39   185]]

 [[12189     2]
  [    9    26]]

 [[12155    34]
  [   14    23]]

 [[12187     9]
  [   12    18]]

 [[12196    14]
  [    3    13]]

 [[12201     3]
  [    7    15]]

 [[12136    17]
  [   19    54]]]

===scores report===
metrics	scores
Accuracy	0.6681
MCC	0.6613
log_loss	1.5030
f1 score weighted	0.6670
f1 score macro	0.5659
f1 score micro	0.6681
roc_auc ovr	0.9733
roc_auc ovo	0.9708
precision	0.6992
recall	0.6681

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff62c1106a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff62c110880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff62c1108e0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff62c1105e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.40      0.86      0.55       358
         1.0       0.67      0.17      0.27        12
         2.0       0.62      0.26      0.37        19
         3.0       0.80      0.42      0.55        79
         4.0       0.42      0.09      0.15        55
         5.0       1.00      0.03      0.07        58
         6.0       0.46      0.13      0.21        45
         7.0       0.84      0.45      0.58        47
         8.0       0.00      0.00      0.00        10
         9.0       0.50      0.24      0.32        21
        10.0       0.33      0.07      0.11        15
        11.0       0.49      0.81      0.61        36
        12.0       0.75      0.25      0.38        12
        13.0       0.62      0.60      0.61        25
        14.0       0.50      0.05      0.10        19
        15.0       0.56      0.86      0.68        22
        16.0       0.70      0.30      0.42        23
        17.0       0.58      0.85      0.69       118
        18.0       1.00      0.11      0.20        18
        19.0       0.00      0.00      0.00        12
        20.0       0.25      0.44      0.32        90
        21.0       1.00      0.23      0.38        13
        22.0       0.90      0.72      0.80        25
        23.0       1.00      0.15      0.27        13
        24.0       0.00      0.00      0.00        22
        25.0       0.68      0.61      0.64        38
        26.0       1.00      0.76      0.87        17
        27.0       1.00      0.03      0.06        35
        28.0       1.00      0.08      0.15        12
        29.0       0.77      0.47      0.59        36
        30.0       0.51      0.69      0.59        32
        31.0       0.89      0.82      0.85        38
        32.0       0.92      0.74      0.82       747
        33.0       0.51      0.95      0.67        75
        34.0       1.00      0.69      0.82        59
        35.0       1.00      0.36      0.53        47
        36.0       0.78      0.61      0.68       501
        37.0       0.69      0.73      0.71       241
        38.0       0.56      0.27      0.37        33
        39.0       0.83      0.50      0.62       344
        40.0       0.96      0.67      0.79       192
        41.0       0.76      0.50      0.60        32
        42.0       0.32      0.88      0.47       384
        43.0       0.95      0.61      0.74       117
        44.0       0.55      0.71      0.62       436
        45.0       0.85      0.69      0.76        49
        46.0       0.93      0.86      0.89       401
        47.0       0.78      0.41      0.54        17
        48.0       0.73      0.52      0.61        42
        49.0       0.62      0.95      0.75        77
        50.0       0.68      0.88      0.77       172
        51.0       0.56      0.50      0.53        20
        52.0       0.56      0.70      0.62       499
        53.0       0.97      0.58      0.72       100
        54.0       0.20      0.09      0.13        11
        55.0       0.87      0.79      0.83       104
        56.0       0.20      0.06      0.09        18
        57.0       0.00      0.00      0.00        10
        58.0       0.97      0.83      0.89        35
        59.0       0.85      0.45      0.59       230
        60.0       0.87      0.78      0.82        58
        61.0       0.00      0.00      0.00        29
        62.0       0.67      0.41      0.51        49
        63.0       0.89      0.16      0.27        50
        64.0       1.00      0.62      0.76        34
        65.0       0.96      0.73      0.83       155
        66.0       0.00      0.00      0.00        14
        67.0       0.88      0.43      0.58       314
        68.0       0.00      0.00      0.00        62
        69.0       0.83      0.30      0.44       307
        70.0       0.94      0.24      0.38        68
        71.0       0.24      0.52      0.33        66
        72.0       0.00      0.00      0.00        14
        73.0       0.88      0.62      0.73        24
        74.0       0.00      0.00      0.00        19
        75.0       0.00      0.00      0.00        60
        76.0       0.68      0.64      0.66       206
        77.0       0.34      0.36      0.35        77
        78.0       0.53      0.68      0.59        59
        79.0       0.19      0.66      0.29       139
        80.0       0.91      0.74      0.82        42
        81.0       0.69      0.34      0.46       174
        82.0       0.24      0.53      0.33        43
        83.0       0.00      0.00      0.00        26
        84.0       0.45      0.42      0.43       106
        85.0       1.00      0.40      0.57        15
        86.0       0.48      0.69      0.57       241
        87.0       0.87      0.66      0.75       309
        88.0       0.56      0.75      0.64        59
        89.0       1.00      0.30      0.46        10
        90.0       0.63      0.28      0.38       188
        91.0       0.72      0.28      0.41        46
        92.0       1.00      0.05      0.09        41
        93.0       0.90      0.28      0.43        32
        94.0       0.41      0.66      0.51       288
        95.0       0.25      0.03      0.06        31
        96.0       0.94      0.60      0.73        75
        97.0       0.23      0.59      0.33        27
        98.0       0.26      0.55      0.35        38
        99.0       0.88      0.96      0.92        24
       100.0       0.00      0.00      0.00        25
       101.0       0.84      0.48      0.61        65
       102.0       1.00      0.68      0.81        22
       103.0       0.98      0.72      0.83        64
       104.0       0.83      0.12      0.22        40
       105.0       0.91      0.83      0.87        12
       106.0       0.60      0.74      0.66       113
       107.0       0.91      0.71      0.80       161
       108.0       0.68      0.54      0.60        24
       109.0       0.93      0.48      0.63        52
       110.0       0.44      0.73      0.55        15
       111.0       0.51      0.66      0.57       124
       112.0       0.81      0.51      0.63        41
       113.0       0.91      0.94      0.92       430
       114.0       1.00      0.31      0.47        65
       115.0       0.60      0.48      0.54        31
       116.0       0.72      0.71      0.71       173
       117.0       1.00      0.81      0.89        31
       118.0       0.86      0.81      0.84       117
       119.0       0.79      0.69      0.74       136
       120.0       0.93      0.60      0.73        62
       121.0       0.77      0.89      0.83       224
       122.0       0.92      0.63      0.75        35
       123.0       0.22      0.73      0.34        37
       124.0       0.69      0.71      0.70        31
       125.0       0.71      0.67      0.69        15
       126.0       0.81      0.81      0.81        21
       127.0       0.78      0.82      0.80        73

    accuracy                           0.62     12226
   macro avg       0.65      0.49      0.51     12226
weighted avg       0.70      0.62      0.62     12226


===confusion_matrix===

[[308   0   0 ...   0   0   0]
 [  1   2   0 ...   0   0   0]
 [  0   0   5 ...   0   0   0]
 ...
 [  0   0   0 ...  10   1   0]
 [  0   0   0 ...   0  17   2]
 [  0   0   0 ...   0   0  60]]

===multilabel confusion matrix===

[[[11409   459]
  [   50   308]]

 [[12213     1]
  [   10     2]]

 [[12204     3]
  [   14     5]]

 [[12139     8]
  [   46    33]]

 [[12164     7]
  [   50     5]]

 [[12168     0]
  [   56     2]]

 [[12174     7]
  [   39     6]]

 [[12175     4]
  [   26    21]]

 [[12215     1]
  [   10     0]]

 [[12200     5]
  [   16     5]]

 [[12209     2]
  [   14     1]]

 [[12160    30]
  [    7    29]]

 [[12213     1]
  [    9     3]]

 [[12192     9]
  [   10    15]]

 [[12206     1]
  [   18     1]]

 [[12189    15]
  [    3    19]]

 [[12200     3]
  [   16     7]]

 [[12035    73]
  [   18   100]]

 [[12208     0]
  [   16     2]]

 [[12214     0]
  [   12     0]]

 [[12017   119]
  [   50    40]]

 [[12213     0]
  [   10     3]]

 [[12199     2]
  [    7    18]]

 [[12213     0]
  [   11     2]]

 [[12204     0]
  [   22     0]]

 [[12177    11]
  [   15    23]]

 [[12209     0]
  [    4    13]]

 [[12191     0]
  [   34     1]]

 [[12214     0]
  [   11     1]]

 [[12185     5]
  [   19    17]]

 [[12173    21]
  [   10    22]]

 [[12184     4]
  [    7    31]]

 [[11431    48]
  [  193   554]]

 [[12084    67]
  [    4    71]]

 [[12167     0]
  [   18    41]]

 [[12179     0]
  [   30    17]]

 [[11638    87]
  [  195   306]]

 [[11905    80]
  [   64   177]]

 [[12186     7]
  [   24     9]]

 [[11848    34]
  [  173   171]]

 [[12029     5]
  [   64   128]]

 [[12189     5]
  [   16    16]]

 [[11122   720]
  [   48   336]]

 [[12105     4]
  [   46    71]]

 [[11539   251]
  [  125   311]]

 [[12171     6]
  [   15    34]]

 [[11801    24]
  [   58   343]]

 [[12207     2]
  [   10     7]]

 [[12176     8]
  [   20    22]]

 [[12105    44]
  [    4    73]]

 [[11981    73]
  [   20   152]]

 [[12198     8]
  [   10    10]]

 [[11455   272]
  [  149   350]]

 [[12124     2]
  [   42    58]]

 [[12211     4]
  [   10     1]]

 [[12110    12]
  [   22    82]]

 [[12204     4]
  [   17     1]]

 [[12215     1]
  [   10     0]]

 [[12190     1]
  [    6    29]]

 [[11978    18]
  [  126   104]]

 [[12161     7]
  [   13    45]]

 [[12197     0]
  [   29     0]]

 [[12167    10]
  [   29    20]]

 [[12175     1]
  [   42     8]]

 [[12192     0]
  [   13    21]]

 [[12066     5]
  [   42   113]]

 [[12211     1]
  [   14     0]]

 [[11894    18]
  [  178   136]]

 [[12164     0]
  [   62     0]]

 [[11900    19]
  [  214    93]]

 [[12157     1]
  [   52    16]]

 [[12055   105]
  [   32    34]]

 [[12212     0]
  [   14     0]]

 [[12200     2]
  [    9    15]]

 [[12207     0]
  [   19     0]]

 [[12164     2]
  [   60     0]]

 [[11958    62]
  [   75   131]]

 [[12095    54]
  [   49    28]]

 [[12131    36]
  [   19    40]]

 [[11694   393]
  [   47    92]]

 [[12181     3]
  [   11    31]]

 [[12026    26]
  [  115    59]]

 [[12111    72]
  [   20    23]]

 [[12198     2]
  [   26     0]]

 [[12066    54]
  [   62    44]]

 [[12211     0]
  [    9     6]]

 [[11807   178]
  [   74   167]]

 [[11887    30]
  [  106   203]]

 [[12132    35]
  [   15    44]]

 [[12216     0]
  [    7     3]]

 [[12007    31]
  [  136    52]]

 [[12175     5]
  [   33    13]]

 [[12185     0]
  [   39     2]]

 [[12193     1]
  [   23     9]]

 [[11665   273]
  [   98   190]]

 [[12192     3]
  [   30     1]]

 [[12148     3]
  [   30    45]]

 [[12145    54]
  [   11    16]]

 [[12127    61]
  [   17    21]]

 [[12199     3]
  [    1    23]]

 [[12201     0]
  [   25     0]]

 [[12155     6]
  [   34    31]]

 [[12204     0]
  [    7    15]]

 [[12161     1]
  [   18    46]]

 [[12185     1]
  [   35     5]]

 [[12213     1]
  [    2    10]]

 [[12056    57]
  [   29    84]]

 [[12054    11]
  [   47   114]]

 [[12196     6]
  [   11    13]]

 [[12172     2]
  [   27    25]]

 [[12197    14]
  [    4    11]]

 [[12022    80]
  [   42    82]]

 [[12180     5]
  [   20    21]]

 [[11754    42]
  [   25   405]]

 [[12161     0]
  [   45    20]]

 [[12185    10]
  [   16    15]]

 [[12005    48]
  [   51   122]]

 [[12195     0]
  [    6    25]]

 [[12094    15]
  [   22    95]]

 [[12065    25]
  [   42    94]]

 [[12161     3]
  [   25    37]]

 [[11944    58]
  [   25   199]]

 [[12189     2]
  [   13    22]]

 [[12093    96]
  [   10    27]]

 [[12185    10]
  [    9    22]]

 [[12207     4]
  [    5    10]]

 [[12201     4]
  [    4    17]]

 [[12136    17]
  [   13    60]]]

===scores report===
metrics	scores
Accuracy	0.6200
MCC	0.6135
log_loss	1.7794
f1 score weighted	0.6179
f1 score macro	0.5065
f1 score micro	0.6200
roc_auc ovr	0.9700
roc_auc ovo	0.9642
precision	0.7006
recall	0.6200

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6609961560480903	0.6543816897089325	1.58566994092385	0.6565708436445418	0.5427111039746674	0.6609961560480903	0.9726676125755073	0.9699468059837408	0.6934502968050174	0.6609961560480903
1	0.6259098715956489	0.6186495101104059	1.8037026352451335	0.6180873264731876	0.5108818588375932	0.6259098715956489	0.9665714161191122	0.963055401537671	0.6659633380854026	0.6259098715956489
2	0.6511532798953051	0.6435722857127735	1.6322413429491833	0.6456348941893894	0.5575704143918288	0.6511532798953051	0.9682558915941496	0.9640303859221601	0.6769320582611376	0.6511532798953051
3	0.6680844102731883	0.6612665067207097	1.502966428528915	0.6669753785999661	0.5659016542168445	0.6680844102731883	0.9732695999807529	0.9708305679005775	0.6991668325177819	0.6680844102731883
4	0.6199901848519549	0.6135385318690753	1.7794238483624532	0.6178578112414372	0.5064973288046957	0.6199901848519549	0.9700394604624674	0.9641862147127769	0.7006172118275876	0.6199901848519549
mean	0.6452267805328376	0.6382817048243794	1.660800839201907	0.6410252508297045	0.536712472045126	0.6452267805328376	0.9701607961463978	0.9664098752113853	0.6872259474993854	0.6452267805328376
std	0.019059362888771133	0.0190428388367727	0.11477311489146812	0.0199960097520601	0.024096560582519435	0.019059362888771133	0.0025485612635917335	0.0032836422478389636	0.01355519040330877	0.019059362888771133

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 26820.2144 secs

