/home/amsequeira/enzymeClassification/models/hot_encoded/bi_attetion_500_post_post_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7c0873e730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7c0873e6d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7c0873e310>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.7740309097264942)
('Validation Accuracy mean: ', 0.6128969267010689)
('Training Loss mean: ', 0.7477742182581049)
('Validation Loss mean: ', 1.2816946114364423)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500, 21)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 128)          44032     
_________________________________________________________________
bidirectional_1 (Bidirection (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_2 (Bidirection (None, 500, 64)           41216     
_________________________________________________________________
attention (attention)        (None, 64)                564       
_________________________________________________________________
dense (Dense)                (None, 32)                2080      
_________________________________________________________________
batch_normalization (BatchNo (None, 32)                128       
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                528       
_________________________________________________________________
batch_normalization_1 (Batch (None, 16)                64        
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 7)                 119       
=================================================================
Total params: 187,547
Trainable params: 187,451
Non-trainable params: 96
_________________________________________________________________Finished run_model in 7721.5308 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7c0873e670>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.90      0.93      0.91      1792
           1       0.94      0.94      0.94      4921
           2       0.90      0.92      0.91      3576
           3       0.95      0.88      0.91       944
           4       0.93      0.93      0.93       695
           5       0.94      0.97      0.96      1073
           6       0.96      0.76      0.85       471

    accuracy                           0.92     13472
   macro avg       0.93      0.90      0.92     13472
weighted avg       0.92      0.92      0.92     13472


===confusion_matrix===

[[1663   47   53    7    5   12    5]
 [  49 4611  186   15   28   26    6]
 [  64  171 3297   10   15   15    4]
 [  16   34   57  828    1    8    0]
 [  11   15   19    2  646    2    0]
 [   5   11    8    2    1 1046    0]
 [  47   13   41    4    1    8  357]]

===multilabel confusion matrix===

[[[11488   192]
  [  129  1663]]

 [[ 8260   291]
  [  310  4611]]

 [[ 9532   364]
  [  279  3297]]

 [[12488    40]
  [  116   828]]

 [[12726    51]
  [   49   646]]

 [[12328    71]
  [   27  1046]]

 [[12986    15]
  [  114   357]]]

===scores report===
metrics	scores
Accuracy	0.9240
MCC	0.9003
log_loss	0.2818
f1 score weighted	0.9237
f1 score macro	0.9152
f1 score micro	0.9240
roc_auc ovr	0.9891
roc_auc ovo	0.9905
precision	0.9247
recall	0.9240

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7c0873e730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7c0873e6d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7c0873e310>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7c0873e670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.78      0.77      1793
         1.0       0.83      0.87      0.85      4921
         2.0       0.81      0.80      0.81      3576
         3.0       0.75      0.63      0.69       943
         4.0       0.83      0.75      0.79       695
         5.0       0.89      0.86      0.88      1073
         6.0       0.91      0.90      0.91       471

    accuracy                           0.82     13472
   macro avg       0.83      0.80      0.81     13472
weighted avg       0.82      0.82      0.82     13472


===confusion_matrix===

[[1403  168  144   41   16   10   11]
 [ 159 4261  329   81   24   55   12]
 [ 127  440 2877   48   41   30   13]
 [  61  135  116  598   18   12    3]
 [  34   59   55   17  524    4    2]
 [  33   71   32    8    5  924    0]
 [  13   17   15    1    0    1  424]]

===multilabel confusion matrix===

[[[11252   427]
  [  390  1403]]

 [[ 7661   890]
  [  660  4261]]

 [[ 9205   691]
  [  699  2877]]

 [[12333   196]
  [  345   598]]

 [[12673   104]
  [  171   524]]

 [[12287   112]
  [  149   924]]

 [[12960    41]
  [   47   424]]]

===scores report===
metrics	scores
Accuracy	0.8173
MCC	0.7593
log_loss	0.6688
f1 score weighted	0.8165
f1 score macro	0.8127
f1 score micro	0.8173
roc_auc ovr	0.9601
roc_auc ovo	0.9649
precision	0.8169
recall	0.8173

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7c0873e730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7c0873e6d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7c0873e310>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7c0873e670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.76      0.78      1792
         1.0       0.82      0.88      0.85      4921
         2.0       0.80      0.78      0.79      3576
         3.0       0.74      0.69      0.71       943
         4.0       0.85      0.75      0.79       696
         5.0       0.86      0.88      0.87      1072
         6.0       0.91      0.91      0.91       471

    accuracy                           0.82     13471
   macro avg       0.83      0.81      0.82     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1355  201  133   48   16   22   17]
 [  97 4312  335   76   31   61    9]
 [ 137  471 2805   71   33   44   15]
 [  33  128  106  651   10   14    1]
 [  22   60   58   22  519   15    0]
 [  19   56   40    8    2  946    1]
 [  10   17   10    3    0    3  428]]

===multilabel confusion matrix===

[[[11361   318]
  [  437  1355]]

 [[ 7617   933]
  [  609  4312]]

 [[ 9213   682]
  [  771  2805]]

 [[12300   228]
  [  292   651]]

 [[12683    92]
  [  177   519]]

 [[12240   159]
  [  126   946]]

 [[12957    43]
  [   43   428]]]

===scores report===
metrics	scores
Accuracy	0.8178
MCC	0.7599
log_loss	0.6201
f1 score weighted	0.8168
f1 score macro	0.8159
f1 score micro	0.8178
roc_auc ovr	0.9594
roc_auc ovo	0.9662
precision	0.8172
recall	0.8178

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7c0873e730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7c0873e6d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7c0873e310>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7c0873e670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.78      0.78      1792
         1.0       0.81      0.87      0.84      4921
         2.0       0.82      0.77      0.79      3576
         3.0       0.73      0.70      0.71       943
         4.0       0.78      0.76      0.77       695
         5.0       0.88      0.89      0.89      1072
         6.0       0.96      0.84      0.90       472

    accuracy                           0.81     13471
   macro avg       0.82      0.80      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1395  211   98   44   28   13    3]
 [ 144 4268  327   76   38   59    9]
 [ 128  507 2760   87   52   37    5]
 [  44  119   94  659   19    8    0]
 [  29   60   45   20  527   13    1]
 [  14   59   23    7   10  959    0]
 [  19   21   23    8    2    2  397]]

===multilabel confusion matrix===

[[[11301   378]
  [  397  1395]]

 [[ 7573   977]
  [  653  4268]]

 [[ 9285   610]
  [  816  2760]]

 [[12286   242]
  [  284   659]]

 [[12627   149]
  [  168   527]]

 [[12267   132]
  [  113   959]]

 [[12981    18]
  [   75   397]]]

===scores report===
metrics	scores
Accuracy	0.8140
MCC	0.7554
log_loss	0.6750
f1 score weighted	0.8134
f1 score macro	0.8118
f1 score micro	0.8140
roc_auc ovr	0.9589
roc_auc ovo	0.9656
precision	0.8142
recall	0.8140

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7c0873e730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7c0873e6d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7c0873e310>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7c0873e670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.79      0.79      1792
         1.0       0.83      0.86      0.84      4920
         2.0       0.81      0.79      0.80      3576
         3.0       0.74      0.72      0.73       944
         4.0       0.82      0.74      0.78       695
         5.0       0.92      0.87      0.89      1072
         6.0       0.91      0.89      0.90       472

    accuracy                           0.82     13471
   macro avg       0.83      0.81      0.82     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1412  181  129   33   15   15    7]
 [ 131 4250  362   85   34   42   16]
 [ 133  452 2835   76   46   19   15]
 [  49  132   72  678    9    3    1]
 [  32   54   55   28  517    7    2]
 [  18   70   30    9    9  936    0]
 [  13   12   20    4    1    0  422]]

===multilabel confusion matrix===

[[[11303   376]
  [  380  1412]]

 [[ 7650   901]
  [  670  4250]]

 [[ 9227   668]
  [  741  2835]]

 [[12292   235]
  [  266   678]]

 [[12662   114]
  [  178   517]]

 [[12313    86]
  [  136   936]]

 [[12958    41]
  [   50   422]]]

===scores report===
metrics	scores
Accuracy	0.8203
MCC	0.7635
log_loss	0.6473
f1 score weighted	0.8200
f1 score macro	0.8201
f1 score micro	0.8203
roc_auc ovr	0.9603
roc_auc ovo	0.9671
precision	0.8204
recall	0.8203

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7c0873e730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7c0873e6d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7c0873e310>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7c0873e670>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.82      0.77      1792
         1.0       0.80      0.89      0.84      4920
         2.0       0.83      0.75      0.79      3576
         3.0       0.80      0.65      0.72       944
         4.0       0.86      0.68      0.76       695
         5.0       0.91      0.88      0.89      1073
         6.0       0.92      0.89      0.90       471

    accuracy                           0.81     13471
   macro avg       0.84      0.79      0.81     13471
weighted avg       0.82      0.81      0.81     13471


===confusion_matrix===

[[1471  159   98   35   10    9   10]
 [ 176 4369  250   56   17   35   17]
 [ 194  583 2677   49   35   31    7]
 [  79  145   89  615   11    4    1]
 [  62   81   58   12  472   10    0]
 [  27   75   25    4    1  941    0]
 [  13   25   13    0    2    1  417]]

===multilabel confusion matrix===

[[[11128   551]
  [  321  1471]]

 [[ 7483  1068]
  [  551  4369]]

 [[ 9362   533]
  [  899  2677]]

 [[12371   156]
  [  329   615]]

 [[12700    76]
  [  223   472]]

 [[12308    90]
  [  132   941]]

 [[12965    35]
  [   54   417]]]

===scores report===
metrics	scores
Accuracy	0.8137
MCC	0.7551
log_loss	0.7059
f1 score weighted	0.8125
f1 score macro	0.8112
f1 score micro	0.8137
roc_auc ovr	0.9573
roc_auc ovo	0.9633
precision	0.8169
recall	0.8137

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8173248218527316	0.759281059100763	0.6688420280530579	0.8164602689460321	0.8127065060521865	0.8173248218527316	0.9600739529380038	0.9649384019093858	0.8169105130815867	0.8173248218527316
1	0.8177566624600995	0.7599397571340504	0.6200764228998221	0.8167718389973678	0.8158971478637378	0.8177566624600995	0.9594099335376982	0.9662250368604393	0.8172338486005615	0.8177566624600995
2	0.8139707519857472	0.7553547363754349	0.6749824171679933	0.8134262478096044	0.811769763268997	0.8139707519857472	0.9588921201533376	0.9655853440026031	0.814221037090779	0.8139707519857472
3	0.8202806027763343	0.763489432889131	0.6472737569666247	0.8199846294886214	0.8200643441854741	0.8202806027763343	0.9603457588590384	0.9671367781313909	0.8203621064995724	0.8202806027763343
4	0.8137480513696088	0.755078945853144	0.7059358476485185	0.8124719690481662	0.8112489490195907	0.8137480513696088	0.9573045402195497	0.9632912939587922	0.81693493734085	0.8137480513696088
mean	0.8166161780889043	0.7586287862705047	0.6634220945472034	0.8158229908579584	0.8143373420779974	0.8166161780889043	0.9592052611415255	0.9654353709725223	0.81713248852267	0.8166161780889043
std	0.0024680080640062693	0.003133393039676196	0.028670723737789155	0.002668310201418206	0.003286998813355362	0.0024680080640062693	0.0010777799935418864	0.0012949822342457834	0.0019496438212280903	0.0024680080640062693

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 31286.1681 secs

