/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_hot_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f209058e400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f209058e2b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f209058e790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f209058e5b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.92      0.88       911
         1.0       0.95      0.66      0.78        53
         2.0       0.88      0.81      0.84       179
         3.0       0.83      0.20      0.32        25
         4.0       0.80      0.60      0.68       112
         5.0       0.86      0.74      0.79       491
         6.0       0.93      0.83      0.88        64
         7.0       0.90      0.51      0.66        37
         8.0       0.93      0.87      0.90       206
         9.0       0.96      0.76      0.85        71
        10.0       0.94      0.91      0.92       404
        11.0       1.00      0.50      0.67        16
        12.0       0.86      0.78      0.82       378
        13.0       0.88      0.80      0.84       191
        14.0       0.62      0.17      0.27        76
        15.0       0.80      0.71      0.75        66
        16.0       0.82      0.84      0.83       141
        17.0       0.87      0.79      0.83       182
        18.0       1.00      0.75      0.86        12
        19.0       1.00      0.87      0.93        38
        20.0       0.92      0.94      0.93      2162
        21.0       0.95      0.96      0.96       168
        22.0       0.82      0.85      0.84      1470
        23.0       0.91      0.88      0.89      1259
        24.0       0.92      0.92      0.92       956
        25.0       0.89      0.91      0.90       283
        26.0       0.90      0.92      0.91      3919
        27.0       0.96      0.93      0.94       531
        28.0       1.00      0.83      0.91        12
        29.0       0.76      0.84      0.80      2345
        30.0       0.68      0.77      0.72       615
        31.0       0.95      0.66      0.78        32
        32.0       0.82      0.77      0.80      1449
        33.0       0.81      0.89      0.85       893
        34.0       0.92      0.88      0.90      1377
        35.0       0.89      0.36      0.52        22
        36.0       0.87      0.89      0.88       844
        37.0       0.89      0.90      0.90      1142
        38.0       0.94      0.88      0.91       314
        39.0       0.76      0.68      0.72        56
        40.0       0.93      0.77      0.84       154
        41.0       0.98      0.90      0.94        52
        42.0       0.88      0.76      0.81       247
        43.0       0.92      0.83      0.87       198
        44.0       0.94      0.94      0.94       529
        45.0       0.97      0.87      0.92       540
        46.0       1.00      0.15      0.26        20
        47.0       0.86      0.69      0.76        80
        48.0       0.98      0.98      0.98      1466
        49.0       0.96      0.91      0.93       148
        50.0       0.93      0.96      0.95      1453
        51.0       1.00      0.25      0.40        12
        52.0       0.99      0.93      0.96       151
        53.0       0.96      0.97      0.97       903
        54.0       0.96      0.82      0.89       108
        55.0       0.97      0.92      0.95        93
        56.0       1.00      0.91      0.95        33
        57.0       0.82      0.86      0.84        49
        58.0       0.85      0.95      0.90       154

    accuracy                           0.88     29892
   macro avg       0.90      0.78      0.82     29892
weighted avg       0.88      0.88      0.88     29892


===confusion_matrix===

[[842   0   0 ...   0   0   0]
 [  0  35   0 ...   0   0   0]
 [  0   0 145 ...   0   0   0]
 ...
 [  0   0   0 ...  30   1   1]
 [  0   0   0 ...   0  42   6]
 [  0   0   0 ...   0   5 147]]

===multilabel confusion matrix===

[[[28813   168]
  [   69   842]]

 [[29837     2]
  [   18    35]]

 [[29693    20]
  [   34   145]]

 [[29866     1]
  [   20     5]]

 [[29763    17]
  [   45    67]]

 [[29340    61]
  [  128   363]]

 [[29824     4]
  [   11    53]]

 [[29853     2]
  [   18    19]]

 [[29673    13]
  [   26   180]]

 [[29819     2]
  [   17    54]]

 [[29463    25]
  [   38   366]]

 [[29876     0]
  [    8     8]]

 [[29466    48]
  [   85   293]]

 [[29680    21]
  [   38   153]]

 [[29808     8]
  [   63    13]]

 [[29814    12]
  [   19    47]]

 [[29725    26]
  [   22   119]]

 [[29688    22]
  [   38   144]]

 [[29880     0]
  [    3     9]]

 [[29854     0]
  [    5    33]]

 [[27559   171]
  [  129  2033]]

 [[29716     8]
  [    6   162]]

 [[28142   280]
  [  214  1256]]

 [[28518   115]
  [  148  1111]]

 [[28856    80]
  [   76   880]]

 [[29578    31]
  [   25   258]]

 [[25569   404]
  [  308  3611]]

 [[29338    23]
  [   39   492]]

 [[29880     0]
  [    2    10]]

 [[26928   619]
  [  377  1968]]

 [[29057   220]
  [  144   471]]

 [[29859     1]
  [   11    21]]

 [[28196   247]
  [  328  1121]]

 [[28818   181]
  [  101   792]]

 [[28413   102]
  [  167  1210]]

 [[29869     1]
  [   14     8]]

 [[28940   108]
  [   97   747]]

 [[28629   121]
  [  112  1030]]

 [[29560    18]
  [   37   277]]

 [[29824    12]
  [   18    38]]

 [[29729     9]
  [   35   119]]

 [[29839     1]
  [    5    47]]

 [[29619    26]
  [   60   187]]

 [[29679    15]
  [   34   164]]

 [[29333    30]
  [   33   496]]

 [[29336    16]
  [   71   469]]

 [[29872     0]
  [   17     3]]

 [[29803     9]
  [   25    55]]

 [[28399    27]
  [   23  1443]]

 [[29738     6]
  [   14   134]]

 [[28339   100]
  [   54  1399]]

 [[29880     0]
  [    9     3]]

 [[29739     2]
  [   11   140]]

 [[28950    39]
  [   24   879]]

 [[29780     4]
  [   19    89]]

 [[29796     3]
  [    7    86]]

 [[29859     0]
  [    3    30]]

 [[29834     9]
  [    7    42]]

 [[29712    26]
  [    7   147]]]

===scores report===
metrics	scores
Accuracy	0.8824
MCC	0.8760
log_loss	0.4935
f1 score weighted	0.8813
f1 score macro	0.8187
f1 score micro	0.8824
roc_auc ovr	0.9936
roc_auc ovo	0.9918
precision	0.8841
recall	0.8824

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f209058e400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f209058e2b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f209058e790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f209058e5b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.87      0.87       912
         1.0       0.95      0.75      0.84        53
         2.0       0.89      0.75      0.81       179
         3.0       1.00      0.24      0.39        25
         4.0       0.58      0.58      0.58       112
         5.0       0.47      0.84      0.60       492
         6.0       0.96      0.80      0.87        65
         7.0       1.00      0.32      0.48        38
         8.0       0.99      0.83      0.90       206
         9.0       0.85      0.70      0.77        71
        10.0       0.93      0.85      0.89       405
        11.0       0.91      0.59      0.71        17
        12.0       0.81      0.74      0.77       377
        13.0       0.80      0.80      0.80       191
        14.0       0.53      0.21      0.30        76
        15.0       0.83      0.65      0.73        66
        16.0       0.97      0.80      0.88       140
        17.0       0.81      0.82      0.81       182
        18.0       1.00      1.00      1.00        11
        19.0       0.97      0.84      0.90        37
        20.0       0.96      0.91      0.93      2163
        21.0       1.00      0.91      0.95       169
        22.0       0.58      0.92      0.71      1469
        23.0       0.90      0.85      0.87      1259
        24.0       0.94      0.86      0.90       956
        25.0       0.93      0.86      0.89       282
        26.0       0.91      0.88      0.90      3919
        27.0       0.93      0.93      0.93       531
        28.0       1.00      0.75      0.86        12
        29.0       0.79      0.80      0.79      2346
        30.0       0.80      0.59      0.68       615
        31.0       1.00      0.81      0.90        32
        32.0       0.72      0.80      0.76      1450
        33.0       0.69      0.83      0.75       893
        34.0       0.95      0.85      0.90      1376
        35.0       0.56      0.45      0.50        22
        36.0       0.91      0.83      0.86       843
        37.0       0.98      0.81      0.88      1142
        38.0       0.96      0.85      0.90       314
        39.0       0.74      0.55      0.63        56
        40.0       0.83      0.70      0.76       154
        41.0       1.00      0.90      0.95        52
        42.0       0.95      0.79      0.86       247
        43.0       0.93      0.84      0.88       198
        44.0       0.96      0.85      0.90       529
        45.0       0.96      0.86      0.91       539
        46.0       1.00      0.32      0.48        19
        47.0       0.79      0.65      0.71        80
        48.0       0.95      0.98      0.96      1466
        49.0       0.97      0.86      0.91       148
        50.0       0.97      0.92      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.93      0.93      0.93       151
        53.0       0.95      0.95      0.95       903
        54.0       0.75      0.86      0.80       108
        55.0       0.82      0.97      0.89        93
        56.0       0.96      0.79      0.87        33
        57.0       0.86      0.88      0.87        49
        58.0       0.94      0.70      0.80       154

    accuracy                           0.85     29892
   macro avg       0.86      0.76      0.79     29892
weighted avg       0.87      0.85      0.86     29892


===confusion_matrix===

[[797   0   0 ...   0   0   0]
 [  0  40   0 ...   0   0   0]
 [  0   0 134 ...   0   0   0]
 ...
 [  0   0   0 ...  26   1   0]
 [  0   0   0 ...   0  43   3]
 [  0   0   0 ...   0   5 108]]

===multilabel confusion matrix===

[[[28858   122]
  [  115   797]]

 [[29837     2]
  [   13    40]]

 [[29697    16]
  [   45   134]]

 [[29867     0]
  [   19     6]]

 [[29733    47]
  [   47    65]]

 [[28932   468]
  [   79   413]]

 [[29825     2]
  [   13    52]]

 [[29854     0]
  [   26    12]]

 [[29684     2]
  [   36   170]]

 [[29812     9]
  [   21    50]]

 [[29461    26]
  [   61   344]]

 [[29874     1]
  [    7    10]]

 [[29451    64]
  [   99   278]]

 [[29662    39]
  [   39   152]]

 [[29802    14]
  [   60    16]]

 [[29817     9]
  [   23    43]]

 [[29748     4]
  [   28   112]]

 [[29675    35]
  [   33   149]]

 [[29881     0]
  [    0    11]]

 [[29854     1]
  [    6    31]]

 [[27645    84]
  [  196  1967]]

 [[29723     0]
  [   15   154]]

 [[27431   992]
  [  121  1348]]

 [[28515   118]
  [  191  1068]]

 [[28885    51]
  [  134   822]]

 [[29593    17]
  [   40   242]]

 [[25617   356]
  [  453  3466]]

 [[29322    39]
  [   36   495]]

 [[29880     0]
  [    3     9]]

 [[27034   512]
  [  474  1872]]

 [[29185    92]
  [  250   365]]

 [[29860     0]
  [    6    26]]

 [[27996   446]
  [  284  1166]]

 [[28669   330]
  [  153   740]]

 [[28453    63]
  [  204  1172]]

 [[29862     8]
  [   12    10]]

 [[28976    73]
  [  145   698]]

 [[28729    21]
  [  220   922]]

 [[29567    11]
  [   46   268]]

 [[29825    11]
  [   25    31]]

 [[29716    22]
  [   46   108]]

 [[29840     0]
  [    5    47]]

 [[29634    11]
  [   52   195]]

 [[29681    13]
  [   31   167]]

 [[29343    20]
  [   80   449]]

 [[29336    17]
  [   74   465]]

 [[29873     0]
  [   13     6]]

 [[29798    14]
  [   28    52]]

 [[28343    83]
  [   32  1434]]

 [[29740     4]
  [   21   127]]

 [[28401    38]
  [  121  1332]]

 [[29880     0]
  [   12     0]]

 [[29730    11]
  [   11   140]]

 [[28946    43]
  [   46   857]]

 [[29753    31]
  [   15    93]]

 [[29779    20]
  [    3    90]]

 [[29858     1]
  [    7    26]]

 [[29836     7]
  [    6    43]]

 [[29731     7]
  [   46   108]]]

===scores report===
metrics	scores
Accuracy	0.8519
MCC	0.8445
log_loss	0.6013
f1 score weighted	0.8553
f1 score macro	0.7932
f1 score micro	0.8519
roc_auc ovr	0.9910
roc_auc ovo	0.9886
precision	0.8699
recall	0.8519

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f209058e400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f209058e2b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f209058e790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f209058e5b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.89      0.87       912
         1.0       0.92      0.87      0.89        52
         2.0       1.00      0.77      0.87       179
         3.0       1.00      0.08      0.15        25
         4.0       0.79      0.45      0.57       112
         5.0       0.77      0.70      0.73       492
         6.0       0.86      0.85      0.85        65
         7.0       0.86      0.32      0.46        38
         8.0       0.98      0.79      0.88       205
         9.0       0.91      0.73      0.81        71
        10.0       0.97      0.86      0.91       405
        11.0       1.00      0.41      0.58        17
        12.0       0.86      0.69      0.77       377
        13.0       0.99      0.76      0.86       190
        14.0       0.38      0.04      0.07        76
        15.0       0.52      0.75      0.61        67
        16.0       0.71      0.85      0.77       140
        17.0       0.92      0.74      0.82       183
        18.0       1.00      0.92      0.96        12
        19.0       0.89      0.89      0.89        37
        20.0       0.71      0.96      0.81      2162
        21.0       0.91      0.97      0.94       169
        22.0       0.97      0.71      0.82      1470
        23.0       0.82      0.90      0.86      1259
        24.0       0.86      0.91      0.88       956
        25.0       0.88      0.89      0.89       282
        26.0       0.86      0.91      0.89      3918
        27.0       0.99      0.87      0.93       531
        28.0       0.91      0.77      0.83        13
        29.0       0.72      0.80      0.76      2346
        30.0       0.63      0.68      0.65       615
        31.0       0.89      0.75      0.81        32
        32.0       0.98      0.65      0.78      1450
        33.0       0.98      0.67      0.80       893
        34.0       0.93      0.86      0.90      1376
        35.0       0.94      0.68      0.79        22
        36.0       0.75      0.88      0.81       843
        37.0       0.87      0.89      0.88      1142
        38.0       0.97      0.89      0.93       314
        39.0       0.93      0.25      0.40        55
        40.0       0.84      0.76      0.80       154
        41.0       0.98      0.85      0.91        52
        42.0       0.65      0.85      0.74       247
        43.0       0.81      0.87      0.84       197
        44.0       0.62      0.94      0.74       530
        45.0       0.94      0.84      0.88       540
        46.0       1.00      0.05      0.10        19
        47.0       0.85      0.49      0.62        79
        48.0       0.95      0.98      0.97      1465
        49.0       0.99      0.83      0.91       149
        50.0       0.95      0.93      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.99      0.88      0.93       152
        53.0       0.97      0.95      0.96       903
        54.0       0.92      0.80      0.86       108
        55.0       0.92      0.92      0.92        93
        56.0       1.00      0.97      0.98        32
        57.0       0.86      0.98      0.92        50
        58.0       0.91      0.94      0.92       154

    accuracy                           0.85     29892
   macro avg       0.86      0.75      0.77     29892
weighted avg       0.86      0.85      0.84     29892


===confusion_matrix===

[[809   0   0 ...   0   0   0]
 [  0  45   0 ...   0   0   0]
 [  0   0 137 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   0  49   0]
 [  0   0   0 ...   0   6 144]]

===multilabel confusion matrix===

[[[28846   134]
  [  103   809]]

 [[29836     4]
  [    7    45]]

 [[29713     0]
  [   42   137]]

 [[29867     0]
  [   23     2]]

 [[29767    13]
  [   62    50]]

 [[29299   101]
  [  149   343]]

 [[29818     9]
  [   10    55]]

 [[29852     2]
  [   26    12]]

 [[29684     3]
  [   43   162]]

 [[29816     5]
  [   19    52]]

 [[29476    11]
  [   55   350]]

 [[29875     0]
  [   10     7]]

 [[29474    41]
  [  115   262]]

 [[29700     2]
  [   46   144]]

 [[29811     5]
  [   73     3]]

 [[29779    46]
  [   17    50]]

 [[29703    49]
  [   21   119]]

 [[29697    12]
  [   48   135]]

 [[29880     0]
  [    1    11]]

 [[29851     4]
  [    4    33]]

 [[26867   863]
  [   96  2066]]

 [[29706    17]
  [    5   164]]

 [[28386    36]
  [  425  1045]]

 [[28391   242]
  [  123  1136]]

 [[28799   137]
  [   89   867]]

 [[29576    34]
  [   31   251]]

 [[25407   567]
  [  352  3566]]

 [[29357     4]
  [   70   461]]

 [[29878     1]
  [    3    10]]

 [[26811   735]
  [  468  1878]]

 [[29036   241]
  [  199   416]]

 [[29857     3]
  [    8    24]]

 [[28419    23]
  [  506   944]]

 [[28989    10]
  [  292   601]]

 [[28431    85]
  [  189  1187]]

 [[29869     1]
  [    7    15]]

 [[28807   242]
  [  104   739]]

 [[28593   157]
  [  127  1015]]

 [[29568    10]
  [   35   279]]

 [[29836     1]
  [   41    14]]

 [[29716    22]
  [   37   117]]

 [[29839     1]
  [    8    44]]

 [[29530   115]
  [   36   211]]

 [[29655    40]
  [   26   171]]

 [[29054   308]
  [   34   496]]

 [[29321    31]
  [   87   453]]

 [[29873     0]
  [   18     1]]

 [[29806     7]
  [   40    39]]

 [[28354    73]
  [   25  1440]]

 [[29742     1]
  [   25   124]]

 [[28363    76]
  [   98  1355]]

 [[29880     0]
  [   12     0]]

 [[29739     1]
  [   18   134]]

 [[28960    29]
  [   41   862]]

 [[29777     7]
  [   22    86]]

 [[29792     7]
  [    7    86]]

 [[29860     0]
  [    1    31]]

 [[29834     8]
  [    1    49]]

 [[29724    14]
  [   10   144]]]

===scores report===
metrics	scores
Accuracy	0.8464
MCC	0.8386
log_loss	0.6339
f1 score weighted	0.8448
f1 score macro	0.7733
f1 score micro	0.8464
roc_auc ovr	0.9914
roc_auc ovo	0.9893
precision	0.8607
recall	0.8464

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f209058e400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f209058e2b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f209058e790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f209058e5b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 1, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.88      0.86       912
         1.0       0.96      0.83      0.89        52
         2.0       0.82      0.72      0.77       179
         3.0       0.67      0.08      0.15        24
         4.0       0.68      0.45      0.54       112
         5.0       0.62      0.76      0.68       492
         6.0       0.96      0.77      0.85        64
         7.0       0.57      0.34      0.43        38
         8.0       0.88      0.86      0.87       205
         9.0       0.93      0.73      0.82        70
        10.0       0.88      0.91      0.90       405
        11.0       0.83      0.29      0.43        17
        12.0       0.77      0.81      0.79       378
        13.0       0.87      0.79      0.82       191
        14.0       0.48      0.16      0.24        76
        15.0       0.86      0.64      0.74        67
        16.0       0.92      0.82      0.87       140
        17.0       0.87      0.72      0.78       183
        18.0       1.00      0.83      0.91        12
        19.0       0.94      0.92      0.93        37
        20.0       0.97      0.90      0.93      2162
        21.0       0.99      0.92      0.95       168
        22.0       0.86      0.83      0.85      1470
        23.0       0.91      0.86      0.89      1259
        24.0       0.92      0.91      0.92       955
        25.0       0.90      0.94      0.92       282
        26.0       0.85      0.90      0.88      3918
        27.0       0.93      0.87      0.90       532
        28.0       1.00      0.92      0.96        13
        29.0       0.73      0.81      0.77      2346
        30.0       0.65      0.79      0.71       616
        31.0       0.92      0.75      0.83        32
        32.0       0.87      0.73      0.80      1449
        33.0       0.93      0.78      0.85       893
        34.0       0.95      0.87      0.91      1377
        35.0       1.00      0.41      0.58        22
        36.0       0.56      0.93      0.70       844
        37.0       0.91      0.87      0.89      1142
        38.0       0.88      0.89      0.88       314
        39.0       1.00      0.48      0.65        56
        40.0       0.95      0.71      0.81       153
        41.0       1.00      0.86      0.93        51
        42.0       0.88      0.74      0.81       246
        43.0       0.99      0.73      0.84       197
        44.0       0.81      0.90      0.85       530
        45.0       0.99      0.82      0.89       540
        46.0       1.00      0.25      0.40        20
        47.0       0.92      0.57      0.71        80
        48.0       0.94      0.98      0.96      1465
        49.0       0.94      0.87      0.91       148
        50.0       0.96      0.93      0.94      1453
        51.0       1.00      0.31      0.47        13
        52.0       0.81      0.89      0.85       151
        53.0       0.96      0.95      0.95       904
        54.0       0.94      0.82      0.88       108
        55.0       0.88      0.94      0.91        93
        56.0       1.00      0.91      0.95        33
        57.0       0.96      0.88      0.92        50
        58.0       0.90      0.91      0.90       153

    accuracy                           0.86     29892
   macro avg       0.88      0.76      0.79     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[804   0   1 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  0   0 129 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   0]
 [  0   0   0 ...   0  44   5]
 [  0   0   0 ...   0   0 139]]

===multilabel confusion matrix===

[[[28837   143]
  [  108   804]]

 [[29838     2]
  [    9    43]]

 [[29684    29]
  [   50   129]]

 [[29867     1]
  [   22     2]]

 [[29756    24]
  [   62    50]]

 [[29171   229]
  [  118   374]]

 [[29826     2]
  [   15    49]]

 [[29844    10]
  [   25    13]]

 [[29663    24]
  [   29   176]]

 [[29818     4]
  [   19    51]]

 [[29438    49]
  [   37   368]]

 [[29874     1]
  [   12     5]]

 [[29422    92]
  [   71   307]]

 [[29678    23]
  [   41   150]]

 [[29803    13]
  [   64    12]]

 [[29818     7]
  [   24    43]]

 [[29742    10]
  [   25   115]]

 [[29689    20]
  [   52   131]]

 [[29880     0]
  [    2    10]]

 [[29853     2]
  [    3    34]]

 [[27666    64]
  [  210  1952]]

 [[29722     2]
  [   14   154]]

 [[28223   199]
  [  248  1222]]

 [[28523   110]
  [  171  1088]]

 [[28860    77]
  [   84   871]]

 [[29580    30]
  [   18   264]]

 [[25362   612]
  [  376  3542]]

 [[29327    33]
  [   71   461]]

 [[29879     0]
  [    1    12]]

 [[26839   707]
  [  437  1909]]

 [[29008   268]
  [  128   488]]

 [[29858     2]
  [    8    24]]

 [[28286   157]
  [  386  1063]]

 [[28943    56]
  [  198   695]]

 [[28447    68]
  [  173  1204]]

 [[29870     0]
  [   13     9]]

 [[28442   606]
  [   59   785]]

 [[28651    99]
  [  143   999]]

 [[29539    39]
  [   34   280]]

 [[29836     0]
  [   29    27]]

 [[29733     6]
  [   44   109]]

 [[29841     0]
  [    7    44]]

 [[29622    24]
  [   63   183]]

 [[29693     2]
  [   53   144]]

 [[29251   111]
  [   53   477]]

 [[29346     6]
  [   99   441]]

 [[29872     0]
  [   15     5]]

 [[29808     4]
  [   34    46]]

 [[28341    86]
  [   26  1439]]

 [[29736     8]
  [   19   129]]

 [[28383    56]
  [  103  1350]]

 [[29879     0]
  [    9     4]]

 [[29710    31]
  [   16   135]]

 [[28948    40]
  [   46   858]]

 [[29778     6]
  [   19    89]]

 [[29787    12]
  [    6    87]]

 [[29859     0]
  [    3    30]]

 [[29840     2]
  [    6    44]]

 [[29723    16]
  [   14   139]]]

===scores report===
metrics	scores
Accuracy	0.8587
MCC	0.8513
log_loss	0.5753
f1 score weighted	0.8595
f1 score macro	0.7949
f1 score micro	0.8587
roc_auc ovr	0.9919
roc_auc ovo	0.9896
precision	0.8692
recall	0.8587

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f209058e400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f209058e2b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f209058e790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f209058e5b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.89      0.86       911
         1.0       0.90      0.72      0.80        53
         2.0       0.81      0.78      0.80       180
         3.0       0.40      0.08      0.13        25
         4.0       0.81      0.45      0.58       111
         5.0       0.87      0.65      0.74       491
         6.0       0.95      0.86      0.90        64
         7.0       0.90      0.24      0.38        37
         8.0       0.84      0.90      0.87       205
         9.0       0.87      0.66      0.75        71
        10.0       0.90      0.89      0.89       404
        11.0       0.67      0.24      0.35        17
        12.0       0.95      0.73      0.82       378
        13.0       0.96      0.72      0.82       191
        14.0       0.52      0.17      0.26        76
        15.0       0.51      0.74      0.60        66
        16.0       0.94      0.76      0.84       140
        17.0       0.90      0.65      0.75       182
        18.0       1.00      0.83      0.91        12
        19.0       0.96      0.73      0.83        37
        20.0       0.95      0.91      0.93      2162
        21.0       0.93      0.96      0.94       168
        22.0       0.71      0.87      0.79      1470
        23.0       0.89      0.85      0.87      1259
        24.0       0.97      0.86      0.91       955
        25.0       0.84      0.93      0.88       283
        26.0       0.92      0.87      0.89      3919
        27.0       0.99      0.89      0.94       532
        28.0       1.00      0.92      0.96        13
        29.0       0.65      0.86      0.74      2345
        30.0       0.69      0.73      0.71       616
        31.0       1.00      0.81      0.90        32
        32.0       0.77      0.77      0.77      1449
        33.0       0.77      0.85      0.81       893
        34.0       0.92      0.85      0.89      1377
        35.0       0.79      0.68      0.73        22
        36.0       0.83      0.88      0.86       844
        37.0       0.86      0.87      0.87      1142
        38.0       0.91      0.90      0.90       314
        39.0       0.97      0.54      0.69        56
        40.0       0.94      0.74      0.83       153
        41.0       0.90      0.90      0.90        52
        42.0       0.80      0.79      0.79       247
        43.0       0.90      0.80      0.85       197
        44.0       0.81      0.90      0.85       529
        45.0       0.98      0.86      0.91       540
        46.0       1.00      0.20      0.33        20
        47.0       1.00      0.53      0.69        80
        48.0       0.97      0.98      0.98      1466
        49.0       0.94      0.88      0.91       148
        50.0       0.97      0.93      0.95      1453
        51.0       1.00      0.08      0.15        12
        52.0       0.96      0.88      0.92       151
        53.0       0.98      0.95      0.96       904
        54.0       0.91      0.69      0.78       108
        55.0       0.95      0.97      0.96        93
        56.0       0.94      0.91      0.92        33
        57.0       0.82      0.92      0.87        50
        58.0       0.90      0.92      0.91       154

    accuracy                           0.86     29892
   macro avg       0.87      0.75      0.79     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[810   0   1 ...   0   0   0]
 [  0  38   1 ...   0   0   0]
 [  0   0 140 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   0]
 [  0   0   0 ...   0  46   2]
 [  0   0   0 ...   0   6 141]]

===multilabel confusion matrix===

[[[28809   172]
  [  101   810]]

 [[29835     4]
  [   15    38]]

 [[29680    32]
  [   40   140]]

 [[29864     3]
  [   23     2]]

 [[29769    12]
  [   61    50]]

 [[29352    49]
  [  174   317]]

 [[29825     3]
  [    9    55]]

 [[29854     1]
  [   28     9]]

 [[29652    35]
  [   21   184]]

 [[29814     7]
  [   24    47]]

 [[29448    40]
  [   45   359]]

 [[29873     2]
  [   13     4]]

 [[29500    14]
  [  103   275]]

 [[29695     6]
  [   53   138]]

 [[29804    12]
  [   63    13]]

 [[29778    48]
  [   17    49]]

 [[29745     7]
  [   33   107]]

 [[29697    13]
  [   64   118]]

 [[29880     0]
  [    2    10]]

 [[29854     1]
  [   10    27]]

 [[27633    97]
  [  202  1960]]

 [[29711    13]
  [    7   161]]

 [[27909   513]
  [  188  1282]]

 [[28495   138]
  [  183  1076]]

 [[28915    22]
  [  135   820]]

 [[29558    51]
  [   21   262]]

 [[25670   303]
  [  510  3409]]

 [[29355     5]
  [   57   475]]

 [[29879     0]
  [    1    12]]

 [[26446  1101]
  [  327  2018]]

 [[29072   204]
  [  164   452]]

 [[29860     0]
  [    6    26]]

 [[28105   338]
  [  328  1121]]

 [[28767   232]
  [  134   759]]

 [[28417    98]
  [  201  1176]]

 [[29866     4]
  [    7    15]]

 [[28901   147]
  [  103   741]]

 [[28588   162]
  [  145   997]]

 [[29549    29]
  [   31   283]]

 [[29835     1]
  [   26    30]]

 [[29732     7]
  [   40   113]]

 [[29835     5]
  [    5    47]]

 [[29595    50]
  [   53   194]]

 [[29678    17]
  [   39   158]]

 [[29251   112]
  [   52   477]]

 [[29343     9]
  [   78   462]]

 [[29872     0]
  [   16     4]]

 [[29812     0]
  [   38    42]]

 [[28384    42]
  [   28  1438]]

 [[29735     9]
  [   18   130]]

 [[28401    38]
  [   98  1355]]

 [[29880     0]
  [   11     1]]

 [[29735     6]
  [   18   133]]

 [[28967    21]
  [   49   855]]

 [[29777     7]
  [   34    74]]

 [[29794     5]
  [    3    90]]

 [[29857     2]
  [    3    30]]

 [[29832    10]
  [    4    46]]

 [[29722    16]
  [   13   141]]]

===scores report===
metrics	scores
Accuracy	0.8570
MCC	0.8496
log_loss	0.5788
f1 score weighted	0.8577
f1 score macro	0.7852
f1 score micro	0.8570
roc_auc ovr	0.9915
roc_auc ovo	0.9889
precision	0.8678
recall	0.8570

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8823765556001606	0.8760036795140682	0.49345282563066684	0.8812635972157808	0.818691441268719	0.8823765556001606	0.9936481937611601	0.991787727840127	0.8840939842011621	0.8823765556001606
1	0.8519001739595878	0.8444761593948255	0.6012560797691219	0.8553372467737617	0.7931976593604091	0.8519001739595878	0.9910461982876845	0.9886009221477086	0.8698769708918238	0.8519001739595878
2	0.846447209955841	0.8385560877338157	0.6338823598570013	0.8448226646119353	0.7733313918527407	0.8464472099558409	0.9913740091513937	0.9892728904167947	0.8607332308591138	0.846447209955841
3	0.8586912886391007	0.8512726470177641	0.5752891676399401	0.8594904857218052	0.7948717591724397	0.8586912886391007	0.9918983415613832	0.9896403820046814	0.8691740014518006	0.8586912886391007
4	0.856985146527499	0.8496101335085766	0.5788254200772361	0.8576560560103981	0.7851701964380849	0.856985146527499	0.9914727819959994	0.988871949505559	0.8677716477912012	0.856985146527499
mean	0.8592800749364379	0.8519837414338101	0.5765411705947934	0.8597140100667362	0.7930524896184787	0.8592800749364379	0.9918879049515242	0.9896347743829741	0.8703299670390203	0.8592800749364379
std	0.012314269339219001	0.01280439586384109	0.04649580001994663	0.01191283400960488	0.014911330594918601	0.012314269339219024	0.0009212612751768369	0.0011328682427389888	0.0076109391413732175	0.012314269339219001

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 68577.8867 secs

