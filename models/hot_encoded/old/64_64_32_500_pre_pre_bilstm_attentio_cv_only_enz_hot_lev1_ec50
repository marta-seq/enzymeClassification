/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_hot_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f39f85fe580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f39f85fe730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f39f85fe790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f39f85fe550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.76      0.79      1793
         1.0       0.83      0.85      0.84      4921
         2.0       0.82      0.78      0.80      3576
         3.0       0.65      0.70      0.67       943
         4.0       0.73      0.78      0.76       695
         5.0       0.84      0.87      0.86      1073
         6.0       0.90      0.90      0.90       471

    accuracy                           0.81     13472
   macro avg       0.80      0.81      0.80     13472
weighted avg       0.81      0.81      0.81     13472


===confusion_matrix===

[[1363  169  123   66   33   23   16]
 [ 110 4189  326  151   61   71   13]
 [ 114  442 2776  105   62   60   17]
 [  42  114   87  662   28    8    2]
 [  21   55   38   27  545    8    1]
 [  21   59   38    8   13  934    0]
 [   7   16   15    2    0    5  426]]

===multilabel confusion matrix===

[[[11364   315]
  [  430  1363]]

 [[ 7696   855]
  [  732  4189]]

 [[ 9269   627]
  [  800  2776]]

 [[12170   359]
  [  281   662]]

 [[12580   197]
  [  150   545]]

 [[12224   175]
  [  139   934]]

 [[12952    49]
  [   45   426]]]

===scores report===
metrics	scores
Accuracy	0.8087
MCC	0.7497
log_loss	0.6913
f1 score weighted	0.8088
f1 score macro	0.8016
f1 score micro	0.8087
roc_auc ovr	0.9585
roc_auc ovo	0.9655
precision	0.8097
recall	0.8087

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f39f85fe580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f39f85fe730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f39f85fe790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f39f85fe550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.61      0.80      0.70      1792
         1.0       0.81      0.81      0.81      4921
         2.0       0.81      0.67      0.73      3576
         3.0       0.58      0.68      0.63       943
         4.0       0.88      0.65      0.75       696
         5.0       0.81      0.89      0.85      1072
         6.0       0.88      0.90      0.89       471

    accuracy                           0.76     13471
   macro avg       0.77      0.77      0.77     13471
weighted avg       0.78      0.76      0.77     13471


===confusion_matrix===

[[1442  152   90   73    4   15   16]
 [ 349 3991  320  149   18   75   19]
 [ 350  512 2394  182   27   92   19]
 [  93  100   74  642    5   24    5]
 [  79   76   39   38  454   10    0]
 [  26   51   20   19    6  950    0]
 [  11   15   13    4    1    2  425]]

===multilabel confusion matrix===

[[[10771   908]
  [  350  1442]]

 [[ 7644   906]
  [  930  3991]]

 [[ 9339   556]
  [ 1182  2394]]

 [[12063   465]
  [  301   642]]

 [[12714    61]
  [  242   454]]

 [[12181   218]
  [  122   950]]

 [[12941    59]
  [   46   425]]]

===scores report===
metrics	scores
Accuracy	0.7645
MCC	0.6960
log_loss	0.6955
f1 score weighted	0.7656
f1 score macro	0.7653
f1 score micro	0.7645
roc_auc ovr	0.9457
roc_auc ovo	0.9564
precision	0.7763
recall	0.7645

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f39f85fe580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f39f85fe730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f39f85fe790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f39f85fe550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.78      0.77      1792
         1.0       0.84      0.84      0.84      4921
         2.0       0.81      0.80      0.80      3576
         3.0       0.72      0.70      0.71       943
         4.0       0.79      0.78      0.78       695
         5.0       0.87      0.87      0.87      1072
         6.0       0.92      0.92      0.92       472

    accuracy                           0.82     13471
   macro avg       0.82      0.81      0.81     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1397  142  149   54   23   23    4]
 [ 181 4155  365   89   46   65   20]
 [ 130  410 2861   76   46   41   12]
 [  42  123   93  661   18    6    0]
 [  32   50   38   22  540   10    3]
 [  25   61   30   10   11  935    0]
 [  10    8   16    4    0    0  434]]

===multilabel confusion matrix===

[[[11259   420]
  [  395  1397]]

 [[ 7756   794]
  [  766  4155]]

 [[ 9204   691]
  [  715  2861]]

 [[12273   255]
  [  282   661]]

 [[12632   144]
  [  155   540]]

 [[12254   145]
  [  137   935]]

 [[12960    39]
  [   38   434]]]

===scores report===
metrics	scores
Accuracy	0.8153
MCC	0.7579
log_loss	0.6739
f1 score weighted	0.8152
f1 score macro	0.8144
f1 score micro	0.8153
roc_auc ovr	0.9592
roc_auc ovo	0.9663
precision	0.8151
recall	0.8153

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f39f85fe580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f39f85fe730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f39f85fe790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f39f85fe550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.81      0.77      1792
         1.0       0.81      0.88      0.84      4920
         2.0       0.84      0.72      0.77      3576
         3.0       0.69      0.74      0.71       944
         4.0       0.84      0.73      0.78       695
         5.0       0.91      0.87      0.89      1072
         6.0       0.95      0.90      0.92       472

    accuracy                           0.81     13471
   macro avg       0.82      0.81      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1452  163   89   46   18   14   10]
 [ 195 4321  244   94   24   36    6]
 [ 210  593 2567  124   40   36    6]
 [  60  114   60  695   11    3    1]
 [  32   78   44   29  506    5    1]
 [  23   66   28   15    5  935    0]
 [  14   10   17    2    1    3  425]]

===multilabel confusion matrix===

[[[11145   534]
  [  340  1452]]

 [[ 7527  1024]
  [  599  4321]]

 [[ 9413   482]
  [ 1009  2567]]

 [[12217   310]
  [  249   695]]

 [[12677    99]
  [  189   506]]

 [[12302    97]
  [  137   935]]

 [[12975    24]
  [   47   425]]]

===scores report===
metrics	scores
Accuracy	0.8092
MCC	0.7506
log_loss	0.6620
f1 score weighted	0.8087
f1 score macro	0.8127
f1 score micro	0.8092
roc_auc ovr	0.9589
roc_auc ovo	0.9659
precision	0.8129
recall	0.8092

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f39f85fe580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f39f85fe730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f39f85fe790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f39f85fe550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.77      0.78      1792
         1.0       0.84      0.83      0.84      4920
         2.0       0.75      0.83      0.79      3576
         3.0       0.77      0.65      0.70       944
         4.0       0.87      0.69      0.77       695
         5.0       0.85      0.87      0.86      1073
         6.0       0.91      0.90      0.91       471

    accuracy                           0.81     13471
   macro avg       0.82      0.79      0.80     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1383  145  172   37   17   24   14]
 [ 173 4074  501   73   24   65   10]
 [ 114  373 2960   48   16   51   14]
 [  51  110  147  611   10   13    2]
 [  30   60   96   16  479   13    1]
 [  12   53   62    7    5  932    2]
 [  12    9   23    0    1    1  425]]

===multilabel confusion matrix===

[[[11287   392]
  [  409  1383]]

 [[ 7801   750]
  [  846  4074]]

 [[ 8894  1001]
  [  616  2960]]

 [[12346   181]
  [  333   611]]

 [[12703    73]
  [  216   479]]

 [[12231   167]
  [  141   932]]

 [[12957    43]
  [   46   425]]]

===scores report===
metrics	scores
Accuracy	0.8065
MCC	0.7458
log_loss	0.7137
f1 score weighted	0.8060
f1 score macro	0.8047
f1 score micro	0.8065
roc_auc ovr	0.9554
roc_auc ovo	0.9625
precision	0.8086
recall	0.8065

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8087143705463183	0.749703714010211	0.6913031811162142	0.8087840354585585	0.8015750273599757	0.8087143705463183	0.9584588139884983	0.9654622168499515	0.8097078480096132	0.8087143705463183
1	0.764456981664316	0.696030009317209	0.6955314302529753	0.7655802851806237	0.7653372646442158	0.764456981664316	0.9456540802822888	0.9563721473167909	0.7763439181003283	0.764456981664316
2	0.8153069556825774	0.7579038117293606	0.6739146457383739	0.8151689750527467	0.8143799342717574	0.8153069556825774	0.9591867017640849	0.9663165658463698	0.8150787929187938	0.8153069556825774
3	0.8092198055081286	0.7505626266954755	0.6619762565628939	0.8086558986305413	0.8126907026838737	0.8092198055081287	0.9588582516269128	0.9658945391872634	0.8128850120301182	0.8092198055081286
4	0.8064731645757554	0.7458097744083562	0.7137132226530517	0.806039407423062	0.8046687448846238	0.8064731645757554	0.9554180241458929	0.9624708882299026	0.8085993432911571	0.8064731645757554
mean	0.800834255595419	0.7400019872321224	0.6872877472647018	0.8008457203491064	0.7997303347688892	0.8008342555954192	0.9555151743615357	0.9633032714860557	0.8045229828700021	0.800834255595419
std	0.018422681997677704	0.02233110459567812	0.017899157375186617	0.017887407078247732	0.017850803678903057	0.018422681997677715	0.005110223242237731	0.0037199193652659042	0.014275208506732133	0.018422681997677704

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 29487.2319 secs

