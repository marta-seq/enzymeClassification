/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_hot_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f012824f430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f012824f2e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f012824f7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f012824f5e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.51      0.89      0.65       358
         1.0       1.00      0.33      0.50        12
         2.0       0.79      0.58      0.67        19
         3.0       0.70      0.50      0.58        80
         4.0       0.75      0.33      0.46        54
         5.0       0.50      0.07      0.12        58
         6.0       0.56      0.22      0.32        45
         7.0       0.59      0.54      0.57        48
         8.0       0.00      0.00      0.00        11
         9.0       0.47      0.43      0.45        21
        10.0       0.50      0.20      0.29        15
        11.0       0.88      0.64      0.74        36
        12.0       0.86      0.50      0.63        12
        13.0       0.80      0.64      0.71        25
        14.0       1.00      0.16      0.27        19
        15.0       0.76      0.73      0.74        22
        16.0       0.86      0.52      0.65        23
        17.0       0.80      0.85      0.82       119
        18.0       0.60      0.67      0.63        18
        19.0       0.00      0.00      0.00        12
        20.0       0.74      0.53      0.62        90
        21.0       1.00      0.17      0.29        12
        22.0       0.92      0.92      0.92        25
        23.0       0.00      0.00      0.00        12
        24.0       0.00      0.00      0.00        22
        25.0       0.57      0.32      0.41        38
        26.0       1.00      0.76      0.87        17
        27.0       0.41      0.26      0.32        35
        28.0       0.00      0.00      0.00        11
        29.0       0.71      0.42      0.53        36
        30.0       0.62      0.56      0.59        32
        31.0       0.96      0.61      0.74        38
        32.0       0.77      0.80      0.78       747
        33.0       0.90      0.88      0.89        74
        34.0       0.85      0.95      0.90        59
        35.0       0.68      0.85      0.76        48
        36.0       0.51      0.76      0.61       502
        37.0       0.59      0.78      0.67       241
        38.0       0.69      0.55      0.61        33
        39.0       0.67      0.71      0.69       344
        40.0       0.73      0.73      0.73       191
        41.0       0.95      0.56      0.71        32
        42.0       0.85      0.76      0.80       384
        43.0       0.74      0.74      0.74       118
        44.0       0.74      0.72      0.73       436
        45.0       0.93      0.81      0.87        48
        46.0       0.87      0.80      0.83       402
        47.0       0.60      0.35      0.44        17
        48.0       0.61      0.71      0.66        42
        49.0       0.77      0.96      0.85        78
        50.0       0.89      0.89      0.89       172
        51.0       0.90      0.45      0.60        20
        52.0       0.67      0.71      0.69       499
        53.0       0.67      0.79      0.72       100
        54.0       0.40      0.36      0.38        11
        55.0       0.92      0.63      0.75       103
        56.0       0.75      0.33      0.46        18
        57.0       0.22      0.20      0.21        10
        58.0       0.92      0.97      0.94        34
        59.0       0.79      0.53      0.64       231
        60.0       0.81      0.67      0.74        58
        61.0       0.00      0.00      0.00        30
        62.0       0.85      0.48      0.61        48
        63.0       0.44      0.16      0.24        50
        64.0       1.00      0.68      0.81        34
        65.0       0.84      0.77      0.81       155
        66.0       0.00      0.00      0.00        14
        67.0       0.69      0.65      0.67       314
        68.0       0.35      0.11      0.17        63
        69.0       0.47      0.74      0.58       308
        70.0       0.64      0.54      0.59        68
        71.0       0.42      0.59      0.49        66
        72.0       0.00      0.00      0.00        14
        73.0       0.64      0.28      0.39        25
        74.0       0.00      0.00      0.00        18
        75.0       0.53      0.28      0.37        60
        76.0       0.66      0.66      0.66       205
        77.0       0.62      0.34      0.44        77
        78.0       0.90      0.76      0.83        59
        79.0       0.66      0.44      0.53       139
        80.0       0.79      0.81      0.80        42
        81.0       0.37      0.59      0.45       175
        82.0       0.53      0.58      0.56        43
        83.0       0.44      0.42      0.43        26
        84.0       0.55      0.57      0.56       106
        85.0       1.00      0.50      0.67        14
        86.0       0.82      0.72      0.77       242
        87.0       0.77      0.74      0.75       309
        88.0       0.81      0.72      0.76        58
        89.0       0.67      0.18      0.29        11
        90.0       0.62      0.56      0.59       187
        91.0       0.43      0.39      0.41        46
        92.0       0.50      0.07      0.13        40
        93.0       0.75      0.38      0.50        32
        94.0       0.64      0.69      0.66       289
        95.0       1.00      0.03      0.06        31
        96.0       0.87      0.70      0.78        74
        97.0       0.52      0.44      0.48        27
        98.0       0.91      0.54      0.68        37
        99.0       1.00      0.92      0.96        24
       100.0       0.00      0.00      0.00        25
       101.0       0.51      0.60      0.55        65
       102.0       0.90      0.86      0.88        22
       103.0       0.42      0.83      0.56        64
       104.0       0.56      0.23      0.32        40
       105.0       0.91      0.83      0.87        12
       106.0       0.83      0.72      0.77       114
       107.0       0.76      0.84      0.80       161
       108.0       0.90      0.38      0.53        24
       109.0       0.95      0.73      0.83        52
       110.0       0.93      0.87      0.90        15
       111.0       0.82      0.65      0.72       123
       112.0       0.61      0.45      0.52        42
       113.0       0.72      0.93      0.81       430
       114.0       0.72      0.75      0.74        65
       115.0       0.88      0.45      0.60        31
       116.0       0.80      0.75      0.78       173
       117.0       0.81      0.94      0.87        31
       118.0       0.85      0.77      0.81       117
       119.0       0.72      0.89      0.79       136
       120.0       0.74      0.81      0.77        62
       121.0       0.94      0.87      0.90       224
       122.0       0.81      0.71      0.76        35
       123.0       0.82      0.73      0.77        37
       124.0       0.68      0.68      0.68        31
       125.0       0.60      0.80      0.69        15
       126.0       0.73      0.90      0.81        21
       127.0       0.77      0.85      0.81        73

    accuracy                           0.69     12227
   macro avg       0.67      0.56      0.58     12227
weighted avg       0.70      0.69      0.68     12227


===confusion_matrix===

[[319   0   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0  11 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   0  19   2]
 [  0   0   0 ...   1   4  62]]

===multilabel confusion matrix===

[[[11560   309]
  [   39   319]]

 [[12215     0]
  [    8     4]]

 [[12205     3]
  [    8    11]]

 [[12130    17]
  [   40    40]]

 [[12167     6]
  [   36    18]]

 [[12165     4]
  [   54     4]]

 [[12174     8]
  [   35    10]]

 [[12161    18]
  [   22    26]]

 [[12214     2]
  [   11     0]]

 [[12196    10]
  [   12     9]]

 [[12209     3]
  [   12     3]]

 [[12188     3]
  [   13    23]]

 [[12214     1]
  [    6     6]]

 [[12198     4]
  [    9    16]]

 [[12208     0]
  [   16     3]]

 [[12200     5]
  [    6    16]]

 [[12202     2]
  [   11    12]]

 [[12083    25]
  [   18   101]]

 [[12201     8]
  [    6    12]]

 [[12214     1]
  [   12     0]]

 [[12120    17]
  [   42    48]]

 [[12215     0]
  [   10     2]]

 [[12200     2]
  [    2    23]]

 [[12213     2]
  [   12     0]]

 [[12196     9]
  [   22     0]]

 [[12180     9]
  [   26    12]]

 [[12210     0]
  [    4    13]]

 [[12179    13]
  [   26     9]]

 [[12216     0]
  [   11     0]]

 [[12185     6]
  [   21    15]]

 [[12184    11]
  [   14    18]]

 [[12188     1]
  [   15    23]]

 [[11303   177]
  [  151   596]]

 [[12146     7]
  [    9    65]]

 [[12158    10]
  [    3    56]]

 [[12160    19]
  [    7    41]]

 [[11360   365]
  [  118   384]]

 [[11854   132]
  [   52   189]]

 [[12186     8]
  [   15    18]]

 [[11763   120]
  [  100   244]]

 [[11985    51]
  [   51   140]]

 [[12194     1]
  [   14    18]]

 [[11792    51]
  [   93   291]]

 [[12078    31]
  [   31    87]]

 [[11679   112]
  [  123   313]]

 [[12176     3]
  [    9    39]]

 [[11775    50]
  [   80   322]]

 [[12206     4]
  [   11     6]]

 [[12166    19]
  [   12    30]]

 [[12126    23]
  [    3    75]]

 [[12037    18]
  [   19   153]]

 [[12206     1]
  [   11     9]]

 [[11550   178]
  [  143   356]]

 [[12088    39]
  [   21    79]]

 [[12210     6]
  [    7     4]]

 [[12118     6]
  [   38    65]]

 [[12207     2]
  [   12     6]]

 [[12210     7]
  [    8     2]]

 [[12190     3]
  [    1    33]]

 [[11963    33]
  [  108   123]]

 [[12160     9]
  [   19    39]]

 [[12196     1]
  [   30     0]]

 [[12175     4]
  [   25    23]]

 [[12167    10]
  [   42     8]]

 [[12193     0]
  [   11    23]]

 [[12049    23]
  [   35   120]]

 [[12212     1]
  [   14     0]]

 [[11821    92]
  [  111   203]]

 [[12151    13]
  [   56     7]]

 [[11667   252]
  [   81   227]]

 [[12138    21]
  [   31    37]]

 [[12107    54]
  [   27    39]]

 [[12213     0]
  [   14     0]]

 [[12198     4]
  [   18     7]]

 [[12208     1]
  [   18     0]]

 [[12152    15]
  [   43    17]]

 [[11953    69]
  [   70   135]]

 [[12134    16]
  [   51    26]]

 [[12163     5]
  [   14    45]]

 [[12056    32]
  [   78    61]]

 [[12176     9]
  [    8    34]]

 [[11877   175]
  [   72   103]]

 [[12162    22]
  [   18    25]]

 [[12187    14]
  [   15    11]]

 [[12071    50]
  [   46    60]]

 [[12213     0]
  [    7     7]]

 [[11948    37]
  [   68   174]]

 [[11851    67]
  [   81   228]]

 [[12159    10]
  [   16    42]]

 [[12215     1]
  [    9     2]]

 [[11977    63]
  [   82   105]]

 [[12157    24]
  [   28    18]]

 [[12184     3]
  [   37     3]]

 [[12191     4]
  [   20    12]]

 [[11828   110]
  [   91   198]]

 [[12196     0]
  [   30     1]]

 [[12145     8]
  [   22    52]]

 [[12189    11]
  [   15    12]]

 [[12188     2]
  [   17    20]]

 [[12203     0]
  [    2    22]]

 [[12199     3]
  [   25     0]]

 [[12124    38]
  [   26    39]]

 [[12203     2]
  [    3    19]]

 [[12091    72]
  [   11    53]]

 [[12180     7]
  [   31     9]]

 [[12214     1]
  [    2    10]]

 [[12096    17]
  [   32    82]]

 [[12024    42]
  [   26   135]]

 [[12202     1]
  [   15     9]]

 [[12173     2]
  [   14    38]]

 [[12211     1]
  [    2    13]]

 [[12086    18]
  [   43    80]]

 [[12173    12]
  [   23    19]]

 [[11640   157]
  [   29   401]]

 [[12143    19]
  [   16    49]]

 [[12194     2]
  [   17    14]]

 [[12022    32]
  [   43   130]]

 [[12189     7]
  [    2    29]]

 [[12094    16]
  [   27    90]]

 [[12043    48]
  [   15   121]]

 [[12147    18]
  [   12    50]]

 [[11990    13]
  [   30   194]]

 [[12186     6]
  [   10    25]]

 [[12184     6]
  [   10    27]]

 [[12186    10]
  [   10    21]]

 [[12204     8]
  [    3    12]]

 [[12199     7]
  [    2    19]]

 [[12135    19]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.6899
MCC	0.6832
log_loss	1.4340
f1 score weighted	0.6805
f1 score macro	0.5830
f1 score micro	0.6899
roc_auc ovr	0.9755
roc_auc ovo	0.9718
precision	0.7010
recall	0.6899

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f012824f430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f012824f2e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f012824f7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f012824f5e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.67      0.84      0.75       357
         1.0       1.00      0.25      0.40        12
         2.0       1.00      0.53      0.69        19
         3.0       0.57      0.56      0.57        80
         4.0       0.19      0.20      0.19        54
         5.0       0.27      0.12      0.17        58
         6.0       0.64      0.16      0.25        44
         7.0       0.60      0.69      0.64        48
         8.0       0.00      0.00      0.00        11
         9.0       0.65      0.71      0.68        21
        10.0       0.00      0.00      0.00        15
        11.0       0.80      0.67      0.73        36
        12.0       0.33      0.08      0.13        12
        13.0       0.80      0.64      0.71        25
        14.0       0.50      0.30      0.37        20
        15.0       0.94      0.74      0.83        23
        16.0       0.59      0.70      0.64        23
        17.0       0.91      0.75      0.82       119
        18.0       0.71      0.59      0.65        17
        19.0       0.00      0.00      0.00        13
        20.0       0.55      0.43      0.48        90
        21.0       1.00      0.17      0.29        12
        22.0       0.85      0.68      0.76        25
        23.0       0.50      0.17      0.25        12
        24.0       0.41      0.32      0.36        22
        25.0       0.48      0.41      0.44        37
        26.0       1.00      1.00      1.00        18
        27.0       0.56      0.40      0.47        35
        28.0       0.17      0.08      0.11        12
        29.0       0.47      0.81      0.59        37
        30.0       0.68      0.72      0.70        32
        31.0       1.00      0.59      0.74        39
        32.0       0.78      0.83      0.81       746
        33.0       0.85      0.86      0.86        74
        34.0       0.94      0.86      0.90        58
        35.0       0.71      0.71      0.71        48
        36.0       0.67      0.69      0.68       502
        37.0       0.74      0.73      0.74       241
        38.0       0.81      0.76      0.78        33
        39.0       0.67      0.76      0.72       344
        40.0       0.84      0.68      0.75       191
        41.0       0.95      0.65      0.77        31
        42.0       0.67      0.77      0.72       384
        43.0       0.81      0.83      0.82       118
        44.0       0.79      0.72      0.76       436
        45.0       0.90      0.79      0.84        48
        46.0       0.82      0.82      0.82       402
        47.0       0.58      0.41      0.48        17
        48.0       0.86      0.57      0.69        42
        49.0       0.88      0.94      0.91        77
        50.0       0.83      0.85      0.84       172
        51.0       1.00      0.60      0.75        20
        52.0       0.78      0.65      0.71       499
        53.0       0.80      0.68      0.73        99
        54.0       0.50      0.09      0.15        11
        55.0       0.88      0.74      0.80       103
        56.0       1.00      0.56      0.71        18
        57.0       0.29      0.18      0.22        11
        58.0       0.97      0.91      0.94        34
        59.0       0.62      0.63      0.62       231
        60.0       0.97      0.66      0.78        58
        61.0       0.22      0.07      0.10        30
        62.0       0.63      0.35      0.45        48
        63.0       0.32      0.16      0.22        49
        64.0       0.91      0.62      0.74        34
        65.0       0.82      0.75      0.78       154
        66.0       0.00      0.00      0.00        14
        67.0       0.76      0.56      0.64       314
        68.0       0.17      0.06      0.09        63
        69.0       0.54      0.63      0.58       308
        70.0       0.72      0.42      0.53        69
        71.0       0.51      0.45      0.48        66
        72.0       0.00      0.00      0.00        14
        73.0       0.94      0.64      0.76        25
        74.0       0.00      0.00      0.00        18
        75.0       0.36      0.49      0.42        59
        76.0       0.74      0.69      0.71       205
        77.0       0.51      0.32      0.40        77
        78.0       0.74      0.54      0.63        59
        79.0       0.57      0.56      0.56       139
        80.0       0.83      0.71      0.76        41
        81.0       0.35      0.49      0.41       175
        82.0       0.71      0.56      0.62        43
        83.0       0.69      0.35      0.46        26
        84.0       0.53      0.55      0.54       105
        85.0       0.64      0.50      0.56        14
        86.0       0.79      0.64      0.71       242
        87.0       0.83      0.73      0.78       309
        88.0       0.94      0.50      0.65        58
        89.0       0.80      0.36      0.50        11
        90.0       0.55      0.56      0.55       187
        91.0       0.35      0.41      0.38        46
        92.0       0.25      0.12      0.17        40
        93.0       0.75      0.55      0.63        33
        94.0       0.29      0.82      0.43       289
        95.0       1.00      0.09      0.17        32
        96.0       0.68      0.68      0.68        74
        97.0       0.44      0.26      0.33        27
        98.0       0.62      0.62      0.62        37
        99.0       0.95      0.88      0.91        24
       100.0       0.25      0.04      0.07        26
       101.0       0.67      0.46      0.55        65
       102.0       0.92      0.50      0.65        22
       103.0       0.94      0.73      0.82        64
       104.0       0.43      0.38      0.40        40
       105.0       0.86      0.46      0.60        13
       106.0       0.75      0.87      0.81       113
       107.0       0.70      0.82      0.75       162
       108.0       0.45      0.21      0.29        24
       109.0       0.90      0.83      0.86        52
       110.0       1.00      0.80      0.89        15
       111.0       0.83      0.67      0.74       123
       112.0       0.95      0.46      0.62        41
       113.0       0.67      0.97      0.79       430
       114.0       0.83      0.80      0.81        65
       115.0       0.61      0.55      0.58        31
       116.0       0.87      0.72      0.79       173
       117.0       0.64      0.70      0.67        30
       118.0       0.92      0.85      0.88       118
       119.0       0.71      0.90      0.80       136
       120.0       0.70      0.61      0.65        61
       121.0       0.80      0.89      0.84       225
       122.0       0.87      0.94      0.90        35
       123.0       0.63      0.76      0.69        38
       124.0       0.71      0.87      0.78        31
       125.0       1.00      0.62      0.77        16
       126.0       0.63      0.81      0.71        21
       127.0       0.73      0.55      0.62        73

    accuracy                           0.68     12227
   macro avg       0.67      0.55      0.58     12227
weighted avg       0.70      0.68      0.68     12227


===confusion_matrix===

[[300   0   0 ...   0   0   0]
 [  2   3   0 ...   0   0   0]
 [  1   0  10 ...   0   0   0]
 ...
 [  0   0   0 ...  10   0   1]
 [  0   0   0 ...   0  17   2]
 [  0   0   0 ...   0   8  40]]

===multilabel confusion matrix===

[[[11722   148]
  [   57   300]]

 [[12215     0]
  [    9     3]]

 [[12208     0]
  [    9    10]]

 [[12113    34]
  [   35    45]]

 [[12125    48]
  [   43    11]]

 [[12150    19]
  [   51     7]]

 [[12179     4]
  [   37     7]]

 [[12157    22]
  [   15    33]]

 [[12216     0]
  [   11     0]]

 [[12198     8]
  [    6    15]]

 [[12211     1]
  [   15     0]]

 [[12185     6]
  [   12    24]]

 [[12213     2]
  [   11     1]]

 [[12198     4]
  [    9    16]]

 [[12201     6]
  [   14     6]]

 [[12203     1]
  [    6    17]]

 [[12193    11]
  [    7    16]]

 [[12099     9]
  [   30    89]]

 [[12206     4]
  [    7    10]]

 [[12214     0]
  [   13     0]]

 [[12105    32]
  [   51    39]]

 [[12215     0]
  [   10     2]]

 [[12199     3]
  [    8    17]]

 [[12213     2]
  [   10     2]]

 [[12195    10]
  [   15     7]]

 [[12174    16]
  [   22    15]]

 [[12209     0]
  [    0    18]]

 [[12181    11]
  [   21    14]]

 [[12210     5]
  [   11     1]]

 [[12156    34]
  [    7    30]]

 [[12184    11]
  [    9    23]]

 [[12188     0]
  [   16    23]]

 [[11304   177]
  [  124   622]]

 [[12142    11]
  [   10    64]]

 [[12166     3]
  [    8    50]]

 [[12165    14]
  [   14    34]]

 [[11554   171]
  [  154   348]]

 [[11923    63]
  [   64   177]]

 [[12188     6]
  [    8    25]]

 [[11755   128]
  [   81   263]]

 [[12012    24]
  [   61   130]]

 [[12195     1]
  [   11    20]]

 [[11696   147]
  [   87   297]]

 [[12086    23]
  [   20    98]]

 [[11709    82]
  [  120   316]]

 [[12175     4]
  [   10    38]]

 [[11755    70]
  [   74   328]]

 [[12205     5]
  [   10     7]]

 [[12181     4]
  [   18    24]]

 [[12140    10]
  [    5    72]]

 [[12026    29]
  [   26   146]]

 [[12207     0]
  [    8    12]]

 [[11634    94]
  [  175   324]]

 [[12111    17]
  [   32    67]]

 [[12215     1]
  [   10     1]]

 [[12114    10]
  [   27    76]]

 [[12209     0]
  [    8    10]]

 [[12211     5]
  [    9     2]]

 [[12192     1]
  [    3    31]]

 [[11905    91]
  [   85   146]]

 [[12168     1]
  [   20    38]]

 [[12190     7]
  [   28     2]]

 [[12169    10]
  [   31    17]]

 [[12161    17]
  [   41     8]]

 [[12191     2]
  [   13    21]]

 [[12048    25]
  [   39   115]]

 [[12213     0]
  [   14     0]]

 [[11857    56]
  [  138   176]]

 [[12144    20]
  [   59     4]]

 [[11753   166]
  [  115   193]]

 [[12147    11]
  [   40    29]]

 [[12132    29]
  [   36    30]]

 [[12209     4]
  [   14     0]]

 [[12201     1]
  [    9    16]]

 [[12209     0]
  [   18     0]]

 [[12117    51]
  [   30    29]]

 [[11972    50]
  [   64   141]]

 [[12126    24]
  [   52    25]]

 [[12157    11]
  [   27    32]]

 [[12028    60]
  [   61    78]]

 [[12180     6]
  [   12    29]]

 [[11889   163]
  [   89    86]]

 [[12174    10]
  [   19    24]]

 [[12197     4]
  [   17     9]]

 [[12070    52]
  [   47    58]]

 [[12209     4]
  [    7     7]]

 [[11945    40]
  [   87   155]]

 [[11872    46]
  [   84   225]]

 [[12167     2]
  [   29    29]]

 [[12215     1]
  [    7     4]]

 [[11955    85]
  [   83   104]]

 [[12145    36]
  [   27    19]]

 [[12172    15]
  [   35     5]]

 [[12188     6]
  [   15    18]]

 [[11368   570]
  [   51   238]]

 [[12195     0]
  [   29     3]]

 [[12130    23]
  [   24    50]]

 [[12191     9]
  [   20     7]]

 [[12176    14]
  [   14    23]]

 [[12202     1]
  [    3    21]]

 [[12198     3]
  [   25     1]]

 [[12147    15]
  [   35    30]]

 [[12204     1]
  [   11    11]]

 [[12160     3]
  [   17    47]]

 [[12167    20]
  [   25    15]]

 [[12213     1]
  [    7     6]]

 [[12082    32]
  [   15    98]]

 [[12007    58]
  [   29   133]]

 [[12197     6]
  [   19     5]]

 [[12170     5]
  [    9    43]]

 [[12212     0]
  [    3    12]]

 [[12087    17]
  [   41    82]]

 [[12185     1]
  [   22    19]]

 [[11589   208]
  [   12   418]]

 [[12151    11]
  [   13    52]]

 [[12185    11]
  [   14    17]]

 [[12036    18]
  [   48   125]]

 [[12185    12]
  [    9    21]]

 [[12100     9]
  [   18   100]]

 [[12041    50]
  [   13   123]]

 [[12150    16]
  [   24    37]]

 [[11952    50]
  [   25   200]]

 [[12187     5]
  [    2    33]]

 [[12172    17]
  [    9    29]]

 [[12185    11]
  [    4    27]]

 [[12211     0]
  [    6    10]]

 [[12196    10]
  [    4    17]]

 [[12139    15]
  [   33    40]]]

===scores report===
metrics	scores
Accuracy	0.6828
MCC	0.6763
log_loss	1.4586
f1 score weighted	0.6789
f1 score macro	0.5837
f1 score micro	0.6828
roc_auc ovr	0.9749
roc_auc ovo	0.9712
precision	0.7013
recall	0.6828

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f012824f430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f012824f2e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f012824f7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f012824f5e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.81      0.74       357
         1.0       0.45      0.38      0.42        13
         2.0       0.57      0.42      0.48        19
         3.0       0.50      0.53      0.52        79
         4.0       0.22      0.24      0.23        55
         5.0       0.38      0.10      0.16        59
         6.0       0.42      0.25      0.31        44
         7.0       0.64      0.73      0.68        48
         8.0       0.50      0.10      0.17        10
         9.0       0.62      0.48      0.54        21
        10.0       0.67      0.27      0.38        15
        11.0       0.65      0.72      0.68        36
        12.0       1.00      0.50      0.67        12
        13.0       1.00      0.64      0.78        25
        14.0       1.00      0.05      0.10        20
        15.0       0.88      0.68      0.77        22
        16.0       0.54      0.65      0.59        23
        17.0       0.90      0.77      0.83       118
        18.0       0.71      0.28      0.40        18
        19.0       1.00      0.08      0.14        13
        20.0       0.90      0.30      0.45        89
        21.0       0.60      0.25      0.35        12
        22.0       1.00      0.75      0.86        24
        23.0       1.00      0.08      0.15        12
        24.0       0.67      0.09      0.15        23
        25.0       0.92      0.32      0.48        37
        26.0       0.94      1.00      0.97        17
        27.0       0.38      0.14      0.20        36
        28.0       0.00      0.00      0.00        12
        29.0       0.78      0.57      0.66        37
        30.0       0.43      0.62      0.51        32
        31.0       0.93      0.72      0.81        39
        32.0       0.85      0.83      0.84       746
        33.0       0.84      0.86      0.85        74
        34.0       0.94      0.76      0.84        58
        35.0       0.39      0.79      0.52        48
        36.0       0.78      0.57      0.66       502
        37.0       0.78      0.68      0.73       240
        38.0       0.75      0.55      0.63        33
        39.0       0.54      0.79      0.64       344
        40.0       0.60      0.74      0.67       191
        41.0       0.82      0.45      0.58        31
        42.0       0.75      0.70      0.72       384
        43.0       0.74      0.79      0.77       117
        44.0       0.68      0.74      0.71       436
        45.0       0.95      0.73      0.83        49
        46.0       0.65      0.90      0.75       402
        47.0       0.86      0.35      0.50        17
        48.0       0.69      0.81      0.75        42
        49.0       0.82      0.90      0.86        77
        50.0       0.91      0.92      0.91       172
        51.0       0.86      0.32      0.46        19
        52.0       0.63      0.66      0.64       499
        53.0       0.62      0.79      0.70        99
        54.0       0.50      0.18      0.27        11
        55.0       0.94      0.64      0.76       103
        56.0       0.89      0.44      0.59        18
        57.0       0.75      0.27      0.40        11
        58.0       0.94      0.94      0.94        35
        59.0       0.59      0.52      0.55       231
        60.0       0.81      0.75      0.78        57
        61.0       0.03      0.03      0.03        29
        62.0       0.67      0.29      0.41        48
        63.0       0.44      0.16      0.24        49
        64.0       0.83      0.59      0.69        34
        65.0       0.93      0.63      0.75       155
        66.0       0.20      0.07      0.11        14
        67.0       0.62      0.65      0.64       315
        68.0       0.28      0.11      0.16        63
        69.0       0.51      0.66      0.58       307
        70.0       0.69      0.35      0.46        69
        71.0       0.32      0.50      0.39        66
        72.0       0.35      0.40      0.38        15
        73.0       0.43      0.36      0.39        25
        74.0       0.22      0.22      0.22        18
        75.0       0.56      0.17      0.26        59
        76.0       0.89      0.53      0.67       206
        77.0       0.85      0.30      0.45        76
        78.0       0.85      0.66      0.74        59
        79.0       0.63      0.42      0.51       140
        80.0       0.72      0.81      0.76        42
        81.0       0.37      0.57      0.45       175
        82.0       0.53      0.53      0.53        43
        83.0       0.62      0.32      0.42        25
        84.0       0.60      0.52      0.56       105
        85.0       0.47      0.50      0.48        14
        86.0       0.82      0.69      0.75       242
        87.0       0.77      0.75      0.76       310
        88.0       0.35      0.73      0.47        59
        89.0       0.38      0.27      0.32        11
        90.0       0.53      0.51      0.52       187
        91.0       0.93      0.28      0.43        46
        92.0       0.60      0.15      0.24        40
        93.0       0.89      0.48      0.63        33
        94.0       0.58      0.64      0.61       289
        95.0       0.60      0.09      0.16        32
        96.0       0.63      0.83      0.72        75
        97.0       0.53      0.29      0.37        28
        98.0       0.77      0.54      0.63        37
        99.0       0.88      1.00      0.94        23
       100.0       0.33      0.12      0.18        25
       101.0       0.69      0.50      0.58        66
       102.0       1.00      0.52      0.69        21
       103.0       0.87      0.72      0.79        65
       104.0       0.50      0.35      0.41        40
       105.0       0.64      0.58      0.61        12
       106.0       0.83      0.81      0.82       113
       107.0       0.69      0.83      0.76       162
       108.0       0.83      0.42      0.56        24
       109.0       0.78      0.79      0.79        53
       110.0       0.89      0.57      0.70        14
       111.0       0.82      0.54      0.65       123
       112.0       0.84      0.39      0.53        41
       113.0       0.52      0.97      0.68       429
       114.0       0.66      0.72      0.69        65
       115.0       0.68      0.55      0.61        31
       116.0       0.57      0.87      0.69       173
       117.0       0.89      0.83      0.86        30
       118.0       0.87      0.83      0.85       117
       119.0       0.71      0.90      0.80       136
       120.0       0.83      0.62      0.71        61
       121.0       0.84      0.88      0.86       225
       122.0       0.81      0.74      0.78        35
       123.0       0.86      0.63      0.73        38
       124.0       0.73      0.80      0.76        30
       125.0       0.86      0.75      0.80        16
       126.0       0.59      0.73      0.65        22
       127.0       0.76      0.88      0.82        73

    accuracy                           0.67     12226
   macro avg       0.68      0.54      0.57     12226
weighted avg       0.69      0.67      0.66     12226


===confusion_matrix===

[[290   0   1 ...   0   0   0]
 [  0   5   0 ...   0   0   0]
 [  0   0   8 ...   0   0   0]
 ...
 [  0   0   0 ...  12   1   1]
 [  0   0   0 ...   0  16   4]
 [  0   0   0 ...   0   5  64]]

===multilabel confusion matrix===

[[[11737   132]
  [   67   290]]

 [[12207     6]
  [    8     5]]

 [[12201     6]
  [   11     8]]

 [[12105    42]
  [   37    42]]

 [[12125    46]
  [   42    13]]

 [[12157    10]
  [   53     6]]

 [[12167    15]
  [   33    11]]

 [[12158    20]
  [   13    35]]

 [[12215     1]
  [    9     1]]

 [[12199     6]
  [   11    10]]

 [[12209     2]
  [   11     4]]

 [[12176    14]
  [   10    26]]

 [[12214     0]
  [    6     6]]

 [[12201     0]
  [    9    16]]

 [[12206     0]
  [   19     1]]

 [[12202     2]
  [    7    15]]

 [[12190    13]
  [    8    15]]

 [[12098    10]
  [   27    91]]

 [[12206     2]
  [   13     5]]

 [[12213     0]
  [   12     1]]

 [[12134     3]
  [   62    27]]

 [[12212     2]
  [    9     3]]

 [[12202     0]
  [    6    18]]

 [[12214     0]
  [   11     1]]

 [[12202     1]
  [   21     2]]

 [[12188     1]
  [   25    12]]

 [[12208     1]
  [    0    17]]

 [[12182     8]
  [   31     5]]

 [[12213     1]
  [   12     0]]

 [[12183     6]
  [   16    21]]

 [[12168    26]
  [   12    20]]

 [[12185     2]
  [   11    28]]

 [[11368   112]
  [  124   622]]

 [[12140    12]
  [   10    64]]

 [[12165     3]
  [   14    44]]

 [[12119    59]
  [   10    38]]

 [[11641    83]
  [  216   286]]

 [[11940    46]
  [   76   164]]

 [[12187     6]
  [   15    18]]

 [[11649   233]
  [   72   272]]

 [[11942    93]
  [   49   142]]

 [[12192     3]
  [   17    14]]

 [[11754    88]
  [  117   267]]

 [[12077    32]
  [   24    93]]

 [[11640   150]
  [  112   324]]

 [[12175     2]
  [   13    36]]

 [[11629   195]
  [   41   361]]

 [[12208     1]
  [   11     6]]

 [[12169    15]
  [    8    34]]

 [[12134    15]
  [    8    69]]

 [[12038    16]
  [   14   158]]

 [[12206     1]
  [   13     6]]

 [[11539   188]
  [  172   327]]

 [[12080    47]
  [   21    78]]

 [[12213     2]
  [    9     2]]

 [[12119     4]
  [   37    66]]

 [[12207     1]
  [   10     8]]

 [[12214     1]
  [    8     3]]

 [[12189     2]
  [    2    33]]

 [[11910    85]
  [  110   121]]

 [[12159    10]
  [   14    43]]

 [[12168    29]
  [   28     1]]

 [[12171     7]
  [   34    14]]

 [[12167    10]
  [   41     8]]

 [[12188     4]
  [   14    20]]

 [[12064     7]
  [   57    98]]

 [[12208     4]
  [   13     1]]

 [[11787   124]
  [  109   206]]

 [[12145    18]
  [   56     7]]

 [[11726   193]
  [  104   203]]

 [[12146    11]
  [   45    24]]

 [[12089    71]
  [   33    33]]

 [[12200    11]
  [    9     6]]

 [[12189    12]
  [   16     9]]

 [[12194    14]
  [   14     4]]

 [[12159     8]
  [   49    10]]

 [[12007    13]
  [   96   110]]

 [[12146     4]
  [   53    23]]

 [[12160     7]
  [   20    39]]

 [[12052    34]
  [   81    59]]

 [[12171    13]
  [    8    34]]

 [[11885   166]
  [   76    99]]

 [[12163    20]
  [   20    23]]

 [[12196     5]
  [   17     8]]

 [[12085    36]
  [   50    55]]

 [[12204     8]
  [    7     7]]

 [[11947    37]
  [   74   168]]

 [[11847    69]
  [   76   234]]

 [[12086    81]
  [   16    43]]

 [[12210     5]
  [    8     3]]

 [[11955    84]
  [   91    96]]

 [[12179     1]
  [   33    13]]

 [[12182     4]
  [   34     6]]

 [[12191     2]
  [   17    16]]

 [[11801   136]
  [  103   186]]

 [[12192     2]
  [   29     3]]

 [[12115    36]
  [   13    62]]

 [[12191     7]
  [   20     8]]

 [[12183     6]
  [   17    20]]

 [[12200     3]
  [    0    23]]

 [[12195     6]
  [   22     3]]

 [[12145    15]
  [   33    33]]

 [[12205     0]
  [   10    11]]

 [[12154     7]
  [   18    47]]

 [[12172    14]
  [   26    14]]

 [[12210     4]
  [    5     7]]

 [[12095    18]
  [   22    91]]

 [[12004    60]
  [   27   135]]

 [[12200     2]
  [   14    10]]

 [[12161    12]
  [   11    42]]

 [[12211     1]
  [    6     8]]

 [[12089    14]
  [   57    66]]

 [[12182     3]
  [   25    16]]

 [[11420   377]
  [   15   414]]

 [[12137    24]
  [   18    47]]

 [[12187     8]
  [   14    17]]

 [[11938   115]
  [   22   151]]

 [[12193     3]
  [    5    25]]

 [[12094    15]
  [   20    97]]

 [[12040    50]
  [   13   123]]

 [[12157     8]
  [   23    38]]

 [[11964    37]
  [   26   199]]

 [[12185     6]
  [    9    26]]

 [[12184     4]
  [   14    24]]

 [[12187     9]
  [    6    24]]

 [[12208     2]
  [    4    12]]

 [[12193    11]
  [    6    16]]

 [[12133    20]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6704
MCC	0.6634
log_loss	1.5636
f1 score weighted	0.6615
f1 score macro	0.5721
f1 score micro	0.6704
roc_auc ovr	0.9715
roc_auc ovo	0.9672
precision	0.6934
recall	0.6704

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f012824f430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f012824f2e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f012824f7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f012824f5e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.80      0.80       358
         1.0       0.33      0.08      0.13        12
         2.0       0.62      0.44      0.52        18
         3.0       0.61      0.42      0.50        79
         4.0       0.21      0.35      0.26        55
         5.0       0.17      0.12      0.14        58
         6.0       0.39      0.27      0.32        45
         7.0       0.73      0.57      0.64        47
         8.0       1.00      0.30      0.46        10
         9.0       0.46      0.62      0.53        21
        10.0       0.43      0.20      0.27        15
        11.0       0.70      0.78      0.74        36
        12.0       0.33      0.17      0.22        12
        13.0       0.67      0.40      0.50        25
        14.0       1.00      0.25      0.40        20
        15.0       1.00      0.77      0.87        22
        16.0       0.65      0.57      0.60        23
        17.0       0.88      0.75      0.81       118
        18.0       0.56      0.50      0.53        18
        19.0       1.00      0.08      0.14        13
        20.0       0.60      0.45      0.51        89
        21.0       0.43      0.23      0.30        13
        22.0       0.86      0.72      0.78        25
        23.0       0.67      0.17      0.27        12
        24.0       1.00      0.04      0.08        23
        25.0       0.62      0.68      0.65        37
        26.0       1.00      0.94      0.97        17
        27.0       0.62      0.14      0.23        36
        28.0       0.67      0.17      0.27        12
        29.0       0.86      0.67      0.75        36
        30.0       0.62      0.81      0.70        32
        31.0       0.66      0.90      0.76        39
        32.0       0.68      0.87      0.76       747
        33.0       0.85      0.84      0.84        74
        34.0       0.78      0.81      0.80        58
        35.0       0.88      0.62      0.73        47
        36.0       0.79      0.63      0.70       502
        37.0       0.64      0.74      0.68       240
        38.0       0.83      0.74      0.78        34
        39.0       0.63      0.77      0.70       344
        40.0       0.75      0.77      0.76       191
        41.0       0.85      0.53      0.65        32
        42.0       0.66      0.78      0.72       384
        43.0       0.76      0.80      0.78       117
        44.0       0.82      0.73      0.77       437
        45.0       0.95      0.73      0.83        49
        46.0       0.85      0.85      0.85       401
        47.0       1.00      0.12      0.21        17
        48.0       0.89      0.38      0.53        42
        49.0       0.94      0.75      0.83        77
        50.0       0.88      0.86      0.87       171
        51.0       0.89      0.40      0.55        20
        52.0       0.72      0.64      0.68       499
        53.0       0.72      0.66      0.69       100
        54.0       0.00      0.00      0.00        11
        55.0       0.89      0.81      0.85       104
        56.0       0.30      0.32      0.31        19
        57.0       0.50      0.09      0.15        11
        58.0       0.92      0.94      0.93        35
        59.0       0.46      0.70      0.56       230
        60.0       0.84      0.81      0.82        58
        61.0       0.10      0.03      0.05        29
        62.0       0.66      0.43      0.52        49
        63.0       0.15      0.26      0.19        50
        64.0       0.92      0.68      0.78        34
        65.0       0.62      0.85      0.72       155
        66.0       0.20      0.07      0.11        14
        67.0       0.60      0.73      0.66       314
        68.0       0.14      0.16      0.15        62
        69.0       0.43      0.68      0.53       307
        70.0       0.47      0.32      0.38        68
        71.0       0.72      0.39      0.51        66
        72.0       0.67      0.13      0.22        15
        73.0       0.88      0.28      0.42        25
        74.0       0.00      0.00      0.00        19
        75.0       0.44      0.20      0.28        59
        76.0       0.58      0.73      0.65       206
        77.0       0.83      0.49      0.62        77
        78.0       0.65      0.61      0.63        59
        79.0       0.92      0.52      0.66       139
        80.0       0.82      0.74      0.78        42
        81.0       0.53      0.46      0.49       174
        82.0       0.83      0.35      0.49        43
        83.0       0.31      0.32      0.31        25
        84.0       0.63      0.59      0.61       105
        85.0       0.69      0.60      0.64        15
        86.0       0.45      0.73      0.56       242
        87.0       0.91      0.71      0.80       309
        88.0       0.82      0.61      0.70        59
        89.0       0.00      0.00      0.00        11
        90.0       0.59      0.40      0.48       188
        91.0       0.71      0.26      0.37        47
        92.0       0.19      0.15      0.17        40
        93.0       0.49      0.55      0.51        33
        94.0       0.65      0.66      0.65       288
        95.0       0.25      0.16      0.19        32
        96.0       0.88      0.81      0.85        75
        97.0       0.70      0.26      0.38        27
        98.0       0.89      0.45      0.60        38
        99.0       0.81      0.96      0.88        23
       100.0       0.43      0.12      0.19        25
       101.0       0.91      0.47      0.62        66
       102.0       0.77      0.77      0.77        22
       103.0       0.87      0.70      0.78        64
       104.0       0.87      0.33      0.48        39
       105.0       1.00      0.67      0.80        12
       106.0       0.48      0.82      0.60       113
       107.0       0.81      0.80      0.80       161
       108.0       0.60      0.39      0.47        23
       109.0       0.84      0.92      0.88        53
       110.0       0.77      0.71      0.74        14
       111.0       0.63      0.65      0.64       123
       112.0       0.68      0.37      0.48        41
       113.0       0.66      0.95      0.78       429
       114.0       0.94      0.77      0.85        65
       115.0       0.59      0.52      0.55        31
       116.0       0.78      0.73      0.75       173
       117.0       0.96      0.84      0.90        31
       118.0       0.90      0.83      0.86       117
       119.0       0.95      0.71      0.81       135
       120.0       0.96      0.76      0.85        62
       121.0       0.85      0.87      0.86       224
       122.0       0.94      0.86      0.90        35
       123.0       1.00      0.59      0.75        37
       124.0       0.80      0.53      0.64        30
       125.0       0.83      0.62      0.71        16
       126.0       0.86      0.86      0.86        22
       127.0       0.67      0.88      0.76        73

    accuracy                           0.68     12226
   macro avg       0.68      0.54      0.58     12226
weighted avg       0.70      0.68      0.68     12226


===confusion_matrix===

[[285   1   0 ...   0   0   0]
 [  0   1   0 ...   0   0   0]
 [  0   0   8 ...   0   0   0]
 ...
 [  0   0   0 ...  10   1   3]
 [  0   0   0 ...   0  19   3]
 [  0   0   0 ...   1   1  64]]

===multilabel confusion matrix===

[[[11802    66]
  [   73   285]]

 [[12212     2]
  [   11     1]]

 [[12203     5]
  [   10     8]]

 [[12126    21]
  [   46    33]]

 [[12100    71]
  [   36    19]]

 [[12135    33]
  [   51     7]]

 [[12162    19]
  [   33    12]]

 [[12169    10]
  [   20    27]]

 [[12216     0]
  [    7     3]]

 [[12190    15]
  [    8    13]]

 [[12207     4]
  [   12     3]]

 [[12178    12]
  [    8    28]]

 [[12210     4]
  [   10     2]]

 [[12196     5]
  [   15    10]]

 [[12206     0]
  [   15     5]]

 [[12204     0]
  [    5    17]]

 [[12196     7]
  [   10    13]]

 [[12096    12]
  [   30    88]]

 [[12201     7]
  [    9     9]]

 [[12213     0]
  [   12     1]]

 [[12110    27]
  [   49    40]]

 [[12209     4]
  [   10     3]]

 [[12198     3]
  [    7    18]]

 [[12213     1]
  [   10     2]]

 [[12203     0]
  [   22     1]]

 [[12174    15]
  [   12    25]]

 [[12209     0]
  [    1    16]]

 [[12187     3]
  [   31     5]]

 [[12213     1]
  [   10     2]]

 [[12186     4]
  [   12    24]]

 [[12178    16]
  [    6    26]]

 [[12169    18]
  [    4    35]]

 [[11167   312]
  [   97   650]]

 [[12141    11]
  [   12    62]]

 [[12155    13]
  [   11    47]]

 [[12175     4]
  [   18    29]]

 [[11641    83]
  [  187   315]]

 [[11886   100]
  [   63   177]]

 [[12187     5]
  [    9    25]]

 [[11728   154]
  [   78   266]]

 [[11986    49]
  [   44   147]]

 [[12191     3]
  [   15    17]]

 [[11690   152]
  [   85   299]]

 [[12079    30]
  [   23    94]]

 [[11718    71]
  [  117   320]]

 [[12175     2]
  [   13    36]]

 [[11767    58]
  [   60   341]]

 [[12209     0]
  [   15     2]]

 [[12182     2]
  [   26    16]]

 [[12145     4]
  [   19    58]]

 [[12034    21]
  [   24   147]]

 [[12205     1]
  [   12     8]]

 [[11603   124]
  [  180   319]]

 [[12100    26]
  [   34    66]]

 [[12215     0]
  [   11     0]]

 [[12112    10]
  [   20    84]]

 [[12193    14]
  [   13     6]]

 [[12214     1]
  [   10     1]]

 [[12188     3]
  [    2    33]]

 [[11806   190]
  [   68   162]]

 [[12159     9]
  [   11    47]]

 [[12188     9]
  [   28     1]]

 [[12166    11]
  [   28    21]]

 [[12101    75]
  [   37    13]]

 [[12190     2]
  [   11    23]]

 [[11991    80]
  [   24   131]]

 [[12208     4]
  [   13     1]]

 [[11758   154]
  [   86   228]]

 [[12103    61]
  [   52    10]]

 [[11646   273]
  [   97   210]]

 [[12133    25]
  [   46    22]]

 [[12150    10]
  [   40    26]]

 [[12210     1]
  [   13     2]]

 [[12200     1]
  [   18     7]]

 [[12207     0]
  [   19     0]]

 [[12152    15]
  [   47    12]]

 [[11912   108]
  [   56   150]]

 [[12141     8]
  [   39    38]]

 [[12148    19]
  [   23    36]]

 [[12081     6]
  [   67    72]]

 [[12177     7]
  [   11    31]]

 [[11980    72]
  [   94    80]]

 [[12180     3]
  [   28    15]]

 [[12183    18]
  [   17     8]]

 [[12084    37]
  [   43    62]]

 [[12207     4]
  [    6     9]]

 [[11773   211]
  [   66   176]]

 [[11896    21]
  [   89   220]]

 [[12159     8]
  [   23    36]]

 [[12215     0]
  [   11     0]]

 [[11985    53]
  [  112    76]]

 [[12174     5]
  [   35    12]]

 [[12160    26]
  [   34     6]]

 [[12174    19]
  [   15    18]]

 [[11835   103]
  [   99   189]]

 [[12179    15]
  [   27     5]]

 [[12143     8]
  [   14    61]]

 [[12196     3]
  [   20     7]]

 [[12186     2]
  [   21    17]]

 [[12198     5]
  [    1    22]]

 [[12197     4]
  [   22     3]]

 [[12157     3]
  [   35    31]]

 [[12199     5]
  [    5    17]]

 [[12155     7]
  [   19    45]]

 [[12185     2]
  [   26    13]]

 [[12214     0]
  [    4     8]]

 [[12011   102]
  [   20    93]]

 [[12035    30]
  [   33   128]]

 [[12197     6]
  [   14     9]]

 [[12164     9]
  [    4    49]]

 [[12209     3]
  [    4    10]]

 [[12057    46]
  [   43    80]]

 [[12178     7]
  [   26    15]]

 [[11589   208]
  [   21   408]]

 [[12158     3]
  [   15    50]]

 [[12184    11]
  [   15    16]]

 [[12018    35]
  [   47   126]]

 [[12194     1]
  [    5    26]]

 [[12098    11]
  [   20    97]]

 [[12086     5]
  [   39    96]]

 [[12162     2]
  [   15    47]]

 [[11968    34]
  [   30   194]]

 [[12189     2]
  [    5    30]]

 [[12189     0]
  [   15    22]]

 [[12192     4]
  [   14    16]]

 [[12208     2]
  [    6    10]]

 [[12201     3]
  [    3    19]]

 [[12121    32]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6813
MCC	0.6744
log_loss	1.4360
f1 score weighted	0.6752
f1 score macro	0.5752
f1 score micro	0.6813
roc_auc ovr	0.9753
roc_auc ovo	0.9720
precision	0.7019
recall	0.6813

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f012824f430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f012824f2e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f012824f7c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f012824f5e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.73      0.75       358
         1.0       0.75      0.50      0.60        12
         2.0       0.90      0.47      0.62        19
         3.0       0.90      0.35      0.51        79
         4.0       0.54      0.24      0.33        55
         5.0       0.55      0.10      0.17        58
         6.0       0.43      0.33      0.38        45
         7.0       0.65      0.51      0.57        47
         8.0       0.00      0.00      0.00        10
         9.0       0.75      0.43      0.55        21
        10.0       1.00      0.07      0.12        15
        11.0       0.64      0.75      0.69        36
        12.0       0.75      0.25      0.38        12
        13.0       1.00      0.64      0.78        25
        14.0       1.00      0.21      0.35        19
        15.0       0.76      0.59      0.67        22
        16.0       0.59      0.70      0.64        23
        17.0       0.79      0.86      0.83       118
        18.0       0.60      0.33      0.43        18
        19.0       0.00      0.00      0.00        12
        20.0       0.52      0.46      0.49        90
        21.0       1.00      0.15      0.27        13
        22.0       1.00      0.64      0.78        25
        23.0       0.00      0.00      0.00        13
        24.0       0.62      0.23      0.33        22
        25.0       0.54      0.53      0.53        38
        26.0       0.89      1.00      0.94        17
        27.0       0.42      0.37      0.39        35
        28.0       0.44      0.33      0.38        12
        29.0       0.72      0.64      0.68        36
        30.0       0.57      0.78      0.66        32
        31.0       0.84      0.68      0.75        38
        32.0       0.87      0.80      0.84       747
        33.0       0.90      0.83      0.86        75
        34.0       0.89      0.92      0.90        59
        35.0       0.65      0.66      0.65        47
        36.0       0.51      0.75      0.61       501
        37.0       0.54      0.71      0.61       241
        38.0       0.96      0.70      0.81        33
        39.0       0.67      0.68      0.68       344
        40.0       0.91      0.75      0.82       192
        41.0       1.00      0.47      0.64        32
        42.0       0.84      0.70      0.76       384
        43.0       0.90      0.85      0.87       117
        44.0       0.71      0.71      0.71       436
        45.0       1.00      0.88      0.93        49
        46.0       0.86      0.84      0.85       401
        47.0       0.86      0.35      0.50        17
        48.0       0.72      0.62      0.67        42
        49.0       0.79      0.88      0.83        77
        50.0       0.79      0.85      0.82       172
        51.0       1.00      0.40      0.57        20
        52.0       0.70      0.64      0.67       499
        53.0       0.79      0.62      0.70       100
        54.0       0.50      0.09      0.15        11
        55.0       0.90      0.85      0.87       104
        56.0       0.62      0.28      0.38        18
        57.0       0.50      0.20      0.29        10
        58.0       0.90      0.80      0.85        35
        59.0       0.49      0.62      0.55       230
        60.0       0.74      0.86      0.79        58
        61.0       0.00      0.00      0.00        29
        62.0       0.71      0.49      0.58        49
        63.0       0.46      0.22      0.30        50
        64.0       0.70      0.68      0.69        34
        65.0       0.63      0.79      0.70       155
        66.0       0.00      0.00      0.00        14
        67.0       0.46      0.71      0.56       314
        68.0       0.20      0.08      0.11        62
        69.0       0.63      0.56      0.60       307
        70.0       0.30      0.50      0.37        68
        71.0       0.61      0.41      0.49        66
        72.0       0.17      0.14      0.15        14
        73.0       0.50      0.58      0.54        24
        74.0       0.00      0.00      0.00        19
        75.0       0.26      0.20      0.22        60
        76.0       0.32      0.80      0.45       206
        77.0       0.77      0.31      0.44        77
        78.0       0.78      0.53      0.63        59
        79.0       0.82      0.51      0.63       139
        80.0       0.67      0.74      0.70        42
        81.0       0.47      0.39      0.43       174
        82.0       0.81      0.30      0.44        43
        83.0       0.75      0.12      0.20        26
        84.0       0.60      0.49      0.54       106
        85.0       0.91      0.67      0.77        15
        86.0       0.49      0.78      0.60       241
        87.0       0.45      0.89      0.60       309
        88.0       0.49      0.58      0.53        59
        89.0       0.67      0.40      0.50        10
        90.0       0.91      0.38      0.54       188
        91.0       0.72      0.46      0.56        46
        92.0       0.14      0.02      0.04        41
        93.0       0.88      0.44      0.58        32
        94.0       0.63      0.63      0.63       288
        95.0       0.22      0.13      0.16        31
        96.0       0.83      0.67      0.74        75
        97.0       0.53      0.30      0.38        27
        98.0       0.94      0.42      0.58        38
        99.0       0.88      0.92      0.90        24
       100.0       1.00      0.04      0.08        25
       101.0       0.77      0.55      0.64        65
       102.0       0.86      0.82      0.84        22
       103.0       1.00      0.66      0.79        64
       104.0       0.92      0.28      0.42        40
       105.0       1.00      0.83      0.91        12
       106.0       0.76      0.75      0.76       113
       107.0       0.86      0.71      0.78       161
       108.0       0.00      0.00      0.00        24
       109.0       0.52      0.87      0.65        52
       110.0       0.92      0.73      0.81        15
       111.0       0.56      0.56      0.56       124
       112.0       0.60      0.44      0.51        41
       113.0       0.87      0.87      0.87       430
       114.0       0.57      0.78      0.66        65
       115.0       0.89      0.52      0.65        31
       116.0       0.94      0.66      0.78       173
       117.0       0.87      0.84      0.85        31
       118.0       0.90      0.80      0.85       117
       119.0       0.73      0.79      0.76       136
       120.0       0.59      0.85      0.70        62
       121.0       0.90      0.80      0.85       224
       122.0       0.65      0.74      0.69        35
       123.0       0.89      0.68      0.77        37
       124.0       0.68      0.84      0.75        31
       125.0       0.67      0.53      0.59        15
       126.0       0.61      0.81      0.69        21
       127.0       0.74      0.86      0.80        73

    accuracy                           0.67     12226
   macro avg       0.67      0.54      0.57     12226
weighted avg       0.70      0.67      0.66     12226


===confusion_matrix===

[[260   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...   8   3   0]
 [  0   0   0 ...   0  17   3]
 [  0   0   0 ...   0   3  63]]

===multilabel confusion matrix===

[[[11794    74]
  [   98   260]]

 [[12212     2]
  [    6     6]]

 [[12206     1]
  [   10     9]]

 [[12144     3]
  [   51    28]]

 [[12160    11]
  [   42    13]]

 [[12163     5]
  [   52     6]]

 [[12161    20]
  [   30    15]]

 [[12166    13]
  [   23    24]]

 [[12216     0]
  [   10     0]]

 [[12202     3]
  [   12     9]]

 [[12211     0]
  [   14     1]]

 [[12175    15]
  [    9    27]]

 [[12213     1]
  [    9     3]]

 [[12201     0]
  [    9    16]]

 [[12207     0]
  [   15     4]]

 [[12200     4]
  [    9    13]]

 [[12192    11]
  [    7    16]]

 [[12081    27]
  [   16   102]]

 [[12204     4]
  [   12     6]]

 [[12211     3]
  [   12     0]]

 [[12098    38]
  [   49    41]]

 [[12213     0]
  [   11     2]]

 [[12201     0]
  [    9    16]]

 [[12210     3]
  [   13     0]]

 [[12201     3]
  [   17     5]]

 [[12171    17]
  [   18    20]]

 [[12207     2]
  [    0    17]]

 [[12173    18]
  [   22    13]]

 [[12209     5]
  [    8     4]]

 [[12181     9]
  [   13    23]]

 [[12175    19]
  [    7    25]]

 [[12183     5]
  [   12    26]]

 [[11392    87]
  [  146   601]]

 [[12144     7]
  [   13    62]]

 [[12160     7]
  [    5    54]]

 [[12162    17]
  [   16    31]]

 [[11357   368]
  [  124   377]]

 [[11838   147]
  [   70   171]]

 [[12192     1]
  [   10    23]]

 [[11768   114]
  [  110   234]]

 [[12020    14]
  [   48   144]]

 [[12194     0]
  [   17    15]]

 [[11791    51]
  [  116   268]]

 [[12098    11]
  [   18    99]]

 [[11661   129]
  [  125   311]]

 [[12177     0]
  [    6    43]]

 [[11771    54]
  [   64   337]]

 [[12208     1]
  [   11     6]]

 [[12174    10]
  [   16    26]]

 [[12131    18]
  [    9    68]]

 [[12015    39]
  [   25   147]]

 [[12206     0]
  [   12     8]]

 [[11592   135]
  [  180   319]]

 [[12110    16]
  [   38    62]]

 [[12214     1]
  [   10     1]]

 [[12112    10]
  [   16    88]]

 [[12205     3]
  [   13     5]]

 [[12214     2]
  [    8     2]]

 [[12188     3]
  [    7    28]]

 [[11845   151]
  [   87   143]]

 [[12150    18]
  [    8    50]]

 [[12197     0]
  [   29     0]]

 [[12167    10]
  [   25    24]]

 [[12163    13]
  [   39    11]]

 [[12182    10]
  [   11    23]]

 [[11999    72]
  [   32   123]]

 [[12211     1]
  [   14     0]]

 [[11652   260]
  [   90   224]]

 [[12144    20]
  [   57     5]]

 [[11818   101]
  [  134   173]]

 [[12078    80]
  [   34    34]]

 [[12143    17]
  [   39    27]]

 [[12202    10]
  [   12     2]]

 [[12188    14]
  [   10    14]]

 [[12207     0]
  [   19     0]]

 [[12131    35]
  [   48    12]]

 [[11662   358]
  [   41   165]]

 [[12142     7]
  [   53    24]]

 [[12158     9]
  [   28    31]]

 [[12071    16]
  [   68    71]]

 [[12169    15]
  [   11    31]]

 [[11976    76]
  [  106    68]]

 [[12180     3]
  [   30    13]]

 [[12199     1]
  [   23     3]]

 [[12085    35]
  [   54    52]]

 [[12210     1]
  [    5    10]]

 [[11785   200]
  [   52   189]]

 [[11587   330]
  [   35   274]]

 [[12131    36]
  [   25    34]]

 [[12214     2]
  [    6     4]]

 [[12031     7]
  [  116    72]]

 [[12172     8]
  [   25    21]]

 [[12179     6]
  [   40     1]]

 [[12192     2]
  [   18    14]]

 [[11833   105]
  [  106   182]]

 [[12181    14]
  [   27     4]]

 [[12141    10]
  [   25    50]]

 [[12192     7]
  [   19     8]]

 [[12187     1]
  [   22    16]]

 [[12199     3]
  [    2    22]]

 [[12201     0]
  [   24     1]]

 [[12150    11]
  [   29    36]]

 [[12201     3]
  [    4    18]]

 [[12162     0]
  [   22    42]]

 [[12185     1]
  [   29    11]]

 [[12214     0]
  [    2    10]]

 [[12086    27]
  [   28    85]]

 [[12047    18]
  [   46   115]]

 [[12201     1]
  [   24     0]]

 [[12132    42]
  [    7    45]]

 [[12210     1]
  [    4    11]]

 [[12047    55]
  [   54    70]]

 [[12173    12]
  [   23    18]]

 [[11738    58]
  [   55   375]]

 [[12122    39]
  [   14    51]]

 [[12193     2]
  [   15    16]]

 [[12046     7]
  [   59   114]]

 [[12191     4]
  [    5    26]]

 [[12098    11]
  [   23    94]]

 [[12050    40]
  [   28   108]]

 [[12127    37]
  [    9    53]]

 [[11983    19]
  [   45   179]]

 [[12177    14]
  [    9    26]]

 [[12186     3]
  [   12    25]]

 [[12183    12]
  [    5    26]]

 [[12207     4]
  [    7     8]]

 [[12194    11]
  [    4    17]]

 [[12131    22]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.6664
MCC	0.6596
log_loss	1.5375
f1 score weighted	0.6615
f1 score macro	0.5677
f1 score micro	0.6664
roc_auc ovr	0.9729
roc_auc ovo	0.9681
precision	0.6976
recall	0.6664

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6899484746871677	0.6832207007792546	1.4340212664333114	0.6804906902440819	0.5830336176763045	0.6899484746871677	0.9755356095251616	0.9717535188165601	0.7010369750720127	0.6899484746871677
1	0.6827512881328208	0.6763076952749371	1.458559683793978	0.6788508135513457	0.5836866506518489	0.6827512881328208	0.9748549772047795	0.9712106881288834	0.7012848811302591	0.6827512881328208
2	0.6703746114837232	0.6634337470783197	1.563639365844303	0.6615458298297101	0.5721214543601825	0.6703746114837232	0.971531501389102	0.967224549327395	0.6934492164094027	0.6703746114837232
3	0.6813348601341404	0.6744198410687441	1.435970449959572	0.6751930770160884	0.5751868963311639	0.6813348601341404	0.9752803902103172	0.9719666724107173	0.7018738906902889	0.6813348601341404
4	0.6663667593652871	0.6595825550874241	1.5374569224095527	0.6614680465240064	0.5676829350365957	0.6663667593652871	0.9728503744223183	0.96814874375212	0.6975951588437121	0.6663667593652871
mean	0.6781551987606278	0.671392907857736	1.4859295376881434	0.6715096914330465	0.5763423108112191	0.6781551987606278	0.9740105705503357	0.9700608344871352	0.6990480244291352	0.6781551987606278
std	0.0086002381687724	0.008672333230294116	0.054098755515838357	0.008345428850366593	0.006210447904370718	0.0086002381687724	0.0015583996537043398	0.0019758626629287654	0.003174978498768776	0.0086002381687724

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 27290.8530 secs

