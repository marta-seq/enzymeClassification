/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_hot_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa478534430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa4785342e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa4785347c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa4785345e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.24      0.87      0.38       402
         1.0       1.00      0.05      0.10        19
         2.0       0.31      0.44      0.36        82
         3.0       0.00      0.00      0.00        16
         4.0       0.67      0.03      0.06        62
         5.0       0.94      0.37      0.53       277
         6.0       0.49      0.58      0.53        36
         7.0       0.00      0.00      0.00        26
         8.0       0.51      0.32      0.39        72
         9.0       0.69      0.37      0.48        30
        10.0       0.52      0.54      0.53       156
        11.0       0.29      0.35      0.32       168
        12.0       0.64      0.30      0.41        83
        13.0       0.00      0.00      0.00        53
        14.0       0.60      0.10      0.17        31
        15.0       0.63      0.37      0.46        52
        16.0       0.13      0.71      0.22        94
        17.0       0.85      0.73      0.78       885
        18.0       0.94      0.31      0.47        48
        19.0       0.56      0.60      0.58       781
        20.0       0.92      0.50      0.65       591
        21.0       0.92      0.56      0.69       385
        22.0       0.90      0.58      0.70       128
        23.0       0.82      0.72      0.76      1888
        24.0       0.58      0.58      0.58       169
        25.0       0.70      0.51      0.59      1296
        26.0       0.37      0.62      0.46       381
        27.0       0.00      0.00      0.00        14
        28.0       0.45      0.58      0.51       769
        29.0       0.36      0.35      0.36       372
        30.0       0.92      0.54      0.68       631
        31.0       0.00      0.00      0.00        11
        32.0       0.53      0.26      0.35       316
        33.0       0.31      0.67      0.42       405
        34.0       0.44      0.29      0.35        96
        35.0       0.00      0.00      0.00        26
        36.0       0.56      0.42      0.48        65
        37.0       1.00      0.43      0.60        21
        38.0       0.32      0.66      0.43       121
        39.0       0.62      0.61      0.61       114
        40.0       0.68      0.62      0.65       207
        41.0       0.92      0.45      0.61       194
        42.0       0.58      0.38      0.46        47
        43.0       0.98      0.65      0.78       431
        44.0       0.85      0.43      0.57        67
        45.0       0.91      0.69      0.78       488
        46.0       0.48      0.52      0.50        62
        47.0       0.90      0.78      0.84       264
        48.0       0.50      0.57      0.53        49
        49.0       0.51      0.67      0.58        30
        50.0       0.44      0.80      0.57        15
        51.0       0.68      0.71      0.70        21
        52.0       0.80      0.45      0.58        73

    accuracy                           0.58     13120
   macro avg       0.57      0.45      0.46     13120
weighted avg       0.68      0.58      0.60     13120


===confusion_matrix===

[[349   0   1 ...   0   0   0]
 [  2   1   0 ...   0   0   0]
 [  0   0  36 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   1  15   3]
 [  0   0   0 ...   1   5  33]]

===multilabel confusion matrix===

[[[11629  1089]
  [   53   349]]

 [[13101     0]
  [   18     1]]

 [[12956    82]
  [   46    36]]

 [[13101     3]
  [   16     0]]

 [[13057     1]
  [   60     2]]

 [[12837     6]
  [  174   103]]

 [[13062    22]
  [   15    21]]

 [[13093     1]
  [   26     0]]

 [[13026    22]
  [   49    23]]

 [[13085     5]
  [   19    11]]

 [[12885    79]
  [   72    84]]

 [[12806   146]
  [  109    59]]

 [[13023    14]
  [   58    25]]

 [[13064     3]
  [   53     0]]

 [[13087     2]
  [   28     3]]

 [[13057    11]
  [   33    19]]

 [[12569   457]
  [   27    67]]

 [[12120   115]
  [  243   642]]

 [[13071     1]
  [   33    15]]

 [[11974   365]
  [  312   469]]

 [[12503    26]
  [  293   298]]

 [[12716    19]
  [  170   215]]

 [[12984     8]
  [   54    74]]

 [[10925   307]
  [  530  1358]]

 [[12881    70]
  [   71    98]]

 [[11549   275]
  [  640   656]]

 [[12338   401]
  [  146   235]]

 [[13105     1]
  [   14     0]]

 [[11815   536]
  [  323   446]]

 [[12514   234]
  [  240   132]]

 [[12461    28]
  [  292   339]]

 [[13109     0]
  [   11     0]]

 [[12733    71]
  [  235    81]]

 [[12096   619]
  [  133   272]]

 [[12988    36]
  [   68    28]]

 [[13094     0]
  [   26     0]]

 [[13034    21]
  [   38    27]]

 [[13099     0]
  [   12     9]]

 [[12831   168]
  [   41    80]]

 [[12963    43]
  [   45    69]]

 [[12853    60]
  [   78   129]]

 [[12918     8]
  [  106    88]]

 [[13060    13]
  [   29    18]]

 [[12683     6]
  [  150   281]]

 [[13048     5]
  [   38    29]]

 [[12598    34]
  [  153   335]]

 [[13023    35]
  [   30    32]]

 [[12833    23]
  [   58   206]]

 [[13043    28]
  [   21    28]]

 [[13071    19]
  [   10    20]]

 [[13090    15]
  [    3    12]]

 [[13092     7]
  [    6    15]]

 [[13039     8]
  [   40    33]]]

===scores report===
metrics	scores
Accuracy	0.5771
MCC	0.5574
log_loss	1.6886
f1 score weighted	0.5970
f1 score macro	0.4557
f1 score micro	0.5771
roc_auc ovr	0.9432
roc_auc ovo	0.9409
precision	0.6805
recall	0.5771

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa478534430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa4785342e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa4785347c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa4785345e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.48      0.84      0.61       402
         1.0       0.89      0.42      0.57        19
         2.0       0.41      0.63      0.50        81
         3.0       1.00      0.06      0.12        16
         4.0       0.67      0.29      0.40        62
         5.0       0.55      0.67      0.61       277
         6.0       0.88      0.78      0.82        36
         7.0       0.67      0.15      0.25        26
         8.0       0.87      0.37      0.52        73
         9.0       0.69      0.38      0.49        29
        10.0       0.54      0.72      0.62       156
        11.0       0.38      0.56      0.45       168
        12.0       0.36      0.51      0.42        83
        13.0       0.17      0.04      0.06        53
        14.0       0.67      0.56      0.61        32
        15.0       0.70      0.37      0.48        52
        16.0       0.66      0.62      0.64        95
        17.0       0.88      0.80      0.84       884
        18.0       0.76      0.67      0.71        48
        19.0       0.67      0.74      0.70       782
        20.0       0.86      0.62      0.72       591
        21.0       0.89      0.69      0.77       385
        22.0       0.82      0.73      0.77       128
        23.0       0.81      0.79      0.80      1888
        24.0       0.85      0.59      0.70       169
        25.0       0.63      0.70      0.66      1295
        26.0       0.46      0.71      0.56       381
        27.0       0.80      0.57      0.67        14
        28.0       0.70      0.53      0.60       769
        29.0       0.62      0.50      0.56       371
        30.0       0.87      0.72      0.78       631
        31.0       1.00      0.36      0.53        11
        32.0       0.47      0.59      0.52       316
        33.0       0.50      0.66      0.57       405
        34.0       0.71      0.55      0.62        96
        35.0       0.00      0.00      0.00        26
        36.0       0.88      0.45      0.59        65
        37.0       1.00      0.73      0.84        22
        38.0       0.53      0.66      0.59       121
        39.0       0.89      0.74      0.81       113
        40.0       0.67      0.78      0.72       208
        41.0       0.91      0.57      0.70       193
        42.0       0.68      0.33      0.44        46
        43.0       0.84      0.93      0.88       431
        44.0       0.90      0.56      0.69        66
        45.0       0.82      0.76      0.79       489
        46.0       0.87      0.65      0.74        62
        47.0       0.82      0.84      0.83       264
        48.0       0.88      0.47      0.61        49
        49.0       0.85      0.55      0.67        31
        50.0       0.67      0.75      0.71        16
        51.0       0.86      0.90      0.88        21
        52.0       0.80      0.86      0.83        73

    accuracy                           0.69     13120
   macro avg       0.71      0.59      0.61     13120
weighted avg       0.72      0.69      0.70     13120


===confusion_matrix===

[[339   0   3 ...   0   0   0]
 [  0   8   1 ...   0   0   0]
 [  2   0  51 ...   0   0   0]
 ...
 [  0   0   0 ...  12   2   1]
 [  0   0   0 ...   0  19   1]
 [  1   0   0 ...   1   0  63]]

===multilabel confusion matrix===

[[[12344   374]
  [   63   339]]

 [[13100     1]
  [   11     8]]

 [[12966    73]
  [   30    51]]

 [[13104     0]
  [   15     1]]

 [[13049     9]
  [   44    18]]

 [[12693   150]
  [   91   186]]

 [[13080     4]
  [    8    28]]

 [[13092     2]
  [   22     4]]

 [[13043     4]
  [   46    27]]

 [[13086     5]
  [   18    11]]

 [[12867    97]
  [   43   113]]

 [[12796   156]
  [   74    94]]

 [[12963    74]
  [   41    42]]

 [[13057    10]
  [   51     2]]

 [[13079     9]
  [   14    18]]

 [[13060     8]
  [   33    19]]

 [[12994    31]
  [   36    59]]

 [[12138    98]
  [  173   711]]

 [[13062    10]
  [   16    32]]

 [[12056   282]
  [  203   579]]

 [[12471    58]
  [  227   364]]

 [[12702    33]
  [  121   264]]

 [[12972    20]
  [   35    93]]

 [[10875   357]
  [  390  1498]]

 [[12934    17]
  [   69   100]]

 [[11287   538]
  [  391   904]]

 [[12426   313]
  [  112   269]]

 [[13104     2]
  [    6     8]]

 [[12178   173]
  [  363   406]]

 [[12637   112]
  [  185   186]]

 [[12420    69]
  [  179   452]]

 [[13109     0]
  [    7     4]]

 [[12589   215]
  [  128   188]]

 [[12447   268]
  [  138   267]]

 [[13002    22]
  [   43    53]]

 [[13093     1]
  [   26     0]]

 [[13051     4]
  [   36    29]]

 [[13098     0]
  [    6    16]]

 [[12928    71]
  [   41    80]]

 [[12997    10]
  [   29    84]]

 [[12833    79]
  [   45   163]]

 [[12916    11]
  [   83   110]]

 [[13067     7]
  [   31    15]]

 [[12614    75]
  [   31   400]]

 [[13050     4]
  [   29    37]]

 [[12552    79]
  [  117   372]]

 [[13052     6]
  [   22    40]]

 [[12807    49]
  [   43   221]]

 [[13068     3]
  [   26    23]]

 [[13086     3]
  [   14    17]]

 [[13098     6]
  [    4    12]]

 [[13096     3]
  [    2    19]]

 [[13031    16]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.6935
MCC	0.6759
log_loss	1.2696
f1 score weighted	0.6952
f1 score macro	0.6150
f1 score micro	0.6935
roc_auc ovr	0.9651
roc_auc ovo	0.9653
precision	0.7200
recall	0.6935

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa478534430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa4785342e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa4785347c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa4785345e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.65      0.80      0.72       401
         1.0       1.00      0.55      0.71        20
         2.0       0.62      0.43      0.51        82
         3.0       0.20      0.06      0.10        16
         4.0       0.30      0.21      0.25        62
         5.0       0.62      0.61      0.61       277
         6.0       0.79      0.83      0.81        36
         7.0       0.44      0.28      0.34        25
         8.0       0.82      0.51      0.63        73
         9.0       0.56      0.62      0.59        29
        10.0       0.74      0.75      0.74       156
        11.0       0.55      0.49      0.52       168
        12.0       0.55      0.55      0.55        83
        13.0       0.19      0.06      0.09        54
        14.0       0.55      0.35      0.43        31
        15.0       0.65      0.53      0.58        53
        16.0       0.68      0.57      0.62        95
        17.0       0.83      0.84      0.83       884
        18.0       0.84      0.77      0.80        47
        19.0       0.75      0.75      0.75       782
        20.0       0.86      0.77      0.81       592
        21.0       0.75      0.73      0.74       385
        22.0       0.81      0.83      0.82       128
        23.0       0.82      0.83      0.82      1887
        24.0       0.74      0.69      0.71       168
        25.0       0.63      0.73      0.67      1295
        26.0       0.67      0.63      0.65       381
        27.0       0.73      0.57      0.64        14
        28.0       0.58      0.68      0.63       768
        29.0       0.54      0.61      0.57       372
        30.0       0.86      0.78      0.82       631
        31.0       0.00      0.00      0.00        10
        32.0       0.59      0.60      0.60       316
        33.0       0.67      0.69      0.68       405
        34.0       0.77      0.65      0.70        96
        35.0       0.45      0.19      0.27        26
        36.0       0.90      0.56      0.69        66
        37.0       0.75      0.55      0.63        22
        38.0       0.88      0.68      0.77       121
        39.0       0.84      0.86      0.85       113
        40.0       0.85      0.71      0.77       208
        41.0       0.77      0.69      0.72       194
        42.0       0.71      0.54      0.62        46
        43.0       0.87      0.93      0.90       431
        44.0       0.90      0.80      0.85        66
        45.0       0.82      0.82      0.82       489
        46.0       0.88      0.69      0.77        62
        47.0       0.88      0.91      0.90       263
        48.0       0.81      0.60      0.69        50
        49.0       0.79      0.71      0.75        31
        50.0       0.88      0.94      0.91        16
        51.0       1.00      0.71      0.83        21
        52.0       0.71      0.85      0.77        73

    accuracy                           0.73     13120
   macro avg       0.70      0.62      0.65     13120
weighted avg       0.74      0.73      0.73     13120


===confusion_matrix===

[[321   0   0 ...   0   0   0]
 [  1  11   0 ...   0   0   0]
 [  0   0  35 ...   0   0   0]
 ...
 [  0   0   0 ...  15   0   0]
 [  0   0   0 ...   0  15   5]
 [  0   0   0 ...   1   0  62]]

===multilabel confusion matrix===

[[[12549   170]
  [   80   321]]

 [[13100     0]
  [    9    11]]

 [[13017    21]
  [   47    35]]

 [[13100     4]
  [   15     1]]

 [[13027    31]
  [   49    13]]

 [[12739   104]
  [  109   168]]

 [[13076     8]
  [    6    30]]

 [[13086     9]
  [   18     7]]

 [[13039     8]
  [   36    37]]

 [[13077    14]
  [   11    18]]

 [[12922    42]
  [   39   117]]

 [[12886    66]
  [   86    82]]

 [[13000    37]
  [   37    46]]

 [[13053    13]
  [   51     3]]

 [[13080     9]
  [   20    11]]

 [[13052    15]
  [   25    28]]

 [[13000    25]
  [   41    54]]

 [[12084   152]
  [  145   739]]

 [[13066     7]
  [   11    36]]

 [[12142   196]
  [  199   583]]

 [[12453    75]
  [  137   455]]

 [[12642    93]
  [  105   280]]

 [[12967    25]
  [   22   106]]

 [[10884   349]
  [  328  1559]]

 [[12911    41]
  [   52   116]]

 [[11266   559]
  [  355   940]]

 [[12622   117]
  [  142   239]]

 [[13103     3]
  [    6     8]]

 [[11978   374]
  [  244   524]]

 [[12556   192]
  [  145   227]]

 [[12412    77]
  [  141   490]]

 [[13107     3]
  [   10     0]]

 [[12670   134]
  [  125   191]]

 [[12580   135]
  [  126   279]]

 [[13005    19]
  [   34    62]]

 [[13088     6]
  [   21     5]]

 [[13050     4]
  [   29    37]]

 [[13094     4]
  [   10    12]]

 [[12988    11]
  [   39    82]]

 [[12989    18]
  [   16    97]]

 [[12886    26]
  [   61   147]]

 [[12886    40]
  [   61   133]]

 [[13064    10]
  [   21    25]]

 [[12627    62]
  [   29   402]]

 [[13048     6]
  [   13    53]]

 [[12541    90]
  [   86   403]]

 [[13052     6]
  [   19    43]]

 [[12825    32]
  [   24   239]]

 [[13063     7]
  [   20    30]]

 [[13083     6]
  [    9    22]]

 [[13102     2]
  [    1    15]]

 [[13099     0]
  [    6    15]]

 [[13022    25]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.7346
MCC	0.7184
log_loss	1.1517
f1 score weighted	0.7330
f1 score macro	0.6520
f1 score micro	0.7346
roc_auc ovr	0.9689
roc_auc ovo	0.9671
precision	0.7371
recall	0.7346

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa478534430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa4785342e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa4785347c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa4785345e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.71      0.74       401
         1.0       0.86      0.30      0.44        20
         2.0       0.59      0.66      0.62        82
         3.0       0.67      0.27      0.38        15
         4.0       0.37      0.27      0.31        62
         5.0       0.71      0.59      0.64       278
         6.0       0.69      0.67      0.68        36
         7.0       0.70      0.28      0.40        25
         8.0       0.73      0.71      0.72        73
         9.0       0.73      0.55      0.63        29
        10.0       0.69      0.76      0.73       156
        11.0       0.67      0.58      0.62       168
        12.0       0.84      0.51      0.63        83
        13.0       0.33      0.06      0.10        54
        14.0       0.47      0.45      0.46        31
        15.0       0.49      0.42      0.45        53
        16.0       0.72      0.56      0.63        95
        17.0       0.83      0.82      0.83       884
        18.0       0.87      0.83      0.85        47
        19.0       0.77      0.72      0.75       781
        20.0       0.79      0.74      0.77       592
        21.0       0.75      0.80      0.78       385
        22.0       0.80      0.87      0.83       129
        23.0       0.81      0.83      0.82      1887
        24.0       0.81      0.71      0.76       168
        25.0       0.65      0.71      0.68      1295
        26.0       0.65      0.59      0.62       381
        27.0       1.00      0.46      0.63        13
        28.0       0.63      0.71      0.67       769
        29.0       0.54      0.60      0.56       372
        30.0       0.76      0.78      0.77       631
        31.0       1.00      0.18      0.31        11
        32.0       0.46      0.63      0.54       316
        33.0       0.64      0.74      0.69       405
        34.0       0.64      0.68      0.66        95
        35.0       0.23      0.12      0.16        25
        36.0       0.64      0.53      0.58        66
        37.0       0.83      0.68      0.75        22
        38.0       0.74      0.60      0.67       121
        39.0       0.78      0.88      0.82       113
        40.0       0.69      0.73      0.71       208
        41.0       0.85      0.63      0.72       194
        42.0       0.79      0.48      0.59        46
        43.0       0.81      0.92      0.86       431
        44.0       0.90      0.68      0.78        66
        45.0       0.89      0.79      0.84       489
        46.0       0.83      0.73      0.78        62
        47.0       0.86      0.90      0.88       263
        48.0       0.79      0.52      0.63        50
        49.0       0.74      0.81      0.77        31
        50.0       0.81      0.81      0.81        16
        51.0       0.89      0.77      0.83        22
        52.0       0.81      0.86      0.83        73

    accuracy                           0.73     13120
   macro avg       0.72      0.63      0.65     13120
weighted avg       0.74      0.73      0.73     13120


===confusion_matrix===

[[286   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0  54 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   1  17   1]
 [  0   0   0 ...   0   2  63]]

===multilabel confusion matrix===

[[[12630    89]
  [  115   286]]

 [[13099     1]
  [   14     6]]

 [[13001    37]
  [   28    54]]

 [[13103     2]
  [   11     4]]

 [[13029    29]
  [   45    17]]

 [[12777    65]
  [  115   163]]

 [[13073    11]
  [   12    24]]

 [[13092     3]
  [   18     7]]

 [[13028    19]
  [   21    52]]

 [[13085     6]
  [   13    16]]

 [[12911    53]
  [   37   119]]

 [[12904    48]
  [   71    97]]

 [[13029     8]
  [   41    42]]

 [[13060     6]
  [   51     3]]

 [[13073    16]
  [   17    14]]

 [[13044    23]
  [   31    22]]

 [[13004    21]
  [   42    53]]

 [[12090   146]
  [  155   729]]

 [[13067     6]
  [    8    39]]

 [[12173   166]
  [  218   563]]

 [[12413   115]
  [  154   438]]

 [[12635   100]
  [   77   308]]

 [[12963    28]
  [   17   112]]

 [[10861   372]
  [  329  1558]]

 [[12924    28]
  [   48   120]]

 [[11334   491]
  [  370   925]]

 [[12617   122]
  [  157   224]]

 [[13107     0]
  [    7     6]]

 [[12031   320]
  [  226   543]]

 [[12556   192]
  [  150   222]]

 [[12337   152]
  [  141   490]]

 [[13109     0]
  [    9     2]]

 [[12573   231]
  [  116   200]]

 [[12550   165]
  [  107   298]]

 [[12988    37]
  [   30    65]]

 [[13085    10]
  [   22     3]]

 [[13034    20]
  [   31    35]]

 [[13095     3]
  [    7    15]]

 [[12974    25]
  [   48    73]]

 [[12979    28]
  [   14    99]]

 [[12844    68]
  [   56   152]]

 [[12904    22]
  [   72   122]]

 [[13068     6]
  [   24    22]]

 [[12594    95]
  [   33   398]]

 [[13049     5]
  [   21    45]]

 [[12582    49]
  [  101   388]]

 [[13049     9]
  [   17    45]]

 [[12819    38]
  [   27   236]]

 [[13063     7]
  [   24    26]]

 [[13080     9]
  [    6    25]]

 [[13101     3]
  [    3    13]]

 [[13096     2]
  [    5    17]]

 [[13032    15]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.7316
MCC	0.7152
log_loss	1.1558
f1 score weighted	0.7298
f1 score macro	0.6543
f1 score micro	0.7316
roc_auc ovr	0.9702
roc_auc ovo	0.9671
precision	0.7356
recall	0.7316

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa478534430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa4785342e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa4785347c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa4785345e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.67      0.80      0.72       402
         1.0       0.79      0.58      0.67        19
         2.0       0.59      0.54      0.56        82
         3.0       0.00      0.00      0.00        16
         4.0       0.56      0.37      0.45        62
         5.0       0.65      0.58      0.61       278
         6.0       0.89      0.69      0.78        36
         7.0       0.55      0.23      0.32        26
         8.0       0.87      0.47      0.61        73
         9.0       0.58      0.63      0.60        30
        10.0       0.89      0.64      0.75       156
        11.0       0.65      0.47      0.54       169
        12.0       0.58      0.54      0.56        83
        13.0       0.27      0.15      0.19        53
        14.0       0.68      0.42      0.52        31
        15.0       0.82      0.44      0.57        52
        16.0       0.73      0.49      0.59        95
        17.0       0.91      0.78      0.84       885
        18.0       0.77      0.75      0.76        48
        19.0       0.79      0.59      0.68       781
        20.0       0.79      0.69      0.74       592
        21.0       0.61      0.79      0.69       384
        22.0       0.78      0.80      0.79       128
        23.0       0.68      0.84      0.75      1887
        24.0       0.70      0.68      0.69       168
        25.0       0.69      0.60      0.64      1295
        26.0       0.56      0.64      0.60       381
        27.0       0.88      0.50      0.64        14
        28.0       0.68      0.59      0.64       769
        29.0       0.45      0.58      0.51       372
        30.0       0.78      0.76      0.77       630
        31.0       0.75      0.27      0.40        11
        32.0       0.48      0.63      0.54       316
        33.0       0.54      0.70      0.61       405
        34.0       0.59      0.67      0.63        95
        35.0       0.00      0.00      0.00        25
        36.0       0.67      0.37      0.48        65
        37.0       0.72      0.82      0.77        22
        38.0       0.60      0.68      0.64       121
        39.0       0.93      0.72      0.81       113
        40.0       0.83      0.76      0.79       208
        41.0       0.76      0.68      0.72       194
        42.0       0.95      0.38      0.55        47
        43.0       0.94      0.88      0.91       431
        44.0       0.85      0.85      0.85        66
        45.0       0.69      0.85      0.76       488
        46.0       0.87      0.71      0.78        63
        47.0       0.69      0.84      0.76       263
        48.0       0.70      0.53      0.60        49
        49.0       0.83      0.67      0.74        30
        50.0       0.93      0.87      0.90        15
        51.0       0.89      0.73      0.80        22
        52.0       0.75      0.86      0.80        73

    accuracy                           0.70     13119
   macro avg       0.69      0.61      0.63     13119
weighted avg       0.71      0.70      0.70     13119


===confusion_matrix===

[[320   0   3 ...   0   0   0]
 [  0  11   0 ...   0   0   0]
 [  1   0  44 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  16   5]
 [  0   0   0 ...   0   2  63]]

===multilabel confusion matrix===

[[[12556   161]
  [   82   320]]

 [[13097     3]
  [    8    11]]

 [[13006    31]
  [   38    44]]

 [[13098     5]
  [   16     0]]

 [[13039    18]
  [   39    23]]

 [[12755    86]
  [  118   160]]

 [[13080     3]
  [   11    25]]

 [[13088     5]
  [   20     6]]

 [[13041     5]
  [   39    34]]

 [[13075    14]
  [   11    19]]

 [[12951    12]
  [   56   100]]

 [[12908    42]
  [   90    79]]

 [[13003    33]
  [   38    45]]

 [[13044    22]
  [   45     8]]

 [[13082     6]
  [   18    13]]

 [[13062     5]
  [   29    23]]

 [[13007    17]
  [   48    47]]

 [[12169    65]
  [  198   687]]

 [[13060    11]
  [   12    36]]

 [[12218   120]
  [  318   463]]

 [[12421   106]
  [  183   409]]

 [[12544   191]
  [   80   304]]

 [[12963    28]
  [   26   102]]

 [[10481   751]
  [  302  1585]]

 [[12903    48]
  [   54   114]]

 [[11469   355]
  [  517   778]]

 [[12550   188]
  [  137   244]]

 [[13104     1]
  [    7     7]]

 [[12140   210]
  [  313   456]]

 [[12484   263]
  [  156   216]]

 [[12350   139]
  [  150   480]]

 [[13107     1]
  [    8     3]]

 [[12587   216]
  [  118   198]]

 [[12475   239]
  [  120   285]]

 [[12979    45]
  [   31    64]]

 [[13090     4]
  [   25     0]]

 [[13042    12]
  [   41    24]]

 [[13090     7]
  [    4    18]]

 [[12944    54]
  [   39    82]]

 [[13000     6]
  [   32    81]]

 [[12879    32]
  [   50   158]]

 [[12884    41]
  [   63   131]]

 [[13071     1]
  [   29    18]]

 [[12663    25]
  [   53   378]]

 [[13043    10]
  [   10    56]]

 [[12442   189]
  [   75   413]]

 [[13049     7]
  [   18    45]]

 [[12759    97]
  [   43   220]]

 [[13059    11]
  [   23    26]]

 [[13085     4]
  [   10    20]]

 [[13103     1]
  [    2    13]]

 [[13095     2]
  [    6    16]]

 [[13025    21]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.6975
MCC	0.6793
log_loss	1.2750
f1 score weighted	0.6956
f1 score macro	0.6341
f1 score micro	0.6975
roc_auc ovr	0.9642
roc_auc ovo	0.9641
precision	0.7094
recall	0.6975

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.5771341463414634	0.5574269594828546	1.6886073396331134	0.5969867649889028	0.45572023506409876	0.5771341463414634	0.9432154008021106	0.9409080464199224	0.6804592226210833	0.5771341463414634
1	0.6935213414634146	0.6758518537986936	1.269572456576045	0.6951870872357463	0.6149860854104906	0.6935213414634146	0.965089047611055	0.9652588304603442	0.7199534928142113	0.6935213414634146
2	0.7346036585365854	0.718363904652215	1.1517209726002586	0.7329703006045182	0.6519612165785864	0.7346036585365854	0.9689196622619628	0.9671007485322876	0.7371469160224885	0.7346036585365854
3	0.7315548780487805	0.7152361871946904	1.1558468447878663	0.7297581012298406	0.6543188573042407	0.7315548780487805	0.9702328155078275	0.9671026650112253	0.7355628054155237	0.7315548780487805
4	0.6974616967756688	0.6793487449976124	1.2749714986781222	0.6956419188526491	0.6341332332528151	0.6974616967756688	0.9641566221719388	0.9640914579349938	0.709384548506667	0.6974616967756688
mean	0.6868551442331825	0.6692455300252133	1.3081438224550812	0.6901088345823314	0.6022239255220463	0.6868551442331825	0.9623227096709789	0.9608923496717546	0.7165013970759947	0.6868551442331825
std	0.05739968874840888	0.05861205756087031	0.19748575573812366	0.04926924625397485	0.07460842848057812	0.05739968874840888	0.009820332689965731	0.010057684203089398	0.020742129005669227	0.05739968874840888

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 29380.1691 secs

