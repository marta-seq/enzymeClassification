/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_3level_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f84d151b760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f84d151b8b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f84d151bc40>]/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_3level_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f12a8350460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f12a8350310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f12a83507f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f12a8350610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.84      0.80       358
         1.0       0.64      0.58      0.61        12
         2.0       0.69      0.47      0.56        19
         3.0       0.62      0.62      0.62        80
         4.0       0.42      0.41      0.41        54
         5.0       0.30      0.19      0.23        58
         6.0       0.44      0.40      0.42        45
         7.0       0.61      0.56      0.59        48
         8.0       0.40      0.18      0.25        11
         9.0       0.75      0.43      0.55        21
        10.0       0.67      0.27      0.38        15
        11.0       0.73      0.67      0.70        36
        12.0       0.70      0.58      0.64        12
        13.0       0.91      0.80      0.85        25
        14.0       0.56      0.26      0.36        19
        15.0       0.94      0.77      0.85        22
        16.0       0.67      0.78      0.72        23
        17.0       0.91      0.81      0.86       119
        18.0       0.63      0.67      0.65        18
        19.0       0.50      0.08      0.14        12
        20.0       0.57      0.52      0.55        90
        21.0       0.56      0.42      0.48        12
        22.0       0.82      0.92      0.87        25
        23.0       0.50      0.08      0.14        12
        24.0       0.45      0.23      0.30        22
        25.0       0.75      0.63      0.69        38
        26.0       1.00      0.94      0.97        17
        27.0       0.62      0.23      0.33        35
        28.0       0.50      0.18      0.27        11
        29.0       0.64      0.69      0.67        36
        30.0       0.76      0.91      0.83        32
        31.0       0.81      0.76      0.78        38
        32.0       0.80      0.85      0.83       747
        33.0       0.82      0.84      0.83        74
        34.0       0.96      0.93      0.95        59
        35.0       0.80      0.85      0.83        48
        36.0       0.73      0.76      0.75       502
        37.0       0.75      0.77      0.76       241
        38.0       0.86      0.58      0.69        33
        39.0       0.67      0.79      0.73       344
        40.0       0.77      0.69      0.73       191
        41.0       0.88      0.66      0.75        32
        42.0       0.79      0.80      0.80       384
        43.0       0.81      0.81      0.81       118
        44.0       0.77      0.78      0.78       436
        45.0       0.89      0.83      0.86        48
        46.0       0.82      0.86      0.84       402
        47.0       0.80      0.47      0.59        17
        48.0       0.78      0.69      0.73        42
        49.0       0.91      0.95      0.93        78
        50.0       0.92      0.90      0.91       172
        51.0       0.90      0.45      0.60        20
        52.0       0.73      0.76      0.75       499
        53.0       0.85      0.83      0.84       100
        54.0       0.67      0.18      0.29        11
        55.0       0.87      0.77      0.81       103
        56.0       0.50      0.39      0.44        18
        57.0       0.33      0.10      0.15        10
        58.0       0.94      0.97      0.96        34
        59.0       0.60      0.66      0.63       231
        60.0       0.91      0.72      0.81        58
        61.0       0.13      0.07      0.09        30
        62.0       0.74      0.58      0.65        48
        63.0       0.43      0.36      0.39        50
        64.0       0.88      0.62      0.72        34
        65.0       0.73      0.77      0.75       155
        66.0       0.33      0.14      0.20        14
        67.0       0.76      0.68      0.72       314
        68.0       0.34      0.25      0.29        63
        69.0       0.55      0.80      0.65       308
        70.0       0.62      0.54      0.58        68
        71.0       0.62      0.67      0.64        66
        72.0       0.67      0.29      0.40        14
        73.0       0.70      0.56      0.62        25
        74.0       0.20      0.06      0.09        18
        75.0       0.51      0.38      0.44        60
        76.0       0.81      0.77      0.79       205
        77.0       0.54      0.43      0.48        77
        78.0       0.86      0.81      0.83        59
        79.0       0.71      0.58      0.64       139
        80.0       0.85      0.79      0.81        42
        81.0       0.51      0.62      0.56       175
        82.0       0.65      0.51      0.57        43
        83.0       0.67      0.62      0.64        26
        84.0       0.68      0.67      0.67       106
        85.0       0.78      0.50      0.61        14
        86.0       0.76      0.81      0.78       242
        87.0       0.77      0.81      0.79       309
        88.0       0.87      0.78      0.82        58
        89.0       0.33      0.18      0.24        11
        90.0       0.63      0.65      0.64       187
        91.0       0.49      0.39      0.43        46
        92.0       0.49      0.42      0.45        40
        93.0       0.88      0.69      0.77        32
        94.0       0.63      0.79      0.70       289
        95.0       0.11      0.03      0.05        31
        96.0       0.78      0.88      0.83        74
        97.0       0.64      0.59      0.62        27
        98.0       0.87      0.73      0.79        37
        99.0       0.92      0.96      0.94        24
       100.0       0.30      0.24      0.27        25
       101.0       0.67      0.65      0.66        65
       102.0       0.83      0.86      0.84        22
       103.0       0.90      0.81      0.85        64
       104.0       0.63      0.42      0.51        40
       105.0       0.85      0.92      0.88        12
       106.0       0.85      0.75      0.79       114
       107.0       0.80      0.88      0.83       161
       108.0       0.81      0.54      0.65        24
       109.0       0.84      0.69      0.76        52
       110.0       1.00      0.80      0.89        15
       111.0       0.69      0.76      0.73       123
       112.0       0.78      0.50      0.61        42
       113.0       0.81      0.95      0.88       430
       114.0       0.93      0.77      0.84        65
       115.0       0.88      0.68      0.76        31
       116.0       0.80      0.80      0.80       173
       117.0       0.97      0.97      0.97        31
       118.0       0.88      0.85      0.87       117
       119.0       0.87      0.90      0.88       136
       120.0       0.83      0.73      0.78        62
       121.0       0.92      0.87      0.89       224
       122.0       0.87      0.74      0.80        35
       123.0       0.91      0.84      0.87        37
       124.0       0.76      0.84      0.80        31
       125.0       1.00      0.87      0.93        15
       126.0       0.94      0.71      0.81        21
       127.0       0.79      0.84      0.81        73

    accuracy                           0.74     12227
   macro avg       0.71      0.63      0.66     12227
weighted avg       0.74      0.74      0.74     12227


===confusion_matrix===

[[302   0   0 ...   0   0   0]
 [  0   7   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  15   5]
 [  0   0   0 ...   0   1  61]]

===multilabel confusion matrix===

[[[11770    99]
  [   56   302]]

 [[12211     4]
  [    5     7]]

 [[12204     4]
  [   10     9]]

 [[12117    30]
  [   30    50]]

 [[12142    31]
  [   32    22]]

 [[12143    26]
  [   47    11]]

 [[12159    23]
  [   27    18]]

 [[12162    17]
  [   21    27]]

 [[12213     3]
  [    9     2]]

 [[12203     3]
  [   12     9]]

 [[12210     2]
  [   11     4]]

 [[12182     9]
  [   12    24]]

 [[12212     3]
  [    5     7]]

 [[12200     2]
  [    5    20]]

 [[12204     4]
  [   14     5]]

 [[12204     1]
  [    5    17]]

 [[12195     9]
  [    5    18]]

 [[12099     9]
  [   23    96]]

 [[12202     7]
  [    6    12]]

 [[12214     1]
  [   11     1]]

 [[12102    35]
  [   43    47]]

 [[12211     4]
  [    7     5]]

 [[12197     5]
  [    2    23]]

 [[12214     1]
  [   11     1]]

 [[12199     6]
  [   17     5]]

 [[12181     8]
  [   14    24]]

 [[12210     0]
  [    1    16]]

 [[12187     5]
  [   27     8]]

 [[12214     2]
  [    9     2]]

 [[12177    14]
  [   11    25]]

 [[12186     9]
  [    3    29]]

 [[12182     7]
  [    9    29]]

 [[11324   156]
  [  109   638]]

 [[12139    14]
  [   12    62]]

 [[12166     2]
  [    4    55]]

 [[12169    10]
  [    7    41]]

 [[11587   138]
  [  121   381]]

 [[11925    61]
  [   55   186]]

 [[12191     3]
  [   14    19]]

 [[11750   133]
  [   72   272]]

 [[11996    40]
  [   59   132]]

 [[12192     3]
  [   11    21]]

 [[11762    81]
  [   77   307]]

 [[12086    23]
  [   22    96]]

 [[11692    99]
  [   96   340]]

 [[12174     5]
  [    8    40]]

 [[11748    77]
  [   56   346]]

 [[12208     2]
  [    9     8]]

 [[12177     8]
  [   13    29]]

 [[12142     7]
  [    4    74]]

 [[12041    14]
  [   17   155]]

 [[12206     1]
  [   11     9]]

 [[11588   140]
  [  119   380]]

 [[12112    15]
  [   17    83]]

 [[12215     1]
  [    9     2]]

 [[12112    12]
  [   24    79]]

 [[12202     7]
  [   11     7]]

 [[12215     2]
  [    9     1]]

 [[12191     2]
  [    1    33]]

 [[11893   103]
  [   79   152]]

 [[12165     4]
  [   16    42]]

 [[12184    13]
  [   28     2]]

 [[12169    10]
  [   20    28]]

 [[12153    24]
  [   32    18]]

 [[12190     3]
  [   13    21]]

 [[12027    45]
  [   35   120]]

 [[12209     4]
  [   12     2]]

 [[11844    69]
  [   99   215]]

 [[12133    31]
  [   47    16]]

 [[11716   203]
  [   62   246]]

 [[12136    23]
  [   31    37]]

 [[12134    27]
  [   22    44]]

 [[12211     2]
  [   10     4]]

 [[12196     6]
  [   11    14]]

 [[12205     4]
  [   17     1]]

 [[12145    22]
  [   37    23]]

 [[11984    38]
  [   47   158]]

 [[12122    28]
  [   44    33]]

 [[12160     8]
  [   11    48]]

 [[12055    33]
  [   58    81]]

 [[12179     6]
  [    9    33]]

 [[11949   103]
  [   67   108]]

 [[12172    12]
  [   21    22]]

 [[12193     8]
  [   10    16]]

 [[12087    34]
  [   35    71]]

 [[12211     2]
  [    7     7]]

 [[11925    60]
  [   47   195]]

 [[11842    76]
  [   58   251]]

 [[12162     7]
  [   13    45]]

 [[12212     4]
  [    9     2]]

 [[11967    73]
  [   65   122]]

 [[12162    19]
  [   28    18]]

 [[12169    18]
  [   23    17]]

 [[12192     3]
  [   10    22]]

 [[11803   135]
  [   61   228]]

 [[12188     8]
  [   30     1]]

 [[12135    18]
  [    9    65]]

 [[12191     9]
  [   11    16]]

 [[12186     4]
  [   10    27]]

 [[12201     2]
  [    1    23]]

 [[12188    14]
  [   19     6]]

 [[12141    21]
  [   23    42]]

 [[12201     4]
  [    3    19]]

 [[12157     6]
  [   12    52]]

 [[12177    10]
  [   23    17]]

 [[12213     2]
  [    1    11]]

 [[12098    15]
  [   29    85]]

 [[12030    36]
  [   20   141]]

 [[12200     3]
  [   11    13]]

 [[12168     7]
  [   16    36]]

 [[12212     0]
  [    3    12]]

 [[12062    42]
  [   29    94]]

 [[12179     6]
  [   21    21]]

 [[11704    93]
  [   23   407]]

 [[12158     4]
  [   15    50]]

 [[12193     3]
  [   10    21]]

 [[12020    34]
  [   35   138]]

 [[12195     1]
  [    1    30]]

 [[12096    14]
  [   17   100]]

 [[12072    19]
  [   14   122]]

 [[12156     9]
  [   17    45]]

 [[11985    18]
  [   29   195]]

 [[12188     4]
  [    9    26]]

 [[12187     3]
  [    6    31]]

 [[12188     8]
  [    5    26]]

 [[12212     0]
  [    2    13]]

 [[12205     1]
  [    6    15]]

 [[12138    16]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.7438
MCC	0.7381
log_loss	1.2674
f1 score weighted	0.7382
f1 score macro	0.6566
f1 score micro	0.7438
roc_auc ovr	0.9814
roc_auc ovo	0.9789
precision	0.7418
recall	0.7438

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f12a8350460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f12a8350310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f12a83507f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f12a8350610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.89      0.81       357
         1.0       0.33      0.25      0.29        12
         2.0       0.81      0.68      0.74        19
         3.0       0.80      0.55      0.65        80
         4.0       0.44      0.31      0.37        54
         5.0       0.34      0.19      0.24        58
         6.0       0.39      0.16      0.23        44
         7.0       0.67      0.60      0.64        48
         8.0       0.60      0.27      0.37        11
         9.0       0.89      0.81      0.85        21
        10.0       0.60      0.20      0.30        15
        11.0       0.76      0.61      0.68        36
        12.0       0.33      0.17      0.22        12
        13.0       0.83      0.60      0.70        25
        14.0       0.75      0.30      0.43        20
        15.0       0.90      0.78      0.84        23
        16.0       0.81      0.74      0.77        23
        17.0       0.91      0.80      0.85       119
        18.0       0.67      0.59      0.62        17
        19.0       0.33      0.08      0.12        13
        20.0       0.68      0.50      0.58        90
        21.0       1.00      0.42      0.59        12
        22.0       0.72      0.72      0.72        25
        23.0       0.33      0.08      0.13        12
        24.0       0.50      0.27      0.35        22
        25.0       0.68      0.57      0.62        37
        26.0       0.90      1.00      0.95        18
        27.0       0.45      0.29      0.35        35
        28.0       1.00      0.25      0.40        12
        29.0       0.84      0.84      0.84        37
        30.0       0.76      0.81      0.79        32
        31.0       0.76      0.67      0.71        39
        32.0       0.79      0.86      0.82       746
        33.0       0.85      0.95      0.90        74
        34.0       0.89      0.88      0.89        58
        35.0       0.82      0.77      0.80        48
        36.0       0.71      0.77      0.74       502
        37.0       0.68      0.78      0.73       241
        38.0       0.65      0.73      0.69        33
        39.0       0.71      0.76      0.73       344
        40.0       0.84      0.76      0.80       191
        41.0       0.91      0.65      0.75        31
        42.0       0.76      0.77      0.77       384
        43.0       0.80      0.89      0.84       118
        44.0       0.69      0.81      0.75       436
        45.0       0.84      0.79      0.82        48
        46.0       0.81      0.85      0.83       402
        47.0       0.64      0.53      0.58        17
        48.0       0.71      0.64      0.67        42
        49.0       0.87      0.94      0.90        77
        50.0       0.92      0.84      0.88       172
        51.0       0.94      0.80      0.86        20
        52.0       0.67      0.76      0.71       499
        53.0       0.75      0.71      0.73        99
        54.0       0.67      0.36      0.47        11
        55.0       0.75      0.75      0.75       103
        56.0       0.73      0.44      0.55        18
        57.0       0.56      0.45      0.50        11
        58.0       0.89      0.91      0.90        34
        59.0       0.64      0.69      0.67       231
        60.0       0.83      0.67      0.74        58
        61.0       0.50      0.10      0.17        30
        62.0       0.66      0.40      0.49        48
        63.0       0.57      0.33      0.42        49
        64.0       0.85      0.68      0.75        34
        65.0       0.83      0.78      0.81       154
        66.0       0.71      0.36      0.48        14
        67.0       0.65      0.65      0.65       314
        68.0       0.23      0.17      0.20        63
        69.0       0.54      0.74      0.63       308
        70.0       0.59      0.46      0.52        69
        71.0       0.52      0.48      0.50        66
        72.0       0.00      0.00      0.00        14
        73.0       0.62      0.60      0.61        25
        74.0       0.67      0.22      0.33        18
        75.0       0.56      0.51      0.53        59
        76.0       0.73      0.70      0.71       205
        77.0       0.53      0.38      0.44        77
        78.0       0.76      0.64      0.70        59
        79.0       0.64      0.62      0.63       139
        80.0       0.92      0.85      0.89        41
        81.0       0.52      0.62      0.56       175
        82.0       0.64      0.58      0.61        43
        83.0       0.57      0.46      0.51        26
        84.0       0.66      0.74      0.70       105
        85.0       0.89      0.57      0.70        14
        86.0       0.70      0.71      0.70       242
        87.0       0.78      0.78      0.78       309
        88.0       0.85      0.67      0.75        58
        89.0       0.75      0.27      0.40        11
        90.0       0.66      0.70      0.68       187
        91.0       0.55      0.48      0.51        46
        92.0       0.60      0.38      0.46        40
        93.0       0.80      0.61      0.69        33
        94.0       0.68      0.74      0.71       289
        95.0       0.62      0.41      0.49        32
        96.0       0.88      0.70      0.78        74
        97.0       0.60      0.44      0.51        27
        98.0       0.64      0.68      0.66        37
        99.0       1.00      0.83      0.91        24
       100.0       0.24      0.15      0.19        26
       101.0       0.66      0.48      0.55        65
       102.0       0.78      0.64      0.70        22
       103.0       0.81      0.78      0.79        64
       104.0       0.52      0.33      0.40        40
       105.0       1.00      0.85      0.92        13
       106.0       0.80      0.88      0.84       113
       107.0       0.82      0.85      0.83       162
       108.0       0.68      0.54      0.60        24
       109.0       0.84      0.83      0.83        52
       110.0       0.76      0.87      0.81        15
       111.0       0.79      0.75      0.77       123
       112.0       0.66      0.51      0.58        41
       113.0       0.85      0.94      0.89       430
       114.0       0.93      0.83      0.88        65
       115.0       0.79      0.61      0.69        31
       116.0       0.80      0.81      0.81       173
       117.0       0.83      0.80      0.81        30
       118.0       0.90      0.86      0.88       118
       119.0       0.82      0.87      0.84       136
       120.0       0.85      0.75      0.80        61
       121.0       0.84      0.90      0.87       225
       122.0       0.89      0.91      0.90        35
       123.0       0.91      0.84      0.88        38
       124.0       0.87      0.84      0.85        31
       125.0       0.93      0.81      0.87        16
       126.0       0.64      0.86      0.73        21
       127.0       0.84      0.88      0.86        73

    accuracy                           0.73     12227
   macro avg       0.71      0.62      0.65     12227
weighted avg       0.73      0.73      0.73     12227


===confusion_matrix===

[[316   0   0 ...   0   0   0]
 [  1   3   0 ...   0   0   0]
 [  0   0  13 ...   0   0   0]
 ...
 [  0   0   0 ...  13   1   0]
 [  0   0   0 ...   0  18   1]
 [  0   0   0 ...   0   6  64]]

===multilabel confusion matrix===

[[[11761   109]
  [   41   316]]

 [[12209     6]
  [    9     3]]

 [[12205     3]
  [    6    13]]

 [[12136    11]
  [   36    44]]

 [[12151    22]
  [   37    17]]

 [[12148    21]
  [   47    11]]

 [[12172    11]
  [   37     7]]

 [[12165    14]
  [   19    29]]

 [[12214     2]
  [    8     3]]

 [[12204     2]
  [    4    17]]

 [[12210     2]
  [   12     3]]

 [[12184     7]
  [   14    22]]

 [[12211     4]
  [   10     2]]

 [[12199     3]
  [   10    15]]

 [[12205     2]
  [   14     6]]

 [[12202     2]
  [    5    18]]

 [[12200     4]
  [    6    17]]

 [[12099     9]
  [   24    95]]

 [[12205     5]
  [    7    10]]

 [[12212     2]
  [   12     1]]

 [[12116    21]
  [   45    45]]

 [[12215     0]
  [    7     5]]

 [[12195     7]
  [    7    18]]

 [[12213     2]
  [   11     1]]

 [[12199     6]
  [   16     6]]

 [[12180    10]
  [   16    21]]

 [[12207     2]
  [    0    18]]

 [[12180    12]
  [   25    10]]

 [[12215     0]
  [    9     3]]

 [[12184     6]
  [    6    31]]

 [[12187     8]
  [    6    26]]

 [[12180     8]
  [   13    26]]

 [[11311   170]
  [  106   640]]

 [[12141    12]
  [    4    70]]

 [[12163     6]
  [    7    51]]

 [[12171     8]
  [   11    37]]

 [[11565   160]
  [  115   387]]

 [[11898    88]
  [   53   188]]

 [[12181    13]
  [    9    24]]

 [[11773   110]
  [   81   263]]

 [[12008    28]
  [   45   146]]

 [[12194     2]
  [   11    20]]

 [[11750    93]
  [   87   297]]

 [[12083    26]
  [   13   105]]

 [[11636   155]
  [   84   352]]

 [[12172     7]
  [   10    38]]

 [[11745    80]
  [   59   343]]

 [[12205     5]
  [    8     9]]

 [[12174    11]
  [   15    27]]

 [[12139    11]
  [    5    72]]

 [[12042    13]
  [   27   145]]

 [[12206     1]
  [    4    16]]

 [[11544   184]
  [  121   378]]

 [[12105    23]
  [   29    70]]

 [[12214     2]
  [    7     4]]

 [[12098    26]
  [   26    77]]

 [[12206     3]
  [   10     8]]

 [[12212     4]
  [    6     5]]

 [[12189     4]
  [    3    31]]

 [[11908    88]
  [   72   159]]

 [[12161     8]
  [   19    39]]

 [[12194     3]
  [   27     3]]

 [[12169    10]
  [   29    19]]

 [[12166    12]
  [   33    16]]

 [[12189     4]
  [   11    23]]

 [[12049    24]
  [   34   120]]

 [[12211     2]
  [    9     5]]

 [[11803   110]
  [  109   205]]

 [[12127    37]
  [   52    11]]

 [[11728   191]
  [   81   227]]

 [[12136    22]
  [   37    32]]

 [[12132    29]
  [   34    32]]

 [[12209     4]
  [   14     0]]

 [[12193     9]
  [   10    15]]

 [[12207     2]
  [   14     4]]

 [[12144    24]
  [   29    30]]

 [[11969    53]
  [   62   143]]

 [[12124    26]
  [   48    29]]

 [[12156    12]
  [   21    38]]

 [[12039    49]
  [   53    86]]

 [[12183     3]
  [    6    35]]

 [[11950   102]
  [   66   109]]

 [[12170    14]
  [   18    25]]

 [[12192     9]
  [   14    12]]

 [[12081    41]
  [   27    78]]

 [[12212     1]
  [    6     8]]

 [[11910    75]
  [   71   171]]

 [[11852    66]
  [   69   240]]

 [[12162     7]
  [   19    39]]

 [[12215     1]
  [    8     3]]

 [[11974    66]
  [   57   130]]

 [[12163    18]
  [   24    22]]

 [[12177    10]
  [   25    15]]

 [[12189     5]
  [   13    20]]

 [[11836   102]
  [   76   213]]

 [[12187     8]
  [   19    13]]

 [[12146     7]
  [   22    52]]

 [[12192     8]
  [   15    12]]

 [[12176    14]
  [   12    25]]

 [[12203     0]
  [    4    20]]

 [[12188    13]
  [   22     4]]

 [[12146    16]
  [   34    31]]

 [[12201     4]
  [    8    14]]

 [[12151    12]
  [   14    50]]

 [[12175    12]
  [   27    13]]

 [[12214     0]
  [    2    11]]

 [[12090    24]
  [   14    99]]

 [[12034    31]
  [   24   138]]

 [[12197     6]
  [   11    13]]

 [[12167     8]
  [    9    43]]

 [[12208     4]
  [    2    13]]

 [[12079    25]
  [   31    92]]

 [[12175    11]
  [   20    21]]

 [[11723    74]
  [   25   405]]

 [[12158     4]
  [   11    54]]

 [[12191     5]
  [   12    19]]

 [[12020    34]
  [   33   140]]

 [[12192     5]
  [    6    24]]

 [[12098    11]
  [   16   102]]

 [[12065    26]
  [   18   118]]

 [[12158     8]
  [   15    46]]

 [[11964    38]
  [   22   203]]

 [[12188     4]
  [    3    32]]

 [[12186     3]
  [    6    32]]

 [[12192     4]
  [    5    26]]

 [[12210     1]
  [    3    13]]

 [[12196    10]
  [    3    18]]

 [[12142    12]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.7343
MCC	0.7283
log_loss	1.3318
f1 score weighted	0.7275
f1 score macro	0.6520
f1 score micro	0.7343
roc_auc ovr	0.9788
roc_auc ovo	0.9757
precision	0.7312
recall	0.7343

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f12a8350460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f12a8350310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f12a83507f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f12a8350610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.84      0.78       357
         1.0       0.67      0.31      0.42        13
         2.0       0.50      0.37      0.42        19
         3.0       0.43      0.53      0.47        79
         4.0       0.28      0.24      0.26        55
         5.0       0.41      0.20      0.27        59
         6.0       0.41      0.25      0.31        44
         7.0       0.74      0.77      0.76        48
         8.0       0.00      0.00      0.00        10
         9.0       0.60      0.43      0.50        21
        10.0       0.50      0.07      0.12        15
        11.0       0.78      0.69      0.74        36
        12.0       0.57      0.33      0.42        12
        13.0       0.77      0.68      0.72        25
        14.0       0.83      0.25      0.38        20
        15.0       0.74      0.77      0.76        22
        16.0       0.82      0.78      0.80        23
        17.0       0.87      0.88      0.87       118
        18.0       0.86      0.67      0.75        18
        19.0       0.38      0.23      0.29        13
        20.0       0.62      0.47      0.54        89
        21.0       0.60      0.25      0.35        12
        22.0       0.83      0.83      0.83        24
        23.0       0.67      0.17      0.27        12
        24.0       0.71      0.22      0.33        23
        25.0       0.62      0.49      0.55        37
        26.0       1.00      0.94      0.97        17
        27.0       0.43      0.25      0.32        36
        28.0       0.40      0.17      0.24        12
        29.0       0.58      0.68      0.63        37
        30.0       0.60      0.56      0.58        32
        31.0       0.77      0.69      0.73        39
        32.0       0.79      0.86      0.82       746
        33.0       0.93      0.92      0.93        74
        34.0       0.89      0.81      0.85        58
        35.0       0.83      0.73      0.78        48
        36.0       0.65      0.75      0.70       502
        37.0       0.72      0.70      0.71       240
        38.0       0.70      0.58      0.63        33
        39.0       0.70      0.78      0.74       344
        40.0       0.82      0.74      0.78       191
        41.0       0.75      0.48      0.59        31
        42.0       0.77      0.77      0.77       384
        43.0       0.76      0.86      0.81       117
        44.0       0.75      0.72      0.73       436
        45.0       0.92      0.73      0.82        49
        46.0       0.83      0.85      0.84       402
        47.0       0.82      0.53      0.64        17
        48.0       0.66      0.60      0.62        42
        49.0       0.96      0.92      0.94        77
        50.0       0.89      0.93      0.91       172
        51.0       0.88      0.37      0.52        19
        52.0       0.65      0.74      0.69       499
        53.0       0.76      0.76      0.76        99
        54.0       0.83      0.45      0.59        11
        55.0       0.81      0.81      0.81       103
        56.0       0.67      0.44      0.53        18
        57.0       0.00      0.00      0.00        11
        58.0       0.89      0.94      0.92        35
        59.0       0.60      0.71      0.65       231
        60.0       0.86      0.77      0.81        57
        61.0       0.14      0.03      0.06        29
        62.0       0.61      0.48      0.53        48
        63.0       0.37      0.33      0.35        49
        64.0       0.91      0.62      0.74        34
        65.0       0.81      0.71      0.76       155
        66.0       0.29      0.14      0.19        14
        67.0       0.64      0.67      0.65       315
        68.0       0.34      0.21      0.26        63
        69.0       0.53      0.77      0.63       307
        70.0       0.55      0.48      0.51        69
        71.0       0.52      0.50      0.51        66
        72.0       1.00      0.13      0.24        15
        73.0       0.80      0.32      0.46        25
        74.0       0.33      0.11      0.17        18
        75.0       0.39      0.27      0.32        59
        76.0       0.76      0.72      0.74       206
        77.0       0.54      0.37      0.44        76
        78.0       0.86      0.75      0.80        59
        79.0       0.64      0.56      0.60       140
        80.0       0.82      0.86      0.84        42
        81.0       0.54      0.53      0.53       175
        82.0       0.51      0.47      0.49        43
        83.0       0.59      0.40      0.48        25
        84.0       0.56      0.63      0.59       105
        85.0       0.70      0.50      0.58        14
        86.0       0.71      0.75      0.73       242
        87.0       0.75      0.76      0.75       310
        88.0       0.93      0.63      0.75        59
        89.0       0.60      0.27      0.37        11
        90.0       0.48      0.62      0.54       187
        91.0       0.49      0.43      0.46        46
        92.0       0.25      0.12      0.17        40
        93.0       0.71      0.61      0.66        33
        94.0       0.59      0.72      0.65       289
        95.0       0.30      0.22      0.25        32
        96.0       0.90      0.80      0.85        75
        97.0       0.52      0.54      0.53        28
        98.0       0.85      0.59      0.70        37
        99.0       0.88      0.91      0.89        23
       100.0       0.08      0.04      0.05        25
       101.0       0.66      0.47      0.55        66
       102.0       0.89      0.76      0.82        21
       103.0       0.88      0.80      0.84        65
       104.0       0.43      0.33      0.37        40
       105.0       0.75      0.75      0.75        12
       106.0       0.83      0.81      0.82       113
       107.0       0.79      0.80      0.80       162
       108.0       0.62      0.33      0.43        24
       109.0       0.95      0.79      0.87        53
       110.0       0.90      0.64      0.75        14
       111.0       0.69      0.67      0.68       123
       112.0       0.66      0.51      0.58        41
       113.0       0.82      0.96      0.89       429
       114.0       0.84      0.71      0.77        65
       115.0       0.85      0.71      0.77        31
       116.0       0.83      0.78      0.81       173
       117.0       0.96      0.83      0.89        30
       118.0       0.93      0.85      0.88       117
       119.0       0.73      0.85      0.79       136
       120.0       0.82      0.67      0.74        61
       121.0       0.85      0.92      0.89       225
       122.0       0.84      0.74      0.79        35
       123.0       0.83      0.63      0.72        38
       124.0       0.72      0.70      0.71        30
       125.0       0.76      0.81      0.79        16
       126.0       0.77      0.77      0.77        22
       127.0       0.72      0.89      0.80        73

    accuracy                           0.71     12226
   macro avg       0.68      0.58      0.61     12226
weighted avg       0.71      0.71      0.71     12226


===confusion_matrix===

[[299   0   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0   7 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   3]
 [  0   0   0 ...   0  17   4]
 [  0   0   0 ...   0   4  65]]

===multilabel confusion matrix===

[[[11754   115]
  [   58   299]]

 [[12211     2]
  [    9     4]]

 [[12200     7]
  [   12     7]]

 [[12091    56]
  [   37    42]]

 [[12138    33]
  [   42    13]]

 [[12150    17]
  [   47    12]]

 [[12166    16]
  [   33    11]]

 [[12165    13]
  [   11    37]]

 [[12216     0]
  [   10     0]]

 [[12199     6]
  [   12     9]]

 [[12210     1]
  [   14     1]]

 [[12183     7]
  [   11    25]]

 [[12211     3]
  [    8     4]]

 [[12196     5]
  [    8    17]]

 [[12205     1]
  [   15     5]]

 [[12198     6]
  [    5    17]]

 [[12199     4]
  [    5    18]]

 [[12092    16]
  [   14   104]]

 [[12206     2]
  [    6    12]]

 [[12208     5]
  [   10     3]]

 [[12111    26]
  [   47    42]]

 [[12212     2]
  [    9     3]]

 [[12198     4]
  [    4    20]]

 [[12213     1]
  [   10     2]]

 [[12201     2]
  [   18     5]]

 [[12178    11]
  [   19    18]]

 [[12209     0]
  [    1    16]]

 [[12178    12]
  [   27     9]]

 [[12211     3]
  [   10     2]]

 [[12171    18]
  [   12    25]]

 [[12182    12]
  [   14    18]]

 [[12179     8]
  [   12    27]]

 [[11310   170]
  [  108   638]]

 [[12147     5]
  [    6    68]]

 [[12162     6]
  [   11    47]]

 [[12171     7]
  [   13    35]]

 [[11522   202]
  [  125   377]]

 [[11921    65]
  [   73   167]]

 [[12185     8]
  [   14    19]]

 [[11769   113]
  [   77   267]]

 [[12004    31]
  [   50   141]]

 [[12190     5]
  [   16    15]]

 [[11755    87]
  [   90   294]]

 [[12077    32]
  [   16   101]]

 [[11685   105]
  [  124   312]]

 [[12174     3]
  [   13    36]]

 [[11752    72]
  [   61   341]]

 [[12207     2]
  [    8     9]]

 [[12171    13]
  [   17    25]]

 [[12146     3]
  [    6    71]]

 [[12034    20]
  [   12   160]]

 [[12206     1]
  [   12     7]]

 [[11529   198]
  [  128   371]]

 [[12103    24]
  [   24    75]]

 [[12214     1]
  [    6     5]]

 [[12104    19]
  [   20    83]]

 [[12204     4]
  [   10     8]]

 [[12213     2]
  [   11     0]]

 [[12187     4]
  [    2    33]]

 [[11884   111]
  [   66   165]]

 [[12162     7]
  [   13    44]]

 [[12191     6]
  [   28     1]]

 [[12163    15]
  [   25    23]]

 [[12150    27]
  [   33    16]]

 [[12190     2]
  [   13    21]]

 [[12045    26]
  [   45   110]]

 [[12207     5]
  [   12     2]]

 [[11794   117]
  [  105   210]]

 [[12138    25]
  [   50    13]]

 [[11707   212]
  [   71   236]]

 [[12130    27]
  [   36    33]]

 [[12130    30]
  [   33    33]]

 [[12211     0]
  [   13     2]]

 [[12199     2]
  [   17     8]]

 [[12204     4]
  [   16     2]]

 [[12142    25]
  [   43    16]]

 [[11974    46]
  [   58   148]]

 [[12126    24]
  [   48    28]]

 [[12160     7]
  [   15    44]]

 [[12042    44]
  [   61    79]]

 [[12176     8]
  [    6    36]]

 [[11972    79]
  [   83    92]]

 [[12164    19]
  [   23    20]]

 [[12194     7]
  [   15    10]]

 [[12069    52]
  [   39    66]]

 [[12209     3]
  [    7     7]]

 [[11910    74]
  [   61   181]]

 [[11838    78]
  [   75   235]]

 [[12164     3]
  [   22    37]]

 [[12213     2]
  [    8     3]]

 [[11913   126]
  [   71   116]]

 [[12159    21]
  [   26    20]]

 [[12171    15]
  [   35     5]]

 [[12185     8]
  [   13    20]]

 [[11794   143]
  [   80   209]]

 [[12178    16]
  [   25     7]]

 [[12144     7]
  [   15    60]]

 [[12184    14]
  [   13    15]]

 [[12185     4]
  [   15    22]]

 [[12200     3]
  [    2    21]]

 [[12190    11]
  [   24     1]]

 [[12144    16]
  [   35    31]]

 [[12203     2]
  [    5    16]]

 [[12154     7]
  [   13    52]]

 [[12169    17]
  [   27    13]]

 [[12211     3]
  [    3     9]]

 [[12095    18]
  [   22    91]]

 [[12030    34]
  [   32   130]]

 [[12197     5]
  [   16     8]]

 [[12171     2]
  [   11    42]]

 [[12211     1]
  [    5     9]]

 [[12066    37]
  [   40    83]]

 [[12174    11]
  [   20    21]]

 [[11709    88]
  [   16   413]]

 [[12152     9]
  [   19    46]]

 [[12191     4]
  [    9    22]]

 [[12026    27]
  [   38   135]]

 [[12195     1]
  [    5    25]]

 [[12101     8]
  [   18    99]]

 [[12048    42]
  [   20   116]]

 [[12156     9]
  [   20    41]]

 [[11964    37]
  [   17   208]]

 [[12186     5]
  [    9    26]]

 [[12183     5]
  [   14    24]]

 [[12188     8]
  [    9    21]]

 [[12206     4]
  [    3    13]]

 [[12199     5]
  [    5    17]]

 [[12128    25]
  [    8    65]]]

===scores report===
metrics	scores
Accuracy	0.7136
MCC	0.7072
log_loss	1.3845
f1 score weighted	0.7062
f1 score macro	0.6116
f1 score micro	0.7136
roc_auc ovr	0.9768
roc_auc ovo	0.9731
precision	0.7112
recall	0.7136

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f12a8350460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f12a8350310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f12a83507f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f12a8350610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.88      0.79       358
         1.0       0.44      0.33      0.38        12
         2.0       0.73      0.44      0.55        18
         3.0       0.54      0.63      0.58        79
         4.0       0.41      0.35      0.38        55
         5.0       0.26      0.16      0.19        58
         6.0       0.47      0.33      0.39        45
         7.0       0.76      0.55      0.64        47
         8.0       0.75      0.30      0.43        10
         9.0       1.00      0.57      0.73        21
        10.0       0.80      0.27      0.40        15
        11.0       0.81      0.83      0.82        36
        12.0       0.50      0.25      0.33        12
        13.0       0.79      0.44      0.56        25
        14.0       0.88      0.35      0.50        20
        15.0       0.95      0.95      0.95        22
        16.0       0.62      0.65      0.64        23
        17.0       0.87      0.80      0.83       118
        18.0       1.00      0.67      0.80        18
        19.0       0.40      0.15      0.22        13
        20.0       0.57      0.42      0.48        89
        21.0       0.62      0.38      0.48        13
        22.0       0.91      0.80      0.85        25
        23.0       0.75      0.25      0.38        12
        24.0       0.70      0.30      0.42        23
        25.0       0.80      0.65      0.72        37
        26.0       1.00      0.94      0.97        17
        27.0       0.47      0.25      0.33        36
        28.0       1.00      0.17      0.29        12
        29.0       0.65      0.61      0.63        36
        30.0       0.67      0.75      0.71        32
        31.0       0.90      0.90      0.90        39
        32.0       0.75      0.85      0.80       747
        33.0       0.90      0.88      0.89        74
        34.0       0.91      0.83      0.86        58
        35.0       0.84      0.79      0.81        47
        36.0       0.73      0.75      0.74       502
        37.0       0.69      0.77      0.73       240
        38.0       0.74      0.68      0.71        34
        39.0       0.68      0.75      0.71       344
        40.0       0.79      0.77      0.78       191
        41.0       0.79      0.59      0.68        32
        42.0       0.74      0.79      0.77       384
        43.0       0.76      0.83      0.80       117
        44.0       0.76      0.78      0.77       437
        45.0       0.92      0.73      0.82        49
        46.0       0.83      0.87      0.85       401
        47.0       0.81      0.76      0.79        17
        48.0       0.69      0.48      0.56        42
        49.0       0.91      0.88      0.89        77
        50.0       0.91      0.87      0.89       171
        51.0       0.85      0.55      0.67        20
        52.0       0.64      0.73      0.68       499
        53.0       0.76      0.69      0.72       100
        54.0       1.00      0.36      0.53        11
        55.0       0.86      0.86      0.86       104
        56.0       0.71      0.26      0.38        19
        57.0       0.40      0.18      0.25        11
        58.0       0.91      0.91      0.91        35
        59.0       0.59      0.71      0.64       230
        60.0       0.87      0.81      0.84        58
        61.0       0.33      0.10      0.16        29
        62.0       0.72      0.47      0.57        49
        63.0       0.28      0.22      0.24        50
        64.0       0.96      0.71      0.81        34
        65.0       0.74      0.82      0.78       155
        66.0       0.00      0.00      0.00        14
        67.0       0.67      0.76      0.71       314
        68.0       0.32      0.15      0.20        62
        69.0       0.50      0.70      0.59       307
        70.0       0.68      0.38      0.49        68
        71.0       0.50      0.44      0.47        66
        72.0       0.50      0.27      0.35        15
        73.0       0.82      0.36      0.50        25
        74.0       0.50      0.05      0.10        19
        75.0       0.49      0.34      0.40        59
        76.0       0.77      0.77      0.77       206
        77.0       0.64      0.53      0.58        77
        78.0       0.72      0.61      0.66        59
        79.0       0.69      0.56      0.62       139
        80.0       0.90      0.86      0.88        42
        81.0       0.56      0.56      0.56       174
        82.0       0.69      0.56      0.62        43
        83.0       0.38      0.36      0.37        25
        84.0       0.59      0.61      0.60       105
        85.0       0.60      0.60      0.60        15
        86.0       0.75      0.67      0.71       242
        87.0       0.78      0.83      0.80       309
        88.0       0.74      0.68      0.71        59
        89.0       0.44      0.36      0.40        11
        90.0       0.55      0.71      0.62       188
        91.0       0.32      0.23      0.27        47
        92.0       0.37      0.25      0.30        40
        93.0       0.71      0.52      0.60        33
        94.0       0.63      0.69      0.66       288
        95.0       0.50      0.16      0.24        32
        96.0       0.85      0.88      0.86        75
        97.0       0.80      0.44      0.57        27
        98.0       0.76      0.58      0.66        38
        99.0       1.00      0.96      0.98        23
       100.0       0.44      0.16      0.24        25
       101.0       0.77      0.62      0.69        66
       102.0       0.79      0.68      0.73        22
       103.0       0.84      0.73      0.78        64
       104.0       0.65      0.38      0.48        39
       105.0       1.00      0.75      0.86        12
       106.0       0.80      0.76      0.78       113
       107.0       0.78      0.86      0.82       161
       108.0       0.75      0.39      0.51        23
       109.0       0.87      0.85      0.86        53
       110.0       0.92      0.79      0.85        14
       111.0       0.81      0.68      0.74       123
       112.0       0.62      0.51      0.56        41
       113.0       0.82      0.94      0.88       429
       114.0       0.82      0.89      0.85        65
       115.0       0.73      0.61      0.67        31
       116.0       0.80      0.72      0.76       173
       117.0       0.90      0.90      0.90        31
       118.0       0.88      0.83      0.85       117
       119.0       0.82      0.84      0.83       135
       120.0       0.75      0.82      0.78        62
       121.0       0.86      0.88      0.87       224
       122.0       0.91      0.89      0.90        35
       123.0       0.96      0.70      0.81        37
       124.0       0.66      0.63      0.64        30
       125.0       0.69      0.69      0.69        16
       126.0       0.95      0.86      0.90        22
       127.0       0.85      0.88      0.86        73

    accuracy                           0.72     12226
   macro avg       0.72      0.60      0.64     12226
weighted avg       0.72      0.72      0.72     12226


===confusion_matrix===

[[315   0   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0   8 ...   0   0   0]
 ...
 [  0   0   0 ...  11   1   1]
 [  0   0   0 ...   0  19   1]
 [  0   0   0 ...   2   0  64]]

===multilabel confusion matrix===

[[[11744   124]
  [   43   315]]

 [[12209     5]
  [    8     4]]

 [[12205     3]
  [   10     8]]

 [[12104    43]
  [   29    50]]

 [[12144    27]
  [   36    19]]

 [[12142    26]
  [   49     9]]

 [[12164    17]
  [   30    15]]

 [[12171     8]
  [   21    26]]

 [[12215     1]
  [    7     3]]

 [[12205     0]
  [    9    12]]

 [[12210     1]
  [   11     4]]

 [[12183     7]
  [    6    30]]

 [[12211     3]
  [    9     3]]

 [[12198     3]
  [   14    11]]

 [[12205     1]
  [   13     7]]

 [[12203     1]
  [    1    21]]

 [[12194     9]
  [    8    15]]

 [[12094    14]
  [   24    94]]

 [[12208     0]
  [    6    12]]

 [[12210     3]
  [   11     2]]

 [[12109    28]
  [   52    37]]

 [[12210     3]
  [    8     5]]

 [[12199     2]
  [    5    20]]

 [[12213     1]
  [    9     3]]

 [[12200     3]
  [   16     7]]

 [[12183     6]
  [   13    24]]

 [[12209     0]
  [    1    16]]

 [[12180    10]
  [   27     9]]

 [[12214     0]
  [   10     2]]

 [[12178    12]
  [   14    22]]

 [[12182    12]
  [    8    24]]

 [[12183     4]
  [    4    35]]

 [[11267   212]
  [  111   636]]

 [[12145     7]
  [    9    65]]

 [[12163     5]
  [   10    48]]

 [[12172     7]
  [   10    37]]

 [[11582   142]
  [  127   375]]

 [[11904    82]
  [   55   185]]

 [[12184     8]
  [   11    23]]

 [[11762   120]
  [   86   258]]

 [[11995    40]
  [   44   147]]

 [[12189     5]
  [   13    19]]

 [[11738   104]
  [   81   303]]

 [[12079    30]
  [   20    97]]

 [[11682   107]
  [   95   342]]

 [[12174     3]
  [   13    36]]

 [[11754    71]
  [   54   347]]

 [[12206     3]
  [    4    13]]

 [[12175     9]
  [   22    20]]

 [[12142     7]
  [    9    68]]

 [[12040    15]
  [   23   148]]

 [[12204     2]
  [    9    11]]

 [[11520   207]
  [  134   365]]

 [[12104    22]
  [   31    69]]

 [[12215     0]
  [    7     4]]

 [[12107    15]
  [   15    89]]

 [[12205     2]
  [   14     5]]

 [[12212     3]
  [    9     2]]

 [[12188     3]
  [    3    32]]

 [[11883   113]
  [   67   163]]

 [[12161     7]
  [   11    47]]

 [[12191     6]
  [   26     3]]

 [[12168     9]
  [   26    23]]

 [[12147    29]
  [   39    11]]

 [[12191     1]
  [   10    24]]

 [[12026    45]
  [   28   127]]

 [[12211     1]
  [   14     0]]

 [[11792   120]
  [   75   239]]

 [[12145    19]
  [   53     9]]

 [[11706   213]
  [   91   216]]

 [[12146    12]
  [   42    26]]

 [[12131    29]
  [   37    29]]

 [[12207     4]
  [   11     4]]

 [[12199     2]
  [   16     9]]

 [[12206     1]
  [   18     1]]

 [[12146    21]
  [   39    20]]

 [[11972    48]
  [   47   159]]

 [[12126    23]
  [   36    41]]

 [[12153    14]
  [   23    36]]

 [[12052    35]
  [   61    78]]

 [[12180     4]
  [    6    36]]

 [[11975    77]
  [   77    97]]

 [[12172    11]
  [   19    24]]

 [[12186    15]
  [   16     9]]

 [[12077    44]
  [   41    64]]

 [[12205     6]
  [    6     9]]

 [[11929    55]
  [   79   163]]

 [[11847    70]
  [   54   255]]

 [[12153    14]
  [   19    40]]

 [[12210     5]
  [    7     4]]

 [[11928   110]
  [   54   134]]

 [[12156    23]
  [   36    11]]

 [[12169    17]
  [   30    10]]

 [[12186     7]
  [   16    17]]

 [[11819   119]
  [   88   200]]

 [[12189     5]
  [   27     5]]

 [[12139    12]
  [    9    66]]

 [[12196     3]
  [   15    12]]

 [[12181     7]
  [   16    22]]

 [[12203     0]
  [    1    22]]

 [[12196     5]
  [   21     4]]

 [[12148    12]
  [   25    41]]

 [[12200     4]
  [    7    15]]

 [[12153     9]
  [   17    47]]

 [[12179     8]
  [   24    15]]

 [[12214     0]
  [    3     9]]

 [[12092    21]
  [   27    86]]

 [[12026    39]
  [   22   139]]

 [[12200     3]
  [   14     9]]

 [[12166     7]
  [    8    45]]

 [[12211     1]
  [    3    11]]

 [[12083    20]
  [   39    84]]

 [[12172    13]
  [   20    21]]

 [[11710    87]
  [   27   402]]

 [[12148    13]
  [    7    58]]

 [[12188     7]
  [   12    19]]

 [[12021    32]
  [   48   125]]

 [[12192     3]
  [    3    28]]

 [[12096    13]
  [   20    97]]

 [[12066    25]
  [   22   113]]

 [[12147    17]
  [   11    51]]

 [[11970    32]
  [   26   198]]

 [[12188     3]
  [    4    31]]

 [[12188     1]
  [   11    26]]

 [[12186    10]
  [   11    19]]

 [[12205     5]
  [    5    11]]

 [[12203     1]
  [    3    19]]

 [[12142    11]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.7247
MCC	0.7185
log_loss	1.3267
f1 score weighted	0.7170
f1 score macro	0.6382
f1 score micro	0.7247
roc_auc ovr	0.9795
roc_auc ovo	0.9757
precision	0.7230
recall	0.7247

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f12a8350460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f12a8350310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f12a83507f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f12a8350610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.84      0.79       358
         1.0       0.73      0.67      0.70        12
         2.0       0.71      0.63      0.67        19
         3.0       0.64      0.63      0.64        79
         4.0       0.43      0.56      0.49        55
         5.0       0.33      0.31      0.32        58
         6.0       0.45      0.40      0.42        45
         7.0       0.57      0.55      0.56        47
         8.0       1.00      0.10      0.18        10
         9.0       0.64      0.67      0.65        21
        10.0       0.29      0.13      0.18        15
        11.0       0.90      0.78      0.84        36
        12.0       0.60      0.25      0.35        12
        13.0       0.74      0.68      0.71        25
        14.0       0.67      0.53      0.59        19
        15.0       0.85      0.77      0.81        22
        16.0       0.74      0.61      0.67        23
        17.0       0.89      0.86      0.88       118
        18.0       0.62      0.56      0.59        18
        19.0       0.50      0.08      0.14        12
        20.0       0.66      0.62      0.64        90
        21.0       0.67      0.46      0.55        13
        22.0       0.86      0.72      0.78        25
        23.0       0.00      0.00      0.00        13
        24.0       0.57      0.36      0.44        22
        25.0       0.75      0.55      0.64        38
        26.0       0.94      1.00      0.97        17
        27.0       0.59      0.37      0.46        35
        28.0       0.50      0.17      0.25        12
        29.0       0.83      0.67      0.74        36
        30.0       0.61      0.72      0.66        32
        31.0       0.77      0.87      0.81        38
        32.0       0.80      0.86      0.83       747
        33.0       0.87      0.89      0.88        75
        34.0       0.88      0.85      0.86        59
        35.0       0.81      0.72      0.76        47
        36.0       0.73      0.76      0.75       501
        37.0       0.75      0.72      0.73       241
        38.0       0.71      0.76      0.74        33
        39.0       0.70      0.76      0.73       344
        40.0       0.86      0.82      0.84       192
        41.0       0.88      0.66      0.75        32
        42.0       0.79      0.83      0.81       384
        43.0       0.76      0.86      0.81       117
        44.0       0.77      0.78      0.77       436
        45.0       0.92      0.90      0.91        49
        46.0       0.84      0.87      0.85       401
        47.0       0.83      0.29      0.43        17
        48.0       0.94      0.71      0.81        42
        49.0       0.93      0.90      0.91        77
        50.0       0.92      0.90      0.91       172
        51.0       0.83      0.50      0.62        20
        52.0       0.65      0.73      0.69       499
        53.0       0.71      0.70      0.71       100
        54.0       0.62      0.45      0.53        11
        55.0       0.81      0.85      0.83       104
        56.0       0.50      0.39      0.44        18
        57.0       0.33      0.20      0.25        10
        58.0       1.00      0.80      0.89        35
        59.0       0.68      0.70      0.69       230
        60.0       0.81      0.83      0.82        58
        61.0       0.28      0.17      0.21        29
        62.0       0.83      0.49      0.62        49
        63.0       0.39      0.46      0.42        50
        64.0       0.83      0.71      0.76        34
        65.0       0.84      0.79      0.81       155
        66.0       0.50      0.07      0.12        14
        67.0       0.74      0.71      0.73       314
        68.0       0.14      0.11      0.12        62
        69.0       0.51      0.77      0.61       307
        70.0       0.58      0.47      0.52        68
        71.0       0.65      0.55      0.60        66
        72.0       0.50      0.29      0.36        14
        73.0       0.72      0.54      0.62        24
        74.0       0.38      0.16      0.22        19
        75.0       0.46      0.37      0.41        60
        76.0       0.71      0.71      0.71       206
        77.0       0.64      0.49      0.56        77
        78.0       0.83      0.75      0.79        59
        79.0       0.76      0.63      0.69       139
        80.0       0.86      0.71      0.78        42
        81.0       0.54      0.53      0.54       174
        82.0       0.66      0.53      0.59        43
        83.0       0.67      0.54      0.60        26
        84.0       0.54      0.62      0.58       106
        85.0       0.62      0.53      0.57        15
        86.0       0.72      0.76      0.74       241
        87.0       0.80      0.79      0.80       309
        88.0       0.84      0.61      0.71        59
        89.0       0.50      0.20      0.29        10
        90.0       0.61      0.69      0.65       188
        91.0       0.57      0.59      0.58        46
        92.0       0.22      0.12      0.16        41
        93.0       0.76      0.59      0.67        32
        94.0       0.64      0.69      0.67       288
        95.0       0.47      0.29      0.36        31
        96.0       0.86      0.84      0.85        75
        97.0       0.55      0.41      0.47        27
        98.0       0.88      0.58      0.70        38
        99.0       0.95      0.88      0.91        24
       100.0       0.42      0.20      0.27        25
       101.0       0.64      0.69      0.67        65
       102.0       0.90      0.82      0.86        22
       103.0       0.86      0.78      0.82        64
       104.0       0.45      0.38      0.41        40
       105.0       0.85      0.92      0.88        12
       106.0       0.84      0.73      0.78       113
       107.0       0.76      0.84      0.80       161
       108.0       0.72      0.54      0.62        24
       109.0       0.79      0.81      0.80        52
       110.0       0.85      0.73      0.79        15
       111.0       0.70      0.57      0.63       124
       112.0       0.75      0.66      0.70        41
       113.0       0.86      0.96      0.91       430
       114.0       0.87      0.82      0.84        65
       115.0       0.77      0.65      0.70        31
       116.0       0.79      0.80      0.79       173
       117.0       0.92      0.74      0.82        31
       118.0       0.95      0.86      0.91       117
       119.0       0.87      0.88      0.88       136
       120.0       0.80      0.82      0.81        62
       121.0       0.86      0.91      0.89       224
       122.0       1.00      0.74      0.85        35
       123.0       0.93      0.68      0.78        37
       124.0       0.78      0.90      0.84        31
       125.0       1.00      0.73      0.85        15
       126.0       0.84      0.76      0.80        21
       127.0       0.85      0.90      0.87        73

    accuracy                           0.74     12226
   macro avg       0.71      0.62      0.65     12226
weighted avg       0.74      0.74      0.73     12226


===confusion_matrix===

[[301   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  1   0  12 ...   0   0   0]
 ...
 [  0   0   0 ...  11   1   0]
 [  0   0   0 ...   0  16   3]
 [  0   0   0 ...   0   0  66]]

===multilabel confusion matrix===

[[[11769    99]
  [   57   301]]

 [[12211     3]
  [    4     8]]

 [[12202     5]
  [    7    12]]

 [[12119    28]
  [   29    50]]

 [[12130    41]
  [   24    31]]

 [[12131    37]
  [   40    18]]

 [[12159    22]
  [   27    18]]

 [[12159    20]
  [   21    26]]

 [[12216     0]
  [    9     1]]

 [[12197     8]
  [    7    14]]

 [[12206     5]
  [   13     2]]

 [[12187     3]
  [    8    28]]

 [[12212     2]
  [    9     3]]

 [[12195     6]
  [    8    17]]

 [[12202     5]
  [    9    10]]

 [[12201     3]
  [    5    17]]

 [[12198     5]
  [    9    14]]

 [[12096    12]
  [   16   102]]

 [[12202     6]
  [    8    10]]

 [[12213     1]
  [   11     1]]

 [[12107    29]
  [   34    56]]

 [[12210     3]
  [    7     6]]

 [[12198     3]
  [    7    18]]

 [[12210     3]
  [   13     0]]

 [[12198     6]
  [   14     8]]

 [[12181     7]
  [   17    21]]

 [[12208     1]
  [    0    17]]

 [[12182     9]
  [   22    13]]

 [[12212     2]
  [   10     2]]

 [[12185     5]
  [   12    24]]

 [[12179    15]
  [    9    23]]

 [[12178    10]
  [    5    33]]

 [[11320   159]
  [  106   641]]

 [[12141    10]
  [    8    67]]

 [[12160     7]
  [    9    50]]

 [[12171     8]
  [   13    34]]

 [[11583   142]
  [  118   383]]

 [[11926    59]
  [   67   174]]

 [[12183    10]
  [    8    25]]

 [[11769   113]
  [   83   261]]

 [[12008    26]
  [   34   158]]

 [[12191     3]
  [   11    21]]

 [[11755    87]
  [   64   320]]

 [[12077    32]
  [   16   101]]

 [[11686   104]
  [   95   341]]

 [[12173     4]
  [    5    44]]

 [[11759    66]
  [   54   347]]

 [[12208     1]
  [   12     5]]

 [[12182     2]
  [   12    30]]

 [[12144     5]
  [    8    69]]

 [[12040    14]
  [   18   154]]

 [[12204     2]
  [   10    10]]

 [[11529   198]
  [  134   365]]

 [[12098    28]
  [   30    70]]

 [[12212     3]
  [    6     5]]

 [[12102    20]
  [   16    88]]

 [[12201     7]
  [   11     7]]

 [[12212     4]
  [    8     2]]

 [[12191     0]
  [    7    28]]

 [[11921    75]
  [   70   160]]

 [[12157    11]
  [   10    48]]

 [[12184    13]
  [   24     5]]

 [[12172     5]
  [   25    24]]

 [[12140    36]
  [   27    23]]

 [[12187     5]
  [   10    24]]

 [[12048    23]
  [   33   122]]

 [[12211     1]
  [   13     1]]

 [[11834    78]
  [   91   223]]

 [[12121    43]
  [   55     7]]

 [[11696   223]
  [   72   235]]

 [[12135    23]
  [   36    32]]

 [[12141    19]
  [   30    36]]

 [[12208     4]
  [   10     4]]

 [[12197     5]
  [   11    13]]

 [[12202     5]
  [   16     3]]

 [[12140    26]
  [   38    22]]

 [[11960    60]
  [   60   146]]

 [[12128    21]
  [   39    38]]

 [[12158     9]
  [   15    44]]

 [[12059    28]
  [   52    87]]

 [[12179     5]
  [   12    30]]

 [[11973    79]
  [   81    93]]

 [[12171    12]
  [   20    23]]

 [[12193     7]
  [   12    14]]

 [[12064    56]
  [   40    66]]

 [[12206     5]
  [    7     8]]

 [[11912    73]
  [   57   184]]

 [[11858    59]
  [   66   243]]

 [[12160     7]
  [   23    36]]

 [[12214     2]
  [    8     2]]

 [[11957    81]
  [   59   129]]

 [[12160    20]
  [   19    27]]

 [[12167    18]
  [   36     5]]

 [[12188     6]
  [   13    19]]

 [[11828   110]
  [   89   199]]

 [[12185    10]
  [   22     9]]

 [[12141    10]
  [   12    63]]

 [[12190     9]
  [   16    11]]

 [[12185     3]
  [   16    22]]

 [[12201     1]
  [    3    21]]

 [[12194     7]
  [   20     5]]

 [[12136    25]
  [   20    45]]

 [[12202     2]
  [    4    18]]

 [[12154     8]
  [   14    50]]

 [[12168    18]
  [   25    15]]

 [[12212     2]
  [    1    11]]

 [[12097    16]
  [   30    83]]

 [[12022    43]
  [   26   135]]

 [[12197     5]
  [   11    13]]

 [[12163    11]
  [   10    42]]

 [[12209     2]
  [    4    11]]

 [[12072    30]
  [   53    71]]

 [[12176     9]
  [   14    27]]

 [[11728    68]
  [   16   414]]

 [[12153     8]
  [   12    53]]

 [[12189     6]
  [   11    20]]

 [[12015    38]
  [   34   139]]

 [[12193     2]
  [    8    23]]

 [[12104     5]
  [   16   101]]

 [[12072    18]
  [   16   120]]

 [[12151    13]
  [   11    51]]

 [[11969    33]
  [   20   204]]

 [[12191     0]
  [    9    26]]

 [[12187     2]
  [   12    25]]

 [[12187     8]
  [    3    28]]

 [[12211     0]
  [    4    11]]

 [[12202     3]
  [    5    16]]

 [[12141    12]
  [    7    66]]]

===scores report===
metrics	scores
Accuracy	0.7384
MCC	0.7326
log_loss	1.2967
f1 score weighted	0.7341
f1 score macro	0.6506
f1 score micro	0.7384
roc_auc ovr	0.9809
roc_auc ovo	0.9771
precision	0.7384
recall	0.7384

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7437638014230801	0.7380790698538394	1.2673533125078187	0.7381758924753782	0.656584883879684	0.7437638014230801	0.98143181185523	0.9789223204436454	0.7418496688872755	0.7437638014230801
1	0.7342766009650773	0.7282872788053222	1.3318333581303936	0.7274613779805413	0.6520125301241464	0.7342766009650773	0.9787658616954671	0.9756735331967492	0.7312199485123928	0.7342766009650773
2	0.7136430557827581	0.7072020268867655	1.3845100114372886	0.7061628316632549	0.6116235431580398	0.7136430557827581	0.9767617185375557	0.973098020753342	0.7111509111576255	0.7136430557827581
3	0.7246850973335515	0.7184522641106357	1.3267323869773253	0.7170210748727949	0.6382099555475711	0.7246850973335514	0.9794642668813359	0.9757297782513452	0.7230019702443911	0.7246850973335515
4	0.738426304596761	0.7326103906969623	1.2966942614185895	0.7340746382001817	0.6506010673426219	0.738426304596761	0.9808684819013874	0.9771253592456917	0.7384330140841461	0.738426304596761
mean	0.7309589720202456	0.724926206070705	1.321424666094283	0.7245791630384303	0.6418063960104126	0.7309589720202456	0.9794584281741952	0.9761098023781548	0.7291311025771662	0.7309589720202456
std	0.010676458517575864	0.01094897055656126	0.0391192478506864	0.011658715374699905	0.016271779935840197	0.010676458517575878	0.001651327947347015	0.0019155777880876582	0.01107704212003764	0.010676458517575864

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 42464.4217 secs

