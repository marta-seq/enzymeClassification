/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_hot_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f90945be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f90945be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f90945be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f90945be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.58      0.83      0.68      1793
         1.0       0.79      0.79      0.79      4921
         2.0       0.79      0.67      0.72      3576
         3.0       0.65      0.59      0.62       943
         4.0       0.79      0.65      0.71       695
         5.0       0.83      0.81      0.82      1073
         6.0       0.90      0.90      0.90       471

    accuracy                           0.75     13472
   macro avg       0.76      0.75      0.75     13472
weighted avg       0.76      0.75      0.75     13472


===confusion_matrix===

[[1488  152   83   32    9   18   11]
 [ 431 3894  365  116   25   72   18]
 [ 342  597 2388  113   60   64   12]
 [ 131  138   89  558   15    8    4]
 [  92   61   54   27  449   10    2]
 [  77   79   33    7    7  869    1]
 [  14   12   17    1    0    2  425]]

===multilabel confusion matrix===

[[[10592  1087]
  [  305  1488]]

 [[ 7512  1039]
  [ 1027  3894]]

 [[ 9255   641]
  [ 1188  2388]]

 [[12233   296]
  [  385   558]]

 [[12661   116]
  [  246   449]]

 [[12225   174]
  [  204   869]]

 [[12953    48]
  [   46   425]]]

===scores report===
metrics	scores
Accuracy	0.7476
MCC	0.6732
log_loss	0.7256
f1 score weighted	0.7484
f1 score macro	0.7500
f1 score micro	0.7476
roc_auc ovr	0.9350
roc_auc ovo	0.9462
precision	0.7590
recall	0.7476

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f90945be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f90945be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f90945be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f90945be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.61      0.70      1792
         1.0       0.75      0.85      0.79      4921
         2.0       0.76      0.71      0.73      3576
         3.0       0.73      0.53      0.62       943
         4.0       0.84      0.64      0.73       696
         5.0       0.61      0.89      0.72      1072
         6.0       0.93      0.85      0.89       471

    accuracy                           0.75     13471
   macro avg       0.78      0.73      0.74     13471
weighted avg       0.76      0.75      0.75     13471


===confusion_matrix===

[[1091  325  185   39   17  126    9]
 [  73 4173  348   67   22  229    9]
 [  74  699 2525   52   32  184   10]
 [  42  201  152  501    9   38    0]
 [  22  100   80   15  448   31    0]
 [   7   71   26    7    3  958    0]
 [   7   30   24    3    0    8  399]]

===multilabel confusion matrix===

[[[11454   225]
  [  701  1091]]

 [[ 7124  1426]
  [  748  4173]]

 [[ 9080   815]
  [ 1051  2525]]

 [[12345   183]
  [  442   501]]

 [[12692    83]
  [  248   448]]

 [[11783   616]
  [  114   958]]

 [[12972    28]
  [   72   399]]]

===scores report===
metrics	scores
Accuracy	0.7494
MCC	0.6701
log_loss	0.7364
f1 score weighted	0.7466
f1 score macro	0.7406
f1 score micro	0.7494
roc_auc ovr	0.9347
roc_auc ovo	0.9448
precision	0.7592
recall	0.7494

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f90945be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f90945be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f90945be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f90945be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.70      0.73      1792
         1.0       0.85      0.71      0.78      4921
         2.0       0.69      0.81      0.74      3576
         3.0       0.50      0.70      0.58       943
         4.0       0.68      0.70      0.69       695
         5.0       0.85      0.79      0.82      1072
         6.0       0.83      0.89      0.86       472

    accuracy                           0.75     13471
   macro avg       0.74      0.76      0.74     13471
weighted avg       0.76      0.75      0.75     13471


===confusion_matrix===

[[1256  104  255  127   19   23    8]
 [ 194 3498  683  317  110   74   45]
 [ 106  311 2879  155   60   37   28]
 [  36   76  137  660   25    8    1]
 [  33   42   94   33  488    3    2]
 [  25   60   95   23   18  851    0]
 [   9   11   22   10    0    2  418]]

===multilabel confusion matrix===

[[[11276   403]
  [  536  1256]]

 [[ 7946   604]
  [ 1423  3498]]

 [[ 8609  1286]
  [  697  2879]]

 [[11863   665]
  [  283   660]]

 [[12544   232]
  [  207   488]]

 [[12252   147]
  [  221   851]]

 [[12915    84]
  [   54   418]]]

===scores report===
metrics	scores
Accuracy	0.7460
MCC	0.6745
log_loss	0.7248
f1 score weighted	0.7494
f1 score macro	0.7428
f1 score micro	0.7460
roc_auc ovr	0.9362
roc_auc ovo	0.9473
precision	0.7626
recall	0.7460

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f90945be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f90945be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f90945be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f90945be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.59      0.81      0.68      1792
         1.0       0.78      0.80      0.79      4920
         2.0       0.77      0.68      0.72      3576
         3.0       0.69      0.60      0.64       944
         4.0       0.68      0.66      0.67       695
         5.0       0.91      0.77      0.84      1072
         6.0       0.96      0.83      0.89       472

    accuracy                           0.75     13471
   macro avg       0.77      0.74      0.75     13471
weighted avg       0.76      0.75      0.75     13471


===confusion_matrix===

[[1452  159  117   34   20    6    4]
 [ 393 3943  382   89   78   30    5]
 [ 333  608 2429   93   82   25    6]
 [ 114  152   82  567   24    5    0]
 [  76   69   64   18  456   11    1]
 [  73  103   40   13   13  830    0]
 [  30   20   25    5    0    2  390]]

===multilabel confusion matrix===

[[[10660  1019]
  [  340  1452]]

 [[ 7440  1111]
  [  977  3943]]

 [[ 9185   710]
  [ 1147  2429]]

 [[12275   252]
  [  377   567]]

 [[12559   217]
  [  239   456]]

 [[12320    79]
  [  242   830]]

 [[12983    16]
  [   82   390]]]

===scores report===
metrics	scores
Accuracy	0.7473
MCC	0.6708
log_loss	0.7248
f1 score weighted	0.7487
f1 score macro	0.7474
f1 score micro	0.7473
roc_auc ovr	0.9341
roc_auc ovo	0.9448
precision	0.7583
recall	0.7473

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f90945be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f90945be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f90945be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f90945be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.56      0.80      0.66      1792
         1.0       0.90      0.62      0.74      4920
         2.0       0.79      0.65      0.71      3576
         3.0       0.37      0.74      0.49       944
         4.0       0.55      0.68      0.61       695
         5.0       0.70      0.89      0.78      1073
         6.0       0.93      0.90      0.91       471

    accuracy                           0.70     13471
   macro avg       0.69      0.75      0.70     13471
weighted avg       0.76      0.70      0.71     13471


===confusion_matrix===

[[1432   48   78  162   29   32   11]
 [ 495 3070  375  585  188  199    8]
 [ 395  227 2321  339  143  140   11]
 [ 100   37   70  699   17   21    0]
 [  62   21   53   61  475   20    3]
 [  38   17   17   34   13  954    0]
 [  22    8    7    6    2    3  423]]

===multilabel confusion matrix===

[[[10567  1112]
  [  360  1432]]

 [[ 8193   358]
  [ 1850  3070]]

 [[ 9295   600]
  [ 1255  2321]]

 [[11340  1187]
  [  245   699]]

 [[12384   392]
  [  220   475]]

 [[11983   415]
  [  119   954]]

 [[12967    33]
  [   48   423]]]

===scores report===
metrics	scores
Accuracy	0.6959
MCC	0.6303
log_loss	0.8929
f1 score weighted	0.7063
f1 score macro	0.7009
f1 score micro	0.6959
roc_auc ovr	0.9287
roc_auc ovo	0.9428
precision	0.7551
recall	0.6959

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7475504750593824	0.6731839636729393	0.7256378779796288	0.7484418449140761	0.7500377796826438	0.7475504750593824	0.9349983466746832	0.9462495931907617	0.7590217636033428	0.7475504750593824
1	0.7493875733056194	0.6701096896379344	0.7364251711133221	0.7465744473936385	0.7406347312685433	0.7493875733056194	0.9347178047747704	0.9447773193880624	0.7592013464058596	0.7493875733056194
2	0.7460470640635439	0.6745492245201119	0.7248006830955059	0.7493590255354439	0.7427700080150519	0.7460470640635438	0.9361580049182269	0.9473001676803675	0.7625904730265763	0.7460470640635439
3	0.7473090342216614	0.6707531804707663	0.7248285583674507	0.7487176269843313	0.7473646904613295	0.7473090342216614	0.9341138272129855	0.9447579410898129	0.7583178186339454	0.7473090342216614
4	0.6958651918936976	0.6302764703279692	0.8929255050111782	0.7062993939846479	0.7009487741397595	0.6958651918936976	0.9287386584899981	0.9428162695619848	0.7550759144534511	0.6958651918936976
mean	0.737231867708781	0.6637745057259442	0.7609235591134171	0.7398784677624276	0.7363511967134656	0.737231867708781	0.9337453284141329	0.945180258182198	0.7588414632246352	0.737231867708781
std	0.020710836177732898	0.016826094590643447	0.06614752494104481	0.016815073468017926	0.018008336562845586	0.020710836177732887	0.0025899539779953473	0.0015209633286707932	0.002394604762012538	0.020710836177732898

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 15089.5768 secs

