/home/amsequeira/enzymeClassification/models/hot_encoded/bi_attetion_500_post_post_lev1_ec90_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f121c139250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f121c139430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f121c139490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f121c1391f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.94      0.85      0.89      3813
         1.0       0.88      0.95      0.91     10869
         2.0       0.89      0.86      0.87      6897
         3.0       0.91      0.87      0.89      2585
         4.0       0.98      0.84      0.90      1616
         5.0       0.97      0.96      0.96      3258
         6.0       0.95      0.96      0.95      1372

    accuracy                           0.91     30410
   macro avg       0.93      0.90      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3251   316   157    52     5    15    17]
 [   63 10355   316    68    10    33    24]
 [   85   764  5920    63    14    23    28]
 [   33   154   127  2255     3    10     3]
 [   21   133    70    25  1357     8     2]
 [    8    81    41    11     1  3114     2]
 [    7    28    14     2     0     1  1320]]

===multilabel confusion matrix===

[[[26380   217]
  [  562  3251]]

 [[18065  1476]
  [  514 10355]]

 [[22788   725]
  [  977  5920]]

 [[27604   221]
  [  330  2255]]

 [[28761    33]
  [  259  1357]]

 [[27062    90]
  [  144  3114]]

 [[28962    76]
  [   52  1320]]]

===scores report===
metrics	scores
Accuracy	0.9067
MCC	0.8803
log_loss	0.3132
f1 score weighted	0.9064
f1 score macro	0.9130
f1 score micro	0.9067
roc_auc ovr	0.9885
roc_auc ovo	0.9906
precision	0.9085
recall	0.9067

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f121c139250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f121c139430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f121c139490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f121c1391f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.88      0.89      3813
         1.0       0.94      0.90      0.92     10869
         2.0       0.82      0.92      0.87      6897
         3.0       0.88      0.89      0.88      2585
         4.0       0.95      0.85      0.90      1616
         5.0       0.98      0.94      0.96      3258
         6.0       0.94      0.97      0.95      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.91      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[3352  130  244   53   11    2   21]
 [ 148 9744  756  126   29   28   38]
 [ 114  280 6354   95   22   12   20]
 [  43   78  146 2301   11    3    3]
 [  36   60  115   27 1374    3    1]
 [  30   59   72   13    3 3075    6]
 [   5   10   27    4    0    0 1326]]

===multilabel confusion matrix===

[[[26221   376]
  [  461  3352]]

 [[18924   617]
  [ 1125  9744]]

 [[22153  1360]
  [  543  6354]]

 [[27507   318]
  [  284  2301]]

 [[28718    76]
  [  242  1374]]

 [[27104    48]
  [  183  3075]]

 [[28949    89]
  [   46  1326]]]

===scores report===
metrics	scores
Accuracy	0.9052
MCC	0.8794
log_loss	0.3080
f1 score weighted	0.9058
f1 score macro	0.9104
f1 score micro	0.9052
roc_auc ovr	0.9884
roc_auc ovo	0.9904
precision	0.9085
recall	0.9052

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f121c139250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f121c139430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f121c139490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f121c1391f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.88      0.88      3814
         1.0       0.95      0.87      0.91     10869
         2.0       0.81      0.93      0.87      6896
         3.0       0.91      0.86      0.89      2584
         4.0       0.97      0.85      0.91      1617
         5.0       0.92      0.97      0.94      3258
         6.0       0.95      0.96      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.91      0.90      0.91     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[3365   98  266   41    8   20   16]
 [ 188 9500  851   97   11  189   33]
 [ 127  244 6391   47   17   54   16]
 [  59   78  203 2225    4   11    4]
 [  39   52  104   24 1379   18    1]
 [  16   29   38    8    2 3165    0]
 [   9   19   20    1    0    1 1322]]

===multilabel confusion matrix===

[[[26158   438]
  [  449  3365]]

 [[19021   520]
  [ 1369  9500]]

 [[22032  1482]
  [  505  6391]]

 [[27608   218]
  [  359  2225]]

 [[28751    42]
  [  238  1379]]

 [[26859   293]
  [   93  3165]]

 [[28968    70]
  [   50  1322]]]

===scores report===
metrics	scores
Accuracy	0.8993
MCC	0.8726
log_loss	0.3387
f1 score weighted	0.8998
f1 score macro	0.9072
f1 score micro	0.8993
roc_auc ovr	0.9876
roc_auc ovo	0.9897
precision	0.9038
recall	0.8993

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f121c139250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f121c139430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f121c139490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f121c1391f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.91      0.91      3813
         1.0       0.91      0.95      0.93     10868
         2.0       0.91      0.88      0.90      6897
         3.0       0.94      0.88      0.91      2585
         4.0       0.96      0.88      0.92      1616
         5.0       0.96      0.97      0.96      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.92     30409
   macro avg       0.93      0.92      0.93     30409
weighted avg       0.92      0.92      0.92     30409


===confusion_matrix===

[[ 3485   150   124    21     9    10    14]
 [  127 10289   304    56    13    62    17]
 [  148   522  6084    59    26    42    16]
 [   57   134    92  2279    14     8     1]
 [   34    81    49    19  1417    14     2]
 [   13    55    26     2     1  3161     0]
 [   12    26    10     1     0     1  1322]]

===multilabel confusion matrix===

[[[26205   391]
  [  328  3485]]

 [[18573   968]
  [  579 10289]]

 [[22907   605]
  [  813  6084]]

 [[27666   158]
  [  306  2279]]

 [[28730    63]
  [  199  1417]]

 [[27014   137]
  [   97  3161]]

 [[28987    50]
  [   50  1322]]]

===scores report===
metrics	scores
Accuracy	0.9220
MCC	0.9000
log_loss	0.2886
f1 score weighted	0.9218
f1 score macro	0.9261
f1 score micro	0.9220
roc_auc ovr	0.9915
roc_auc ovo	0.9929
precision	0.9222
recall	0.9220

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f121c139250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f121c139430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f121c139490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f121c1391f0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.96      0.78      0.86      3813
         1.0       0.94      0.88      0.91     10868
         2.0       0.81      0.92      0.86      6897
         3.0       0.83      0.90      0.86      2585
         4.0       0.91      0.88      0.89      1616
         5.0       0.87      0.98      0.92      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.89     30409
   macro avg       0.90      0.90      0.90     30409
weighted avg       0.90      0.89      0.89     30409


===confusion_matrix===

[[2965  156  428  110   46   91   17]
 [  55 9533  749  230   47  223   31]
 [  27  265 6368   98   28  100   11]
 [  20   64  148 2315   19   18    1]
 [   9   43   88   25 1424   26    1]
 [   3   12   49    6    2 3186    0]
 [   8   17   24    4    1    6 1312]]

===multilabel confusion matrix===

[[[26474   122]
  [  848  2965]]

 [[18984   557]
  [ 1335  9533]]

 [[22026  1486]
  [  529  6368]]

 [[27351   473]
  [  270  2315]]

 [[28650   143]
  [  192  1424]]

 [[26687   464]
  [   72  3186]]

 [[28976    61]
  [   60  1312]]]

===scores report===
metrics	scores
Accuracy	0.8913
MCC	0.8628
log_loss	0.3477
f1 score weighted	0.8915
f1 score macro	0.8953
f1 score micro	0.8913
roc_auc ovr	0.9879
roc_auc ovo	0.9902
precision	0.8975
recall	0.8913

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9066754357119369	0.880251172250326	0.31321581845414903	0.9063644181237309	0.9130279500369115	0.9066754357119369	0.9885158999073517	0.9905771810477928	0.9085047606697025	0.9066754357119369
1	0.905162775402828	0.8793780122894307	0.3080189491944715	0.9058073585398497	0.9103814113005678	0.905162775402828	0.9883624216263769	0.9903950956341568	0.9084930021914591	0.905162775402828
2	0.8992765537652088	0.8726417013763831	0.3386839632809637	0.8997945176043701	0.907249272927445	0.8992765537652088	0.9875577913358434	0.9896749309190697	0.9038197570396695	0.8992765537652088
3	0.9219967772698872	0.8999944923955482	0.2885947626336327	0.9217933077477707	0.9261489004298425	0.9219967772698872	0.9914503029805134	0.9928658991511595	0.9222358440466075	0.9219967772698872
4	0.8912821861948765	0.8627862206456157	0.3476764675104688	0.8914763069400148	0.8953345160141177	0.8912821861948765	0.9879067582087063	0.9902353587602765	0.8975064119586587	0.8912821861948765
mean	0.9048787456689474	0.8790103197914607	0.31923799221473714	0.9050471817911472	0.9104284101417768	0.9048787456689474	0.9887586348117583	0.9907496931024911	0.9081119551812193	0.9048787456689474
std	0.010125085259387587	0.012213034889714716	0.021391744623139187	0.009944896581507462	0.009917925033182819	0.010125085259387587	0.0013877104491392643	0.0011003164436179536	0.008132456475008739	0.010125085259387587

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 63589.7623 secs

