/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_middle_bilstm_attentio_cv_only_enz_hot_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c8033e250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c8033e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c8033e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c8033e640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.78      0.79      1793
         1.0       0.83      0.86      0.85      4921
         2.0       0.81      0.80      0.80      3576
         3.0       0.69      0.69      0.69       943
         4.0       0.81      0.75      0.78       695
         5.0       0.85      0.87      0.86      1073
         6.0       0.93      0.89      0.91       471

    accuracy                           0.82     13472
   macro avg       0.82      0.80      0.81     13472
weighted avg       0.82      0.82      0.82     13472


===confusion_matrix===

[[1399  174  121   42   20   26   11]
 [ 123 4229  326  119   41   76    7]
 [ 113  420 2861   86   41   45   10]
 [  49  102  112  647   18   12    3]
 [  24   64   53   26  518   10    0]
 [  20   70   34   10    3  936    0]
 [   9   14   26    4    0    0  418]]

===multilabel confusion matrix===

[[[11341   338]
  [  394  1399]]

 [[ 7707   844]
  [  692  4229]]

 [[ 9224   672]
  [  715  2861]]

 [[12242   287]
  [  296   647]]

 [[12654   123]
  [  177   518]]

 [[12230   169]
  [  137   936]]

 [[12970    31]
  [   53   418]]]

===scores report===
metrics	scores
Accuracy	0.8171
MCC	0.7597
log_loss	0.6725
f1 score weighted	0.8168
f1 score macro	0.8110
f1 score micro	0.8171
roc_auc ovr	0.9592
roc_auc ovo	0.9647
precision	0.8168
recall	0.8171

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c8033e250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c8033e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c8033e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c8033e640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.52      0.62      1792
         1.0       0.70      0.77      0.73      4921
         2.0       0.67      0.63      0.65      3576
         3.0       0.48      0.42      0.44       943
         4.0       0.43      0.60      0.50       696
         5.0       0.66      0.80      0.72      1072
         6.0       0.91      0.81      0.85       471

    accuracy                           0.67     13471
   macro avg       0.66      0.65      0.65     13471
weighted avg       0.68      0.67      0.67     13471


===confusion_matrix===

[[ 925  362  243  103  105   49    5]
 [  94 3789  513  159  164  189   13]
 [  90  799 2247  103  192  126   19]
 [  32  253  163  393   65   36    1]
 [  15  113   76   42  421   29    0]
 [  16   87   66   21   27  855    0]
 [   8   43   29    3    2    6  380]]

===multilabel confusion matrix===

[[[11424   255]
  [  867   925]]

 [[ 6893  1657]
  [ 1132  3789]]

 [[ 8805  1090]
  [ 1329  2247]]

 [[12097   431]
  [  550   393]]

 [[12220   555]
  [  275   421]]

 [[11964   435]
  [  217   855]]

 [[12962    38]
  [   91   380]]]

===scores report===
metrics	scores
Accuracy	0.6688
MCC	0.5650
log_loss	0.9233
f1 score weighted	0.6671
f1 score macro	0.6473
f1 score micro	0.6688
roc_auc ovr	0.8915
roc_auc ovo	0.9077
precision	0.6774
recall	0.6688

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c8033e250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c8033e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c8033e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c8033e640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.68      0.70      1792
         1.0       0.74      0.84      0.79      4921
         2.0       0.70      0.79      0.74      3576
         3.0       0.96      0.38      0.54       943
         4.0       0.87      0.64      0.74       695
         5.0       0.91      0.80      0.85      1072
         6.0       0.99      0.76      0.86       472

    accuracy                           0.76     13471
   macro avg       0.84      0.70      0.75     13471
weighted avg       0.77      0.76      0.75     13471


===confusion_matrix===

[[1217  296  248    2   10   17    2]
 [ 168 4147  555    6   15   29    1]
 [ 119  593 2817    1   19   25    2]
 [  74  267  222  356   13   11    0]
 [  39  105   95    3  448    5    0]
 [  26  134   45    0    8  859    0]
 [  32   54   26    1    0    0  359]]

===multilabel confusion matrix===

[[[11221   458]
  [  575  1217]]

 [[ 7101  1449]
  [  774  4147]]

 [[ 8704  1191]
  [  759  2817]]

 [[12515    13]
  [  587   356]]

 [[12711    65]
  [  247   448]]

 [[12312    87]
  [  213   859]]

 [[12994     5]
  [  113   359]]]

===scores report===
metrics	scores
Accuracy	0.7574
MCC	0.6762
log_loss	0.7369
f1 score weighted	0.7528
f1 score macro	0.7469
f1 score micro	0.7574
roc_auc ovr	0.9370
roc_auc ovo	0.9458
precision	0.7734
recall	0.7574

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c8033e250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c8033e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c8033e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c8033e640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.80      0.79      1792
         1.0       0.84      0.84      0.84      4920
         2.0       0.80      0.81      0.80      3576
         3.0       0.73      0.71      0.72       944
         4.0       0.80      0.74      0.77       695
         5.0       0.85      0.89      0.87      1072
         6.0       0.93      0.89      0.91       472

    accuracy                           0.82     13471
   macro avg       0.82      0.81      0.81     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1425  140  139   35   18   25   10]
 [ 157 4147  383   97   46   79   11]
 [ 111  414 2882   75   40   44   10]
 [  54  123   73  668   18    7    1]
 [  32   61   50   32  513    7    0]
 [  18   48   37    6    7  956    0]
 [  13    8   24    3    2    2  420]]

===multilabel confusion matrix===

[[[11294   385]
  [  367  1425]]

 [[ 7757   794]
  [  773  4147]]

 [[ 9189   706]
  [  694  2882]]

 [[12279   248]
  [  276   668]]

 [[12645   131]
  [  182   513]]

 [[12235   164]
  [  116   956]]

 [[12967    32]
  [   52   420]]]

===scores report===
metrics	scores
Accuracy	0.8174
MCC	0.7605
log_loss	0.6463
f1 score weighted	0.8172
f1 score macro	0.8147
f1 score micro	0.8174
roc_auc ovr	0.9596
roc_auc ovo	0.9664
precision	0.8172
recall	0.8174

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5c8033e250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5c8033e850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5c8033e8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5c8033e640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.76      0.78      1792
         1.0       0.86      0.82      0.84      4920
         2.0       0.75      0.83      0.79      3576
         3.0       0.72      0.67      0.69       944
         4.0       0.77      0.73      0.75       695
         5.0       0.87      0.91      0.89      1073
         6.0       0.91      0.90      0.90       471

    accuracy                           0.81     13471
   macro avg       0.81      0.80      0.80     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1353  123  199   46   32   24   15]
 [ 139 4025  512  106   59   65   14]
 [  81  349 2973   71   45   45   12]
 [  57   90  145  629   15    6    2]
 [  27   51   82   19  506   10    0]
 [   6   40   44    4    4  975    0]
 [  10   15   21    1    0    2  422]]

===multilabel confusion matrix===

[[[11359   320]
  [  439  1353]]

 [[ 7883   668]
  [  895  4025]]

 [[ 8892  1003]
  [  603  2973]]

 [[12280   247]
  [  315   629]]

 [[12621   155]
  [  189   506]]

 [[12246   152]
  [   98   975]]

 [[12957    43]
  [   49   422]]]

===scores report===
metrics	scores
Accuracy	0.8079
MCC	0.7488
log_loss	0.7055
f1 score weighted	0.8078
f1 score macro	0.8045
f1 score micro	0.8079
roc_auc ovr	0.9555
roc_auc ovo	0.9624
precision	0.8098
recall	0.8079

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8171021377672208	0.7596531602584543	0.6725024630979493	0.8167653374136726	0.8109834872193312	0.8171021377672208	0.9591842851838398	0.964747652287479	0.8168393915927219	0.8171021377672208
1	0.6688441838022419	0.5649924911829316	0.923290629103484	0.6670617655593655	0.6472564882826387	0.6688441838022419	0.8914548963888778	0.9077230794333881	0.6773874223095577	0.6688441838022419
2	0.7574047954866009	0.6761641614400155	0.7368708867597438	0.7527804036751253	0.746878568102825	0.7574047954866009	0.9369628356190626	0.9458253745171711	0.7733506646821396	0.7574047954866009
3	0.8173854947665355	0.7605052705923088	0.6463442893818202	0.8171606972798878	0.8146819184364708	0.8173854947665355	0.9596008415665775	0.966416365974943	0.8171792878341364	0.8173854947665355
4	0.8078836018112984	0.748821072796732	0.7055037737279073	0.8078098093859112	0.8044708104855471	0.8078836018112983	0.9554533346903261	0.9624485512379034	0.8097702289218409	0.8078836018112984
mean	0.7737240427267795	0.7020272312540885	0.736902408414181	0.7723156026627926	0.7648542545053626	0.7737240427267794	0.9405312386897368	0.949432204690177	0.7789053990680793	0.7737240427267795
std	0.05695780831268565	0.07533592868127906	0.09805566780652097	0.057804315351063236	0.06376916752406106	0.05695780831268563	0.025905504127687877	0.022113843178817042	0.05327902167134804	0.05695780831268565

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 30098.2534 secs

