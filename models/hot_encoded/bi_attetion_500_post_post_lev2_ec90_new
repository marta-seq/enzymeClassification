/home/amsequeira/enzymeClassification/models/hot_encoded/bi_attetion_500_post_post_lev2_ec90_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5160367070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5160367400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5160367460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5160367190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.90      0.88       911
         1.0       1.00      0.62      0.77        53
         2.0       0.94      0.81      0.87       179
         3.0       0.33      0.04      0.07        25
         4.0       0.84      0.46      0.59       112
         5.0       0.79      0.73      0.76       491
         6.0       1.00      0.83      0.91        64
         7.0       1.00      0.24      0.39        37
         8.0       0.99      0.77      0.87       206
         9.0       0.68      0.75      0.71        71
        10.0       0.81      0.93      0.86       404
        11.0       1.00      0.44      0.61        16
        12.0       0.93      0.69      0.79       378
        13.0       0.80      0.75      0.78       191
        14.0       0.86      0.08      0.14        76
        15.0       0.88      0.65      0.75        66
        16.0       0.93      0.81      0.86       141
        17.0       0.82      0.73      0.77       182
        18.0       0.90      0.75      0.82        12
        19.0       1.00      0.89      0.94        38
        20.0       0.77      0.94      0.85      2162
        21.0       0.99      0.93      0.96       168
        22.0       0.94      0.72      0.82      1470
        23.0       0.93      0.82      0.87      1259
        24.0       0.97      0.86      0.91       956
        25.0       0.66      0.94      0.78       283
        26.0       0.84      0.89      0.87      3919
        27.0       0.98      0.89      0.93       531
        28.0       0.71      0.83      0.77        12
        29.0       0.79      0.77      0.78      2345
        30.0       0.62      0.77      0.69       615
        31.0       1.00      0.66      0.79        32
        32.0       0.72      0.82      0.77      1449
        33.0       0.94      0.75      0.83       893
        34.0       0.93      0.88      0.91      1377
        35.0       0.89      0.36      0.52        22
        36.0       0.90      0.85      0.88       844
        37.0       0.97      0.85      0.91      1142
        38.0       0.90      0.89      0.90       314
        39.0       0.90      0.46      0.61        56
        40.0       0.88      0.69      0.77       154
        41.0       0.96      0.90      0.93        52
        42.0       0.84      0.75      0.79       247
        43.0       0.63      0.86      0.73       198
        44.0       0.71      0.94      0.81       529
        45.0       0.93      0.86      0.90       540
        46.0       1.00      0.15      0.26        20
        47.0       0.52      0.75      0.61        80
        48.0       0.83      1.00      0.90      1466
        49.0       0.83      0.92      0.87       148
        50.0       0.94      0.94      0.94      1453
        51.0       0.50      0.42      0.45        12
        52.0       0.99      0.89      0.94       151
        53.0       0.97      0.95      0.96       903
        54.0       0.92      0.54      0.68       108
        55.0       0.90      0.92      0.91        93
        56.0       0.94      0.88      0.91        33
        57.0       0.78      0.88      0.83        49
        58.0       0.83      0.86      0.84       154

    accuracy                           0.85     29892
   macro avg       0.86      0.74      0.77     29892
weighted avg       0.86      0.85      0.85     29892


===confusion_matrix===

[[819   0   0 ...   0   0   0]
 [  0  33   0 ...   0   0   0]
 [  0   0 145 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   0]
 [  0   0   0 ...   0  43   6]
 [  0   0   0 ...   1   7 132]]

===multilabel confusion matrix===

[[[28854   127]
  [   92   819]]

 [[29839     0]
  [   20    33]]

 [[29703    10]
  [   34   145]]

 [[29865     2]
  [   24     1]]

 [[29770    10]
  [   61    51]]

 [[29308    93]
  [  133   358]]

 [[29828     0]
  [   11    53]]

 [[29855     0]
  [   28     9]]

 [[29685     1]
  [   47   159]]

 [[29796    25]
  [   18    53]]

 [[29398    90]
  [   30   374]]

 [[29876     0]
  [    9     7]]

 [[29495    19]
  [  119   259]]

 [[29666    35]
  [   48   143]]

 [[29815     1]
  [   70     6]]

 [[29820     6]
  [   23    43]]

 [[29742     9]
  [   27   114]]

 [[29682    28]
  [   50   132]]

 [[29879     1]
  [    3     9]]

 [[29854     0]
  [    4    34]]

 [[27131   599]
  [  129  2033]]

 [[29723     1]
  [   11   157]]

 [[28352    70]
  [  407  1063]]

 [[28550    83]
  [  224  1035]]

 [[28913    23]
  [  135   821]]

 [[29473   136]
  [   16   267]]

 [[25318   655]
  [  421  3498]]

 [[29351    10]
  [   59   472]]

 [[29876     4]
  [    2    10]]

 [[27067   480]
  [  528  1817]]

 [[28981   296]
  [  139   476]]

 [[29860     0]
  [   11    21]]

 [[27983   460]
  [  266  1183]]

 [[28957    42]
  [  223   670]]

 [[28429    86]
  [  162  1215]]

 [[29869     1]
  [   14     8]]

 [[28969    79]
  [  123   721]]

 [[28723    27]
  [  171   971]]

 [[29547    31]
  [   34   280]]

 [[29833     3]
  [   30    26]]

 [[29723    15]
  [   48   106]]

 [[29838     2]
  [    5    47]]

 [[29610    35]
  [   62   185]]

 [[29593   101]
  [   27   171]]

 [[29156   207]
  [   31   498]]

 [[29318    34]
  [   74   466]]

 [[29872     0]
  [   17     3]]

 [[29756    56]
  [   20    60]]

 [[28118   308]
  [    4  1462]]

 [[29717    27]
  [   12   136]]

 [[28357    82]
  [   82  1371]]

 [[29875     5]
  [    7     5]]

 [[29739     2]
  [   16   135]]

 [[28965    24]
  [   47   856]]

 [[29779     5]
  [   50    58]]

 [[29789    10]
  [    7    86]]

 [[29857     2]
  [    4    29]]

 [[29831    12]
  [    6    43]]

 [[29711    27]
  [   22   132]]]

===scores report===
metrics	scores
Accuracy	0.8496
MCC	0.8416
log_loss	0.6146
f1 score weighted	0.8484
f1 score macro	0.7714
f1 score micro	0.8496
roc_auc ovr	0.9912
roc_auc ovo	0.9886
precision	0.8603
recall	0.8496

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5160367070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5160367400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5160367460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5160367190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.92      0.86       912
         1.0       0.95      0.70      0.80        53
         2.0       0.68      0.78      0.73       179
         3.0       0.71      0.20      0.31        25
         4.0       0.89      0.49      0.63       112
         5.0       0.81      0.74      0.77       492
         6.0       0.94      0.78      0.86        65
         7.0       0.71      0.58      0.64        38
         8.0       0.98      0.79      0.87       206
         9.0       0.98      0.56      0.71        71
        10.0       0.96      0.83      0.89       405
        11.0       0.88      0.41      0.56        17
        12.0       0.82      0.77      0.79       377
        13.0       0.95      0.73      0.82       191
        14.0       0.43      0.20      0.27        76
        15.0       0.62      0.76      0.68        66
        16.0       0.97      0.71      0.82       140
        17.0       0.82      0.81      0.81       182
        18.0       1.00      1.00      1.00        11
        19.0       0.91      0.84      0.87        37
        20.0       0.97      0.91      0.94      2163
        21.0       0.90      0.93      0.92       169
        22.0       0.80      0.84      0.82      1469
        23.0       0.86      0.86      0.86      1259
        24.0       0.97      0.85      0.91       956
        25.0       0.94      0.87      0.90       282
        26.0       0.80      0.94      0.86      3919
        27.0       0.99      0.88      0.93       531
        28.0       1.00      0.83      0.91        12
        29.0       0.79      0.79      0.79      2346
        30.0       0.51      0.82      0.63       615
        31.0       0.96      0.81      0.88        32
        32.0       0.78      0.79      0.79      1450
        33.0       0.94      0.73      0.82       893
        34.0       0.87      0.91      0.89      1376
        35.0       1.00      0.50      0.67        22
        36.0       0.82      0.85      0.83       843
        37.0       0.89      0.86      0.87      1142
        38.0       0.99      0.87      0.92       314
        39.0       0.97      0.50      0.66        56
        40.0       0.97      0.64      0.77       154
        41.0       1.00      0.85      0.92        52
        42.0       0.75      0.89      0.81       247
        43.0       0.96      0.76      0.85       198
        44.0       0.92      0.90      0.91       529
        45.0       0.99      0.77      0.87       539
        46.0       1.00      0.21      0.35        19
        47.0       0.84      0.71      0.77        80
        48.0       0.99      0.97      0.98      1466
        49.0       0.91      0.91      0.91       148
        50.0       0.98      0.92      0.95      1453
        51.0       1.00      0.17      0.29        12
        52.0       0.99      0.88      0.93       151
        53.0       0.95      0.95      0.95       903
        54.0       0.85      0.77      0.81       108
        55.0       1.00      0.80      0.89        93
        56.0       0.82      0.82      0.82        33
        57.0       0.87      0.84      0.85        49
        58.0       0.78      0.92      0.85       154

    accuracy                           0.86     29892
   macro avg       0.88      0.76      0.80     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[841   0   2 ...   0   0   1]
 [  0  37   0 ...   0   0   0]
 [  0   0 139 ...   0   0   0]
 ...
 [  0   0   0 ...  27   1   3]
 [  0   0   0 ...   0  41   6]
 [  0   0   0 ...   1   4 142]]

===multilabel confusion matrix===

[[[28774   206]
  [   71   841]]

 [[29837     2]
  [   16    37]]

 [[29648    65]
  [   40   139]]

 [[29865     2]
  [   20     5]]

 [[29773     7]
  [   57    55]]

 [[29315    85]
  [  130   362]]

 [[29824     3]
  [   14    51]]

 [[29845     9]
  [   16    22]]

 [[29683     3]
  [   44   162]]

 [[29820     1]
  [   31    40]]

 [[29473    14]
  [   67   338]]

 [[29874     1]
  [   10     7]]

 [[29452    63]
  [   88   289]]

 [[29693     8]
  [   52   139]]

 [[29796    20]
  [   61    15]]

 [[29796    30]
  [   16    50]]

 [[29749     3]
  [   41    99]]

 [[29678    32]
  [   35   147]]

 [[29881     0]
  [    0    11]]

 [[29852     3]
  [    6    31]]

 [[27660    69]
  [  184  1979]]

 [[29706    17]
  [   11   158]]

 [[28112   311]
  [  237  1232]]

 [[28454   179]
  [  176  1083]]

 [[28911    25]
  [  141   815]]

 [[29593    17]
  [   37   245]]

 [[25042   931]
  [  254  3665]]

 [[29355     6]
  [   63   468]]

 [[29880     0]
  [    2    10]]

 [[27052   494]
  [  499  1847]]

 [[28796   481]
  [  111   504]]

 [[29859     1]
  [    6    26]]

 [[28124   318]
  [  300  1150]]

 [[28956    43]
  [  240   653]]

 [[28321   195]
  [  121  1255]]

 [[29870     0]
  [   11    11]]

 [[28887   162]
  [  126   717]]

 [[28629   121]
  [  164   978]]

 [[29574     4]
  [   41   273]]

 [[29835     1]
  [   28    28]]

 [[29735     3]
  [   55    99]]

 [[29840     0]
  [    8    44]]

 [[29573    72]
  [   28   219]]

 [[29688     6]
  [   48   150]]

 [[29319    44]
  [   54   475]]

 [[29350     3]
  [  122   417]]

 [[29873     0]
  [   15     4]]

 [[29801    11]
  [   23    57]]

 [[28417     9]
  [   49  1417]]

 [[29730    14]
  [   13   135]]

 [[28412    27]
  [  111  1342]]

 [[29880     0]
  [   10     2]]

 [[29740     1]
  [   18   133]]

 [[28944    45]
  [   43   860]]

 [[29769    15]
  [   25    83]]

 [[29799     0]
  [   19    74]]

 [[29853     6]
  [    6    27]]

 [[29837     6]
  [    8    41]]

 [[29698    40]
  [   12   142]]]

===scores report===
metrics	scores
Accuracy	0.8584
MCC	0.8508
log_loss	0.5755
f1 score weighted	0.8590
f1 score macro	0.7963
f1 score micro	0.8584
roc_auc ovr	0.9919
roc_auc ovo	0.9899
precision	0.8688
recall	0.8584

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5160367070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5160367400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5160367460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5160367190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.90      0.88       912
         1.0       0.93      0.83      0.88        52
         2.0       0.90      0.79      0.85       179
         3.0       0.67      0.16      0.26        25
         4.0       0.66      0.51      0.57       112
         5.0       0.81      0.76      0.78       492
         6.0       0.90      0.82      0.85        65
         7.0       0.55      0.42      0.48        38
         8.0       0.90      0.83      0.87       205
         9.0       0.81      0.79      0.80        71
        10.0       0.86      0.91      0.89       405
        11.0       1.00      0.59      0.74        17
        12.0       0.80      0.77      0.78       377
        13.0       0.90      0.78      0.83       190
        14.0       0.67      0.18      0.29        76
        15.0       0.72      0.64      0.68        67
        16.0       0.92      0.85      0.88       140
        17.0       0.60      0.84      0.70       183
        18.0       0.79      0.92      0.85        12
        19.0       1.00      0.89      0.94        37
        20.0       0.94      0.91      0.93      2162
        21.0       0.95      0.96      0.96       169
        22.0       0.77      0.84      0.80      1470
        23.0       0.83      0.89      0.86      1259
        24.0       0.94      0.89      0.92       956
        25.0       0.90      0.94      0.92       282
        26.0       0.91      0.86      0.89      3918
        27.0       0.97      0.92      0.94       531
        28.0       1.00      0.77      0.87        13
        29.0       0.82      0.77      0.80      2346
        30.0       0.62      0.74      0.68       615
        31.0       1.00      0.72      0.84        32
        32.0       0.77      0.81      0.79      1450
        33.0       0.91      0.78      0.84       893
        34.0       0.83      0.88      0.85      1376
        35.0       0.69      0.50      0.58        22
        36.0       0.87      0.86      0.86       843
        37.0       0.84      0.90      0.87      1142
        38.0       0.81      0.95      0.87       314
        39.0       0.68      0.49      0.57        55
        40.0       0.83      0.72      0.77       154
        41.0       0.95      0.77      0.85        52
        42.0       0.94      0.79      0.86       247
        43.0       0.92      0.86      0.89       197
        44.0       0.80      0.93      0.86       530
        45.0       0.90      0.90      0.90       540
        46.0       0.00      0.00      0.00        19
        47.0       0.77      0.72      0.75        79
        48.0       0.95      0.99      0.97      1465
        49.0       0.80      0.97      0.87       149
        50.0       0.95      0.94      0.95      1453
        51.0       1.00      0.33      0.50        12
        52.0       0.88      0.89      0.88       152
        53.0       0.94      0.97      0.96       903
        54.0       0.84      0.79      0.81       108
        55.0       0.57      0.94      0.71        93
        56.0       0.79      0.97      0.87        32
        57.0       0.92      0.94      0.93        50
        58.0       0.91      0.68      0.78       154

    accuracy                           0.86     29892
   macro avg       0.83      0.77      0.79     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[820   0   0 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  0   0 142 ...   0   0   0]
 ...
 [  0   0   0 ...  31   0   0]
 [  0   0   0 ...   1  47   1]
 [  0   0   0 ...   0   3 104]]

===multilabel confusion matrix===

[[[28854   126]
  [   92   820]]

 [[29837     3]
  [    9    43]]

 [[29698    15]
  [   37   142]]

 [[29865     2]
  [   21     4]]

 [[29750    30]
  [   55    57]]

 [[29310    90]
  [  120   372]]

 [[29821     6]
  [   12    53]]

 [[29841    13]
  [   22    16]]

 [[29669    18]
  [   34   171]]

 [[29808    13]
  [   15    56]]

 [[29429    58]
  [   36   369]]

 [[29875     0]
  [    7    10]]

 [[29440    75]
  [   86   291]]

 [[29685    17]
  [   42   148]]

 [[29809     7]
  [   62    14]]

 [[29808    17]
  [   24    43]]

 [[29742    10]
  [   21   119]]

 [[29606   103]
  [   29   154]]

 [[29877     3]
  [    1    11]]

 [[29855     0]
  [    4    33]]

 [[27598   132]
  [  185  1977]]

 [[29714     9]
  [    6   163]]

 [[28053   369]
  [  232  1238]]

 [[28403   230]
  [  135  1124]]

 [[28886    50]
  [  105   851]]

 [[29581    29]
  [   18   264]]

 [[25640   334]
  [  534  3384]]

 [[29347    14]
  [   44   487]]

 [[29879     0]
  [    3    10]]

 [[27154   392]
  [  532  1814]]

 [[29002   275]
  [  159   456]]

 [[29860     0]
  [    9    23]]

 [[28089   353]
  [  279  1171]]

 [[28928    71]
  [  194   699]]

 [[28266   250]
  [  164  1212]]

 [[29865     5]
  [   11    11]]

 [[28943   106]
  [  122   721]]

 [[28559   191]
  [  109  1033]]

 [[29507    71]
  [   16   298]]

 [[29824    13]
  [   28    27]]

 [[29715    23]
  [   43   111]]

 [[29838     2]
  [   12    40]]

 [[29632    13]
  [   52   195]]

 [[29681    14]
  [   28   169]]

 [[29238   124]
  [   37   493]]

 [[29298    54]
  [   53   487]]

 [[29873     0]
  [   19     0]]

 [[29796    17]
  [   22    57]]

 [[28346    81]
  [   14  1451]]

 [[29706    37]
  [    5   144]]

 [[28372    67]
  [   80  1373]]

 [[29880     0]
  [    8     4]]

 [[29721    19]
  [   17   135]]

 [[28933    56]
  [   23   880]]

 [[29768    16]
  [   23    85]]

 [[29734    65]
  [    6    87]]

 [[29852     8]
  [    1    31]]

 [[29838     4]
  [    3    47]]

 [[29728    10]
  [   50   104]]]

===scores report===
metrics	scores
Accuracy	0.8625
MCC	0.8553
log_loss	0.5581
f1 score weighted	0.8617
f1 score macro	0.7888
f1 score micro	0.8625
roc_auc ovr	0.9918
roc_auc ovo	0.9902
precision	0.8653
recall	0.8625

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5160367070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5160367400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5160367460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5160367190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.90      0.84       912
         1.0       1.00      0.73      0.84        52
         2.0       0.90      0.77      0.83       179
         3.0       1.00      0.04      0.08        24
         4.0       0.67      0.38      0.49       112
         5.0       0.78      0.75      0.76       492
         6.0       0.94      0.80      0.86        64
         7.0       0.60      0.08      0.14        38
         8.0       0.96      0.79      0.87       205
         9.0       0.94      0.63      0.75        70
        10.0       0.82      0.88      0.85       405
        11.0       0.83      0.29      0.43        17
        12.0       0.78      0.80      0.79       378
        13.0       0.82      0.79      0.80       191
        14.0       0.20      0.01      0.02        76
        15.0       0.78      0.60      0.68        67
        16.0       0.80      0.87      0.84       140
        17.0       0.80      0.78      0.79       183
        18.0       1.00      0.92      0.96        12
        19.0       1.00      0.95      0.97        37
        20.0       0.85      0.95      0.90      2162
        21.0       0.96      0.95      0.95       168
        22.0       0.83      0.83      0.83      1470
        23.0       0.87      0.87      0.87      1259
        24.0       0.94      0.89      0.91       955
        25.0       0.92      0.95      0.93       282
        26.0       0.97      0.81      0.88      3918
        27.0       0.92      0.91      0.92       532
        28.0       1.00      0.92      0.96        13
        29.0       0.56      0.91      0.69      2346
        30.0       0.70      0.74      0.72       616
        31.0       0.86      0.75      0.80        32
        32.0       0.94      0.71      0.81      1449
        33.0       0.77      0.83      0.80       893
        34.0       0.97      0.86      0.91      1377
        35.0       1.00      0.27      0.43        22
        36.0       0.89      0.83      0.86       844
        37.0       0.95      0.83      0.89      1142
        38.0       0.96      0.89      0.92       314
        39.0       0.88      0.62      0.73        56
        40.0       0.98      0.64      0.77       153
        41.0       1.00      0.88      0.94        51
        42.0       0.75      0.79      0.77       246
        43.0       0.99      0.82      0.90       197
        44.0       0.93      0.90      0.92       530
        45.0       0.90      0.88      0.89       540
        46.0       1.00      0.10      0.18        20
        47.0       0.89      0.70      0.78        80
        48.0       0.97      0.99      0.98      1465
        49.0       0.94      0.84      0.89       148
        50.0       0.95      0.94      0.94      1453
        51.0       1.00      0.15      0.27        13
        52.0       0.99      0.82      0.90       151
        53.0       0.96      0.95      0.96       904
        54.0       0.84      0.75      0.79       108
        55.0       0.90      0.95      0.92        93
        56.0       0.94      0.97      0.96        33
        57.0       0.98      0.94      0.96        50
        58.0       0.88      0.89      0.89       153

    accuracy                           0.85     29892
   macro avg       0.88      0.75      0.78     29892
weighted avg       0.87      0.85      0.85     29892


===confusion_matrix===

[[819   0   0 ...   0   0   0]
 [  0  38   0 ...   0   0   0]
 [  1   0 137 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   0]
 [  0   0   0 ...   0  47   3]
 [  0   0   0 ...   1   1 136]]

===multilabel confusion matrix===

[[[28761   219]
  [   93   819]]

 [[29840     0]
  [   14    38]]

 [[29698    15]
  [   42   137]]

 [[29868     0]
  [   23     1]]

 [[29759    21]
  [   69    43]]

 [[29293   107]
  [  123   369]]

 [[29825     3]
  [   13    51]]

 [[29852     2]
  [   35     3]]

 [[29680     7]
  [   43   162]]

 [[29819     3]
  [   26    44]]

 [[29409    78]
  [   48   357]]

 [[29874     1]
  [   12     5]]

 [[29429    85]
  [   77   301]]

 [[29669    32]
  [   41   150]]

 [[29812     4]
  [   75     1]]

 [[29814    11]
  [   27    40]]

 [[29722    30]
  [   18   122]]

 [[29673    36]
  [   41   142]]

 [[29880     0]
  [    1    11]]

 [[29855     0]
  [    2    35]]

 [[27369   361]
  [  112  2050]]

 [[29717     7]
  [    9   159]]

 [[28167   255]
  [  252  1218]]

 [[28472   161]
  [  160  1099]]

 [[28887    50]
  [  108   847]]

 [[29586    24]
  [   14   268]]

 [[25859   115]
  [  744  3174]]

 [[29317    43]
  [   46   486]]

 [[29879     0]
  [    1    12]]

 [[25876  1670]
  [  222  2124]]

 [[29078   198]
  [  162   454]]

 [[29856     4]
  [    8    24]]

 [[28373    70]
  [  416  1033]]

 [[28782   217]
  [  148   745]]

 [[28479    36]
  [  189  1188]]

 [[29870     0]
  [   16     6]]

 [[28965    83]
  [  141   703]]

 [[28703    47]
  [  189   953]]

 [[29566    12]
  [   36   278]]

 [[29831     5]
  [   21    35]]

 [[29737     2]
  [   55    98]]

 [[29841     0]
  [    6    45]]

 [[29580    66]
  [   52   194]]

 [[29694     1]
  [   36   161]]

 [[29328    34]
  [   54   476]]

 [[29301    51]
  [   65   475]]

 [[29872     0]
  [   18     2]]

 [[29805     7]
  [   24    56]]

 [[28380    47]
  [   19  1446]]

 [[29736     8]
  [   23   125]]

 [[28362    77]
  [   83  1370]]

 [[29879     0]
  [   11     2]]

 [[29740     1]
  [   27   124]]

 [[28954    34]
  [   44   860]]

 [[29768    16]
  [   27    81]]

 [[29789    10]
  [    5    88]]

 [[29857     2]
  [    1    32]]

 [[29841     1]
  [    3    47]]

 [[29721    18]
  [   17   136]]]

===scores report===
metrics	scores
Accuracy	0.8532
MCC	0.8467
log_loss	0.5807
f1 score weighted	0.8549
f1 score macro	0.7781
f1 score micro	0.8532
roc_auc ovr	0.9921
roc_auc ovo	0.9905
precision	0.8721
recall	0.8532

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5160367070>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5160367400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5160367460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5160367190>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.90      0.87       911
         1.0       1.00      0.62      0.77        53
         2.0       0.99      0.74      0.85       180
         3.0       0.67      0.24      0.35        25
         4.0       0.98      0.38      0.55       111
         5.0       0.75      0.71      0.73       491
         6.0       0.97      0.91      0.94        64
         7.0       1.00      0.41      0.58        37
         8.0       0.80      0.85      0.82       205
         9.0       0.95      0.76      0.84        71
        10.0       0.81      0.90      0.85       404
        11.0       1.00      0.12      0.21        17
        12.0       0.95      0.74      0.83       378
        13.0       0.88      0.74      0.80       191
        14.0       0.56      0.12      0.20        76
        15.0       0.94      0.52      0.67        66
        16.0       0.94      0.74      0.82       140
        17.0       0.90      0.71      0.79       182
        18.0       0.92      1.00      0.96        12
        19.0       1.00      0.65      0.79        37
        20.0       0.95      0.91      0.93      2162
        21.0       0.93      0.92      0.92       168
        22.0       0.70      0.86      0.77      1470
        23.0       0.88      0.84      0.86      1259
        24.0       0.95      0.89      0.92       955
        25.0       0.92      0.94      0.93       283
        26.0       0.82      0.92      0.87      3919
        27.0       0.96      0.91      0.93       532
        28.0       1.00      0.77      0.87        13
        29.0       0.70      0.82      0.76      2345
        30.0       0.82      0.58      0.68       616
        31.0       1.00      0.81      0.90        32
        32.0       0.80      0.77      0.79      1449
        33.0       0.94      0.73      0.82       893
        34.0       0.86      0.90      0.88      1377
        35.0       1.00      0.55      0.71        22
        36.0       0.87      0.84      0.85       844
        37.0       0.80      0.90      0.85      1142
        38.0       0.88      0.92      0.90       314
        39.0       0.89      0.59      0.71        56
        40.0       0.91      0.67      0.77       153
        41.0       0.96      0.85      0.90        52
        42.0       0.93      0.77      0.84       247
        43.0       0.97      0.83      0.90       197
        44.0       0.96      0.87      0.91       529
        45.0       0.98      0.90      0.94       540
        46.0       1.00      0.10      0.18        20
        47.0       0.73      0.80      0.76        80
        48.0       0.97      0.98      0.97      1466
        49.0       0.96      0.86      0.91       148
        50.0       0.98      0.94      0.96      1453
        51.0       1.00      0.25      0.40        12
        52.0       0.97      0.84      0.90       151
        53.0       0.96      0.96      0.96       904
        54.0       0.90      0.74      0.81       108
        55.0       0.93      0.90      0.92        93
        56.0       1.00      0.88      0.94        33
        57.0       0.94      0.88      0.91        50
        58.0       0.90      0.90      0.90       154

    accuracy                           0.86     29892
   macro avg       0.91      0.75      0.79     29892
weighted avg       0.87      0.86      0.86     29892


===confusion_matrix===

[[818   0   0 ...   0   0   0]
 [  0  33   0 ...   0   0   0]
 [  0   0 134 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   1]
 [  0   0   0 ...   0  44   3]
 [  0   0   0 ...   0   3 139]]

===multilabel confusion matrix===

[[[28828   153]
  [   93   818]]

 [[29839     0]
  [   20    33]]

 [[29710     2]
  [   46   134]]

 [[29864     3]
  [   19     6]]

 [[29780     1]
  [   69    42]]

 [[29288   113]
  [  144   347]]

 [[29826     2]
  [    6    58]]

 [[29855     0]
  [   22    15]]

 [[29644    43]
  [   31   174]]

 [[29818     3]
  [   17    54]]

 [[29403    85]
  [   41   363]]

 [[29875     0]
  [   15     2]]

 [[29498    16]
  [  100   278]]

 [[29681    20]
  [   49   142]]

 [[29809     7]
  [   67     9]]

 [[29824     2]
  [   32    34]]

 [[29745     7]
  [   37   103]]

 [[29696    14]
  [   53   129]]

 [[29879     1]
  [    0    12]]

 [[29855     0]
  [   13    24]]

 [[27636    94]
  [  194  1968]]

 [[29712    12]
  [   14   154]]

 [[27873   549]
  [  203  1267]]

 [[28492   141]
  [  205  1054]]

 [[28890    47]
  [  101   854]]

 [[29587    22]
  [   17   266]]

 [[25164   809]
  [  297  3622]]

 [[29339    21]
  [   50   482]]

 [[29879     0]
  [    3    10]]

 [[26730   817]
  [  424  1921]]

 [[29195    81]
  [  258   358]]

 [[29860     0]
  [    6    26]]

 [[28168   275]
  [  332  1117]]

 [[28955    44]
  [  239   654]]

 [[28305   210]
  [  132  1245]]

 [[29870     0]
  [   10    12]]

 [[28938   110]
  [  136   708]]

 [[28499   251]
  [  118  1024]]

 [[29540    38]
  [   26   288]]

 [[29832     4]
  [   23    33]]

 [[29729    10]
  [   50   103]]

 [[29838     2]
  [    8    44]]

 [[29631    14]
  [   57   190]]

 [[29690     5]
  [   33   164]]

 [[29344    19]
  [   71   458]]

 [[29342    10]
  [   56   484]]

 [[29872     0]
  [   18     2]]

 [[29788    24]
  [   16    64]]

 [[28374    52]
  [   24  1442]]

 [[29739     5]
  [   20   128]]

 [[28415    24]
  [   92  1361]]

 [[29880     0]
  [    9     3]]

 [[29737     4]
  [   24   127]]

 [[28954    34]
  [   32   872]]

 [[29775     9]
  [   28    80]]

 [[29793     6]
  [    9    84]]

 [[29859     0]
  [    4    29]]

 [[29839     3]
  [    6    44]]

 [[29722    16]
  [   15   139]]]

===scores report===
metrics	scores
Accuracy	0.8584
MCC	0.8507
log_loss	0.5643
f1 score weighted	0.8570
f1 score macro	0.7938
f1 score micro	0.8584
roc_auc ovr	0.9920
roc_auc ovo	0.9897
precision	0.8660
recall	0.8584

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8495584102769972	0.8416204885591445	0.6146036745302501	0.8484188618028808	0.7714270671110671	0.8495584102769971	0.9911536767277893	0.988568240414169	0.8603278646106545	0.8495584102769972
1	0.8583567509701593	0.8507631553307365	0.5754701382991302	0.8589848325725913	0.7962788232295747	0.8583567509701593	0.9919019942817209	0.989887604754892	0.8687957734116565	0.8583567509701593
2	0.8625050180650341	0.8553412504366192	0.5581259680970534	0.8617372367453693	0.7888112827479997	0.8625050180650341	0.9918153921983995	0.9901584243221799	0.8652857841433061	0.8625050180650341
3	0.853238324635354	0.8466627774816065	0.580745269700555	0.8548671979849937	0.7781248474248298	0.853238324635354	0.992088233936606	0.9904920191092508	0.8720569502364036	0.853238324635354
4	0.8583567509701593	0.8506512164593678	0.5642636182068639	0.8569782733181219	0.7938396363392345	0.8583567509701593	0.991985691397958	0.9896891761121327	0.8659516298729244	0.8583567509701593
mean	0.8564030509835406	0.849007777653495	0.5786417337667704	0.8561972804847914	0.7856963313705412	0.8564030509835406	0.9917889977084947	0.9897590929425248	0.8664836004549891	0.8564030509835406
std	0.0045107092302571605	0.004603611307715912	0.019674206020980196	0.004502097921289376	0.00947570307143966	0.004510709230257194	0.000330250926076395	0.0006536328801445416	0.003899210483405055	0.0045107092302571605

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 65395.9415 secs

