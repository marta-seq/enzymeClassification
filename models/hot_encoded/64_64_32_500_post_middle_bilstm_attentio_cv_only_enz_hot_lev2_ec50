/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_middle_bilstm_attentio_cv_only_enz_hot_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff1385b56a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff1385b57f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff1385b58b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff1385b55e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.80      0.73       402
         1.0       0.86      0.32      0.46        19
         2.0       0.27      0.74      0.39        82
         3.0       0.00      0.00      0.00        16
         4.0       0.25      0.21      0.23        62
         5.0       0.51      0.60      0.55       277
         6.0       0.69      0.67      0.68        36
         7.0       0.29      0.08      0.12        26
         8.0       0.86      0.43      0.57        72
         9.0       0.76      0.63      0.69        30
        10.0       0.77      0.69      0.73       156
        11.0       0.36      0.49      0.41       168
        12.0       0.34      0.66      0.45        83
        13.0       0.38      0.09      0.15        53
        14.0       0.62      0.26      0.36        31
        15.0       0.46      0.50      0.48        52
        16.0       0.54      0.63      0.58        94
        17.0       0.86      0.80      0.83       885
        18.0       0.95      0.73      0.82        48
        19.0       0.81      0.59      0.68       781
        20.0       0.92      0.66      0.77       591
        21.0       0.90      0.63      0.74       385
        22.0       0.62      0.86      0.72       128
        23.0       0.76      0.79      0.77      1888
        24.0       0.63      0.73      0.68       169
        25.0       0.77      0.55      0.64      1296
        26.0       0.66      0.58      0.62       381
        27.0       0.56      0.36      0.43        14
        28.0       0.63      0.62      0.62       769
        29.0       0.29      0.65      0.40       372
        30.0       0.94      0.69      0.80       631
        31.0       0.43      0.27      0.33        11
        32.0       0.50      0.66      0.57       316
        33.0       0.67      0.62      0.64       405
        34.0       0.86      0.53      0.66        96
        35.0       0.00      0.00      0.00        26
        36.0       0.83      0.31      0.45        65
        37.0       0.85      0.52      0.65        21
        38.0       0.67      0.64      0.65       121
        39.0       0.69      0.73      0.71       114
        40.0       0.86      0.76      0.81       207
        41.0       0.67      0.71      0.69       194
        42.0       0.78      0.45      0.57        47
        43.0       0.70      0.93      0.80       431
        44.0       0.95      0.58      0.72        67
        45.0       0.59      0.86      0.70       488
        46.0       0.68      0.71      0.69        62
        47.0       0.82      0.87      0.85       264
        48.0       0.89      0.51      0.65        49
        49.0       0.86      0.60      0.71        30
        50.0       0.55      0.73      0.63        15
        51.0       0.94      0.81      0.87        21
        52.0       0.69      0.81      0.75        73

    accuracy                           0.68     13120
   macro avg       0.65      0.58      0.59     13120
weighted avg       0.72      0.68      0.69     13120


===confusion_matrix===

[[323   0   1 ...   0   0   0]
 [  1   6   1 ...   0   0   0]
 [  0   0  61 ...   0   0   0]
 ...
 [  0   0   0 ...  11   1   0]
 [  0   0   0 ...   0  17   3]
 [  0   0   0 ...   5   0  59]]

===multilabel confusion matrix===

[[[12554   164]
  [   79   323]]

 [[13100     1]
  [   13     6]]

 [[12871   167]
  [   21    61]]

 [[13096     8]
  [   16     0]]

 [[13020    38]
  [   49    13]]

 [[12684   159]
  [  110   167]]

 [[13073    11]
  [   12    24]]

 [[13089     5]
  [   24     2]]

 [[13043     5]
  [   41    31]]

 [[13084     6]
  [   11    19]]

 [[12932    32]
  [   48   108]]

 [[12805   147]
  [   86    82]]

 [[12929   108]
  [   28    55]]

 [[13059     8]
  [   48     5]]

 [[13084     5]
  [   23     8]]

 [[13038    30]
  [   26    26]]

 [[12976    50]
  [   35    59]]

 [[12116   119]
  [  174   711]]

 [[13070     2]
  [   13    35]]

 [[12230   109]
  [  324   457]]

 [[12497    32]
  [  198   393]]

 [[12708    27]
  [  141   244]]

 [[12926    66]
  [   18   110]]

 [[10751   481]
  [  402  1486]]

 [[12880    71]
  [   46   123]]

 [[11605   219]
  [  580   716]]

 [[12624   115]
  [  159   222]]

 [[13102     4]
  [    9     5]]

 [[12072   279]
  [  294   475]]

 [[12162   586]
  [  130   242]]

 [[12462    27]
  [  196   435]]

 [[13105     4]
  [    8     3]]

 [[12598   206]
  [  109   207]]

 [[12588   127]
  [  152   253]]

 [[13016     8]
  [   45    51]]

 [[13093     1]
  [   26     0]]

 [[13051     4]
  [   45    20]]

 [[13097     2]
  [   10    11]]

 [[12961    38]
  [   44    77]]

 [[12968    38]
  [   31    83]]

 [[12887    26]
  [   49   158]]

 [[12859    67]
  [   56   138]]

 [[13067     6]
  [   26    21]]

 [[12515   174]
  [   30   401]]

 [[13051     2]
  [   28    39]]

 [[12338   294]
  [   67   421]]

 [[13037    21]
  [   18    44]]

 [[12807    49]
  [   34   230]]

 [[13068     3]
  [   24    25]]

 [[13087     3]
  [   12    18]]

 [[13096     9]
  [    4    11]]

 [[13098     1]
  [    4    17]]

 [[13021    26]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.6806
MCC	0.6636
log_loss	1.3585
f1 score weighted	0.6858
f1 score macro	0.5891
f1 score micro	0.6806
roc_auc ovr	0.9627
roc_auc ovo	0.9635
precision	0.7190
recall	0.6806

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff1385b56a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff1385b57f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff1385b58b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff1385b55e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.56      0.82      0.66       402
         1.0       0.90      0.47      0.62        19
         2.0       0.64      0.57      0.60        81
         3.0       0.00      0.00      0.00        16
         4.0       0.60      0.40      0.48        62
         5.0       0.67      0.58      0.62       277
         6.0       0.93      0.72      0.81        36
         7.0       0.60      0.12      0.19        26
         8.0       0.65      0.49      0.56        73
         9.0       0.62      0.34      0.44        29
        10.0       0.79      0.63      0.70       156
        11.0       0.44      0.62      0.51       168
        12.0       0.52      0.55      0.54        83
        13.0       0.25      0.09      0.14        53
        14.0       0.62      0.50      0.55        32
        15.0       0.59      0.31      0.41        52
        16.0       0.66      0.63      0.65        95
        17.0       0.84      0.82      0.83       884
        18.0       0.89      0.69      0.78        48
        19.0       0.65      0.71      0.68       782
        20.0       0.90      0.60      0.72       591
        21.0       0.79      0.74      0.76       385
        22.0       0.78      0.84      0.81       128
        23.0       0.80      0.80      0.80      1888
        24.0       0.74      0.69      0.71       169
        25.0       0.59      0.74      0.66      1295
        26.0       0.66      0.58      0.62       381
        27.0       1.00      0.43      0.60        14
        28.0       0.73      0.61      0.67       769
        29.0       0.52      0.61      0.56       371
        30.0       0.83      0.76      0.79       631
        31.0       1.00      0.27      0.43        11
        32.0       0.43      0.66      0.52       316
        33.0       0.58      0.65      0.61       405
        34.0       0.56      0.64      0.60        96
        35.0       0.57      0.15      0.24        26
        36.0       0.93      0.43      0.59        65
        37.0       0.88      0.68      0.77        22
        38.0       0.62      0.59      0.60       121
        39.0       0.80      0.76      0.78       113
        40.0       0.69      0.75      0.72       208
        41.0       0.89      0.63      0.74       193
        42.0       0.65      0.43      0.52        46
        43.0       0.95      0.93      0.94       431
        44.0       0.72      0.58      0.64        66
        45.0       0.83      0.80      0.82       489
        46.0       0.79      0.68      0.73        62
        47.0       0.86      0.87      0.86       264
        48.0       1.00      0.45      0.62        49
        49.0       0.77      0.87      0.82        31
        50.0       1.00      0.81      0.90        16
        51.0       0.90      0.86      0.88        21
        52.0       0.82      0.85      0.83        73

    accuracy                           0.71     13120
   macro avg       0.72      0.60      0.63     13120
weighted avg       0.73      0.71      0.71     13120


===confusion_matrix===

[[330   0   0 ...   0   0   0]
 [  0   9   0 ...   0   0   0]
 [  1   0  46 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   1]
 [  0   0   0 ...   0  18   3]
 [  0   0   0 ...   0   2  62]]

===multilabel confusion matrix===

[[[12457   261]
  [   72   330]]

 [[13100     1]
  [   10     9]]

 [[13013    26]
  [   35    46]]

 [[13104     0]
  [   16     0]]

 [[13041    17]
  [   37    25]]

 [[12762    81]
  [  115   162]]

 [[13082     2]
  [   10    26]]

 [[13092     2]
  [   23     3]]

 [[13028    19]
  [   37    36]]

 [[13085     6]
  [   19    10]]

 [[12937    27]
  [   57    99]]

 [[12816   136]
  [   63   105]]

 [[12995    42]
  [   37    46]]

 [[13052    15]
  [   48     5]]

 [[13078    10]
  [   16    16]]

 [[13057    11]
  [   36    16]]

 [[12994    31]
  [   35    60]]

 [[12099   137]
  [  158   726]]

 [[13068     4]
  [   15    33]]

 [[12039   299]
  [  230   552]]

 [[12488    41]
  [  234   357]]

 [[12661    74]
  [  101   284]]

 [[12962    30]
  [   21   107]]

 [[10861   371]
  [  387  1501]]

 [[12910    41]
  [   53   116]]

 [[11171   654]
  [  336   959]]

 [[12628   111]
  [  161   220]]

 [[13106     0]
  [    8     6]]

 [[12179   172]
  [  300   469]]

 [[12539   210]
  [  144   227]]

 [[12388   101]
  [  153   478]]

 [[13109     0]
  [    8     3]]

 [[12523   281]
  [  107   209]]

 [[12525   190]
  [  143   262]]

 [[12976    48]
  [   35    61]]

 [[13091     3]
  [   22     4]]

 [[13053     2]
  [   37    28]]

 [[13096     2]
  [    7    15]]

 [[12956    43]
  [   50    71]]

 [[12985    22]
  [   27    86]]

 [[12841    71]
  [   51   157]]

 [[12912    15]
  [   71   122]]

 [[13063    11]
  [   26    20]]

 [[12667    22]
  [   30   401]]

 [[13039    15]
  [   28    38]]

 [[12552    79]
  [   96   393]]

 [[13047    11]
  [   20    42]]

 [[12819    37]
  [   35   229]]

 [[13071     0]
  [   27    22]]

 [[13081     8]
  [    4    27]]

 [[13104     0]
  [    3    13]]

 [[13097     2]
  [    3    18]]

 [[13033    14]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.7098
MCC	0.6925
log_loss	1.1956
f1 score weighted	0.7102
f1 score macro	0.6345
f1 score micro	0.7098
roc_auc ovr	0.9654
roc_auc ovo	0.9653
precision	0.7258
recall	0.7098

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff1385b56a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff1385b57f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff1385b58b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff1385b55e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.62      0.81      0.70       401
         1.0       0.89      0.40      0.55        20
         2.0       0.95      0.46      0.62        82
         3.0       0.33      0.06      0.11        16
         4.0       0.40      0.26      0.31        62
         5.0       0.61      0.66      0.64       277
         6.0       0.75      0.83      0.79        36
         7.0       0.55      0.24      0.33        25
         8.0       0.82      0.45      0.58        73
         9.0       0.73      0.55      0.63        29
        10.0       0.85      0.68      0.75       156
        11.0       0.58      0.50      0.54       168
        12.0       0.66      0.51      0.57        83
        13.0       0.29      0.11      0.16        54
        14.0       0.25      0.29      0.27        31
        15.0       0.79      0.43      0.56        53
        16.0       0.79      0.59      0.67        95
        17.0       0.85      0.83      0.84       884
        18.0       0.78      0.77      0.77        47
        19.0       0.66      0.70      0.68       782
        20.0       0.47      0.85      0.60       592
        21.0       0.75      0.74      0.75       385
        22.0       0.92      0.80      0.85       128
        23.0       0.81      0.75      0.78      1887
        24.0       0.88      0.67      0.76       168
        25.0       0.65      0.69      0.67      1295
        26.0       0.52      0.63      0.57       381
        27.0       0.71      0.71      0.71        14
        28.0       0.68      0.61      0.64       768
        29.0       0.59      0.58      0.59       372
        30.0       0.80      0.77      0.79       631
        31.0       0.00      0.00      0.00        10
        32.0       0.58      0.60      0.59       316
        33.0       0.59      0.67      0.63       405
        34.0       0.80      0.62      0.70        96
        35.0       0.50      0.04      0.07        26
        36.0       0.81      0.45      0.58        66
        37.0       1.00      0.59      0.74        22
        38.0       0.64      0.60      0.62       121
        39.0       0.95      0.77      0.85       113
        40.0       0.73      0.74      0.74       208
        41.0       0.88      0.63      0.74       194
        42.0       0.70      0.57      0.63        46
        43.0       0.91      0.93      0.92       431
        44.0       0.77      0.65      0.70        66
        45.0       0.95      0.75      0.84       489
        46.0       0.91      0.66      0.77        62
        47.0       0.90      0.83      0.86       263
        48.0       0.62      0.70      0.66        50
        49.0       0.78      0.45      0.57        31
        50.0       0.56      0.94      0.70        16
        51.0       0.71      0.81      0.76        21
        52.0       0.77      0.79      0.78        73

    accuracy                           0.71     13120
   macro avg       0.70      0.60      0.63     13120
weighted avg       0.72      0.71      0.71     13120


===confusion_matrix===

[[326   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  0   0  38 ...   0   0   1]
 ...
 [  0   0   0 ...  15   0   0]
 [  0   0   0 ...   0  17   3]
 [  0   0   0 ...   0   7  58]]

===multilabel confusion matrix===

[[[12520   199]
  [   75   326]]

 [[13099     1]
  [   12     8]]

 [[13036     2]
  [   44    38]]

 [[13102     2]
  [   15     1]]

 [[13034    24]
  [   46    16]]

 [[12729   114]
  [   95   182]]

 [[13074    10]
  [    6    30]]

 [[13090     5]
  [   19     6]]

 [[13040     7]
  [   40    33]]

 [[13085     6]
  [   13    16]]

 [[12945    19]
  [   50   106]]

 [[12892    60]
  [   84    84]]

 [[13015    22]
  [   41    42]]

 [[13051    15]
  [   48     6]]

 [[13062    27]
  [   22     9]]

 [[13061     6]
  [   30    23]]

 [[13010    15]
  [   39    56]]

 [[12104   132]
  [  153   731]]

 [[13063    10]
  [   11    36]]

 [[12054   284]
  [  231   551]]

 [[11951   577]
  [   87   505]]

 [[12640    95]
  [   99   286]]

 [[12983     9]
  [   26   102]]

 [[10898   335]
  [  466  1421]]

 [[12936    16]
  [   56   112]]

 [[11332   493]
  [  398   897]]

 [[12514   225]
  [  141   240]]

 [[13102     4]
  [    4    10]]

 [[12136   216]
  [  302   466]]

 [[12600   148]
  [  157   215]]

 [[12367   122]
  [  143   488]]

 [[13108     2]
  [   10     0]]

 [[12668   136]
  [  125   191]]

 [[12527   188]
  [  135   270]]

 [[13009    15]
  [   36    60]]

 [[13093     1]
  [   25     1]]

 [[13047     7]
  [   36    30]]

 [[13098     0]
  [    9    13]]

 [[12958    41]
  [   48    73]]

 [[13002     5]
  [   26    87]]

 [[12856    56]
  [   54   154]]

 [[12909    17]
  [   71   123]]

 [[13063    11]
  [   20    26]]

 [[12651    38]
  [   32   399]]

 [[13041    13]
  [   23    43]]

 [[12611    20]
  [  120   369]]

 [[13054     4]
  [   21    41]]

 [[12832    25]
  [   44   219]]

 [[13049    21]
  [   15    35]]

 [[13085     4]
  [   17    14]]

 [[13092    12]
  [    1    15]]

 [[13092     7]
  [    4    17]]

 [[13030    17]
  [   15    58]]]

===scores report===
metrics	scores
Accuracy	0.7073
MCC	0.6904
log_loss	1.2060
f1 score weighted	0.7082
f1 score macro	0.6273
f1 score micro	0.7073
roc_auc ovr	0.9663
roc_auc ovo	0.9670
precision	0.7246
recall	0.7073

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff1385b56a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff1385b57f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff1385b58b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff1385b55e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.68      0.80      0.73       401
         1.0       0.75      0.30      0.43        20
         2.0       0.67      0.61      0.64        82
         3.0       0.00      0.00      0.00        15
         4.0       0.30      0.27      0.29        62
         5.0       0.58      0.59      0.59       278
         6.0       0.63      0.67      0.65        36
         7.0       0.86      0.24      0.38        25
         8.0       0.66      0.62      0.64        73
         9.0       0.69      0.62      0.65        29
        10.0       0.87      0.70      0.78       156
        11.0       0.53      0.51      0.52       168
        12.0       0.90      0.31      0.46        83
        13.0       0.11      0.06      0.07        54
        14.0       0.46      0.52      0.48        31
        15.0       0.56      0.34      0.42        53
        16.0       0.62      0.64      0.63        95
        17.0       0.79      0.83      0.81       884
        18.0       0.94      0.70      0.80        47
        19.0       0.72      0.68      0.70       781
        20.0       0.74      0.74      0.74       592
        21.0       0.58      0.82      0.68       385
        22.0       0.79      0.80      0.79       129
        23.0       0.76      0.83      0.79      1887
        24.0       0.80      0.70      0.74       168
        25.0       0.63      0.70      0.66      1295
        26.0       0.61      0.57      0.59       381
        27.0       0.86      0.46      0.60        13
        28.0       0.70      0.66      0.68       769
        29.0       0.60      0.54      0.57       372
        30.0       0.77      0.84      0.81       631
        31.0       0.71      0.45      0.56        11
        32.0       0.62      0.48      0.54       316
        33.0       0.66      0.67      0.67       405
        34.0       0.68      0.61      0.64        95
        35.0       0.11      0.04      0.06        25
        36.0       0.30      0.55      0.38        66
        37.0       0.47      0.68      0.56        22
        38.0       0.87      0.60      0.71       121
        39.0       0.84      0.77      0.81       113
        40.0       0.84      0.69      0.75       208
        41.0       0.71      0.71      0.71       194
        42.0       0.61      0.67      0.64        46
        43.0       0.89      0.90      0.90       431
        44.0       0.88      0.64      0.74        66
        45.0       0.97      0.74      0.84       489
        46.0       1.00      0.81      0.89        62
        47.0       0.87      0.86      0.86       263
        48.0       0.87      0.52      0.65        50
        49.0       0.74      0.90      0.81        31
        50.0       0.86      0.75      0.80        16
        51.0       0.78      0.82      0.80        22
        52.0       0.90      0.85      0.87        73

    accuracy                           0.72     13120
   macro avg       0.69      0.61      0.63     13120
weighted avg       0.72      0.72      0.71     13120


===confusion_matrix===

[[319   0   1 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0  50 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   0  18   3]
 [  0   0   0 ...   1   4  62]]

===multilabel confusion matrix===

[[[12568   151]
  [   82   319]]

 [[13098     2]
  [   14     6]]

 [[13013    25]
  [   32    50]]

 [[13105     0]
  [   15     0]]

 [[13018    40]
  [   45    17]]

 [[12721   121]
  [  113   165]]

 [[13070    14]
  [   12    24]]

 [[13094     1]
  [   19     6]]

 [[13024    23]
  [   28    45]]

 [[13083     8]
  [   11    18]]

 [[12948    16]
  [   47   109]]

 [[12875    77]
  [   82    86]]

 [[13034     3]
  [   57    26]]

 [[13042    24]
  [   51     3]]

 [[13070    19]
  [   15    16]]

 [[13053    14]
  [   35    18]]

 [[12988    37]
  [   34    61]]

 [[12046   190]
  [  149   735]]

 [[13071     2]
  [   14    33]]

 [[12137   202]
  [  251   530]]

 [[12373   155]
  [  153   439]]

 [[12507   228]
  [   70   315]]

 [[12963    28]
  [   26   103]]

 [[10737   496]
  [  319  1568]]

 [[12922    30]
  [   51   117]]

 [[11294   531]
  [  391   904]]

 [[12598   141]
  [  164   217]]

 [[13106     1]
  [    7     6]]

 [[12136   215]
  [  262   507]]

 [[12613   135]
  [  170   202]]

 [[12332   157]
  [   99   532]]

 [[13107     2]
  [    6     5]]

 [[12710    94]
  [  163   153]]

 [[12575   140]
  [  133   272]]

 [[12998    27]
  [   37    58]]

 [[13087     8]
  [   24     1]]

 [[12968    86]
  [   30    36]]

 [[13081    17]
  [    7    15]]

 [[12988    11]
  [   49    72]]

 [[12991    16]
  [   26    87]]

 [[12884    28]
  [   65   143]]

 [[12870    56]
  [   57   137]]

 [[13054    20]
  [   15    31]]

 [[12641    48]
  [   43   388]]

 [[13048     6]
  [   24    42]]

 [[12619    12]
  [  125   364]]

 [[13058     0]
  [   12    50]]

 [[12824    33]
  [   38   225]]

 [[13066     4]
  [   24    26]]

 [[13079    10]
  [    3    28]]

 [[13102     2]
  [    4    12]]

 [[13093     5]
  [    4    18]]

 [[13040     7]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.7166
MCC	0.6991
log_loss	1.1736
f1 score weighted	0.7142
f1 score macro	0.6324
f1 score micro	0.7166
roc_auc ovr	0.9673
roc_auc ovo	0.9646
precision	0.7217
recall	0.7166

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff1385b56a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff1385b57f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff1385b58b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff1385b55e0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.69      0.76       402
         1.0       0.69      0.58      0.63        19
         2.0       0.76      0.45      0.56        82
         3.0       0.00      0.00      0.00        16
         4.0       0.31      0.13      0.18        62
         5.0       0.71      0.55      0.62       278
         6.0       0.96      0.67      0.79        36
         7.0       1.00      0.23      0.38        26
         8.0       0.90      0.37      0.52        73
         9.0       0.63      0.57      0.60        30
        10.0       0.95      0.60      0.73       156
        11.0       0.79      0.37      0.50       169
        12.0       0.80      0.54      0.65        83
        13.0       0.00      0.00      0.00        53
        14.0       0.59      0.32      0.42        31
        15.0       0.72      0.25      0.37        52
        16.0       0.70      0.46      0.56        95
        17.0       0.77      0.83      0.80       885
        18.0       0.71      0.60      0.65        48
        19.0       0.80      0.63      0.71       781
        20.0       0.56      0.79      0.65       592
        21.0       0.88      0.73      0.80       384
        22.0       0.87      0.76      0.81       128
        23.0       0.78      0.79      0.78      1887
        24.0       0.86      0.64      0.73       168
        25.0       0.48      0.80      0.60      1295
        26.0       0.50      0.57      0.53       381
        27.0       0.83      0.36      0.50        14
        28.0       0.69      0.62      0.65       769
        29.0       0.59      0.46      0.51       372
        30.0       0.74      0.82      0.78       630
        31.0       0.80      0.36      0.50        11
        32.0       0.42      0.63      0.50       316
        33.0       0.77      0.61      0.68       405
        34.0       0.84      0.64      0.73        95
        35.0       0.00      0.00      0.00        25
        36.0       0.77      0.37      0.50        65
        37.0       0.76      0.73      0.74        22
        38.0       0.71      0.51      0.60       121
        39.0       0.98      0.72      0.83       113
        40.0       0.83      0.72      0.77       208
        41.0       0.87      0.58      0.69       194
        42.0       0.93      0.28      0.43        47
        43.0       0.82      0.94      0.88       431
        44.0       0.82      0.80      0.81        66
        45.0       0.94      0.77      0.85       488
        46.0       0.84      0.75      0.79        63
        47.0       0.80      0.84      0.82       263
        48.0       0.72      0.47      0.57        49
        49.0       0.74      0.67      0.70        30
        50.0       0.85      0.73      0.79        15
        51.0       0.59      0.86      0.70        22
        52.0       0.72      0.70      0.71        73

    accuracy                           0.70     13119
   macro avg       0.72      0.56      0.61     13119
weighted avg       0.72      0.70      0.69     13119


===confusion_matrix===

[[277   0   0 ...   0   0   0]
 [  0  11   0 ...   0   0   1]
 [  0   0  37 ...   0   0   0]
 ...
 [  0   0   0 ...  11   2   0]
 [  0   0   0 ...   0  19   3]
 [  0   0   0 ...   0  11  51]]

===multilabel confusion matrix===

[[[12664    53]
  [  125   277]]

 [[13095     5]
  [    8    11]]

 [[13025    12]
  [   45    37]]

 [[13102     1]
  [   16     0]]

 [[13039    18]
  [   54     8]]

 [[12777    64]
  [  124   154]]

 [[13082     1]
  [   12    24]]

 [[13093     0]
  [   20     6]]

 [[13043     3]
  [   46    27]]

 [[13079    10]
  [   13    17]]

 [[12958     5]
  [   63    93]]

 [[12934    16]
  [  107    62]]

 [[13025    11]
  [   38    45]]

 [[13065     1]
  [   53     0]]

 [[13081     7]
  [   21    10]]

 [[13062     5]
  [   39    13]]

 [[13005    19]
  [   51    44]]

 [[12015   219]
  [  149   736]]

 [[13059    12]
  [   19    29]]

 [[12215   123]
  [  288   493]]

 [[12154   373]
  [  125   467]]

 [[12695    40]
  [  104   280]]

 [[12977    14]
  [   31    97]]

 [[10815   417]
  [  405  1482]]

 [[12933    18]
  [   60   108]]

 [[10710  1114]
  [  265  1030]]

 [[12522   216]
  [  164   217]]

 [[13104     1]
  [    9     5]]

 [[12140   210]
  [  293   476]]

 [[12628   119]
  [  202   170]]

 [[12303   186]
  [  111   519]]

 [[13107     1]
  [    7     4]]

 [[12522   281]
  [  116   200]]

 [[12642    72]
  [  159   246]]

 [[13012    12]
  [   34    61]]

 [[13093     1]
  [   25     0]]

 [[13047     7]
  [   41    24]]

 [[13092     5]
  [    6    16]]

 [[12973    25]
  [   59    62]]

 [[13004     2]
  [   32    81]]

 [[12881    30]
  [   58   150]]

 [[12908    17]
  [   82   112]]

 [[13071     1]
  [   34    13]]

 [[12599    89]
  [   24   407]]

 [[13041    12]
  [   13    53]]

 [[12608    23]
  [  113   375]]

 [[13047     9]
  [   16    47]]

 [[12801    55]
  [   42   221]]

 [[13061     9]
  [   26    23]]

 [[13082     7]
  [   10    20]]

 [[13102     2]
  [    4    11]]

 [[13084    13]
  [    3    19]]

 [[13026    20]
  [   22    51]]]

===scores report===
metrics	scores
Accuracy	0.6962
MCC	0.6780
log_loss	1.2434
f1 score weighted	0.6946
f1 score macro	0.6105
f1 score micro	0.6962
roc_auc ovr	0.9646
roc_auc ovo	0.9619
precision	0.7217
recall	0.6962

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.680640243902439	0.6636105430006137	1.3585179381957524	0.6858284972785287	0.5891263394496519	0.680640243902439	0.9626585725516071	0.9635260320663313	0.7189736732423861	0.680640243902439
1	0.7097560975609756	0.6924701021632214	1.1956220923042693	0.7101512112418661	0.6345258390177387	0.7097560975609755	0.965444655937941	0.9653032937704903	0.725831836619476	0.7097560975609756
2	0.7073170731707317	0.690362555696522	1.2060489527245533	0.7081923796556919	0.6272714983642852	0.7073170731707317	0.9663293941663019	0.9670295412418597	0.72463509960473	0.7073170731707317
3	0.7166158536585366	0.6991120323413438	1.173620224442583	0.7141953819471645	0.6323803060756383	0.7166158536585368	0.9673363208336683	0.9646457128909781	0.7216806681465537	0.7166158536585366
4	0.6961658663007851	0.6780072997203341	1.2433728938313935	0.6945856000491764	0.6104698018476162	0.6961658663007851	0.9645942522049734	0.9619188389477547	0.7217095400082228	0.6961658663007851
mean	0.7020990269186936	0.684712506584407	1.2354364202997103	0.7025906140344856	0.618754756950986	0.7020990269186936	0.9652726391388983	0.9644846837834828	0.7225661635242737	0.7020990269186936
std	0.012587920873285799	0.012567436909252301	0.06554707269462003	0.010660786589737629	0.017049346659058724	0.01258792087328581	0.0015936534164827985	0.0017131797922912853	0.0024235927713794543	0.012587920873285799

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 29080.7018 secs

