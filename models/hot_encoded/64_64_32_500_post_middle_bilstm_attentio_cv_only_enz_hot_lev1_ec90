/home/amsequeira/enzymeClassification/models/hot_encoded/64_64_32_500_post_middle_bilstm_attentio_cv_only_enz_hot_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f827c3dc250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f827c3dc850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f827c3dc8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f827c3dc640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.91      0.89      3813
         1.0       0.92      0.94      0.93     10869
         2.0       0.92      0.86      0.89      6897
         3.0       0.90      0.90      0.90      2585
         4.0       0.88      0.91      0.89      1616
         5.0       0.97      0.96      0.97      3258
         6.0       0.97      0.96      0.97      1372

    accuracy                           0.92     30410
   macro avg       0.92      0.92      0.92     30410
weighted avg       0.92      0.92      0.92     30410


===confusion_matrix===

[[ 3460   178    95    28    38     6     8]
 [  162 10208   297   108    50    37     7]
 [  210   520  5926   105    89    32    15]
 [   44   112    64  2332    23     8     2]
 [   35    46    31    16  1475    10     3]
 [   18    63    24    12     6  3135     0]
 [   11    27    11     1     1     0  1321]]

===multilabel confusion matrix===

[[[26117   480]
  [  353  3460]]

 [[18595   946]
  [  661 10208]]

 [[22991   522]
  [  971  5926]]

 [[27555   270]
  [  253  2332]]

 [[28587   207]
  [  141  1475]]

 [[27059    93]
  [  123  3135]]

 [[29003    35]
  [   51  1321]]]

===scores report===
metrics	scores
Accuracy	0.9160
MCC	0.8927
log_loss	0.2895
f1 score weighted	0.9159
f1 score macro	0.9195
f1 score micro	0.9160
roc_auc ovr	0.9908
roc_auc ovo	0.9926
precision	0.9164
recall	0.9160

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f827c3dc250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f827c3dc850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f827c3dc8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f827c3dc640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.88      0.89      3813
         1.0       0.92      0.92      0.92     10869
         2.0       0.86      0.89      0.88      6897
         3.0       0.89      0.90      0.89      2585
         4.0       0.93      0.87      0.90      1616
         5.0       0.98      0.94      0.96      3258
         6.0       0.92      0.98      0.95      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.91      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[3359  159  196   49   17   10   23]
 [ 126 9978  534  116   41   27   47]
 [ 112  491 6141   78   33   14   28]
 [  36  112  100 2317   14    2    4]
 [  36   64   76   35 1400    3    2]
 [  32   81   57   10    6 3065    7]
 [   5    7   19    3    0    0 1338]]

===multilabel confusion matrix===

[[[26250   347]
  [  454  3359]]

 [[18627   914]
  [  891  9978]]

 [[22531   982]
  [  756  6141]]

 [[27534   291]
  [  268  2317]]

 [[28683   111]
  [  216  1400]]

 [[27096    56]
  [  193  3065]]

 [[28927   111]
  [   34  1338]]]

===scores report===
metrics	scores
Accuracy	0.9075
MCC	0.8816
log_loss	0.2984
f1 score weighted	0.9077
f1 score macro	0.9120
f1 score micro	0.9075
roc_auc ovr	0.9883
roc_auc ovo	0.9906
precision	0.9082
recall	0.9075

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f827c3dc250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f827c3dc850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f827c3dc8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f827c3dc640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.91      0.90      3814
         1.0       0.92      0.95      0.93     10869
         2.0       0.91      0.89      0.90      6896
         3.0       0.92      0.89      0.90      2584
         4.0       0.92      0.91      0.91      1617
         5.0       0.99      0.95      0.97      3258
         6.0       0.96      0.97      0.97      1372

    accuracy                           0.92     30410
   macro avg       0.93      0.92      0.93     30410
weighted avg       0.92      0.92      0.92     30410


===confusion_matrix===

[[ 3469   157   116    24    27     7    14]
 [  127 10301   302    72    35    19    13]
 [  157   465  6118    76    43    16    21]
 [   49   121   105  2291    15     2     1]
 [   25    62    46    14  1464     2     4]
 [   30    76    42     5     6  3099     0]
 [   12    11    14     0     0     1  1334]]

===multilabel confusion matrix===

[[[26196   400]
  [  345  3469]]

 [[18649   892]
  [  568 10301]]

 [[22889   625]
  [  778  6118]]

 [[27635   191]
  [  293  2291]]

 [[28667   126]
  [  153  1464]]

 [[27105    47]
  [  159  3099]]

 [[28985    53]
  [   38  1334]]]

===scores report===
metrics	scores
Accuracy	0.9232
MCC	0.9016
log_loss	0.2721
f1 score weighted	0.9232
f1 score macro	0.9266
f1 score micro	0.9232
roc_auc ovr	0.9917
roc_auc ovo	0.9929
precision	0.9235
recall	0.9232

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f827c3dc250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f827c3dc850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f827c3dc8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f827c3dc640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.94      0.83      0.88      3813
         1.0       0.90      0.94      0.92     10868
         2.0       0.87      0.89      0.88      6897
         3.0       0.90      0.88      0.89      2585
         4.0       0.92      0.88      0.90      1616
         5.0       0.96      0.95      0.96      3258
         6.0       0.98      0.96      0.97      1372

    accuracy                           0.91     30409
   macro avg       0.92      0.91      0.91     30409
weighted avg       0.91      0.91      0.91     30409


===confusion_matrix===

[[ 3172   281   247    48    24    24    17]
 [   90 10165   440    87    37    43     6]
 [   62   531  6149    80    38    32     5]
 [   28   133   129  2271    15     8     1]
 [   15    78    66    23  1425     9     0]
 [   16    68    50     9     7  3108     0]
 [    7    18    22     3     0     2  1320]]

===multilabel confusion matrix===

[[[26378   218]
  [  641  3172]]

 [[18432  1109]
  [  703 10165]]

 [[22558   954]
  [  748  6149]]

 [[27574   250]
  [  314  2271]]

 [[28672   121]
  [  191  1425]]

 [[27033   118]
  [  150  3108]]

 [[29008    29]
  [   52  1320]]]

===scores report===
metrics	scores
Accuracy	0.9080
MCC	0.8819
log_loss	0.3006
f1 score weighted	0.9078
f1 score macro	0.9139
f1 score micro	0.9080
roc_auc ovr	0.9887
roc_auc ovo	0.9907
precision	0.9088
recall	0.9080

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f827c3dc250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f827c3dc850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f827c3dc8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f827c3dc640>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.91      0.87      3813
         1.0       0.92      0.90      0.91     10868
         2.0       0.93      0.81      0.86      6897
         3.0       0.94      0.86      0.90      2585
         4.0       0.81      0.91      0.86      1616
         5.0       0.79      0.98      0.88      3258
         6.0       0.96      0.97      0.96      1372

    accuracy                           0.89     30409
   macro avg       0.88      0.91      0.89     30409
weighted avg       0.89      0.89      0.89     30409


===confusion_matrix===

[[3474  120   87   16   27   73   16]
 [ 283 9757  230   51  136  392   19]
 [ 289  554 5575   54  125  284   16]
 [  92   97   74 2213   43   63    3]
 [  30   47   27    7 1476   27    2]
 [  17   13   12    4    6 3206    0]
 [  17   12   11    1    2    2 1327]]

===multilabel confusion matrix===

[[[25868   728]
  [  339  3474]]

 [[18698   843]
  [ 1111  9757]]

 [[23071   441]
  [ 1322  5575]]

 [[27691   133]
  [  372  2213]]

 [[28454   339]
  [  140  1476]]

 [[26310   841]
  [   52  3206]]

 [[28981    56]
  [   45  1327]]]

===scores report===
metrics	scores
Accuracy	0.8888
MCC	0.8598
log_loss	0.3643
f1 score weighted	0.8889
f1 score macro	0.8912
f1 score micro	0.8888
roc_auc ovr	0.9870
roc_auc ovo	0.9903
precision	0.8944
recall	0.8888

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.916047352844459	0.8926911867702755	0.28948187628370325	0.9159056790741079	0.9195052182096343	0.916047352844459	0.9907534167809012	0.992617652671591	0.9164388011424021	0.916047352844459
1	0.907530417625781	0.8815872545541192	0.2984397686865861	0.907672329548966	0.9119864333463409	0.907530417625781	0.9882673830143498	0.9905569196534937	0.9082328767661743	0.907530417625781
2	0.9232489312726077	0.9016201271943949	0.272069618799755	0.9231804354477764	0.9266146161038691	0.9232489312726077	0.991708337964811	0.9928526979839881	0.9234540046035026	0.9232489312726077
3	0.9079548817784209	0.8818594688140992	0.3005898119677209	0.9078207109716252	0.9138723272188605	0.9079548817784209	0.9887328966978425	0.990650656092721	0.9088399184990527	0.9079548817784209
4	0.8888158111085533	0.8597869235519988	0.3643218128825424	0.888935358212069	0.8911997054175893	0.8888158111085533	0.9870443762034121	0.990251816144994	0.8943906401134033	0.8888158111085533
mean	0.9087194789259645	0.8835089921769775	0.3049805777240615	0.9087029026509089	0.9126356600592589	0.9087194789259645	0.9893012821322633	0.9913859485093575	0.9102712482249069	0.9087194789259645
std	0.01151483555955708	0.014010542115366566	0.03132661539515769	0.011437439401421279	0.011866364512070677	0.01151483555955708	0.0016963635564668396	0.0011119936300453526	0.009697640452260042	0.01151483555955708

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 62392.7655 secs

