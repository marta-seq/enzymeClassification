/home/amsequeira/enzymeClassification/models/hot_encoded/bi_attetion_500_post_post_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f618455b760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f618455b700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f618455b340>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.8808633621249881)
('Validation Accuracy mean: ', 0.6698985265833991)
('Training Loss mean: ', 0.4563205250671932)
('Validation Loss mean: ', 1.2436244589941843)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500, 21)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 128)          44032     
_________________________________________________________________
bidirectional_1 (Bidirection (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_2 (Bidirection (None, 500, 64)           41216     
_________________________________________________________________
attention (attention)        (None, 64)                564       
_________________________________________________________________
dense (Dense)                (None, 32)                2080      
_________________________________________________________________
batch_normalization (BatchNo (None, 32)                128       
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                528       
_________________________________________________________________
batch_normalization_1 (Batch (None, 16)                64        
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 7)                 119       
=================================================================
Total params: 187,547
Trainable params: 187,451
Non-trainable params: 96
_________________________________________________________________Finished run_model in 14826.1446 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f618455b6a0>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.89      0.93      0.91      3813
           1       0.92      0.97      0.94     10869
           2       0.95      0.88      0.91      6897
           3       0.93      0.94      0.94      2585
           4       0.95      0.96      0.95      1616
           5       0.97      0.98      0.98      3258
           6       0.98      0.72      0.83      1372

    accuracy                           0.93     30410
   macro avg       0.94      0.91      0.92     30410
weighted avg       0.93      0.93      0.93     30410


===confusion_matrix===

[[ 3558   130    82    13     7    23     0]
 [   91 10508   143    68    33    24     2]
 [  117   556  6090    64    32    22    16]
 [   38    66    45  2431     5     0     0]
 [   14    18    18    15  1549     2     0]
 [    9    33     6     6     3  3201     0]
 [  150   147    59     9     1    12   994]]

===multilabel confusion matrix===

[[[26178   419]
  [  255  3558]]

 [[18591   950]
  [  361 10508]]

 [[23160   353]
  [  807  6090]]

 [[27650   175]
  [  154  2431]]

 [[28713    81]
  [   67  1549]]

 [[27069    83]
  [   57  3201]]

 [[29020    18]
  [  378   994]]]

===scores report===
metrics	scores
Accuracy	0.9316
MCC	0.9126
log_loss	0.2683
f1 score weighted	0.9308
f1 score macro	0.9245
f1 score micro	0.9316
roc_auc ovr	0.9930
roc_auc ovo	0.9937
precision	0.9329
recall	0.9316

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f618455b760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f618455b700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f618455b340>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f618455b6a0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.89      0.88      3813
         1.0       0.88      0.95      0.91     10869
         2.0       0.89      0.85      0.87      6897
         3.0       0.92      0.88      0.90      2585
         4.0       0.94      0.88      0.91      1616
         5.0       0.99      0.91      0.95      3258
         6.0       0.98      0.94      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.93      0.90      0.91     30410
weighted avg       0.91      0.90      0.90     30410


===confusion_matrix===

[[ 3378   225   162    30    13     2     3]
 [  166 10310   298    66    17     9     3]
 [  160   758  5862    59    34    11    13]
 [   53   149   113  2265     5     0     0]
 [   30    82    70    16  1415     3     0]
 [   58   138    48    15    17  2981     1]
 [   27    34    16     2     0     0  1293]]

===multilabel confusion matrix===

[[[26103   494]
  [  435  3378]]

 [[18155  1386]
  [  559 10310]]

 [[22806   707]
  [ 1035  5862]]

 [[27637   188]
  [  320  2265]]

 [[28708    86]
  [  201  1415]]

 [[27127    25]
  [  277  2981]]

 [[29018    20]
  [   79  1293]]]

===scores report===
metrics	scores
Accuracy	0.9044
MCC	0.8774
log_loss	0.3047
f1 score weighted	0.9044
f1 score macro	0.9122
f1 score micro	0.9044
roc_auc ovr	0.9884
roc_auc ovo	0.9905
precision	0.9061
recall	0.9044

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f618455b760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f618455b700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f618455b340>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f618455b6a0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.92      0.85      3813
         1.0       0.91      0.92      0.91     10869
         2.0       0.94      0.79      0.86      6897
         3.0       0.79      0.91      0.84      2585
         4.0       0.91      0.88      0.89      1616
         5.0       0.96      0.96      0.96      3258
         6.0       0.97      0.96      0.96      1372

    accuracy                           0.89     30410
   macro avg       0.89      0.91      0.90     30410
weighted avg       0.90      0.89      0.89     30410


===confusion_matrix===

[[3497  138   69   74   19   10    6]
 [ 323 9986  208  251   41   50   10]
 [ 420  629 5459  250   64   49   26]
 [  69   90   42 2362   18    3    1]
 [  60   60   26   44 1419    7    0]
 [  43   59   18   20    1 3117    0]
 [  14   24    7    7    1    0 1319]]

===multilabel confusion matrix===

[[[25668   929]
  [  316  3497]]

 [[18541  1000]
  [  883  9986]]

 [[23143   370]
  [ 1438  5459]]

 [[27179   646]
  [  223  2362]]

 [[28650   144]
  [  197  1419]]

 [[27033   119]
  [  141  3117]]

 [[28995    43]
  [   53  1319]]]

===scores report===
metrics	scores
Accuracy	0.8931
MCC	0.8648
log_loss	0.3451
f1 score weighted	0.8933
f1 score macro	0.8976
f1 score micro	0.8931
roc_auc ovr	0.9878
roc_auc ovo	0.9904
precision	0.8982
recall	0.8931

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f618455b760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f618455b700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f618455b340>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f618455b6a0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.84      0.89      3814
         1.0       0.89      0.94      0.91     10869
         2.0       0.88      0.87      0.88      6896
         3.0       0.93      0.85      0.89      2584
         4.0       0.94      0.87      0.90      1617
         5.0       0.93      0.97      0.95      3258
         6.0       0.97      0.96      0.97      1372

    accuracy                           0.91     30410
   macro avg       0.93      0.90      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3211   294   182    44    11    58    14]
 [   58 10239   412    49    25    73    13]
 [   94   632  6032    43    33    53     9]
 [   38   183   127  2198    13    24     1]
 [   24    90    60    15  1407    19     2]
 [    4    59    28     6     4  3156     1]
 [   12    25    16     1     0     1  1317]]

===multilabel confusion matrix===

[[[26366   230]
  [  603  3211]]

 [[18258  1283]
  [  630 10239]]

 [[22689   825]
  [  864  6032]]

 [[27668   158]
  [  386  2198]]

 [[28707    86]
  [  210  1407]]

 [[26924   228]
  [  102  3156]]

 [[28998    40]
  [   55  1317]]]

===scores report===
metrics	scores
Accuracy	0.9063
MCC	0.8797
log_loss	0.3097
f1 score weighted	0.9059
f1 score macro	0.9124
f1 score micro	0.9063
roc_auc ovr	0.9884
roc_auc ovo	0.9903
precision	0.9072
recall	0.9063

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f618455b760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f618455b700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f618455b340>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f618455b6a0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.86      0.88      3813
         1.0       0.93      0.89      0.91     10868
         2.0       0.88      0.88      0.88      6897
         3.0       0.80      0.90      0.85      2585
         4.0       0.80      0.90      0.85      1616
         5.0       0.96      0.96      0.96      3258
         6.0       0.95      0.96      0.95      1372

    accuracy                           0.90     30409
   macro avg       0.89      0.91      0.90     30409
weighted avg       0.90      0.90      0.90     30409


===confusion_matrix===

[[3294  109  168  124   83   21   14]
 [ 224 9663  470  262  149   66   34]
 [ 118  405 6070  153  102   33   16]
 [  28   86   99 2338   26    8    0]
 [  18   44   47   41 1462    4    0]
 [  17   34   43   15   11 3138    0]
 [  10   20   20    6    1    3 1312]]

===multilabel confusion matrix===

[[[26181   415]
  [  519  3294]]

 [[18843   698]
  [ 1205  9663]]

 [[22665   847]
  [  827  6070]]

 [[27223   601]
  [  247  2338]]

 [[28421   372]
  [  154  1462]]

 [[27016   135]
  [  120  3138]]

 [[28973    64]
  [   60  1312]]]

===scores report===
metrics	scores
Accuracy	0.8970
MCC	0.8693
log_loss	0.3247
f1 score weighted	0.8975
f1 score macro	0.8964
f1 score micro	0.8970
roc_auc ovr	0.9876
roc_auc ovo	0.9902
precision	0.8994
recall	0.8970

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f618455b760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f618455b700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f618455b340>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f618455b6a0>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.91      0.90      3813
         1.0       0.92      0.94      0.93     10868
         2.0       0.92      0.86      0.89      6897
         3.0       0.86      0.93      0.89      2585
         4.0       0.95      0.89      0.92      1616
         5.0       0.97      0.97      0.97      3258
         6.0       0.96      0.97      0.96      1372

    accuracy                           0.92     30409
   macro avg       0.93      0.92      0.92     30409
weighted avg       0.92      0.92      0.92     30409


===confusion_matrix===

[[ 3486   133   103    61    12     9     9]
 [  161 10238   256   136    11    40    26]
 [  158   545  5952   168    30    23    21]
 [   37    73    61  2396    14     4     0]
 [   40    65    39    19  1446     7     0]
 [   24    39    27    14     3  3151     0]
 [   15    24     9     0     0     0  1324]]

===multilabel confusion matrix===

[[[26161   435]
  [  327  3486]]

 [[18662   879]
  [  630 10238]]

 [[23017   495]
  [  945  5952]]

 [[27426   398]
  [  189  2396]]

 [[28723    70]
  [  170  1446]]

 [[27068    83]
  [  107  3151]]

 [[28981    56]
  [   48  1324]]]

===scores report===
metrics	scores
Accuracy	0.9205
MCC	0.8985
log_loss	0.2887
f1 score weighted	0.9204
f1 score macro	0.9246
f1 score micro	0.9205
roc_auc ovr	0.9915
roc_auc ovo	0.9933
precision	0.9213
recall	0.9205

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9044393291680368	0.8773611772274065	0.3047159405694859	0.9044025193061849	0.9122234275399694	0.9044393291680368	0.988448882442885	0.9904541158217318	0.9061008536264351	0.9044393291680368
1	0.8930943768497205	0.8647680350403529	0.34510798090903466	0.8932552577476224	0.8975528195759308	0.8930943768497205	0.9877534316972079	0.9904034336644657	0.8982361141377552	0.8930943768497205
2	0.906280828674778	0.8796704212283692	0.30973718731207595	0.905902691584186	0.9124490754857696	0.906280828674778	0.9883541242069375	0.9902857884706466	0.9072247028689244	0.906280828674778
3	0.8970041763951462	0.8692987084178719	0.32470932125961083	0.8975370495724095	0.8964091369600918	0.8970041763951462	0.9876479917974209	0.9901559431175105	0.8994399576260902	0.8970041763951462
4	0.9205498372192443	0.8985014167176611	0.2886541128871799	0.9204497895895676	0.9245869576407494	0.9205498372192443	0.9915227326932171	0.9932963703059895	0.9212727008547583	0.9205498372192443
mean	0.9042737096613852	0.8779199517263324	0.3145849085874775	0.904309461559994	0.9086442834405022	0.9042737096613852	0.9887454325675338	0.9909191302760689	0.9064548658227928	0.9042737096613852
std	0.009452955948882093	0.011612681191750003	0.019117870032288414	0.009285668706252453	0.010527819866467126	0.009452955948882093	0.001424282427628436	0.0011930656376999739	0.008210274356144081	0.009452955948882093

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 68108.9023 secs

