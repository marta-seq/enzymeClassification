/home/amsequeira/enzymeClassification/models/embedding/bi_attetion_emb8_50_1_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd20463e8e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd20463e340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd20463e970>]/home/amsequeira/enzymeClassification/models/embedding/bi_attetion_emb8_50_1_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe5744fe8e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe5744fe340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe5744fe970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe5744fe700>, 'x_test': array([[13,  4, 12, ...,  0,  0,  0],
       [13, 16, 16, ...,  0,  0,  0],
       [13, 12, 12, ...,  0,  0,  0],
       ...,
       [13, 16, 16, ...,  0,  0,  0],
       [17, 19, 16, ...,  6, 14,  4],
       [20,  6, 15, ...,  4,  2,  3]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.74      0.74      1793
         1.0       0.84      0.79      0.82      4921
         2.0       0.69      0.83      0.76      3576
         3.0       0.72      0.60      0.65       943
         4.0       0.82      0.67      0.74       695
         5.0       0.88      0.82      0.85      1073
         6.0       0.90      0.85      0.87       471

    accuracy                           0.78     13472
   macro avg       0.80      0.76      0.78     13472
weighted avg       0.79      0.78      0.78     13472


===confusion_matrix===

[[1322  138  246   52   13   12   10]
 [ 163 3907  671   82   31   49   18]
 [ 131  339 2969   59   36   32   10]
 [  62  126  165  564   14   10    2]
 [  44   49   98   25  468    8    3]
 [  37   53   96    3    7  875    2]
 [  16   19   29    2    1    3  401]]

===multilabel confusion matrix===

[[[11226   453]
  [  471  1322]]

 [[ 7827   724]
  [ 1014  3907]]

 [[ 8591  1305]
  [  607  2969]]

 [[12306   223]
  [  379   564]]

 [[12675   102]
  [  227   468]]

 [[12285   114]
  [  198   875]]

 [[12956    45]
  [   70   401]]]

===scores report===
metrics	scores
Accuracy	0.7798
MCC	0.7117
log_loss	0.7521
f1 score weighted	0.7802
f1 score macro	0.7758
f1 score micro	0.7798
roc_auc ovr	0.9445
roc_auc ovo	0.9508
precision	0.7861
recall	0.7798

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe5744fe8e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe5744fe340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe5744fe970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe5744fe700>, 'x_test': array([[13, 17, 12, ...,  0,  0,  0],
       [13, 12, 17, ...,  0,  0,  0],
       [13,  3, 12, ...,  0,  0,  0],
       ...,
       [13, 20, 16, ...,  1,  6,  2],
       [13,  1,  8, ...,  0,  0,  0],
       [ 3, 16, 15, ..., 11, 19,  1]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.51      0.63      1792
         1.0       0.75      0.80      0.77      4921
         2.0       0.63      0.76      0.69      3576
         3.0       0.56      0.56      0.56       943
         4.0       0.83      0.59      0.69       696
         5.0       0.86      0.74      0.80      1072
         6.0       0.88      0.86      0.87       471

    accuracy                           0.72     13471
   macro avg       0.76      0.69      0.72     13471
weighted avg       0.73      0.72      0.72     13471


===confusion_matrix===

[[ 922  297  405  111   15   30   12]
 [  79 3919  707  132   22   40   22]
 [  67  599 2701  118   27   43   21]
 [  25  163  203  524   14   11    3]
 [  18   75  152   28  413   10    0]
 [  10  135  102   21    6  798    0]
 [  11   27   19    6    0    1  407]]

===multilabel confusion matrix===

[[[11469   210]
  [  870   922]]

 [[ 7254  1296]
  [ 1002  3919]]

 [[ 8307  1588]
  [  875  2701]]

 [[12112   416]
  [  419   524]]

 [[12691    84]
  [  283   413]]

 [[12264   135]
  [  274   798]]

 [[12942    58]
  [   64   407]]]

===scores report===
metrics	scores
Accuracy	0.7189
MCC	0.6275
log_loss	0.8305
f1 score weighted	0.7172
f1 score macro	0.7151
f1 score micro	0.7189
roc_auc ovr	0.9140
roc_auc ovo	0.9252
precision	0.7307
recall	0.7189

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe5744fe8e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe5744fe340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe5744fe970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe5744fe700>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       [13,  3, 15, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [ 8, 15, 15, ...,  9, 17, 11],
       [14,  5, 17, ...,  3,  6,  3]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.69      0.70      1792
         1.0       0.74      0.85      0.79      4921
         2.0       0.73      0.74      0.73      3576
         3.0       0.79      0.41      0.54       943
         4.0       0.89      0.56      0.69       695
         5.0       0.87      0.81      0.84      1072
         6.0       0.79      0.85      0.82       472

    accuracy                           0.75     13471
   macro avg       0.79      0.70      0.73     13471
weighted avg       0.76      0.75      0.75     13471


===confusion_matrix===

[[1245  293  206   18    5   13   12]
 [ 171 4169  462   28   10   52   29]
 [ 178  621 2654   28   18   39   38]
 [  90  273  152  389   11   12   16]
 [  44  115   98   27  390   13    8]
 [  29  106   65    2    1  865    4]
 [  15   32   23    2    1    0  399]]

===multilabel confusion matrix===

[[[11152   527]
  [  547  1245]]

 [[ 7110  1440]
  [  752  4169]]

 [[ 8889  1006]
  [  922  2654]]

 [[12423   105]
  [  554   389]]

 [[12730    46]
  [  305   390]]

 [[12270   129]
  [  207   865]]

 [[12892   107]
  [   73   399]]]

===scores report===
metrics	scores
Accuracy	0.7506
MCC	0.6681
log_loss	0.7763
f1 score weighted	0.7456
f1 score macro	0.7298
f1 score micro	0.7506
roc_auc ovr	0.9326
roc_auc ovo	0.9399
precision	0.7556
recall	0.7506

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe5744fe8e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe5744fe340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe5744fe970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe5744fe700>, 'x_test': array([[13, 13,  2, ...,  0,  0,  0],
       [13, 16,  8, ...,  0,  0,  0],
       [13, 16,  7, ...,  0,  0,  0],
       ...,
       [17,  5, 17, ...,  3,  1, 20],
       [20, 19, 11, ...,  1, 19,  5],
       [ 6, 17,  1, ...,  4,  6, 11]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.63      0.73      1792
         1.0       0.83      0.81      0.82      4920
         2.0       0.69      0.84      0.76      3576
         3.0       0.71      0.60      0.65       944
         4.0       0.76      0.68      0.72       695
         5.0       0.82      0.84      0.83      1072
         6.0       0.92      0.85      0.89       472

    accuracy                           0.78     13471
   macro avg       0.80      0.75      0.77     13471
weighted avg       0.78      0.78      0.78     13471


===confusion_matrix===

[[1136  190  327   62   26   46    5]
 [  73 3999  642   77   43   71   15]
 [  53  370 2998   54   39   52   10]
 [  30  128  174  563   31   18    0]
 [  15   76   93   25  470   13    3]
 [   8   58   92    8    6  900    0]
 [  14   17   34    5    1    0  401]]

===multilabel confusion matrix===

[[[11486   193]
  [  656  1136]]

 [[ 7712   839]
  [  921  3999]]

 [[ 8533  1362]
  [  578  2998]]

 [[12296   231]
  [  381   563]]

 [[12630   146]
  [  225   470]]

 [[12199   200]
  [  172   900]]

 [[12966    33]
  [   71   401]]]

===scores report===
metrics	scores
Accuracy	0.7770
MCC	0.7072
log_loss	0.7439
f1 score weighted	0.7761
f1 score macro	0.7689
f1 score micro	0.7770
roc_auc ovr	0.9447
roc_auc ovo	0.9518
precision	0.7847
recall	0.7770

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe5744fe8e0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe5744fe340>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe5744fe970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fe5744fe700>, 'x_test': array([[13,  7,  1, ...,  0,  0,  0],
       [13, 12,  3, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       ...,
       [20, 20, 20, ...,  1,  7,  1],
       [13, 15,  3, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.72      0.75      1792
         1.0       0.76      0.87      0.81      4920
         2.0       0.79      0.71      0.75      3576
         3.0       0.74      0.60      0.66       944
         4.0       0.77      0.65      0.71       695
         5.0       0.80      0.86      0.83      1073
         6.0       0.93      0.86      0.90       471

    accuracy                           0.78     13471
   macro avg       0.80      0.76      0.77     13471
weighted avg       0.78      0.78      0.78     13471


===confusion_matrix===

[[1291  258  147   37   22   28    9]
 [ 123 4302  309   57   40   79   10]
 [ 114  705 2536   71   44   95   11]
 [  41  196   94  568   22   23    0]
 [  34  101   69   24  455   12    0]
 [  13   84   36    7    6  927    0]
 [  17   24   20    3    1    0  406]]

===multilabel confusion matrix===

[[[11337   342]
  [  501  1291]]

 [[ 7183  1368]
  [  618  4302]]

 [[ 9220   675]
  [ 1040  2536]]

 [[12328   199]
  [  376   568]]

 [[12641   135]
  [  240   455]]

 [[12161   237]
  [  146   927]]

 [[12970    30]
  [   65   406]]]

===scores report===
metrics	scores
Accuracy	0.7783
MCC	0.7076
log_loss	0.7293
f1 score weighted	0.7758
f1 score macro	0.7728
f1 score micro	0.7783
roc_auc ovr	0.9428
roc_auc ovo	0.9511
precision	0.7796
recall	0.7783

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7798396674584323	0.7117098452742031	0.752093734111207	0.7802086863610082	0.7758198295468108	0.7798396674584321	0.9444829686768553	0.9508186063120098	0.7861056369534862	0.7798396674584323
1	0.7188775888946626	0.6275306398200018	0.8305190923379667	0.7171879181738716	0.7150522403299701	0.7188775888946626	0.9140464935458453	0.9252309012681607	0.730665163015726	0.7188775888946626
2	0.7505753099250241	0.6681014921141462	0.7762581980687618	0.7456334949764859	0.7297741712375566	0.7505753099250241	0.9326381269466812	0.9398695610747114	0.7556289017063366	0.7505753099250241
3	0.7770024497067776	0.7071991753837474	0.7438606624624801	0.7761180407935809	0.7688530510002443	0.7770024497067776	0.944739183089804	0.9517507124425668	0.7846700069560653	0.7770024497067776
4	0.7783386534036077	0.7075808041796536	0.7293213273234541	0.7757803698098145	0.7728289018940054	0.7783386534036077	0.942844989035522	0.9510611022033636	0.7796077567781379	0.7783386534036077
mean	0.7609267338777009	0.6844243913543504	0.766410602860774	0.7589857020229521	0.7524656388017175	0.7609267338777009	0.9357503522589417	0.9437461766601624	0.7673354930819504	0.7609267338777009
std	0.023641426392143373	0.03256606283047433	0.03548509675080481	0.024295386927325077	0.02507306552103066	0.023641426392143356	0.011731453189031658	0.01025127856624457	0.021378351279929098	0.023641426392143373

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 31510.2777 secs

