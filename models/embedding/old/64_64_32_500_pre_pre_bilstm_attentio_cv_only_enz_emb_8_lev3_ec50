/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_emb_8_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc03411cd00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc03411cb80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc03411cbb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc03411cd90>, 'x_test': array([[ 0,  0,  0, ...,  3,  7, 11],
       [ 0,  0,  0, ...,  3,  0,  8],
       [ 0,  0,  0, ..., 16,  5,  2],
       ...,
       [ 0,  0,  0, ..., 10, 13,  6],
       [16, 18, 15, ...,  5, 13,  3],
       [ 0,  0,  0, ..., 10, 12,  1]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.72      0.77       358
         1.0       0.38      0.25      0.30        12
         2.0       0.86      0.32      0.46        19
         3.0       0.58      0.35      0.44        80
         4.0       0.18      0.35      0.24        54
         5.0       0.15      0.07      0.10        58
         6.0       0.27      0.20      0.23        45
         7.0       0.71      0.50      0.59        48
         8.0       0.00      0.00      0.00        11
         9.0       0.45      0.24      0.31        21
        10.0       1.00      0.07      0.12        15
        11.0       0.70      0.64      0.67        36
        12.0       0.73      0.67      0.70        12
        13.0       0.89      0.64      0.74        25
        14.0       0.00      0.00      0.00        19
        15.0       0.88      0.64      0.74        22
        16.0       0.67      0.43      0.53        23
        17.0       0.93      0.77      0.84       119
        18.0       0.78      0.39      0.52        18
        19.0       0.00      0.00      0.00        12
        20.0       0.49      0.32      0.39        90
        21.0       1.00      0.33      0.50        12
        22.0       0.95      0.72      0.82        25
        23.0       0.00      0.00      0.00        12
        24.0       0.29      0.09      0.14        22
        25.0       0.57      0.34      0.43        38
        26.0       1.00      0.59      0.74        17
        27.0       0.36      0.14      0.20        35
        28.0       0.00      0.00      0.00        11
        29.0       0.62      0.44      0.52        36
        30.0       0.58      0.66      0.62        32
        31.0       0.84      0.68      0.75        38
        32.0       0.60      0.87      0.71       747
        33.0       0.85      0.74      0.79        74
        34.0       0.75      0.86      0.80        59
        35.0       0.96      0.52      0.68        48
        36.0       0.75      0.64      0.69       502
        37.0       0.73      0.56      0.63       241
        38.0       1.00      0.21      0.35        33
        39.0       0.65      0.72      0.68       344
        40.0       0.75      0.64      0.69       191
        41.0       0.92      0.38      0.53        32
        42.0       0.73      0.69      0.71       384
        43.0       0.74      0.68      0.71       118
        44.0       0.46      0.79      0.58       436
        45.0       0.94      0.71      0.81        48
        46.0       0.74      0.86      0.79       402
        47.0       1.00      0.06      0.11        17
        48.0       0.76      0.31      0.44        42
        49.0       0.94      0.87      0.91        78
        50.0       0.91      0.87      0.89       172
        51.0       0.86      0.30      0.44        20
        52.0       0.76      0.60      0.67       499
        53.0       0.87      0.71      0.78       100
        54.0       0.00      0.00      0.00        11
        55.0       0.81      0.66      0.73       103
        56.0       1.00      0.28      0.43        18
        57.0       0.00      0.00      0.00        10
        58.0       1.00      0.88      0.94        34
        59.0       0.52      0.67      0.58       231
        60.0       0.97      0.64      0.77        58
        61.0       0.25      0.03      0.06        30
        62.0       0.48      0.44      0.46        48
        63.0       0.20      0.14      0.16        50
        64.0       0.84      0.62      0.71        34
        65.0       0.81      0.71      0.76       155
        66.0       0.00      0.00      0.00        14
        67.0       0.52      0.67      0.59       314
        68.0       0.50      0.03      0.06        63
        69.0       0.49      0.62      0.55       308
        70.0       0.79      0.38      0.51        68
        71.0       0.66      0.38      0.48        66
        72.0       0.00      0.00      0.00        14
        73.0       0.89      0.32      0.47        25
        74.0       0.00      0.00      0.00        18
        75.0       0.19      0.27      0.22        60
        76.0       0.71      0.68      0.70       205
        77.0       0.40      0.23      0.30        77
        78.0       0.76      0.42      0.54        59
        79.0       0.58      0.40      0.47       139
        80.0       0.81      0.81      0.81        42
        81.0       0.33      0.50      0.40       175
        82.0       0.70      0.33      0.44        43
        83.0       0.22      0.08      0.11        26
        84.0       0.26      0.58      0.36       106
        85.0       1.00      0.50      0.67        14
        86.0       0.75      0.68      0.72       242
        87.0       0.67      0.74      0.70       309
        88.0       0.67      0.55      0.60        58
        89.0       1.00      0.09      0.17        11
        90.0       0.51      0.48      0.49       187
        91.0       0.56      0.33      0.41        46
        92.0       0.16      0.07      0.10        40
        93.0       0.64      0.28      0.39        32
        94.0       0.59      0.65      0.62       289
        95.0       0.00      0.00      0.00        31
        96.0       0.79      0.57      0.66        74
        97.0       0.48      0.41      0.44        27
        98.0       1.00      0.38      0.55        37
        99.0       0.88      0.88      0.88        24
       100.0       0.00      0.00      0.00        25
       101.0       0.71      0.38      0.50        65
       102.0       0.93      0.64      0.76        22
       103.0       0.83      0.70      0.76        64
       104.0       0.58      0.35      0.44        40
       105.0       1.00      0.83      0.91        12
       106.0       0.75      0.73      0.74       114
       107.0       0.62      0.86      0.72       161
       108.0       0.91      0.42      0.57        24
       109.0       0.74      0.60      0.66        52
       110.0       0.81      0.87      0.84        15
       111.0       0.40      0.67      0.50       123
       112.0       0.50      0.36      0.42        42
       113.0       0.74      0.91      0.82       430
       114.0       0.95      0.63      0.76        65
       115.0       0.43      0.58      0.49        31
       116.0       0.53      0.75      0.62       173
       117.0       0.85      0.90      0.88        31
       118.0       0.91      0.74      0.81       117
       119.0       0.64      0.74      0.68       136
       120.0       0.78      0.56      0.65        62
       121.0       0.68      0.87      0.76       224
       122.0       0.96      0.63      0.76        35
       123.0       0.87      0.70      0.78        37
       124.0       0.47      0.81      0.60        31
       125.0       0.63      0.80      0.71        15
       126.0       0.91      0.48      0.62        21
       127.0       0.77      0.56      0.65        73

    accuracy                           0.64     12227
   macro avg       0.63      0.48      0.52     12227
weighted avg       0.66      0.64      0.63     12227


===confusion_matrix===

[[256   2   0 ...   0   0   0]
 [  0   3   0 ...   0   0   0]
 [  0   0   6 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   0  10   4]
 [  0   0   0 ...   3   1  41]]

===multilabel confusion matrix===

[[[11816    53]
  [  102   256]]

 [[12210     5]
  [    9     3]]

 [[12207     1]
  [   13     6]]

 [[12127    20]
  [   52    28]]

 [[12085    88]
  [   35    19]]

 [[12147    22]
  [   54     4]]

 [[12158    24]
  [   36     9]]

 [[12169    10]
  [   24    24]]

 [[12216     0]
  [   11     0]]

 [[12200     6]
  [   16     5]]

 [[12212     0]
  [   14     1]]

 [[12181    10]
  [   13    23]]

 [[12212     3]
  [    4     8]]

 [[12200     2]
  [    9    16]]

 [[12206     2]
  [   19     0]]

 [[12203     2]
  [    8    14]]

 [[12199     5]
  [   13    10]]

 [[12101     7]
  [   27    92]]

 [[12207     2]
  [   11     7]]

 [[12212     3]
  [   12     0]]

 [[12107    30]
  [   61    29]]

 [[12215     0]
  [    8     4]]

 [[12201     1]
  [    7    18]]

 [[12214     1]
  [   12     0]]

 [[12200     5]
  [   20     2]]

 [[12179    10]
  [   25    13]]

 [[12210     0]
  [    7    10]]

 [[12183     9]
  [   30     5]]

 [[12215     1]
  [   11     0]]

 [[12181    10]
  [   20    16]]

 [[12180    15]
  [   11    21]]

 [[12184     5]
  [   12    26]]

 [[11051   429]
  [  100   647]]

 [[12143    10]
  [   19    55]]

 [[12151    17]
  [    8    51]]

 [[12178     1]
  [   23    25]]

 [[11619   106]
  [  181   321]]

 [[11936    50]
  [  107   134]]

 [[12194     0]
  [   26     7]]

 [[11750   133]
  [   98   246]]

 [[11995    41]
  [   68   123]]

 [[12194     1]
  [   20    12]]

 [[11744    99]
  [  119   265]]

 [[12081    28]
  [   38    80]]

 [[11379   412]
  [   92   344]]

 [[12177     2]
  [   14    34]]

 [[11704   121]
  [   58   344]]

 [[12210     0]
  [   16     1]]

 [[12181     4]
  [   29    13]]

 [[12145     4]
  [   10    68]]

 [[12041    14]
  [   23   149]]

 [[12206     1]
  [   14     6]]

 [[11632    96]
  [  199   300]]

 [[12116    11]
  [   29    71]]

 [[12214     2]
  [   11     0]]

 [[12108    16]
  [   35    68]]

 [[12209     0]
  [   13     5]]

 [[12213     4]
  [   10     0]]

 [[12193     0]
  [    4    30]]

 [[11851   145]
  [   77   154]]

 [[12168     1]
  [   21    37]]

 [[12194     3]
  [   29     1]]

 [[12156    23]
  [   27    21]]

 [[12149    28]
  [   43     7]]

 [[12189     4]
  [   13    21]]

 [[12047    25]
  [   45   110]]

 [[12213     0]
  [   14     0]]

 [[11721   192]
  [  104   210]]

 [[12162     2]
  [   61     2]]

 [[11723   196]
  [  117   191]]

 [[12152     7]
  [   42    26]]

 [[12148    13]
  [   41    25]]

 [[12213     0]
  [   14     0]]

 [[12201     1]
  [   17     8]]

 [[12209     0]
  [   18     0]]

 [[12099    68]
  [   44    16]]

 [[11965    57]
  [   65   140]]

 [[12123    27]
  [   59    18]]

 [[12160     8]
  [   34    25]]

 [[12048    40]
  [   84    55]]

 [[12177     8]
  [    8    34]]

 [[11877   175]
  [   88    87]]

 [[12178     6]
  [   29    14]]

 [[12194     7]
  [   24     2]]

 [[11940   181]
  [   44    62]]

 [[12213     0]
  [    7     7]]

 [[11931    54]
  [   77   165]]

 [[11804   114]
  [   81   228]]

 [[12153    16]
  [   26    32]]

 [[12216     0]
  [   10     1]]

 [[11954    86]
  [   98    89]]

 [[12169    12]
  [   31    15]]

 [[12171    16]
  [   37     3]]

 [[12190     5]
  [   23     9]]

 [[11808   130]
  [  102   187]]

 [[12195     1]
  [   31     0]]

 [[12142    11]
  [   32    42]]

 [[12188    12]
  [   16    11]]

 [[12190     0]
  [   23    14]]

 [[12200     3]
  [    3    21]]

 [[12202     0]
  [   25     0]]

 [[12152    10]
  [   40    25]]

 [[12204     1]
  [    8    14]]

 [[12154     9]
  [   19    45]]

 [[12177    10]
  [   26    14]]

 [[12215     0]
  [    2    10]]

 [[12086    27]
  [   31    83]]

 [[11982    84]
  [   22   139]]

 [[12202     1]
  [   14    10]]

 [[12164    11]
  [   21    31]]

 [[12209     3]
  [    2    13]]

 [[11979   125]
  [   40    83]]

 [[12170    15]
  [   27    15]]

 [[11662   135]
  [   39   391]]

 [[12160     2]
  [   24    41]]

 [[12172    24]
  [   13    18]]

 [[11939   115]
  [   43   130]]

 [[12191     5]
  [    3    28]]

 [[12101     9]
  [   31    86]]

 [[12035    56]
  [   36   100]]

 [[12155    10]
  [   27    35]]

 [[11911    92]
  [   30   194]]

 [[12191     1]
  [   13    22]]

 [[12186     4]
  [   11    26]]

 [[12168    28]
  [    6    25]]

 [[12205     7]
  [    3    12]]

 [[12205     1]
  [   11    10]]

 [[12142    12]
  [   32    41]]]

===scores report===
metrics	scores
Accuracy	0.6379
MCC	0.6298
log_loss	1.6631
f1 score weighted	0.6286
f1 score macro	0.5172
f1 score micro	0.6379
roc_auc ovr	0.9679
roc_auc ovo	0.9626
precision	0.6566
recall	0.6379

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc03411cd00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc03411cb80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc03411cbb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc03411cd90>, 'x_test': array([[ 0,  0,  0, ...,  7, 17,  5],
       [ 0,  0,  0, ..., 17, 19,  8],
       [ 0,  0,  0, ..., 11, 13,  2],
       ...,
       [ 0,  0,  0, ..., 19,  3,  3],
       [ 0,  0,  0, ..., 18,  9, 12],
       [11, 11, 10, ..., 15,  8, 19]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.68      0.81      0.74       357
         1.0       1.00      0.17      0.29        12
         2.0       0.79      0.58      0.67        19
         3.0       0.71      0.40      0.51        80
         4.0       0.16      0.37      0.22        54
         5.0       0.10      0.12      0.11        58
         6.0       0.48      0.25      0.33        44
         7.0       0.87      0.69      0.77        48
         8.0       1.00      0.09      0.17        11
         9.0       0.52      0.52      0.52        21
        10.0       0.25      0.07      0.11        15
        11.0       0.87      0.72      0.79        36
        12.0       0.00      0.00      0.00        12
        13.0       0.93      0.52      0.67        25
        14.0       0.71      0.25      0.37        20
        15.0       0.81      0.57      0.67        23
        16.0       0.72      0.57      0.63        23
        17.0       0.83      0.80      0.82       119
        18.0       0.85      0.65      0.73        17
        19.0       0.00      0.00      0.00        13
        20.0       0.64      0.38      0.48        90
        21.0       0.60      0.25      0.35        12
        22.0       0.88      0.56      0.68        25
        23.0       0.60      0.25      0.35        12
        24.0       0.70      0.32      0.44        22
        25.0       0.90      0.49      0.63        37
        26.0       0.94      0.94      0.94        18
        27.0       1.00      0.06      0.11        35
        28.0       0.00      0.00      0.00        12
        29.0       0.44      0.54      0.49        37
        30.0       0.85      0.69      0.76        32
        31.0       0.84      0.67      0.74        39
        32.0       0.78      0.83      0.80       746
        33.0       0.82      0.85      0.83        74
        34.0       0.72      0.79      0.75        58
        35.0       0.81      0.52      0.63        48
        36.0       0.58      0.76      0.66       502
        37.0       0.49      0.77      0.60       241
        38.0       0.76      0.39      0.52        33
        39.0       0.62      0.73      0.67       344
        40.0       0.78      0.69      0.73       191
        41.0       0.93      0.42      0.58        31
        42.0       0.67      0.76      0.71       384
        43.0       0.71      0.82      0.76       118
        44.0       0.84      0.71      0.77       436
        45.0       0.95      0.83      0.89        48
        46.0       0.75      0.86      0.80       402
        47.0       0.56      0.53      0.55        17
        48.0       0.87      0.64      0.74        42
        49.0       0.84      0.90      0.87        77
        50.0       0.91      0.80      0.85       172
        51.0       0.88      0.70      0.78        20
        52.0       0.66      0.68      0.67       499
        53.0       0.78      0.59      0.67        99
        54.0       0.00      0.00      0.00        11
        55.0       0.89      0.78      0.83       103
        56.0       0.38      0.17      0.23        18
        57.0       0.00      0.00      0.00        11
        58.0       1.00      0.91      0.95        34
        59.0       0.62      0.61      0.61       231
        60.0       0.75      0.69      0.72        58
        61.0       0.11      0.07      0.08        30
        62.0       0.38      0.25      0.30        48
        63.0       0.09      0.06      0.07        49
        64.0       0.88      0.65      0.75        34
        65.0       0.86      0.71      0.78       154
        66.0       0.00      0.00      0.00        14
        67.0       0.48      0.67      0.56       314
        68.0       0.09      0.08      0.09        63
        69.0       0.46      0.66      0.54       308
        70.0       0.64      0.42      0.51        69
        71.0       0.45      0.45      0.45        66
        72.0       0.00      0.00      0.00        14
        73.0       1.00      0.44      0.61        25
        74.0       0.00      0.00      0.00        18
        75.0       0.27      0.15      0.20        59
        76.0       0.83      0.59      0.69       205
        77.0       0.70      0.25      0.37        77
        78.0       0.66      0.59      0.62        59
        79.0       0.42      0.46      0.44       139
        80.0       0.96      0.66      0.78        41
        81.0       0.39      0.55      0.46       175
        82.0       0.61      0.33      0.42        43
        83.0       0.41      0.42      0.42        26
        84.0       0.45      0.63      0.52       105
        85.0       0.67      0.43      0.52        14
        86.0       0.57      0.76      0.65       242
        87.0       0.85      0.73      0.79       309
        88.0       0.82      0.57      0.67        58
        89.0       0.67      0.18      0.29        11
        90.0       0.68      0.49      0.57       187
        91.0       0.46      0.26      0.33        46
        92.0       0.35      0.23      0.27        40
        93.0       0.64      0.64      0.64        33
        94.0       0.80      0.62      0.70       289
        95.0       0.75      0.09      0.17        32
        96.0       0.59      0.72      0.65        74
        97.0       0.69      0.33      0.45        27
        98.0       0.70      0.51      0.59        37
        99.0       0.87      0.83      0.85        24
       100.0       0.07      0.04      0.05        26
       101.0       0.59      0.42      0.49        65
       102.0       0.82      0.64      0.72        22
       103.0       0.78      0.83      0.80        64
       104.0       0.82      0.23      0.35        40
       105.0       1.00      0.85      0.92        13
       106.0       0.46      0.83      0.59       113
       107.0       0.74      0.79      0.76       162
       108.0       1.00      0.33      0.50        24
       109.0       0.80      0.75      0.77        52
       110.0       0.86      0.80      0.83        15
       111.0       0.56      0.61      0.59       123
       112.0       0.73      0.39      0.51        41
       113.0       0.75      0.95      0.84       430
       114.0       0.78      0.80      0.79        65
       115.0       0.73      0.61      0.67        31
       116.0       0.87      0.68      0.76       173
       117.0       0.77      0.80      0.79        30
       118.0       0.90      0.80      0.84       118
       119.0       0.93      0.68      0.79       136
       120.0       0.89      0.64      0.74        61
       121.0       0.89      0.85      0.87       225
       122.0       1.00      0.86      0.92        35
       123.0       0.78      0.74      0.76        38
       124.0       0.65      0.71      0.68        31
       125.0       0.78      0.44      0.56        16
       126.0       0.64      0.76      0.70        21
       127.0       0.71      0.78      0.75        73

    accuracy                           0.67     12227
   macro avg       0.65      0.52      0.56     12227
weighted avg       0.69      0.67      0.66     12227


===confusion_matrix===

[[290   0   0 ...   0   0   0]
 [  0   2   0 ...   0   0   0]
 [  0   0  11 ...   0   0   0]
 ...
 [  0   0   0 ...   7   1   0]
 [  0   0   0 ...   0  16   1]
 [  0   0   0 ...   1   7  57]]

===multilabel confusion matrix===

[[[11736   134]
  [   67   290]]

 [[12215     0]
  [   10     2]]

 [[12205     3]
  [    8    11]]

 [[12134    13]
  [   48    32]]

 [[12064   109]
  [   34    20]]

 [[12109    60]
  [   51     7]]

 [[12171    12]
  [   33    11]]

 [[12174     5]
  [   15    33]]

 [[12216     0]
  [   10     1]]

 [[12196    10]
  [   10    11]]

 [[12209     3]
  [   14     1]]

 [[12187     4]
  [   10    26]]

 [[12215     0]
  [   12     0]]

 [[12201     1]
  [   12    13]]

 [[12205     2]
  [   15     5]]

 [[12201     3]
  [   10    13]]

 [[12199     5]
  [   10    13]]

 [[12089    19]
  [   24    95]]

 [[12208     2]
  [    6    11]]

 [[12214     0]
  [   13     0]]

 [[12118    19]
  [   56    34]]

 [[12213     2]
  [    9     3]]

 [[12200     2]
  [   11    14]]

 [[12213     2]
  [    9     3]]

 [[12202     3]
  [   15     7]]

 [[12188     2]
  [   19    18]]

 [[12208     1]
  [    1    17]]

 [[12192     0]
  [   33     2]]

 [[12214     1]
  [   12     0]]

 [[12165    25]
  [   17    20]]

 [[12191     4]
  [   10    22]]

 [[12183     5]
  [   13    26]]

 [[11305   176]
  [  127   619]]

 [[12139    14]
  [   11    63]]

 [[12151    18]
  [   12    46]]

 [[12173     6]
  [   23    25]]

 [[11451   274]
  [  119   383]]

 [[11790   196]
  [   55   186]]

 [[12190     4]
  [   20    13]]

 [[11728   155]
  [   93   251]]

 [[11999    37]
  [   60   131]]

 [[12195     1]
  [   18    13]]

 [[11701   142]
  [   92   292]]

 [[12070    39]
  [   21    97]]

 [[11730    61]
  [  127   309]]

 [[12177     2]
  [    8    40]]

 [[11709   116]
  [   58   344]]

 [[12203     7]
  [    8     9]]

 [[12181     4]
  [   15    27]]

 [[12137    13]
  [    8    69]]

 [[12041    14]
  [   34   138]]

 [[12205     2]
  [    6    14]]

 [[11554   174]
  [  162   337]]

 [[12112    16]
  [   41    58]]

 [[12214     2]
  [   11     0]]

 [[12114    10]
  [   23    80]]

 [[12204     5]
  [   15     3]]

 [[12216     0]
  [   11     0]]

 [[12193     0]
  [    3    31]]

 [[11911    85]
  [   91   140]]

 [[12156    13]
  [   18    40]]

 [[12180    17]
  [   28     2]]

 [[12159    20]
  [   36    12]]

 [[12148    30]
  [   46     3]]

 [[12190     3]
  [   12    22]]

 [[12055    18]
  [   45   109]]

 [[12213     0]
  [   14     0]]

 [[11687   226]
  [  104   210]]

 [[12115    49]
  [   58     5]]

 [[11677   242]
  [  104   204]]

 [[12142    16]
  [   40    29]]

 [[12125    36]
  [   36    30]]

 [[12212     1]
  [   14     0]]

 [[12202     0]
  [   14    11]]

 [[12208     1]
  [   18     0]]

 [[12144    24]
  [   50     9]]

 [[11997    25]
  [   84   121]]

 [[12142     8]
  [   58    19]]

 [[12150    18]
  [   24    35]]

 [[11999    89]
  [   75    64]]

 [[12185     1]
  [   14    27]]

 [[11903   149]
  [   79    96]]

 [[12175     9]
  [   29    14]]

 [[12185    16]
  [   15    11]]

 [[12041    81]
  [   39    66]]

 [[12210     3]
  [    8     6]]

 [[11846   139]
  [   57   185]]

 [[11879    39]
  [   84   225]]

 [[12162     7]
  [   25    33]]

 [[12215     1]
  [    9     2]]

 [[11998    42]
  [   96    91]]

 [[12167    14]
  [   34    12]]

 [[12170    17]
  [   31     9]]

 [[12182    12]
  [   12    21]]

 [[11892    46]
  [  110   179]]

 [[12194     1]
  [   29     3]]

 [[12116    37]
  [   21    53]]

 [[12196     4]
  [   18     9]]

 [[12182     8]
  [   18    19]]

 [[12200     3]
  [    4    20]]

 [[12188    13]
  [   25     1]]

 [[12143    19]
  [   38    27]]

 [[12202     3]
  [    8    14]]

 [[12148    15]
  [   11    53]]

 [[12185     2]
  [   31     9]]

 [[12214     0]
  [    2    11]]

 [[12004   110]
  [   19    94]]

 [[12019    46]
  [   34   128]]

 [[12203     0]
  [   16     8]]

 [[12165    10]
  [   13    39]]

 [[12210     2]
  [    3    12]]

 [[12046    58]
  [   48    75]]

 [[12180     6]
  [   25    16]]

 [[11660   137]
  [   23   407]]

 [[12147    15]
  [   13    52]]

 [[12189     7]
  [   12    19]]

 [[12036    18]
  [   55   118]]

 [[12190     7]
  [    6    24]]

 [[12098    11]
  [   24    94]]

 [[12084     7]
  [   43    93]]

 [[12161     5]
  [   22    39]]

 [[11978    24]
  [   34   191]]

 [[12192     0]
  [    5    30]]

 [[12181     8]
  [   10    28]]

 [[12184    12]
  [    9    22]]

 [[12209     2]
  [    9     7]]

 [[12197     9]
  [    5    16]]

 [[12131    23]
  [   16    57]]]

===scores report===
metrics	scores
Accuracy	0.6681
MCC	0.6608
log_loss	1.5877
f1 score weighted	0.6619
f1 score macro	0.5575
f1 score micro	0.6681
roc_auc ovr	0.9700
roc_auc ovo	0.9640
precision	0.6852
recall	0.6681

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc03411cd00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc03411cb80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc03411cbb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc03411cd90>, 'x_test': array([[ 0,  0,  0, ..., 14,  0, 14],
       [ 0,  0,  0, ...,  0,  5,  0],
       [ 0,  0,  0, ...,  0, 10,  0],
       ...,
       [ 0,  0,  0, ..., 19, 11, 11],
       [ 5, 16,  0, ...,  3,  5, 10],
       [ 0,  0,  0, ...,  7,  1, 17]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.56      0.86      0.68       357
         1.0       0.00      0.00      0.00        13
         2.0       1.00      0.05      0.10        19
         3.0       0.72      0.35      0.47        79
         4.0       0.50      0.07      0.13        55
         5.0       0.25      0.03      0.06        59
         6.0       1.00      0.07      0.13        44
         7.0       0.83      0.31      0.45        48
         8.0       0.00      0.00      0.00        10
         9.0       0.50      0.05      0.09        21
        10.0       1.00      0.13      0.24        15
        11.0       1.00      0.67      0.80        36
        12.0       0.75      0.25      0.38        12
        13.0       0.93      0.52      0.67        25
        14.0       0.33      0.05      0.09        20
        15.0       0.83      0.91      0.87        22
        16.0       0.83      0.65      0.73        23
        17.0       0.60      0.86      0.71       118
        18.0       0.56      0.50      0.53        18
        19.0       0.00      0.00      0.00        13
        20.0       0.53      0.10      0.17        89
        21.0       0.00      0.00      0.00        12
        22.0       1.00      0.54      0.70        24
        23.0       0.00      0.00      0.00        12
        24.0       0.00      0.00      0.00        23
        25.0       0.93      0.35      0.51        37
        26.0       0.92      0.71      0.80        17
        27.0       0.36      0.14      0.20        36
        28.0       0.00      0.00      0.00        12
        29.0       0.91      0.54      0.68        37
        30.0       0.73      0.34      0.47        32
        31.0       0.93      0.72      0.81        39
        32.0       0.91      0.76      0.83       746
        33.0       0.96      0.65      0.77        74
        34.0       0.93      0.69      0.79        58
        35.0       0.52      0.58      0.55        48
        36.0       0.57      0.66      0.61       502
        37.0       0.77      0.63      0.69       240
        38.0       0.50      0.27      0.35        33
        39.0       0.64      0.51      0.57       344
        40.0       0.94      0.50      0.66       191
        41.0       0.88      0.23      0.36        31
        42.0       0.65      0.70      0.67       384
        43.0       0.71      0.73      0.72       117
        44.0       0.65      0.74      0.69       436
        45.0       0.83      0.71      0.77        49
        46.0       0.92      0.76      0.83       402
        47.0       1.00      0.24      0.38        17
        48.0       0.57      0.62      0.59        42
        49.0       0.88      0.83      0.85        77
        50.0       0.87      0.90      0.88       172
        51.0       0.80      0.21      0.33        19
        52.0       0.33      0.80      0.47       499
        53.0       0.87      0.59      0.70        99
        54.0       0.11      0.18      0.14        11
        55.0       0.43      0.83      0.56       103
        56.0       1.00      0.44      0.62        18
        57.0       0.00      0.00      0.00        11
        58.0       0.97      0.94      0.96        35
        59.0       0.55      0.60      0.57       231
        60.0       0.55      0.79      0.65        57
        61.0       1.00      0.03      0.07        29
        62.0       0.67      0.42      0.51        48
        63.0       0.17      0.08      0.11        49
        64.0       0.95      0.56      0.70        34
        65.0       0.91      0.63      0.75       155
        66.0       0.00      0.00      0.00        14
        67.0       0.42      0.72      0.53       315
        68.0       0.20      0.03      0.05        63
        69.0       0.59      0.44      0.50       307
        70.0       0.34      0.25      0.29        69
        71.0       1.00      0.08      0.14        66
        72.0       0.27      0.20      0.23        15
        73.0       0.33      0.24      0.28        25
        74.0       0.00      0.00      0.00        18
        75.0       0.27      0.07      0.11        59
        76.0       0.59      0.67      0.63       206
        77.0       0.25      0.36      0.30        76
        78.0       0.92      0.39      0.55        59
        79.0       0.62      0.43      0.51       140
        80.0       0.92      0.83      0.88        42
        81.0       0.54      0.31      0.40       175
        82.0       0.31      0.42      0.35        43
        83.0       1.00      0.08      0.15        25
        84.0       0.32      0.48      0.38       105
        85.0       0.86      0.43      0.57        14
        86.0       0.75      0.67      0.71       242
        87.0       0.45      0.87      0.59       310
        88.0       0.92      0.39      0.55        59
        89.0       0.00      0.00      0.00        11
        90.0       0.32      0.68      0.43       187
        91.0       0.50      0.37      0.42        46
        92.0       0.19      0.17      0.18        40
        93.0       0.40      0.18      0.25        33
        94.0       0.42      0.71      0.53       289
        95.0       0.33      0.06      0.11        32
        96.0       0.97      0.41      0.58        75
        97.0       0.62      0.18      0.28        28
        98.0       0.60      0.68      0.63        37
        99.0       0.68      0.83      0.75        23
       100.0       0.50      0.04      0.07        25
       101.0       0.76      0.33      0.46        66
       102.0       0.79      0.71      0.75        21
       103.0       0.70      0.77      0.74        65
       104.0       0.88      0.17      0.29        40
       105.0       1.00      0.67      0.80        12
       106.0       0.92      0.61      0.73       113
       107.0       0.96      0.64      0.77       162
       108.0       0.64      0.29      0.40        24
       109.0       0.81      0.64      0.72        53
       110.0       1.00      0.21      0.35        14
       111.0       0.65      0.62      0.63       123
       112.0       0.75      0.22      0.34        41
       113.0       0.97      0.64      0.77       429
       114.0       0.94      0.49      0.65        65
       115.0       0.93      0.45      0.61        31
       116.0       0.89      0.72      0.80       173
       117.0       0.75      0.80      0.77        30
       118.0       0.92      0.69      0.79       117
       119.0       0.56      0.82      0.66       136
       120.0       0.60      0.62      0.61        61
       121.0       0.77      0.92      0.84       225
       122.0       0.76      0.74      0.75        35
       123.0       0.73      0.63      0.68        38
       124.0       0.71      0.50      0.59        30
       125.0       0.63      0.75      0.69        16
       126.0       0.94      0.73      0.82        22
       127.0       0.77      0.86      0.81        73

    accuracy                           0.61     12226
   macro avg       0.64      0.45      0.48     12226
weighted avg       0.67      0.61      0.60     12226


===confusion_matrix===

[[306   0   0 ...   0   0   0]
 [  4   0   0 ...   0   0   0]
 [  0   0   1 ...   0   0   0]
 ...
 [  0   0   0 ...  12   1   1]
 [  0   0   0 ...   1  16   3]
 [  0   0   0 ...   1   0  63]]

===multilabel confusion matrix===

[[[11629   240]
  [   51   306]]

 [[12213     0]
  [   13     0]]

 [[12207     0]
  [   18     1]]

 [[12136    11]
  [   51    28]]

 [[12167     4]
  [   51     4]]

 [[12161     6]
  [   57     2]]

 [[12182     0]
  [   41     3]]

 [[12175     3]
  [   33    15]]

 [[12216     0]
  [   10     0]]

 [[12204     1]
  [   20     1]]

 [[12211     0]
  [   13     2]]

 [[12190     0]
  [   12    24]]

 [[12213     1]
  [    9     3]]

 [[12200     1]
  [   12    13]]

 [[12204     2]
  [   19     1]]

 [[12200     4]
  [    2    20]]

 [[12200     3]
  [    8    15]]

 [[12041    67]
  [   16   102]]

 [[12201     7]
  [    9     9]]

 [[12213     0]
  [   13     0]]

 [[12129     8]
  [   80     9]]

 [[12214     0]
  [   12     0]]

 [[12202     0]
  [   11    13]]

 [[12213     1]
  [   12     0]]

 [[12203     0]
  [   23     0]]

 [[12188     1]
  [   24    13]]

 [[12208     1]
  [    5    12]]

 [[12181     9]
  [   31     5]]

 [[12213     1]
  [   12     0]]

 [[12187     2]
  [   17    20]]

 [[12190     4]
  [   21    11]]

 [[12185     2]
  [   11    28]]

 [[11427    53]
  [  182   564]]

 [[12150     2]
  [   26    48]]

 [[12165     3]
  [   18    40]]

 [[12152    26]
  [   20    28]]

 [[11479   245]
  [  172   330]]

 [[11940    46]
  [   89   151]]

 [[12184     9]
  [   24     9]]

 [[11786    96]
  [  170   174]]

 [[12029     6]
  [   95    96]]

 [[12194     1]
  [   24     7]]

 [[11699   143]
  [  116   268]]

 [[12074    35]
  [   32    85]]

 [[11618   172]
  [  114   322]]

 [[12170     7]
  [   14    35]]

 [[11796    28]
  [   96   306]]

 [[12209     0]
  [   13     4]]

 [[12164    20]
  [   16    26]]

 [[12140     9]
  [   13    64]]

 [[12030    24]
  [   18   154]]

 [[12206     1]
  [   15     4]]

 [[10905   822]
  [   98   401]]

 [[12118     9]
  [   41    58]]

 [[12199    16]
  [    9     2]]

 [[12007   116]
  [   17    86]]

 [[12208     0]
  [   10     8]]

 [[12215     0]
  [   11     0]]

 [[12190     1]
  [    2    33]]

 [[11880   115]
  [   92   139]]

 [[12132    37]
  [   12    45]]

 [[12197     0]
  [   28     1]]

 [[12168    10]
  [   28    20]]

 [[12158    19]
  [   45     4]]

 [[12191     1]
  [   15    19]]

 [[12061    10]
  [   57    98]]

 [[12210     2]
  [   14     0]]

 [[11593   318]
  [   89   226]]

 [[12155     8]
  [   61     2]]

 [[11826    93]
  [  172   135]]

 [[12124    33]
  [   52    17]]

 [[12160     0]
  [   61     5]]

 [[12203     8]
  [   12     3]]

 [[12189    12]
  [   19     6]]

 [[12208     0]
  [   18     0]]

 [[12156    11]
  [   55     4]]

 [[11922    98]
  [   67   139]]

 [[12071    79]
  [   49    27]]

 [[12165     2]
  [   36    23]]

 [[12049    37]
  [   80    60]]

 [[12181     3]
  [    7    35]]

 [[12005    46]
  [  120    55]]

 [[12142    41]
  [   25    18]]

 [[12201     0]
  [   23     2]]

 [[12015   106]
  [   55    50]]

 [[12211     1]
  [    8     6]]

 [[11930    54]
  [   80   162]]

 [[11583   333]
  [   41   269]]

 [[12165     2]
  [   36    23]]

 [[12213     2]
  [   11     0]]

 [[11768   271]
  [   60   127]]

 [[12163    17]
  [   29    17]]

 [[12156    30]
  [   33     7]]

 [[12184     9]
  [   27     6]]

 [[11657   280]
  [   83   206]]

 [[12190     4]
  [   30     2]]

 [[12150     1]
  [   44    31]]

 [[12195     3]
  [   23     5]]

 [[12172    17]
  [   12    25]]

 [[12194     9]
  [    4    19]]

 [[12200     1]
  [   24     1]]

 [[12153     7]
  [   44    22]]

 [[12201     4]
  [    6    15]]

 [[12140    21]
  [   15    50]]

 [[12185     1]
  [   33     7]]

 [[12214     0]
  [    4     8]]

 [[12107     6]
  [   44    69]]

 [[12060     4]
  [   59   103]]

 [[12198     4]
  [   17     7]]

 [[12165     8]
  [   19    34]]

 [[12212     0]
  [   11     3]]

 [[12062    41]
  [   47    76]]

 [[12182     3]
  [   32     9]]

 [[11789     8]
  [  154   275]]

 [[12159     2]
  [   33    32]]

 [[12194     1]
  [   17    14]]

 [[12037    16]
  [   48   125]]

 [[12188     8]
  [    6    24]]

 [[12102     7]
  [   36    81]]

 [[12001    89]
  [   25   111]]

 [[12140    25]
  [   23    38]]

 [[11939    62]
  [   19   206]]

 [[12183     8]
  [    9    26]]

 [[12179     9]
  [   14    24]]

 [[12190     6]
  [   15    15]]

 [[12203     7]
  [    4    12]]

 [[12203     1]
  [    6    16]]

 [[12134    19]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.6107
MCC	0.6032
log_loss	2.0336
f1 score weighted	0.6026
f1 score macro	0.4835
f1 score micro	0.6107
roc_auc ovr	0.9647
roc_auc ovo	0.9582
precision	0.6688
recall	0.6107

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc03411cd00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc03411cb80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc03411cbb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc03411cd90>, 'x_test': array([[ 0,  0,  0, ..., 10, 11, 15],
       [ 0,  0,  0, ...,  5, 12, 19],
       [ 0,  0,  0, ..., 11, 17,  0],
       ...,
       [16, 11, 14, ...,  2,  8, 10],
       [19,  5, 14, ...,  3,  1,  2],
       [ 7, 14, 14, ...,  8, 16, 10]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.77      0.77       358
         1.0       0.57      0.33      0.42        12
         2.0       0.73      0.44      0.55        18
         3.0       0.38      0.46      0.41        79
         4.0       0.34      0.20      0.25        55
         5.0       0.13      0.07      0.09        58
         6.0       0.54      0.33      0.41        45
         7.0       0.63      0.36      0.46        47
         8.0       0.14      0.10      0.12        10
         9.0       0.58      0.52      0.55        21
        10.0       1.00      0.20      0.33        15
        11.0       0.90      0.72      0.80        36
        12.0       1.00      0.17      0.29        12
        13.0       0.68      0.52      0.59        25
        14.0       0.30      0.15      0.20        20
        15.0       0.93      0.64      0.76        22
        16.0       0.56      0.39      0.46        23
        17.0       0.89      0.64      0.74       118
        18.0       0.50      0.39      0.44        18
        19.0       0.17      0.08      0.11        13
        20.0       0.71      0.33      0.45        89
        21.0       0.00      0.00      0.00        13
        22.0       1.00      0.56      0.72        25
        23.0       0.57      0.33      0.42        12
        24.0       0.75      0.13      0.22        23
        25.0       0.85      0.59      0.70        37
        26.0       1.00      0.94      0.97        17
        27.0       0.50      0.14      0.22        36
        28.0       0.38      0.25      0.30        12
        29.0       0.71      0.67      0.69        36
        30.0       0.84      0.66      0.74        32
        31.0       0.88      0.77      0.82        39
        32.0       0.81      0.82      0.81       747
        33.0       0.94      0.78      0.85        74
        34.0       0.66      0.84      0.74        58
        35.0       0.51      0.64      0.57        47
        36.0       0.55      0.70      0.61       502
        37.0       0.68      0.70      0.69       240
        38.0       0.57      0.50      0.53        34
        39.0       0.70      0.65      0.68       344
        40.0       0.73      0.73      0.73       191
        41.0       0.91      0.66      0.76        32
        42.0       0.73      0.72      0.72       384
        43.0       0.70      0.79      0.74       117
        44.0       0.71      0.72      0.72       437
        45.0       1.00      0.71      0.83        49
        46.0       0.73      0.86      0.79       401
        47.0       0.79      0.65      0.71        17
        48.0       0.85      0.52      0.65        42
        49.0       0.84      0.81      0.82        77
        50.0       0.92      0.77      0.84       171
        51.0       0.76      0.65      0.70        20
        52.0       0.59      0.69      0.64       499
        53.0       0.78      0.59      0.67       100
        54.0       0.00      0.00      0.00        11
        55.0       0.83      0.73      0.78       104
        56.0       0.33      0.11      0.16        19
        57.0       0.33      0.09      0.14        11
        58.0       1.00      0.89      0.94        35
        59.0       0.46      0.67      0.55       230
        60.0       0.82      0.79      0.81        58
        61.0       0.00      0.00      0.00        29
        62.0       0.33      0.24      0.28        49
        63.0       0.27      0.26      0.27        50
        64.0       0.95      0.62      0.75        34
        65.0       0.81      0.81      0.81       155
        66.0       0.33      0.07      0.12        14
        67.0       0.44      0.73      0.54       314
        68.0       0.17      0.16      0.17        62
        69.0       0.51      0.59      0.55       307
        70.0       0.62      0.29      0.40        68
        71.0       0.43      0.29      0.35        66
        72.0       0.60      0.20      0.30        15
        73.0       0.50      0.36      0.42        25
        74.0       0.00      0.00      0.00        19
        75.0       0.40      0.10      0.16        59
        76.0       0.46      0.74      0.57       206
        77.0       0.61      0.39      0.48        77
        78.0       0.57      0.63      0.60        59
        79.0       0.68      0.42      0.52       139
        80.0       0.97      0.79      0.87        42
        81.0       0.36      0.44      0.40       174
        82.0       0.46      0.26      0.33        43
        83.0       0.60      0.12      0.20        25
        84.0       0.44      0.63      0.52       105
        85.0       0.57      0.27      0.36        15
        86.0       0.60      0.62      0.61       242
        87.0       0.91      0.69      0.78       309
        88.0       0.89      0.66      0.76        59
        89.0       0.75      0.27      0.40        11
        90.0       0.31      0.71      0.43       188
        91.0       0.53      0.17      0.26        47
        92.0       0.26      0.23      0.24        40
        93.0       0.83      0.45      0.59        33
        94.0       0.41      0.64      0.50       288
        95.0       0.40      0.06      0.11        32
        96.0       0.76      0.68      0.72        75
        97.0       0.28      0.33      0.31        27
        98.0       0.77      0.45      0.57        38
        99.0       0.94      0.74      0.83        23
       100.0       0.00      0.00      0.00        25
       101.0       0.78      0.42      0.55        66
       102.0       1.00      0.77      0.87        22
       103.0       0.82      0.52      0.63        64
       104.0       0.46      0.31      0.37        39
       105.0       0.75      0.50      0.60        12
       106.0       0.70      0.73      0.71       113
       107.0       0.64      0.81      0.72       161
       108.0       0.60      0.26      0.36        23
       109.0       0.86      0.70      0.77        53
       110.0       1.00      0.71      0.83        14
       111.0       0.78      0.46      0.57       123
       112.0       0.57      0.39      0.46        41
       113.0       0.86      0.84      0.85       429
       114.0       0.88      0.68      0.77        65
       115.0       0.74      0.45      0.56        31
       116.0       0.88      0.68      0.76       173
       117.0       0.75      0.87      0.81        31
       118.0       0.91      0.72      0.80       117
       119.0       0.77      0.75      0.76       135
       120.0       0.90      0.60      0.72        62
       121.0       0.76      0.83      0.79       224
       122.0       0.93      0.80      0.86        35
       123.0       0.92      0.59      0.72        37
       124.0       0.80      0.40      0.53        30
       125.0       0.46      0.69      0.55        16
       126.0       0.74      0.91      0.82        22
       127.0       0.72      0.79      0.75        73

    accuracy                           0.65     12226
   macro avg       0.64      0.51      0.54     12226
weighted avg       0.67      0.65      0.64     12226


===confusion_matrix===

[[277   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0   8 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   0]
 [  0   0   0 ...   2  20   0]
 [  0   0   0 ...   4   5  58]]

===multilabel confusion matrix===

[[[11787    81]
  [   81   277]]

 [[12211     3]
  [    8     4]]

 [[12205     3]
  [   10     8]]

 [[12087    60]
  [   43    36]]

 [[12150    21]
  [   44    11]]

 [[12141    27]
  [   54     4]]

 [[12168    13]
  [   30    15]]

 [[12169    10]
  [   30    17]]

 [[12210     6]
  [    9     1]]

 [[12197     8]
  [   10    11]]

 [[12211     0]
  [   12     3]]

 [[12187     3]
  [   10    26]]

 [[12214     0]
  [   10     2]]

 [[12195     6]
  [   12    13]]

 [[12199     7]
  [   17     3]]

 [[12203     1]
  [    8    14]]

 [[12196     7]
  [   14     9]]

 [[12099     9]
  [   43    75]]

 [[12201     7]
  [   11     7]]

 [[12208     5]
  [   12     1]]

 [[12125    12]
  [   60    29]]

 [[12213     0]
  [   13     0]]

 [[12201     0]
  [   11    14]]

 [[12211     3]
  [    8     4]]

 [[12202     1]
  [   20     3]]

 [[12185     4]
  [   15    22]]

 [[12209     0]
  [    1    16]]

 [[12185     5]
  [   31     5]]

 [[12209     5]
  [    9     3]]

 [[12180    10]
  [   12    24]]

 [[12190     4]
  [   11    21]]

 [[12183     4]
  [    9    30]]

 [[11335   144]
  [  137   610]]

 [[12148     4]
  [   16    58]]

 [[12143    25]
  [    9    49]]

 [[12150    29]
  [   17    30]]

 [[11440   284]
  [  153   349]]

 [[11907    79]
  [   72   168]]

 [[12179    13]
  [   17    17]]

 [[11787    95]
  [  120   224]]

 [[11982    53]
  [   51   140]]

 [[12192     2]
  [   11    21]]

 [[11742   100]
  [  109   275]]

 [[12069    40]
  [   24    93]]

 [[11660   129]
  [  122   315]]

 [[12177     0]
  [   14    35]]

 [[11700   125]
  [   56   345]]

 [[12206     3]
  [    6    11]]

 [[12180     4]
  [   20    22]]

 [[12137    12]
  [   15    62]]

 [[12044    11]
  [   39   132]]

 [[12202     4]
  [    7    13]]

 [[11490   237]
  [  153   346]]

 [[12109    17]
  [   41    59]]

 [[12214     1]
  [   11     0]]

 [[12106    16]
  [   28    76]]

 [[12203     4]
  [   17     2]]

 [[12213     2]
  [   10     1]]

 [[12191     0]
  [    4    31]]

 [[11817   179]
  [   76   154]]

 [[12158    10]
  [   12    46]]

 [[12192     5]
  [   29     0]]

 [[12153    24]
  [   37    12]]

 [[12141    35]
  [   37    13]]

 [[12191     1]
  [   13    21]]

 [[12042    29]
  [   30   125]]

 [[12210     2]
  [   13     1]]

 [[11616   296]
  [   86   228]]

 [[12115    49]
  [   52    10]]

 [[11746   173]
  [  127   180]]

 [[12146    12]
  [   48    20]]

 [[12135    25]
  [   47    19]]

 [[12209     2]
  [   12     3]]

 [[12192     9]
  [   16     9]]

 [[12207     0]
  [   19     0]]

 [[12158     9]
  [   53     6]]

 [[11841   179]
  [   54   152]]

 [[12130    19]
  [   47    30]]

 [[12139    28]
  [   22    37]]

 [[12059    28]
  [   80    59]]

 [[12183     1]
  [    9    33]]

 [[11915   137]
  [   97    77]]

 [[12170    13]
  [   32    11]]

 [[12199     2]
  [   22     3]]

 [[12038    83]
  [   39    66]]

 [[12208     3]
  [   11     4]]

 [[11884   100]
  [   91   151]]

 [[11895    22]
  [   97   212]]

 [[12162     5]
  [   20    39]]

 [[12214     1]
  [    8     3]]

 [[11737   301]
  [   54   134]]

 [[12172     7]
  [   39     8]]

 [[12160    26]
  [   31     9]]

 [[12190     3]
  [   18    15]]

 [[11677   261]
  [  105   183]]

 [[12191     3]
  [   30     2]]

 [[12135    16]
  [   24    51]]

 [[12176    23]
  [   18     9]]

 [[12183     5]
  [   21    17]]

 [[12202     1]
  [    6    17]]

 [[12198     3]
  [   25     0]]

 [[12152     8]
  [   38    28]]

 [[12204     0]
  [    5    17]]

 [[12155     7]
  [   31    33]]

 [[12173    14]
  [   27    12]]

 [[12212     2]
  [    6     6]]

 [[12078    35]
  [   31    82]]

 [[11991    74]
  [   30   131]]

 [[12199     4]
  [   17     6]]

 [[12167     6]
  [   16    37]]

 [[12212     0]
  [    4    10]]

 [[12087    16]
  [   67    56]]

 [[12173    12]
  [   25    16]]

 [[11739    58]
  [   70   359]]

 [[12155     6]
  [   21    44]]

 [[12190     5]
  [   17    14]]

 [[12037    16]
  [   56   117]]

 [[12186     9]
  [    4    27]]

 [[12101     8]
  [   33    84]]

 [[12061    30]
  [   34   101]]

 [[12160     4]
  [   25    37]]

 [[11942    60]
  [   39   185]]

 [[12189     2]
  [    7    28]]

 [[12187     2]
  [   15    22]]

 [[12193     3]
  [   18    12]]

 [[12197    13]
  [    5    11]]

 [[12197     7]
  [    2    20]]

 [[12130    23]
  [   15    58]]]

===scores report===
metrics	scores
Accuracy	0.6473
MCC	0.6396
log_loss	1.6988
f1 score weighted	0.6433
f1 score macro	0.5448
f1 score micro	0.6473
roc_auc ovr	0.9686
roc_auc ovo	0.9642
precision	0.6685
recall	0.6473

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc03411cd00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc03411cb80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc03411cbb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fc03411cd90>, 'x_test': array([[ 0,  0,  0, ...,  1, 19, 16],
       [ 0,  0,  0, ...,  5, 14,  1],
       [ 0,  0,  0, ..., 15,  9, 11],
       ...,
       [19, 18, 10, ...,  0, 18,  4],
       [19, 19, 19, ...,  0,  6,  0],
       [10, 10,  1, ...,  0, 15,  0]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.69      0.75       358
         1.0       0.50      0.50      0.50        12
         2.0       1.00      0.11      0.19        19
         3.0       0.54      0.47      0.50        79
         4.0       0.42      0.15      0.22        55
         5.0       0.24      0.07      0.11        58
         6.0       0.69      0.20      0.31        45
         7.0       0.72      0.45      0.55        47
         8.0       0.00      0.00      0.00        10
         9.0       0.80      0.19      0.31        21
        10.0       0.00      0.00      0.00        15
        11.0       0.90      0.72      0.80        36
        12.0       0.00      0.00      0.00        12
        13.0       0.80      0.32      0.46        25
        14.0       0.75      0.16      0.26        19
        15.0       0.88      0.64      0.74        22
        16.0       1.00      0.22      0.36        23
        17.0       0.76      0.86      0.81       118
        18.0       0.80      0.44      0.57        18
        19.0       1.00      0.08      0.15        12
        20.0       0.55      0.46      0.50        90
        21.0       1.00      0.15      0.27        13
        22.0       0.71      0.68      0.69        25
        23.0       1.00      0.08      0.14        13
        24.0       0.83      0.23      0.36        22
        25.0       0.63      0.32      0.42        38
        26.0       1.00      0.94      0.97        17
        27.0       0.33      0.06      0.10        35
        28.0       0.00      0.00      0.00        12
        29.0       0.86      0.50      0.63        36
        30.0       0.41      0.62      0.49        32
        31.0       0.83      0.79      0.81        38
        32.0       0.73      0.82      0.78       747
        33.0       0.86      0.81      0.84        75
        34.0       0.73      0.73      0.73        59
        35.0       0.79      0.57      0.67        47
        36.0       0.52      0.75      0.61       501
        37.0       0.69      0.51      0.59       241
        38.0       0.35      0.52      0.41        33
        39.0       0.69      0.59      0.64       344
        40.0       0.52      0.79      0.63       192
        41.0       0.83      0.59      0.69        32
        42.0       0.82      0.71      0.76       384
        43.0       0.70      0.81      0.75       117
        44.0       0.80      0.63      0.70       436
        45.0       0.80      0.88      0.83        49
        46.0       0.67      0.88      0.76       401
        47.0       0.00      0.00      0.00        17
        48.0       0.79      0.62      0.69        42
        49.0       0.88      0.84      0.86        77
        50.0       0.72      0.85      0.78       172
        51.0       0.59      0.50      0.54        20
        52.0       0.47      0.76      0.58       499
        53.0       0.88      0.58      0.70       100
        54.0       0.43      0.27      0.33        11
        55.0       0.56      0.81      0.66       104
        56.0       0.75      0.17      0.27        18
        57.0       0.33      0.10      0.15        10
        58.0       0.86      0.71      0.78        35
        59.0       0.42      0.61      0.50       230
        60.0       0.83      0.74      0.78        58
        61.0       0.00      0.00      0.00        29
        62.0       0.43      0.41      0.42        49
        63.0       0.33      0.18      0.23        50
        64.0       0.96      0.65      0.77        34
        65.0       0.64      0.79      0.71       155
        66.0       0.14      0.07      0.10        14
        67.0       0.68      0.62      0.65       314
        68.0       0.10      0.05      0.07        62
        69.0       0.54      0.41      0.46       307
        70.0       0.43      0.32      0.37        68
        71.0       0.52      0.20      0.29        66
        72.0       0.13      0.14      0.14        14
        73.0       0.55      0.50      0.52        24
        74.0       0.00      0.00      0.00        19
        75.0       0.12      0.23      0.16        60
        76.0       0.74      0.63      0.68       206
        77.0       0.71      0.26      0.38        77
        78.0       0.86      0.51      0.64        59
        79.0       0.84      0.27      0.41       139
        80.0       0.93      0.62      0.74        42
        81.0       0.50      0.37      0.43       174
        82.0       0.48      0.37      0.42        43
        83.0       0.67      0.08      0.14        26
        84.0       0.48      0.60      0.53       106
        85.0       0.67      0.40      0.50        15
        86.0       0.79      0.53      0.63       241
        87.0       0.42      0.87      0.57       309
        88.0       0.71      0.51      0.59        59
        89.0       0.20      0.10      0.13        10
        90.0       0.53      0.55      0.54       188
        91.0       0.37      0.41      0.39        46
        92.0       0.14      0.05      0.07        41
        93.0       0.77      0.62      0.69        32
        94.0       0.45      0.66      0.54       288
        95.0       0.16      0.16      0.16        31
        96.0       0.80      0.60      0.69        75
        97.0       0.24      0.44      0.32        27
        98.0       0.78      0.55      0.65        38
        99.0       1.00      0.88      0.93        24
       100.0       1.00      0.04      0.08        25
       101.0       0.65      0.51      0.57        65
       102.0       0.65      0.68      0.67        22
       103.0       0.75      0.75      0.75        64
       104.0       0.69      0.28      0.39        40
       105.0       1.00      0.75      0.86        12
       106.0       0.81      0.65      0.72       113
       107.0       0.84      0.73      0.78       161
       108.0       0.53      0.33      0.41        24
       109.0       0.76      0.56      0.64        52
       110.0       1.00      0.73      0.85        15
       111.0       0.62      0.57      0.59       124
       112.0       0.31      0.51      0.39        41
       113.0       0.81      0.87      0.84       430
       114.0       0.62      0.74      0.67        65
       115.0       1.00      0.35      0.52        31
       116.0       0.86      0.75      0.80       173
       117.0       0.92      0.74      0.82        31
       118.0       0.77      0.79      0.78       117
       119.0       0.75      0.73      0.74       136
       120.0       0.54      0.79      0.64        62
       121.0       0.84      0.80      0.82       224
       122.0       1.00      0.74      0.85        35
       123.0       0.87      0.73      0.79        37
       124.0       0.58      0.81      0.68        31
       125.0       0.65      0.73      0.69        15
       126.0       0.73      0.76      0.74        21
       127.0       0.86      0.70      0.77        73

    accuracy                           0.63     12226
   macro avg       0.63      0.49      0.52     12226
weighted avg       0.66      0.63      0.62     12226


===confusion_matrix===

[[248   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0   2 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   0]
 [  0   0   0 ...   0  16   2]
 [  0   0   0 ...   0   4  51]]

===multilabel confusion matrix===

[[[11815    53]
  [  110   248]]

 [[12208     6]
  [    6     6]]

 [[12207     0]
  [   17     2]]

 [[12115    32]
  [   42    37]]

 [[12160    11]
  [   47     8]]

 [[12155    13]
  [   54     4]]

 [[12177     4]
  [   36     9]]

 [[12171     8]
  [   26    21]]

 [[12215     1]
  [   10     0]]

 [[12204     1]
  [   17     4]]

 [[12211     0]
  [   15     0]]

 [[12187     3]
  [   10    26]]

 [[12214     0]
  [   12     0]]

 [[12199     2]
  [   17     8]]

 [[12206     1]
  [   16     3]]

 [[12202     2]
  [    8    14]]

 [[12203     0]
  [   18     5]]

 [[12076    32]
  [   16   102]]

 [[12206     2]
  [   10     8]]

 [[12214     0]
  [   11     1]]

 [[12102    34]
  [   49    41]]

 [[12213     0]
  [   11     2]]

 [[12194     7]
  [    8    17]]

 [[12213     0]
  [   12     1]]

 [[12203     1]
  [   17     5]]

 [[12181     7]
  [   26    12]]

 [[12209     0]
  [    1    16]]

 [[12187     4]
  [   33     2]]

 [[12212     2]
  [   12     0]]

 [[12187     3]
  [   18    18]]

 [[12165    29]
  [   12    20]]

 [[12182     6]
  [    8    30]]

 [[11257   222]
  [  133   614]]

 [[12141    10]
  [   14    61]]

 [[12151    16]
  [   16    43]]

 [[12172     7]
  [   20    27]]

 [[11376   349]
  [  126   375]]

 [[11928    57]
  [  117   124]]

 [[12161    32]
  [   16    17]]

 [[11793    89]
  [  142   202]]

 [[11895   139]
  [   40   152]]

 [[12190     4]
  [   13    19]]

 [[11781    61]
  [  113   271]]

 [[12068    41]
  [   22    95]]

 [[11720    70]
  [  162   274]]

 [[12166    11]
  [    6    43]]

 [[11651   174]
  [   47   354]]

 [[12209     0]
  [   17     0]]

 [[12177     7]
  [   16    26]]

 [[12140     9]
  [   12    65]]

 [[11998    56]
  [   26   146]]

 [[12199     7]
  [   10    10]]

 [[11303   424]
  [  121   378]]

 [[12118     8]
  [   42    58]]

 [[12211     4]
  [    8     3]]

 [[12056    66]
  [   20    84]]

 [[12207     1]
  [   15     3]]

 [[12214     2]
  [    9     1]]

 [[12187     4]
  [   10    25]]

 [[11805   191]
  [   90   140]]

 [[12159     9]
  [   15    43]]

 [[12193     4]
  [   29     0]]

 [[12150    27]
  [   29    20]]

 [[12158    18]
  [   41     9]]

 [[12191     1]
  [   12    22]]

 [[12003    68]
  [   32   123]]

 [[12206     6]
  [   13     1]]

 [[11822    90]
  [  120   194]]

 [[12138    26]
  [   59     3]]

 [[11812   107]
  [  182   125]]

 [[12129    29]
  [   46    22]]

 [[12148    12]
  [   53    13]]

 [[12199    13]
  [   12     2]]

 [[12192    10]
  [   12    12]]

 [[12206     1]
  [   19     0]]

 [[12061   105]
  [   46    14]]

 [[11974    46]
  [   76   130]]

 [[12141     8]
  [   57    20]]

 [[12162     5]
  [   29    30]]

 [[12080     7]
  [  101    38]]

 [[12182     2]
  [   16    26]]

 [[11987    65]
  [  109    65]]

 [[12166    17]
  [   27    16]]

 [[12199     1]
  [   24     2]]

 [[12050    70]
  [   42    64]]

 [[12208     3]
  [    9     6]]

 [[11951    34]
  [  114   127]]

 [[11549   368]
  [   39   270]]

 [[12155    12]
  [   29    30]]

 [[12212     4]
  [    9     1]]

 [[11947    91]
  [   84   104]]

 [[12147    33]
  [   27    19]]

 [[12173    12]
  [   39     2]]

 [[12188     6]
  [   12    20]]

 [[11703   235]
  [   97   191]]

 [[12168    27]
  [   26     5]]

 [[12140    11]
  [   30    45]]

 [[12162    37]
  [   15    12]]

 [[12182     6]
  [   17    21]]

 [[12202     0]
  [    3    21]]

 [[12201     0]
  [   24     1]]

 [[12143    18]
  [   32    33]]

 [[12196     8]
  [    7    15]]

 [[12146    16]
  [   16    48]]

 [[12181     5]
  [   29    11]]

 [[12214     0]
  [    3     9]]

 [[12096    17]
  [   40    73]]

 [[12042    23]
  [   44   117]]

 [[12195     7]
  [   16     8]]

 [[12165     9]
  [   23    29]]

 [[12211     0]
  [    4    11]]

 [[12058    44]
  [   53    71]]

 [[12138    47]
  [   20    21]]

 [[11707    89]
  [   55   375]]

 [[12131    30]
  [   17    48]]

 [[12195     0]
  [   20    11]]

 [[12031    22]
  [   43   130]]

 [[12193     2]
  [    8    23]]

 [[12081    28]
  [   25    92]]

 [[12057    33]
  [   37    99]]

 [[12122    42]
  [   13    49]]

 [[11967    35]
  [   44   180]]

 [[12191     0]
  [    9    26]]

 [[12185     4]
  [   10    27]]

 [[12177    18]
  [    6    25]]

 [[12205     6]
  [    4    11]]

 [[12199     6]
  [    5    16]]

 [[12145     8]
  [   22    51]]]

===scores report===
metrics	scores
Accuracy	0.6345
MCC	0.6267
log_loss	1.7523
f1 score weighted	0.6249
f1 score macro	0.5195
f1 score micro	0.6345
roc_auc ovr	0.9690
roc_auc ovo	0.9621
precision	0.6584
recall	0.6345

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6378506583789973	0.6297975185839517	1.6630990013825078	0.628598624161422	0.5171886645922814	0.6378506583789973	0.9678934834246758	0.9625868129929621	0.6566487906657805	0.6378506583789973
1	0.6681115563915924	0.6607615813133106	1.5876572562062927	0.6619111141134003	0.557540185664328	0.6681115563915924	0.9700118384748785	0.9639913031899094	0.6851697726690139	0.6681115563915924
2	0.6107475871094389	0.6031971472639115	2.0336378201806875	0.602645428490762	0.48353157418504417	0.6107475871094389	0.964669261852959	0.958216160156237	0.6687891915347227	0.6107475871094389
3	0.6473090135776215	0.6395903862127162	1.6988288139920356	0.6432725288702287	0.5447643538668969	0.6473090135776215	0.9686043091483045	0.9641795109319818	0.6685078746192623	0.6473090135776215
4	0.6345493211189269	0.6266618825683633	1.7523355522652306	0.6249193047616175	0.5194574116170244	0.6345493211189269	0.9689584081378458	0.9621005844517235	0.6583889492622134	0.6345493211189269
mean	0.6397136273153154	0.6320017031884506	1.7471116888053508	0.6322694000794861	0.524496437985115	0.6397136273153154	0.9680274602077328	0.9622148743445628	0.6675009157501985	0.6397136273153154
std	0.01861883167790655	0.018696487669265054	0.15293109326366455	0.01972195854252788	0.025532696997129588	0.01861883167790655	0.0018128773717129608	0.0021520507457261076	0.010155379634504729	0.01861883167790655

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 35272.3113 secs

