/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_hot_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2384dbd30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff2384dbf40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2384dbbb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff2384dbee0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.85      0.78       358
         1.0       0.75      0.25      0.38        12
         2.0       0.61      0.58      0.59        19
         3.0       0.69      0.65      0.67        80
         4.0       0.46      0.46      0.46        54
         5.0       0.28      0.19      0.22        58
         6.0       0.45      0.44      0.45        45
         7.0       0.67      0.62      0.65        48
         8.0       0.00      0.00      0.00        11
         9.0       0.56      0.48      0.51        21
        10.0       0.30      0.20      0.24        15
        11.0       0.85      0.81      0.83        36
        12.0       0.73      0.67      0.70        12
        13.0       0.72      0.72      0.72        25
        14.0       0.71      0.26      0.38        19
        15.0       0.89      0.73      0.80        22
        16.0       0.71      0.65      0.68        23
        17.0       0.85      0.84      0.85       119
        18.0       0.74      0.78      0.76        18
        19.0       0.00      0.00      0.00        12
        20.0       0.62      0.58      0.60        90
        21.0       1.00      0.33      0.50        12
        22.0       0.76      0.88      0.81        25
        23.0       0.00      0.00      0.00        12
        24.0       0.57      0.36      0.44        22
        25.0       0.71      0.63      0.67        38
        26.0       1.00      1.00      1.00        17
        27.0       0.38      0.17      0.24        35
        28.0       0.50      0.09      0.15        11
        29.0       0.64      0.75      0.69        36
        30.0       0.77      0.94      0.85        32
        31.0       0.90      0.74      0.81        38
        32.0       0.80      0.85      0.82       747
        33.0       0.97      0.85      0.91        74
        34.0       0.97      0.97      0.97        59
        35.0       0.82      0.77      0.80        48
        36.0       0.72      0.77      0.74       502
        37.0       0.71      0.80      0.75       241
        38.0       0.81      0.64      0.71        33
        39.0       0.73      0.78      0.75       344
        40.0       0.79      0.70      0.74       191
        41.0       0.91      0.62      0.74        32
        42.0       0.76      0.80      0.78       384
        43.0       0.74      0.77      0.76       118
        44.0       0.77      0.74      0.75       436
        45.0       0.98      0.83      0.90        48
        46.0       0.82      0.87      0.84       402
        47.0       0.70      0.41      0.52        17
        48.0       0.78      0.67      0.72        42
        49.0       0.91      0.95      0.93        78
        50.0       0.86      0.88      0.87       172
        51.0       0.90      0.45      0.60        20
        52.0       0.71      0.77      0.74       499
        53.0       0.81      0.79      0.80       100
        54.0       0.50      0.36      0.42        11
        55.0       0.82      0.78      0.80       103
        56.0       0.64      0.50      0.56        18
        57.0       0.57      0.40      0.47        10
        58.0       0.94      1.00      0.97        34
        59.0       0.69      0.66      0.68       231
        60.0       0.91      0.71      0.80        58
        61.0       0.36      0.17      0.23        30
        62.0       0.79      0.62      0.70        48
        63.0       0.48      0.44      0.46        50
        64.0       0.79      0.65      0.71        34
        65.0       0.79      0.74      0.76       155
        66.0       0.60      0.43      0.50        14
        67.0       0.72      0.70      0.71       314
        68.0       0.50      0.21      0.29        63
        69.0       0.55      0.81      0.66       308
        70.0       0.58      0.56      0.57        68
        71.0       0.66      0.71      0.69        66
        72.0       0.33      0.21      0.26        14
        73.0       0.70      0.56      0.62        25
        74.0       0.33      0.06      0.10        18
        75.0       0.50      0.52      0.51        60
        76.0       0.81      0.72      0.76       205
        77.0       0.49      0.40      0.44        77
        78.0       0.83      0.75      0.79        59
        79.0       0.68      0.68      0.68       139
        80.0       0.94      0.81      0.87        42
        81.0       0.53      0.59      0.56       175
        82.0       0.62      0.53      0.57        43
        83.0       0.33      0.23      0.27        26
        84.0       0.56      0.62      0.59       106
        85.0       0.67      0.57      0.62        14
        86.0       0.73      0.79      0.75       242
        87.0       0.80      0.79      0.79       309
        88.0       0.85      0.69      0.76        58
        89.0       0.33      0.18      0.24        11
        90.0       0.66      0.67      0.66       187
        91.0       0.53      0.46      0.49        46
        92.0       0.52      0.38      0.43        40
        93.0       0.79      0.69      0.73        32
        94.0       0.62      0.76      0.69       289
        95.0       0.44      0.26      0.33        31
        96.0       0.84      0.85      0.85        74
        97.0       0.58      0.52      0.55        27
        98.0       0.84      0.73      0.78        37
        99.0       0.88      0.92      0.90        24
       100.0       0.31      0.20      0.24        25
       101.0       0.70      0.65      0.67        65
       102.0       0.95      0.86      0.90        22
       103.0       0.82      0.83      0.82        64
       104.0       0.62      0.40      0.48        40
       105.0       0.77      0.83      0.80        12
       106.0       0.87      0.84      0.86       114
       107.0       0.80      0.83      0.82       161
       108.0       1.00      0.54      0.70        24
       109.0       0.90      0.71      0.80        52
       110.0       0.93      0.87      0.90        15
       111.0       0.78      0.74      0.76       123
       112.0       0.65      0.48      0.55        42
       113.0       0.80      0.93      0.86       430
       114.0       0.81      0.78      0.80        65
       115.0       0.75      0.58      0.65        31
       116.0       0.83      0.76      0.79       173
       117.0       0.91      0.97      0.94        31
       118.0       0.91      0.87      0.89       117
       119.0       0.84      0.90      0.87       136
       120.0       0.89      0.65      0.75        62
       121.0       0.87      0.87      0.87       224
       122.0       0.84      0.74      0.79        35
       123.0       0.85      0.76      0.80        37
       124.0       0.81      0.84      0.83        31
       125.0       1.00      0.87      0.93        15
       126.0       0.89      0.76      0.82        21
       127.0       0.82      0.90      0.86        73

    accuracy                           0.74     12227
   macro avg       0.70      0.63      0.66     12227
weighted avg       0.74      0.74      0.74     12227


===confusion_matrix===

[[303   0   0 ...   0   0   0]
 [  0   3   0 ...   0   0   0]
 [  0   0  11 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  16   4]
 [  0   0   0 ...   0   1  66]]

===multilabel confusion matrix===

[[[11757   112]
  [   55   303]]

 [[12214     1]
  [    9     3]]

 [[12201     7]
  [    8    11]]

 [[12124    23]
  [   28    52]]

 [[12144    29]
  [   29    25]]

 [[12140    29]
  [   47    11]]

 [[12158    24]
  [   25    20]]

 [[12164    15]
  [   18    30]]

 [[12216     0]
  [   11     0]]

 [[12198     8]
  [   11    10]]

 [[12205     7]
  [   12     3]]

 [[12186     5]
  [    7    29]]

 [[12212     3]
  [    4     8]]

 [[12195     7]
  [    7    18]]

 [[12206     2]
  [   14     5]]

 [[12203     2]
  [    6    16]]

 [[12198     6]
  [    8    15]]

 [[12091    17]
  [   19   100]]

 [[12204     5]
  [    4    14]]

 [[12210     5]
  [   12     0]]

 [[12105    32]
  [   38    52]]

 [[12215     0]
  [    8     4]]

 [[12195     7]
  [    3    22]]

 [[12214     1]
  [   12     0]]

 [[12199     6]
  [   14     8]]

 [[12179    10]
  [   14    24]]

 [[12210     0]
  [    0    17]]

 [[12182    10]
  [   29     6]]

 [[12215     1]
  [   10     1]]

 [[12176    15]
  [    9    27]]

 [[12186     9]
  [    2    30]]

 [[12186     3]
  [   10    28]]

 [[11321   159]
  [  112   635]]

 [[12151     2]
  [   11    63]]

 [[12166     2]
  [    2    57]]

 [[12171     8]
  [   11    37]]

 [[11576   149]
  [  116   386]]

 [[11906    80]
  [   47   194]]

 [[12189     5]
  [   12    21]]

 [[11783   100]
  [   77   267]]

 [[12000    36]
  [   58   133]]

 [[12193     2]
  [   12    20]]

 [[11744    99]
  [   76   308]]

 [[12077    32]
  [   27    91]]

 [[11694    97]
  [  113   323]]

 [[12178     1]
  [    8    40]]

 [[11748    77]
  [   53   349]]

 [[12207     3]
  [   10     7]]

 [[12177     8]
  [   14    28]]

 [[12142     7]
  [    4    74]]

 [[12031    24]
  [   20   152]]

 [[12206     1]
  [   11     9]]

 [[11572   156]
  [  114   385]]

 [[12109    18]
  [   21    79]]

 [[12212     4]
  [    7     4]]

 [[12107    17]
  [   23    80]]

 [[12204     5]
  [    9     9]]

 [[12214     3]
  [    6     4]]

 [[12191     2]
  [    0    34]]

 [[11927    69]
  [   78   153]]

 [[12165     4]
  [   17    41]]

 [[12188     9]
  [   25     5]]

 [[12171     8]
  [   18    30]]

 [[12153    24]
  [   28    22]]

 [[12187     6]
  [   12    22]]

 [[12042    30]
  [   41   114]]

 [[12209     4]
  [    8     6]]

 [[11828    85]
  [   93   221]]

 [[12151    13]
  [   50    13]]

 [[11719   200]
  [   60   248]]

 [[12132    27]
  [   30    38]]

 [[12137    24]
  [   19    47]]

 [[12207     6]
  [   11     3]]

 [[12196     6]
  [   11    14]]

 [[12207     2]
  [   17     1]]

 [[12136    31]
  [   29    31]]

 [[11988    34]
  [   58   147]]

 [[12118    32]
  [   46    31]]

 [[12159     9]
  [   15    44]]

 [[12043    45]
  [   45    94]]

 [[12183     2]
  [    8    34]]

 [[11962    90]
  [   72   103]]

 [[12170    14]
  [   20    23]]

 [[12189    12]
  [   20     6]]

 [[12069    52]
  [   40    66]]

 [[12209     4]
  [    6     8]]

 [[11913    72]
  [   52   190]]

 [[11855    63]
  [   64   245]]

 [[12162     7]
  [   18    40]]

 [[12212     4]
  [    9     2]]

 [[11976    64]
  [   62   125]]

 [[12162    19]
  [   25    21]]

 [[12173    14]
  [   25    15]]

 [[12189     6]
  [   10    22]]

 [[11805   133]
  [   69   220]]

 [[12186    10]
  [   23     8]]

 [[12141    12]
  [   11    63]]

 [[12190    10]
  [   13    14]]

 [[12185     5]
  [   10    27]]

 [[12200     3]
  [    2    22]]

 [[12191    11]
  [   20     5]]

 [[12144    18]
  [   23    42]]

 [[12204     1]
  [    3    19]]

 [[12151    12]
  [   11    53]]

 [[12177    10]
  [   24    16]]

 [[12212     3]
  [    2    10]]

 [[12099    14]
  [   18    96]]

 [[12033    33]
  [   27   134]]

 [[12203     0]
  [   11    13]]

 [[12171     4]
  [   15    37]]

 [[12211     1]
  [    2    13]]

 [[12079    25]
  [   32    91]]

 [[12174    11]
  [   22    20]]

 [[11699    98]
  [   28   402]]

 [[12150    12]
  [   14    51]]

 [[12190     6]
  [   13    18]]

 [[12028    26]
  [   42   131]]

 [[12193     3]
  [    1    30]]

 [[12100    10]
  [   15   102]]

 [[12067    24]
  [   13   123]]

 [[12160     5]
  [   22    40]]

 [[11973    30]
  [   29   195]]

 [[12187     5]
  [    9    26]]

 [[12185     5]
  [    9    28]]

 [[12190     6]
  [    5    26]]

 [[12212     0]
  [    2    13]]

 [[12204     2]
  [    5    16]]

 [[12140    14]
  [    7    66]]]

===scores report===
metrics	scores
Accuracy	0.7423
MCC	0.7366
log_loss	1.2811
f1 score weighted	0.7367
f1 score macro	0.6555
f1 score micro	0.7423
roc_auc ovr	0.9811
roc_auc ovo	0.9788
precision	0.7398
recall	0.7423

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2384dbd30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff2384dbf40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2384dbbb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7ff2384dbee0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.68      0.88      0.76       357
         1.0       0.50      0.33      0.40        12
         2.0       0.76      0.68      0.72        19
         3.0       0.67      0.60      0.63        80
         4.0       0.27      0.33      0.30        54
         5.0       0.21      0.14      0.16        58
         6.0       0.41      0.25      0.31        44
         7.0       0.75      0.62      0.68        48
         8.0       0.00      0.00      0.00        11
         9.0       0.71      0.81      0.76        21
        10.0       0.29      0.13      0.18        15
        11.0       0.76      0.72      0.74        36
        12.0       0.00      0.00      0.00        12
        13.0       0.71      0.60      0.65        25
        14.0       0.55      0.30      0.39        20
        15.0       0.86      0.78      0.82        23
        16.0       0.56      0.61      0.58        23
        17.0       0.87      0.87      0.87       119
        18.0       0.77      0.59      0.67        17
        19.0       0.00      0.00      0.00        13
        20.0       0.61      0.43      0.51        90
        21.0       0.60      0.25      0.35        12
        22.0       0.89      0.68      0.77        25
        23.0       0.25      0.08      0.12        12
        24.0       0.46      0.27      0.34        22
        25.0       0.79      0.59      0.68        37
        26.0       0.94      0.94      0.94        18
        27.0       0.50      0.14      0.22        35
        28.0       1.00      0.25      0.40        12
        29.0       0.64      0.57      0.60        37
        30.0       0.78      0.78      0.78        32
        31.0       0.97      0.77      0.86        39
        32.0       0.77      0.85      0.81       746
        33.0       0.92      0.92      0.92        74
        34.0       0.89      0.86      0.88        58
        35.0       0.72      0.71      0.72        48
        36.0       0.69      0.70      0.69       502
        37.0       0.68      0.73      0.70       241
        38.0       0.82      0.70      0.75        33
        39.0       0.67      0.72      0.70       344
        40.0       0.79      0.74      0.76       191
        41.0       0.92      0.71      0.80        31
        42.0       0.73      0.79      0.76       384
        43.0       0.83      0.90      0.86       118
        44.0       0.73      0.74      0.73       436
        45.0       0.95      0.85      0.90        48
        46.0       0.77      0.87      0.82       402
        47.0       0.86      0.35      0.50        17
        48.0       0.73      0.45      0.56        42
        49.0       0.90      0.96      0.93        77
        50.0       0.89      0.86      0.88       172
        51.0       0.84      0.80      0.82        20
        52.0       0.65      0.75      0.70       499
        53.0       0.87      0.70      0.78        99
        54.0       0.83      0.45      0.59        11
        55.0       0.82      0.82      0.82       103
        56.0       0.85      0.61      0.71        18
        57.0       0.50      0.09      0.15        11
        58.0       0.94      0.91      0.93        34
        59.0       0.64      0.71      0.67       231
        60.0       0.87      0.71      0.78        58
        61.0       0.12      0.03      0.05        30
        62.0       0.61      0.46      0.52        48
        63.0       0.28      0.22      0.25        49
        64.0       0.96      0.71      0.81        34
        65.0       0.83      0.76      0.79       154
        66.0       0.33      0.07      0.12        14
        67.0       0.68      0.61      0.64       314
        68.0       0.41      0.19      0.26        63
        69.0       0.53      0.74      0.62       308
        70.0       0.62      0.49      0.55        69
        71.0       0.43      0.45      0.44        66
        72.0       0.00      0.00      0.00        14
        73.0       0.88      0.56      0.68        25
        74.0       0.60      0.17      0.26        18
        75.0       0.52      0.58      0.54        59
        76.0       0.76      0.70      0.73       205
        77.0       0.46      0.36      0.41        77
        78.0       0.88      0.59      0.71        59
        79.0       0.69      0.60      0.64       139
        80.0       0.86      0.88      0.87        41
        81.0       0.44      0.54      0.48       175
        82.0       0.63      0.63      0.63        43
        83.0       0.31      0.19      0.24        26
        84.0       0.62      0.68      0.65       105
        85.0       0.64      0.50      0.56        14
        86.0       0.74      0.72      0.73       242
        87.0       0.77      0.77      0.77       309
        88.0       0.87      0.59      0.70        58
        89.0       0.80      0.36      0.50        11
        90.0       0.56      0.65      0.60       187
        91.0       0.42      0.37      0.40        46
        92.0       0.47      0.42      0.45        40
        93.0       0.74      0.70      0.72        33
        94.0       0.62      0.73      0.67       289
        95.0       0.33      0.12      0.18        32
        96.0       0.84      0.69      0.76        74
        97.0       0.64      0.33      0.44        27
        98.0       0.75      0.57      0.65        37
        99.0       0.83      0.83      0.83        24
       100.0       0.00      0.00      0.00        26
       101.0       0.49      0.49      0.49        65
       102.0       0.70      0.64      0.67        22
       103.0       0.80      0.83      0.82        64
       104.0       0.50      0.25      0.33        40
       105.0       1.00      0.85      0.92        13
       106.0       0.79      0.81      0.80       113
       107.0       0.77      0.81      0.79       162
       108.0       0.78      0.58      0.67        24
       109.0       0.81      0.85      0.83        52
       110.0       1.00      0.87      0.93        15
       111.0       0.80      0.76      0.78       123
       112.0       0.62      0.39      0.48        41
       113.0       0.84      0.95      0.89       430
       114.0       0.89      0.86      0.88        65
       115.0       0.81      0.71      0.76        31
       116.0       0.79      0.76      0.77       173
       117.0       1.00      0.70      0.82        30
       118.0       0.92      0.92      0.92       118
       119.0       0.81      0.85      0.83       136
       120.0       0.93      0.84      0.88        61
       121.0       0.86      0.90      0.88       225
       122.0       0.89      0.94      0.92        35
       123.0       0.88      0.76      0.82        38
       124.0       0.68      0.84      0.75        31
       125.0       0.88      0.88      0.88        16
       126.0       0.67      0.86      0.75        21
       127.0       0.81      0.77      0.79        73

    accuracy                           0.72     12227
   macro avg       0.68      0.60      0.62     12227
weighted avg       0.71      0.72      0.71     12227


===confusion_matrix===

[[314   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0  13 ...   0   0   0]
 ...
 [  0   0   0 ...  14   1   0]
 [  0   0   0 ...   0  18   1]
 [  0   0   0 ...   1   5  56]]

===multilabel confusion matrix===

[[[11720   150]
  [   43   314]]

 [[12211     4]
  [    8     4]]

 [[12204     4]
  [    6    13]]

 [[12123    24]
  [   32    48]]

 [[12125    48]
  [   36    18]]

 [[12138    31]
  [   50     8]]

 [[12167    16]
  [   33    11]]

 [[12169    10]
  [   18    30]]

 [[12215     1]
  [   11     0]]

 [[12199     7]
  [    4    17]]

 [[12207     5]
  [   13     2]]

 [[12183     8]
  [   10    26]]

 [[12215     0]
  [   12     0]]

 [[12196     6]
  [   10    15]]

 [[12202     5]
  [   14     6]]

 [[12201     3]
  [    5    18]]

 [[12193    11]
  [    9    14]]

 [[12092    16]
  [   16   103]]

 [[12207     3]
  [    7    10]]

 [[12212     2]
  [   13     0]]

 [[12112    25]
  [   51    39]]

 [[12213     2]
  [    9     3]]

 [[12200     2]
  [    8    17]]

 [[12212     3]
  [   11     1]]

 [[12198     7]
  [   16     6]]

 [[12184     6]
  [   15    22]]

 [[12208     1]
  [    1    17]]

 [[12187     5]
  [   30     5]]

 [[12215     0]
  [    9     3]]

 [[12178    12]
  [   16    21]]

 [[12188     7]
  [    7    25]]

 [[12187     1]
  [    9    30]]

 [[11294   187]
  [  110   636]]

 [[12147     6]
  [    6    68]]

 [[12163     6]
  [    8    50]]

 [[12166    13]
  [   14    34]]

 [[11565   160]
  [  151   351]]

 [[11905    81]
  [   66   175]]

 [[12189     5]
  [   10    23]]

 [[11764   119]
  [   97   247]]

 [[11998    38]
  [   50   141]]

 [[12194     2]
  [    9    22]]

 [[11732   111]
  [   80   304]]

 [[12087    22]
  [   12   106]]

 [[11670   121]
  [  113   323]]

 [[12177     2]
  [    7    41]]

 [[11723   102]
  [   54   348]]

 [[12209     1]
  [   11     6]]

 [[12178     7]
  [   23    19]]

 [[12142     8]
  [    3    74]]

 [[12037    18]
  [   24   148]]

 [[12204     3]
  [    4    16]]

 [[11526   202]
  [  123   376]]

 [[12118    10]
  [   30    69]]

 [[12215     1]
  [    6     5]]

 [[12106    18]
  [   19    84]]

 [[12207     2]
  [    7    11]]

 [[12215     1]
  [   10     1]]

 [[12191     2]
  [    3    31]]

 [[11902    94]
  [   66   165]]

 [[12163     6]
  [   17    41]]

 [[12190     7]
  [   29     1]]

 [[12165    14]
  [   26    22]]

 [[12149    29]
  [   38    11]]

 [[12192     1]
  [   10    24]]

 [[12049    24]
  [   37   117]]

 [[12211     2]
  [   13     1]]

 [[11821    92]
  [  122   192]]

 [[12147    17]
  [   51    12]]

 [[11715   204]
  [   79   229]]

 [[12137    21]
  [   35    34]]

 [[12121    40]
  [   36    30]]

 [[12213     0]
  [   14     0]]

 [[12200     2]
  [   11    14]]

 [[12207     2]
  [   15     3]]

 [[12136    32]
  [   25    34]]

 [[11976    46]
  [   61   144]]

 [[12117    33]
  [   49    28]]

 [[12163     5]
  [   24    35]]

 [[12050    38]
  [   56    83]]

 [[12180     6]
  [    5    36]]

 [[11929   123]
  [   80    95]]

 [[12168    16]
  [   16    27]]

 [[12190    11]
  [   21     5]]

 [[12078    44]
  [   34    71]]

 [[12209     4]
  [    7     7]]

 [[11924    61]
  [   67   175]]

 [[11847    71]
  [   70   239]]

 [[12164     5]
  [   24    34]]

 [[12215     1]
  [    7     4]]

 [[11944    96]
  [   66   121]]

 [[12158    23]
  [   29    17]]

 [[12168    19]
  [   23    17]]

 [[12186     8]
  [   10    23]]

 [[11811   127]
  [   78   211]]

 [[12187     8]
  [   28     4]]

 [[12143    10]
  [   23    51]]

 [[12195     5]
  [   18     9]]

 [[12183     7]
  [   16    21]]

 [[12199     4]
  [    4    20]]

 [[12196     5]
  [   26     0]]

 [[12129    33]
  [   33    32]]

 [[12199     6]
  [    8    14]]

 [[12150    13]
  [   11    53]]

 [[12177    10]
  [   30    10]]

 [[12214     0]
  [    2    11]]

 [[12090    24]
  [   21    92]]

 [[12026    39]
  [   31   131]]

 [[12199     4]
  [   10    14]]

 [[12165    10]
  [    8    44]]

 [[12212     0]
  [    2    13]]

 [[12081    23]
  [   30    93]]

 [[12176    10]
  [   25    16]]

 [[11720    77]
  [   22   408]]

 [[12155     7]
  [    9    56]]

 [[12191     5]
  [    9    22]]

 [[12018    36]
  [   41   132]]

 [[12197     0]
  [    9    21]]

 [[12100     9]
  [   10   108]]

 [[12063    28]
  [   20   116]]

 [[12162     4]
  [   10    51]]

 [[11970    32]
  [   23   202]]

 [[12188     4]
  [    2    33]]

 [[12185     4]
  [    9    29]]

 [[12184    12]
  [    5    26]]

 [[12209     2]
  [    2    14]]

 [[12197     9]
  [    3    18]]

 [[12141    13]
  [   17    56]]]

===scores report===
metrics	scores
Accuracy	0.7178
MCC	0.7115
log_loss	1.3690
f1 score weighted	0.7098
f1 score macro	0.6227
f1 score micro	0.7178
roc_auc ovr	0.9778
roc_auc ovo	0.9735
precision	0.7130
recall	0.7178

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2384dbd30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff2384dbf40>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2384dbbb0>]