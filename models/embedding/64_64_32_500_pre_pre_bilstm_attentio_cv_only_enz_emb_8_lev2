/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_emb_8_lev2
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6f64403d30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6f64403f10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6f64403bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6f64403dc0>, 'x_test': array([[ 0,  0,  0, ...,  8,  5,  0],
       [ 0,  0,  0, ...,  3,  7, 11],
       [ 0,  0,  0, ..., 15,  9, 11],
       ...,
       [ 0,  0,  0, ..., 10, 13,  6],
       [ 0,  0,  0, ..., 18,  9, 12],
       [ 0,  0,  0, ...,  7,  1, 17]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.90      0.85       911
         1.0       0.94      0.57      0.71        53
         2.0       0.90      0.74      0.81       179
         3.0       0.60      0.24      0.34        25
         4.0       0.70      0.58      0.63       112
         5.0       0.66      0.76      0.70       491
         6.0       0.98      0.78      0.87        64
         7.0       0.67      0.22      0.33        37
         8.0       0.93      0.86      0.89       206
         9.0       0.88      0.75      0.81        71
        10.0       0.95      0.85      0.90       404
        11.0       1.00      0.56      0.72        16
        12.0       0.75      0.71      0.73       378
        13.0       0.90      0.74      0.81       191
        14.0       0.89      0.11      0.19        76
        15.0       0.84      0.71      0.77        66
        16.0       0.90      0.80      0.85       141
        17.0       0.91      0.58      0.71       182
        18.0       0.90      0.75      0.82        12
        19.0       0.97      0.87      0.92        38
        20.0       0.91      0.92      0.91      2162
        21.0       0.97      0.92      0.95       168
        22.0       0.87      0.75      0.81      1470
        23.0       0.82      0.87      0.84      1259
        24.0       0.80      0.90      0.85       956
        25.0       0.76      0.89      0.82       283
        26.0       0.80      0.91      0.85      3919
        27.0       0.94      0.89      0.91       531
        28.0       0.89      0.67      0.76        12
        29.0       0.86      0.73      0.79      2345
        30.0       0.70      0.68      0.69       615
        31.0       0.95      0.66      0.78        32
        32.0       0.81      0.69      0.75      1449
        33.0       0.69      0.85      0.76       893
        34.0       0.95      0.83      0.89      1377
        35.0       0.92      0.50      0.65        22
        36.0       0.65      0.88      0.75       844
        37.0       0.91      0.86      0.88      1142
        38.0       0.93      0.87      0.90       314
        39.0       0.66      0.48      0.56        56
        40.0       0.93      0.73      0.81       154
        41.0       0.96      0.83      0.89        52
        42.0       0.85      0.72      0.78       247
        43.0       0.82      0.71      0.76       198
        44.0       0.90      0.89      0.89       529
        45.0       0.90      0.85      0.88       540
        46.0       1.00      0.10      0.18        20
        47.0       0.94      0.42      0.59        80
        48.0       0.93      0.97      0.95      1466
        49.0       0.92      0.89      0.90       148
        50.0       0.89      0.92      0.91      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.96      0.87      0.91       151
        53.0       0.89      0.96      0.92       903
        54.0       0.75      0.77      0.76       108
        55.0       0.92      0.92      0.92        93
        56.0       0.88      0.91      0.90        33
        57.0       0.88      0.78      0.83        49
        58.0       0.87      0.77      0.82       154

    accuracy                           0.84     29892
   macro avg       0.85      0.73      0.76     29892
weighted avg       0.85      0.84      0.84     29892


===confusion_matrix===

[[818   0   0 ...   0   0   0]
 [  0  30   0 ...   0   0   0]
 [  0   1 132 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   0]
 [  0   0   0 ...   0  38   9]
 [  0   0   0 ...   2   5 119]]

===multilabel confusion matrix===

[[[28777   204]
  [   93   818]]

 [[29837     2]
  [   23    30]]

 [[29698    15]
  [   47   132]]

 [[29863     4]
  [   19     6]]

 [[29752    28]
  [   47    65]]

 [[29206   195]
  [  118   373]]

 [[29827     1]
  [   14    50]]

 [[29851     4]
  [   29     8]]

 [[29672    14]
  [   29   177]]

 [[29814     7]
  [   18    53]]

 [[29471    17]
  [   61   343]]

 [[29876     0]
  [    7     9]]

 [[29427    87]
  [  111   267]]

 [[29685    16]
  [   49   142]]

 [[29815     1]
  [   68     8]]

 [[29817     9]
  [   19    47]]

 [[29739    12]
  [   28   113]]

 [[29700    10]
  [   76   106]]

 [[29879     1]
  [    3     9]]

 [[29853     1]
  [    5    33]]

 [[27535   195]
  [  183  1979]]

 [[29720     4]
  [   13   155]]

 [[28259   163]
  [  361  1109]]

 [[28386   247]
  [  163  1096]]

 [[28724   212]
  [   97   859]]

 [[29529    80]
  [   31   252]]

 [[25053   920]
  [  338  3581]]

 [[29330    31]
  [   59   472]]

 [[29879     1]
  [    4     8]]

 [[27257   290]
  [  622  1723]]

 [[29094   183]
  [  195   420]]

 [[29859     1]
  [   11    21]]

 [[28201   242]
  [  443  1006]]

 [[28650   349]
  [  134   759]]

 [[28461    54]
  [  233  1144]]

 [[29869     1]
  [   11    11]]

 [[28638   410]
  [   99   745]]

 [[28654    96]
  [  163   979]]

 [[29557    21]
  [   42   272]]

 [[29822    14]
  [   29    27]]

 [[29729     9]
  [   42   112]]

 [[29838     2]
  [    9    43]]

 [[29613    32]
  [   69   178]]

 [[29664    30]
  [   58   140]]

 [[29310    53]
  [   58   471]]

 [[29302    50]
  [   80   460]]

 [[29872     0]
  [   18     2]]

 [[29810     2]
  [   46    34]]

 [[28318   108]
  [   42  1424]]

 [[29732    12]
  [   17   131]]

 [[28269   170]
  [  111  1342]]

 [[29880     0]
  [   12     0]]

 [[29735     6]
  [   20   131]]

 [[28877   112]
  [   32   871]]

 [[29756    28]
  [   25    83]]

 [[29792     7]
  [    7    86]]

 [[29855     4]
  [    3    30]]

 [[29838     5]
  [   11    38]]

 [[29720    18]
  [   35   119]]]

===scores report===
metrics	scores
Accuracy	0.8398
MCC	0.8313
log_loss	0.6753
f1 score weighted	0.8378
f1 score macro	0.7632
f1 score micro	0.8398
roc_auc ovr	0.9895
roc_auc ovo	0.9867
precision	0.8460
recall	0.8398

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6f64403d30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6f64403f10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6f64403bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6f64403dc0>, 'x_test': array([[ 0,  0,  0, ..., 13, 11,  1],
       [ 0,  0,  0, ...,  3, 17, 19],
       [ 0,  0,  0, ...,  9,  4,  5],
       ...,
       [19, 19, 19, ...,  0,  6,  0],
       [ 0,  0,  0, ...,  2,  0,  9],
       [10, 10,  1, ...,  0, 15,  0]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.89      0.88       912
         1.0       0.95      0.68      0.79        53
         2.0       0.90      0.76      0.82       179
         3.0       0.56      0.40      0.47        25
         4.0       0.62      0.65      0.64       112
         5.0       0.79      0.77      0.78       492
         6.0       0.86      0.74      0.79        65
         7.0       0.59      0.34      0.43        38
         8.0       0.91      0.85      0.88       206
         9.0       0.90      0.76      0.82        71
        10.0       0.96      0.86      0.91       405
        11.0       0.85      0.65      0.73        17
        12.0       0.83      0.79      0.81       377
        13.0       0.89      0.80      0.85       191
        14.0       0.53      0.26      0.35        76
        15.0       0.67      0.77      0.72        66
        16.0       0.79      0.79      0.79       140
        17.0       0.85      0.82      0.83       182
        18.0       1.00      1.00      1.00        11
        19.0       0.97      0.86      0.91        37
        20.0       0.89      0.94      0.92      2163
        21.0       0.95      0.88      0.91       169
        22.0       0.82      0.84      0.83      1469
        23.0       0.85      0.89      0.87      1259
        24.0       0.93      0.88      0.91       956
        25.0       0.92      0.85      0.89       282
        26.0       0.89      0.91      0.90      3919
        27.0       0.94      0.91      0.93       531
        28.0       1.00      0.75      0.86        12
        29.0       0.78      0.81      0.80      2346
        30.0       0.64      0.75      0.69       615
        31.0       0.96      0.84      0.90        32
        32.0       0.80      0.77      0.79      1450
        33.0       0.76      0.83      0.79       893
        34.0       0.91      0.88      0.89      1376
        35.0       0.92      0.50      0.65        22
        36.0       0.81      0.85      0.83       843
        37.0       0.90      0.86      0.88      1142
        38.0       0.96      0.89      0.92       314
        39.0       0.63      0.55      0.59        56
        40.0       0.93      0.74      0.83       154
        41.0       0.83      0.92      0.87        52
        42.0       0.84      0.89      0.86       247
        43.0       0.93      0.82      0.87       198
        44.0       0.89      0.92      0.90       529
        45.0       0.94      0.91      0.92       539
        46.0       0.62      0.42      0.50        19
        47.0       0.83      0.60      0.70        80
        48.0       0.99      0.95      0.97      1466
        49.0       0.95      0.82      0.88       148
        50.0       0.94      0.93      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.99      0.91      0.94       151
        53.0       0.93      0.97      0.95       903
        54.0       0.94      0.84      0.89       108
        55.0       0.93      0.92      0.93        93
        56.0       1.00      0.79      0.88        33
        57.0       0.93      0.88      0.91        49
        58.0       0.84      0.92      0.88       154

    accuracy                           0.87     29892
   macro avg       0.84      0.78      0.81     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[808   0   0 ...   0   0   0]
 [  0  36   0 ...   0   0   0]
 [  0   0 136 ...   0   0   0]
 ...
 [  0   0   0 ...  26   1   3]
 [  0   0   0 ...   0  43   5]
 [  0   0   0 ...   0   2 141]]

===multilabel confusion matrix===

[[[28867   113]
  [  104   808]]

 [[29837     2]
  [   17    36]]

 [[29698    15]
  [   43   136]]

 [[29859     8]
  [   15    10]]

 [[29736    44]
  [   39    73]]

 [[29298   102]
  [  115   377]]

 [[29819     8]
  [   17    48]]

 [[29845     9]
  [   25    13]]

 [[29669    17]
  [   31   175]]

 [[29815     6]
  [   17    54]]

 [[29472    15]
  [   55   350]]

 [[29873     2]
  [    6    11]]

 [[29455    60]
  [   81   296]]

 [[29683    18]
  [   38   153]]

 [[29798    18]
  [   56    20]]

 [[29801    25]
  [   15    51]]

 [[29722    30]
  [   29   111]]

 [[29683    27]
  [   33   149]]

 [[29881     0]
  [    0    11]]

 [[29854     1]
  [    5    32]]

 [[27486   243]
  [  123  2040]]

 [[29715     8]
  [   20   149]]

 [[28159   264]
  [  240  1229]]

 [[28433   200]
  [  134  1125]]

 [[28874    62]
  [  111   845]]

 [[29590    20]
  [   41   241]]

 [[25534   439]
  [  347  3572]]

 [[29330    31]
  [   46   485]]

 [[29880     0]
  [    3     9]]

 [[27014   532]
  [  440  1906]]

 [[29020   257]
  [  153   462]]

 [[29859     1]
  [    5    27]]

 [[28155   287]
  [  327  1123]]

 [[28760   239]
  [  148   745]]

 [[28397   119]
  [  172  1204]]

 [[29869     1]
  [   11    11]]

 [[28878   171]
  [  124   719]]

 [[28636   114]
  [  161   981]]

 [[29567    11]
  [   35   279]]

 [[29818    18]
  [   25    31]]

 [[29730     8]
  [   40   114]]

 [[29830    10]
  [    4    48]]

 [[29602    43]
  [   28   219]]

 [[29682    12]
  [   36   162]]

 [[29303    60]
  [   43   486]]

 [[29319    34]
  [   48   491]]

 [[29868     5]
  [   11     8]]

 [[29802    10]
  [   32    48]]

 [[28405    21]
  [   68  1398]]

 [[29737     7]
  [   26   122]]

 [[28349    90]
  [  100  1353]]

 [[29880     0]
  [   12     0]]

 [[29739     2]
  [   14   137]]

 [[28919    70]
  [   31   872]]

 [[29778     6]
  [   17    91]]

 [[29793     6]
  [    7    86]]

 [[29859     0]
  [    7    26]]

 [[29840     3]
  [    6    43]]

 [[29712    26]
  [   13   141]]]

===scores report===
metrics	scores
Accuracy	0.8679
MCC	0.8607
log_loss	0.6438
f1 score weighted	0.8675
f1 score macro	0.8061
f1 score micro	0.8679
roc_auc ovr	0.9917
roc_auc ovo	0.9894
precision	0.8692
recall	0.8679

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6f64403d30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6f64403f10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6f64403bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6f64403dc0>, 'x_test': array([[ 0,  0,  0, ...,  3,  0,  8],
       [ 0,  0,  0, ...,  7, 17,  6],
       [ 0,  0,  0, ..., 18,  4,  9],
       ...,
       [ 0,  0,  0, ...,  9, 17,  9],
       [ 8,  4,  0, ...,  7, 10, 14],
       [19,  5, 14, ...,  3,  1,  2]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.89      0.81       912
         1.0       0.91      0.83      0.87        52
         2.0       0.91      0.66      0.77       179
         3.0       0.00      0.00      0.00        25
         4.0       1.00      0.22      0.36       112
         5.0       0.90      0.71      0.79       492
         6.0       0.98      0.69      0.81        65
         7.0       1.00      0.13      0.23        38
         8.0       0.72      0.79      0.75       205
         9.0       0.75      0.85      0.79        71
        10.0       0.87      0.85      0.86       405
        11.0       1.00      0.29      0.45        17
        12.0       0.76      0.70      0.73       377
        13.0       0.89      0.71      0.79       190
        14.0       0.00      0.00      0.00        76
        15.0       0.80      0.54      0.64        67
        16.0       0.94      0.68      0.79       140
        17.0       0.85      0.70      0.77       183
        18.0       1.00      0.92      0.96        12
        19.0       1.00      0.84      0.91        37
        20.0       0.95      0.88      0.92      2162
        21.0       0.78      0.92      0.84       169
        22.0       0.79      0.78      0.79      1470
        23.0       0.80      0.88      0.84      1259
        24.0       0.89      0.87      0.88       956
        25.0       0.96      0.83      0.89       282
        26.0       0.73      0.95      0.82      3918
        27.0       0.99      0.85      0.91       531
        28.0       1.00      0.46      0.63        13
        29.0       0.82      0.73      0.77      2346
        30.0       0.65      0.58      0.61       615
        31.0       0.89      0.75      0.81        32
        32.0       0.66      0.76      0.71      1450
        33.0       0.80      0.73      0.76       893
        34.0       0.93      0.85      0.89      1376
        35.0       1.00      0.23      0.37        22
        36.0       0.83      0.78      0.81       843
        37.0       0.80      0.87      0.83      1142
        38.0       0.93      0.86      0.90       314
        39.0       0.94      0.31      0.47        55
        40.0       0.88      0.64      0.74       154
        41.0       0.97      0.65      0.78        52
        42.0       0.85      0.78      0.81       247
        43.0       0.93      0.83      0.87       197
        44.0       0.94      0.87      0.91       530
        45.0       0.93      0.86      0.89       540
        46.0       0.00      0.00      0.00        19
        47.0       0.85      0.51      0.63        79
        48.0       0.97      0.97      0.97      1465
        49.0       0.89      0.87      0.88       149
        50.0       0.93      0.91      0.92      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.97      0.88      0.92       152
        53.0       0.95      0.94      0.95       903
        54.0       0.97      0.80      0.87       108
        55.0       0.90      0.84      0.87        93
        56.0       0.65      0.94      0.77        32
        57.0       0.78      0.98      0.87        50
        58.0       0.92      0.82      0.87       154

    accuracy                           0.83     29892
   macro avg       0.82      0.69      0.73     29892
weighted avg       0.84      0.83      0.83     29892


===confusion_matrix===

[[815   0   0 ...   0   0   0]
 [  1  43   0 ...   0   0   0]
 [  0   0 118 ...   0   0   0]
 ...
 [  0   0   0 ...  30   1   0]
 [  0   0   0 ...   0  49   1]
 [  0   0   0 ...   5  11 126]]

===multilabel confusion matrix===

[[[28705   275]
  [   97   815]]

 [[29836     4]
  [    9    43]]

 [[29702    11]
  [   61   118]]

 [[29867     0]
  [   25     0]]

 [[29780     0]
  [   87    25]]

 [[29360    40]
  [  145   347]]

 [[29826     1]
  [   20    45]]

 [[29854     0]
  [   33     5]]

 [[29623    64]
  [   44   161]]

 [[29801    20]
  [   11    60]]

 [[29436    51]
  [   61   344]]

 [[29875     0]
  [   12     5]]

 [[29430    85]
  [  113   264]]

 [[29685    17]
  [   56   134]]

 [[29813     3]
  [   76     0]]

 [[29816     9]
  [   31    36]]

 [[29746     6]
  [   45    95]]

 [[29686    23]
  [   54   129]]

 [[29880     0]
  [    1    11]]

 [[29855     0]
  [    6    31]]

 [[27640    90]
  [  256  1906]]

 [[29679    44]
  [   14   155]]

 [[28123   299]
  [  319  1151]]

 [[28362   271]
  [  150  1109]]

 [[28831   105]
  [  123   833]]

 [[29601     9]
  [   47   235]]

 [[24574  1400]
  [  215  3703]]

 [[29355     6]
  [   80   451]]

 [[29879     0]
  [    7     6]]

 [[27158   388]
  [  623  1723]]

 [[29082   195]
  [  260   355]]

 [[29857     3]
  [    8    24]]

 [[27883   559]
  [  352  1098]]

 [[28838   161]
  [  241   652]]

 [[28434    82]
  [  202  1174]]

 [[29870     0]
  [   17     5]]

 [[28915   134]
  [  184   659]]

 [[28495   255]
  [  143   999]]

 [[29558    20]
  [   43   271]]

 [[29836     1]
  [   38    17]]

 [[29725    13]
  [   55    99]]

 [[29839     1]
  [   18    34]]

 [[29611    34]
  [   55   192]]

 [[29682    13]
  [   34   163]]

 [[29335    27]
  [   69   461]]

 [[29318    34]
  [   77   463]]

 [[29873     0]
  [   19     0]]

 [[29806     7]
  [   39    40]]

 [[28383    44]
  [   50  1415]]

 [[29727    16]
  [   20   129]]

 [[28345    94]
  [  125  1328]]

 [[29880     0]
  [   12     0]]

 [[29736     4]
  [   18   134]]

 [[28942    47]
  [   50   853]]

 [[29781     3]
  [   22    86]]

 [[29790     9]
  [   15    78]]

 [[29844    16]
  [    2    30]]

 [[29828    14]
  [    1    49]]

 [[29727    11]
  [   28   126]]]

===scores report===
metrics	scores
Accuracy	0.8321
MCC	0.8232
log_loss	0.7248
f1 score weighted	0.8292
f1 score macro	0.7300
f1 score micro	0.8321
roc_auc ovr	0.9883
roc_auc ovo	0.9834
precision	0.8387
recall	0.8321

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6f64403d30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6f64403f10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6f64403bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6f64403dc0>, 'x_test': array([[ 0,  0,  0, ..., 14,  0, 14],
       [ 0,  0,  0, ...,  5, 12, 19],
       [ 0,  0,  0, ..., 11, 16,  1],
       ...,
       [16, 11, 14, ...,  2,  8, 10],
       [19,  1,  0, ...,  6,  5,  5],
       [ 7, 14, 14, ...,  8, 16, 10]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.90      0.88       912
         1.0       0.94      0.85      0.89        52
         2.0       0.83      0.73      0.78       179
         3.0       0.47      0.29      0.36        24
         4.0       0.71      0.54      0.61       112
         5.0       0.75      0.71      0.73       492
         6.0       0.79      0.77      0.78        64
         7.0       0.60      0.39      0.48        38
         8.0       0.90      0.84      0.87       205
         9.0       0.83      0.83      0.83        70
        10.0       0.89      0.89      0.89       405
        11.0       0.82      0.53      0.64        17
        12.0       0.79      0.78      0.78       378
        13.0       0.88      0.79      0.83       191
        14.0       0.54      0.28      0.37        76
        15.0       0.75      0.67      0.71        67
        16.0       0.86      0.85      0.86       140
        17.0       0.78      0.78      0.78       183
        18.0       0.83      0.83      0.83        12
        19.0       1.00      0.84      0.91        37
        20.0       0.91      0.93      0.92      2162
        21.0       0.96      0.91      0.94       168
        22.0       0.77      0.84      0.80      1470
        23.0       0.88      0.88      0.88      1259
        24.0       0.89      0.89      0.89       955
        25.0       0.92      0.91      0.92       282
        26.0       0.87      0.92      0.89      3918
        27.0       0.94      0.91      0.93       532
        28.0       0.86      0.92      0.89        13
        29.0       0.81      0.80      0.81      2346
        30.0       0.77      0.66      0.71       616
        31.0       0.86      0.75      0.80        32
        32.0       0.74      0.83      0.78      1449
        33.0       0.82      0.82      0.82       893
        34.0       0.90      0.90      0.90      1377
        35.0       0.83      0.45      0.59        22
        36.0       0.90      0.85      0.87       844
        37.0       0.87      0.89      0.88      1142
        38.0       0.93      0.90      0.91       314
        39.0       0.77      0.59      0.67        56
        40.0       0.90      0.75      0.81       153
        41.0       0.96      0.90      0.93        51
        42.0       0.91      0.79      0.85       246
        43.0       0.86      0.88      0.87       197
        44.0       0.93      0.91      0.92       530
        45.0       0.95      0.89      0.92       540
        46.0       1.00      0.45      0.62        20
        47.0       0.72      0.62      0.67        80
        48.0       0.96      0.96      0.96      1465
        49.0       0.92      0.87      0.90       148
        50.0       0.94      0.94      0.94      1453
        51.0       1.00      0.31      0.47        13
        52.0       0.90      0.85      0.87       151
        53.0       0.95      0.95      0.95       904
        54.0       0.87      0.81      0.84       108
        55.0       0.95      0.90      0.93        93
        56.0       0.97      0.97      0.97        33
        57.0       0.89      0.94      0.91        50
        58.0       0.89      0.92      0.90       153

    accuracy                           0.87     29892
   macro avg       0.86      0.78      0.81     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[819   0   0 ...   0   0   0]
 [  0  44   0 ...   0   0   0]
 [  0   0 130 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   1]
 [  0   0   0 ...   0  47   2]
 [  0   0   0 ...   0   5 141]]

===multilabel confusion matrix===

[[[28859   121]
  [   93   819]]

 [[29837     3]
  [    8    44]]

 [[29687    26]
  [   49   130]]

 [[29860     8]
  [   17     7]]

 [[29756    24]
  [   52    60]]

 [[29286   114]
  [  142   350]]

 [[29815    13]
  [   15    49]]

 [[29844    10]
  [   23    15]]

 [[29667    20]
  [   33   172]]

 [[29810    12]
  [   12    58]]

 [[29442    45]
  [   43   362]]

 [[29873     2]
  [    8     9]]

 [[29435    79]
  [   84   294]]

 [[29680    21]
  [   41   150]]

 [[29798    18]
  [   55    21]]

 [[29810    15]
  [   22    45]]

 [[29733    19]
  [   21   119]]

 [[29668    41]
  [   40   143]]

 [[29878     2]
  [    2    10]]

 [[29855     0]
  [    6    31]]

 [[27530   200]
  [  150  2012]]

 [[29718     6]
  [   15   153]]

 [[28056   366]
  [  239  1231]]

 [[28486   147]
  [  157  1102]]

 [[28831   106]
  [  106   849]]

 [[29589    21]
  [   25   257]]

 [[25441   533]
  [  325  3593]]

 [[29331    29]
  [   49   483]]

 [[29877     2]
  [    1    12]]

 [[27102   444]
  [  458  1888]]

 [[29154   122]
  [  211   405]]

 [[29856     4]
  [    8    24]]

 [[28023   420]
  [  251  1198]]

 [[28844   155]
  [  163   730]]

 [[28377   138]
  [  144  1233]]

 [[29868     2]
  [   12    10]]

 [[28970    78]
  [  128   716]]

 [[28603   147]
  [  129  1013]]

 [[29556    22]
  [   31   283]]

 [[29826    10]
  [   23    33]]

 [[29726    13]
  [   39   114]]

 [[29839     2]
  [    5    46]]

 [[29627    19]
  [   51   195]]

 [[29668    27]
  [   24   173]]

 [[29328    34]
  [   46   484]]

 [[29326    26]
  [   61   479]]

 [[29872     0]
  [   11     9]]

 [[29793    19]
  [   30    50]]

 [[28371    56]
  [   54  1411]]

 [[29733    11]
  [   19   129]]

 [[28346    93]
  [   89  1364]]

 [[29879     0]
  [    9     4]]

 [[29727    14]
  [   23   128]]

 [[28945    43]
  [   47   857]]

 [[29771    13]
  [   20    88]]

 [[29795     4]
  [    9    84]]

 [[29858     1]
  [    1    32]]

 [[29836     6]
  [    3    47]]

 [[29721    18]
  [   12   141]]]

===scores report===
metrics	scores
Accuracy	0.8681
MCC	0.8609
log_loss	0.6138
f1 score weighted	0.8671
f1 score macro	0.8108
f1 score micro	0.8681
roc_auc ovr	0.9918
roc_auc ovo	0.9899
precision	0.8682
recall	0.8681

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6f64403d30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6f64403f10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6f64403bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6f64403dc0>, 'x_test': array([[ 0,  0,  0, ..., 19,  3, 15],
       [ 0,  0,  0, ..., 11, 17, 14],
       [ 0,  0,  0, ..., 17, 19,  8],
       ...,
       [ 9,  5,  5, ...,  7, 15, 10],
       [ 0,  0,  0, ..., 10, 12,  1],
       [14,  7, 18, ...,  7,  7,  8]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.88      0.88       911
         1.0       0.93      0.72      0.81        53
         2.0       0.93      0.75      0.83       180
         3.0       0.33      0.04      0.07        25
         4.0       0.70      0.45      0.55       111
         5.0       0.67      0.71      0.69       491
         6.0       0.91      0.80      0.85        64
         7.0       0.47      0.24      0.32        37
         8.0       0.82      0.84      0.83       205
         9.0       0.90      0.75      0.82        71
        10.0       0.95      0.86      0.90       404
        11.0       0.50      0.41      0.45        17
        12.0       0.87      0.80      0.83       378
        13.0       0.88      0.73      0.80       191
        14.0       0.77      0.22      0.35        76
        15.0       0.61      0.80      0.69        66
        16.0       0.71      0.82      0.76       140
        17.0       0.90      0.65      0.76       182
        18.0       1.00      0.92      0.96        12
        19.0       0.86      0.68      0.76        37
        20.0       0.82      0.94      0.87      2162
        21.0       0.94      0.93      0.93       168
        22.0       0.63      0.85      0.72      1470
        23.0       0.86      0.84      0.85      1259
        24.0       0.82      0.90      0.86       955
        25.0       0.85      0.95      0.90       283
        26.0       0.90      0.87      0.88      3919
        27.0       0.98      0.89      0.93       532
        28.0       1.00      0.92      0.96        13
        29.0       0.65      0.83      0.73      2345
        30.0       0.67      0.67      0.67       616
        31.0       0.78      0.78      0.78        32
        32.0       0.88      0.64      0.74      1449
        33.0       0.88      0.74      0.80       893
        34.0       0.91      0.83      0.87      1377
        35.0       0.57      0.59      0.58        22
        36.0       0.76      0.86      0.81       844
        37.0       0.96      0.84      0.89      1142
        38.0       0.88      0.88      0.88       314
        39.0       0.55      0.41      0.47        56
        40.0       0.89      0.68      0.77       153
        41.0       0.96      0.90      0.93        52
        42.0       0.89      0.75      0.81       247
        43.0       0.96      0.78      0.86       197
        44.0       0.93      0.86      0.90       529
        45.0       0.88      0.90      0.89       540
        46.0       1.00      0.05      0.10        20
        47.0       0.90      0.59      0.71        80
        48.0       0.98      0.96      0.97      1466
        49.0       0.94      0.88      0.91       148
        50.0       0.96      0.90      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.99      0.82      0.90       151
        53.0       0.95      0.92      0.93       904
        54.0       0.70      0.71      0.71       108
        55.0       0.91      0.94      0.92        93
        56.0       0.97      0.85      0.90        33
        57.0       0.96      0.46      0.62        50
        58.0       0.72      0.91      0.80       154

    accuracy                           0.84     29892
   macro avg       0.82      0.73      0.76     29892
weighted avg       0.85      0.84      0.84     29892


===confusion_matrix===

[[798   0   0 ...   0   0   0]
 [  0  38   0 ...   0   0   0]
 [  2   0 135 ...   0   0   0]
 ...
 [  0   0   0 ...  28   0   1]
 [  0   0   0 ...   0  23  26]
 [  0   0   0 ...   0   0 140]]

===multilabel confusion matrix===

[[[28872   109]
  [  113   798]]

 [[29836     3]
  [   15    38]]

 [[29702    10]
  [   45   135]]

 [[29865     2]
  [   24     1]]

 [[29760    21]
  [   61    50]]

 [[29229   172]
  [  142   349]]

 [[29823     5]
  [   13    51]]

 [[29845    10]
  [   28     9]]

 [[29648    39]
  [   33   172]]

 [[29815     6]
  [   18    53]]

 [[29470    18]
  [   57   347]]

 [[29868     7]
  [   10     7]]

 [[29468    46]
  [   76   302]]

 [[29682    19]
  [   51   140]]

 [[29811     5]
  [   59    17]]

 [[29792    34]
  [   13    53]]

 [[29705    47]
  [   25   115]]

 [[29697    13]
  [   63   119]]

 [[29880     0]
  [    1    11]]

 [[29851     4]
  [   12    25]]

 [[27280   450]
  [  138  2024]]

 [[29714    10]
  [   12   156]]

 [[27685   737]
  [  224  1246]]

 [[28460   173]
  [  198  1061]]

 [[28748   189]
  [   97   858]]

 [[29560    49]
  [   13   270]]

 [[25579   394]
  [  521  3398]]

 [[29352     8]
  [   58   474]]

 [[29879     0]
  [    1    12]]

 [[26517  1030]
  [  403  1942]]

 [[29078   198]
  [  206   410]]

 [[29853     7]
  [    7    25]]

 [[28313   130]
  [  526   923]]

 [[28908    91]
  [  232   661]]

 [[28404   111]
  [  240  1137]]

 [[29860    10]
  [    9    13]]

 [[28824   224]
  [  118   726]]

 [[28708    42]
  [  188   954]]

 [[29542    36]
  [   39   275]]

 [[29817    19]
  [   33    23]]

 [[29726    13]
  [   49   104]]

 [[29838     2]
  [    5    47]]

 [[29623    22]
  [   62   185]]

 [[29688     7]
  [   43   154]]

 [[29329    34]
  [   72   457]]

 [[29283    69]
  [   54   486]]

 [[29872     0]
  [   19     1]]

 [[29807     5]
  [   33    47]]

 [[28392    34]
  [   52  1414]]

 [[29736     8]
  [   18   130]]

 [[28381    58]
  [  148  1305]]

 [[29880     0]
  [   12     0]]

 [[29740     1]
  [   27   124]]

 [[28943    45]
  [   76   828]]

 [[29751    33]
  [   31    77]]

 [[29790     9]
  [    6    87]]

 [[29858     1]
  [    5    28]]

 [[29841     1]
  [   27    23]]

 [[29683    55]
  [   14   140]]]

===scores report===
metrics	scores
Accuracy	0.8369
MCC	0.8285
log_loss	0.6932
f1 score weighted	0.8371
f1 score macro	0.7557
f1 score micro	0.8369
roc_auc ovr	0.9892
roc_auc ovo	0.9858
precision	0.8481
recall	0.8369

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8397564565770106	0.8312732907214064	0.6753461194699962	0.8377518879891941	0.7632488409980198	0.8397564565770106	0.9894775997741277	0.9866808237274456	0.8460320239956197	0.8397564565770106
1	0.8678576207680985	0.8607083665674056	0.6438264345224461	0.8675058966224739	0.8060842043133394	0.8678576207680984	0.9916748017808145	0.989416788088382	0.8692185342854829	0.8678576207680985
2	0.8321289977251438	0.8231874470366776	0.724824678713134	0.8292300589384001	0.7300457320051672	0.8321289977251439	0.9882587990743673	0.9834121350395586	0.8386635720456236	0.8321289977251438
3	0.8680583433694634	0.8608756914374557	0.6138124055200056	0.8671109806408092	0.8107657828842126	0.8680583433694634	0.9917857244141925	0.9898546349210576	0.8682239353592847	0.8680583433694634
4	0.8369128863910076	0.8284636738059625	0.6932237783574032	0.8370838841765785	0.7557364764691143	0.8369128863910076	0.9891865412720243	0.9858036988775953	0.8481318125051363	0.8369128863910076
mean	0.8489428609661449	0.8409016939137816	0.670206683316597	0.8477365416734912	0.7731762073339707	0.8489428609661449	0.9900766932631054	0.9870336161308078	0.8540539756382295	0.8489428609661449
std	0.01571614530884353	0.01644670114852213	0.038511187942905464	0.016259511705849588	0.030850760678909704	0.01571614530884348	0.0014093091333677835	0.0023828529043231246	0.012385797063870772	0.01571614530884353

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 72373.3774 secs

