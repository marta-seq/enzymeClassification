/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_emb_5
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd9835c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd9835c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd9835c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd9835c520>, 'x_test': array([[ 0,  0,  0, ...,  7, 17,  6],
       [ 0,  0,  0, ..., 18,  4,  9],
       [ 0,  0,  0, ...,  3, 17,  0],
       ...,
       [ 0,  0,  0, ..., 10, 12,  1],
       [10, 10,  1, ...,  0, 15,  0],
       [14,  7, 18, ...,  7,  7,  8]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.98      0.70      0.82      3813
         1.0       0.87      0.92      0.90     10869
         2.0       0.84      0.85      0.84      6897
         3.0       0.94      0.81      0.87      2585
         4.0       0.74      0.88      0.81      1616
         5.0       0.86      0.96      0.91      3258
         6.0       0.93      0.97      0.95      1372

    accuracy                           0.87     30410
   macro avg       0.88      0.87      0.87     30410
weighted avg       0.88      0.87      0.87     30410


===confusion_matrix===

[[ 2678   453   352    49   111   152    18]
 [   15 10033   477    32   120   143    49]
 [   21   665  5835    44   163   145    24]
 [    3   232   144  2091    79    32     4]
 [    3    81    63     8  1427    31     3]
 [    1    64    42     3    14  3133     1]
 [    1     9    20     0     6     4  1332]]

===multilabel confusion matrix===

[[[26553    44]
  [ 1135  2678]]

 [[18037  1504]
  [  836 10033]]

 [[22415  1098]
  [ 1062  5835]]

 [[27689   136]
  [  494  2091]]

 [[28301   493]
  [  189  1427]]

 [[26645   507]
  [  125  3133]]

 [[28939    99]
  [   40  1332]]]

===scores report===
metrics	scores
Accuracy	0.8724
MCC	0.8369
log_loss	0.4706
f1 score weighted	0.8712
f1 score macro	0.8706
f1 score micro	0.8724
roc_auc ovr	0.9824
roc_auc ovo	0.9855
precision	0.8786
recall	0.8724

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd9835c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd9835c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd9835c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd9835c520>, 'x_test': array([[ 0,  0,  0, ...,  3,  7, 11],
       [ 0,  0,  0, ..., 19,  3, 15],
       [ 0,  0,  0, ..., 15,  9, 11],
       ...,
       [15, 19,  7, ...,  7,  7, 13],
       [ 0,  0,  0, ...,  2,  0,  9],
       [ 8,  4,  0, ...,  7, 10, 14]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.88      0.88      3813
         1.0       0.90      0.94      0.92     10869
         2.0       0.88      0.86      0.87      6897
         3.0       0.92      0.87      0.89      2585
         4.0       0.93      0.87      0.90      1616
         5.0       0.97      0.96      0.96      3258
         6.0       0.97      0.97      0.97      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.90      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3351   242   152    39    11     8    10]
 [  152 10176   406    59    26    31    19]
 [  188   621  5920    75    35    44    14]
 [   65   151    88  2252    24     5     0]
 [   34    82    68    24  1401     4     3]
 [   34    59    38     8     2  3117     0]
 [    7    13    24     1     3     0  1324]]

===multilabel confusion matrix===

[[[26117   480]
  [  462  3351]]

 [[18373  1168]
  [  693 10176]]

 [[22737   776]
  [  977  5920]]

 [[27619   206]
  [  333  2252]]

 [[28693   101]
  [  215  1401]]

 [[27060    92]
  [  141  3117]]

 [[28992    46]
  [   48  1324]]]

===scores report===
metrics	scores
Accuracy	0.9057
MCC	0.8789
log_loss	0.3656
f1 score weighted	0.9055
f1 score macro	0.9122
f1 score micro	0.9057
roc_auc ovr	0.9878
roc_auc ovo	0.9900
precision	0.9059
recall	0.9057

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd9835c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd9835c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd9835c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd9835c520>, 'x_test': array([[ 0,  0,  0, ..., 13, 11,  1],
       [ 0,  0,  0, ..., 14,  0, 15],
       [ 0,  0,  0, ...,  3, 17, 19],
       ...,
       [11, 11, 10, ..., 15,  8, 19],
       [ 0,  0,  0, ...,  7,  1, 17],
       [16, 11, 14, ...,  2,  8, 10]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.83      0.87      3814
         1.0       0.83      0.96      0.89     10869
         2.0       0.89      0.81      0.85      6896
         3.0       0.98      0.75      0.85      2584
         4.0       0.92      0.84      0.88      1617
         5.0       0.97      0.93      0.95      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.88     30410
   macro avg       0.92      0.87      0.89     30410
weighted avg       0.89      0.88      0.88     30410


===confusion_matrix===

[[ 3177   421   166    15    11    12    12]
 [   95 10437   262    10    28    23    14]
 [  133  1047  5590    14    46    43    23]
 [   62   385   171  1930    29     7     0]
 [   32   140    67     6  1366     4     2]
 [   18   159    35     3     7  3036     0]
 [    8    36    10     1     0     1  1316]]

===multilabel confusion matrix===

[[[26248   348]
  [  637  3177]]

 [[17353  2188]
  [  432 10437]]

 [[22803   711]
  [ 1306  5590]]

 [[27777    49]
  [  654  1930]]

 [[28672   121]
  [  251  1366]]

 [[27062    90]
  [  222  3036]]

 [[28987    51]
  [   56  1316]]]

===scores report===
metrics	scores
Accuracy	0.8830
MCC	0.8503
log_loss	0.4110
f1 score weighted	0.8822
f1 score macro	0.8914
f1 score micro	0.8830
roc_auc ovr	0.9845
roc_auc ovo	0.9867
precision	0.8889
recall	0.8830

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd9835c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd9835c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd9835c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd9835c520>, 'x_test': array([[ 0,  0,  0, ..., 14,  0, 14],
       [ 0,  0,  0, ...,  7,  7,  0],
       [ 0,  0,  0, ..., 11, 17, 14],
       ...,
       [ 5, 16,  0, ...,  3,  5, 10],
       [ 9,  5,  5, ...,  7, 15, 10],
       [13,  4, 16, ...,  2,  5,  2]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.84      0.87      3813
         1.0       0.91      0.90      0.91     10868
         2.0       0.79      0.92      0.85      6897
         3.0       0.92      0.84      0.88      2585
         4.0       0.95      0.81      0.88      1616
         5.0       0.98      0.90      0.94      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.89     30409
   macro avg       0.92      0.88      0.90     30409
weighted avg       0.90      0.89      0.89     30409


===confusion_matrix===

[[3192  198  350   41    7    9   16]
 [ 137 9794  813   55   17   22   30]
 [  96  387 6317   50   21   15   11]
 [  51  142  196 2177   15    2    2]
 [  29   94  139   34 1315    4    1]
 [  27  111  159   10    2 2947    2]
 [  11   13   28    3    1    0 1316]]

===multilabel confusion matrix===

[[[26245   351]
  [  621  3192]]

 [[18596   945]
  [ 1074  9794]]

 [[21827  1685]
  [  580  6317]]

 [[27631   193]
  [  408  2177]]

 [[28730    63]
  [  301  1315]]

 [[27099    52]
  [  311  2947]]

 [[28975    62]
  [   56  1316]]]

===scores report===
metrics	scores
Accuracy	0.8898
MCC	0.8592
log_loss	0.3677
f1 score weighted	0.8906
f1 score macro	0.8969
f1 score micro	0.8898
roc_auc ovr	0.9846
roc_auc ovo	0.9867
precision	0.8951
recall	0.8898

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd9835c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd9835c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd9835c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd9835c520>, 'x_test': array([[ 0,  0,  0, ...,  8,  5,  0],
       [ 0,  0,  0, ...,  3,  0,  8],
       [ 0,  0,  0, ..., 11, 16,  1],
       ...,
       [ 0,  0,  0, ...,  9, 17,  9],
       [19,  5, 14, ...,  3,  1,  2],
       [ 7, 14, 14, ...,  8, 16, 10]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.87      0.87      3813
         1.0       0.91      0.90      0.91     10868
         2.0       0.83      0.88      0.85      6897
         3.0       0.92      0.86      0.89      2585
         4.0       0.94      0.84      0.89      1616
         5.0       0.95      0.94      0.95      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.89     30409
   macro avg       0.91      0.89      0.90     30409
weighted avg       0.90      0.89      0.89     30409


===confusion_matrix===

[[3335  179  227   31   15   17    9]
 [ 195 9795  694   72   25   69   18]
 [ 186  470 6094   64   28   40   15]
 [  76  106  146 2219   18   18    2]
 [  37   87  112   13 1354    8    5]
 [  41   59   76    7    2 3073    0]
 [  12   12   26    3    0    1 1318]]

===multilabel confusion matrix===

[[[26049   547]
  [  478  3335]]

 [[18628   913]
  [ 1073  9795]]

 [[22231  1281]
  [  803  6094]]

 [[27634   190]
  [  366  2219]]

 [[28705    88]
  [  262  1354]]

 [[26998   153]
  [  185  3073]]

 [[28988    49]
  [   54  1318]]]

===scores report===
metrics	scores
Accuracy	0.8941
MCC	0.8645
log_loss	0.3413
f1 score weighted	0.8945
f1 score macro	0.9019
f1 score micro	0.8941
roc_auc ovr	0.9856
roc_auc ovo	0.9883
precision	0.8958
recall	0.8941

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.872377507398882	0.8369299031661083	0.47063538079317235	0.8711976873127028	0.8705659763484555	0.872377507398882	0.9824497093553909	0.9855424102789921	0.8785805035001633	0.872377507398882
1	0.9056560341992765	0.8789425445356761	0.3656129381643291	0.9054773189297202	0.9122120608824311	0.9056560341992765	0.9878147254654862	0.9900328255687237	0.9059219646897885	0.9056560341992765
2	0.8829990134824071	0.8503386685076973	0.41100124834437096	0.8821878165315514	0.8913688181940456	0.8829990134824071	0.9845023421342124	0.9866877185531199	0.8888889018851139	0.8829990134824071
3	0.8898023611430826	0.8592288052118381	0.3676579876539467	0.8906322759432386	0.8969435968765033	0.8898023611430826	0.9845740793297909	0.9867427949981026	0.8951288112401113	0.8898023611430826
4	0.8940774112927093	0.8644799299137158	0.3412949387954978	0.8944538686278175	0.9018869929016116	0.8940774112927092	0.9855695235622193	0.9883214866771196	0.8958173514782748	0.8940774112927093
mean	0.8889824655032715	0.8579839702670071	0.3912404987502634	0.8887897934690061	0.8945954890406094	0.8889824655032715	0.98498207596942	0.9874654472152116	0.8928675065586903	0.8889824655032715
std	0.011101035323359789	0.014033768714261399	0.045610306224618063	0.011550050160686125	0.013833669993147257	0.011101035323359779	0.001742325131557868	0.001558806872400962	0.008990903320038261	0.011101035323359789

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 70720.1266 secs

