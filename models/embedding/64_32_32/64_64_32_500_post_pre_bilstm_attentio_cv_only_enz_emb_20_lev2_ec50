/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_emb_20_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab282347f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab28234640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab28234820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab28234550>, 'x_test': array([[13, 13,  2, ...,  0,  0,  0],
       [13,  4, 12, ...,  0,  0,  0],
       [13, 16,  8, ...,  0,  0,  0],
       ...,
       [13,  1, 20, ...,  0,  0,  0],
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.74      0.70       402
         1.0       0.62      0.26      0.37        19
         2.0       0.48      0.26      0.33        82
         3.0       0.00      0.00      0.00        16
         4.0       0.35      0.10      0.15        62
         5.0       0.63      0.45      0.52       277
         6.0       0.75      0.58      0.66        36
         7.0       0.00      0.00      0.00        26
         8.0       0.62      0.39      0.48        72
         9.0       0.67      0.60      0.63        30
        10.0       0.76      0.61      0.68       156
        11.0       0.44      0.39      0.41       168
        12.0       0.58      0.35      0.44        83
        13.0       0.22      0.08      0.11        53
        14.0       0.44      0.26      0.33        31
        15.0       0.54      0.27      0.36        52
        16.0       0.51      0.43      0.46        94
        17.0       0.80      0.80      0.80       885
        18.0       0.83      0.50      0.62        48
        19.0       0.68      0.66      0.67       781
        20.0       0.66      0.69      0.67       591
        21.0       0.72      0.70      0.71       385
        22.0       0.81      0.66      0.72       128
        23.0       0.69      0.82      0.75      1888
        24.0       0.71      0.60      0.65       169
        25.0       0.56      0.69      0.62      1296
        26.0       0.51      0.51      0.51       381
        27.0       0.75      0.21      0.33        14
        28.0       0.54      0.56      0.55       769
        29.0       0.42      0.47      0.44       372
        30.0       0.81      0.70      0.75       631
        31.0       0.00      0.00      0.00        11
        32.0       0.38      0.53      0.44       316
        33.0       0.57      0.60      0.58       405
        34.0       0.68      0.50      0.57        96
        35.0       0.00      0.00      0.00        26
        36.0       0.87      0.42      0.56        65
        37.0       0.79      0.52      0.63        21
        38.0       0.78      0.50      0.61       121
        39.0       0.77      0.57      0.66       114
        40.0       0.73      0.65      0.69       207
        41.0       0.62      0.49      0.55       194
        42.0       0.84      0.57      0.68        47
        43.0       0.91      0.86      0.88       431
        44.0       0.80      0.60      0.68        67
        45.0       0.78      0.75      0.77       488
        46.0       0.82      0.52      0.63        62
        47.0       0.76      0.86      0.81       264
        48.0       0.69      0.49      0.57        49
        49.0       0.62      0.60      0.61        30
        50.0       1.00      0.60      0.75        15
        51.0       0.88      0.67      0.76        21
        52.0       0.61      0.82      0.70        73

    accuracy                           0.66     13120
   macro avg       0.62      0.50      0.54     13120
weighted avg       0.66      0.66      0.65     13120


===confusion_matrix===

[[296   0   1 ...   0   0   0]
 [  0   5   1 ...   0   0   0]
 [  2   0  21 ...   0   0   0]
 ...
 [  0   0   0 ...   9   0   3]
 [  0   0   0 ...   0  14   5]
 [  0   0   0 ...   0   0  60]]

===multilabel confusion matrix===

[[[12566   152]
  [  106   296]]

 [[13098     3]
  [   14     5]]

 [[13015    23]
  [   61    21]]

 [[13102     2]
  [   16     0]]

 [[13047    11]
  [   56     6]]

 [[12769    74]
  [  153   124]]

 [[13077     7]
  [   15    21]]

 [[13092     2]
  [   26     0]]

 [[13031    17]
  [   44    28]]

 [[13081     9]
  [   12    18]]

 [[12934    30]
  [   61    95]]

 [[12867    85]
  [  102    66]]

 [[13016    21]
  [   54    29]]

 [[13053    14]
  [   49     4]]

 [[13079    10]
  [   23     8]]

 [[13056    12]
  [   38    14]]

 [[12987    39]
  [   54    40]]

 [[12062   173]
  [  181   704]]

 [[13067     5]
  [   24    24]]

 [[12095   244]
  [  269   512]]

 [[12321   208]
  [  186   405]]

 [[12632   103]
  [  116   269]]

 [[12972    20]
  [   44    84]]

 [[10551   681]
  [  340  1548]]

 [[12910    41]
  [   67   102]]

 [[11129   695]
  [  396   900]]

 [[12554   185]
  [  188   193]]

 [[13105     1]
  [   11     3]]

 [[11977   374]
  [  335   434]]

 [[12506   242]
  [  197   175]]

 [[12382   107]
  [  187   444]]

 [[13109     0]
  [   11     0]]

 [[12535   269]
  [  149   167]]

 [[12531   184]
  [  164   241]]

 [[13001    23]
  [   48    48]]

 [[13093     1]
  [   26     0]]

 [[13051     4]
  [   38    27]]

 [[13096     3]
  [   10    11]]

 [[12982    17]
  [   61    60]]

 [[12987    19]
  [   49    65]]

 [[12864    49]
  [   73   134]]

 [[12867    59]
  [   98    96]]

 [[13068     5]
  [   20    27]]

 [[12651    38]
  [   60   371]]

 [[13043    10]
  [   27    40]]

 [[12532   100]
  [  123   365]]

 [[13051     7]
  [   30    32]]

 [[12785    71]
  [   36   228]]

 [[13060    11]
  [   25    24]]

 [[13079    11]
  [   12    18]]

 [[13105     0]
  [    6     9]]

 [[13097     2]
  [    7    14]]

 [[13009    38]
  [   13    60]]]

===scores report===
metrics	scores
Accuracy	0.6562
MCC	0.6340
log_loss	1.5058
f1 score weighted	0.6511
f1 score macro	0.5393
f1 score micro	0.6562
roc_auc ovr	0.9522
roc_auc ovo	0.9480
precision	0.6581
recall	0.6562

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab282347f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab28234640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab28234820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab28234550>, 'x_test': array([[13, 16,  7, ...,  0,  0,  0],
       [13, 16, 12, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [12, 20, 14, ...,  9, 15, 11],
       [ 3, 16, 15, ..., 11, 19,  1],
       [13,  4, 11, ...,  0,  0,  0]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.71      0.72       402
         1.0       1.00      0.42      0.59        19
         2.0       0.46      0.27      0.34        81
         3.0       0.75      0.19      0.30        16
         4.0       0.37      0.18      0.24        62
         5.0       0.44      0.58      0.50       277
         6.0       1.00      0.64      0.78        36
         7.0       0.33      0.04      0.07        26
         8.0       0.64      0.25      0.36        73
         9.0       0.76      0.45      0.57        29
        10.0       0.71      0.62      0.66       156
        11.0       0.54      0.35      0.43       168
        12.0       0.49      0.25      0.33        83
        13.0       0.00      0.00      0.00        53
        14.0       0.38      0.31      0.34        32
        15.0       0.56      0.37      0.44        52
        16.0       0.66      0.56      0.61        95
        17.0       0.80      0.80      0.80       884
        18.0       0.38      0.40      0.39        48
        19.0       0.53      0.72      0.61       782
        20.0       0.54      0.73      0.62       591
        21.0       0.69      0.68      0.69       385
        22.0       0.74      0.71      0.73       128
        23.0       0.75      0.77      0.76      1888
        24.0       0.80      0.59      0.68       169
        25.0       0.56      0.69      0.62      1295
        26.0       0.65      0.40      0.50       381
        27.0       1.00      0.57      0.73        14
        28.0       0.56      0.60      0.58       769
        29.0       0.46      0.44      0.45       371
        30.0       0.63      0.73      0.67       631
        31.0       0.50      0.09      0.15        11
        32.0       0.41      0.38      0.39       316
        33.0       0.69      0.53      0.60       405
        34.0       0.77      0.42      0.54        96
        35.0       0.00      0.00      0.00        26
        36.0       0.71      0.23      0.35        65
        37.0       0.88      0.64      0.74        22
        38.0       0.82      0.49      0.61       121
        39.0       0.93      0.56      0.70       113
        40.0       0.79      0.62      0.69       208
        41.0       0.63      0.59      0.61       193
        42.0       0.56      0.41      0.47        46
        43.0       0.85      0.90      0.87       431
        44.0       0.73      0.65      0.69        66
        45.0       0.81      0.67      0.73       489
        46.0       0.65      0.56      0.60        62
        47.0       0.72      0.83      0.77       264
        48.0       0.74      0.41      0.53        49
        49.0       0.77      0.65      0.70        31
        50.0       0.91      0.62      0.74        16
        51.0       0.66      0.90      0.76        21
        52.0       0.70      0.74      0.72        73

    accuracy                           0.65     13120
   macro avg       0.64      0.51      0.55     13120
weighted avg       0.65      0.65      0.64     13120


===confusion_matrix===

[[286   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  0   0  22 ...   0   0   0]
 ...
 [  0   0   0 ...  10   1   3]
 [  0   0   0 ...   0  19   1]
 [  0   0   0 ...   0   3  54]]

===multilabel confusion matrix===

[[[12607   111]
  [  116   286]]

 [[13101     0]
  [   11     8]]

 [[13013    26]
  [   59    22]]

 [[13103     1]
  [   13     3]]

 [[13039    19]
  [   51    11]]

 [[12642   201]
  [  117   160]]

 [[13084     0]
  [   13    23]]

 [[13092     2]
  [   25     1]]

 [[13037    10]
  [   55    18]]

 [[13087     4]
  [   16    13]]

 [[12924    40]
  [   60    96]]

 [[12902    50]
  [  109    59]]

 [[13015    22]
  [   62    21]]

 [[13063     4]
  [   53     0]]

 [[13072    16]
  [   22    10]]

 [[13053    15]
  [   33    19]]

 [[12998    27]
  [   42    53]]

 [[12057   179]
  [  179   705]]

 [[13041    31]
  [   29    19]]

 [[11844   494]
  [  222   560]]

 [[12165   364]
  [  160   431]]

 [[12617   118]
  [  122   263]]

 [[12960    32]
  [   37    91]]

 [[10751   481]
  [  427  1461]]

 [[12926    25]
  [   70    99]]

 [[11118   707]
  [  400   895]]

 [[12656    83]
  [  227   154]]

 [[13106     0]
  [    6     8]]

 [[11992   359]
  [  311   458]]

 [[12555   194]
  [  207   164]]

 [[12215   274]
  [  173   458]]

 [[13108     1]
  [   10     1]]

 [[12628   176]
  [  195   121]]

 [[12617    98]
  [  189   216]]

 [[13012    12]
  [   56    40]]

 [[13094     0]
  [   26     0]]

 [[13049     6]
  [   50    15]]

 [[13096     2]
  [    8    14]]

 [[12986    13]
  [   62    59]]

 [[13002     5]
  [   50    63]]

 [[12878    34]
  [   80   128]]

 [[12861    66]
  [   79   114]]

 [[13059    15]
  [   27    19]]

 [[12619    70]
  [   44   387]]

 [[13038    16]
  [   23    43]]

 [[12555    76]
  [  162   327]]

 [[13039    19]
  [   27    35]]

 [[12773    83]
  [   46   218]]

 [[13064     7]
  [   29    20]]

 [[13083     6]
  [   11    20]]

 [[13103     1]
  [    6    10]]

 [[13089    10]
  [    2    19]]

 [[13024    23]
  [   19    54]]]

===scores report===
metrics	scores
Accuracy	0.6473
MCC	0.6251
log_loss	1.6215
f1 score weighted	0.6411
f1 score macro	0.5483
f1 score micro	0.6473
roc_auc ovr	0.9494
roc_auc ovo	0.9460
precision	0.6531
recall	0.6473

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab282347f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab28234640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab28234820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab28234550>, 'x_test': array([[13,  7,  1, ...,  0,  0,  0],
       [13,  1,  1, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       ...,
       [17, 19, 16, ...,  6, 14,  4],
       [20, 20, 20, ...,  1,  7,  1],
       [17, 12, 15, ...,  3,  9, 11]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.74      0.71       401
         1.0       0.89      0.40      0.55        20
         2.0       0.64      0.44      0.52        82
         3.0       1.00      0.06      0.12        16
         4.0       0.38      0.24      0.30        62
         5.0       0.54      0.55      0.55       277
         6.0       0.73      0.53      0.61        36
         7.0       0.50      0.08      0.14        25
         8.0       0.67      0.47      0.55        73
         9.0       0.52      0.41      0.46        29
        10.0       0.83      0.68      0.75       156
        11.0       0.51      0.45      0.48       168
        12.0       0.65      0.51      0.57        83
        13.0       0.33      0.07      0.12        54
        14.0       0.41      0.35      0.38        31
        15.0       0.68      0.25      0.36        53
        16.0       0.60      0.53      0.56        95
        17.0       0.82      0.78      0.80       884
        18.0       0.73      0.51      0.60        47
        19.0       0.70      0.66      0.68       782
        20.0       0.68      0.77      0.72       592
        21.0       0.67      0.64      0.66       385
        22.0       0.79      0.77      0.78       128
        23.0       0.71      0.82      0.76      1887
        24.0       0.83      0.64      0.72       168
        25.0       0.57      0.68      0.62      1295
        26.0       0.53      0.51      0.52       381
        27.0       0.89      0.57      0.70        14
        28.0       0.55      0.58      0.56       768
        29.0       0.51      0.45      0.48       372
        30.0       0.76      0.75      0.76       631
        31.0       0.50      0.10      0.17        10
        32.0       0.40      0.47      0.43       316
        33.0       0.62      0.60      0.61       405
        34.0       0.68      0.49      0.57        96
        35.0       0.00      0.00      0.00        26
        36.0       0.67      0.45      0.54        66
        37.0       0.94      0.73      0.82        22
        38.0       0.69      0.53      0.60       121
        39.0       0.83      0.73      0.78       113
        40.0       0.70      0.68      0.69       208
        41.0       0.75      0.68      0.71       194
        42.0       0.65      0.52      0.58        46
        43.0       0.85      0.89      0.87       431
        44.0       0.81      0.67      0.73        66
        45.0       0.81      0.74      0.77       489
        46.0       0.76      0.60      0.67        62
        47.0       0.84      0.83      0.83       263
        48.0       0.83      0.58      0.68        50
        49.0       0.60      0.58      0.59        31
        50.0       0.71      0.62      0.67        16
        51.0       0.71      0.57      0.63        21
        52.0       0.68      0.84      0.75        73

    accuracy                           0.67     13120
   macro avg       0.67      0.54      0.58     13120
weighted avg       0.67      0.67      0.67     13120


===confusion_matrix===

[[295   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  0   0  36 ...   0   0   0]
 ...
 [  0   0   0 ...  10   2   2]
 [  0   0   0 ...   0  12   8]
 [  0   0   0 ...   1   1  61]]

===multilabel confusion matrix===

[[[12587   132]
  [  106   295]]

 [[13099     1]
  [   12     8]]

 [[13018    20]
  [   46    36]]

 [[13104     0]
  [   15     1]]

 [[13034    24]
  [   47    15]]

 [[12715   128]
  [  125   152]]

 [[13077     7]
  [   17    19]]

 [[13093     2]
  [   23     2]]

 [[13030    17]
  [   39    34]]

 [[13080    11]
  [   17    12]]

 [[12942    22]
  [   50   106]]

 [[12880    72]
  [   92    76]]

 [[13014    23]
  [   41    42]]

 [[13058     8]
  [   50     4]]

 [[13073    16]
  [   20    11]]

 [[13061     6]
  [   40    13]]

 [[12991    34]
  [   45    50]]

 [[12085   151]
  [  195   689]]

 [[13064     9]
  [   23    24]]

 [[12112   226]
  [  266   516]]

 [[12312   216]
  [  139   453]]

 [[12611   124]
  [  137   248]]

 [[12966    26]
  [   29    99]]

 [[10615   618]
  [  339  1548]]

 [[12930    22]
  [   61   107]]

 [[11159   666]
  [  415   880]]

 [[12564   175]
  [  186   195]]

 [[13105     1]
  [    6     8]]

 [[11980   372]
  [  322   446]]

 [[12586   162]
  [  205   167]]

 [[12340   149]
  [  155   476]]

 [[13109     1]
  [    9     1]]

 [[12587   217]
  [  169   147]]

 [[12565   150]
  [  161   244]]

 [[13002    22]
  [   49    47]]

 [[13093     1]
  [   26     0]]

 [[13039    15]
  [   36    30]]

 [[13097     1]
  [    6    16]]

 [[12970    29]
  [   57    64]]

 [[12990    17]
  [   30    83]]

 [[12851    61]
  [   67   141]]

 [[12882    44]
  [   63   131]]

 [[13061    13]
  [   22    24]]

 [[12624    65]
  [   48   383]]

 [[13044    10]
  [   22    44]]

 [[12544    87]
  [  125   364]]

 [[13046    12]
  [   25    37]]

 [[12814    43]
  [   45   218]]

 [[13064     6]
  [   21    29]]

 [[13077    12]
  [   13    18]]

 [[13100     4]
  [    6    10]]

 [[13094     5]
  [    9    12]]

 [[13018    29]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.6735
MCC	0.6527
log_loss	1.4716
f1 score weighted	0.6694
f1 score macro	0.5804
f1 score micro	0.6735
roc_auc ovr	0.9552
roc_auc ovo	0.9527
precision	0.6746
recall	0.6735

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab282347f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab28234640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab28234820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab28234550>, 'x_test': array([[13, 12, 12, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 20,  8, ...,  0,  0,  0],
       ...,
       [12, 12, 11, ..., 16,  9, 20],
       [13,  6, 12, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.69      0.70       401
         1.0       0.50      0.20      0.29        20
         2.0       0.34      0.55      0.42        82
         3.0       0.33      0.13      0.19        15
         4.0       0.32      0.21      0.25        62
         5.0       0.61      0.54      0.57       278
         6.0       0.95      0.56      0.70        36
         7.0       0.50      0.12      0.19        25
         8.0       0.51      0.51      0.51        73
         9.0       0.47      0.48      0.47        29
        10.0       0.71      0.64      0.68       156
        11.0       0.44      0.51      0.47       168
        12.0       0.55      0.39      0.45        83
        13.0       0.00      0.00      0.00        54
        14.0       0.46      0.35      0.40        31
        15.0       0.33      0.28      0.31        53
        16.0       0.56      0.47      0.51        95
        17.0       0.78      0.79      0.78       884
        18.0       0.81      0.55      0.66        47
        19.0       0.58      0.69      0.63       781
        20.0       0.65      0.71      0.68       592
        21.0       0.70      0.68      0.69       385
        22.0       0.71      0.69      0.70       129
        23.0       0.72      0.78      0.75      1887
        24.0       0.68      0.68      0.68       168
        25.0       0.65      0.61      0.63      1295
        26.0       0.54      0.48      0.51       381
        27.0       0.71      0.38      0.50        13
        28.0       0.54      0.58      0.56       769
        29.0       0.43      0.49      0.46       372
        30.0       0.63      0.76      0.69       631
        31.0       0.00      0.00      0.00        11
        32.0       0.46      0.46      0.46       316
        33.0       0.68      0.53      0.60       405
        34.0       0.64      0.41      0.50        95
        35.0       0.00      0.00      0.00        25
        36.0       0.42      0.15      0.22        66
        37.0       0.75      0.55      0.63        22
        38.0       0.75      0.54      0.62       121
        39.0       0.82      0.70      0.76       113
        40.0       0.68      0.65      0.66       208
        41.0       0.73      0.54      0.62       194
        42.0       0.57      0.46      0.51        46
        43.0       0.84      0.84      0.84       431
        44.0       0.82      0.61      0.70        66
        45.0       0.79      0.76      0.78       489
        46.0       0.78      0.61      0.68        62
        47.0       0.73      0.89      0.81       263
        48.0       0.62      0.36      0.46        50
        49.0       0.67      0.71      0.69        31
        50.0       0.67      0.75      0.71        16
        51.0       0.93      0.64      0.76        22
        52.0       0.67      0.79      0.72        73

    accuracy                           0.65     13120
   macro avg       0.59      0.52      0.54     13120
weighted avg       0.65      0.65      0.65     13120


===confusion_matrix===

[[276   0   1 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  1   0  45 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   1]
 [  0   0   0 ...   2  14   4]
 [  0   0   0 ...   2   0  58]]

===multilabel confusion matrix===

[[[12602   117]
  [  125   276]]

 [[13096     4]
  [   16     4]]

 [[12949    89]
  [   37    45]]

 [[13101     4]
  [   13     2]]

 [[13030    28]
  [   49    13]]

 [[12745    97]
  [  127   151]]

 [[13083     1]
  [   16    20]]

 [[13092     3]
  [   22     3]]

 [[13011    36]
  [   36    37]]

 [[13075    16]
  [   15    14]]

 [[12924    40]
  [   56   100]]

 [[12842   110]
  [   83    85]]

 [[13011    26]
  [   51    32]]

 [[13061     5]
  [   54     0]]

 [[13076    13]
  [   20    11]]

 [[13037    30]
  [   38    15]]

 [[12989    36]
  [   50    45]]

 [[12035   201]
  [  183   701]]

 [[13067     6]
  [   21    26]]

 [[11943   396]
  [  239   542]]

 [[12299   229]
  [  172   420]]

 [[12623   112]
  [  124   261]]

 [[12954    37]
  [   40    89]]

 [[10673   560]
  [  411  1476]]

 [[12898    54]
  [   53   115]]

 [[11407   418]
  [  504   791]]

 [[12584   155]
  [  199   182]]

 [[13105     2]
  [    8     5]]

 [[11964   387]
  [  321   448]]

 [[12500   248]
  [  188   184]]

 [[12209   280]
  [  151   480]]

 [[13109     0]
  [   11     0]]

 [[12631   173]
  [  170   146]]

 [[12614   101]
  [  189   216]]

 [[13003    22]
  [   56    39]]

 [[13094     1]
  [   25     0]]

 [[13040    14]
  [   56    10]]

 [[13094     4]
  [   10    12]]

 [[12977    22]
  [   56    65]]

 [[12990    17]
  [   34    79]]

 [[12848    64]
  [   73   135]]

 [[12888    38]
  [   89   105]]

 [[13058    16]
  [   25    21]]

 [[12620    69]
  [   68   363]]

 [[13045     9]
  [   26    40]]

 [[12530   101]
  [  115   374]]

 [[13047    11]
  [   24    38]]

 [[12772    85]
  [   28   235]]

 [[13059    11]
  [   32    18]]

 [[13078    11]
  [    9    22]]

 [[13098     6]
  [    4    12]]

 [[13097     1]
  [    8    14]]

 [[13018    29]
  [   15    58]]]

===scores report===
metrics	scores
Accuracy	0.6536
MCC	0.6322
log_loss	1.5381
f1 score weighted	0.6488
f1 score macro	0.5423
f1 score micro	0.6536
roc_auc ovr	0.9528
roc_auc ovo	0.9510
precision	0.6518
recall	0.6536

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab282347f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab28234640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab28234820>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab28234550>, 'x_test': array([[13, 17, 12, ...,  0,  0,  0],
       [13, 12,  3, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       ...,
       [ 8, 20,  4, ...,  0,  0,  0],
       [20,  6, 15, ...,  4,  2,  3],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.73      0.71       402
         1.0       1.00      0.42      0.59        19
         2.0       0.71      0.44      0.54        82
         3.0       0.00      0.00      0.00        16
         4.0       0.23      0.08      0.12        62
         5.0       0.62      0.52      0.57       278
         6.0       0.85      0.61      0.71        36
         7.0       0.00      0.00      0.00        26
         8.0       0.50      0.48      0.49        73
         9.0       0.58      0.47      0.52        30
        10.0       0.73      0.61      0.66       156
        11.0       0.42      0.38      0.40       169
        12.0       0.64      0.45      0.52        83
        13.0       0.16      0.11      0.13        53
        14.0       0.58      0.35      0.44        31
        15.0       0.43      0.35      0.38        52
        16.0       0.61      0.48      0.54        95
        17.0       0.65      0.84      0.73       885
        18.0       0.72      0.58      0.64        48
        19.0       0.71      0.66      0.69       781
        20.0       0.76      0.68      0.72       592
        21.0       0.60      0.70      0.64       384
        22.0       0.80      0.65      0.72       128
        23.0       0.77      0.75      0.76      1887
        24.0       0.68      0.62      0.65       168
        25.0       0.56      0.67      0.61      1295
        26.0       0.56      0.55      0.55       381
        27.0       1.00      0.36      0.53        14
        28.0       0.65      0.49      0.56       769
        29.0       0.52      0.43      0.47       372
        30.0       0.67      0.74      0.70       630
        31.0       0.00      0.00      0.00        11
        32.0       0.35      0.51      0.42       316
        33.0       0.48      0.65      0.55       405
        34.0       0.65      0.58      0.61        95
        35.0       0.00      0.00      0.00        25
        36.0       0.54      0.32      0.40        65
        37.0       0.83      0.68      0.75        22
        38.0       0.70      0.43      0.53       121
        39.0       0.66      0.73      0.69       113
        40.0       0.72      0.74      0.73       208
        41.0       0.71      0.59      0.64       194
        42.0       0.54      0.45      0.49        47
        43.0       0.83      0.88      0.86       431
        44.0       0.89      0.82      0.85        66
        45.0       0.74      0.75      0.75       488
        46.0       0.65      0.62      0.63        63
        47.0       0.80      0.81      0.81       263
        48.0       0.72      0.43      0.54        49
        49.0       0.56      0.90      0.69        30
        50.0       0.52      0.73      0.61        15
        51.0       0.87      0.59      0.70        22
        52.0       0.78      0.68      0.73        73

    accuracy                           0.65     13119
   macro avg       0.60      0.53      0.55     13119
weighted avg       0.66      0.65      0.65     13119


===confusion_matrix===

[[292   0   0 ...   0   0   0]
 [  0   8   1 ...   0   0   0]
 [  1   0  36 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   0]
 [  0   0   0 ...   4  13   3]
 [  0   0   0 ...   3   1  50]]

===multilabel confusion matrix===

[[[12587   130]
  [  110   292]]

 [[13100     0]
  [   11     8]]

 [[13022    15]
  [   46    36]]

 [[13100     3]
  [   16     0]]

 [[13040    17]
  [   57     5]]

 [[12754    87]
  [  133   145]]

 [[13079     4]
  [   14    22]]

 [[13093     0]
  [   26     0]]

 [[13011    35]
  [   38    35]]

 [[13079    10]
  [   16    14]]

 [[12927    36]
  [   61    95]]

 [[12861    89]
  [  104    65]]

 [[13015    21]
  [   46    37]]

 [[13035    31]
  [   47     6]]

 [[13080     8]
  [   20    11]]

 [[13043    24]
  [   34    18]]

 [[12994    30]
  [   49    46]]

 [[11831   403]
  [  143   742]]

 [[13060    11]
  [   20    28]]

 [[12132   206]
  [  265   516]]

 [[12403   124]
  [  191   401]]

 [[12556   179]
  [  117   267]]

 [[12970    21]
  [   45    83]]

 [[10817   415]
  [  475  1412]]

 [[12901    50]
  [   64   104]]

 [[11148   676]
  [  433   862]]

 [[12573   165]
  [  173   208]]

 [[13105     0]
  [    9     5]]

 [[12147   203]
  [  392   377]]

 [[12599   148]
  [  213   159]]

 [[12256   233]
  [  162   468]]

 [[13108     0]
  [   11     0]]

 [[12505   298]
  [  155   161]]

 [[12426   288]
  [  143   262]]

 [[12995    29]
  [   40    55]]

 [[13092     2]
  [   25     0]]

 [[13036    18]
  [   44    21]]

 [[13094     3]
  [    7    15]]

 [[12976    22]
  [   69    52]]

 [[12964    42]
  [   31    82]]

 [[12851    60]
  [   54   154]]

 [[12878    47]
  [   80   114]]

 [[13054    18]
  [   26    21]]

 [[12612    76]
  [   50   381]]

 [[13046     7]
  [   12    54]]

 [[12505   126]
  [  121   367]]

 [[13035    21]
  [   24    39]]

 [[12803    53]
  [   50   213]]

 [[13062     8]
  [   28    21]]

 [[13068    21]
  [    3    27]]

 [[13094    10]
  [    4    11]]

 [[13095     2]
  [    9    13]]

 [[13032    14]
  [   23    50]]]

===scores report===
metrics	scores
Accuracy	0.6540
MCC	0.6332
log_loss	1.5324
f1 score weighted	0.6500
f1 score macro	0.5525
f1 score micro	0.6540
roc_auc ovr	0.9528
roc_auc ovo	0.9521
precision	0.6570
recall	0.6540

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6561737804878048	0.6339974833194664	1.505817036003483	0.6510725273687794	0.5392516530118093	0.6561737804878048	0.9522152863041972	0.9479676872871804	0.6581354112039788	0.6561737804878048
1	0.6472560975609756	0.6250652871785538	1.6214571015756283	0.6411444579541353	0.5482771231333744	0.6472560975609756	0.9494090831414499	0.9460073686294744	0.6530550145097545	0.6472560975609756
2	0.6734756097560975	0.6526610392255844	1.4716226749446188	0.6693988757796139	0.580423468022728	0.6734756097560975	0.9552117105171132	0.952712464689676	0.674643472377541	0.6734756097560975
3	0.6535823170731707	0.6322423933372995	1.53813767265353	0.6487705055966383	0.5423470453512537	0.6535823170731707	0.9528078740093779	0.9510289541353989	0.6518307766261987	0.6535823170731707
4	0.654013263206037	0.6331587914321702	1.5324119281443507	0.6500452732501212	0.5524973151119723	0.654013263206037	0.9528041766229276	0.9520785781947068	0.6569816559278605	0.654013263206037
mean	0.656900213616817	0.6354249988986148	1.533889282664322	0.6520863279898576	0.5525593209262276	0.656900213616817	0.9524896261190131	0.9499590105872873	0.6589292661290667	0.656900213616817
std	0.008804809559691611	0.009183759450729167	0.049706208409549396	0.009334208109363168	0.014670626120334327	0.008804809559691611	0.001853373927744837	0.002561237910887008	0.008200671368453148	0.008804809559691611

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 24354.8039 secs

