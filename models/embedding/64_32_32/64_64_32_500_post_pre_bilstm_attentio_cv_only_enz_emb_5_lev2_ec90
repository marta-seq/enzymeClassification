/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_emb_5_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efdb4512820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efdb4512670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efdb4512850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efdb4512580>, 'x_test': array([[13,  2,  3, ...,  0,  0,  0],
       [13, 13,  2, ...,  0,  0,  0],
       [13,  7,  1, ...,  0,  0,  0],
       ...,
       [13,  4, 11, ...,  0,  0,  0],
       [13,  1, 20, ...,  0,  0,  0],
       [13,  6, 12, ...,  0,  0,  0]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.77      0.83       911
         1.0       0.97      0.60      0.74        53
         2.0       0.88      0.65      0.75       179
         3.0       0.00      0.00      0.00        25
         4.0       0.78      0.06      0.12       112
         5.0       0.88      0.47      0.61       491
         6.0       1.00      0.55      0.71        64
         7.0       0.00      0.00      0.00        37
         8.0       0.95      0.67      0.78       206
         9.0       0.95      0.58      0.72        71
        10.0       0.95      0.79      0.86       404
        11.0       1.00      0.50      0.67        16
        12.0       0.94      0.58      0.72       378
        13.0       0.97      0.60      0.74       191
        14.0       0.00      0.00      0.00        76
        15.0       0.89      0.50      0.64        66
        16.0       0.97      0.52      0.68       141
        17.0       0.82      0.58      0.68       182
        18.0       1.00      0.33      0.50        12
        19.0       0.97      0.84      0.90        38
        20.0       0.98      0.85      0.91      2162
        21.0       0.86      0.92      0.89       168
        22.0       0.87      0.66      0.75      1470
        23.0       0.87      0.80      0.83      1259
        24.0       0.90      0.81      0.85       956
        25.0       0.97      0.81      0.88       283
        26.0       0.64      0.94      0.76      3919
        27.0       0.99      0.87      0.93       531
        28.0       1.00      0.58      0.74        12
        29.0       0.48      0.87      0.62      2345
        30.0       0.72      0.51      0.60       615
        31.0       1.00      0.62      0.77        32
        32.0       0.75      0.64      0.69      1449
        33.0       0.77      0.73      0.74       893
        34.0       0.90      0.79      0.84      1377
        35.0       1.00      0.36      0.53        22
        36.0       0.83      0.73      0.77       844
        37.0       0.91      0.80      0.86      1142
        38.0       0.95      0.81      0.88       314
        39.0       1.00      0.36      0.53        56
        40.0       0.87      0.76      0.81       154
        41.0       1.00      0.85      0.92        52
        42.0       0.91      0.64      0.76       247
        43.0       0.88      0.64      0.74       198
        44.0       0.83      0.88      0.85       529
        45.0       0.92      0.82      0.87       540
        46.0       0.00      0.00      0.00        20
        47.0       0.97      0.38      0.54        80
        48.0       0.98      0.94      0.96      1466
        49.0       0.97      0.77      0.86       148
        50.0       0.97      0.86      0.91      1453
        51.0       0.00      0.00      0.00        12
        52.0       1.00      0.82      0.90       151
        53.0       0.94      0.93      0.94       903
        54.0       0.93      0.59      0.72       108
        55.0       0.99      0.88      0.93        93
        56.0       0.97      0.88      0.92        33
        57.0       0.60      0.86      0.71        49
        58.0       0.82      0.87      0.85       154

    accuracy                           0.79     29892
   macro avg       0.83      0.63      0.70     29892
weighted avg       0.83      0.79      0.79     29892


===confusion_matrix===

[[697   0   1 ...   0   0   0]
 [  0  32   0 ...   0   0   0]
 [  0   0 117 ...   0   0   0]
 ...
 [  0   0   0 ...  29   3   0]
 [  0   0   0 ...   0  42   5]
 [  0   0   0 ...   0  13 134]]

===multilabel confusion matrix===

[[[28917    64]
  [  214   697]]

 [[29838     1]
  [   21    32]]

 [[29697    16]
  [   62   117]]

 [[29867     0]
  [   25     0]]

 [[29778     2]
  [  105     7]]

 [[29370    31]
  [  261   230]]

 [[29828     0]
  [   29    35]]

 [[29855     0]
  [   37     0]]

 [[29678     8]
  [   68   138]]

 [[29819     2]
  [   30    41]]

 [[29471    17]
  [   86   318]]

 [[29876     0]
  [    8     8]]

 [[29499    15]
  [  159   219]]

 [[29697     4]
  [   77   114]]

 [[29816     0]
  [   76     0]]

 [[29822     4]
  [   33    33]]

 [[29749     2]
  [   68    73]]

 [[29687    23]
  [   77   105]]

 [[29880     0]
  [    8     4]]

 [[29853     1]
  [    6    32]]

 [[27686    44]
  [  321  1841]]

 [[29698    26]
  [   14   154]]

 [[28281   141]
  [  499   971]]

 [[28486   147]
  [  256  1003]]

 [[28854    82]
  [  181   775]]

 [[29602     7]
  [   53   230]]

 [[23908  2065]
  [  235  3684]]

 [[29356     5]
  [   68   463]]

 [[29880     0]
  [    5     7]]

 [[25336  2211]
  [  299  2046]]

 [[29157   120]
  [  300   315]]

 [[29860     0]
  [   12    20]]

 [[28135   308]
  [  524   925]]

 [[28800   199]
  [  245   648]]

 [[28394   121]
  [  296  1081]]

 [[29870     0]
  [   14     8]]

 [[28918   130]
  [  231   613]]

 [[28664    86]
  [  224   918]]

 [[29566    12]
  [   60   254]]

 [[29836     0]
  [   36    20]]

 [[29720    18]
  [   37   117]]

 [[29840     0]
  [    8    44]]

 [[29630    15]
  [   88   159]]

 [[29676    18]
  [   71   127]]

 [[29269    94]
  [   66   463]]

 [[29315    37]
  [   96   444]]

 [[29872     0]
  [   20     0]]

 [[29811     1]
  [   50    30]]

 [[28398    28]
  [   91  1375]]

 [[29740     4]
  [   34   114]]

 [[28400    39]
  [  197  1256]]

 [[29880     0]
  [   12     0]]

 [[29741     0]
  [   27   124]]

 [[28934    55]
  [   61   842]]

 [[29779     5]
  [   44    64]]

 [[29798     1]
  [   11    82]]

 [[29858     1]
  [    4    29]]

 [[29815    28]
  [    7    42]]

 [[29709    29]
  [   20   134]]]

===scores report===
metrics	scores
Accuracy	0.7903
MCC	0.7805
log_loss	0.8684
f1 score weighted	0.7923
f1 score macro	0.6982
f1 score micro	0.7903
roc_auc ovr	0.9852
roc_auc ovo	0.9807
precision	0.8278
recall	0.7903

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efdb4512820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efdb4512670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efdb4512850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efdb4512580>, 'x_test': array([[13, 12,  3, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [20, 20, 20, ...,  1,  7,  1],
       [13, 16, 11, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.85      0.84       912
         1.0       1.00      0.60      0.75        53
         2.0       0.92      0.59      0.72       179
         3.0       1.00      0.04      0.08        25
         4.0       0.93      0.12      0.21       112
         5.0       0.91      0.54      0.68       492
         6.0       0.94      0.75      0.84        65
         7.0       0.67      0.05      0.10        38
         8.0       0.94      0.74      0.83       206
         9.0       0.84      0.58      0.68        71
        10.0       0.93      0.82      0.87       405
        11.0       1.00      0.29      0.45        17
        12.0       0.84      0.66      0.74       377
        13.0       0.91      0.65      0.76       191
        14.0       0.50      0.09      0.16        76
        15.0       0.73      0.58      0.64        66
        16.0       0.98      0.65      0.78       140
        17.0       0.88      0.62      0.72       182
        18.0       1.00      1.00      1.00        11
        19.0       1.00      0.73      0.84        37
        20.0       0.95      0.88      0.91      2163
        21.0       0.95      0.90      0.92       169
        22.0       0.74      0.78      0.76      1469
        23.0       0.70      0.87      0.78      1259
        24.0       0.94      0.82      0.88       956
        25.0       0.92      0.82      0.86       282
        26.0       0.68      0.94      0.79      3919
        27.0       0.99      0.81      0.89       531
        28.0       1.00      0.75      0.86        12
        29.0       0.73      0.73      0.73      2346
        30.0       0.59      0.63      0.61       615
        31.0       0.89      0.75      0.81        32
        32.0       0.65      0.74      0.69      1450
        33.0       0.79      0.69      0.74       893
        34.0       0.88      0.86      0.87      1376
        35.0       0.78      0.32      0.45        22
        36.0       0.72      0.79      0.75       843
        37.0       0.86      0.81      0.84      1142
        38.0       0.99      0.81      0.89       314
        39.0       0.88      0.38      0.53        56
        40.0       0.75      0.73      0.74       154
        41.0       1.00      0.83      0.91        52
        42.0       0.79      0.76      0.78       247
        43.0       0.97      0.65      0.78       198
        44.0       0.92      0.81      0.86       529
        45.0       0.94      0.85      0.89       539
        46.0       0.50      0.05      0.10        19
        47.0       0.93      0.50      0.65        80
        48.0       0.98      0.94      0.96      1466
        49.0       0.92      0.78      0.84       148
        50.0       0.98      0.87      0.92      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.96      0.85      0.91       151
        53.0       0.95      0.94      0.94       903
        54.0       0.97      0.71      0.82       108
        55.0       0.96      0.74      0.84        93
        56.0       0.92      0.67      0.77        33
        57.0       0.82      0.82      0.82        49
        58.0       0.75      0.89      0.81       154

    accuracy                           0.81     29892
   macro avg       0.85      0.67      0.72     29892
weighted avg       0.83      0.81      0.81     29892


===confusion_matrix===

[[774   0   0 ...   0   0   0]
 [  0  32   0 ...   0   0   0]
 [  0   0 105 ...   0   0   0]
 ...
 [  0   0   0 ...  22   2   3]
 [  0   0   0 ...   0  40   6]
 [  0   0   0 ...   0   5 137]]

===multilabel confusion matrix===

[[[28829   151]
  [  138   774]]

 [[29839     0]
  [   21    32]]

 [[29704     9]
  [   74   105]]

 [[29867     0]
  [   24     1]]

 [[29779     1]
  [   99    13]]

 [[29372    28]
  [  224   268]]

 [[29824     3]
  [   16    49]]

 [[29853     1]
  [   36     2]]

 [[29677     9]
  [   53   153]]

 [[29813     8]
  [   30    41]]

 [[29463    24]
  [   73   332]]

 [[29875     0]
  [   12     5]]

 [[29468    47]
  [  128   249]]

 [[29689    12]
  [   67   124]]

 [[29809     7]
  [   69     7]]

 [[29812    14]
  [   28    38]]

 [[29750     2]
  [   49    91]]

 [[29694    16]
  [   70   112]]

 [[29881     0]
  [    0    11]]

 [[29855     0]
  [   10    27]]

 [[27637    92]
  [  263  1900]]

 [[29715     8]
  [   17   152]]

 [[28008   415]
  [  316  1153]]

 [[28169   464]
  [  159  1100]]

 [[28884    52]
  [  170   786]]

 [[29590    20]
  [   52   230]]

 [[24228  1745]
  [  242  3677]]

 [[29358     3]
  [   99   432]]

 [[29880     0]
  [    3     9]]

 [[26923   623]
  [  639  1707]]

 [[29011   266]
  [  228   387]]

 [[29857     3]
  [    8    24]]

 [[27871   571]
  [  379  1071]]

 [[28831   168]
  [  276   617]]

 [[28352   164]
  [  193  1183]]

 [[29868     2]
  [   15     7]]

 [[28789   260]
  [  175   668]]

 [[28605   145]
  [  213   929]]

 [[29576     2]
  [   60   254]]

 [[29833     3]
  [   35    21]]

 [[29701    37]
  [   41   113]]

 [[29840     0]
  [    9    43]]

 [[29596    49]
  [   59   188]]

 [[29690     4]
  [   69   129]]

 [[29325    38]
  [  102   427]]

 [[29326    27]
  [   81   458]]

 [[29872     1]
  [   18     1]]

 [[29809     3]
  [   40    40]]

 [[28394    32]
  [   95  1371]]

 [[29734    10]
  [   33   115]]

 [[28408    31]
  [  190  1263]]

 [[29880     0]
  [   12     0]]

 [[29736     5]
  [   22   129]]

 [[28944    45]
  [   56   847]]

 [[29782     2]
  [   31    77]]

 [[29796     3]
  [   24    69]]

 [[29857     2]
  [   11    22]]

 [[29834     9]
  [    9    40]]

 [[29692    46]
  [   17   137]]]

===scores report===
metrics	scores
Accuracy	0.8099
MCC	0.7997
log_loss	0.7694
f1 score weighted	0.8086
f1 score macro	0.7220
f1 score micro	0.8099
roc_auc ovr	0.9860
roc_auc ovo	0.9815
precision	0.8263
recall	0.8099

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efdb4512820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efdb4512670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efdb4512850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efdb4512580>, 'x_test': array([[13, 16,  8, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       [13, 19,  3, ...,  0,  0,  0],
       ...,
       [13,  1, 17, ...,  0,  0,  0],
       [ 9,  5,  1, ...,  8, 11, 15],
       [20,  6, 15, ...,  4,  2,  3]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.90      0.81       912
         1.0       1.00      0.81      0.89        52
         2.0       0.92      0.67      0.77       179
         3.0       0.00      0.00      0.00        25
         4.0       0.93      0.22      0.36       112
         5.0       0.93      0.55      0.69       492
         6.0       0.85      0.82      0.83        65
         7.0       0.00      0.00      0.00        38
         8.0       1.00      0.72      0.84       205
         9.0       0.93      0.56      0.70        71
        10.0       0.87      0.85      0.86       405
        11.0       1.00      0.24      0.38        17
        12.0       0.78      0.71      0.75       377
        13.0       0.74      0.71      0.72       190
        14.0       0.00      0.00      0.00        76
        15.0       0.82      0.55      0.66        67
        16.0       1.00      0.59      0.74       140
        17.0       0.78      0.63      0.70       183
        18.0       1.00      0.58      0.74        12
        19.0       1.00      0.86      0.93        37
        20.0       0.93      0.89      0.91      2162
        21.0       1.00      0.82      0.90       169
        22.0       0.61      0.80      0.69      1470
        23.0       0.86      0.80      0.83      1259
        24.0       0.96      0.86      0.91       956
        25.0       0.99      0.80      0.88       282
        26.0       0.75      0.91      0.82      3918
        27.0       0.95      0.87      0.91       531
        28.0       1.00      0.69      0.82        13
        29.0       0.62      0.80      0.70      2346
        30.0       0.76      0.44      0.56       615
        31.0       1.00      0.75      0.86        32
        32.0       0.60      0.79      0.69      1450
        33.0       0.87      0.70      0.77       893
        34.0       0.93      0.83      0.88      1376
        35.0       1.00      0.45      0.62        22
        36.0       0.87      0.75      0.81       843
        37.0       0.82      0.86      0.84      1142
        38.0       0.96      0.86      0.90       314
        39.0       1.00      0.27      0.43        55
        40.0       0.78      0.66      0.72       154
        41.0       1.00      0.79      0.88        52
        42.0       0.88      0.71      0.79       247
        43.0       1.00      0.69      0.81       197
        44.0       0.99      0.82      0.90       530
        45.0       0.98      0.79      0.88       540
        46.0       0.00      0.00      0.00        19
        47.0       0.80      0.46      0.58        79
        48.0       1.00      0.92      0.96      1465
        49.0       0.97      0.79      0.87       149
        50.0       0.98      0.89      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.97      0.84      0.90       152
        53.0       0.94      0.93      0.93       903
        54.0       0.95      0.71      0.81       108
        55.0       0.85      0.87      0.86        93
        56.0       0.97      0.88      0.92        32
        57.0       0.97      0.76      0.85        50
        58.0       0.83      0.96      0.89       154

    accuracy                           0.81     29892
   macro avg       0.82      0.67      0.72     29892
weighted avg       0.83      0.81      0.81     29892


===confusion_matrix===

[[824   0   0 ...   0   0   0]
 [  0  42   0 ...   0   0   0]
 [  1   0 120 ...   0   0   0]
 ...
 [  0   0   0 ...  28   0   0]
 [  0   0   0 ...   0  38  11]
 [  0   0   0 ...   0   0 148]]

===multilabel confusion matrix===

[[[28691   289]
  [   88   824]]

 [[29840     0]
  [   10    42]]

 [[29702    11]
  [   59   120]]

 [[29867     0]
  [   25     0]]

 [[29778     2]
  [   87    25]]

 [[29380    20]
  [  223   269]]

 [[29818     9]
  [   12    53]]

 [[29854     0]
  [   38     0]]

 [[29687     0]
  [   58   147]]

 [[29818     3]
  [   31    40]]

 [[29437    50]
  [   60   345]]

 [[29875     0]
  [   13     4]]

 [[29440    75]
  [  108   269]]

 [[29654    48]
  [   55   135]]

 [[29816     0]
  [   76     0]]

 [[29817     8]
  [   30    37]]

 [[29752     0]
  [   58    82]]

 [[29676    33]
  [   67   116]]

 [[29880     0]
  [    5     7]]

 [[29855     0]
  [    5    32]]

 [[27595   135]
  [  246  1916]]

 [[29723     0]
  [   31   138]]

 [[27660   762]
  [  288  1182]]

 [[28467   166]
  [  252  1007]]

 [[28902    34]
  [  132   824]]

 [[29607     3]
  [   56   226]]

 [[24783  1191]
  [  337  3581]]

 [[29335    26]
  [   69   462]]

 [[29879     0]
  [    4     9]]

 [[26414  1132]
  [  460  1886]]

 [[29193    84]
  [  342   273]]

 [[29860     0]
  [    8    24]]

 [[27691   751]
  [  300  1150]]

 [[28906    93]
  [  272   621]]

 [[28426    90]
  [  234  1142]]

 [[29870     0]
  [   12    10]]

 [[28957    92]
  [  213   630]]

 [[28537   213]
  [  161   981]]

 [[29566    12]
  [   45   269]]

 [[29837     0]
  [   40    15]]

 [[29709    29]
  [   52   102]]

 [[29840     0]
  [   11    41]]

 [[29622    23]
  [   71   176]]

 [[29695     0]
  [   62   135]]

 [[29357     5]
  [   95   435]]

 [[29344     8]
  [  111   429]]

 [[29873     0]
  [   19     0]]

 [[29804     9]
  [   43    36]]

 [[28426     1]
  [  124  1341]]

 [[29739     4]
  [   31   118]]

 [[28406    33]
  [  165  1288]]

 [[29880     0]
  [   12     0]]

 [[29736     4]
  [   24   128]]

 [[28932    57]
  [   61   842]]

 [[29780     4]
  [   31    77]]

 [[29785    14]
  [   12    81]]

 [[29859     1]
  [    4    28]]

 [[29841     1]
  [   12    38]]

 [[29707    31]
  [    6   148]]]

===scores report===
metrics	scores
Accuracy	0.8141
MCC	0.8041
log_loss	0.7421
f1 score weighted	0.8132
f1 score macro	0.7219
f1 score micro	0.8141
roc_auc ovr	0.9870
roc_auc ovo	0.9824
precision	0.8313
recall	0.8141

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efdb4512820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efdb4512670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efdb4512850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efdb4512580>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       [13, 12, 12, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [20,  2,  1, ...,  7,  6,  6],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.85      0.85       912
         1.0       1.00      0.77      0.87        52
         2.0       0.71      0.59      0.64       179
         3.0       0.00      0.00      0.00        24
         4.0       0.63      0.21      0.32       112
         5.0       0.79      0.56      0.66       492
         6.0       0.92      0.70      0.80        64
         7.0       0.50      0.03      0.05        38
         8.0       0.99      0.70      0.82       205
         9.0       0.83      0.69      0.75        70
        10.0       0.89      0.83      0.86       405
        11.0       1.00      0.12      0.21        17
        12.0       0.94      0.61      0.74       378
        13.0       0.85      0.72      0.78       191
        14.0       0.10      0.01      0.02        76
        15.0       0.57      0.70      0.63        67
        16.0       0.95      0.67      0.79       140
        17.0       0.68      0.67      0.67       183
        18.0       0.71      0.83      0.77        12
        19.0       0.97      0.89      0.93        37
        20.0       0.92      0.90      0.91      2162
        21.0       0.99      0.87      0.93       168
        22.0       0.82      0.76      0.79      1470
        23.0       0.67      0.86      0.76      1259
        24.0       0.95      0.84      0.89       955
        25.0       0.93      0.90      0.91       282
        26.0       0.92      0.84      0.88      3918
        27.0       0.97      0.85      0.90       532
        28.0       0.92      0.92      0.92        13
        29.0       0.50      0.88      0.63      2346
        30.0       0.59      0.62      0.60       616
        31.0       0.92      0.75      0.83        32
        32.0       0.62      0.76      0.68      1449
        33.0       0.93      0.64      0.76       893
        34.0       0.87      0.88      0.87      1377
        35.0       1.00      0.27      0.43        22
        36.0       0.92      0.77      0.84       844
        37.0       0.92      0.82      0.87      1142
        38.0       0.96      0.83      0.89       314
        39.0       1.00      0.41      0.58        56
        40.0       0.89      0.76      0.82       153
        41.0       0.84      0.71      0.77        51
        42.0       0.88      0.66      0.75       246
        43.0       0.96      0.69      0.80       197
        44.0       0.95      0.81      0.87       530
        45.0       0.97      0.78      0.86       540
        46.0       0.00      0.00      0.00        20
        47.0       0.73      0.59      0.65        80
        48.0       0.97      0.95      0.96      1465
        49.0       0.96      0.76      0.85       148
        50.0       0.98      0.88      0.93      1453
        51.0       0.00      0.00      0.00        13
        52.0       1.00      0.76      0.86       151
        53.0       0.83      0.94      0.88       904
        54.0       0.85      0.66      0.74       108
        55.0       0.96      0.88      0.92        93
        56.0       0.87      1.00      0.93        33
        57.0       0.87      0.90      0.88        50
        58.0       0.93      0.91      0.92       153

    accuracy                           0.81     29892
   macro avg       0.81      0.68      0.72     29892
weighted avg       0.84      0.81      0.82     29892


===confusion_matrix===

[[778   0   1 ...   0   0   0]
 [  0  40   0 ...   0   0   0]
 [  0   0 105 ...   0   0   0]
 ...
 [  0   0   0 ...  33   0   0]
 [  0   0   0 ...   0  45   0]
 [  0   0   0 ...   0   5 139]]

===multilabel confusion matrix===

[[[28847   133]
  [  134   778]]

 [[29840     0]
  [   12    40]]

 [[29671    42]
  [   74   105]]

 [[29868     0]
  [   24     0]]

 [[29766    14]
  [   88    24]]

 [[29327    73]
  [  215   277]]

 [[29824     4]
  [   19    45]]

 [[29853     1]
  [   37     1]]

 [[29686     1]
  [   62   143]]

 [[29812    10]
  [   22    48]]

 [[29446    41]
  [   68   337]]

 [[29875     0]
  [   15     2]]

 [[29499    15]
  [  147   231]]

 [[29676    25]
  [   54   137]]

 [[29807     9]
  [   75     1]]

 [[29790    35]
  [   20    47]]

 [[29747     5]
  [   46    94]]

 [[29651    58]
  [   61   122]]

 [[29876     4]
  [    2    10]]

 [[29854     1]
  [    4    33]]

 [[27560   170]
  [  221  1941]]

 [[29723     1]
  [   22   146]]

 [[28179   243]
  [  349  1121]]

 [[28103   530]
  [  170  1089]]

 [[28891    46]
  [  156   799]]

 [[29590    20]
  [   28   254]]

 [[25683   291]
  [  638  3280]]

 [[29344    16]
  [   82   450]]

 [[29878     1]
  [    1    12]]

 [[25445  2101]
  [  279  2067]]

 [[29003   273]
  [  231   385]]

 [[29858     2]
  [    8    24]]

 [[27759   684]
  [  347  1102]]

 [[28959    40]
  [  321   572]]

 [[28329   186]
  [  172  1205]]

 [[29870     0]
  [   16     6]]

 [[28994    54]
  [  192   652]]

 [[28671    79]
  [  205   937]]

 [[29567    11]
  [   52   262]]

 [[29836     0]
  [   33    23]]

 [[29724    15]
  [   36   117]]

 [[29834     7]
  [   15    36]]

 [[29623    23]
  [   83   163]]

 [[29689     6]
  [   61   136]]

 [[29339    23]
  [  102   428]]

 [[29338    14]
  [  120   420]]

 [[29872     0]
  [   20     0]]

 [[29795    17]
  [   33    47]]

 [[28388    39]
  [   75  1390]]

 [[29739     5]
  [   35   113]]

 [[28407    32]
  [  169  1284]]

 [[29879     0]
  [   13     0]]

 [[29741     0]
  [   36   115]]

 [[28809   179]
  [   50   854]]

 [[29771    13]
  [   37    71]]

 [[29796     3]
  [   11    82]]

 [[29854     5]
  [    0    33]]

 [[29835     7]
  [    5    45]]

 [[29729    10]
  [   14   139]]]

===scores report===
metrics	scores
Accuracy	0.8121
MCC	0.8034
log_loss	0.7732
f1 score weighted	0.8160
f1 score macro	0.7195
f1 score micro	0.8121
roc_auc ovr	0.9862
roc_auc ovo	0.9829
precision	0.8407
recall	0.8121

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7efdb4512820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7efdb4512670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7efdb4512850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7efdb4512580>, 'x_test': array([[13, 11,  3, ...,  0,  0,  0],
       [13, 17,  4, ...,  0,  0,  0],
       [13,  1, 11, ...,  0,  0,  0],
       ...,
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0],
       [15,  8, 19, ...,  8,  8,  9]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.90      0.88       911
         1.0       0.86      0.68      0.76        53
         2.0       0.81      0.70      0.75       180
         3.0       1.00      0.04      0.08        25
         4.0       0.62      0.41      0.49       111
         5.0       0.71      0.67      0.69       491
         6.0       0.95      0.83      0.88        64
         7.0       1.00      0.11      0.20        37
         8.0       0.96      0.78      0.86       205
         9.0       0.83      0.70      0.76        71
        10.0       0.97      0.86      0.91       404
        11.0       1.00      0.24      0.38        17
        12.0       0.90      0.73      0.81       378
        13.0       0.89      0.71      0.79       191
        14.0       0.75      0.04      0.07        76
        15.0       0.81      0.58      0.67        66
        16.0       0.80      0.76      0.78       140
        17.0       0.85      0.63      0.73       182
        18.0       1.00      0.58      0.74        12
        19.0       0.96      0.68      0.79        37
        20.0       0.93      0.91      0.92      2162
        21.0       0.99      0.91      0.95       168
        22.0       0.80      0.79      0.79      1470
        23.0       0.84      0.84      0.84      1259
        24.0       0.92      0.86      0.89       955
        25.0       0.96      0.89      0.93       283
        26.0       0.87      0.88      0.87      3919
        27.0       0.98      0.88      0.93       532
        28.0       0.92      0.85      0.88        13
        29.0       0.70      0.79      0.74      2345
        30.0       0.64      0.57      0.61       616
        31.0       0.93      0.81      0.87        32
        32.0       0.67      0.77      0.71      1449
        33.0       0.61      0.83      0.70       893
        34.0       0.87      0.87      0.87      1377
        35.0       1.00      0.59      0.74        22
        36.0       0.78      0.85      0.82       844
        37.0       0.91      0.83      0.87      1142
        38.0       0.96      0.89      0.92       314
        39.0       0.78      0.38      0.51        56
        40.0       0.96      0.77      0.86       153
        41.0       0.92      0.90      0.91        52
        42.0       0.89      0.75      0.81       247
        43.0       0.88      0.75      0.81       197
        44.0       0.89      0.88      0.89       529
        45.0       0.94      0.90      0.92       540
        46.0       0.00      0.00      0.00        20
        47.0       0.93      0.51      0.66        80
        48.0       0.94      0.98      0.96      1466
        49.0       0.95      0.86      0.90       148
        50.0       0.88      0.93      0.91      1453
        51.0       1.00      0.08      0.15        12
        52.0       0.98      0.81      0.88       151
        53.0       0.88      0.95      0.91       904
        54.0       0.94      0.73      0.82       108
        55.0       0.89      0.92      0.91        93
        56.0       0.94      0.91      0.92        33
        57.0       0.90      0.90      0.90        50
        58.0       0.88      0.93      0.90       154

    accuracy                           0.84     29892
   macro avg       0.87      0.71      0.75     29892
weighted avg       0.84      0.84      0.84     29892


===confusion_matrix===

[[816   0   0 ...   0   0   0]
 [  0  36   1 ...   0   0   0]
 [  0   0 126 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   0]
 [  0   0   0 ...   1  45   2]
 [  0   0   0 ...   0   5 143]]

===multilabel confusion matrix===

[[[28856   125]
  [   95   816]]

 [[29833     6]
  [   17    36]]

 [[29683    29]
  [   54   126]]

 [[29867     0]
  [   24     1]]

 [[29754    27]
  [   66    45]]

 [[29269   132]
  [  161   330]]

 [[29825     3]
  [   11    53]]

 [[29855     0]
  [   33     4]]

 [[29681     6]
  [   45   160]]

 [[29811    10]
  [   21    50]]

 [[29476    12]
  [   58   346]]

 [[29875     0]
  [   13     4]]

 [[29483    31]
  [  101   277]]

 [[29685    16]
  [   56   135]]

 [[29815     1]
  [   73     3]]

 [[29817     9]
  [   28    38]]

 [[29725    27]
  [   34   106]]

 [[29690    20]
  [   67   115]]

 [[29880     0]
  [    5     7]]

 [[29854     1]
  [   12    25]]

 [[27573   157]
  [  198  1964]]

 [[29722     2]
  [   15   153]]

 [[28128   294]
  [  316  1154]]

 [[28432   201]
  [  197  1062]]

 [[28866    71]
  [  134   821]]

 [[29599    10]
  [   30   253]]

 [[25437   536]
  [  457  3462]]

 [[29350    10]
  [   62   470]]

 [[29878     1]
  [    2    11]]

 [[26736   811]
  [  493  1852]]

 [[29080   196]
  [  263   353]]

 [[29858     2]
  [    6    26]]

 [[27884   559]
  [  339  1110]]

 [[28527   472]
  [  154   739]]

 [[28342   173]
  [  182  1195]]

 [[29870     0]
  [    9    13]]

 [[28851   197]
  [  125   719]]

 [[28660    90]
  [  190   952]]

 [[29567    11]
  [   35   279]]

 [[29830     6]
  [   35    21]]

 [[29734     5]
  [   35   118]]

 [[29836     4]
  [    5    47]]

 [[29622    23]
  [   62   185]]

 [[29675    20]
  [   49   148]]

 [[29308    55]
  [   65   464]]

 [[29322    30]
  [   54   486]]

 [[29872     0]
  [   20     0]]

 [[29809     3]
  [   39    41]]

 [[28342    84]
  [   31  1435]]

 [[29737     7]
  [   21   127]]

 [[28253   186]
  [   97  1356]]

 [[29880     0]
  [   11     1]]

 [[29738     3]
  [   29   122]]

 [[28871   117]
  [   45   859]]

 [[29779     5]
  [   29    79]]

 [[29788    11]
  [    7    86]]

 [[29857     2]
  [    3    30]]

 [[29837     5]
  [    5    45]]

 [[29718    20]
  [   11   143]]]

===scores report===
metrics	scores
Accuracy	0.8383
MCC	0.8295
log_loss	0.6462
f1 score weighted	0.8369
f1 score macro	0.7527
f1 score micro	0.8383
roc_auc ovr	0.9892
roc_auc ovo	0.9856
precision	0.8443
recall	0.8383

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7903452428743476	0.7805131676200684	0.8684482469810882	0.7922669290407344	0.6981709198550342	0.7903452428743476	0.9851872635860989	0.9807054380375996	0.8278257307236256	0.7903452428743476
1	0.8099156965074268	0.7997478137610895	0.7694237146586185	0.8085748572287041	0.7220239148897141	0.8099156965074268	0.9859629192793261	0.9814752936898455	0.8262864892582203	0.8099156965074268
2	0.81413087113609	0.8040571098500277	0.7420620650902173	0.8132235565262772	0.7219171909370583	0.81413087113609	0.9869647353222719	0.9824166463951	0.8312538405225101	0.81413087113609
3	0.8120901913555466	0.803353149723916	0.773168674609253	0.8160273526252165	0.7194512345437863	0.8120901913555466	0.9861980626618216	0.9828821206709408	0.8407256657968888	0.8120901913555466
4	0.8382844908336679	0.8295112172605349	0.6461865460566983	0.8368609975945813	0.7527295785322201	0.838284490833668	0.9892080467646172	0.9855845779324583	0.8443114744424903	0.8382844908336679
mean	0.8129532985414158	0.8034364916431272	0.759857849479175	0.8133907386031026	0.7228585677515627	0.8129532985414158	0.9867042055228271	0.9826128153451889	0.8340806401487469	0.8129532985414158
std	0.015258782004729113	0.015616456433140719	0.07113144654185145	0.014333462835721063	0.017406607935014865	0.01525878200472915	0.0013743285975663104	0.0016657985592762148	0.007165051463292634	0.015258782004729113

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 70174.7642 secs

