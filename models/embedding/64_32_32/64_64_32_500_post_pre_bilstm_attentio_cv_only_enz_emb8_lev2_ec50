/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_emb8_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2e881b47f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2e881b4640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2e881b47c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2e881b4550>, 'x_test': array([[13, 13,  2, ...,  0,  0,  0],
       [13,  4, 12, ...,  0,  0,  0],
       [13, 16,  8, ...,  0,  0,  0],
       ...,
       [13,  1, 20, ...,  0,  0,  0],
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.50      0.78      0.61       402
         1.0       1.00      0.05      0.10        19
         2.0       0.51      0.33      0.40        82
         3.0       0.00      0.00      0.00        16
         4.0       0.00      0.00      0.00        62
         5.0       0.57      0.55      0.56       277
         6.0       0.84      0.58      0.69        36
         7.0       0.00      0.00      0.00        26
         8.0       0.77      0.32      0.45        72
         9.0       0.35      0.50      0.41        30
        10.0       0.68      0.59      0.63       156
        11.0       0.33      0.22      0.26       168
        12.0       0.46      0.42      0.44        83
        13.0       0.14      0.02      0.03        53
        14.0       0.50      0.29      0.37        31
        15.0       0.83      0.29      0.43        52
        16.0       0.39      0.48      0.43        94
        17.0       0.77      0.80      0.79       885
        18.0       0.70      0.29      0.41        48
        19.0       0.51      0.71      0.60       781
        20.0       0.91      0.53      0.67       591
        21.0       0.72      0.68      0.70       385
        22.0       0.95      0.64      0.77       128
        23.0       0.68      0.78      0.73      1888
        24.0       0.84      0.57      0.68       169
        25.0       0.67      0.54      0.60      1296
        26.0       0.67      0.40      0.50       381
        27.0       0.80      0.29      0.42        14
        28.0       0.42      0.62      0.50       769
        29.0       0.36      0.47      0.41       372
        30.0       0.73      0.72      0.72       631
        31.0       0.00      0.00      0.00        11
        32.0       0.62      0.28      0.38       316
        33.0       0.57      0.57      0.57       405
        34.0       0.72      0.43      0.54        96
        35.0       0.00      0.00      0.00        26
        36.0       0.81      0.32      0.46        65
        37.0       0.92      0.52      0.67        21
        38.0       0.74      0.55      0.63       121
        39.0       0.48      0.68      0.56       114
        40.0       0.86      0.64      0.73       207
        41.0       0.68      0.63      0.65       194
        42.0       0.46      0.55      0.50        47
        43.0       0.82      0.87      0.85       431
        44.0       0.96      0.67      0.79        67
        45.0       0.60      0.79      0.68       488
        46.0       0.76      0.68      0.72        62
        47.0       0.80      0.87      0.83       264
        48.0       0.68      0.51      0.58        49
        49.0       0.78      0.47      0.58        30
        50.0       0.85      0.73      0.79        15
        51.0       0.70      0.76      0.73        21
        52.0       0.66      0.92      0.77        73

    accuracy                           0.63     13120
   macro avg       0.60      0.49      0.52     13120
weighted avg       0.65      0.63      0.62     13120


===confusion_matrix===

[[312   0   0 ...   0   0   0]
 [  2   1   0 ...   0   0   0]
 [  0   0  27 ...   0   0   0]
 ...
 [  0   0   0 ...  11   2   0]
 [  0   0   0 ...   0  16   2]
 [  0   0   0 ...   1   2  67]]

===multilabel confusion matrix===

[[[12412   306]
  [   90   312]]

 [[13101     0]
  [   18     1]]

 [[13012    26]
  [   55    27]]

 [[13103     1]
  [   16     0]]

 [[13058     0]
  [   62     0]]

 [[12730   113]
  [  126   151]]

 [[13080     4]
  [   15    21]]

 [[13093     1]
  [   26     0]]

 [[13041     7]
  [   49    23]]

 [[13062    28]
  [   15    15]]

 [[12921    43]
  [   64    92]]

 [[12876    76]
  [  131    37]]

 [[12996    41]
  [   48    35]]

 [[13061     6]
  [   52     1]]

 [[13080     9]
  [   22     9]]

 [[13065     3]
  [   37    15]]

 [[12956    70]
  [   49    45]]

 [[12026   209]
  [  173   712]]

 [[13066     6]
  [   34    14]]

 [[11805   534]
  [  223   558]]

 [[12499    30]
  [  275   316]]

 [[12633   102]
  [  125   260]]

 [[12988     4]
  [   46    82]]

 [[10533   699]
  [  407  1481]]

 [[12932    19]
  [   72    97]]

 [[11482   342]
  [  596   700]]

 [[12663    76]
  [  227   154]]

 [[13105     1]
  [   10     4]]

 [[11695   656]
  [  296   473]]

 [[12438   310]
  [  198   174]]

 [[12318   171]
  [  179   452]]

 [[13109     0]
  [   11     0]]

 [[12750    54]
  [  228    88]]

 [[12540   175]
  [  175   230]]

 [[13008    16]
  [   55    41]]

 [[13094     0]
  [   26     0]]

 [[13050     5]
  [   44    21]]

 [[13098     1]
  [   10    11]]

 [[12976    23]
  [   55    66]]

 [[12920    86]
  [   36    78]]

 [[12891    22]
  [   74   133]]

 [[12869    57]
  [   72   122]]

 [[13042    31]
  [   21    26]]

 [[12609    80]
  [   57   374]]

 [[13051     2]
  [   22    45]]

 [[12373   259]
  [  101   387]]

 [[13045    13]
  [   20    42]]

 [[12800    56]
  [   35   229]]

 [[13059    12]
  [   24    25]]

 [[13086     4]
  [   16    14]]

 [[13103     2]
  [    4    11]]

 [[13092     7]
  [    5    16]]

 [[13012    35]
  [    6    67]]]

===scores report===
metrics	scores
Accuracy	0.6316
MCC	0.6092
log_loss	1.4601
f1 score weighted	0.6246
f1 score macro	0.5154
f1 score micro	0.6316
roc_auc ovr	0.9504
roc_auc ovo	0.9483
precision	0.6475
recall	0.6316

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2e881b47f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2e881b4640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2e881b47c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2e881b4550>, 'x_test': array([[13, 16,  7, ...,  0,  0,  0],
       [13, 16, 12, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [12, 20, 14, ...,  9, 15, 11],
       [ 3, 16, 15, ..., 11, 19,  1],
       [13,  4, 11, ...,  0,  0,  0]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.60      0.68       402
         1.0       0.70      0.37      0.48        19
         2.0       0.47      0.33      0.39        81
         3.0       0.00      0.00      0.00        16
         4.0       0.35      0.15      0.20        62
         5.0       0.45      0.64      0.53       277
         6.0       0.90      0.75      0.82        36
         7.0       0.00      0.00      0.00        26
         8.0       0.75      0.29      0.42        73
         9.0       0.47      0.31      0.38        29
        10.0       0.56      0.67      0.61       156
        11.0       0.69      0.32      0.43       168
        12.0       0.72      0.31      0.44        83
        13.0       0.00      0.00      0.00        53
        14.0       0.52      0.34      0.42        32
        15.0       0.62      0.15      0.25        52
        16.0       0.65      0.35      0.45        95
        17.0       0.80      0.81      0.81       884
        18.0       0.57      0.50      0.53        48
        19.0       0.45      0.74      0.56       782
        20.0       0.63      0.74      0.68       591
        21.0       0.74      0.70      0.72       385
        22.0       0.71      0.83      0.77       128
        23.0       0.77      0.77      0.77      1888
        24.0       0.91      0.51      0.66       169
        25.0       0.52      0.70      0.59      1295
        26.0       0.59      0.59      0.59       381
        27.0       1.00      0.50      0.67        14
        28.0       0.62      0.47      0.54       769
        29.0       0.49      0.50      0.49       371
        30.0       0.68      0.75      0.71       631
        31.0       0.60      0.27      0.37        11
        32.0       0.44      0.52      0.48       316
        33.0       0.78      0.47      0.59       405
        34.0       0.74      0.44      0.55        96
        35.0       0.33      0.04      0.07        26
        36.0       0.94      0.23      0.37        65
        37.0       1.00      0.64      0.78        22
        38.0       0.83      0.45      0.58       121
        39.0       0.85      0.60      0.70       113
        40.0       0.89      0.57      0.70       208
        41.0       0.79      0.57      0.66       193
        42.0       0.63      0.26      0.37        46
        43.0       0.68      0.95      0.79       431
        44.0       0.80      0.68      0.74        66
        45.0       0.87      0.69      0.77       489
        46.0       0.50      0.69      0.58        62
        47.0       0.89      0.72      0.80       264
        48.0       0.81      0.45      0.58        49
        49.0       0.79      0.48      0.60        31
        50.0       0.93      0.81      0.87        16
        51.0       0.72      0.62      0.67        21
        52.0       0.62      0.90      0.74        73

    accuracy                           0.65     13120
   macro avg       0.65      0.50      0.55     13120
weighted avg       0.67      0.65      0.64     13120


===confusion_matrix===

[[243   0   0 ...   0   1   0]
 [  0   7   0 ...   0   0   0]
 [  0   0  27 ...   0   0   0]
 ...
 [  0   0   0 ...  13   1   1]
 [  0   0   0 ...   0  13   8]
 [  0   0   0 ...   0   0  66]]

===multilabel confusion matrix===

[[[12649    69]
  [  159   243]]

 [[13098     3]
  [   12     7]]

 [[13009    30]
  [   54    27]]

 [[13100     4]
  [   16     0]]

 [[13041    17]
  [   53     9]]

 [[12628   215]
  [  101   176]]

 [[13081     3]
  [    9    27]]

 [[13094     0]
  [   26     0]]

 [[13040     7]
  [   52    21]]

 [[13081    10]
  [   20     9]]

 [[12881    83]
  [   52   104]]

 [[12928    24]
  [  115    53]]

 [[13027    10]
  [   57    26]]

 [[13067     0]
  [   53     0]]

 [[13078    10]
  [   21    11]]

 [[13063     5]
  [   44     8]]

 [[13007    18]
  [   62    33]]

 [[12058   178]
  [  164   720]]

 [[13054    18]
  [   24    24]]

 [[11645   693]
  [  204   578]]

 [[12276   253]
  [  154   437]]

 [[12642    93]
  [  115   270]]

 [[12949    43]
  [   22   106]]

 [[10802   430]
  [  439  1449]]

 [[12942     9]
  [   82    87]]

 [[10980   845]
  [  394   901]]

 [[12583   156]
  [  157   224]]

 [[13106     0]
  [    7     7]]

 [[12132   219]
  [  406   363]]

 [[12556   193]
  [  186   185]]

 [[12266   223]
  [  158   473]]

 [[13107     2]
  [    8     3]]

 [[12595   209]
  [  152   164]]

 [[12661    54]
  [  215   190]]

 [[13009    15]
  [   54    42]]

 [[13092     2]
  [   25     1]]

 [[13054     1]
  [   50    15]]

 [[13098     0]
  [    8    14]]

 [[12988    11]
  [   67    54]]

 [[12995    12]
  [   45    68]]

 [[12898    14]
  [   89   119]]

 [[12897    30]
  [   83   110]]

 [[13067     7]
  [   34    12]]

 [[12497   192]
  [   23   408]]

 [[13043    11]
  [   21    45]]

 [[12579    52]
  [  150   339]]

 [[13015    43]
  [   19    43]]

 [[12832    24]
  [   73   191]]

 [[13066     5]
  [   27    22]]

 [[13085     4]
  [   16    15]]

 [[13103     1]
  [    3    13]]

 [[13094     5]
  [    8    13]]

 [[13007    40]
  [    7    66]]]

===scores report===
metrics	scores
Accuracy	0.6498
MCC	0.6283
log_loss	1.4079
f1 score weighted	0.6445
f1 score macro	0.5457
f1 score micro	0.6498
roc_auc ovr	0.9536
roc_auc ovo	0.9517
precision	0.6704
recall	0.6498

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2e881b47f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2e881b4640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2e881b47c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2e881b4550>, 'x_test': array([[13,  7,  1, ...,  0,  0,  0],
       [13,  1,  1, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       ...,
       [17, 19, 16, ...,  6, 14,  4],
       [20, 20, 20, ...,  1,  7,  1],
       [17, 12, 15, ...,  3,  9, 11]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.74      0.70       401
         1.0       1.00      0.40      0.57        20
         2.0       0.64      0.37      0.47        82
         3.0       1.00      0.06      0.12        16
         4.0       0.39      0.11      0.18        62
         5.0       0.81      0.39      0.53       277
         6.0       0.79      0.75      0.77        36
         7.0       0.00      0.00      0.00        25
         8.0       0.96      0.36      0.52        73
         9.0       0.48      0.34      0.40        29
        10.0       0.70      0.63      0.67       156
        11.0       0.49      0.41      0.45       168
        12.0       0.53      0.30      0.38        83
        13.0       0.47      0.13      0.20        54
        14.0       0.23      0.26      0.24        31
        15.0       0.52      0.42      0.46        53
        16.0       0.76      0.44      0.56        95
        17.0       0.88      0.76      0.82       884
        18.0       0.37      0.70      0.48        47
        19.0       0.85      0.50      0.63       782
        20.0       0.64      0.79      0.70       592
        21.0       0.75      0.69      0.72       385
        22.0       0.84      0.80      0.82       128
        23.0       0.75      0.80      0.77      1887
        24.0       0.82      0.57      0.67       168
        25.0       0.51      0.66      0.57      1295
        26.0       0.42      0.61      0.50       381
        27.0       1.00      0.64      0.78        14
        28.0       0.63      0.49      0.55       768
        29.0       0.40      0.41      0.41       372
        30.0       0.76      0.72      0.74       631
        31.0       0.18      0.20      0.19        10
        32.0       0.31      0.53      0.39       316
        33.0       0.52      0.52      0.52       405
        34.0       0.58      0.60      0.59        96
        35.0       0.00      0.00      0.00        26
        36.0       0.58      0.29      0.38        66
        37.0       1.00      0.32      0.48        22
        38.0       0.72      0.63      0.67       121
        39.0       0.93      0.68      0.79       113
        40.0       0.80      0.72      0.75       208
        41.0       0.52      0.69      0.59       194
        42.0       0.65      0.33      0.43        46
        43.0       0.76      0.95      0.85       431
        44.0       0.82      0.77      0.80        66
        45.0       0.67      0.80      0.73       489
        46.0       0.64      0.56      0.60        62
        47.0       0.80      0.86      0.83       263
        48.0       0.85      0.58      0.69        50
        49.0       0.71      0.71      0.71        31
        50.0       0.83      0.62      0.71        16
        51.0       0.71      0.81      0.76        21
        52.0       0.79      0.81      0.80        73

    accuracy                           0.65     13120
   macro avg       0.65      0.53      0.56     13120
weighted avg       0.67      0.65      0.65     13120


===confusion_matrix===

[[298   0   1 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  0   0  30 ...   0   0   0]
 ...
 [  0   0   0 ...  10   2   0]
 [  0   0   0 ...   0  17   2]
 [  0   0   0 ...   0   4  59]]

===multilabel confusion matrix===

[[[12565   154]
  [  103   298]]

 [[13100     0]
  [   12     8]]

 [[13021    17]
  [   52    30]]

 [[13104     0]
  [   15     1]]

 [[13047    11]
  [   55     7]]

 [[12817    26]
  [  168   109]]

 [[13077     7]
  [    9    27]]

 [[13095     0]
  [   25     0]]

 [[13046     1]
  [   47    26]]

 [[13080    11]
  [   19    10]]

 [[12922    42]
  [   57    99]]

 [[12881    71]
  [   99    69]]

 [[13015    22]
  [   58    25]]

 [[13058     8]
  [   47     7]]

 [[13062    27]
  [   23     8]]

 [[13047    20]
  [   31    22]]

 [[13012    13]
  [   53    42]]

 [[12143    93]
  [  211   673]]

 [[13016    57]
  [   14    33]]

 [[12270    68]
  [  392   390]]

 [[12260   268]
  [  124   468]]

 [[12645    90]
  [  119   266]]

 [[12972    20]
  [   25   103]]

 [[10739   494]
  [  385  1502]]

 [[12931    21]
  [   73    95]]

 [[11010   815]
  [  444   851]]

 [[12418   321]
  [  148   233]]

 [[13106     0]
  [    5     9]]

 [[12134   218]
  [  393   375]]

 [[12522   226]
  [  220   152]]

 [[12345   144]
  [  175   456]]

 [[13101     9]
  [    8     2]]

 [[12420   384]
  [  147   169]]

 [[12520   195]
  [  193   212]]

 [[12982    42]
  [   38    58]]

 [[13094     0]
  [   26     0]]

 [[13040    14]
  [   47    19]]

 [[13098     0]
  [   15     7]]

 [[12969    30]
  [   45    76]]

 [[13001     6]
  [   36    77]]

 [[12874    38]
  [   59   149]]

 [[12802   124]
  [   61   133]]

 [[13066     8]
  [   31    15]]

 [[12563   126]
  [   22   409]]

 [[13043    11]
  [   15    51]]

 [[12441   190]
  [   96   393]]

 [[13038    20]
  [   27    35]]

 [[12800    57]
  [   37   226]]

 [[13065     5]
  [   21    29]]

 [[13080     9]
  [    9    22]]

 [[13102     2]
  [    6    10]]

 [[13092     7]
  [    4    17]]

 [[13031    16]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.6526
MCC	0.6318
log_loss	1.4042
f1 score weighted	0.6502
f1 score macro	0.5594
f1 score micro	0.6526
roc_auc ovr	0.9544
roc_auc ovo	0.9528
precision	0.6743
recall	0.6526

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2e881b47f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2e881b4640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2e881b47c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2e881b4550>, 'x_test': array([[13, 12, 12, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 20,  8, ...,  0,  0,  0],
       ...,
       [12, 12, 11, ..., 16,  9, 20],
       [13,  6, 12, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.67      0.78      0.72       401
         1.0       0.00      0.00      0.00        20
         2.0       0.84      0.20      0.32        82
         3.0       0.00      0.00      0.00        15
         4.0       0.50      0.05      0.09        62
         5.0       0.76      0.48      0.59       278
         6.0       1.00      0.33      0.50        36
         7.0       1.00      0.04      0.08        25
         8.0       0.72      0.49      0.59        73
         9.0       0.81      0.45      0.58        29
        10.0       0.77      0.69      0.73       156
        11.0       0.41      0.45      0.43       168
        12.0       0.72      0.25      0.38        83
        13.0       0.50      0.09      0.16        54
        14.0       0.62      0.32      0.43        31
        15.0       0.50      0.11      0.18        53
        16.0       0.68      0.57      0.62        95
        17.0       0.66      0.84      0.74       884
        18.0       0.68      0.68      0.68        47
        19.0       0.61      0.64      0.63       781
        20.0       0.67      0.68      0.67       592
        21.0       0.67      0.73      0.70       385
        22.0       0.89      0.64      0.74       129
        23.0       0.64      0.84      0.73      1887
        24.0       0.73      0.64      0.68       168
        25.0       0.63      0.58      0.61      1295
        26.0       0.75      0.28      0.40       381
        27.0       0.83      0.38      0.53        13
        28.0       0.64      0.51      0.57       769
        29.0       0.35      0.42      0.38       372
        30.0       0.69      0.77      0.73       631
        31.0       0.00      0.00      0.00        11
        32.0       0.33      0.49      0.40       316
        33.0       0.46      0.58      0.51       405
        34.0       0.79      0.35      0.48        95
        35.0       0.00      0.00      0.00        25
        36.0       0.85      0.17      0.28        66
        37.0       0.88      0.64      0.74        22
        38.0       0.49      0.65      0.56       121
        39.0       0.66      0.80      0.72       113
        40.0       0.77      0.58      0.66       208
        41.0       0.79      0.52      0.62       194
        42.0       0.58      0.41      0.48        46
        43.0       0.90      0.81      0.85       431
        44.0       0.95      0.59      0.73        66
        45.0       0.74      0.73      0.74       489
        46.0       0.83      0.63      0.72        62
        47.0       0.79      0.86      0.82       263
        48.0       0.85      0.46      0.60        50
        49.0       0.54      0.68      0.60        31
        50.0       0.50      0.62      0.56        16
        51.0       0.60      0.55      0.57        22
        52.0       0.77      0.67      0.72        73

    accuracy                           0.64     13120
   macro avg       0.64      0.49      0.52     13120
weighted avg       0.66      0.64      0.63     13120


===confusion_matrix===

[[312   0   0 ...   0   0   0]
 [  0   0   0 ...   0   0   0]
 [  0   0  16 ...   0   0   0]
 ...
 [  0   0   0 ...  10   0   1]
 [  0   0   0 ...   2  12   3]
 [  0   0   0 ...   3   5  49]]

===multilabel confusion matrix===

[[[12568   151]
  [   89   312]]

 [[13100     0]
  [   20     0]]

 [[13035     3]
  [   66    16]]

 [[13105     0]
  [   15     0]]

 [[13055     3]
  [   59     3]]

 [[12801    41]
  [  145   133]]

 [[13084     0]
  [   24    12]]

 [[13095     0]
  [   24     1]]

 [[13033    14]
  [   37    36]]

 [[13088     3]
  [   16    13]]

 [[12932    32]
  [   49   107]]

 [[12843   109]
  [   92    76]]

 [[13029     8]
  [   62    21]]

 [[13061     5]
  [   49     5]]

 [[13083     6]
  [   21    10]]

 [[13061     6]
  [   47     6]]

 [[12999    26]
  [   41    54]]

 [[11861   375]
  [  140   744]]

 [[13058    15]
  [   15    32]]

 [[12022   317]
  [  279   502]]

 [[12329   199]
  [  190   402]]

 [[12595   140]
  [  105   280]]

 [[12981    10]
  [   47    82]]

 [[10334   899]
  [  293  1594]]

 [[12913    39]
  [   61   107]]

 [[11391   434]
  [  540   755]]

 [[12704    35]
  [  276   105]]

 [[13106     1]
  [    8     5]]

 [[12133   218]
  [  375   394]]

 [[12456   292]
  [  216   156]]

 [[12270   219]
  [  147   484]]

 [[13109     0]
  [   11     0]]

 [[12498   306]
  [  162   154]]

 [[12440   275]
  [  170   235]]

 [[13016     9]
  [   62    33]]

 [[13095     0]
  [   25     0]]

 [[13052     2]
  [   55    11]]

 [[13096     2]
  [    8    14]]

 [[12916    83]
  [   42    79]]

 [[12960    47]
  [   23    90]]

 [[12877    35]
  [   88   120]]

 [[12899    27]
  [   94   100]]

 [[13060    14]
  [   27    19]]

 [[12649    40]
  [   80   351]]

 [[13052     2]
  [   27    39]]

 [[12504   127]
  [  131   358]]

 [[13050     8]
  [   23    39]]

 [[12798    59]
  [   38   225]]

 [[13066     4]
  [   27    23]]

 [[13071    18]
  [   10    21]]

 [[13094    10]
  [    6    10]]

 [[13090     8]
  [   10    12]]

 [[13032    15]
  [   24    49]]]

===scores report===
metrics	scores
Accuracy	0.6425
MCC	0.6197
log_loss	1.4216
f1 score weighted	0.6317
f1 score macro	0.5189
f1 score micro	0.6425
roc_auc ovr	0.9535
roc_auc ovo	0.9487
precision	0.6557
recall	0.6425

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2e881b47f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2e881b4640>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2e881b47c0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2e881b4550>, 'x_test': array([[13, 17, 12, ...,  0,  0,  0],
       [13, 12,  3, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       ...,
       [ 8, 20,  4, ...,  0,  0,  0],
       [20,  6, 15, ...,  4,  2,  3],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.71      0.77      0.74       402
         1.0       1.00      0.21      0.35        19
         2.0       0.83      0.24      0.38        82
         3.0       0.00      0.00      0.00        16
         4.0       0.00      0.00      0.00        62
         5.0       0.54      0.48      0.51       278
         6.0       0.83      0.42      0.56        36
         7.0       1.00      0.08      0.14        26
         8.0       0.34      0.48      0.40        73
         9.0       0.38      0.60      0.46        30
        10.0       0.79      0.58      0.67       156
        11.0       0.35      0.57      0.43       169
        12.0       0.85      0.20      0.33        83
        13.0       0.00      0.00      0.00        53
        14.0       1.00      0.03      0.06        31
        15.0       0.83      0.10      0.17        52
        16.0       0.52      0.46      0.49        95
        17.0       0.67      0.84      0.75       885
        18.0       0.94      0.35      0.52        48
        19.0       0.77      0.57      0.66       781
        20.0       0.88      0.53      0.66       592
        21.0       0.35      0.82      0.49       384
        22.0       0.94      0.57      0.71       128
        23.0       0.48      0.87      0.62      1887
        24.0       0.58      0.65      0.61       168
        25.0       0.69      0.43      0.53      1295
        26.0       0.79      0.40      0.54       381
        27.0       1.00      0.50      0.67        14
        28.0       0.70      0.42      0.53       769
        29.0       0.49      0.37      0.42       372
        30.0       0.48      0.77      0.59       630
        31.0       0.00      0.00      0.00        11
        32.0       0.50      0.33      0.40       316
        33.0       0.85      0.46      0.59       405
        34.0       0.64      0.45      0.53        95
        35.0       0.00      0.00      0.00        25
        36.0       0.30      0.17      0.22        65
        37.0       0.93      0.59      0.72        22
        38.0       0.85      0.43      0.57       121
        39.0       0.69      0.70      0.69       113
        40.0       0.87      0.62      0.73       208
        41.0       0.69      0.56      0.62       194
        42.0       0.93      0.28      0.43        47
        43.0       0.94      0.76      0.84       431
        44.0       0.98      0.70      0.81        66
        45.0       0.82      0.68      0.74       488
        46.0       0.95      0.63      0.76        63
        47.0       0.80      0.76      0.78       263
        48.0       0.70      0.43      0.53        49
        49.0       0.41      0.63      0.50        30
        50.0       0.86      0.80      0.83        15
        51.0       0.67      0.55      0.60        22
        52.0       0.67      0.49      0.57        73

    accuracy                           0.60     13119
   macro avg       0.66      0.46      0.50     13119
weighted avg       0.66      0.60      0.60     13119


===confusion_matrix===

[[311   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  1   0  20 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   2  12   3]
 [  0   0   0 ...   0   4  36]]

===multilabel confusion matrix===

[[[12589   128]
  [   91   311]]

 [[13100     0]
  [   15     4]]

 [[13033     4]
  [   62    20]]

 [[13103     0]
  [   16     0]]

 [[13057     0]
  [   62     0]]

 [[12728   113]
  [  144   134]]

 [[13080     3]
  [   21    15]]

 [[13093     0]
  [   24     2]]

 [[12978    68]
  [   38    35]]

 [[13059    30]
  [   12    18]]

 [[12939    24]
  [   65    91]]

 [[12771   179]
  [   73    96]]

 [[13033     3]
  [   66    17]]

 [[13064     2]
  [   53     0]]

 [[13088     0]
  [   30     1]]

 [[13066     1]
  [   47     5]]

 [[12983    41]
  [   51    44]]

 [[11872   362]
  [  139   746]]

 [[13070     1]
  [   31    17]]

 [[12207   131]
  [  333   448]]

 [[12484    43]
  [  279   313]]

 [[12154   581]
  [   70   314]]

 [[12986     5]
  [   55    73]]

 [[ 9431  1801]
  [  241  1646]]

 [[12872    79]
  [   59   109]]

 [[11569   255]
  [  733   562]]

 [[12698    40]
  [  227   154]]

 [[13105     0]
  [    7     7]]

 [[12212   138]
  [  444   325]]

 [[12603   144]
  [  236   136]]

 [[11970   519]
  [  144   486]]

 [[13108     0]
  [   11     0]]

 [[12697   106]
  [  212   104]]

 [[12682    32]
  [  220   185]]

 [[13000    24]
  [   52    43]]

 [[13094     0]
  [   25     0]]

 [[13028    26]
  [   54    11]]

 [[13096     1]
  [    9    13]]

 [[12989     9]
  [   69    52]]

 [[12970    36]
  [   34    79]]

 [[12892    19]
  [   78   130]]

 [[12876    49]
  [   85   109]]

 [[13071     1]
  [   34    13]]

 [[12668    20]
  [  105   326]]

 [[13052     1]
  [   20    46]]

 [[12558    73]
  [  156   332]]

 [[13054     2]
  [   23    40]]

 [[12805    51]
  [   63   200]]

 [[13061     9]
  [   28    21]]

 [[13062    27]
  [   11    19]]

 [[13102     2]
  [    3    12]]

 [[13091     6]
  [   10    12]]

 [[13028    18]
  [   37    36]]]

===scores report===
metrics	scores
Accuracy	0.6031
MCC	0.5804
log_loss	1.6200
f1 score weighted	0.5952
f1 score macro	0.4988
f1 score micro	0.6031
roc_auc ovr	0.9490
roc_auc ovo	0.9471
precision	0.6592
recall	0.6031

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6316310975609756	0.6092313369044635	1.460101859225801	0.6245685209628032	0.5153915681086844	0.6316310975609756	0.9503615471662743	0.9482734869750618	0.647496225933679	0.6316310975609756
1	0.6497713414634146	0.6283317748933062	1.4079447087382508	0.6444600917128561	0.5456698639222707	0.6497713414634146	0.9536442695450393	0.9517450655363009	0.6704283425433073	0.6497713414634146
2	0.6525914634146341	0.6318378741905718	1.404220270143753	0.6501732964651937	0.5593711187019867	0.6525914634146341	0.9544036797994626	0.9527684885863159	0.674342597275467	0.6525914634146341
3	0.6424542682926829	0.6196957582429113	1.421600719151051	0.6316801226641787	0.5189424104980688	0.6424542682926829	0.9534520176788858	0.9487469746794954	0.6556596138530696	0.6424542682926829
4	0.6030947480753106	0.5804062149900547	1.6199582382213071	0.5951517967591564	0.49881675963333233	0.6030947480753106	0.9489700835949939	0.9471054966012389	0.6592155601361874	0.6030947480753106
mean	0.6359085837614036	0.6139005918442615	1.4627651590960324	0.6292067657128376	0.5276383441728686	0.6359085837614036	0.9521663195569312	0.9497279024756825	0.661428467948342	0.6359085837614036
std	0.01793535732145101	0.018478443215264533	0.0810482007288655	0.019285388693300917	0.0218558514160458	0.01793535732145101	0.0021126412089829726	0.0021572513562121078	0.009798535452970403	0.01793535732145101

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 38304.9752 secs

