/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_post_pre_bilstm_attentio_cv_only_enz_emb_5_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4924634820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4924634670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4924634850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4924634580>, 'x_test': array([[13, 13,  2, ...,  0,  0,  0],
       [13,  4, 12, ...,  0,  0,  0],
       [13, 16,  8, ...,  0,  0,  0],
       ...,
       [13,  1, 20, ...,  0,  0,  0],
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.65      0.72      0.69       402
         1.0       0.60      0.16      0.25        19
         2.0       0.38      0.04      0.07        82
         3.0       0.00      0.00      0.00        16
         4.0       0.50      0.03      0.06        62
         5.0       0.56      0.42      0.48       277
         6.0       0.49      0.56      0.52        36
         7.0       0.00      0.00      0.00        26
         8.0       1.00      0.15      0.27        72
         9.0       0.39      0.53      0.45        30
        10.0       0.66      0.66      0.66       156
        11.0       0.51      0.25      0.33       168
        12.0       0.59      0.33      0.42        83
        13.0       0.00      0.00      0.00        53
        14.0       0.27      0.29      0.28        31
        15.0       0.33      0.06      0.10        52
        16.0       0.47      0.54      0.50        94
        17.0       0.83      0.78      0.81       885
        18.0       0.38      0.23      0.29        48
        19.0       0.61      0.64      0.63       781
        20.0       0.70      0.74      0.72       591
        21.0       0.61      0.69      0.64       385
        22.0       0.44      0.84      0.58       128
        23.0       0.87      0.71      0.78      1888
        24.0       0.84      0.57      0.68       169
        25.0       0.43      0.67      0.52      1296
        26.0       0.35      0.65      0.45       381
        27.0       0.83      0.36      0.50        14
        28.0       0.62      0.37      0.46       769
        29.0       0.28      0.31      0.29       372
        30.0       0.83      0.65      0.73       631
        31.0       0.00      0.00      0.00        11
        32.0       0.31      0.46      0.37       316
        33.0       0.51      0.50      0.50       405
        34.0       0.53      0.43      0.47        96
        35.0       0.00      0.00      0.00        26
        36.0       1.00      0.06      0.12        65
        37.0       0.65      0.62      0.63        21
        38.0       0.66      0.52      0.58       121
        39.0       0.74      0.56      0.64       114
        40.0       0.56      0.71      0.62       207
        41.0       0.74      0.52      0.61       194
        42.0       1.00      0.04      0.08        47
        43.0       0.85      0.86      0.86       431
        44.0       0.86      0.66      0.75        67
        45.0       0.64      0.78      0.70       488
        46.0       0.90      0.45      0.60        62
        47.0       0.64      0.84      0.73       264
        48.0       0.76      0.51      0.61        49
        49.0       0.60      0.30      0.40        30
        50.0       0.55      0.40      0.46        15
        51.0       1.00      0.29      0.44        21
        52.0       0.56      0.86      0.68        73

    accuracy                           0.61     13120
   macro avg       0.57      0.44      0.45     13120
weighted avg       0.64      0.61      0.61     13120


===confusion_matrix===

[[290   0   0 ...   0   0   0]
 [  0   3   0 ...   0   0   0]
 [  0   0   3 ...   0   0   0]
 ...
 [  0   0   0 ...   6   0   7]
 [  0   0   0 ...   1   6  11]
 [  0   0   0 ...   0   0  63]]

===multilabel confusion matrix===

[[[12565   153]
  [  112   290]]

 [[13099     2]
  [   16     3]]

 [[13033     5]
  [   79     3]]

 [[13104     0]
  [   16     0]]

 [[13056     2]
  [   60     2]]

 [[12752    91]
  [  160   117]]

 [[13063    21]
  [   16    20]]

 [[13094     0]
  [   26     0]]

 [[13048     0]
  [   61    11]]

 [[13065    25]
  [   14    16]]

 [[12912    52]
  [   53   103]]

 [[12911    41]
  [  126    42]]

 [[13018    19]
  [   56    27]]

 [[13066     1]
  [   53     0]]

 [[13065    24]
  [   22     9]]

 [[13062     6]
  [   49     3]]

 [[12968    58]
  [   43    51]]

 [[12095   140]
  [  194   691]]

 [[13054    18]
  [   37    11]]

 [[12017   322]
  [  279   502]]

 [[12344   185]
  [  153   438]]

 [[12562   173]
  [  120   265]]

 [[12857   135]
  [   21   107]]

 [[11026   206]
  [  556  1332]]

 [[12933    18]
  [   72    97]]

 [[10675  1149]
  [  426   870]]

 [[12279   460]
  [  134   247]]

 [[13105     1]
  [    9     5]]

 [[12181   170]
  [  486   283]]

 [[12453   295]
  [  258   114]]

 [[12406    83]
  [  220   411]]

 [[13109     0]
  [   11     0]]

 [[12479   325]
  [  172   144]]

 [[12519   196]
  [  203   202]]

 [[12988    36]
  [   55    41]]

 [[13094     0]
  [   26     0]]

 [[13055     0]
  [   61     4]]

 [[13092     7]
  [    8    13]]

 [[12967    32]
  [   58    63]]

 [[12983    23]
  [   50    64]]

 [[12798   115]
  [   61   146]]

 [[12890    36]
  [   93   101]]

 [[13073     0]
  [   45     2]]

 [[12622    67]
  [   59   372]]

 [[13046     7]
  [   23    44]]

 [[12418   214]
  [  107   381]]

 [[13055     3]
  [   34    28]]

 [[12728   128]
  [   41   223]]

 [[13063     8]
  [   24    25]]

 [[13084     6]
  [   21     9]]

 [[13100     5]
  [    9     6]]

 [[13099     0]
  [   15     6]]

 [[12997    50]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.6103
MCC	0.5884
log_loss	1.5242
f1 score weighted	0.6053
f1 score macro	0.4532
f1 score micro	0.6103
roc_auc ovr	0.9423
roc_auc ovo	0.9401
precision	0.6412
recall	0.6103

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4924634820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4924634670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4924634850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4924634580>, 'x_test': array([[13, 16,  7, ...,  0,  0,  0],
       [13, 16, 12, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [12, 20, 14, ...,  9, 15, 11],
       [ 3, 16, 15, ..., 11, 19,  1],
       [13,  4, 11, ...,  0,  0,  0]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.71      0.72       402
         1.0       0.00      0.00      0.00        19
         2.0       0.71      0.06      0.11        81
         3.0       0.00      0.00      0.00        16
         4.0       0.86      0.10      0.17        62
         5.0       0.56      0.49      0.52       277
         6.0       0.95      0.56      0.70        36
         7.0       0.00      0.00      0.00        26
         8.0       0.68      0.29      0.40        73
         9.0       0.54      0.48      0.51        29
        10.0       0.76      0.65      0.70       156
        11.0       0.49      0.37      0.42       168
        12.0       0.49      0.27      0.34        83
        13.0       0.00      0.00      0.00        53
        14.0       0.50      0.16      0.24        32
        15.0       0.52      0.25      0.34        52
        16.0       0.71      0.31      0.43        95
        17.0       0.57      0.86      0.69       884
        18.0       0.92      0.25      0.39        48
        19.0       0.52      0.64      0.57       782
        20.0       0.48      0.79      0.60       591
        21.0       0.60      0.69      0.64       385
        22.0       0.72      0.73      0.72       128
        23.0       0.71      0.80      0.75      1888
        24.0       0.79      0.59      0.68       169
        25.0       0.49      0.59      0.53      1295
        26.0       0.56      0.45      0.50       381
        27.0       1.00      0.57      0.73        14
        28.0       0.65      0.42      0.51       769
        29.0       0.49      0.21      0.29       371
        30.0       0.65      0.73      0.69       631
        31.0       0.00      0.00      0.00        11
        32.0       0.36      0.49      0.41       316
        33.0       0.59      0.44      0.50       405
        34.0       0.67      0.39      0.49        96
        35.0       0.00      0.00      0.00        26
        36.0       1.00      0.15      0.27        65
        37.0       1.00      0.50      0.67        22
        38.0       0.69      0.50      0.58       121
        39.0       0.91      0.57      0.70       113
        40.0       0.70      0.65      0.68       208
        41.0       0.78      0.43      0.55       193
        42.0       0.88      0.15      0.26        46
        43.0       0.86      0.90      0.88       431
        44.0       0.88      0.70      0.78        66
        45.0       0.78      0.69      0.73       489
        46.0       0.89      0.55      0.68        62
        47.0       0.77      0.80      0.78       264
        48.0       0.80      0.49      0.61        49
        49.0       0.68      0.48      0.57        31
        50.0       0.73      0.69      0.71        16
        51.0       0.75      0.71      0.73        21
        52.0       0.64      0.85      0.73        73

    accuracy                           0.62     13120
   macro avg       0.62      0.46      0.49     13120
weighted avg       0.63      0.62      0.60     13120


===confusion_matrix===

[[286   0   1 ...   0   0   0]
 [  0   0   0 ...   0   0   0]
 [  0   0   5 ...   0   0   0]
 ...
 [  0   0   0 ...  11   1   2]
 [  0   0   0 ...   1  15   4]
 [  0   0   0 ...   0   3  62]]

===multilabel confusion matrix===

[[[12609   109]
  [  116   286]]

 [[13101     0]
  [   19     0]]

 [[13037     2]
  [   76     5]]

 [[13104     0]
  [   16     0]]

 [[13057     1]
  [   56     6]]

 [[12734   109]
  [  141   136]]

 [[13083     1]
  [   16    20]]

 [[13094     0]
  [   26     0]]

 [[13037    10]
  [   52    21]]

 [[13079    12]
  [   15    14]]

 [[12932    32]
  [   55   101]]

 [[12888    64]
  [  106    62]]

 [[13014    23]
  [   61    22]]

 [[13067     0]
  [   53     0]]

 [[13083     5]
  [   27     5]]

 [[13056    12]
  [   39    13]]

 [[13013    12]
  [   66    29]]

 [[11674   562]
  [  124   760]]

 [[13071     1]
  [   36    12]]

 [[11881   457]
  [  285   497]]

 [[12026   503]
  [  122   469]]

 [[12557   178]
  [  119   266]]

 [[12956    36]
  [   35    93]]

 [[10624   608]
  [  386  1502]]

 [[12924    27]
  [   69   100]]

 [[11031   794]
  [  537   758]]

 [[12605   134]
  [  209   172]]

 [[13106     0]
  [    6     8]]

 [[12179   172]
  [  448   321]]

 [[12667    82]
  [  293    78]]

 [[12239   250]
  [  169   462]]

 [[13109     0]
  [   11     0]]

 [[12527   277]
  [  161   155]]

 [[12594   121]
  [  228   177]]

 [[13006    18]
  [   59    37]]

 [[13094     0]
  [   26     0]]

 [[13055     0]
  [   55    10]]

 [[13098     0]
  [   11    11]]

 [[12971    28]
  [   60    61]]

 [[13001     6]
  [   49    64]]

 [[12855    57]
  [   72   136]]

 [[12903    24]
  [  110    83]]

 [[13073     1]
  [   39     7]]

 [[12627    62]
  [   41   390]]

 [[13048     6]
  [   20    46]]

 [[12537    94]
  [  151   338]]

 [[13054     4]
  [   28    34]]

 [[12792    64]
  [   53   211]]

 [[13065     6]
  [   25    24]]

 [[13082     7]
  [   16    15]]

 [[13100     4]
  [    5    11]]

 [[13094     5]
  [    6    15]]

 [[13012    35]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.6178
MCC	0.5934
log_loss	1.4824
f1 score weighted	0.6032
f1 score macro	0.4948
f1 score micro	0.6178
roc_auc ovr	0.9449
roc_auc ovo	0.9410
precision	0.6279
recall	0.6178

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4924634820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4924634670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4924634850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4924634580>, 'x_test': array([[13,  7,  1, ...,  0,  0,  0],
       [13,  1,  1, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       ...,
       [17, 19, 16, ...,  6, 14,  4],
       [20, 20, 20, ...,  1,  7,  1],
       [17, 12, 15, ...,  3,  9, 11]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.31      0.80      0.45       401
         1.0       0.00      0.00      0.00        20
         2.0       0.37      0.37      0.37        82
         3.0       0.00      0.00      0.00        16
         4.0       0.00      0.00      0.00        62
         5.0       0.55      0.41      0.47       277
         6.0       1.00      0.42      0.59        36
         7.0       0.00      0.00      0.00        25
         8.0       0.18      0.33      0.23        73
         9.0       0.42      0.45      0.43        29
        10.0       0.50      0.60      0.55       156
        11.0       0.20      0.46      0.28       168
        12.0       0.35      0.07      0.12        83
        13.0       0.00      0.00      0.00        54
        14.0       0.47      0.26      0.33        31
        15.0       0.88      0.13      0.23        53
        16.0       0.81      0.22      0.35        95
        17.0       0.96      0.72      0.82       884
        18.0       0.62      0.45      0.52        47
        19.0       0.60      0.46      0.52       782
        20.0       0.77      0.68      0.72       592
        21.0       0.25      0.82      0.38       385
        22.0       0.72      0.80      0.76       128
        23.0       0.58      0.83      0.68      1887
        24.0       0.43      0.67      0.53       168
        25.0       0.85      0.34      0.49      1295
        26.0       0.80      0.29      0.43       381
        27.0       1.00      0.14      0.25        14
        28.0       0.75      0.33      0.46       768
        29.0       0.54      0.18      0.27       372
        30.0       0.79      0.66      0.72       631
        31.0       0.00      0.00      0.00        10
        32.0       0.44      0.25      0.32       316
        33.0       0.32      0.48      0.38       405
        34.0       0.38      0.52      0.44        96
        35.0       0.00      0.00      0.00        26
        36.0       0.61      0.17      0.26        66
        37.0       0.91      0.45      0.61        22
        38.0       0.94      0.40      0.56       121
        39.0       0.80      0.69      0.74       113
        40.0       0.85      0.64      0.73       208
        41.0       0.66      0.36      0.46       194
        42.0       0.89      0.35      0.50        46
        43.0       0.96      0.80      0.87       431
        44.0       0.82      0.68      0.74        66
        45.0       0.47      0.84      0.60       489
        46.0       0.90      0.45      0.60        62
        47.0       0.81      0.79      0.80       263
        48.0       0.90      0.52      0.66        50
        49.0       0.45      0.84      0.58        31
        50.0       0.67      0.50      0.57        16
        51.0       0.79      0.52      0.63        21
        52.0       0.69      0.73      0.71        73

    accuracy                           0.56     13120
   macro avg       0.56      0.43      0.45     13120
weighted avg       0.65      0.56      0.56     13120


===confusion_matrix===

[[320   0   0 ...   0   0   0]
 [  2   0   1 ...   0   0   0]
 [  9   0  30 ...   0   0   0]
 ...
 [  0   0   0 ...   8   3   2]
 [  0   0   0 ...   2  11   5]
 [  0   0   0 ...   0   0  53]]

===multilabel confusion matrix===

[[[12020   699]
  [   81   320]]

 [[13100     0]
  [   20     0]]

 [[12987    51]
  [   52    30]]

 [[13104     0]
  [   16     0]]

 [[13058     0]
  [   62     0]]

 [[12750    93]
  [  163   114]]

 [[13084     0]
  [   21    15]]

 [[13095     0]
  [   25     0]]

 [[12937   110]
  [   49    24]]

 [[13073    18]
  [   16    13]]

 [[12870    94]
  [   62    94]]

 [[12643   309]
  [   91    77]]

 [[13026    11]
  [   77     6]]

 [[13066     0]
  [   54     0]]

 [[13080     9]
  [   23     8]]

 [[13066     1]
  [   46     7]]

 [[13020     5]
  [   74    21]]

 [[12208    28]
  [  250   634]]

 [[13060    13]
  [   26    21]]

 [[12103   235]
  [  426   356]]

 [[12406   122]
  [  189   403]]

 [[11775   960]
  [   69   316]]

 [[12951    41]
  [   25   103]]

 [[10089  1144]
  [  319  1568]]

 [[12803   149]
  [   55   113]]

 [[11747    78]
  [  854   441]]

 [[12712    27]
  [  270   111]]

 [[13106     0]
  [   12     2]]

 [[12267    85]
  [  516   252]]

 [[12692    56]
  [  306    66]]

 [[12379   110]
  [  213   418]]

 [[13110     0]
  [   10     0]]

 [[12703   101]
  [  236    80]]

 [[12305   410]
  [  211   194]]

 [[12944    80]
  [   46    50]]

 [[13094     0]
  [   26     0]]

 [[13047     7]
  [   55    11]]

 [[13097     1]
  [   12    10]]

 [[12996     3]
  [   73    48]]

 [[12988    19]
  [   35    78]]

 [[12889    23]
  [   74   134]]

 [[12890    36]
  [  125    69]]

 [[13072     2]
  [   30    16]]

 [[12673    16]
  [   86   345]]

 [[13044    10]
  [   21    45]]

 [[12170   461]
  [   77   412]]

 [[13055     3]
  [   34    28]]

 [[12807    50]
  [   56   207]]

 [[13067     3]
  [   24    26]]

 [[13057    32]
  [    5    26]]

 [[13100     4]
  [    8     8]]

 [[13096     3]
  [   10    11]]

 [[13023    24]
  [   20    53]]]

===scores report===
metrics	scores
Accuracy	0.5628
MCC	0.5411
log_loss	1.7323
f1 score weighted	0.5587
f1 score macro	0.4474
f1 score micro	0.5628
roc_auc ovr	0.9422
roc_auc ovo	0.9398
precision	0.6490
recall	0.5628

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4924634820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4924634670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4924634850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4924634580>, 'x_test': array([[13, 12, 12, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 20,  8, ...,  0,  0,  0],
       ...,
       [12, 12, 11, ..., 16,  9, 20],
       [13,  6, 12, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.60      0.67      0.63       401
         1.0       0.00      0.00      0.00        20
         2.0       0.20      0.12      0.15        82
         3.0       0.00      0.00      0.00        15
         4.0       1.00      0.02      0.03        62
         5.0       0.65      0.42      0.51       278
         6.0       0.69      0.56      0.62        36
         7.0       1.00      0.04      0.08        25
         8.0       0.81      0.18      0.29        73
         9.0       0.37      0.45      0.41        29
        10.0       0.96      0.31      0.47       156
        11.0       0.33      0.33      0.33       168
        12.0       0.83      0.18      0.30        83
        13.0       0.00      0.00      0.00        54
        14.0       0.36      0.42      0.39        31
        15.0       0.00      0.00      0.00        53
        16.0       0.51      0.31      0.38        95
        17.0       0.96      0.64      0.77       884
        18.0       0.74      0.55      0.63        47
        19.0       0.56      0.60      0.58       781
        20.0       0.75      0.61      0.67       592
        21.0       0.65      0.68      0.66       385
        22.0       0.89      0.63      0.74       129
        23.0       0.74      0.79      0.76      1887
        24.0       0.72      0.63      0.67       168
        25.0       0.45      0.66      0.54      1295
        26.0       0.51      0.39      0.45       381
        27.0       1.00      0.15      0.27        13
        28.0       0.47      0.58      0.52       769
        29.0       0.37      0.17      0.24       372
        30.0       0.80      0.68      0.73       631
        31.0       0.00      0.00      0.00        11
        32.0       0.33      0.31      0.32       316
        33.0       0.21      0.74      0.33       405
        34.0       0.54      0.34      0.42        95
        35.0       0.00      0.00      0.00        25
        36.0       0.33      0.02      0.03        66
        37.0       1.00      0.09      0.17        22
        38.0       0.83      0.32      0.46       121
        39.0       0.91      0.55      0.69       113
        40.0       0.55      0.64      0.59       208
        41.0       0.95      0.27      0.42       194
        42.0       0.91      0.22      0.35        46
        43.0       0.99      0.62      0.76       431
        44.0       0.73      0.62      0.67        66
        45.0       0.86      0.69      0.76       489
        46.0       0.83      0.55      0.66        62
        47.0       0.58      0.88      0.70       263
        48.0       0.45      0.54      0.49        50
        49.0       0.46      0.19      0.27        31
        50.0       0.00      0.00      0.00        16
        51.0       0.75      0.41      0.53        22
        52.0       0.54      0.84      0.65        73

    accuracy                           0.58     13120
   macro avg       0.58      0.39      0.42     13120
weighted avg       0.64      0.58      0.58     13120


===confusion_matrix===

[[267   0   0 ...   0   0   0]
 [  0   0   0 ...   0   0   0]
 [  0   0  10 ...   0   0   0]
 ...
 [  0   0   0 ...   0   0   7]
 [  0   0   0 ...   0   9   7]
 [  0   0   0 ...   0   2  61]]

===multilabel confusion matrix===

[[[12543   176]
  [  134   267]]

 [[13100     0]
  [   20     0]]

 [[12999    39]
  [   72    10]]

 [[13105     0]
  [   15     0]]

 [[13058     0]
  [   61     1]]

 [[12778    64]
  [  160   118]]

 [[13075     9]
  [   16    20]]

 [[13095     0]
  [   24     1]]

 [[13044     3]
  [   60    13]]

 [[13069    22]
  [   16    13]]

 [[12962     2]
  [  108    48]]

 [[12840   112]
  [  112    56]]

 [[13034     3]
  [   68    15]]

 [[13066     0]
  [   54     0]]

 [[13066    23]
  [   18    13]]

 [[13064     3]
  [   53     0]]

 [[12997    28]
  [   66    29]]

 [[12212    24]
  [  319   565]]

 [[13064     9]
  [   21    26]]

 [[11968   371]
  [  312   469]]

 [[12405   123]
  [  228   364]]

 [[12594   141]
  [  123   262]]

 [[12981    10]
  [   48    81]]

 [[10705   528]
  [  405  1482]]

 [[12911    41]
  [   62   106]]

 [[10773  1052]
  [  435   860]]

 [[12597   142]
  [  231   150]]

 [[13107     0]
  [   11     2]]

 [[11845   506]
  [  324   445]]

 [[12641   107]
  [  308    64]]

 [[12381   108]
  [  202   429]]

 [[13109     0]
  [   11     0]]

 [[12606   198]
  [  218    98]]

 [[11583  1132]
  [  106   299]]

 [[12998    27]
  [   63    32]]

 [[13095     0]
  [   25     0]]

 [[13052     2]
  [   65     1]]

 [[13098     0]
  [   20     2]]

 [[12991     8]
  [   82    39]]

 [[13001     6]
  [   51    62]]

 [[12804   108]
  [   75   133]]

 [[12923     3]
  [  142    52]]

 [[13073     1]
  [   36    10]]

 [[12685     4]
  [  165   266]]

 [[13039    15]
  [   25    41]]

 [[12576    55]
  [  154   335]]

 [[13051     7]
  [   28    34]]

 [[12692   165]
  [   32   231]]

 [[13037    33]
  [   23    27]]

 [[13082     7]
  [   25     6]]

 [[13104     0]
  [   16     0]]

 [[13095     3]
  [   13     9]]

 [[12994    53]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.5829
MCC	0.5585
log_loss	1.6483
f1 score weighted	0.5823
f1 score macro	0.4166
f1 score micro	0.5829
roc_auc ovr	0.9405
roc_auc ovo	0.9371
precision	0.6408
recall	0.5829

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4924634820>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4924634670>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4924634850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4924634580>, 'x_test': array([[13, 17, 12, ...,  0,  0,  0],
       [13, 12,  3, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       ...,
       [ 8, 20,  4, ...,  0,  0,  0],
       [20,  6, 15, ...,  4,  2,  3],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.55      0.76      0.64       402
         1.0       0.90      0.47      0.62        19
         2.0       0.46      0.07      0.13        82
         3.0       0.00      0.00      0.00        16
         4.0       1.00      0.02      0.03        62
         5.0       0.75      0.43      0.54       278
         6.0       0.48      0.67      0.56        36
         7.0       0.00      0.00      0.00        26
         8.0       0.76      0.47      0.58        73
         9.0       0.47      0.60      0.53        30
        10.0       0.57      0.65      0.61       156
        11.0       0.64      0.27      0.38       169
        12.0       0.49      0.41      0.45        83
        13.0       0.00      0.00      0.00        53
        14.0       0.43      0.10      0.16        31
        15.0       0.00      0.00      0.00        52
        16.0       0.40      0.27      0.33        95
        17.0       0.65      0.83      0.73       885
        18.0       0.91      0.44      0.59        48
        19.0       0.67      0.61      0.64       781
        20.0       0.81      0.61      0.70       592
        21.0       0.90      0.53      0.67       384
        22.0       0.69      0.67      0.68       128
        23.0       0.66      0.80      0.72      1887
        24.0       0.92      0.49      0.64       168
        25.0       0.58      0.56      0.57      1295
        26.0       0.36      0.59      0.45       381
        27.0       1.00      0.43      0.60        14
        28.0       0.41      0.66      0.51       769
        29.0       0.27      0.56      0.37       372
        30.0       0.88      0.57      0.70       630
        31.0       0.60      0.27      0.37        11
        32.0       0.45      0.23      0.31       316
        33.0       0.83      0.41      0.55       405
        34.0       0.84      0.28      0.43        95
        35.0       0.00      0.00      0.00        25
        36.0       0.00      0.00      0.00        65
        37.0       1.00      0.14      0.24        22
        38.0       0.56      0.48      0.52       121
        39.0       0.58      0.78      0.67       113
        40.0       0.84      0.67      0.75       208
        41.0       0.64      0.55      0.59       194
        42.0       0.57      0.26      0.35        47
        43.0       0.64      0.94      0.77       431
        44.0       1.00      0.74      0.85        66
        45.0       0.85      0.65      0.74       488
        46.0       0.94      0.54      0.69        63
        47.0       0.88      0.75      0.81       263
        48.0       0.74      0.47      0.58        49
        49.0       0.56      0.47      0.51        30
        50.0       1.00      0.27      0.42        15
        51.0       0.79      0.68      0.73        22
        52.0       0.62      0.88      0.72        73

    accuracy                           0.61     13119
   macro avg       0.61      0.45      0.48     13119
weighted avg       0.65      0.61      0.60     13119


===confusion_matrix===

[[307   0   0 ...   0   0   0]
 [  0   9   0 ...   0   0   0]
 [  2   0   6 ...   0   0   0]
 ...
 [  0   0   0 ...   4   0   4]
 [  0   0   0 ...   0  15   6]
 [  0   0   0 ...   0   4  64]]

===multilabel confusion matrix===

[[[12468   249]
  [   95   307]]

 [[13099     1]
  [   10     9]]

 [[13030     7]
  [   76     6]]

 [[13103     0]
  [   16     0]]

 [[13057     0]
  [   61     1]]

 [[12801    40]
  [  159   119]]

 [[13057    26]
  [   12    24]]

 [[13093     0]
  [   26     0]]

 [[13035    11]
  [   39    34]]

 [[13069    20]
  [   12    18]]

 [[12886    77]
  [   54   102]]

 [[12925    25]
  [  124    45]]

 [[13001    35]
  [   49    34]]

 [[13066     0]
  [   53     0]]

 [[13084     4]
  [   28     3]]

 [[13067     0]
  [   52     0]]

 [[12985    39]
  [   69    26]]

 [[11832   402]
  [  147   738]]

 [[13069     2]
  [   27    21]]

 [[12104   234]
  [  306   475]]

 [[12443    84]
  [  229   363]]

 [[12712    23]
  [  180   204]]

 [[12953    38]
  [   42    86]]

 [[10437   795]
  [  377  1510]]

 [[12944     7]
  [   86    82]]

 [[11295   529]
  [  576   719]]

 [[12339   399]
  [  157   224]]

 [[13105     0]
  [    8     6]]

 [[11626   724]
  [  262   507]]

 [[12190   557]
  [  163   209]]

 [[12440    49]
  [  268   362]]

 [[13106     2]
  [    8     3]]

 [[12712    91]
  [  242    74]]

 [[12680    34]
  [  239   166]]

 [[13019     5]
  [   68    27]]

 [[13094     0]
  [   25     0]]

 [[13054     0]
  [   65     0]]

 [[13097     0]
  [   19     3]]

 [[12952    46]
  [   63    58]]

 [[12943    63]
  [   25    88]]

 [[12884    27]
  [   68   140]]

 [[12865    60]
  [   87   107]]

 [[13063     9]
  [   35    12]]

 [[12462   226]
  [   24   407]]

 [[13053     0]
  [   17    49]]

 [[12577    54]
  [  173   315]]

 [[13054     2]
  [   29    34]]

 [[12829    27]
  [   67   196]]

 [[13062     8]
  [   26    23]]

 [[13078    11]
  [   16    14]]

 [[13104     0]
  [   11     4]]

 [[13093     4]
  [    7    15]]

 [[13006    40]
  [    9    64]]]

===scores report===
metrics	scores
Accuracy	0.6123
MCC	0.5884
log_loss	1.4734
f1 score weighted	0.6042
f1 score macro	0.4843
f1 score micro	0.6123
roc_auc ovr	0.9483
roc_auc ovo	0.9457
precision	0.6453
recall	0.6123

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6102896341463414	0.5883827167109587	1.5241538289775205	0.6053458112272168	0.45321054022436313	0.6102896341463414	0.9423055894897977	0.9401259765413262	0.6411568347624872	0.6102896341463414
1	0.6177591463414634	0.5934283223620554	1.4824038085462599	0.603245060335723	0.49478261771481674	0.6177591463414634	0.9449008271633136	0.9410026578344214	0.6278570622455107	0.6177591463414634
2	0.5628048780487804	0.5411183369521241	1.732342866890565	0.5587186885846913	0.44739042874345636	0.5628048780487804	0.9421537068991633	0.9397749718584097	0.6489550017076645	0.5628048780487804
3	0.5828506097560976	0.5584909836952434	1.6483398422892983	0.5822525816700503	0.416613445275349	0.5828506097560976	0.9404568852022438	0.9370853111655185	0.6407620534896129	0.5828506097560976
4	0.6123180120436009	0.5883556973677389	1.4733688812677346	0.6041838255277335	0.484303531085053	0.6123180120436009	0.9483093316580204	0.9457211476948224	0.645276105000797	0.6123180120436009
mean	0.5972044560672567	0.5739552114176242	1.5721218455942758	0.590749193469083	0.4592601126086076	0.5972044560672567	0.9436252680825078	0.9407420130188996	0.6408014114412144	0.5972044560672567
std	0.021030932569211618	0.02055301251960615	0.10157003833670832	0.018154023975359725	0.027875602715390718	0.021030932569211618	0.0027390946142258	0.0028123248686145234	0.007130048633372608	0.021030932569211618

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 30658.3903 secs

