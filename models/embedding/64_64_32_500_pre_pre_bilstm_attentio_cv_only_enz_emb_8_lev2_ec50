/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_emb_8_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f69d4040d00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f69d4040b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f69d4040bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f69d4040d90>, 'x_test': array([[ 0,  0,  0, ...,  3,  7, 11],
       [ 0,  0,  0, ...,  5, 14,  1],
       [ 0,  0,  0, ...,  3,  0,  8],
       ...,
       [ 0,  0,  0, ..., 18,  9, 12],
       [ 9,  5,  5, ...,  7, 15, 10],
       [ 0,  0,  0, ..., 10, 12,  1]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.74      0.76       402
         1.0       0.80      0.21      0.33        19
         2.0       0.63      0.32      0.42        82
         3.0       1.00      0.06      0.12        16
         4.0       0.29      0.15      0.19        62
         5.0       0.75      0.43      0.55       277
         6.0       0.75      0.58      0.66        36
         7.0       0.29      0.08      0.12        26
         8.0       0.71      0.42      0.53        72
         9.0       0.87      0.67      0.75        30
        10.0       0.84      0.62      0.71       156
        11.0       0.40      0.49      0.44       168
        12.0       0.90      0.42      0.57        83
        13.0       0.78      0.13      0.23        53
        14.0       0.58      0.45      0.51        31
        15.0       0.85      0.42      0.56        52
        16.0       0.75      0.59      0.66        94
        17.0       0.81      0.83      0.82       885
        18.0       1.00      0.42      0.59        48
        19.0       0.76      0.67      0.71       781
        20.0       0.53      0.81      0.64       591
        21.0       0.54      0.76      0.63       385
        22.0       0.79      0.73      0.76       128
        23.0       0.88      0.72      0.79      1888
        24.0       0.75      0.63      0.69       169
        25.0       0.60      0.64      0.62      1296
        26.0       0.52      0.55      0.53       381
        27.0       0.83      0.36      0.50        14
        28.0       0.45      0.67      0.54       769
        29.0       0.52      0.39      0.44       372
        30.0       0.87      0.70      0.77       631
        31.0       1.00      0.09      0.17        11
        32.0       0.38      0.57      0.46       316
        33.0       0.51      0.70      0.59       405
        34.0       0.53      0.53      0.53        96
        35.0       0.33      0.04      0.07        26
        36.0       0.85      0.45      0.59        65
        37.0       0.88      0.67      0.76        21
        38.0       0.81      0.58      0.68       121
        39.0       0.82      0.61      0.70       114
        40.0       0.50      0.80      0.61       207
        41.0       0.92      0.52      0.66       194
        42.0       0.94      0.32      0.48        47
        43.0       0.93      0.86      0.89       431
        44.0       0.97      0.58      0.73        67
        45.0       0.69      0.82      0.75       488
        46.0       0.88      0.61      0.72        62
        47.0       0.84      0.88      0.86       264
        48.0       0.77      0.69      0.73        49
        49.0       0.92      0.37      0.52        30
        50.0       0.89      0.53      0.67        15
        51.0       0.92      0.57      0.71        21
        52.0       0.66      0.84      0.73        73

    accuracy                           0.67     13120
   macro avg       0.73      0.53      0.58     13120
weighted avg       0.70      0.67      0.67     13120


===confusion_matrix===

[[298   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   0]
 [  0   0  26 ...   0   0   0]
 ...
 [  0   0   0 ...   8   1   6]
 [  0   0   0 ...   0  12   4]
 [  0   0   0 ...   0   0  61]]

===multilabel confusion matrix===

[[[12636    82]
  [  104   298]]

 [[13100     1]
  [   15     4]]

 [[13023    15]
  [   56    26]]

 [[13104     0]
  [   15     1]]

 [[13036    22]
  [   53     9]]

 [[12804    39]
  [  158   119]]

 [[13077     7]
  [   15    21]]

 [[13089     5]
  [   24     2]]

 [[13036    12]
  [   42    30]]

 [[13087     3]
  [   10    20]]

 [[12945    19]
  [   59    97]]

 [[12827   125]
  [   86    82]]

 [[13033     4]
  [   48    35]]

 [[13065     2]
  [   46     7]]

 [[13079    10]
  [   17    14]]

 [[13064     4]
  [   30    22]]

 [[13008    18]
  [   39    55]]

 [[12062   173]
  [  154   731]]

 [[13072     0]
  [   28    20]]

 [[12170   169]
  [  256   525]]

 [[12112   417]
  [  113   478]]

 [[12482   253]
  [   93   292]]

 [[12968    24]
  [   35    93]]

 [[11042   190]
  [  538  1350]]

 [[12915    36]
  [   62   107]]

 [[11259   565]
  [  461   835]]

 [[12542   197]
  [  171   210]]

 [[13105     1]
  [    9     5]]

 [[11721   630]
  [  250   519]]

 [[12612   136]
  [  227   145]]

 [[12425    64]
  [  192   439]]

 [[13109     0]
  [   10     1]]

 [[12512   292]
  [  136   180]]

 [[12449   266]
  [  123   282]]

 [[12979    45]
  [   45    51]]

 [[13092     2]
  [   25     1]]

 [[13050     5]
  [   36    29]]

 [[13097     2]
  [    7    14]]

 [[12983    16]
  [   51    70]]

 [[12991    15]
  [   44    70]]

 [[12747   166]
  [   42   165]]

 [[12917     9]
  [   93   101]]

 [[13072     1]
  [   32    15]]

 [[12661    28]
  [   60   371]]

 [[13052     1]
  [   28    39]]

 [[12452   180]
  [   88   400]]

 [[13053     5]
  [   24    38]]

 [[12813    43]
  [   32   232]]

 [[13061    10]
  [   15    34]]

 [[13089     1]
  [   19    11]]

 [[13104     1]
  [    7     8]]

 [[13098     1]
  [    9    12]]

 [[13015    32]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.6689
MCC	0.6504
log_loss	1.4344
f1 score weighted	0.6706
f1 score macro	0.5804
f1 score micro	0.6689
roc_auc ovr	0.9574
roc_auc ovo	0.9530
precision	0.7036
recall	0.6689

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f69d4040d00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f69d4040b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f69d4040bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f69d4040d90>, 'x_test': array([[ 0,  0,  0, ...,  0,  5,  0],
       [ 0,  0,  0, ...,  5, 17, 10],
       [ 0,  0,  0, ...,  9,  4,  5],
       ...,
       [11, 19, 13, ...,  8, 14, 10],
       [ 2, 15, 14, ..., 10, 18,  0],
       [ 0,  0,  0, ..., 10, 13,  6]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.74      0.72       402
         1.0       0.57      0.42      0.48        19
         2.0       0.41      0.53      0.46        81
         3.0       0.00      0.00      0.00        16
         4.0       0.30      0.40      0.35        62
         5.0       0.53      0.66      0.59       277
         6.0       0.74      0.72      0.73        36
         7.0       0.33      0.12      0.17        26
         8.0       0.69      0.47      0.56        73
         9.0       0.69      0.38      0.49        29
        10.0       0.77      0.66      0.71       156
        11.0       0.65      0.42      0.51       168
        12.0       0.47      0.57      0.52        83
        13.0       0.70      0.13      0.22        53
        14.0       0.45      0.53      0.49        32
        15.0       0.44      0.44      0.44        52
        16.0       0.64      0.52      0.57        95
        17.0       0.86      0.83      0.84       884
        18.0       0.77      0.62      0.69        48
        19.0       0.65      0.73      0.69       782
        20.0       0.74      0.72      0.73       591
        21.0       0.79      0.79      0.79       385
        22.0       0.77      0.75      0.76       128
        23.0       0.84      0.78      0.81      1888
        24.0       0.71      0.69      0.70       169
        25.0       0.62      0.68      0.65      1295
        26.0       0.55      0.58      0.57       381
        27.0       0.88      0.50      0.64        14
        28.0       0.65      0.58      0.61       769
        29.0       0.39      0.63      0.48       371
        30.0       0.77      0.76      0.76       631
        31.0       0.45      0.45      0.45        11
        32.0       0.47      0.56      0.51       316
        33.0       0.68      0.61      0.64       405
        34.0       0.62      0.55      0.58        96
        35.0       0.00      0.00      0.00        26
        36.0       0.66      0.29      0.40        65
        37.0       0.94      0.77      0.85        22
        38.0       0.82      0.62      0.70       121
        39.0       0.69      0.74      0.71       113
        40.0       0.88      0.74      0.80       208
        41.0       0.75      0.66      0.70       193
        42.0       0.73      0.52      0.61        46
        43.0       0.90      0.92      0.91       431
        44.0       0.82      0.68      0.74        66
        45.0       0.78      0.78      0.78       489
        46.0       0.90      0.74      0.81        62
        47.0       0.75      0.88      0.81       264
        48.0       0.83      0.51      0.63        49
        49.0       0.87      0.84      0.85        31
        50.0       1.00      0.94      0.97        16
        51.0       0.77      0.81      0.79        21
        52.0       0.72      0.85      0.78        73

    accuracy                           0.70     13120
   macro avg       0.66      0.60      0.62     13120
weighted avg       0.71      0.70      0.70     13120


===confusion_matrix===

[[298   0   2 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  1   0  43 ...   0   0   0]
 ...
 [  0   0   0 ...  15   0   1]
 [  0   0   0 ...   0  17   4]
 [  0   0   0 ...   0   3  62]]

===multilabel confusion matrix===

[[[12591   127]
  [  104   298]]

 [[13095     6]
  [   11     8]]

 [[12976    63]
  [   38    43]]

 [[13100     4]
  [   16     0]]

 [[13001    57]
  [   37    25]]

 [[12680   163]
  [   95   182]]

 [[13075     9]
  [   10    26]]

 [[13088     6]
  [   23     3]]

 [[13032    15]
  [   39    34]]

 [[13086     5]
  [   18    11]]

 [[12934    30]
  [   53   103]]

 [[12913    39]
  [   97    71]]

 [[12985    52]
  [   36    47]]

 [[13064     3]
  [   46     7]]

 [[13067    21]
  [   15    17]]

 [[13039    29]
  [   29    23]]

 [[12997    28]
  [   46    49]]

 [[12116   120]
  [  152   732]]

 [[13063     9]
  [   18    30]]

 [[12025   313]
  [  211   571]]

 [[12377   152]
  [  168   423]]

 [[12654    81]
  [   80   305]]

 [[12964    28]
  [   32    96]]

 [[10961   271]
  [  414  1474]]

 [[12904    47]
  [   53   116]]

 [[11284   541]
  [  415   880]]

 [[12561   178]
  [  160   221]]

 [[13105     1]
  [    7     7]]

 [[12108   243]
  [  321   448]]

 [[12378   371]
  [  136   235]]

 [[12346   143]
  [  154   477]]

 [[13103     6]
  [    6     5]]

 [[12606   198]
  [  140   176]]

 [[12598   117]
  [  158   247]]

 [[12991    33]
  [   43    53]]

 [[13093     1]
  [   26     0]]

 [[13045    10]
  [   46    19]]

 [[13097     1]
  [    5    17]]

 [[12982    17]
  [   46    75]]

 [[12969    38]
  [   29    84]]

 [[12890    22]
  [   54   154]]

 [[12884    43]
  [   66   127]]

 [[13065     9]
  [   22    24]]

 [[12644    45]
  [   33   398]]

 [[13044    10]
  [   21    45]]

 [[12526   105]
  [  107   382]]

 [[13053     5]
  [   16    46]]

 [[12779    77]
  [   33   231]]

 [[13066     5]
  [   24    25]]

 [[13085     4]
  [    5    26]]

 [[13104     0]
  [    1    15]]

 [[13094     5]
  [    4    17]]

 [[13023    24]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.7005
MCC	0.6829
log_loss	1.3003
f1 score weighted	0.7011
f1 score macro	0.6185
f1 score micro	0.7005
roc_auc ovr	0.9635
roc_auc ovo	0.9617
precision	0.7109
recall	0.7005

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f69d4040d00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f69d4040b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f69d4040bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f69d4040d90>, 'x_test': array([[ 0,  0,  0, ..., 15,  9, 11],
       [ 0,  0,  0, ..., 14,  0, 14],
       [ 0,  0,  0, ...,  7, 17,  5],
       ...,
       [16, 18, 15, ...,  5, 13,  3],
       [19, 19, 19, ...,  0,  6,  0],
       [16, 11, 14, ...,  2,  8, 10]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.67      0.73       401
         1.0       1.00      0.05      0.10        20
         2.0       0.26      0.24      0.25        82
         3.0       0.25      0.06      0.10        16
         4.0       0.25      0.24      0.24        62
         5.0       0.54      0.49      0.52       277
         6.0       0.64      0.69      0.67        36
         7.0       0.50      0.12      0.19        25
         8.0       0.69      0.37      0.48        73
         9.0       0.83      0.52      0.64        29
        10.0       0.69      0.65      0.67       156
        11.0       0.68      0.30      0.42       168
        12.0       0.35      0.60      0.44        83
        13.0       0.80      0.07      0.14        54
        14.0       0.39      0.35      0.37        31
        15.0       0.27      0.58      0.37        53
        16.0       0.53      0.62      0.57        95
        17.0       0.73      0.82      0.77       884
        18.0       0.92      0.51      0.66        47
        19.0       0.65      0.67      0.66       782
        20.0       0.84      0.67      0.75       592
        21.0       0.81      0.67      0.73       385
        22.0       0.84      0.80      0.82       128
        23.0       0.86      0.75      0.80      1887
        24.0       0.85      0.61      0.71       168
        25.0       0.55      0.71      0.62      1295
        26.0       0.45      0.61      0.52       381
        27.0       1.00      0.36      0.53        14
        28.0       0.61      0.49      0.54       768
        29.0       0.33      0.65      0.44       372
        30.0       0.78      0.74      0.76       631
        31.0       0.33      0.10      0.15        10
        32.0       0.46      0.57      0.51       316
        33.0       0.74      0.53      0.61       405
        34.0       0.68      0.48      0.56        96
        35.0       0.00      0.00      0.00        26
        36.0       0.83      0.53      0.65        66
        37.0       0.57      0.55      0.56        22
        38.0       0.74      0.64      0.69       121
        39.0       0.54      0.76      0.63       113
        40.0       0.74      0.71      0.72       208
        41.0       0.78      0.56      0.65       194
        42.0       0.51      0.54      0.53        46
        43.0       0.83      0.94      0.88       431
        44.0       0.88      0.68      0.77        66
        45.0       0.80      0.75      0.77       489
        46.0       0.93      0.60      0.73        62
        47.0       0.75      0.84      0.79       263
        48.0       0.91      0.58      0.71        50
        49.0       0.85      0.55      0.67        31
        50.0       0.75      0.94      0.83        16
        51.0       0.91      0.48      0.62        21
        52.0       0.62      0.92      0.74        73

    accuracy                           0.67     13120
   macro avg       0.66      0.55      0.57     13120
weighted avg       0.70      0.67      0.67     13120


===confusion_matrix===

[[269   0   0 ...   0   0   0]
 [  0   1   0 ...   0   0   0]
 [  0   0  20 ...   0   0   0]
 ...
 [  0   0   0 ...  15   0   1]
 [  0   0   0 ...   0  10  10]
 [  0   0   0 ...   1   0  67]]

===multilabel confusion matrix===

[[[12650    69]
  [  132   269]]

 [[13100     0]
  [   19     1]]

 [[12982    56]
  [   62    20]]

 [[13101     3]
  [   15     1]]

 [[13012    46]
  [   47    15]]

 [[12727   116]
  [  140   137]]

 [[13070    14]
  [   11    25]]

 [[13092     3]
  [   22     3]]

 [[13035    12]
  [   46    27]]

 [[13088     3]
  [   14    15]]

 [[12919    45]
  [   54   102]]

 [[12928    24]
  [  117    51]]

 [[12943    94]
  [   33    50]]

 [[13065     1]
  [   50     4]]

 [[13072    17]
  [   20    11]]

 [[12985    82]
  [   22    31]]

 [[12973    52]
  [   36    59]]

 [[11963   273]
  [  159   725]]

 [[13071     2]
  [   23    24]]

 [[12058   280]
  [  260   522]]

 [[12453    75]
  [  195   397]]

 [[12673    62]
  [  127   258]]

 [[12972    20]
  [   25   103]]

 [[10997   236]
  [  475  1412]]

 [[12934    18]
  [   65   103]]

 [[11066   759]
  [  372   923]]

 [[12458   281]
  [  147   234]]

 [[13106     0]
  [    9     5]]

 [[12113   239]
  [  395   373]]

 [[12252   496]
  [  130   242]]

 [[12357   132]
  [  161   470]]

 [[13108     2]
  [    9     1]]

 [[12590   214]
  [  136   180]]

 [[12639    76]
  [  192   213]]

 [[13002    22]
  [   50    46]]

 [[13086     8]
  [   26     0]]

 [[13047     7]
  [   31    35]]

 [[13089     9]
  [   10    12]]

 [[12971    28]
  [   43    78]]

 [[12935    72]
  [   27    86]]

 [[12860    52]
  [   61   147]]

 [[12896    30]
  [   85   109]]

 [[13050    24]
  [   21    25]]

 [[12606    83]
  [   28   403]]

 [[13048     6]
  [   21    45]]

 [[12537    94]
  [  123   366]]

 [[13055     3]
  [   25    37]]

 [[12784    73]
  [   42   221]]

 [[13067     3]
  [   21    29]]

 [[13086     3]
  [   14    17]]

 [[13099     5]
  [    1    15]]

 [[13098     1]
  [   11    10]]

 [[13006    41]
  [    6    67]]]

===scores report===
metrics	scores
Accuracy	0.6672
MCC	0.6483
log_loss	1.4126
f1 score weighted	0.6697
f1 score macro	0.5658
f1 score micro	0.6672
roc_auc ovr	0.9574
roc_auc ovo	0.9558
precision	0.6958
recall	0.6672

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f69d4040d00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f69d4040b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f69d4040bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f69d4040d90>, 'x_test': array([[ 0,  0,  0, ..., 11, 16,  4],
       [ 0,  0,  0, ...,  6, 17, 19],
       [ 0,  0,  0, ..., 11, 17, 14],
       ...,
       [11, 11, 10, ..., 15,  8, 19],
       [ 0,  0,  0, ...,  7,  1, 17],
       [10, 10,  1, ...,  0, 15,  0]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.64      0.68       401
         1.0       0.75      0.15      0.25        20
         2.0       0.60      0.46      0.52        82
         3.0       0.00      0.00      0.00        15
         4.0       0.27      0.13      0.17        62
         5.0       0.60      0.46      0.52       278
         6.0       0.88      0.39      0.54        36
         7.0       0.00      0.00      0.00        25
         8.0       0.73      0.44      0.55        73
         9.0       0.71      0.17      0.28        29
        10.0       0.69      0.69      0.69       156
        11.0       0.62      0.29      0.39       168
        12.0       0.64      0.49      0.56        83
        13.0       0.00      0.00      0.00        54
        14.0       0.67      0.26      0.37        31
        15.0       0.47      0.17      0.25        53
        16.0       0.60      0.46      0.52        95
        17.0       0.72      0.81      0.76       884
        18.0       0.86      0.51      0.64        47
        19.0       0.74      0.55      0.63       781
        20.0       0.76      0.65      0.70       592
        21.0       0.94      0.62      0.75       385
        22.0       0.82      0.70      0.75       129
        23.0       0.65      0.83      0.73      1887
        24.0       0.73      0.67      0.70       168
        25.0       0.51      0.71      0.60      1295
        26.0       0.64      0.46      0.53       381
        27.0       1.00      0.38      0.56        13
        28.0       0.73      0.48      0.58       769
        29.0       0.30      0.54      0.38       372
        30.0       0.67      0.78      0.72       631
        31.0       0.00      0.00      0.00        11
        32.0       0.37      0.45      0.40       316
        33.0       0.70      0.54      0.61       405
        34.0       0.73      0.47      0.57        95
        35.0       0.33      0.04      0.07        25
        36.0       0.84      0.32      0.46        66
        37.0       0.75      0.55      0.63        22
        38.0       0.77      0.45      0.57       121
        39.0       0.78      0.61      0.69       113
        40.0       0.87      0.68      0.76       208
        41.0       0.70      0.63      0.66       194
        42.0       0.64      0.30      0.41        46
        43.0       0.86      0.83      0.84       431
        44.0       0.90      0.68      0.78        66
        45.0       0.65      0.81      0.72       489
        46.0       0.78      0.65      0.71        62
        47.0       0.72      0.92      0.81       263
        48.0       1.00      0.42      0.59        50
        49.0       0.60      0.68      0.64        31
        50.0       0.71      0.75      0.73        16
        51.0       0.78      0.64      0.70        22
        52.0       0.67      0.81      0.73        73

    accuracy                           0.65     13120
   macro avg       0.64      0.49      0.54     13120
weighted avg       0.67      0.65      0.64     13120


===confusion_matrix===

[[255   0   0 ...   0   0   0]
 [  0   3   1 ...   0   0   0]
 [  0   0  38 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   1]
 [  0   0   0 ...   0  14   7]
 [  0   0   0 ...   3   3  59]]

===multilabel confusion matrix===

[[[12626    93]
  [  146   255]]

 [[13099     1]
  [   17     3]]

 [[13013    25]
  [   44    38]]

 [[13105     0]
  [   15     0]]

 [[13036    22]
  [   54     8]]

 [[12756    86]
  [  150   128]]

 [[13082     2]
  [   22    14]]

 [[13095     0]
  [   25     0]]

 [[13035    12]
  [   41    32]]

 [[13089     2]
  [   24     5]]

 [[12916    48]
  [   49   107]]

 [[12923    29]
  [  120    48]]

 [[13014    23]
  [   42    41]]

 [[13066     0]
  [   54     0]]

 [[13085     4]
  [   23     8]]

 [[13057    10]
  [   44     9]]

 [[12996    29]
  [   51    44]]

 [[11953   283]
  [  171   713]]

 [[13069     4]
  [   23    24]]

 [[12186   153]
  [  349   432]]

 [[12407   121]
  [  206   386]]

 [[12721    14]
  [  147   238]]

 [[12971    20]
  [   39    90]]

 [[10396   837]
  [  320  1567]]

 [[12911    41]
  [   56   112]]

 [[10949   876]
  [  372   923]]

 [[12640    99]
  [  207   174]]

 [[13107     0]
  [    8     5]]

 [[12212   139]
  [  399   370]]

 [[12271   477]
  [  170   202]]

 [[12250   239]
  [  139   492]]

 [[13109     0]
  [   11     0]]

 [[12564   240]
  [  175   141]]

 [[12622    93]
  [  186   219]]

 [[13008    17]
  [   50    45]]

 [[13093     2]
  [   24     1]]

 [[13050     4]
  [   45    21]]

 [[13094     4]
  [   10    12]]

 [[12983    16]
  [   66    55]]

 [[12988    19]
  [   44    69]]

 [[12891    21]
  [   67   141]]

 [[12873    53]
  [   72   122]]

 [[13066     8]
  [   32    14]]

 [[12629    60]
  [   72   359]]

 [[13049     5]
  [   21    45]]

 [[12415   216]
  [   91   398]]

 [[13047    11]
  [   22    40]]

 [[12765    92]
  [   22   241]]

 [[13070     0]
  [   29    21]]

 [[13075    14]
  [   10    21]]

 [[13099     5]
  [    4    12]]

 [[13094     4]
  [    8    14]]

 [[13018    29]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.6492
MCC	0.6269
log_loss	1.4571
f1 score weighted	0.6432
f1 score macro	0.5363
f1 score micro	0.6492
roc_auc ovr	0.9539
roc_auc ovo	0.9488
precision	0.6678
recall	0.6492

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f69d4040d00>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f69d4040b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f69d4040bb0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f69d4040d90>, 'x_test': array([[ 0,  0,  0, ...,  1, 19, 16],
       [ 0,  0,  0, ..., 13, 11,  1],
       [ 0,  0,  0, ...,  5, 12, 19],
       ...,
       [ 0,  0,  0, ..., 18, 15, 11],
       [19,  5, 14, ...,  3,  1,  2],
       [ 7, 14, 14, ...,  8, 16, 10]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.80      0.74       402
         1.0       0.82      0.47      0.60        19
         2.0       0.63      0.54      0.58        82
         3.0       0.00      0.00      0.00        16
         4.0       0.33      0.24      0.28        62
         5.0       0.48      0.67      0.56       278
         6.0       0.96      0.61      0.75        36
         7.0       0.00      0.00      0.00        26
         8.0       0.53      0.44      0.48        73
         9.0       0.67      0.60      0.63        30
        10.0       0.77      0.72      0.75       156
        11.0       0.54      0.59      0.56       169
        12.0       0.59      0.65      0.62        83
        13.0       0.29      0.04      0.07        53
        14.0       0.61      0.45      0.52        31
        15.0       0.58      0.37      0.45        52
        16.0       0.68      0.52      0.59        95
        17.0       0.81      0.83      0.82       885
        18.0       0.86      0.65      0.74        48
        19.0       0.65      0.73      0.69       781
        20.0       0.66      0.76      0.71       592
        21.0       0.76      0.77      0.76       384
        22.0       0.75      0.74      0.75       128
        23.0       0.81      0.78      0.80      1887
        24.0       0.69      0.68      0.69       168
        25.0       0.64      0.66      0.65      1295
        26.0       0.61      0.54      0.57       381
        27.0       0.75      0.21      0.33        14
        28.0       0.63      0.60      0.61       769
        29.0       0.47      0.47      0.47       372
        30.0       0.74      0.80      0.77       630
        31.0       0.40      0.18      0.25        11
        32.0       0.42      0.61      0.50       316
        33.0       0.72      0.60      0.65       405
        34.0       0.84      0.57      0.68        95
        35.0       0.25      0.04      0.07        25
        36.0       0.75      0.42      0.53        65
        37.0       0.84      0.73      0.78        22
        38.0       0.83      0.60      0.69       121
        39.0       0.91      0.74      0.82       113
        40.0       0.84      0.79      0.81       208
        41.0       0.84      0.66      0.74       194
        42.0       0.68      0.45      0.54        47
        43.0       0.81      0.89      0.85       431
        44.0       0.88      0.85      0.86        66
        45.0       0.82      0.78      0.80       488
        46.0       0.80      0.70      0.75        63
        47.0       0.76      0.83      0.80       263
        48.0       0.78      0.59      0.67        49
        49.0       0.63      0.63      0.63        30
        50.0       0.86      0.80      0.83        15
        51.0       0.81      0.77      0.79        22
        52.0       0.73      0.84      0.78        73

    accuracy                           0.70     13119
   macro avg       0.66      0.58      0.61     13119
weighted avg       0.70      0.70      0.70     13119


===confusion_matrix===

[[320   0   4 ...   0   0   0]
 [  0   9   0 ...   0   0   0]
 [  1   0  44 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   1  17   4]
 [  0   0   0 ...   0   2  61]]

===multilabel confusion matrix===

[[[12579   138]
  [   82   320]]

 [[13098     2]
  [   10     9]]

 [[13011    26]
  [   38    44]]

 [[13103     0]
  [   16     0]]

 [[13026    31]
  [   47    15]]

 [[12643   198]
  [   93   185]]

 [[13082     1]
  [   14    22]]

 [[13092     1]
  [   26     0]]

 [[13018    28]
  [   41    32]]

 [[13080     9]
  [   12    18]]

 [[12930    33]
  [   43   113]]

 [[12866    84]
  [   70    99]]

 [[12999    37]
  [   29    54]]

 [[13061     5]
  [   51     2]]

 [[13079     9]
  [   17    14]]

 [[13053    14]
  [   33    19]]

 [[13001    23]
  [   46    49]]

 [[12065   169]
  [  148   737]]

 [[13066     5]
  [   17    31]]

 [[12037   301]
  [  214   567]]

 [[12294   233]
  [  142   450]]

 [[12641    94]
  [   89   295]]

 [[12959    32]
  [   33    95]]

 [[10884   348]
  [  408  1479]]

 [[12900    51]
  [   53   115]]

 [[11347   477]
  [  435   860]]

 [[12604   134]
  [  174   207]]

 [[13104     1]
  [   11     3]]

 [[12078   272]
  [  308   461]]

 [[12548   199]
  [  197   175]]

 [[12313   176]
  [  124   506]]

 [[13105     3]
  [    9     2]]

 [[12535   268]
  [  123   193]]

 [[12621    93]
  [  163   242]]

 [[13014    10]
  [   41    54]]

 [[13091     3]
  [   24     1]]

 [[13045     9]
  [   38    27]]

 [[13094     3]
  [    6    16]]

 [[12983    15]
  [   49    72]]

 [[12998     8]
  [   29    84]]

 [[12880    31]
  [   44   164]]

 [[12901    24]
  [   65   129]]

 [[13062    10]
  [   26    21]]

 [[12599    89]
  [   46   385]]

 [[13045     8]
  [   10    56]]

 [[12547    84]
  [  107   381]]

 [[13045    11]
  [   19    44]]

 [[12788    68]
  [   44   219]]

 [[13062     8]
  [   20    29]]

 [[13078    11]
  [   11    19]]

 [[13102     2]
  [    3    12]]

 [[13093     4]
  [    5    17]]

 [[13024    22]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.7016
MCC	0.6837
log_loss	1.2875
f1 score weighted	0.6989
f1 score macro	0.6107
f1 score micro	0.7016
roc_auc ovr	0.9628
roc_auc ovo	0.9608
precision	0.7040
recall	0.7016

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6689024390243903	0.6504008389952981	1.434402682356131	0.6706272934962222	0.5804074789470275	0.6689024390243903	0.9574095846826713	0.9529584365846476	0.7035648847280059	0.6689024390243903
1	0.7004573170731707	0.6829413559613079	1.3002959438774966	0.7011249302945951	0.6184701149765519	0.7004573170731707	0.9634707765354263	0.9617239476942554	0.7108509988970049	0.7004573170731707
2	0.6672256097560976	0.6482548547266727	1.412602928523928	0.6696588398419857	0.5658498655192321	0.6672256097560976	0.9574435735674125	0.9558102281109213	0.6957742534073224	0.6672256097560976
3	0.6492378048780488	0.6268984930690713	1.4571064543765935	0.6431736859866475	0.536290435333804	0.6492378048780488	0.9539274354880841	0.9487942382892169	0.6677791136801066	0.6492378048780488
4	0.701577864166476	0.6837250346325476	1.2875381233199217	0.6988800505180343	0.6106896797628405	0.701577864166476	0.9628286056910969	0.9608081434581732	0.7039557442018506	0.701577864166476
mean	0.6774802069796367	0.6584441154769796	1.3783892264908144	0.6766929600274969	0.5823415149078912	0.6774802069796367	0.9590159951929383	0.9560189988274429	0.6963849989828581	0.6774802069796367
std	0.020420640606619845	0.021922049580266084	0.07050811350121328	0.021442952432191176	0.030017698506580728	0.020420640606619845	0.003614625291391388	0.004839217687928625	0.015078473265636558	0.020420640606619845

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 37403.4797 secs

