/home/amsequeira/enzymeClassification/models/embedding/64_64_32_500_post_terminals_bilstm_attentio_cv_only_enz_emb20_lev2_ec50_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f04d83b4850>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f04d83b46a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f04d83b4880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f04d83b45b0>, 'x_test': array([[13, 13,  2, ...,  0,  0,  0],
       [13,  4, 12, ...,  0,  0,  0],
       [13, 16,  8, ...,  0,  0,  0],
       ...,
       [13,  1, 20, ...,  0,  0,  0],
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.77      0.79       402
         1.0       1.00      0.42      0.59        19
         2.0       0.49      0.49      0.49        82
         3.0       0.33      0.06      0.11        16
         4.0       0.20      0.15      0.17        62
         5.0       0.62      0.52      0.56       277
         6.0       0.78      0.58      0.67        36
         7.0       0.40      0.08      0.13        26
         8.0       0.63      0.51      0.56        72
         9.0       0.81      0.57      0.67        30
        10.0       0.81      0.67      0.74       156
        11.0       0.51      0.42      0.46       168
        12.0       0.58      0.46      0.51        83
        13.0       0.28      0.15      0.20        53
        14.0       0.44      0.26      0.33        31
        15.0       0.66      0.40      0.50        52
        16.0       0.69      0.57      0.63        94
        17.0       0.86      0.81      0.84       885
        18.0       0.96      0.56      0.71        48
        19.0       0.61      0.71      0.66       781
        20.0       0.68      0.72      0.70       591
        21.0       0.75      0.70      0.73       385
        22.0       0.79      0.62      0.70       128
        23.0       0.71      0.82      0.76      1888
        24.0       0.80      0.64      0.71       169
        25.0       0.61      0.71      0.65      1296
        26.0       0.50      0.57      0.53       381
        27.0       0.83      0.36      0.50        14
        28.0       0.53      0.62      0.57       769
        29.0       0.42      0.41      0.42       372
        30.0       0.82      0.69      0.75       631
        31.0       1.00      0.18      0.31        11
        32.0       0.46      0.54      0.49       316
        33.0       0.62      0.57      0.59       405
        34.0       0.79      0.57      0.66        96
        35.0       0.11      0.04      0.06        26
        36.0       0.78      0.43      0.55        65
        37.0       0.86      0.57      0.69        21
        38.0       0.69      0.59      0.63       121
        39.0       0.83      0.56      0.67       114
        40.0       0.81      0.67      0.73       207
        41.0       0.71      0.61      0.66       194
        42.0       0.55      0.36      0.44        47
        43.0       0.87      0.83      0.85       431
        44.0       0.76      0.67      0.71        67
        45.0       0.81      0.75      0.78       488
        46.0       0.74      0.45      0.56        62
        47.0       0.91      0.89      0.90       264
        48.0       0.76      0.69      0.72        49
        49.0       0.56      0.73      0.64        30
        50.0       0.83      0.67      0.74        15
        51.0       0.57      0.38      0.46        21
        52.0       0.73      0.85      0.78        73

    accuracy                           0.68     13120
   macro avg       0.67      0.54      0.58     13120
weighted avg       0.69      0.68      0.68     13120


===confusion_matrix===

[[308   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  0   0  40 ...   0   0   0]
 ...
 [  0   0   0 ...  10   1   1]
 [  0   0   0 ...   1   8   6]
 [  0   0   0 ...   0   1  62]]

===multilabel confusion matrix===

[[[12644    74]
  [   94   308]]

 [[13101     0]
  [   11     8]]

 [[12997    41]
  [   42    40]]

 [[13102     2]
  [   15     1]]

 [[13021    37]
  [   53     9]]

 [[12756    87]
  [  134   143]]

 [[13078     6]
  [   15    21]]

 [[13091     3]
  [   24     2]]

 [[13026    22]
  [   35    37]]

 [[13086     4]
  [   13    17]]

 [[12940    24]
  [   51   105]]

 [[12883    69]
  [   97    71]]

 [[13010    27]
  [   45    38]]

 [[13046    21]
  [   45     8]]

 [[13079    10]
  [   23     8]]

 [[13057    11]
  [   31    21]]

 [[13002    24]
  [   40    54]]

 [[12120   115]
  [  168   717]]

 [[13071     1]
  [   21    27]]

 [[11986   353]
  [  228   553]]

 [[12332   197]
  [  167   424]]

 [[12646    89]
  [  114   271]]

 [[12971    21]
  [   48    80]]

 [[10597   635]
  [  336  1552]]

 [[12923    28]
  [   60   109]]

 [[11224   600]
  [  374   922]]

 [[12523   216]
  [  165   216]]

 [[13105     1]
  [    9     5]]

 [[11931   420]
  [  293   476]]

 [[12535   213]
  [  218   154]]

 [[12396    93]
  [  195   436]]

 [[13109     0]
  [    9     2]]

 [[12601   203]
  [  146   170]]

 [[12571   144]
  [  173   232]]

 [[13009    15]
  [   41    55]]

 [[13086     8]
  [   25     1]]

 [[13047     8]
  [   37    28]]

 [[13097     2]
  [    9    12]]

 [[12967    32]
  [   50    71]]

 [[12993    13]
  [   50    64]]

 [[12881    32]
  [   69   138]]

 [[12877    49]
  [   75   119]]

 [[13059    14]
  [   30    17]]

 [[12634    55]
  [   72   359]]

 [[13039    14]
  [   22    45]]

 [[12546    86]
  [  124   364]]

 [[13048    10]
  [   34    28]]

 [[12832    24]
  [   30   234]]

 [[13060    11]
  [   15    34]]

 [[13073    17]
  [    8    22]]

 [[13103     2]
  [    5    10]]

 [[13093     6]
  [   13     8]]

 [[13024    23]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.6790
MCC	0.6584
log_loss	1.6117
f1 score weighted	0.6770
f1 score macro	0.5839
f1 score micro	0.6790
roc_auc ovr	0.9563
roc_auc ovo	0.9521
precision	0.6855
recall	0.6790

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f04d83b4850>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f04d83b46a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f04d83b4880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f04d83b45b0>, 'x_test': array([[13, 16,  7, ...,  0,  0,  0],
       [13, 16, 12, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [12, 20, 14, ...,  9, 15, 11],
       [ 3, 16, 15, ..., 11, 19,  1],
       [13,  4, 11, ...,  0,  0,  0]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.77      0.71       402
         1.0       0.62      0.26      0.37        19
         2.0       0.65      0.43      0.52        81
         3.0       0.33      0.06      0.11        16
         4.0       0.40      0.34      0.37        62
         5.0       0.65      0.57      0.61       277
         6.0       0.81      0.69      0.75        36
         7.0       0.60      0.23      0.33        26
         8.0       0.61      0.48      0.54        73
         9.0       0.56      0.48      0.52        29
        10.0       0.92      0.61      0.73       156
        11.0       0.42      0.53      0.47       168
        12.0       0.72      0.49      0.59        83
        13.0       0.33      0.11      0.17        53
        14.0       0.56      0.28      0.38        32
        15.0       0.56      0.37      0.44        52
        16.0       0.65      0.56      0.60        95
        17.0       0.84      0.78      0.81       884
        18.0       0.70      0.44      0.54        48
        19.0       0.73      0.65      0.69       782
        20.0       0.74      0.64      0.69       591
        21.0       0.70      0.71      0.70       385
        22.0       0.78      0.73      0.76       128
        23.0       0.74      0.82      0.78      1888
        24.0       0.83      0.66      0.74       169
        25.0       0.58      0.70      0.63      1295
        26.0       0.50      0.54      0.52       381
        27.0       1.00      0.57      0.73        14
        28.0       0.58      0.59      0.59       769
        29.0       0.53      0.47      0.50       371
        30.0       0.80      0.67      0.73       631
        31.0       0.50      0.27      0.35        11
        32.0       0.40      0.57      0.47       316
        33.0       0.51      0.64      0.57       405
        34.0       0.57      0.56      0.57        96
        35.0       0.00      0.00      0.00        26
        36.0       0.82      0.43      0.57        65
        37.0       1.00      0.59      0.74        22
        38.0       0.60      0.50      0.55       121
        39.0       0.74      0.70      0.72       113
        40.0       0.75      0.69      0.72       208
        41.0       0.59      0.66      0.62       193
        42.0       0.64      0.35      0.45        46
        43.0       0.92      0.87      0.89       431
        44.0       0.73      0.61      0.66        66
        45.0       0.77      0.81      0.79       489
        46.0       0.88      0.68      0.76        62
        47.0       0.87      0.79      0.83       264
        48.0       0.74      0.47      0.58        49
        49.0       0.83      0.61      0.70        31
        50.0       0.93      0.81      0.87        16
        51.0       0.64      0.67      0.65        21
        52.0       0.66      0.84      0.73        73

    accuracy                           0.68     13120
   macro avg       0.66      0.55      0.59     13120
weighted avg       0.69      0.68      0.68     13120


===confusion_matrix===

[[311   0   0 ...   0   0   0]
 [  0   5   1 ...   0   0   0]
 [  0   0  35 ...   0   0   0]
 ...
 [  0   0   0 ...  13   2   0]
 [  0   0   0 ...   0  14   7]
 [  0   0   0 ...   0   2  61]]

===multilabel confusion matrix===

[[[12561   157]
  [   91   311]]

 [[13098     3]
  [   14     5]]

 [[13020    19]
  [   46    35]]

 [[13102     2]
  [   15     1]]

 [[13027    31]
  [   41    21]]

 [[12758    85]
  [  118   159]]

 [[13078     6]
  [   11    25]]

 [[13090     4]
  [   20     6]]

 [[13025    22]
  [   38    35]]

 [[13080    11]
  [   15    14]]

 [[12956     8]
  [   61    95]]

 [[12831   121]
  [   79    89]]

 [[13021    16]
  [   42    41]]

 [[13055    12]
  [   47     6]]

 [[13081     7]
  [   23     9]]

 [[13053    15]
  [   33    19]]

 [[12997    28]
  [   42    53]]

 [[12103   133]
  [  192   692]]

 [[13063     9]
  [   27    21]]

 [[12148   190]
  [  271   511]]

 [[12397   132]
  [  213   378]]

 [[12619   116]
  [  113   272]]

 [[12966    26]
  [   34    94]]

 [[10685   547]
  [  337  1551]]

 [[12929    22]
  [   58   111]]

 [[11158   667]
  [  385   910]]

 [[12530   209]
  [  176   205]]

 [[13106     0]
  [    6     8]]

 [[12025   326]
  [  314   455]]

 [[12590   159]
  [  195   176]]

 [[12384   105]
  [  207   424]]

 [[13106     3]
  [    8     3]]

 [[12531   273]
  [  135   181]]

 [[12466   249]
  [  147   258]]

 [[12984    40]
  [   42    54]]

 [[13093     1]
  [   26     0]]

 [[13049     6]
  [   37    28]]

 [[13098     0]
  [    9    13]]

 [[12959    40]
  [   60    61]]

 [[12979    28]
  [   34    79]]

 [[12865    47]
  [   64   144]]

 [[12837    90]
  [   65   128]]

 [[13065     9]
  [   30    16]]

 [[12656    33]
  [   58   373]]

 [[13039    15]
  [   26    40]]

 [[12510   121]
  [   94   395]]

 [[13052     6]
  [   20    42]]

 [[12824    32]
  [   55   209]]

 [[13063     8]
  [   26    23]]

 [[13085     4]
  [   12    19]]

 [[13103     1]
  [    3    13]]

 [[13091     8]
  [    7    14]]

 [[13015    32]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.6773
MCC	0.6572
log_loss	1.6223
f1 score weighted	0.6763
f1 score macro	0.5922
f1 score micro	0.6773
roc_auc ovr	0.9570
roc_auc ovo	0.9541
precision	0.6862
recall	0.6773

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f04d83b4850>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f04d83b46a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f04d83b4880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f04d83b45b0>, 'x_test': array([[13,  7,  1, ...,  0,  0,  0],
       [13,  1,  1, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       ...,
       [17, 19, 16, ...,  6, 14,  4],
       [20, 20, 20, ...,  1,  7,  1],
       [17, 12, 15, ...,  3,  9, 11]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.65      0.68      0.67       401
         1.0       0.80      0.40      0.53        20
         2.0       0.68      0.46      0.55        82
         3.0       0.00      0.00      0.00        16
         4.0       0.35      0.21      0.26        62
         5.0       0.57      0.52      0.54       277
         6.0       0.74      0.69      0.71        36
         7.0       0.43      0.24      0.31        25
         8.0       0.56      0.40      0.46        73
         9.0       0.50      0.41      0.45        29
        10.0       0.76      0.60      0.67       156
        11.0       0.45      0.37      0.41       168
        12.0       0.45      0.47      0.46        83
        13.0       0.29      0.19      0.22        54
        14.0       0.44      0.26      0.33        31
        15.0       0.49      0.38      0.43        53
        16.0       0.58      0.52      0.54        95
        17.0       0.80      0.78      0.79       884
        18.0       0.71      0.57      0.64        47
        19.0       0.63      0.66      0.65       782
        20.0       0.68      0.73      0.70       592
        21.0       0.73      0.68      0.70       385
        22.0       0.74      0.76      0.75       128
        23.0       0.75      0.79      0.77      1887
        24.0       0.69      0.65      0.67       168
        25.0       0.54      0.68      0.60      1295
        26.0       0.52      0.54      0.53       381
        27.0       0.67      0.29      0.40        14
        28.0       0.56      0.57      0.56       768
        29.0       0.47      0.47      0.47       372
        30.0       0.78      0.71      0.75       631
        31.0       0.00      0.00      0.00        10
        32.0       0.49      0.53      0.51       316
        33.0       0.57      0.60      0.59       405
        34.0       0.64      0.56      0.60        96
        35.0       0.60      0.12      0.19        26
        36.0       0.57      0.35      0.43        66
        37.0       0.77      0.45      0.57        22
        38.0       0.57      0.57      0.57       121
        39.0       0.70      0.73      0.72       113
        40.0       0.76      0.72      0.74       208
        41.0       0.67      0.61      0.64       194
        42.0       0.60      0.39      0.47        46
        43.0       0.85      0.84      0.85       431
        44.0       0.71      0.70      0.70        66
        45.0       0.89      0.75      0.81       489
        46.0       0.82      0.53      0.65        62
        47.0       0.83      0.82      0.82       263
        48.0       0.59      0.64      0.62        50
        49.0       0.83      0.48      0.61        31
        50.0       0.78      0.88      0.82        16
        51.0       0.80      0.57      0.67        21
        52.0       0.65      0.81      0.72        73

    accuracy                           0.66     13120
   macro avg       0.62      0.53      0.56     13120
weighted avg       0.67      0.66      0.66     13120


===confusion_matrix===

[[273   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  0   0  38 ...   0   0   0]
 ...
 [  0   0   0 ...  14   0   2]
 [  0   0   0 ...   0  12   8]
 [  0   0   0 ...   0   1  59]]

===multilabel confusion matrix===

[[[12574   145]
  [  128   273]]

 [[13098     2]
  [   12     8]]

 [[13020    18]
  [   44    38]]

 [[13103     1]
  [   16     0]]

 [[13034    24]
  [   49    13]]

 [[12736   107]
  [  134   143]]

 [[13075     9]
  [   11    25]]

 [[13087     8]
  [   19     6]]

 [[13024    23]
  [   44    29]]

 [[13079    12]
  [   17    12]]

 [[12934    30]
  [   63    93]]

 [[12877    75]
  [  106    62]]

 [[12989    48]
  [   44    39]]

 [[13041    25]
  [   44    10]]

 [[13079    10]
  [   23     8]]

 [[13046    21]
  [   33    20]]

 [[12989    36]
  [   46    49]]

 [[12064   172]
  [  191   693]]

 [[13062    11]
  [   20    27]]

 [[12037   301]
  [  263   519]]

 [[12325   203]
  [  162   430]]

 [[12639    96]
  [  124   261]]

 [[12958    34]
  [   31    97]]

 [[10737   496]
  [  396  1491]]

 [[12902    50]
  [   58   110]]

 [[11074   751]
  [  420   875]]

 [[12545   194]
  [  175   206]]

 [[13104     2]
  [   10     4]]

 [[12009   343]
  [  333   435]]

 [[12555   193]
  [  198   174]]

 [[12365   124]
  [  181   450]]

 [[13107     3]
  [   10     0]]

 [[12628   176]
  [  148   168]]

 [[12536   179]
  [  163   242]]

 [[12994    30]
  [   42    54]]

 [[13092     2]
  [   23     3]]

 [[13037    17]
  [   43    23]]

 [[13095     3]
  [   12    10]]

 [[12946    53]
  [   52    69]]

 [[12971    36]
  [   30    83]]

 [[12866    46]
  [   59   149]]

 [[12867    59]
  [   76   118]]

 [[13062    12]
  [   28    18]]

 [[12624    65]
  [   67   364]]

 [[13035    19]
  [   20    46]]

 [[12585    46]
  [  123   366]]

 [[13051     7]
  [   29    33]]

 [[12812    45]
  [   47   216]]

 [[13048    22]
  [   18    32]]

 [[13086     3]
  [   16    15]]

 [[13100     4]
  [    2    14]]

 [[13096     3]
  [    9    12]]

 [[13015    32]
  [   14    59]]]

===scores report===
metrics	scores
Accuracy	0.6627
MCC	0.6416
log_loss	1.7274
f1 score weighted	0.6607
f1 score macro	0.5627
f1 score micro	0.6627
roc_auc ovr	0.9517
roc_auc ovo	0.9483
precision	0.6651
recall	0.6627

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f04d83b4850>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f04d83b46a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f04d83b4880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f04d83b45b0>, 'x_test': array([[13, 12, 12, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 20,  8, ...,  0,  0,  0],
       ...,
       [12, 12, 11, ..., 16,  9, 20],
       [13,  6, 12, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.68      0.73      0.70       401
         1.0       0.70      0.35      0.47        20
         2.0       0.59      0.50      0.54        82
         3.0       0.25      0.07      0.11        15
         4.0       0.35      0.27      0.31        62
         5.0       0.64      0.58      0.61       278
         6.0       0.92      0.64      0.75        36
         7.0       0.50      0.32      0.39        25
         8.0       0.63      0.52      0.57        73
         9.0       0.62      0.45      0.52        29
        10.0       0.80      0.68      0.74       156
        11.0       0.57      0.48      0.52       168
        12.0       0.62      0.42      0.50        83
        13.0       0.20      0.09      0.13        54
        14.0       0.54      0.45      0.49        31
        15.0       0.36      0.34      0.35        53
        16.0       0.67      0.58      0.62        95
        17.0       0.81      0.80      0.80       884
        18.0       0.68      0.60      0.64        47
        19.0       0.71      0.65      0.68       781
        20.0       0.66      0.71      0.69       592
        21.0       0.71      0.71      0.71       385
        22.0       0.84      0.76      0.80       129
        23.0       0.74      0.81      0.77      1887
        24.0       0.85      0.74      0.79       168
        25.0       0.59      0.69      0.64      1295
        26.0       0.56      0.60      0.58       381
        27.0       0.57      0.31      0.40        13
        28.0       0.58      0.62      0.60       769
        29.0       0.53      0.54      0.54       372
        30.0       0.75      0.72      0.74       631
        31.0       0.40      0.36      0.38        11
        32.0       0.48      0.58      0.52       316
        33.0       0.64      0.63      0.64       405
        34.0       0.73      0.54      0.62        95
        35.0       0.25      0.16      0.20        25
        36.0       0.61      0.47      0.53        66
        37.0       0.77      0.45      0.57        22
        38.0       0.60      0.58      0.59       121
        39.0       0.82      0.79      0.80       113
        40.0       0.76      0.67      0.71       208
        41.0       0.75      0.65      0.70       194
        42.0       0.58      0.33      0.42        46
        43.0       0.87      0.83      0.85       431
        44.0       0.71      0.56      0.63        66
        45.0       0.84      0.74      0.79       489
        46.0       0.87      0.66      0.75        62
        47.0       0.82      0.88      0.85       263
        48.0       0.76      0.52      0.62        50
        49.0       0.71      0.71      0.71        31
        50.0       0.93      0.81      0.87        16
        51.0       0.67      0.73      0.70        22
        52.0       0.76      0.77      0.76        73

    accuracy                           0.69     13120
   macro avg       0.65      0.57      0.60     13120
weighted avg       0.69      0.69      0.68     13120


===confusion_matrix===

[[292   1   1 ...   0   0   0]
 [  0   7   0 ...   0   0   0]
 [  0   0  41 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   1  16   4]
 [  0   0   0 ...   0   5  56]]

===multilabel confusion matrix===

[[[12583   136]
  [  109   292]]

 [[13097     3]
  [   13     7]]

 [[13010    28]
  [   41    41]]

 [[13102     3]
  [   14     1]]

 [[13026    32]
  [   45    17]]

 [[12752    90]
  [  116   162]]

 [[13082     2]
  [   13    23]]

 [[13087     8]
  [   17     8]]

 [[13025    22]
  [   35    38]]

 [[13083     8]
  [   16    13]]

 [[12938    26]
  [   50   106]]

 [[12891    61]
  [   87    81]]

 [[13016    21]
  [   48    35]]

 [[13046    20]
  [   49     5]]

 [[13077    12]
  [   17    14]]

 [[13035    32]
  [   35    18]]

 [[12998    27]
  [   40    55]]

 [[12070   166]
  [  180   704]]

 [[13060    13]
  [   19    28]]

 [[12129   210]
  [  272   509]]

 [[12313   215]
  [  171   421]]

 [[12625   110]
  [  110   275]]

 [[12972    19]
  [   31    98]]

 [[10682   551]
  [  357  1530]]

 [[12930    22]
  [   44   124]]

 [[11203   622]
  [  399   896]]

 [[12557   182]
  [  152   229]]

 [[13104     3]
  [    9     4]]

 [[12005   346]
  [  296   473]]

 [[12571   177]
  [  170   202]]

 [[12339   150]
  [  175   456]]

 [[13103     6]
  [    7     4]]

 [[12607   197]
  [  134   182]]

 [[12572   143]
  [  149   256]]

 [[13006    19]
  [   44    51]]

 [[13083    12]
  [   21     4]]

 [[13034    20]
  [   35    31]]

 [[13095     3]
  [   12    10]]

 [[12953    46]
  [   51    70]]

 [[12987    20]
  [   24    89]]

 [[12868    44]
  [   68   140]]

 [[12885    41]
  [   68   126]]

 [[13063    11]
  [   31    15]]

 [[12637    52]
  [   75   356]]

 [[13039    15]
  [   29    37]]

 [[12563    68]
  [  125   364]]

 [[13052     6]
  [   21    41]]

 [[12806    51]
  [   32   231]]

 [[13062     8]
  [   24    26]]

 [[13080     9]
  [    9    22]]

 [[13103     1]
  [    3    13]]

 [[13090     8]
  [    6    16]]

 [[13029    18]
  [   17    56]]]

===scores report===
metrics	scores
Accuracy	0.6864
MCC	0.6667
log_loss	1.6396
f1 score weighted	0.6848
f1 score macro	0.6016
f1 score micro	0.6864
roc_auc ovr	0.9576
roc_auc ovo	0.9548
precision	0.6886
recall	0.6864

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f04d83b4850>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f04d83b46a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f04d83b4880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f04d83b45b0>, 'x_test': array([[13, 17, 12, ...,  0,  0,  0],
       [13, 12,  3, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       ...,
       [ 8, 20,  4, ...,  0,  0,  0],
       [20,  6, 15, ...,  4,  2,  3],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.72      0.75       402
         1.0       1.00      0.53      0.69        19
         2.0       0.74      0.51      0.60        82
         3.0       0.00      0.00      0.00        16
         4.0       0.44      0.26      0.33        62
         5.0       0.60      0.60      0.60       278
         6.0       0.96      0.69      0.81        36
         7.0       1.00      0.08      0.14        26
         8.0       0.63      0.40      0.49        73
         9.0       0.75      0.40      0.52        30
        10.0       0.78      0.65      0.71       156
        11.0       0.48      0.37      0.42       169
        12.0       0.68      0.47      0.56        83
        13.0       0.15      0.04      0.06        53
        14.0       0.52      0.42      0.46        31
        15.0       0.66      0.44      0.53        52
        16.0       0.64      0.48      0.55        95
        17.0       0.85      0.80      0.83       885
        18.0       0.67      0.50      0.57        48
        19.0       0.79      0.60      0.68       781
        20.0       0.66      0.75      0.70       592
        21.0       0.65      0.72      0.68       384
        22.0       0.77      0.67      0.72       128
        23.0       0.75      0.80      0.77      1887
        24.0       0.91      0.67      0.77       168
        25.0       0.55      0.73      0.63      1295
        26.0       0.48      0.58      0.52       381
        27.0       1.00      0.50      0.67        14
        28.0       0.64      0.60      0.62       769
        29.0       0.51      0.53      0.52       372
        30.0       0.81      0.68      0.74       630
        31.0       0.50      0.18      0.27        11
        32.0       0.43      0.53      0.47       316
        33.0       0.52      0.72      0.60       405
        34.0       0.76      0.58      0.66        95
        35.0       0.00      0.00      0.00        25
        36.0       0.52      0.40      0.45        65
        37.0       0.84      0.73      0.78        22
        38.0       0.58      0.60      0.59       121
        39.0       0.83      0.65      0.73       113
        40.0       0.69      0.75      0.72       208
        41.0       0.67      0.69      0.68       194
        42.0       0.56      0.38      0.46        47
        43.0       0.89      0.84      0.87       431
        44.0       0.92      0.74      0.82        66
        45.0       0.78      0.79      0.78       488
        46.0       0.95      0.57      0.71        63
        47.0       0.82      0.79      0.81       263
        48.0       0.76      0.53      0.63        49
        49.0       0.73      0.63      0.68        30
        50.0       0.78      0.93      0.85        15
        51.0       0.93      0.59      0.72        22
        52.0       0.71      0.90      0.80        73

    accuracy                           0.68     13119
   macro avg       0.68      0.56      0.60     13119
weighted avg       0.69      0.68      0.68     13119


===confusion_matrix===

[[291   0   0 ...   0   0   0]
 [  0  10   0 ...   0   0   0]
 [  0   0  42 ...   0   0   0]
 ...
 [  0   0   0 ...  14   0   0]
 [  0   0   0 ...   0  13   9]
 [  0   0   0 ...   0   0  66]]

===multilabel confusion matrix===

[[[12632    85]
  [  111   291]]

 [[13100     0]
  [    9    10]]

 [[13022    15]
  [   40    42]]

 [[13100     3]
  [   16     0]]

 [[13037    20]
  [   46    16]]

 [[12731   110]
  [  111   167]]

 [[13082     1]
  [   11    25]]

 [[13093     0]
  [   24     2]]

 [[13029    17]
  [   44    29]]

 [[13085     4]
  [   18    12]]

 [[12934    29]
  [   55   101]]

 [[12882    68]
  [  106    63]]

 [[13018    18]
  [   44    39]]

 [[13055    11]
  [   51     2]]

 [[13076    12]
  [   18    13]]

 [[13055    12]
  [   29    23]]

 [[12998    26]
  [   49    46]]

 [[12110   124]
  [  175   710]]

 [[13059    12]
  [   24    24]]

 [[12209   129]
  [  309   472]]

 [[12300   227]
  [  150   442]]

 [[12590   145]
  [  109   275]]

 [[12965    26]
  [   42    86]]

 [[10733   499]
  [  378  1509]]

 [[12940    11]
  [   56   112]]

 [[11060   764]
  [  354   941]]

 [[12497   241]
  [  161   220]]

 [[13105     0]
  [    7     7]]

 [[12090   260]
  [  310   459]]

 [[12559   188]
  [  175   197]]

 [[12391    98]
  [  202   428]]

 [[13106     2]
  [    9     2]]

 [[12582   221]
  [  149   167]]

 [[12446   268]
  [  114   291]]

 [[13007    17]
  [   40    55]]

 [[13086     8]
  [   25     0]]

 [[13030    24]
  [   39    26]]

 [[13094     3]
  [    6    16]]

 [[12945    53]
  [   48    73]]

 [[12991    15]
  [   39    74]]

 [[12841    70]
  [   52   156]]

 [[12859    66]
  [   61   133]]

 [[13058    14]
  [   29    18]]

 [[12645    43]
  [   68   363]]

 [[13049     4]
  [   17    49]]

 [[12524   107]
  [  104   384]]

 [[13054     2]
  [   27    36]]

 [[12809    47]
  [   54   209]]

 [[13062     8]
  [   23    26]]

 [[13082     7]
  [   11    19]]

 [[13100     4]
  [    1    14]]

 [[13096     1]
  [    9    13]]

 [[13019    27]
  [    7    66]]]

===scores report===
metrics	scores
Accuracy	0.6824
MCC	0.6629
log_loss	1.6110
f1 score weighted	0.6812
f1 score macro	0.5984
f1 score micro	0.6824
roc_auc ovr	0.9583
roc_auc ovo	0.9561
precision	0.6933
recall	0.6824

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6789634146341463	0.6584283229251187	1.6117342982413325	0.677022805282071	0.5838844818786483	0.6789634146341463	0.9563338744025945	0.9520891771448193	0.6854905651594656	0.6789634146341463
1	0.6772865853658536	0.6571725121207579	1.622278554537945	0.6763300134167783	0.5921829520127238	0.6772865853658536	0.9570044588051407	0.9541277736263004	0.6861587990049247	0.6772865853658536
2	0.6626524390243902	0.6415904588211357	1.7274105751113962	0.660690383639164	0.5626937139908558	0.6626524390243902	0.9516877647435241	0.9482976241676174	0.665135396261252	0.6626524390243902
3	0.6863567073170732	0.6666686577671818	1.6396186800079842	0.6848100748402728	0.6015557922945709	0.6863567073170732	0.9576461221482937	0.9548388865143965	0.688603524667136	0.6863567073170732
4	0.6824453083314277	0.6628960137381054	1.6110012079734533	0.6811877194776371	0.5983806305975901	0.6824453083314277	0.9583044110941481	0.9561210647269209	0.6932714972024889	0.6824453083314277
mean	0.6775408909345781	0.6573511930744599	1.6424086631744224	0.6760081993311846	0.5877395141548776	0.6775408909345781	0.9561953262387402	0.9530949052360109	0.6837319564590535	0.6775408909345781
std	0.008068781491309398	0.008569166403967302	0.04373939921621168	0.008247046847702121	0.013899787196098785	0.008068781491309398	0.0023471280082415637	0.0027309823770219365	0.009690710344404455	0.008068781491309398

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 30572.9242 secs

