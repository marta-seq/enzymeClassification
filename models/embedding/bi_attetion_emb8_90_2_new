/home/amsequeira/enzymeClassification/models/embedding/bi_attetion_emb8_90_2_new
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f07001e2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f07001e2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f07001e2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f07001e26a0>, 'x_test': array([[13,  2,  3, ...,  0,  0,  0],
       [13, 13,  2, ...,  0,  0,  0],
       [13,  7,  1, ...,  0,  0,  0],
       ...,
       [13,  4, 11, ...,  0,  0,  0],
       [13,  1, 20, ...,  0,  0,  0],
       [13,  6, 12, ...,  0,  0,  0]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.86      0.87       911
         1.0       1.00      0.64      0.78        53
         2.0       0.73      0.80      0.76       179
         3.0       0.60      0.12      0.20        25
         4.0       0.71      0.42      0.53       112
         5.0       0.77      0.68      0.72       491
         6.0       0.89      0.80      0.84        64
         7.0       0.31      0.22      0.25        37
         8.0       0.93      0.81      0.86       206
         9.0       0.85      0.65      0.74        71
        10.0       0.89      0.90      0.89       404
        11.0       0.67      0.50      0.57        16
        12.0       0.80      0.75      0.78       378
        13.0       0.79      0.76      0.78       191
        14.0       0.38      0.08      0.13        76
        15.0       0.76      0.76      0.76        66
        16.0       0.71      0.80      0.75       141
        17.0       0.54      0.82      0.65       182
        18.0       1.00      0.75      0.86        12
        19.0       1.00      0.84      0.91        38
        20.0       0.91      0.91      0.91      2162
        21.0       0.95      0.92      0.93       168
        22.0       0.74      0.83      0.78      1470
        23.0       0.94      0.80      0.87      1259
        24.0       0.93      0.87      0.90       956
        25.0       0.96      0.85      0.90       283
        26.0       0.90      0.88      0.89      3919
        27.0       0.87      0.90      0.88       531
        28.0       1.00      0.75      0.86        12
        29.0       0.70      0.84      0.76      2345
        30.0       0.65      0.65      0.65       615
        31.0       0.95      0.66      0.78        32
        32.0       0.76      0.75      0.75      1449
        33.0       0.75      0.81      0.78       893
        34.0       0.77      0.89      0.83      1377
        35.0       1.00      0.41      0.58        22
        36.0       0.78      0.84      0.81       844
        37.0       0.90      0.86      0.88      1142
        38.0       0.88      0.85      0.86       314
        39.0       0.88      0.52      0.65        56
        40.0       0.91      0.75      0.82       154
        41.0       1.00      0.87      0.93        52
        42.0       0.96      0.66      0.78       247
        43.0       0.57      0.82      0.67       198
        44.0       0.87      0.88      0.87       529
        45.0       0.97      0.83      0.90       540
        46.0       0.88      0.35      0.50        20
        47.0       0.96      0.57      0.72        80
        48.0       0.97      0.96      0.97      1466
        49.0       0.93      0.82      0.87       148
        50.0       0.96      0.92      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.96      0.91      0.93       151
        53.0       0.95      0.96      0.95       903
        54.0       0.95      0.75      0.84       108
        55.0       0.99      0.91      0.95        93
        56.0       0.91      0.91      0.91        33
        57.0       0.81      0.86      0.83        49
        58.0       0.87      0.92      0.90       154

    accuracy                           0.84     29892
   macro avg       0.83      0.74      0.77     29892
weighted avg       0.85      0.84      0.84     29892


===confusion_matrix===

[[779   0   0 ...   0   0   0]
 [  0  34   0 ...   0   0   0]
 [  0   0 143 ...   0   0   0]
 ...
 [  0   0   0 ...  30   1   0]
 [  0   0   0 ...   0  42   6]
 [  0   0   0 ...   1   5 142]]

===multilabel confusion matrix===

[[[28890    91]
  [  132   779]]

 [[29839     0]
  [   19    34]]

 [[29661    52]
  [   36   143]]

 [[29865     2]
  [   22     3]]

 [[29761    19]
  [   65    47]]

 [[29303    98]
  [  158   333]]

 [[29822     6]
  [   13    51]]

 [[29837    18]
  [   29     8]]

 [[29674    12]
  [   40   166]]

 [[29813     8]
  [   25    46]]

 [[29441    47]
  [   40   364]]

 [[29872     4]
  [    8     8]]

 [[29444    70]
  [   94   284]]

 [[29663    38]
  [   45   146]]

 [[29806    10]
  [   70     6]]

 [[29810    16]
  [   16    50]]

 [[29705    46]
  [   28   113]]

 [[29582   128]
  [   32   150]]

 [[29880     0]
  [    3     9]]

 [[29854     0]
  [    6    32]]

 [[27540   190]
  [  197  1965]]

 [[29716     8]
  [   14   154]]

 [[27990   432]
  [  252  1218]]

 [[28573    60]
  [  252  1007]]

 [[28873    63]
  [  125   831]]

 [[29599    10]
  [   42   241]]

 [[25607   366]
  [  484  3435]]

 [[29288    73]
  [   53   478]]

 [[29880     0]
  [    3     9]]

 [[26703   844]
  [  381  1964]]

 [[29057   220]
  [  213   402]]

 [[29859     1]
  [   11    21]]

 [[28091   352]
  [  358  1091]]

 [[28760   239]
  [  166   727]]

 [[28157   358]
  [  152  1225]]

 [[29870     0]
  [   13     9]]

 [[28850   198]
  [  138   706]]

 [[28647   103]
  [  162   980]]

 [[29540    38]
  [   47   267]]

 [[29832     4]
  [   27    29]]

 [[29726    12]
  [   39   115]]

 [[29840     0]
  [    7    45]]

 [[29638     7]
  [   84   163]]

 [[29570   124]
  [   35   163]]

 [[29291    72]
  [   62   467]]

 [[29340    12]
  [   92   448]]

 [[29871     1]
  [   13     7]]

 [[29810     2]
  [   34    46]]

 [[28388    38]
  [   52  1414]]

 [[29735     9]
  [   27   121]]

 [[28383    56]
  [  113  1340]]

 [[29880     0]
  [   12     0]]

 [[29735     6]
  [   14   137]]

 [[28940    49]
  [   39   864]]

 [[29780     4]
  [   27    81]]

 [[29798     1]
  [    8    85]]

 [[29856     3]
  [    3    30]]

 [[29833    10]
  [    7    42]]

 [[29717    21]
  [   12   142]]]

===scores report===
metrics	scores
Accuracy	0.8444
MCC	0.8362
log_loss	0.6621
f1 score weighted	0.8445
f1 score macro	0.7660
f1 score micro	0.8444
roc_auc ovr	0.9898
roc_auc ovo	0.9864
precision	0.8511
recall	0.8444

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f07001e2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f07001e2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f07001e2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f07001e26a0>, 'x_test': array([[13, 12,  3, ...,  0,  0,  0],
       [13, 16, 11, ...,  0,  0,  0],
       [13, 16,  4, ...,  0,  0,  0],
       ...,
       [20, 20, 20, ...,  1,  7,  1],
       [13, 16, 11, ...,  0,  0,  0],
       [11, 11,  2, ...,  1, 16,  1]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.95      0.76      0.85       912
         1.0       0.82      0.70      0.76        53
         2.0       0.74      0.73      0.73       179
         3.0       0.62      0.20      0.30        25
         4.0       0.50      0.51      0.51       112
         5.0       0.91      0.63      0.75       492
         6.0       0.80      0.75      0.78        65
         7.0       0.75      0.08      0.14        38
         8.0       0.94      0.78      0.85       206
         9.0       0.91      0.59      0.72        71
        10.0       0.83      0.82      0.83       405
        11.0       0.58      0.41      0.48        17
        12.0       0.99      0.54      0.70       377
        13.0       0.83      0.67      0.74       191
        14.0       1.00      0.04      0.08        76
        15.0       0.89      0.59      0.71        66
        16.0       0.90      0.69      0.78       140
        17.0       0.82      0.67      0.74       182
        18.0       0.77      0.91      0.83        11
        19.0       0.97      0.78      0.87        37
        20.0       0.98      0.86      0.92      2163
        21.0       0.97      0.89      0.93       169
        22.0       0.91      0.71      0.80      1469
        23.0       0.89      0.84      0.86      1259
        24.0       0.99      0.74      0.84       956
        25.0       0.88      0.87      0.87       282
        26.0       0.96      0.80      0.87      3919
        27.0       0.86      0.92      0.89       531
        28.0       0.77      0.83      0.80        12
        29.0       0.56      0.86      0.67      2346
        30.0       0.38      0.79      0.51       615
        31.0       1.00      0.59      0.75        32
        32.0       0.48      0.85      0.62      1450
        33.0       0.59      0.82      0.68       893
        34.0       0.96      0.85      0.90      1376
        35.0       0.90      0.41      0.56        22
        36.0       0.76      0.81      0.79       843
        37.0       0.97      0.74      0.84      1142
        38.0       0.95      0.83      0.89       314
        39.0       0.88      0.52      0.65        56
        40.0       0.94      0.61      0.74       154
        41.0       1.00      0.92      0.96        52
        42.0       0.78      0.81      0.79       247
        43.0       0.94      0.64      0.76       198
        44.0       0.95      0.78      0.86       529
        45.0       0.92      0.89      0.91       539
        46.0       1.00      0.32      0.48        19
        47.0       0.60      0.60      0.60        80
        48.0       0.97      0.95      0.96      1466
        49.0       0.93      0.84      0.88       148
        50.0       0.98      0.88      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.94      0.84      0.89       151
        53.0       0.97      0.93      0.95       903
        54.0       0.98      0.59      0.74       108
        55.0       0.94      0.97      0.95        93
        56.0       0.96      0.76      0.85        33
        57.0       0.96      0.88      0.91        49
        58.0       0.82      0.94      0.88       154

    accuracy                           0.81     29892
   macro avg       0.84      0.70      0.74     29892
weighted avg       0.86      0.81      0.82     29892


===confusion_matrix===

[[697   0   1 ...   0   0   0]
 [  0  37   0 ...   0   0   0]
 [  0   0 131 ...   0   0   0]
 ...
 [  0   0   0 ...  25   0   4]
 [  0   0   0 ...   0  43   5]
 [  0   0   0 ...   1   0 145]]

===multilabel confusion matrix===

[[[28942    38]
  [  215   697]]

 [[29831     8]
  [   16    37]]

 [[29666    47]
  [   48   131]]

 [[29864     3]
  [   20     5]]

 [[29724    56]
  [   55    57]]

 [[29368    32]
  [  180   312]]

 [[29815    12]
  [   16    49]]

 [[29853     1]
  [   35     3]]

 [[29676    10]
  [   45   161]]

 [[29817     4]
  [   29    42]]

 [[29418    69]
  [   72   333]]

 [[29870     5]
  [   10     7]]

 [[29512     3]
  [  172   205]]

 [[29674    27]
  [   63   128]]

 [[29816     0]
  [   73     3]]

 [[29821     5]
  [   27    39]]

 [[29741    11]
  [   43    97]]

 [[29683    27]
  [   60   122]]

 [[29878     3]
  [    1    10]]

 [[29854     1]
  [    8    29]]

 [[27688    41]
  [  303  1860]]

 [[29719     4]
  [   18   151]]

 [[28321   102]
  [  429  1040]]

 [[28501   132]
  [  205  1054]]

 [[28930     6]
  [  253   703]]

 [[29575    35]
  [   37   245]]

 [[25850   123]
  [  797  3122]]

 [[29279    82]
  [   41   490]]

 [[29877     3]
  [    2    10]]

 [[25952  1594]
  [  339  2007]]

 [[28482   795]
  [  128   487]]

 [[29860     0]
  [   13    19]]

 [[27139  1303]
  [  223  1227]]

 [[28480   519]
  [  159   734]]

 [[28461    55]
  [  203  1173]]

 [[29869     1]
  [   13     9]]

 [[28832   217]
  [  157   686]]

 [[28724    26]
  [  299   843]]

 [[29565    13]
  [   53   261]]

 [[29832     4]
  [   27    29]]

 [[29732     6]
  [   60    94]]

 [[29840     0]
  [    4    48]]

 [[29590    55]
  [   48   199]]

 [[29686     8]
  [   72   126]]

 [[29341    22]
  [  115   414]]

 [[29313    40]
  [   57   482]]

 [[29873     0]
  [   13     6]]

 [[29780    32]
  [   32    48]]

 [[28389    37]
  [   75  1391]]

 [[29734    10]
  [   24   124]]

 [[28415    24]
  [  171  1282]]

 [[29880     0]
  [   12     0]]

 [[29733     8]
  [   24   127]]

 [[28962    27]
  [   63   840]]

 [[29783     1]
  [   44    64]]

 [[29793     6]
  [    3    90]]

 [[29858     1]
  [    8    25]]

 [[29841     2]
  [    6    43]]

 [[29707    31]
  [    9   145]]]

===scores report===
metrics	scores
Accuracy	0.8084
MCC	0.8002
log_loss	0.9196
f1 score weighted	0.8186
f1 score macro	0.7427
f1 score micro	0.8084
roc_auc ovr	0.9869
roc_auc ovo	0.9829
precision	0.8589
recall	0.8084

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f07001e2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f07001e2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f07001e2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f07001e26a0>, 'x_test': array([[13, 16,  8, ...,  0,  0,  0],
       [13,  7, 17, ...,  0,  0,  0],
       [13, 19,  3, ...,  0,  0,  0],
       ...,
       [13,  1, 17, ...,  0,  0,  0],
       [ 9,  5,  1, ...,  8, 11, 15],
       [20,  6, 15, ...,  4,  2,  3]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.87      0.89       912
         1.0       0.84      0.83      0.83        52
         2.0       0.75      0.75      0.75       179
         3.0       0.62      0.20      0.30        25
         4.0       0.38      0.64      0.48       112
         5.0       0.83      0.68      0.75       492
         6.0       0.91      0.75      0.82        65
         7.0       0.88      0.18      0.30        38
         8.0       0.97      0.72      0.83       205
         9.0       0.93      0.77      0.85        71
        10.0       0.99      0.80      0.89       405
        11.0       0.92      0.65      0.76        17
        12.0       0.92      0.72      0.80       377
        13.0       0.88      0.75      0.81       190
        14.0       0.60      0.16      0.25        76
        15.0       0.87      0.70      0.78        67
        16.0       0.93      0.79      0.85       140
        17.0       0.80      0.75      0.77       183
        18.0       1.00      0.92      0.96        12
        19.0       0.94      0.84      0.89        37
        20.0       0.90      0.93      0.91      2162
        21.0       0.89      0.94      0.91       169
        22.0       0.90      0.76      0.83      1470
        23.0       0.95      0.78      0.86      1259
        24.0       0.95      0.86      0.90       956
        25.0       0.92      0.88      0.90       282
        26.0       0.94      0.85      0.89      3918
        27.0       0.97      0.90      0.93       531
        28.0       1.00      0.77      0.87        13
        29.0       0.63      0.86      0.73      2346
        30.0       0.47      0.74      0.57       615
        31.0       1.00      0.75      0.86        32
        32.0       0.86      0.74      0.79      1450
        33.0       0.51      0.89      0.65       893
        34.0       0.96      0.83      0.89      1376
        35.0       0.93      0.64      0.76        22
        36.0       0.78      0.86      0.82       843
        37.0       0.89      0.87      0.88      1142
        38.0       0.89      0.89      0.89       314
        39.0       0.58      0.60      0.59        55
        40.0       0.97      0.72      0.83       154
        41.0       0.98      0.77      0.86        52
        42.0       0.92      0.77      0.84       247
        43.0       0.94      0.76      0.84       197
        44.0       0.83      0.93      0.88       530
        45.0       0.93      0.88      0.90       540
        46.0       1.00      0.26      0.42        19
        47.0       0.91      0.39      0.55        79
        48.0       0.96      0.98      0.97      1465
        49.0       1.00      0.89      0.94       149
        50.0       0.95      0.90      0.93      1453
        51.0       0.33      0.08      0.13        12
        52.0       0.98      0.86      0.92       152
        53.0       0.92      0.96      0.94       903
        54.0       0.93      0.80      0.86       108
        55.0       0.71      0.94      0.81        93
        56.0       0.88      0.94      0.91        32
        57.0       0.97      0.74      0.84        50
        58.0       0.95      0.82      0.88       154

    accuracy                           0.84     29892
   macro avg       0.86      0.75      0.78     29892
weighted avg       0.87      0.84      0.85     29892


===confusion_matrix===

[[792   0   0 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  0   0 134 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   0]
 [  0   0   0 ...   1  37   5]
 [  0   0   0 ...   2   1 126]]

===multilabel confusion matrix===

[[[28912    68]
  [  120   792]]

 [[29832     8]
  [    9    43]]

 [[29669    44]
  [   45   134]]

 [[29864     3]
  [   20     5]]

 [[29664   116]
  [   40    72]]

 [[29331    69]
  [  155   337]]

 [[29822     5]
  [   16    49]]

 [[29853     1]
  [   31     7]]

 [[29683     4]
  [   58   147]]

 [[29817     4]
  [   16    55]]

 [[29485     2]
  [   80   325]]

 [[29874     1]
  [    6    11]]

 [[29490    25]
  [  107   270]]

 [[29683    19]
  [   47   143]]

 [[29808     8]
  [   64    12]]

 [[29818     7]
  [   20    47]]

 [[29743     9]
  [   29   111]]

 [[29675    34]
  [   46   137]]

 [[29880     0]
  [    1    11]]

 [[29853     2]
  [    6    31]]

 [[27507   223]
  [  153  2009]]

 [[29703    20]
  [   10   159]]

 [[28301   121]
  [  349  1121]]

 [[28581    52]
  [  272   987]]

 [[28896    40]
  [  136   820]]

 [[29587    23]
  [   33   249]]

 [[25754   220]
  [  577  3341]]

 [[29345    16]
  [   53   478]]

 [[29879     0]
  [    3    10]]

 [[26341  1205]
  [  318  2028]]

 [[28763   514]
  [  162   453]]

 [[29860     0]
  [    8    24]]

 [[28262   180]
  [  378  1072]]

 [[28224   775]
  [   96   797]]

 [[28471    45]
  [  236  1140]]

 [[29869     1]
  [    8    14]]

 [[28847   202]
  [  122   721]]

 [[28622   128]
  [  149   993]]

 [[29544    34]
  [   33   281]]

 [[29813    24]
  [   22    33]]

 [[29734     4]
  [   43   111]]

 [[29839     1]
  [   12    40]]

 [[29629    16]
  [   58   189]]

 [[29685    10]
  [   47   150]]

 [[29259   103]
  [   37   493]]

 [[29314    38]
  [   64   476]]

 [[29873     0]
  [   14     5]]

 [[29810     3]
  [   48    31]]

 [[28368    59]
  [   33  1432]]

 [[29743     0]
  [   16   133]]

 [[28370    69]
  [  142  1311]]

 [[29878     2]
  [   11     1]]

 [[29738     2]
  [   22   130]]

 [[28914    75]
  [   35   868]]

 [[29778     6]
  [   22    86]]

 [[29764    35]
  [    6    87]]

 [[29856     4]
  [    2    30]]

 [[29841     1]
  [   13    37]]

 [[29731     7]
  [   28   126]]]

===scores report===
metrics	scores
Accuracy	0.8432
MCC	0.8357
log_loss	0.6894
f1 score weighted	0.8481
f1 score macro	0.7837
f1 score micro	0.8432
roc_auc ovr	0.9905
roc_auc ovo	0.9879
precision	0.8684
recall	0.8432

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f07001e2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f07001e2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f07001e2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f07001e26a0>, 'x_test': array([[13,  1,  1, ...,  0,  0,  0],
       [13,  3, 10, ...,  0,  0,  0],
       [13, 12, 12, ...,  0,  0,  0],
       ...,
       [17, 12, 15, ...,  3,  9, 11],
       [20,  2,  1, ...,  7,  6,  6],
       [ 8, 15, 15, ...,  9, 17, 11]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.90      0.88       912
         1.0       0.92      0.85      0.88        52
         2.0       0.86      0.76      0.81       179
         3.0       0.67      0.25      0.36        24
         4.0       0.77      0.60      0.67       112
         5.0       0.75      0.72      0.73       492
         6.0       0.95      0.83      0.88        64
         7.0       0.71      0.39      0.51        38
         8.0       0.94      0.83      0.88       205
         9.0       0.95      0.86      0.90        70
        10.0       0.93      0.89      0.91       405
        11.0       0.75      0.18      0.29        17
        12.0       0.80      0.80      0.80       378
        13.0       0.88      0.80      0.84       191
        14.0       0.36      0.16      0.22        76
        15.0       0.79      0.73      0.76        67
        16.0       0.88      0.85      0.87       140
        17.0       0.84      0.79      0.82       183
        18.0       0.92      0.92      0.92        12
        19.0       1.00      0.95      0.97        37
        20.0       0.93      0.92      0.92      2162
        21.0       0.96      0.93      0.95       168
        22.0       0.80      0.85      0.82      1470
        23.0       0.85      0.88      0.86      1259
        24.0       0.94      0.89      0.91       955
        25.0       0.94      0.94      0.94       282
        26.0       0.90      0.90      0.90      3918
        27.0       0.95      0.92      0.93       532
        28.0       0.92      0.92      0.92        13
        29.0       0.76      0.82      0.79      2346
        30.0       0.65      0.75      0.70       616
        31.0       0.96      0.78      0.86        32
        32.0       0.80      0.79      0.80      1449
        33.0       0.75      0.85      0.80       893
        34.0       0.88      0.90      0.89      1377
        35.0       1.00      0.68      0.81        22
        36.0       0.78      0.89      0.83       844
        37.0       0.94      0.85      0.89      1142
        38.0       0.95      0.89      0.92       314
        39.0       0.79      0.61      0.69        56
        40.0       0.94      0.74      0.83       153
        41.0       0.98      0.84      0.91        51
        42.0       0.83      0.81      0.82       246
        43.0       0.87      0.88      0.88       197
        44.0       0.93      0.91      0.92       530
        45.0       0.95      0.88      0.91       540
        46.0       0.83      0.25      0.38        20
        47.0       0.86      0.60      0.71        80
        48.0       0.98      0.97      0.97      1465
        49.0       0.96      0.88      0.92       148
        50.0       0.95      0.94      0.94      1453
        51.0       0.00      0.00      0.00        13
        52.0       0.93      0.85      0.89       151
        53.0       0.95      0.95      0.95       904
        54.0       0.92      0.78      0.84       108
        55.0       0.93      0.94      0.93        93
        56.0       0.97      0.91      0.94        33
        57.0       0.84      0.94      0.89        50
        58.0       0.92      0.88      0.90       153

    accuracy                           0.87     29892
   macro avg       0.86      0.78      0.81     29892
weighted avg       0.87      0.87      0.87     29892


===confusion_matrix===

[[823   0   1 ...   0   0   0]
 [  0  44   0 ...   0   0   0]
 [  0   0 136 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   2]
 [  0   0   0 ...   0  47   1]
 [  0   0   0 ...   0   6 134]]

===multilabel confusion matrix===

[[[28844   136]
  [   89   823]]

 [[29836     4]
  [    8    44]]

 [[29691    22]
  [   43   136]]

 [[29865     3]
  [   18     6]]

 [[29760    20]
  [   45    67]]

 [[29281   119]
  [  138   354]]

 [[29825     3]
  [   11    53]]

 [[29848     6]
  [   23    15]]

 [[29676    11]
  [   35   170]]

 [[29819     3]
  [   10    60]]

 [[29458    29]
  [   43   362]]

 [[29874     1]
  [   14     3]]

 [[29436    78]
  [   74   304]]

 [[29680    21]
  [   38   153]]

 [[29795    21]
  [   64    12]]

 [[29812    13]
  [   18    49]]

 [[29736    16]
  [   21   119]]

 [[29682    27]
  [   38   145]]

 [[29879     1]
  [    1    11]]

 [[29855     0]
  [    2    35]]

 [[27569   161]
  [  164  1998]]

 [[29718     6]
  [   11   157]]

 [[28109   313]
  [  224  1246]]

 [[28436   197]
  [  151  1108]]

 [[28880    57]
  [  105   850]]

 [[29592    18]
  [   18   264]]

 [[25577   397]
  [  408  3510]]

 [[29337    23]
  [   45   487]]

 [[29878     1]
  [    1    12]]

 [[26934   612]
  [  434  1912]]

 [[29026   250]
  [  153   463]]

 [[29859     1]
  [    7    25]]

 [[28165   278]
  [  304  1145]]

 [[28750   249]
  [  131   762]]

 [[28342   173]
  [  134  1243]]

 [[29870     0]
  [    7    15]]

 [[28836   212]
  [   96   748]]

 [[28685    65]
  [  168   974]]

 [[29564    14]
  [   35   279]]

 [[29827     9]
  [   22    34]]

 [[29732     7]
  [   40   113]]

 [[29840     1]
  [    8    43]]

 [[29606    40]
  [   47   199]]

 [[29670    25]
  [   24   173]]

 [[29323    39]
  [   48   482]]

 [[29325    27]
  [   65   475]]

 [[29871     1]
  [   15     5]]

 [[29804     8]
  [   32    48]]

 [[28397    30]
  [   47  1418]]

 [[29739     5]
  [   18   130]]

 [[28361    78]
  [   94  1359]]

 [[29879     0]
  [   13     0]]

 [[29731    10]
  [   22   129]]

 [[28940    48]
  [   45   859]]

 [[29777     7]
  [   24    84]]

 [[29792     7]
  [    6    87]]

 [[29858     1]
  [    3    30]]

 [[29833     9]
  [    3    47]]

 [[29728    11]
  [   19   134]]]

===scores report===
metrics	scores
Accuracy	0.8687
MCC	0.8617
log_loss	0.5660
f1 score weighted	0.8683
f1 score macro	0.8060
f1 score micro	0.8687
roc_auc ovr	0.9923
roc_auc ovo	0.9906
precision	0.8706
recall	0.8687

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f07001e2940>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f07001e2790>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f07001e2970>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f07001e26a0>, 'x_test': array([[13, 11,  3, ...,  0,  0,  0],
       [13, 17,  4, ...,  0,  0,  0],
       [13,  1, 11, ...,  0,  0,  0],
       ...,
       [10,  6,  6, ...,  8, 16, 11],
       [13, 15,  3, ...,  0,  0,  0],
       [15,  8, 19, ...,  8,  8,  9]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.87      0.87       911
         1.0       1.00      0.58      0.74        53
         2.0       0.96      0.64      0.77       180
         3.0       1.00      0.04      0.08        25
         4.0       0.75      0.37      0.49       111
         5.0       0.85      0.60      0.70       491
         6.0       0.98      0.64      0.77        64
         7.0       1.00      0.08      0.15        37
         8.0       0.86      0.82      0.84       205
         9.0       0.78      0.72      0.75        71
        10.0       0.82      0.90      0.86       404
        11.0       1.00      0.06      0.11        17
        12.0       0.88      0.77      0.82       378
        13.0       0.87      0.76      0.82       191
        14.0       1.00      0.03      0.05        76
        15.0       0.76      0.58      0.66        66
        16.0       0.99      0.64      0.78       140
        17.0       0.91      0.60      0.73       182
        18.0       1.00      0.75      0.86        12
        19.0       1.00      0.68      0.81        37
        20.0       0.83      0.94      0.88      2162
        21.0       0.98      0.93      0.95       168
        22.0       0.71      0.84      0.77      1470
        23.0       0.88      0.83      0.86      1259
        24.0       0.88      0.86      0.87       955
        25.0       0.96      0.84      0.89       283
        26.0       0.74      0.94      0.83      3919
        27.0       0.98      0.90      0.94       532
        28.0       0.91      0.77      0.83        13
        29.0       0.72      0.78      0.75      2345
        30.0       0.78      0.47      0.59       616
        31.0       1.00      0.78      0.88        32
        32.0       0.68      0.80      0.73      1449
        33.0       0.91      0.68      0.78       893
        34.0       0.90      0.86      0.88      1377
        35.0       0.90      0.41      0.56        22
        36.0       0.87      0.80      0.83       844
        37.0       0.96      0.81      0.88      1142
        38.0       0.94      0.84      0.89       314
        39.0       1.00      0.52      0.68        56
        40.0       0.91      0.71      0.79       153
        41.0       0.93      0.83      0.88        52
        42.0       0.91      0.75      0.82       247
        43.0       0.89      0.76      0.82       197
        44.0       0.87      0.88      0.87       529
        45.0       0.96      0.87      0.91       540
        46.0       0.00      0.00      0.00        20
        47.0       0.60      0.74      0.66        80
        48.0       0.92      0.98      0.95      1466
        49.0       0.98      0.80      0.88       148
        50.0       0.99      0.88      0.93      1453
        51.0       1.00      0.08      0.15        12
        52.0       0.99      0.87      0.93       151
        53.0       0.98      0.94      0.96       904
        54.0       0.94      0.68      0.78       108
        55.0       0.91      0.97      0.94        93
        56.0       1.00      0.88      0.94        33
        57.0       0.90      0.92      0.91        50
        58.0       0.88      0.88      0.88       154

    accuracy                           0.84     29892
   macro avg       0.89      0.70      0.74     29892
weighted avg       0.85      0.84      0.83     29892


===confusion_matrix===

[[789   0   0 ...   0   0   0]
 [  0  31   0 ...   0   0   0]
 [  0   0 115 ...   0   0   0]
 ...
 [  0   0   0 ...  29   0   1]
 [  0   0   0 ...   0  46   3]
 [  0   0   0 ...   0   4 136]]

===multilabel confusion matrix===

[[[28872   109]
  [  122   789]]

 [[29839     0]
  [   22    31]]

 [[29707     5]
  [   65   115]]

 [[29867     0]
  [   24     1]]

 [[29767    14]
  [   70    41]]

 [[29348    53]
  [  198   293]]

 [[29827     1]
  [   23    41]]

 [[29855     0]
  [   34     3]]

 [[29660    27]
  [   36   169]]

 [[29807    14]
  [   20    51]]

 [[29411    77]
  [   41   363]]

 [[29875     0]
  [   16     1]]

 [[29473    41]
  [   87   291]]

 [[29680    21]
  [   45   146]]

 [[29816     0]
  [   74     2]]

 [[29814    12]
  [   28    38]]

 [[29751     1]
  [   50    90]]

 [[29699    11]
  [   72   110]]

 [[29880     0]
  [    3     9]]

 [[29855     0]
  [   12    25]]

 [[27329   401]
  [  140  2022]]

 [[29720     4]
  [   11   157]]

 [[27927   495]
  [  231  1239]]

 [[28492   141]
  [  212  1047]]

 [[28824   113]
  [  135   820]]

 [[29598    11]
  [   45   238]]

 [[24682  1291]
  [  254  3665]]

 [[29350    10]
  [   55   477]]

 [[29878     1]
  [    3    10]]

 [[26818   729]
  [  508  1837]]

 [[29195    81]
  [  325   291]]

 [[29860     0]
  [    7    25]]

 [[27905   538]
  [  296  1153]]

 [[28936    63]
  [  285   608]]

 [[28381   134]
  [  196  1181]]

 [[29869     1]
  [   13     9]]

 [[28946   102]
  [  167   677]]

 [[28714    36]
  [  212   930]]

 [[29562    16]
  [   50   264]]

 [[29836     0]
  [   27    29]]

 [[29728    11]
  [   45   108]]

 [[29837     3]
  [    9    43]]

 [[29627    18]
  [   61   186]]

 [[29677    18]
  [   47   150]]

 [[29291    72]
  [   65   464]]

 [[29333    19]
  [   69   471]]

 [[29872     0]
  [   20     0]]

 [[29773    39]
  [   21    59]]

 [[28306   120]
  [   25  1441]]

 [[29741     3]
  [   29   119]]

 [[28423    16]
  [  174  1279]]

 [[29880     0]
  [   11     1]]

 [[29739     2]
  [   19   132]]

 [[28968    20]
  [   58   846]]

 [[29779     5]
  [   35    73]]

 [[29790     9]
  [    3    90]]

 [[29859     0]
  [    4    29]]

 [[29837     5]
  [    4    46]]

 [[29720    18]
  [   18   136]]]

===scores report===
metrics	scores
Accuracy	0.8350
MCC	0.8260
log_loss	0.6958
f1 score weighted	0.8320
f1 score macro	0.7448
f1 score micro	0.8350
roc_auc ovr	0.9895
roc_auc ovo	0.9853
precision	0.8464
recall	0.8350

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8444065301752978	0.8361633030938214	0.6620520673425878	0.8445009264750072	0.7659738096368531	0.8444065301752978	0.9898460959850003	0.9863949773631178	0.8511171076052443	0.8444065301752978
1	0.8084102769971899	0.8001699486573565	0.9195744567105172	0.8186281759588658	0.7427322893307783	0.8084102769971899	0.9869224455934157	0.9828642586229405	0.8588889300702676	0.8084102769971899
2	0.8432021945671082	0.8356511911282911	0.6893796005510684	0.8480901878852565	0.7836570031185158	0.8432021945671082	0.9904663317479898	0.9878870282369958	0.8683704557075275	0.8432021945671082
3	0.8687274187073465	0.8616744451701791	0.5659746825608387	0.8683046520472505	0.8059576182495	0.8687274187073465	0.9922923719332044	0.990557673613426	0.870634541323152	0.8687274187073465
4	0.8350394754449351	0.8260386229918346	0.6957719197388971	0.8319930804062181	0.7448261452396414	0.8350394754449351	0.9894556100762282	0.9852941700288981	0.8463535382602051	0.8350394754449351
mean	0.8399571791783753	0.8319395022082965	0.7065505453807818	0.8423034045545196	0.7686293731150577	0.8399571791783753	0.9897965710671677	0.9865996215730755	0.8590729145932793	0.8399571791783753
std	0.019377535338429782	0.0197985295911545	0.11621694770607169	0.016620469717704568	0.02393128568022873	0.019377535338429782	0.0017353331487748344	0.002569926505896023	0.009436384189402045	0.019377535338429782

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 81218.5033 secs

