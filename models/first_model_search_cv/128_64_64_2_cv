/home/amsequeira/enzymeClassification/models/first_model_search_cv/128_64_64_2_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f313e6df640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f313e6df460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f313e6df6a0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f313e6df340>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.43      0.84      0.57      4541
         1.0       0.33      0.02      0.04      3813
         2.0       0.44      0.62      0.51     10869
         3.0       0.41      0.21      0.28      6897
         4.0       0.45      0.00      0.00      2585
         5.0       0.61      0.03      0.05      1617
         6.0       0.38      0.66      0.48      3258
         7.0       0.58      0.46      0.52      1372

    accuracy                           0.43     34952
   macro avg       0.46      0.36      0.31     34952
weighted avg       0.43      0.43      0.36     34952


===confusion_matrix===

[[3819    3  380  239    0    2   48   50]
 [ 510   87 2192  393    0    3  601   27]
 [1759   61 6754  766    2    9 1314  204]
 [1931   37 2706 1477    2    9  592  143]
 [ 227   35 1447  323    5    1  535   12]
 [ 206   27  895  142    2   44  297    4]
 [ 131   15  816  142    0    3 2139   12]
 [ 298    0  287   79    0    1   74  633]]

===multilabel confusion matrix===

[[[25349  5062]
  [  722  3819]]

 [[30961   178]
  [ 3726    87]]

 [[15360  8723]
  [ 4115  6754]]

 [[25971  2084]
  [ 5420  1477]]

 [[32361     6]
  [ 2580     5]]

 [[33307    28]
  [ 1573    44]]

 [[28233  3461]
  [ 1119  2139]]

 [[33128   452]
  [  739   633]]]

===scores report===
metrics	scores
Accuracy	0.4280
MCC	0.2904
log_loss	1.5254
f1 score weighted	0.3617
f1 score macro	0.3076
f1 score micro	0.4280
roc_auc ovr	0.7581
roc_auc ovo	0.7762
precision	0.4296
recall	0.4280

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f313e6df640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f313e6df460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f313e6df6a0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f313e6df340>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.76      0.75      4541
         1.0       0.92      0.78      0.84      3813
         2.0       0.96      0.77      0.85     10869
         3.0       0.77      0.84      0.80      6897
         4.0       0.63      0.91      0.75      2585
         5.0       0.73      0.87      0.79      1616
         6.0       0.83      0.97      0.89      3258
         7.0       0.94      0.94      0.94      1372

    accuracy                           0.82     34951
   macro avg       0.81      0.85      0.83     34951
weighted avg       0.84      0.82      0.83     34951


===confusion_matrix===

[[3452   39  132  576  145   77   77   43]
 [ 115 2971   63  257  241   89   68    9]
 [ 572  125 8373  716  559  187  329    8]
 [ 379   57  109 5761  325  118  130   18]
 [  39   13   33   90 2353   32   25    0]
 [  31   10   22   63   60 1402   27    1]
 [  20    6   13   23   25   16 3155    0]
 [  27    6    2   15   22    2    8 1290]]

===multilabel confusion matrix===

[[[29227  1183]
  [ 1089  3452]]

 [[30882   256]
  [  842  2971]]

 [[23708   374]
  [ 2496  8373]]

 [[26314  1740]
  [ 1136  5761]]

 [[30989  1377]
  [  232  2353]]

 [[32814   521]
  [  214  1402]]

 [[31029   664]
  [  103  3155]]

 [[33500    79]
  [   82  1290]]]

===scores report===
metrics	scores
Accuracy	0.8228
MCC	0.7893
log_loss	0.5504
f1 score weighted	0.8250
f1 score macro	0.8276
f1 score micro	0.8228
roc_auc ovr	0.9750
roc_auc ovo	0.9798
precision	0.8408
recall	0.8228

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f313e6df640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f313e6df460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f313e6df6a0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f313e6df340>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 1., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 1., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.81      0.79      4542
         1.0       0.84      0.91      0.88      3814
         2.0       0.92      0.91      0.91     10869
         3.0       0.86      0.83      0.85      6896
         4.0       0.87      0.89      0.88      2584
         5.0       0.93      0.86      0.90      1616
         6.0       0.97      0.96      0.97      3258
         7.0       0.96      0.97      0.96      1372

    accuracy                           0.88     34951
   macro avg       0.89      0.89      0.89     34951
weighted avg       0.89      0.88      0.88     34951


===confusion_matrix===

[[3658  120  279  357   64   17   17   30]
 [  85 3473  100   89   47    7    3   10]
 [ 379  173 9906  265   86   29   27    4]
 [ 444  218  322 5735  116   27   19   15]
 [  38   57   75   94 2306    9    5    0]
 [  51   41   53   54   16 1393    8    0]
 [  18   28   43   31   15    9 3114    0]
 [  16   11    7   11    1    1    1 1324]]

===multilabel confusion matrix===

[[[29378  1031]
  [  884  3658]]

 [[30489   648]
  [  341  3473]]

 [[23203   879]
  [  963  9906]]

 [[27154   901]
  [ 1161  5735]]

 [[32022   345]
  [  278  2306]]

 [[33236    99]
  [  223  1393]]

 [[31613    80]
  [  144  3114]]

 [[33520    59]
  [   48  1324]]]

===scores report===
metrics	scores
Accuracy	0.8844
MCC	0.8588
log_loss	0.3692
f1 score weighted	0.8846
f1 score macro	0.8918
f1 score micro	0.8844
roc_auc ovr	0.9855
roc_auc ovo	0.9880
precision	0.8854
recall	0.8844

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f313e6df640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f313e6df460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f313e6df6a0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f313e6df340>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        ...,
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 1., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 1.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.68      0.76      4542
         1.0       0.93      0.83      0.88      3813
         2.0       0.90      0.91      0.90     10868
         3.0       0.76      0.90      0.82      6897
         4.0       0.89      0.87      0.88      2585
         5.0       0.89      0.86      0.87      1616
         6.0       0.93      0.97      0.95      3258
         7.0       0.97      0.96      0.96      1372

    accuracy                           0.87     34951
   macro avg       0.89      0.87      0.88     34951
weighted avg       0.87      0.87      0.87     34951


===confusion_matrix===

[[3076   61  363  895   35   34   51   27]
 [  41 3159  202  289   45   34   36    7]
 [ 235   80 9842  493   89   33   92    4]
 [ 189   41  319 6179   73   41   51    4]
 [  19   19  106  166 2249   16   10    0]
 [  17   21   62   88   32 1386   10    0]
 [  12    5   37   45    9    4 3146    0]
 [  16    6    7   22    0    4    0 1317]]

===multilabel confusion matrix===

[[[29880   529]
  [ 1466  3076]]

 [[30905   233]
  [  654  3159]]

 [[22987  1096]
  [ 1026  9842]]

 [[26056  1998]
  [  718  6179]]

 [[32083   283]
  [  336  2249]]

 [[33169   166]
  [  230  1386]]

 [[31443   250]
  [  112  3146]]

 [[33537    42]
  [   55  1317]]]

===scores report===
metrics	scores
Accuracy	0.8685
MCC	0.8397
log_loss	0.4254
f1 score weighted	0.8677
f1 score macro	0.8773
f1 score micro	0.8685
roc_auc ovr	0.9834
roc_auc ovo	0.9860
precision	0.8728
recall	0.8685

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f313e6df640>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f313e6df460>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f313e6df6a0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f313e6df340>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 1., 0., ..., 0., 0., 0.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       [[0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.79      0.81      4542
         1.0       0.95      0.86      0.90      3813
         2.0       0.94      0.92      0.93     10868
         3.0       0.82      0.92      0.86      6897
         4.0       0.88      0.92      0.90      2585
         5.0       0.95      0.89      0.92      1616
         6.0       0.97      0.96      0.97      3258
         7.0       0.97      0.95      0.96      1372

    accuracy                           0.90     34951
   macro avg       0.91      0.90      0.91     34951
weighted avg       0.90      0.90      0.90     34951


===confusion_matrix===

[[3599   51  251  563   40    8    7   23]
 [  77 3282  135  209   64   13   23   10]
 [ 277   37 9977  425  110   17   21    4]
 [ 248   43  180 6329   58   12   19    8]
 [  32   18   51   96 2370   15    3    0]
 [  39    7   33   56   28 1446    7    0]
 [  20    4   32   61   10    8 3123    0]
 [  32   14   10   14    0    1    1 1300]]

===multilabel confusion matrix===

[[[29684   725]
  [  943  3599]]

 [[30964   174]
  [  531  3282]]

 [[23391   692]
  [  891  9977]]

 [[26630  1424]
  [  568  6329]]

 [[32056   310]
  [  215  2370]]

 [[33261    74]
  [  170  1446]]

 [[31612    81]
  [  135  3123]]

 [[33534    45]
  [   72  1300]]]

===scores report===
metrics	scores
Accuracy	0.8991
MCC	0.8769
log_loss	0.3658
f1 score weighted	0.8995
f1 score macro	0.9064
f1 score micro	0.8991
roc_auc ovr	0.9887
roc_auc ovo	0.9905
precision	0.9018
recall	0.8991

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.427958342870222	0.29036594194588977	1.525406258496743	0.36170407677573296	0.30763524620999483	0.427958342870222	0.7581188740748478	0.7762372014734423	0.4296283704356283	0.427958342870222
1	0.822780464078281	0.789330240686843	0.5504290082512663	0.8250433241613353	0.8275974545389134	0.822780464078281	0.9749580338239111	0.9797815741338836	0.8408092077311932	0.822780464078281
2	0.8843523790449487	0.8588218441224498	0.3692375082580644	0.8845716446892777	0.8917872287832923	0.8843523790449487	0.9855165954079458	0.9879620039853289	0.8854340564958765	0.8843523790449487
3	0.8684730050642328	0.8396862903006309	0.4254376616553107	0.8677405064285078	0.8773292960282062	0.8684730050642328	0.9834129990201665	0.9859533326519648	0.8727746692156618	0.8684730050642328
4	0.8991445166089669	0.8769365400856399	0.36579481212003084	0.8995045057042772	0.9064243285599631	0.8991445166089669	0.9886878274100099	0.9905115816094064	0.9018292975967088	0.8991445166089669
mean	0.7805417415333303	0.7310281714282907	0.6472610497562831	0.7677128115518261	0.7621547108240739	0.7805417415333303	0.9381388659473762	0.9440891387708052	0.7860951202950137	0.7805417415333303
std	0.1781428283807178	0.22226533395651946	0.4441264234338616	0.20452895035310556	0.22880305671430434	0.1781428283807178	0.0901248494880165	0.08400083931387786	0.1793533625899408	0.1781428283807178

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 96086.6475 secs

