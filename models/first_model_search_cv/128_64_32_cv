/home/amsequeira/enzymeClassification/models/first_model_search_cv/128_64_32_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcefc713d60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcefc713ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcefc713f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fcefc713b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.55      0.80      0.65      4541
         1.0       0.85      0.43      0.57      3813
         2.0       0.74      0.65      0.70     10869
         3.0       0.55      0.65      0.60      6897
         4.0       0.95      0.30      0.46      2585
         5.0       0.59      0.52      0.55      1617
         6.0       0.53      0.93      0.67      3258
         7.0       0.98      0.66      0.79      1372

    accuracy                           0.64     34952
   macro avg       0.72      0.62      0.62     34952
weighted avg       0.69      0.64      0.63     34952


===confusion_matrix===

[[3612   18  240  499    0   14  147   11]
 [ 270 1657  645  775   10  144  312    0]
 [1024   92 7102 1278   20  181 1172    0]
 [1065   46  661 4456    6  148  504   11]
 [ 125   72  574  583  777   72  382    0]
 [ 120   36  191  266    1  837  165    1]
 [  28    3   85   98    0   21 3023    0]
 [ 279   27   39   80    2    2   38  905]]

===multilabel confusion matrix===

[[[27500  2911]
  [  929  3612]]

 [[30845   294]
  [ 2156  1657]]

 [[21648  2435]
  [ 3767  7102]]

 [[24476  3579]
  [ 2441  4456]]

 [[32328    39]
  [ 1808   777]]

 [[32753   582]
  [  780   837]]

 [[28974  2720]
  [  235  3023]]

 [[33557    23]
  [  467   905]]]

===scores report===
metrics	scores
Accuracy	0.6400
MCC	0.5664
log_loss	1.0329
f1 score weighted	0.6346
f1 score macro	0.6235
f1 score micro	0.6400
roc_auc ovr	0.9052
roc_auc ovo	0.9160
precision	0.6907
recall	0.6400

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcefc713d60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcefc713ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcefc713f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fcefc713b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.81      0.77      4541
         1.0       0.86      0.87      0.86      3813
         2.0       0.91      0.87      0.89     10869
         3.0       0.90      0.75      0.82      6897
         4.0       0.57      0.93      0.71      2585
         5.0       0.94      0.79      0.86      1616
         6.0       0.99      0.91      0.95      3258
         7.0       0.92      0.96      0.94      1372

    accuracy                           0.85     34951
   macro avg       0.85      0.86      0.85     34951
weighted avg       0.87      0.85      0.85     34951


===confusion_matrix===

[[3682   98  261  221  191   18    4   66]
 [  96 3306  103   71  216    5    0   16]
 [ 475  193 9487  196  490   18    4    6]
 [ 536  137  364 5174  640   25    4   17]
 [  52   29   51   44 2394   10    1    4]
 [  67   41   55   28  146 1275    2    2]
 [  39   34   67   27  112    4 2974    1]
 [  16   10    7   10   10    0    0 1319]]

===multilabel confusion matrix===

[[[29129  1281]
  [  859  3682]]

 [[30596   542]
  [  507  3306]]

 [[23174   908]
  [ 1382  9487]]

 [[27457   597]
  [ 1723  5174]]

 [[30561  1805]
  [  191  2394]]

 [[33255    80]
  [  341  1275]]

 [[31678    15]
  [  284  2974]]

 [[33467   112]
  [   53  1319]]]

===scores report===
metrics	scores
Accuracy	0.8472
MCC	0.8164
log_loss	0.4773
f1 score weighted	0.8511
f1 score macro	0.8506
f1 score micro	0.8472
roc_auc ovr	0.9799
roc_auc ovo	0.9835
precision	0.8655
recall	0.8472

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcefc713d60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcefc713ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcefc713f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fcefc713b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 1., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 1., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.76      0.78      4542
         1.0       0.75      0.92      0.82      3814
         2.0       0.93      0.85      0.89     10869
         3.0       0.91      0.77      0.83      6896
         4.0       0.91      0.85      0.88      2584
         5.0       0.73      0.90      0.81      1616
         6.0       0.71      0.98      0.82      3258
         7.0       0.98      0.91      0.94      1372

    accuracy                           0.85     34951
   macro avg       0.84      0.87      0.85     34951
weighted avg       0.86      0.85      0.85     34951


===confusion_matrix===

[[3451  219  238  223   24  123  251   13]
 [  62 3491   58   60   20   30   87    6]
 [ 336  415 9213  168   81  132  523    1]
 [ 398  294  258 5319   81  196  340   10]
 [  26  123   58   62 2200   41   74    0]
 [  27   52   18   19    7 1454   39    0]
 [   7   13   13    7    2    8 3208    0]
 [  40   51   10    6    0    1   10 1254]]

===multilabel confusion matrix===

[[[29513   896]
  [ 1091  3451]]

 [[29970  1167]
  [  323  3491]]

 [[23429   653]
  [ 1656  9213]]

 [[27510   545]
  [ 1577  5319]]

 [[32152   215]
  [  384  2200]]

 [[32804   531]
  [  162  1454]]

 [[30369  1324]
  [   50  3208]]

 [[33549    30]
  [  118  1254]]]

===scores report===
metrics	scores
Accuracy	0.8466
MCC	0.8165
log_loss	0.4917
f1 score weighted	0.8479
f1 score macro	0.8473
f1 score micro	0.8466
roc_auc ovr	0.9807
roc_auc ovo	0.9844
precision	0.8599
recall	0.8466

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcefc713d60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcefc713ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcefc713f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fcefc713b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       ...,

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        ...,
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 1., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 0., 0., 1.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 1., 0.]]], dtype=float32), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.66      0.71      4542
         1.0       0.88      0.75      0.81      3813
         2.0       0.76      0.91      0.83     10868
         3.0       0.81      0.72      0.76      6897
         4.0       0.94      0.72      0.81      2585
         5.0       0.92      0.73      0.81      1616
         6.0       0.76      0.96      0.85      3258
         7.0       0.96      0.88      0.92      1372

    accuracy                           0.81     34951
   macro avg       0.85      0.79      0.81     34951
weighted avg       0.81      0.81      0.80     34951


===confusion_matrix===

[[3013   75  783  508   13   14  111   25]
 [  86 2852  527  149   33   13  141   12]
 [ 306   96 9929  217   13   21  284    2]
 [ 339   84 1113 4977   48   31  295   10]
 [  32   84  344  162 1852   27   81    3]
 [  47   33  179   73   11 1183   90    0]
 [  15   11   78   17    2    0 3135    0]
 [  53   20   55   27    2    0    9 1206]]

===multilabel confusion matrix===

[[[29531   878]
  [ 1529  3013]]

 [[30735   403]
  [  961  2852]]

 [[21004  3079]
  [  939  9929]]

 [[26901  1153]
  [ 1920  4977]]

 [[32244   122]
  [  733  1852]]

 [[33229   106]
  [  433  1183]]

 [[30682  1011]
  [  123  3135]]

 [[33527    52]
  [  166  1206]]]

===scores report===
metrics	scores
Accuracy	0.8053
MCC	0.7616
log_loss	0.5790
f1 score weighted	0.8030
f1 score macro	0.8135
f1 score micro	0.8053
roc_auc ovr	0.9689
roc_auc ovo	0.9727
precision	0.8137
recall	0.8053

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fcefc713d60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fcefc713ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fcefc713f10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fcefc713b80>, 'x_test': array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 1., 0., ..., 0., 0., 0.]],

       ...,

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]],

       [[1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        ...,
        [1., 0., 0., ..., 0., 0., 0.],
        [1., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 1.]],

       [[0., 0., 0., ..., 0., 0., 1.],
        [0., 0., 0., ..., 1., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.46      0.85      0.60      4542
         1.0       0.74      0.46      0.56      3813
         2.0       0.74      0.54      0.62     10868
         3.0       0.66      0.39      0.49      6897
         4.0       0.27      0.75      0.40      2585
         5.0       0.60      0.36      0.45      1616
         6.0       0.79      0.71      0.75      3258
         7.0       0.86      0.73      0.79      1372

    accuracy                           0.57     34951
   macro avg       0.64      0.60      0.58     34951
weighted avg       0.66      0.57      0.58     34951


===confusion_matrix===

[[3861   51  198  217  139    5   30   41]
 [ 492 1748  486  269  631   81   84   22]
 [1576  235 5832  586 2207  134  244   54]
 [1759  189  771 2661 1251   83  147   36]
 [ 217   60  177   93 1950   40   48    0]
 [ 228   62  148   88  464  578   44    4]
 [ 115   22  192  106  456   42 2324    1]
 [ 185   11   63   41   61    0    9 1002]]

===multilabel confusion matrix===

[[[25837  4572]
  [  681  3861]]

 [[30508   630]
  [ 2065  1748]]

 [[22048  2035]
  [ 5036  5832]]

 [[26654  1400]
  [ 4236  2661]]

 [[27157  5209]
  [  635  1950]]

 [[32950   385]
  [ 1038   578]]

 [[31087   606]
  [  934  2324]]

 [[33421   158]
  [  370  1002]]]

===scores report===
metrics	scores
Accuracy	0.5710
MCC	0.5046
log_loss	1.1535
f1 score weighted	0.5798
f1 score macro	0.5824
f1 score micro	0.5710
roc_auc ovr	0.8841
roc_auc ovo	0.8995
precision	0.6553
recall	0.5710

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6399919890135042	0.5663673119881157	1.0328950669472192	0.6345861574663489	0.6234690819012079	0.6399919890135042	0.9051968827536514	0.9159658931099031	0.690658741508648	0.6399919890135042
1	0.8472146719693285	0.8164335735819109	0.47725196386995716	0.8510920975776135	0.8505523350256969	0.8472146719693285	0.9799337152053329	0.9834647932355176	0.8654580658664467	0.8472146719693285
2	0.8466138307916797	0.8164584030500993	0.4916737520473481	0.8479313994309619	0.8473199883737208	0.8466138307916797	0.980732169222267	0.9843976184738501	0.8598541054651281	0.8466138307916797
3	0.8053274584418185	0.761566166636694	0.5789635097625393	0.8029956443770496	0.8135346166623099	0.8053274584418185	0.9688550844313338	0.9727379916217337	0.8137238821591928	0.8053274584418185
4	0.5709707876741724	0.5045889646901115	1.153466182858095	0.579790018378399	0.5823960363585632	0.5709707876741724	0.8840800759826997	0.899469198862341	0.6552520694632523	0.5709707876741724
mean	0.7420237475781006	0.6930828839893863	0.7468500950970316	0.7432790634460746	0.7434544116642996	0.7420237475781006	0.9437595855190569	0.9512070990606689	0.7769893728925336	0.7420237475781006
std	0.11461341172629022	0.13169181077729433	0.28745169774955365	0.11374062375535464	0.11619426660601534	0.11461341172629022	0.04087554176516723	0.036123404215736295	0.087539301657342	0.11461341172629022

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 77634.2301 secs

