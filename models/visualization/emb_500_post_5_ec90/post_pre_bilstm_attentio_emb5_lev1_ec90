/home/amsequeira/enzymeClassification/models/visualization/emb_500_post_5_ec90/post_pre_bilstm_attentio_emb5_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9498319730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f94983196d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9498319310>]/home/amsequeira/enzymeClassification/models/visualization/emb_500_post_5_ec90/post_pre_bilstm_attentio_emb5_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fed70299700>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fed702996a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fed702992e0>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.8016945257782936)
('Validation Accuracy mean: ', 0.7744596108794213)
('Training Loss mean: ', 0.6407214269042015)
('Validation Loss mean: ', 0.7466963985562325)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500)               0         
_________________________________________________________________
embedding (Embedding)        (None, 500, 5)            105       
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 128)          35840     
_________________________________________________________________
bidirectional_1 (Bidirection (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_2 (Bidirection (None, 500, 64)           41216     
_________________________________________________________________
attention (attention)        (None, 64)                564       
_________________________________________________________________
dense (Dense)                (None, 32)                2080      
_________________________________________________________________
batch_normalization (BatchNo (None, 32)                128       
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                528       
_________________________________________________________________
batch_normalization_1 (Batch (None, 16)                64        
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 7)                 119       
=================================================================
Total params: 179,460
Trainable params: 179,364
Non-trainable params: 96
_________________________________________________________________Finished run_model in 13054.0107 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fed70299640>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.83      0.88      0.85      3813
           1       0.92      0.88      0.90     10869
           2       0.84      0.85      0.85      6897
           3       0.86      0.86      0.86      2585
           4       0.90      0.85      0.88      1616
           5       0.89      0.96      0.93      3258
           6       0.97      0.95      0.96      1372

    accuracy                           0.88     30410
   macro avg       0.89      0.89      0.89     30410
weighted avg       0.88      0.88      0.88     30410


===confusion_matrix===

[[3337  161  185   53   11   51   15]
 [ 291 9588  643  128   60  152    7]
 [ 258  462 5881  116   54  108   18]
 [  67  101  134 2234   18   30    1]
 [  38   59   81   35 1377   24    2]
 [  24   38   47   14    5 3130    0]
 [  13   33   21    3    1    3 1298]]

===multilabel confusion matrix===

[[[25906   691]
  [  476  3337]]

 [[18687   854]
  [ 1281  9588]]

 [[22402  1111]
  [ 1016  5881]]

 [[27476   349]
  [  351  2234]]

 [[28645   149]
  [  239  1377]]

 [[26784   368]
  [  128  3130]]

 [[28995    43]
  [   74  1298]]]

===scores report===
metrics	scores
Accuracy	0.8828
MCC	0.8507
log_loss	0.4511
f1 score weighted	0.8829
f1 score macro	0.8889
f1 score micro	0.8828
roc_auc ovr	0.9834
roc_auc ovo	0.9867
precision	0.8838
recall	0.8828
/home/amsequeira/enzymeClassification/models/visualization/emb_500_post_5_ec90/post_pre_bilstm_attentio_emb5_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8dbc358730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8dbc3586d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8dbc358310>]/home/amsequeira/enzymeClassification/models/visualization/emb_500_post_5_ec90/post_pre_bilstm_attentio_emb5_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6eb8599730>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6eb85996d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6eb8599310>]/home/amsequeira/enzymeClassification/models/visualization/emb_500_post_5_ec90/post_pre_bilstm_attentio_emb5_lev1_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f65a3358d60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f65a3358eb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f65a3358f70>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.4992499996721744)
('Validation Accuracy mean: ', 0.24900000028312205)
('Training Loss mean: ', 1.5281129586696625)
('Validation Loss mean: ', 1.966904683113098)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500)               0         
_________________________________________________________________
embedding (Embedding)        (None, 500, 5)            105       
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 128)          35840     
_________________________________________________________________
bidirectional_1 (Bidirection (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_2 (Bidirection (None, 500, 64)           41216     
_________________________________________________________________
attention (attention)        (None, 64)                564       
_________________________________________________________________
dense (Dense)                (None, 32)                2080      
_________________________________________________________________
batch_normalization (BatchNo (None, 32)                128       
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                528       
_________________________________________________________________
batch_normalization_1 (Batch (None, 16)                64        
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 7)                 119       
=================================================================
Total params: 179,460
Trainable params: 179,364
Non-trainable params: 96
_________________________________________________________________Finished run_model in 105.2602 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f65a33403d0>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.00      0.00      0.00         8
           1       0.43      1.00      0.60        43
           2       0.00      0.00      0.00        21
           3       0.00      0.00      0.00        10
           4       0.00      0.00      0.00         7
           5       0.00      0.00      0.00         8
           6       0.00      0.00      0.00         3

    accuracy                           0.43       100
   macro avg       0.06      0.14      0.09       100
weighted avg       0.18      0.43      0.26       100


===confusion_matrix===

[[ 0  8  0  0  0  0  0]
 [ 0 43  0  0  0  0  0]
 [ 0 21  0  0  0  0  0]
 [ 0 10  0  0  0  0  0]
 [ 0  7  0  0  0  0  0]
 [ 0  8  0  0  0  0  0]
 [ 0  3  0  0  0  0  0]]

===multilabel confusion matrix===

[[[92  0]
  [ 8  0]]

 [[ 0 57]
  [ 0 43]]

 [[79  0]
  [21  0]]

 [[90  0]
  [10  0]]

 [[93  0]
  [ 7  0]]

 [[92  0]
  [ 8  0]]

 [[97  0]
  [ 3  0]]]

===scores report===
metrics	scores
Accuracy	0.4300
MCC	0.0000
log_loss	1.6854
f1 score weighted	0.2586
f1 score macro	0.0859
f1 score micro	0.4300
roc_auc ovr	0.5629
roc_auc ovo	0.5596
precision	0.1849
recall	0.4300
