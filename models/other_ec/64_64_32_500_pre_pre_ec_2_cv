/home/amsequeira/enzymeClassification/models/other_ec/64_64_32_500_pre_pre_ec_2_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ef998356220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ef9983564f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ef9983560a0>]/home/amsequeira/enzymeClassification/models/other_ec/64_64_32_500_pre_pre_ec_2_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6ef83b6430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6ef83b63a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6ef83b6490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6ef83b62e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([25., 25., 25., ...,  0.,  0.,  0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.78      0.76      4542
         1.0       0.68      0.88      0.77       912
         2.0       1.00      0.71      0.83        52
         3.0       0.97      0.64      0.77       179
         4.0       0.00      0.00      0.00        25
         5.0       0.81      0.26      0.39       112
         6.0       0.85      0.51      0.64       492
         7.0       0.98      0.80      0.88        65
         8.0       1.00      0.32      0.48        38
         9.0       0.80      0.82      0.81       205
        10.0       0.84      0.59      0.69        71
        11.0       0.72      0.92      0.81       405
        12.0       0.00      0.00      0.00        17
        13.0       0.60      0.76      0.67       378
        14.0       0.82      0.77      0.80       190
        15.0       0.00      0.00      0.00        76
        16.0       0.64      0.58      0.61        67
        17.0       0.84      0.81      0.83       140
        18.0       0.86      0.56      0.68       183
        19.0       1.00      0.75      0.86        12
        20.0       1.00      0.68      0.81        37
        21.0       0.96      0.85      0.90      2162
        22.0       0.92      0.83      0.87       169
        23.0       0.58      0.82      0.68      1470
        24.0       0.79      0.87      0.83      1259
        25.0       0.89      0.85      0.87       956
        26.0       0.77      0.94      0.85       282
        27.0       0.83      0.87      0.85      3918
        28.0       0.94      0.82      0.88       531
        29.0       0.89      0.62      0.73        13
        30.0       0.82      0.68      0.74      2345
        31.0       0.64      0.60      0.62       615
        32.0       1.00      0.59      0.75        32
        33.0       0.66      0.71      0.68      1450
        34.0       0.82      0.74      0.78       893
        35.0       0.94      0.81      0.87      1376
        36.0       0.75      0.55      0.63        22
        37.0       0.75      0.83      0.79       843
        38.0       0.74      0.88      0.80      1142
        39.0       0.96      0.87      0.91       314
        40.0       0.90      0.33      0.48        55
        41.0       0.93      0.68      0.78       154
        42.0       0.95      0.81      0.88        52
        43.0       0.82      0.80      0.81       247
        44.0       0.99      0.69      0.81       197
        45.0       0.84      0.87      0.86       530
        46.0       0.98      0.84      0.90       540
        47.0       0.67      0.11      0.18        19
        48.0       1.00      0.32      0.48        79
        49.0       0.98      0.97      0.97      1465
        50.0       0.88      0.82      0.85       149
        51.0       0.94      0.91      0.93      1453
        52.0       0.00      0.00      0.00        12
        53.0       0.83      0.83      0.83       152
        54.0       0.94      0.92      0.93       903
        55.0       0.76      0.79      0.77       108
        56.0       0.87      0.85      0.86        93
        57.0       0.67      0.81      0.73        32
        58.0       0.86      0.84      0.85        50
        59.0       0.80      0.84      0.82       154

    accuracy                           0.81     34434
   macro avg       0.79      0.68      0.71     34434
weighted avg       0.81      0.81      0.80     34434


===confusion_matrix===

[[3526   26    0 ...    0    2    8]
 [   5  807    0 ...    0    0    0]
 [   2    0   37 ...    0    0    0]
 ...
 [   0    0    0 ...   26    0    1]
 [   1    0    0 ...    0   42    5]
 [   3    0    0 ...    2    5  130]]

===multilabel confusion matrix===

[[[28663  1229]
  [ 1016  3526]]

 [[33148   374]
  [  105   807]]

 [[34382     0]
  [   15    37]]

 [[34251     4]
  [   64   115]]

 [[34409     0]
  [   25     0]]

 [[34315     7]
  [   83    29]]

 [[33896    46]
  [  240   252]]

 [[34368     1]
  [   13    52]]

 [[34396     0]
  [   26    12]]

 [[34188    41]
  [   36   169]]

 [[34355     8]
  [   29    42]]

 [[33887   142]
  [   34   371]]

 [[34417     0]
  [   17     0]]

 [[33866   190]
  [   90   288]]

 [[34213    31]
  [   44   146]]

 [[34358     0]
  [   76     0]]

 [[34345    22]
  [   28    39]]

 [[34273    21]
  [   26   114]]

 [[34234    17]
  [   80   103]]

 [[34422     0]
  [    3     9]]

 [[34397     0]
  [   12    25]]

 [[32186    86]
  [  324  1838]]

 [[34253    12]
  [   29   140]]

 [[32101   863]
  [  258  1212]]

 [[32881   294]
  [  166  1093]]

 [[33375   103]
  [  139   817]]

 [[34075    77]
  [   17   265]]

 [[29805   711]
  [  499  3419]]

 [[33874    29]
  [   93   438]]

 [[34420     1]
  [    5     8]]

 [[31728   361]
  [  750  1595]]

 [[33611   208]
  [  246   369]]

 [[34402     0]
  [   13    19]]

 [[32457   527]
  [  427  1023]]

 [[33394   147]
  [  233   660]]

 [[32985    73]
  [  264  1112]]

 [[34408     4]
  [   10    12]]

 [[33356   235]
  [  143   700]]

 [[32947   345]
  [  141  1001]]

 [[34110    10]
  [   41   273]]

 [[34377     2]
  [   37    18]]

 [[34272     8]
  [   50   104]]

 [[34380     2]
  [   10    42]]

 [[34145    42]
  [   50   197]]

 [[34236     1]
  [   62   135]]

 [[33816    88]
  [   68   462]]

 [[33885     9]
  [   87   453]]

 [[34414     1]
  [   17     2]]

 [[34355     0]
  [   54    25]]

 [[32938    31]
  [   44  1421]]

 [[34269    16]
  [   27   122]]

 [[32897    84]
  [  128  1325]]

 [[34422     0]
  [   12     0]]

 [[34256    26]
  [   26   126]]

 [[33474    57]
  [   70   833]]

 [[34299    27]
  [   23    85]]

 [[34329    12]
  [   14    79]]

 [[34389    13]
  [    6    26]]

 [[34377     7]
  [    8    42]]

 [[34248    32]
  [   24   130]]]

===scores report===
metrics	scores
Accuracy	0.8061
MCC	0.7947
log_loss	0.7887
f1 score weighted	0.8047
f1 score macro	0.7141
f1 score micro	0.8061
roc_auc ovr	0.9826
roc_auc ovo	0.9821
precision	0.8150
recall	0.8061

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6ef83b6430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6ef83b63a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6ef83b6490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6ef83b62e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([25., 13., 13., ...,  0.,  0.,  0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.81      0.73      4541
         1.0       0.77      0.84      0.80       912
         2.0       1.00      0.58      0.73        52
         3.0       0.87      0.53      0.66       179
         4.0       0.00      0.00      0.00        24
         5.0       0.74      0.21      0.32       112
         6.0       0.72      0.57      0.64       492
         7.0       0.90      0.70      0.79        64
         8.0       1.00      0.08      0.15        38
         9.0       0.90      0.74      0.81       205
        10.0       0.77      0.63      0.69        70
        11.0       0.81      0.80      0.81       405
        12.0       0.00      0.00      0.00        17
        13.0       0.60      0.59      0.60       377
        14.0       0.88      0.65      0.75       191
        15.0       0.00      0.00      0.00        76
        16.0       0.97      0.55      0.70        67
        17.0       0.81      0.74      0.78       140
        18.0       0.75      0.62      0.68       183
        19.0       1.00      0.92      0.96        12
        20.0       1.00      0.76      0.86        37
        21.0       0.76      0.91      0.83      2162
        22.0       0.97      0.89      0.93       168
        23.0       0.69      0.69      0.69      1470
        24.0       0.84      0.79      0.82      1259
        25.0       0.86      0.86      0.86       956
        26.0       0.82      0.84      0.83       282
        27.0       0.74      0.88      0.81      3918
        28.0       0.90      0.87      0.88       532
        29.0       0.50      0.08      0.13        13
        30.0       0.76      0.63      0.69      2346
        31.0       0.71      0.52      0.60       616
        32.0       0.92      0.75      0.83        32
        33.0       0.73      0.64      0.68      1449
        34.0       0.75      0.69      0.72       893
        35.0       0.93      0.78      0.85      1377
        36.0       1.00      0.05      0.09        22
        37.0       0.74      0.76      0.75       844
        38.0       0.90      0.77      0.83      1142
        39.0       0.82      0.83      0.82       314
        40.0       0.76      0.39      0.52        56
        41.0       0.97      0.57      0.72       153
        42.0       0.95      0.79      0.86        52
        43.0       0.88      0.76      0.82       246
        44.0       0.97      0.74      0.84       197
        45.0       0.89      0.76      0.82       530
        46.0       0.91      0.81      0.85       540
        47.0       0.00      0.00      0.00        20
        48.0       0.89      0.31      0.46        80
        49.0       0.87      0.97      0.92      1465
        50.0       0.91      0.79      0.84       148
        51.0       0.92      0.90      0.91      1453
        52.0       0.00      0.00      0.00        13
        53.0       0.88      0.81      0.85       151
        54.0       0.94      0.92      0.93       904
        55.0       0.88      0.54      0.67       108
        56.0       0.85      0.86      0.86        93
        57.0       0.68      0.70      0.69        33
        58.0       0.85      0.88      0.86        50
        59.0       0.78      0.81      0.79       153

    accuracy                           0.78     34434
   macro avg       0.77      0.63      0.67     34434
weighted avg       0.79      0.78      0.78     34434


===confusion_matrix===

[[3699    5    0 ...    0    2    2]
 [  17  765    0 ...    0    0    0]
 [   3    0   30 ...    0    0    0]
 ...
 [   1    0    0 ...   23    1    4]
 [   0    0    0 ...    1   44    2]
 [  10    0    0 ...    0    5  124]]

===multilabel confusion matrix===

[[[27998  1895]
  [  842  3699]]

 [[33298   224]
  [  147   765]]

 [[34382     0]
  [   22    30]]

 [[34241    14]
  [   84    95]]

 [[34410     0]
  [   24     0]]

 [[34314     8]
  [   89    23]]

 [[33830   112]
  [  211   281]]

 [[34365     5]
  [   19    45]]

 [[34396     0]
  [   35     3]]

 [[34213    16]
  [   54   151]]

 [[34351    13]
  [   26    44]]

 [[33953    76]
  [   80   325]]

 [[34417     0]
  [   17     0]]

 [[33912   145]
  [  155   222]]

 [[34226    17]
  [   67   124]]

 [[34358     0]
  [   76     0]]

 [[34366     1]
  [   30    37]]

 [[34270    24]
  [   36   104]]

 [[34214    37]
  [   69   114]]

 [[34422     0]
  [    1    11]]

 [[34397     0]
  [    9    28]]

 [[31637   635]
  [  188  1974]]

 [[34261     5]
  [   19   149]]

 [[32498   466]
  [  451  1019]]

 [[32991   184]
  [  259  1000]]

 [[33343   135]
  [  133   823]]

 [[34101    51]
  [   44   238]]

 [[29331  1185]
  [  458  3460]]

 [[33848    54]
  [   71   461]]

 [[34420     1]
  [   12     1]]

 [[31630   458]
  [  879  1467]]

 [[33689   129]
  [  297   319]]

 [[34400     2]
  [    8    24]]

 [[32640   345]
  [  526   923]]

 [[33336   205]
  [  277   616]]

 [[32977    80]
  [  309  1068]]

 [[34412     0]
  [   21     1]]

 [[33365   225]
  [  206   638]]

 [[33199    93]
  [  261   881]]

 [[34062    58]
  [   53   261]]

 [[34371     7]
  [   34    22]]

 [[34278     3]
  [   66    87]]

 [[34380     2]
  [   11    41]]

 [[34163    25]
  [   58   188]]

 [[34232     5]
  [   52   145]]

 [[33853    51]
  [  128   402]]

 [[33851    43]
  [  105   435]]

 [[34414     0]
  [   20     0]]

 [[34351     3]
  [   55    25]]

 [[32758   211]
  [   43  1422]]

 [[34274    12]
  [   31   117]]

 [[32863   118]
  [  142  1311]]

 [[34421     0]
  [   13     0]]

 [[34267    16]
  [   28   123]]

 [[33473    57]
  [   68   836]]

 [[34318     8]
  [   50    58]]

 [[34327    14]
  [   13    80]]

 [[34390    11]
  [   10    23]]

 [[34376     8]
  [    6    44]]

 [[34246    35]
  [   29   124]]]

===scores report===
metrics	scores
Accuracy	0.7814
MCC	0.7680
log_loss	0.8503
f1 score weighted	0.7768
f1 score macro	0.6715
f1 score micro	0.7814
roc_auc ovr	0.9781
roc_auc ovo	0.9757
precision	0.7859
recall	0.7814

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6ef83b6430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6ef83b63a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6ef83b6490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6ef83b62e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([25., 25., 25., ...,  0.,  0.,  0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.69      0.75      4541
         1.0       0.69      0.91      0.79       911
         2.0       1.00      0.60      0.75        53
         3.0       0.87      0.75      0.81       180
         4.0       0.75      0.12      0.21        25
         5.0       0.63      0.34      0.44       111
         6.0       0.83      0.56      0.67       491
         7.0       0.98      0.70      0.82        64
         8.0       0.86      0.16      0.27        37
         9.0       0.82      0.84      0.83       205
        10.0       0.94      0.48      0.64        71
        11.0       0.85      0.87      0.86       404
        12.0       0.00      0.00      0.00        17
        13.0       0.85      0.62      0.72       377
        14.0       0.88      0.71      0.79       191
        15.0       0.20      0.01      0.02        76
        16.0       0.83      0.45      0.59        66
        17.0       0.83      0.83      0.83       140
        18.0       0.73      0.68      0.70       182
        19.0       0.92      0.92      0.92        12
        20.0       0.97      0.84      0.90        37
        21.0       0.96      0.86      0.91      2162
        22.0       0.80      0.90      0.85       168
        23.0       0.86      0.71      0.78      1470
        24.0       0.94      0.80      0.87      1259
        25.0       0.93      0.85      0.89       956
        26.0       0.77      0.93      0.84       283
        27.0       0.63      0.93      0.75      3919
        28.0       0.96      0.89      0.92       532
        29.0       0.73      0.85      0.79        13
        30.0       0.83      0.63      0.71      2346
        31.0       0.82      0.45      0.58       616
        32.0       0.92      0.72      0.81        32
        33.0       0.62      0.75      0.68      1449
        34.0       0.67      0.77      0.72       893
        35.0       0.97      0.77      0.86      1377
        36.0       1.00      0.27      0.43        22
        37.0       0.68      0.82      0.74       844
        38.0       0.89      0.83      0.85      1142
        39.0       0.75      0.88      0.81       314
        40.0       0.96      0.46      0.63        56
        41.0       0.88      0.65      0.75       153
        42.0       0.92      0.67      0.78        52
        43.0       0.65      0.83      0.73       247
        44.0       0.82      0.76      0.79       197
        45.0       0.72      0.92      0.80       529
        46.0       0.85      0.88      0.86       540
        47.0       0.00      0.00      0.00        20
        48.0       0.71      0.38      0.49        80
        49.0       0.84      0.98      0.90      1466
        50.0       0.75      0.85      0.80       148
        51.0       0.84      0.93      0.88      1453
        52.0       0.00      0.00      0.00        12
        53.0       0.92      0.86      0.89       151
        54.0       0.93      0.93      0.93       904
        55.0       0.89      0.70      0.79       108
        56.0       0.90      0.88      0.89        93
        57.0       0.78      0.94      0.85        33
        58.0       0.68      0.84      0.75        50
        59.0       0.82      0.84      0.83       154

    accuracy                           0.79     34434
   macro avg       0.78      0.68      0.71     34434
weighted avg       0.81      0.79      0.79     34434


===confusion_matrix===

[[3130   19    0 ...    0    7    4]
 [   1  832    0 ...    0    0    0]
 [   2    1   32 ...    0    0    0]
 ...
 [   0    0    0 ...   31    0    1]
 [   0    0    0 ...    0   42    6]
 [   1    0    0 ...    1    8  129]]

===multilabel confusion matrix===

[[[29199   694]
  [ 1411  3130]]

 [[33150   373]
  [   79   832]]

 [[34381     0]
  [   21    32]]

 [[34234    20]
  [   45   135]]

 [[34408     1]
  [   22     3]]

 [[34301    22]
  [   73    38]]

 [[33887    56]
  [  216   275]]

 [[34369     1]
  [   19    45]]

 [[34396     1]
  [   31     6]]

 [[34192    37]
  [   32   173]]

 [[34361     2]
  [   37    34]]

 [[33969    61]
  [   51   353]]

 [[34417     0]
  [   17     0]]

 [[34017    40]
  [  142   235]]

 [[34224    19]
  [   55   136]]

 [[34354     4]
  [   75     1]]

 [[34362     6]
  [   36    30]]

 [[34270    24]
  [   24   116]]

 [[34206    46]
  [   59   123]]

 [[34421     1]
  [    1    11]]

 [[34396     1]
  [    6    31]]

 [[32197    75]
  [  309  1853]]

 [[34229    37]
  [   16   152]]

 [[32795   169]
  [  419  1051]]

 [[33113    62]
  [  250  1009]]

 [[33418    60]
  [  140   816]]

 [[34073    78]
  [   21   262]]

 [[28391  2124]
  [  284  3635]]

 [[33882    20]
  [   58   474]]

 [[34417     4]
  [    2    11]]

 [[31796   292]
  [  879  1467]]

 [[33757    61]
  [  338   278]]

 [[34400     2]
  [    9    23]]

 [[32308   677]
  [  357  1092]]

 [[33206   335]
  [  205   688]]

 [[33020    37]
  [  314  1063]]

 [[34412     0]
  [   16     6]]

 [[33259   331]
  [  156   688]]

 [[33171   121]
  [  199   943]]

 [[34026    94]
  [   37   277]]

 [[34377     1]
  [   30    26]]

 [[34267    14]
  [   53   100]]

 [[34379     3]
  [   17    35]]

 [[34076   111]
  [   43   204]]

 [[34205    32]
  [   47   150]]

 [[33712   193]
  [   44   485]]

 [[33811    83]
  [   66   474]]

 [[34413     1]
  [   20     0]]

 [[34342    12]
  [   50    30]]

 [[32689   279]
  [   25  1441]]

 [[34245    41]
  [   22   126]]

 [[32733   248]
  [  103  1350]]

 [[34422     0]
  [   12     0]]

 [[34272    11]
  [   21   130]]

 [[33471    59]
  [   60   844]]

 [[34317     9]
  [   32    76]]

 [[34332     9]
  [   11    82]]

 [[34392     9]
  [    2    31]]

 [[34364    20]
  [    8    42]]

 [[34251    29]
  [   25   129]]]

===scores report===
metrics	scores
Accuracy	0.7923
MCC	0.7814
log_loss	0.8233
f1 score weighted	0.7898
f1 score macro	0.7073
f1 score micro	0.7923
roc_auc ovr	0.9823
roc_auc ovo	0.9818
precision	0.8096
recall	0.7923

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6ef83b6430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6ef83b63a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6ef83b6490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6ef83b62e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([25., 25., 25., ...,  0.,  0.,  0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.79      0.76      4542
         1.0       0.66      0.92      0.77       911
         2.0       0.91      0.75      0.82        53
         3.0       0.96      0.54      0.69       179
         4.0       0.00      0.00      0.00        25
         5.0       0.44      0.38      0.40       112
         6.0       0.61      0.73      0.66       491
         7.0       0.96      0.81      0.88        64
         8.0       0.89      0.46      0.61        37
         9.0       0.90      0.78      0.84       206
        10.0       0.78      0.75      0.76        71
        11.0       0.92      0.82      0.87       404
        12.0       0.00      0.00      0.00        16
        13.0       0.70      0.66      0.68       378
        14.0       0.78      0.72      0.75       191
        15.0       0.00      0.00      0.00        76
        16.0       0.86      0.55      0.67        66
        17.0       0.93      0.65      0.77       141
        18.0       0.88      0.64      0.74       182
        19.0       0.85      0.92      0.88        12
        20.0       1.00      0.82      0.90        38
        21.0       0.86      0.93      0.89      2162
        22.0       0.99      0.89      0.93       168
        23.0       0.57      0.83      0.67      1470
        24.0       0.85      0.85      0.85      1259
        25.0       0.96      0.83      0.89       955
        26.0       0.85      0.90      0.87       283
        27.0       0.87      0.86      0.87      3919
        28.0       0.96      0.90      0.93       531
        29.0       1.00      0.75      0.86        12
        30.0       0.81      0.71      0.76      2346
        31.0       0.52      0.70      0.60       615
        32.0       1.00      0.62      0.77        32
        33.0       0.65      0.75      0.70      1449
        34.0       0.88      0.70      0.78       893
        35.0       0.97      0.77      0.86      1377
        36.0       0.80      0.18      0.30        22
        37.0       0.78      0.83      0.81       844
        38.0       0.87      0.87      0.87      1142
        39.0       0.87      0.87      0.87       314
        40.0       0.81      0.45      0.57        56
        41.0       0.94      0.59      0.73       154
        42.0       1.00      0.82      0.90        51
        43.0       0.79      0.78      0.79       247
        44.0       0.99      0.73      0.84       198
        45.0       0.93      0.82      0.87       529
        46.0       0.96      0.85      0.90       540
        47.0       1.00      0.05      0.10        20
        48.0       0.95      0.44      0.60        80
        49.0       0.99      0.94      0.97      1466
        50.0       0.93      0.78      0.85       148
        51.0       0.98      0.88      0.93      1453
        52.0       0.00      0.00      0.00        12
        53.0       0.95      0.83      0.89       151
        54.0       0.98      0.91      0.94       903
        55.0       0.76      0.78      0.77       108
        56.0       0.90      0.92      0.91        93
        57.0       1.00      0.79      0.88        33
        58.0       0.97      0.71      0.82        49
        59.0       0.84      0.79      0.81       154

    accuracy                           0.81     34433
   macro avg       0.81      0.69      0.73     34433
weighted avg       0.83      0.81      0.81     34433


===confusion_matrix===

[[3591   19    0 ...    0    0    2]
 [   3  835    0 ...    0    0    0]
 [   3    0   40 ...    0    0    0]
 ...
 [   1    0    0 ...   26    0    0]
 [   2    0    0 ...    0   35   11]
 [   5    1    0 ...    0    1  122]]

===multilabel confusion matrix===

[[[28602  1289]
  [  951  3591]]

 [[33094   428]
  [   76   835]]

 [[34376     4]
  [   13    40]]

 [[34250     4]
  [   82    97]]

 [[34408     0]
  [   25     0]]

 [[34267    54]
  [   70    42]]

 [[33710   232]
  [  135   356]]

 [[34367     2]
  [   12    52]]

 [[34394     2]
  [   20    17]]

 [[34210    17]
  [   45   161]]

 [[34347    15]
  [   18    53]]

 [[33999    30]
  [   73   331]]

 [[34417     0]
  [   16     0]]

 [[33946   109]
  [  127   251]]

 [[34203    39]
  [   54   137]]

 [[34355     2]
  [   76     0]]

 [[34361     6]
  [   30    36]]

 [[34285     7]
  [   49    92]]

 [[34235    16]
  [   65   117]]

 [[34419     2]
  [    1    11]]

 [[34395     0]
  [    7    31]]

 [[31933   338]
  [  154  2008]]

 [[34263     2]
  [   19   149]]

 [[32035   928]
  [  249  1221]]

 [[32991   183]
  [  190  1069]]

 [[33443    35]
  [  161   794]]

 [[34104    46]
  [   29   254]]

 [[30008   506]
  [  536  3383]]

 [[33883    19]
  [   54   477]]

 [[34421     0]
  [    3     9]]

 [[31686   401]
  [  677  1669]]

 [[33424   394]
  [  187   428]]

 [[34401     0]
  [   12    20]]

 [[32396   588]
  [  363  1086]]

 [[33458    82]
  [  265   628]]

 [[33027    29]
  [  314  1063]]

 [[34410     1]
  [   18     4]]

 [[33390   199]
  [  140   704]]

 [[33137   154]
  [  149   993]]

 [[34079    40]
  [   41   273]]

 [[34371     6]
  [   31    25]]

 [[34273     6]
  [   63    91]]

 [[34382     0]
  [    9    42]]

 [[34135    51]
  [   54   193]]

 [[34233     2]
  [   54   144]]

 [[33869    35]
  [   95   434]]

 [[33876    17]
  [   82   458]]

 [[34413     0]
  [   19     1]]

 [[34351     2]
  [   45    35]]

 [[32951    16]
  [   82  1384]]

 [[34276     9]
  [   32   116]]

 [[32957    23]
  [  173  1280]]

 [[34421     0]
  [   12     0]]

 [[34276     6]
  [   26   125]]

 [[33517    13]
  [   84   819]]

 [[34298    27]
  [   24    84]]

 [[34330    10]
  [    7    86]]

 [[34400     0]
  [    7    26]]

 [[34383     1]
  [   14    35]]

 [[34255    24]
  [   32   122]]]

===scores report===
metrics	scores
Accuracy	0.8127
MCC	0.8017
log_loss	0.7410
f1 score weighted	0.8139
f1 score macro	0.7263
f1 score micro	0.8127
roc_auc ovr	0.9844
roc_auc ovo	0.9841
precision	0.8262
recall	0.8127

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f6ef83b6430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f6ef83b63a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6ef83b6490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f6ef83b62e0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([25., 13., 13., ...,  0.,  0.,  0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.71      0.81      0.76      4542
         1.0       0.82      0.87      0.84       912
         2.0       0.95      0.68      0.79        53
         3.0       0.36      0.75      0.49       179
         4.0       0.00      0.00      0.00        25
         5.0       0.84      0.19      0.31       112
         6.0       0.80      0.56      0.66       492
         7.0       0.98      0.80      0.88        65
         8.0       0.56      0.39      0.46        38
         9.0       0.98      0.62      0.76       206
        10.0       0.65      0.72      0.68        71
        11.0       0.95      0.84      0.89       405
        12.0       0.00      0.00      0.00        17
        13.0       0.84      0.64      0.73       378
        14.0       0.95      0.61      0.74       191
        15.0       1.00      0.03      0.05        76
        16.0       0.76      0.52      0.61        66
        17.0       0.94      0.69      0.79       140
        18.0       0.66      0.71      0.69       182
        19.0       0.67      0.73      0.70        11
        20.0       1.00      0.78      0.88        37
        21.0       0.98      0.85      0.91      2163
        22.0       0.78      0.95      0.85       169
        23.0       0.92      0.69      0.79      1469
        24.0       0.66      0.88      0.75      1259
        25.0       0.95      0.82      0.88       955
        26.0       0.98      0.81      0.89       282
        27.0       0.76      0.90      0.82      3919
        28.0       1.00      0.82      0.90       531
        29.0       1.00      0.58      0.74        12
        30.0       0.79      0.67      0.73      2345
        31.0       0.51      0.74      0.60       615
        32.0       0.96      0.72      0.82        32
        33.0       0.76      0.71      0.73      1450
        34.0       0.89      0.67      0.76       893
        35.0       0.94      0.80      0.86      1376
        36.0       1.00      0.23      0.37        22
        37.0       0.66      0.84      0.74       843
        38.0       0.93      0.80      0.86      1142
        39.0       0.89      0.82      0.86       314
        40.0       1.00      0.38      0.55        56
        41.0       0.76      0.60      0.67       154
        42.0       0.96      0.85      0.90        52
        43.0       0.81      0.70      0.75       247
        44.0       1.00      0.66      0.79       198
        45.0       0.69      0.90      0.78       529
        46.0       0.97      0.78      0.86       539
        47.0       0.67      0.11      0.18        19
        48.0       0.93      0.51      0.66        80
        49.0       0.87      0.98      0.92      1466
        50.0       0.93      0.70      0.80       148
        51.0       0.93      0.91      0.92      1453
        52.0       0.00      0.00      0.00        12
        53.0       0.99      0.77      0.87       151
        54.0       0.77      0.97      0.86       903
        55.0       0.85      0.67      0.75       108
        56.0       0.82      0.91      0.86        93
        57.0       0.82      0.82      0.82        33
        58.0       0.70      0.86      0.77        49
        59.0       0.82      0.80      0.81       154

    accuracy                           0.80     34433
   macro avg       0.80      0.67      0.70     34433
weighted avg       0.82      0.80      0.80     34433


===confusion_matrix===

[[3693    8    0 ...    1    5    4]
 [   5  789    0 ...    0    0    0]
 [   4    0   36 ...    0    0    0]
 ...
 [   0    0    0 ...   27    1    2]
 [   0    0    0 ...    0   42    5]
 [   1    0    0 ...    0    9  123]]

===multilabel confusion matrix===

[[[28381  1510]
  [  849  3693]]

 [[33345   176]
  [  123   789]]

 [[34378     2]
  [   17    36]]

 [[34012   242]
  [   44   135]]

 [[34408     0]
  [   25     0]]

 [[34317     4]
  [   91    21]]

 [[33873    68]
  [  216   276]]

 [[34367     1]
  [   13    52]]

 [[34383    12]
  [   23    15]]

 [[34225     2]
  [   78   128]]

 [[34334    28]
  [   20    51]]

 [[34010    18]
  [   66   339]]

 [[34416     0]
  [   17     0]]

 [[34010    45]
  [  136   242]]

 [[34236     6]
  [   75   116]]

 [[34357     0]
  [   74     2]]

 [[34356    11]
  [   32    34]]

 [[34287     6]
  [   44    96]]

 [[34186    65]
  [   53   129]]

 [[34418     4]
  [    3     8]]

 [[34396     0]
  [    8    29]]

 [[32233    37]
  [  330  1833]]

 [[34218    46]
  [    9   160]]

 [[32881    83]
  [  459  1010]]

 [[32592   582]
  [  151  1108]]

 [[33439    39]
  [  175   780]]

 [[34146     5]
  [   54   228]]

 [[29392  1122]
  [  411  3508]]

 [[33900     2]
  [   93   438]]

 [[34421     0]
  [    5     7]]

 [[31680   408]
  [  777  1568]]

 [[33374   444]
  [  159   456]]

 [[34400     1]
  [    9    23]]

 [[32652   331]
  [  417  1033]]

 [[33463    77]
  [  295   598]]

 [[32984    73]
  [  280  1096]]

 [[34411     0]
  [   17     5]]

 [[33224   366]
  [  132   711]]

 [[33226    65]
  [  225   917]]

 [[34088    31]
  [   56   258]]

 [[34377     0]
  [   35    21]]

 [[34249    30]
  [   61    93]]

 [[34379     2]
  [    8    44]]

 [[34144    42]
  [   73   174]]

 [[34235     0]
  [   68   130]]

 [[33688   216]
  [   51   478]]

 [[33879    15]
  [  117   422]]

 [[34413     1]
  [   17     2]]

 [[34350     3]
  [   39    41]]

 [[32749   218]
  [   33  1433]]

 [[34277     8]
  [   44   104]]

 [[32874   106]
  [  127  1326]]

 [[34421     0]
  [   12     0]]

 [[34281     1]
  [   35   116]]

 [[33269   261]
  [   29   874]]

 [[34312    13]
  [   36    72]]

 [[34321    19]
  [    8    85]]

 [[34394     6]
  [    6    27]]

 [[34366    18]
  [    7    42]]

 [[34252    27]
  [   31   123]]]

===scores report===
metrics	scores
Accuracy	0.7997
MCC	0.7878
log_loss	0.8062
f1 score weighted	0.7991
f1 score macro	0.7014
f1 score micro	0.7997
roc_auc ovr	0.9837
roc_auc ovo	0.9823
precision	0.8189
recall	0.7997

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8060928152407504	0.7947461798551351	0.7887039599041885	0.8046930113965097	0.714064785358001	0.8060928152407504	0.9826065181745859	0.9820575177738681	0.8149707391741152	0.8060928152407504
1	0.7814079107858511	0.7679508329122507	0.850297838165686	0.7768044413267736	0.6714563171885458	0.7814079107858513	0.9781179188720172	0.9756967594308542	0.7858734414377341	0.7814079107858511
2	0.7922983098100714	0.7813612631707247	0.8233396012158998	0.7897527095642582	0.7073253791207612	0.7922983098100714	0.982319340333778	0.9818411387964998	0.8095525419878642	0.7922983098100714
3	0.8126506548950135	0.801700538853698	0.7409649588768703	0.8138840639255164	0.7262979028196526	0.8126506548950135	0.9843900460341322	0.9840820557054255	0.8262142069316122	0.8126506548950135
4	0.7996689222548137	0.7878268908760565	0.8061896752442881	0.7991266249835903	0.7014336575794922	0.7996689222548136	0.9836712257367195	0.9822519209214482	0.8189264146734342	0.7996689222548137
mean	0.7984237225973001	0.7867171411335729	0.8018992066813866	0.7968521702393296	0.7041156084132906	0.7984237225973	0.9822210098302465	0.9811858785256191	0.811107468840952	0.7984237225973001
std	0.010861212088723865	0.011584981377052982	0.03662682967675801	0.012720464719510893	0.01830390722539761	0.010861212088723827	0.002181810496451856	0.002858105599334344	0.013736435082240222	0.010861212088723865

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 73919.9911 secs

