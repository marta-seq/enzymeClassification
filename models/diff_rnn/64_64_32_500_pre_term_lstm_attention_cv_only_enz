/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_term_lstm_attention_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa8a019c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa8a019c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa8a019c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa8a019c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.79      0.85      3813
         1.0       0.77      0.97      0.86     10869
         2.0       0.91      0.73      0.81      6897
         3.0       0.95      0.77      0.85      2585
         4.0       0.96      0.80      0.87      1616
         5.0       0.98      0.91      0.94      3258
         6.0       0.96      0.95      0.95      1372

    accuracy                           0.86     30410
   macro avg       0.92      0.84      0.88     30410
weighted avg       0.88      0.86      0.86     30410


===confusion_matrix===

[[ 3029   583   149    20    12     9    11]
 [   77 10566   160    23    14    20     9]
 [   94  1662  5026    41    21    20    33]
 [   35   473    80  1981     8     8     0]
 [   22   223    55    13  1292    11     0]
 [   12   258    35     2     1  2949     1]
 [   11    45    10     3     2     0  1301]]

===multilabel confusion matrix===

[[[26346   251]
  [  784  3029]]

 [[16297  3244]
  [  303 10566]]

 [[23024   489]
  [ 1871  5026]]

 [[27723   102]
  [  604  1981]]

 [[28736    58]
  [  324  1292]]

 [[27084    68]
  [  309  2949]]

 [[28984    54]
  [   71  1301]]]

===scores report===
metrics	scores
Accuracy	0.8597
MCC	0.8230
log_loss	0.4201
f1 score weighted	0.8590
f1 score macro	0.8763
f1 score micro	0.8597
roc_auc ovr	0.9815
roc_auc ovo	0.9841
precision	0.8757
recall	0.8597

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa8a019c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa8a019c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa8a019c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa8a019c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.86      0.87      3813
         1.0       0.93      0.88      0.90     10869
         2.0       0.83      0.88      0.85      6897
         3.0       0.81      0.88      0.84      2585
         4.0       0.91      0.87      0.89      1616
         5.0       0.94      0.95      0.95      3258
         6.0       0.94      0.97      0.96      1372

    accuracy                           0.89     30410
   macro avg       0.89      0.90      0.90     30410
weighted avg       0.89      0.89      0.89     30410


===confusion_matrix===

[[3268  159  229  101   25   16   15]
 [ 149 9610  725  221   37   87   40]
 [ 131  418 6078  140   52   57   21]
 [  47   96  141 2273   17   10    1]
 [  34   47   80   31 1413    8    3]
 [  21   47   54   34   10 3092    0]
 [  12    8   18    3    0    2 1329]]

===multilabel confusion matrix===

[[[26203   394]
  [  545  3268]]

 [[18766   775]
  [ 1259  9610]]

 [[22266  1247]
  [  819  6078]]

 [[27295   530]
  [  312  2273]]

 [[28653   141]
  [  203  1413]]

 [[26972   180]
  [  166  3092]]

 [[28958    80]
  [   43  1329]]]

===scores report===
metrics	scores
Accuracy	0.8899
MCC	0.8599
log_loss	0.3237
f1 score weighted	0.8904
f1 score macro	0.8959
f1 score micro	0.8899
roc_auc ovr	0.9857
roc_auc ovo	0.9884
precision	0.8919
recall	0.8899

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa8a019c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa8a019c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa8a019c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa8a019c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.85      0.85      3814
         1.0       0.88      0.90      0.89     10869
         2.0       0.82      0.86      0.84      6896
         3.0       0.92      0.81      0.86      2584
         4.0       0.95      0.83      0.88      1617
         5.0       0.96      0.93      0.95      3258
         6.0       0.94      0.96      0.95      1372

    accuracy                           0.88     30410
   macro avg       0.90      0.88      0.89     30410
weighted avg       0.88      0.88      0.88     30410


===confusion_matrix===

[[3239  252  239   35   10   15   24]
 [ 217 9821  669   65   20   49   28]
 [ 157  650 5965   47   26   29   22]
 [  65  196  200 2100   11    8    4]
 [  60   80  108   15 1336   10    8]
 [  48  110   58    8    3 3030    1]
 [   9   19   17    5    1    2 1319]]

===multilabel confusion matrix===

[[[26040   556]
  [  575  3239]]

 [[18234  1307]
  [ 1048  9821]]

 [[22223  1291]
  [  931  5965]]

 [[27651   175]
  [  484  2100]]

 [[28722    71]
  [  281  1336]]

 [[27039   113]
  [  228  3030]]

 [[28951    87]
  [   53  1319]]]

===scores report===
metrics	scores
Accuracy	0.8816
MCC	0.8480
log_loss	0.3565
f1 score weighted	0.8818
f1 score macro	0.8902
f1 score micro	0.8816
roc_auc ovr	0.9823
roc_auc ovo	0.9853
precision	0.8834
recall	0.8816

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa8a019c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa8a019c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa8a019c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa8a019c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.79      0.84      3813
         1.0       0.86      0.91      0.88     10868
         2.0       0.90      0.75      0.82      6897
         3.0       0.69      0.89      0.78      2585
         4.0       0.93      0.81      0.86      1616
         5.0       0.88      0.95      0.91      3258
         6.0       0.90      0.96      0.93      1372

    accuracy                           0.86     30409
   macro avg       0.86      0.87      0.86     30409
weighted avg       0.87      0.86      0.86     30409


===confusion_matrix===

[[3004  362  142  192   21   61   31]
 [ 107 9912  300  281   25  178   65]
 [ 136  929 5188  425   42  133   44]
 [  27  165   70 2291   10   19    3]
 [  28  108   54   79 1307   39    1]
 [  12   70   22   39    4 3109    2]
 [   7   15   17   10    1    1 1321]]

===multilabel confusion matrix===

[[[26279   317]
  [  809  3004]]

 [[17892  1649]
  [  956  9912]]

 [[22907   605]
  [ 1709  5188]]

 [[26798  1026]
  [  294  2291]]

 [[28690   103]
  [  309  1307]]

 [[26720   431]
  [  149  3109]]

 [[28891   146]
  [   51  1321]]]

===scores report===
metrics	scores
Accuracy	0.8594
MCC	0.8214
log_loss	0.4301
f1 score weighted	0.8588
f1 score macro	0.8613
f1 score micro	0.8594
roc_auc ovr	0.9795
roc_auc ovo	0.9835
precision	0.8657
recall	0.8594

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa8a019c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa8a019c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa8a019c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa8a019c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.82      0.86      3813
         1.0       0.87      0.91      0.89     10868
         2.0       0.85      0.84      0.85      6897
         3.0       0.96      0.81      0.88      2585
         4.0       0.93      0.84      0.88      1616
         5.0       0.86      0.97      0.91      3258
         6.0       0.94      0.95      0.94      1372

    accuracy                           0.88     30409
   macro avg       0.90      0.88      0.89     30409
weighted avg       0.88      0.88      0.88     30409


===confusion_matrix===

[[3111  332  229   23   21   74   23]
 [ 109 9937  513   33   27  223   26]
 [  90  763 5823   30   29  141   21]
 [  63  194  162 2095   19   50    2]
 [  33  102   86    7 1356   28    4]
 [   4   58   35    0    6 3152    3]
 [   6   35   21    1    5    5 1299]]

===multilabel confusion matrix===

[[[26291   305]
  [  702  3111]]

 [[18057  1484]
  [  931  9937]]

 [[22466  1046]
  [ 1074  5823]]

 [[27730    94]
  [  490  2095]]

 [[28686   107]
  [  260  1356]]

 [[26630   521]
  [  106  3152]]

 [[28958    79]
  [   73  1299]]]

===scores report===
metrics	scores
Accuracy	0.8804
MCC	0.8466
log_loss	0.3598
f1 score weighted	0.8800
f1 score macro	0.8873
f1 score micro	0.8804
roc_auc ovr	0.9826
roc_auc ovo	0.9860
precision	0.8825
recall	0.8804

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8597171982900361	0.822965889637136	0.42011145656115884	0.8590054144481988	0.8763234844156298	0.8597171982900361	0.9815345913133524	0.9841294848159982	0.8756791336790619	0.8597171982900361
1	0.8899375205524499	0.859918159846701	0.3236773431425949	0.8903749647991246	0.8959154687213007	0.8899375205524499	0.9857008349766355	0.9883921014778047	0.8918764263927179	0.8899375205524499
2	0.8816178888523512	0.847954761367264	0.3565019902172558	0.8817932009879005	0.8902278489663076	0.8816178888523512	0.9822888585755618	0.985289503320726	0.8834360768947853	0.8816178888523512
3	0.8593508500772797	0.8213602849548927	0.43005862389593996	0.8588220398167155	0.861307931671696	0.8593508500772797	0.9795091123484406	0.9834667389719834	0.865656368807153	0.8593508500772797
4	0.8804301358150548	0.8465719595955719	0.35975245345523826	0.8799614869054017	0.8872983203044269	0.8804301358150548	0.9826209279497459	0.9859531895420649	0.8825071331506289	0.8804301358150548
mean	0.8742107187174344	0.8397542110803131	0.3780203734544376	0.8739914213914682	0.8822146108158723	0.8742107187174344	0.9823308650327472	0.9854462036257153	0.8798310277848694	0.8742107187174344
std	0.012423827468068652	0.015102978546409324	0.04056984458393367	0.012803284603309366	0.012243889890598684	0.012423827468068652	0.0020019459787198987	0.0017094989089871898	0.00875681138812417	0.012423827468068652

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 36099.9866 secs

