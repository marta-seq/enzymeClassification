/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_post_bilstm_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f657035c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f657035c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f657035c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f657035c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.88      0.90      3813
         1.0       0.96      0.89      0.92     10869
         2.0       0.83      0.93      0.88      6897
         3.0       0.93      0.88      0.90      2585
         4.0       0.88      0.89      0.88      1616
         5.0       0.94      0.97      0.96      3258
         6.0       0.96      0.97      0.97      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.92      0.92     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[3357   99  254   33   26   32   12]
 [ 144 9680  806   65   74   78   22]
 [  91  204 6447   46   53   36   20]
 [  46   73  144 2265   38   19    0]
 [  24   30   88   15 1441   18    0]
 [  16   34   36    4    7 3159    2]
 [  10    9   13    2    2    1 1335]]

===multilabel confusion matrix===

[[[26266   331]
  [  456  3357]]

 [[19092   449]
  [ 1189  9680]]

 [[22172  1341]
  [  450  6447]]

 [[27660   165]
  [  320  2265]]

 [[28594   200]
  [  175  1441]]

 [[26968   184]
  [   99  3159]]

 [[28982    56]
  [   37  1335]]]

===scores report===
metrics	scores
Accuracy	0.9104
MCC	0.8865
log_loss	0.3259
f1 score weighted	0.9109
f1 score macro	0.9152
f1 score micro	0.9104
roc_auc ovr	0.9898
roc_auc ovo	0.9915
precision	0.9139
recall	0.9104

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f657035c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f657035c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f657035c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f657035c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.92      0.87      3813
         1.0       0.91      0.94      0.92     10869
         2.0       0.88      0.87      0.87      6897
         3.0       0.96      0.84      0.90      2585
         4.0       0.95      0.82      0.88      1616
         5.0       0.99      0.94      0.96      3258
         6.0       0.96      0.97      0.96      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.90      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3526   137   111    14     6     2    17]
 [  213 10169   432    20    10    19     6]
 [  263   552  5985    33    23    12    29]
 [  104   155   134  2174    12     2     4]
 [   94   111    70     8  1324     8     1]
 [   51    89    54     6    11  3047     0]
 [   14    15    16     2     1     0  1324]]

===multilabel confusion matrix===

[[[25858   739]
  [  287  3526]]

 [[18482  1059]
  [  700 10169]]

 [[22696   817]
  [  912  5985]]

 [[27742    83]
  [  411  2174]]

 [[28731    63]
  [  292  1324]]

 [[27109    43]
  [  211  3047]]

 [[28981    57]
  [   48  1324]]]

===scores report===
metrics	scores
Accuracy	0.9059
MCC	0.8794
log_loss	0.3043
f1 score weighted	0.9060
f1 score macro	0.9098
f1 score micro	0.9059
roc_auc ovr	0.9885
roc_auc ovo	0.9902
precision	0.9084
recall	0.9059

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f657035c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f657035c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f657035c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f657035c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.62      0.77      0.69      3814
         1.0       0.77      0.85      0.81     10869
         2.0       0.76      0.70      0.73      6896
         3.0       0.78      0.60      0.68      2584
         4.0       0.95      0.49      0.65      1617
         5.0       0.90      0.86      0.88      3258
         6.0       0.82      0.92      0.87      1372

    accuracy                           0.77     30410
   macro avg       0.80      0.74      0.76     30410
weighted avg       0.78      0.77      0.77     30410


===confusion_matrix===

[[2932  464  253   76    4   47   38]
 [ 563 9201  747  133   11   89  125]
 [ 537 1242 4844  124   16   54   79]
 [ 354  421  217 1551    9   21   11]
 [ 174  233  221  100  793   86   10]
 [ 107  266   81    9    2 2786    7]
 [  25   49   21    4    0    4 1269]]

===multilabel confusion matrix===

[[[24836  1760]
  [  882  2932]]

 [[16866  2675]
  [ 1668  9201]]

 [[21974  1540]
  [ 2052  4844]]

 [[27380   446]
  [ 1033  1551]]

 [[28751    42]
  [  824   793]]

 [[26851   301]
  [  472  2786]]

 [[28768   270]
  [  103  1269]]]

===scores report===
metrics	scores
Accuracy	0.7687
MCC	0.7024
log_loss	0.6775
f1 score weighted	0.7664
f1 score macro	0.7574
f1 score micro	0.7687
roc_auc ovr	0.9433
roc_auc ovo	0.9489
precision	0.7777
recall	0.7687

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f657035c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f657035c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f657035c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f657035c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.86      0.83      3813
         1.0       0.91      0.88      0.90     10868
         2.0       0.91      0.78      0.84      6897
         3.0       0.67      0.90      0.77      2585
         4.0       0.87      0.83      0.85      1616
         5.0       0.91      0.96      0.94      3258
         6.0       0.97      0.95      0.96      1372

    accuracy                           0.87     30409
   macro avg       0.86      0.88      0.87     30409
weighted avg       0.87      0.87      0.87     30409


===confusion_matrix===

[[3285  119  115  201   40   41   12]
 [ 331 9616  291  434   57  124   15]
 [ 335  648 5353  387   77   81   16]
 [  69   84   63 2334   19   14    2]
 [  34   61   52  102 1336   31    0]
 [  29   39   26   28   10 3124    2]
 [  19   17    7   18    1    7 1303]]

===multilabel confusion matrix===

[[[25779   817]
  [  528  3285]]

 [[18573   968]
  [ 1252  9616]]

 [[22958   554]
  [ 1544  5353]]

 [[26654  1170]
  [  251  2334]]

 [[28589   204]
  [  280  1336]]

 [[26853   298]
  [  134  3124]]

 [[28990    47]
  [   69  1303]]]

===scores report===
metrics	scores
Accuracy	0.8666
MCC	0.8318
log_loss	0.4105
f1 score weighted	0.8677
f1 score macro	0.8670
f1 score micro	0.8666
roc_auc ovr	0.9818
roc_auc ovo	0.9851
precision	0.8747
recall	0.8666

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f657035c550>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f657035c700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f657035c760>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f657035c520>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.89      0.91      3813
         1.0       0.91      0.94      0.93     10868
         2.0       0.89      0.89      0.89      6897
         3.0       0.90      0.90      0.90      2585
         4.0       0.91      0.90      0.91      1616
         5.0       0.97      0.97      0.97      3258
         6.0       0.97      0.96      0.96      1372

    accuracy                           0.92     30409
   macro avg       0.93      0.92      0.92     30409
weighted avg       0.92      0.92      0.92     30409


===confusion_matrix===

[[ 3375   182   166    47    17    15    11]
 [   93 10201   370   102    39    49    14]
 [   92   528  6115    73    50    29    10]
 [   33   113    95  2316    21     7     0]
 [   17    63    55    21  1453     6     1]
 [   12    46    26    14     7  3152     1]
 [   14    24    15     3     2     3  1311]]

===multilabel confusion matrix===

[[[26335   261]
  [  438  3375]]

 [[18585   956]
  [  667 10201]]

 [[22785   727]
  [  782  6115]]

 [[27564   260]
  [  269  2316]]

 [[28657   136]
  [  163  1453]]

 [[27042   109]
  [  106  3152]]

 [[29000    37]
  [   61  1311]]]

===scores report===
metrics	scores
Accuracy	0.9182
MCC	0.8952
log_loss	0.2938
f1 score weighted	0.9182
f1 score macro	0.9225
f1 score micro	0.9182
roc_auc ovr	0.9905
roc_auc ovo	0.9922
precision	0.9183
recall	0.9182

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9103584347254192	0.8865364486793554	0.32593341315106	0.910851677950471	0.9152477406076251	0.9103584347254192	0.9897608418876744	0.9914655692257424	0.9138889645359511	0.9103584347254192
1	0.9059191055573824	0.8794159696823052	0.30425821867167224	0.9060355585892195	0.9098256166852814	0.9059191055573824	0.9885072886771581	0.9902460983484542	0.908429393736014	0.9059191055573824
2	0.7686945083853995	0.702432052731489	0.6774553865033753	0.7664150886881862	0.7574245010403021	0.7686945083853997	0.9433481983406377	0.9489475461160951	0.7777326106180623	0.7686945083853995
3	0.8665526653293433	0.8318436144584862	0.41046592403370213	0.8677033918990027	0.8669586957927882	0.8665526653293434	0.9817626781587776	0.9851416930151777	0.8747424486301292	0.8665526653293433
4	0.918247887138676	0.8951840438475975	0.29379656978645935	0.9181564471887128	0.922548344631913	0.918247887138676	0.9905096774686561	0.9921912518939887	0.9183279963322266	0.918247887138676
mean	0.8739545202272441	0.8390824258798467	0.4023819024292538	0.8738324328631183	0.8744009797515819	0.8739545202272442	0.9787777369065808	0.9815984317198916	0.8786242827704764	0.8739545202272441
std	0.055575785387781435	0.07176600232213023	0.14352294334927743	0.05647678289711569	0.06161236187884501	0.055575785387781386	0.017983844301532725	0.016510514293853838	0.052730494851243516	0.055575785387781435

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 61806.8697 secs

