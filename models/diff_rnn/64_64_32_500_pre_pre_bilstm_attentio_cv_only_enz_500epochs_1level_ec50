/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_1level_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3a9c4be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f3a9c4be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3a9c4be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3a9c4be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.78      0.78      1793
         1.0       0.82      0.85      0.84      4921
         2.0       0.80      0.78      0.79      3576
         3.0       0.70      0.69      0.69       943
         4.0       0.81      0.74      0.77       695
         5.0       0.87      0.87      0.87      1073
         6.0       0.91      0.90      0.91       471

    accuracy                           0.81     13472
   macro avg       0.81      0.80      0.81     13472
weighted avg       0.81      0.81      0.81     13472


===confusion_matrix===

[[1399  173  120   51   19   15   16]
 [ 146 4205  358  106   35   59   12]
 [ 134  479 2774   95   39   46    9]
 [  47  118  100  646   20   10    2]
 [  22   63   59   22  515   12    2]
 [  20   69   39    7    6  931    1]
 [   5   22   15    1    1    3  424]]

===multilabel confusion matrix===

[[[11305   374]
  [  394  1399]]

 [[ 7627   924]
  [  716  4205]]

 [[ 9205   691]
  [  802  2774]]

 [[12247   282]
  [  297   646]]

 [[12657   120]
  [  180   515]]

 [[12254   145]
  [  142   931]]

 [[12959    42]
  [   47   424]]]

===scores report===
metrics	scores
Accuracy	0.8086
MCC	0.7485
log_loss	0.6697
f1 score weighted	0.8082
f1 score macro	0.8065
f1 score micro	0.8086
roc_auc ovr	0.9561
roc_auc ovo	0.9625
precision	0.8083
recall	0.8086

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3a9c4be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f3a9c4be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3a9c4be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3a9c4be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.80      0.78      1792
         1.0       0.84      0.86      0.85      4921
         2.0       0.83      0.75      0.79      3576
         3.0       0.63      0.76      0.69       943
         4.0       0.81      0.75      0.78       696
         5.0       0.89      0.85      0.87      1072
         6.0       0.93      0.91      0.92       471

    accuracy                           0.81     13471
   macro avg       0.81      0.81      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1433  147  109   62   16   17    8]
 [ 194 4214  292  137   32   42   10]
 [ 182  441 2685  165   52   37   14]
 [  42   89   76  721    9    6    0]
 [  25   72   34   31  523   11    0]
 [  24   66   31   24   11  916    0]
 [   5   11   18    5    0    2  430]]

===multilabel confusion matrix===

[[[11207   472]
  [  359  1433]]

 [[ 7724   826]
  [  707  4214]]

 [[ 9335   560]
  [  891  2685]]

 [[12104   424]
  [  222   721]]

 [[12655   120]
  [  173   523]]

 [[12284   115]
  [  156   916]]

 [[12968    32]
  [   41   430]]]

===scores report===
metrics	scores
Accuracy	0.8108
MCC	0.7531
log_loss	0.7001
f1 score weighted	0.8115
f1 score macro	0.8105
f1 score micro	0.8108
roc_auc ovr	0.9586
roc_auc ovo	0.9657
precision	0.8145
recall	0.8108

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3a9c4be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f3a9c4be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3a9c4be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3a9c4be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.76      0.77      1792
         1.0       0.82      0.87      0.84      4921
         2.0       0.82      0.78      0.80      3576
         3.0       0.73      0.73      0.73       943
         4.0       0.81      0.76      0.79       695
         5.0       0.87      0.87      0.87      1072
         6.0       0.95      0.91      0.93       472

    accuracy                           0.82     13471
   macro avg       0.83      0.81      0.82     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1360  201  139   53   14   22    3]
 [ 147 4286  310   82   39   52    5]
 [ 123  465 2803   83   42   48   12]
 [  35  116   83  689   17    3    0]
 [  30   65   40   18  530   10    2]
 [  20   77   24   12    7  931    1]
 [   9   14   15    2    3    1  428]]

===multilabel confusion matrix===

[[[11315   364]
  [  432  1360]]

 [[ 7612   938]
  [  635  4286]]

 [[ 9284   611]
  [  773  2803]]

 [[12278   250]
  [  254   689]]

 [[12654   122]
  [  165   530]]

 [[12263   136]
  [  141   931]]

 [[12976    23]
  [   44   428]]]

===scores report===
metrics	scores
Accuracy	0.8186
MCC	0.7614
log_loss	0.6700
f1 score weighted	0.8181
f1 score macro	0.8197
f1 score micro	0.8186
roc_auc ovr	0.9596
roc_auc ovo	0.9662
precision	0.8186
recall	0.8186

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3a9c4be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f3a9c4be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3a9c4be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3a9c4be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.80      0.78      1792
         1.0       0.85      0.84      0.85      4920
         2.0       0.79      0.80      0.79      3576
         3.0       0.70      0.77      0.73       944
         4.0       0.81      0.76      0.78       695
         5.0       0.92      0.87      0.90      1072
         6.0       0.92      0.89      0.90       472

    accuracy                           0.82     13471
   macro avg       0.82      0.82      0.82     13471
weighted avg       0.82      0.82      0.82     13471


===confusion_matrix===

[[1429  131  137   54   12   19   10]
 [ 153 4151  419  105   51   30   11]
 [ 166  371 2844  115   43   24   13]
 [  38   98   69  726   10    3    0]
 [  39   42   60   22  525    4    3]
 [  16   59   40   14    6  936    1]
 [  15   15   18    4    1    0  419]]

===multilabel confusion matrix===

[[[11252   427]
  [  363  1429]]

 [[ 7835   716]
  [  769  4151]]

 [[ 9152   743]
  [  732  2844]]

 [[12213   314]
  [  218   726]]

 [[12653   123]
  [  170   525]]

 [[12319    80]
  [  136   936]]

 [[12961    38]
  [   53   419]]]

===scores report===
metrics	scores
Accuracy	0.8188
MCC	0.7629
log_loss	0.6878
f1 score weighted	0.8194
f1 score macro	0.8197
f1 score micro	0.8188
roc_auc ovr	0.9605
roc_auc ovo	0.9674
precision	0.8205
recall	0.8188

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3a9c4be580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f3a9c4be730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3a9c4be790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f3a9c4be550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.79      0.78      1792
         1.0       0.83      0.85      0.84      4920
         2.0       0.78      0.80      0.79      3576
         3.0       0.71      0.70      0.70       944
         4.0       0.85      0.71      0.78       695
         5.0       0.92      0.86      0.89      1073
         6.0       0.93      0.91      0.92       471

    accuracy                           0.81     13471
   macro avg       0.83      0.80      0.81     13471
weighted avg       0.81      0.81      0.81     13471


===confusion_matrix===

[[1412  149  141   55   16    9   10]
 [ 161 4174  417   97   39   27    5]
 [ 123  464 2847   80   24   27   11]
 [  52  108  113  657    6    4    4]
 [  28   65   77   22  495    7    1]
 [  23   66   51    8    2  923    0]
 [  15   13   13    1    0    1  428]]

===multilabel confusion matrix===

[[[11277   402]
  [  380  1412]]

 [[ 7686   865]
  [  746  4174]]

 [[ 9083   812]
  [  729  2847]]

 [[12264   263]
  [  287   657]]

 [[12689    87]
  [  200   495]]

 [[12323    75]
  [  150   923]]

 [[12969    31]
  [   43   428]]]

===scores report===
metrics	scores
Accuracy	0.8118
MCC	0.7523
log_loss	0.6963
f1 score weighted	0.8118
f1 score macro	0.8143
f1 score micro	0.8118
roc_auc ovr	0.9549
roc_auc ovo	0.9622
precision	0.8128
recall	0.8118

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8086401425178147	0.7484863118064665	0.6696735064777938	0.8081891359866922	0.8065494638099955	0.8086401425178147	0.9560795509287481	0.9625048990907935	0.8082818974181587	0.8086401425178147
1	0.8107787098210971	0.7531017483784215	0.700096730141899	0.8114547146500353	0.8104692557824833	0.8107787098210972	0.9585778559146875	0.9656658636300256	0.8144972873010682	0.8107787098210971
2	0.8185732313859402	0.7613821461478713	0.6699516510902164	0.8180946276830094	0.8196574354981997	0.8185732313859402	0.9595653166347908	0.966204469283444	0.8185907451906259	0.8185732313859402
3	0.8187959320020786	0.7628662742001712	0.6877859051035509	0.8194012535224432	0.8197250397775891	0.8187959320020786	0.9605116922433579	0.9674376327352351	0.8205487527978497	0.8187959320020786
4	0.8118179793630762	0.7522719325313032	0.6962534037112539	0.8118223690934183	0.8143372357360376	0.8118179793630762	0.9548574239086124	0.9621648347300772	0.8128218369605545	0.8118179793630762
mean	0.8137211990180016	0.7556216826128468	0.6847522393049428	0.8137924201871197	0.8141476861208611	0.8137211990180016	0.9579183679260395	0.9647955398939152	0.8149481039336515	0.8137211990180016
std	0.004180735721044514	0.005552503185134638	0.01283245031238005	0.004259360586796942	0.005152940386023277	0.004180735721044498	0.002127125840122019	0.002092407463207812	0.004331250609497253	0.004180735721044514

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 30867.8940 secs

