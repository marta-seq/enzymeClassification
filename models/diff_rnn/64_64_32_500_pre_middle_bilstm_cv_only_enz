/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_middle_bilstm_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb4d429c220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb4d429c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb4d429c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb4d429c640>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.80      0.86      3813
         1.0       0.87      0.94      0.90     10869
         2.0       0.88      0.85      0.86      6897
         3.0       0.91      0.82      0.86      2585
         4.0       0.88      0.86      0.87      1616
         5.0       0.94      0.95      0.94      3258
         6.0       0.91      0.97      0.94      1372

    accuracy                           0.89     30410
   macro avg       0.90      0.88      0.89     30410
weighted avg       0.89      0.89      0.89     30410


===confusion_matrix===

[[ 3038   364   217    90    12    67    25]
 [   58 10239   373    41    36    62    60]
 [   94   746  5841    57    63    48    48]
 [   47   224   137  2114    54     7     2]
 [   13   102    64    20  1395    21     1]
 [   10   104    21     4    17  3101     1]
 [    4    18    16     3     1     3  1327]]

===multilabel confusion matrix===

[[[26371   226]
  [  775  3038]]

 [[17983  1558]
  [  630 10239]]

 [[22685   828]
  [ 1056  5841]]

 [[27610   215]
  [  471  2114]]

 [[28611   183]
  [  221  1395]]

 [[26944   208]
  [  157  3101]]

 [[28901   137]
  [   45  1327]]]

===scores report===
metrics	scores
Accuracy	0.8897
MCC	0.8585
log_loss	0.3517
f1 score weighted	0.8888
f1 score macro	0.8910
f1 score micro	0.8897
roc_auc ovr	0.9853
roc_auc ovo	0.9876
precision	0.8910
recall	0.8897

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb4d429c220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb4d429c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb4d429c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb4d429c640>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.86      0.86      3813
         1.0       0.95      0.82      0.88     10869
         2.0       0.77      0.92      0.84      6897
         3.0       0.85      0.87      0.86      2585
         4.0       0.92      0.80      0.86      1616
         5.0       0.87      0.96      0.91      3258
         6.0       0.97      0.94      0.96      1372

    accuracy                           0.87     30410
   macro avg       0.88      0.88      0.88     30410
weighted avg       0.88      0.87      0.87     30410


===confusion_matrix===

[[3296   98  293   54   15   52    5]
 [ 319 8923 1110  204   56  239   18]
 [ 148  205 6341   91   17   87    8]
 [  56   69  178 2240   16   23    3]
 [  32   42  159   43 1300   39    1]
 [  20   30   76   12    2 3118    0]
 [  13   10   51    3    1    8 1286]]

===multilabel confusion matrix===

[[[26009   588]
  [  517  3296]]

 [[19087   454]
  [ 1946  8923]]

 [[21646  1867]
  [  556  6341]]

 [[27418   407]
  [  345  2240]]

 [[28687   107]
  [  316  1300]]

 [[26704   448]
  [  140  3118]]

 [[29003    35]
  [   86  1286]]]

===scores report===
metrics	scores
Accuracy	0.8716
MCC	0.8394
log_loss	0.4064
f1 score weighted	0.8723
f1 score macro	0.8804
f1 score micro	0.8716
roc_auc ovr	0.9833
roc_auc ovo	0.9860
precision	0.8804
recall	0.8716

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb4d429c220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb4d429c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb4d429c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb4d429c640>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.82      0.87      3814
         1.0       0.93      0.91      0.92     10869
         2.0       0.78      0.94      0.85      6896
         3.0       0.93      0.85      0.88      2584
         4.0       0.97      0.80      0.88      1617
         5.0       0.99      0.93      0.96      3258
         6.0       0.97      0.95      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.93      0.89      0.90     30410
weighted avg       0.91      0.90      0.90     30410


===confusion_matrix===

[[3144  158  447   37    5    8   15]
 [  88 9869  818   54   18   10   12]
 [  52  293 6496   33    5    7   10]
 [  35  125  234 2185    2    3    0]
 [  30  105  147   31 1297    3    4]
 [  20   69  128   14    4 3023    0]
 [   7   18   35    1    1    2 1308]]

===multilabel confusion matrix===

[[[26364   232]
  [  670  3144]]

 [[18773   768]
  [ 1000  9869]]

 [[21705  1809]
  [  400  6496]]

 [[27656   170]
  [  399  2185]]

 [[28758    35]
  [  320  1297]]

 [[27119    33]
  [  235  3023]]

 [[28997    41]
  [   64  1308]]]

===scores report===
metrics	scores
Accuracy	0.8985
MCC	0.8709
log_loss	0.3484
f1 score weighted	0.8995
f1 score macro	0.9043
f1 score micro	0.8985
roc_auc ovr	0.9871
roc_auc ovo	0.9884
precision	0.9061
recall	0.8985

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb4d429c220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb4d429c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb4d429c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb4d429c640>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.95      0.81      0.88      3813
         1.0       0.94      0.88      0.91     10868
         2.0       0.79      0.94      0.86      6897
         3.0       0.89      0.86      0.87      2585
         4.0       0.97      0.81      0.88      1616
         5.0       0.91      0.96      0.93      3258
         6.0       0.89      0.97      0.93      1372

    accuracy                           0.89     30409
   macro avg       0.91      0.89      0.89     30409
weighted avg       0.90      0.89      0.89     30409


===confusion_matrix===

[[3102  163  337   89    9   72   41]
 [  69 9574  894   85   15  140   91]
 [  46  246 6461   61   10   50   23]
 [  25   97  215 2211    9   27    1]
 [  18   75  156   22 1305   38    2]
 [   4   30   71    1    2 3143    7]
 [   8    9   18    3    0    2 1332]]

===multilabel confusion matrix===

[[[26426   170]
  [  711  3102]]

 [[18921   620]
  [ 1294  9574]]

 [[21821  1691]
  [  436  6461]]

 [[27563   261]
  [  374  2211]]

 [[28748    45]
  [  311  1305]]

 [[26822   329]
  [  115  3143]]

 [[28872   165]
  [   40  1332]]]

===scores report===
metrics	scores
Accuracy	0.8921
MCC	0.8635
log_loss	0.3546
f1 score weighted	0.8925
f1 score macro	0.8943
f1 score micro	0.8921
roc_auc ovr	0.9865
roc_auc ovo	0.9884
precision	0.8988
recall	0.8921

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb4d429c220>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb4d429c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb4d429c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb4d429c640>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.90      0.90      3813
         1.0       0.92      0.94      0.93     10868
         2.0       0.90      0.88      0.89      6897
         3.0       0.90      0.89      0.89      2585
         4.0       0.91      0.89      0.90      1616
         5.0       0.95      0.97      0.96      3258
         6.0       0.98      0.95      0.96      1372

    accuracy                           0.92     30409
   macro avg       0.92      0.92      0.92     30409
weighted avg       0.92      0.92      0.92     30409


===confusion_matrix===

[[ 3444   134   121    57    24    25     8]
 [  152 10167   351    88    37    62    11]
 [  155   483  6056    81    50    61    11]
 [   54    99   106  2298    17    11     0]
 [   23    64    60    20  1435    14     0]
 [   16    41    39     4     3  3153     2]
 [   16    18    21     3     4     3  1307]]

===multilabel confusion matrix===

[[[26180   416]
  [  369  3444]]

 [[18702   839]
  [  701 10167]]

 [[22814   698]
  [  841  6056]]

 [[27571   253]
  [  287  2298]]

 [[28658   135]
  [  181  1435]]

 [[26975   176]
  [  105  3153]]

 [[29005    32]
  [   65  1307]]]

===scores report===
metrics	scores
Accuracy	0.9162
MCC	0.8927
log_loss	0.2962
f1 score weighted	0.9160
f1 score macro	0.9188
f1 score micro	0.9162
roc_auc ovr	0.9905
roc_auc ovo	0.9921
precision	0.9161
recall	0.9162

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.889674449194344	0.8584652428559586	0.35173856597971226	0.8888270233203965	0.8910432712589957	0.889674449194344	0.985295720075867	0.9876263307368865	0.8909902612373408	0.889674449194344
1	0.871555409404801	0.8394074077701592	0.40635576722470607	0.8723370730253347	0.8803898989486012	0.871555409404801	0.983324816797948	0.9860054549133733	0.8803582692268783	0.871555409404801
2	0.8984544557711279	0.8708644734719588	0.34839193021786624	0.8994505523958944	0.9043427957009433	0.8984544557711279	0.9870572673599388	0.9883972417566582	0.9061216459826821	0.8984544557711279
3	0.8921043112236509	0.8635294700523752	0.35456575792208245	0.8925283930217872	0.8943453883462935	0.892104311223651	0.9864734255057195	0.9883670362080811	0.8988288573940874	0.8921043112236509
4	0.9161761320661647	0.892670868257254	0.29615773231898507	0.9160464543337279	0.9188267060124684	0.9161761320661647	0.9904899107616143	0.9921025242195259	0.9160592024773156	0.9161761320661647
mean	0.8935929515320176	0.864987492481541	0.35144195073267037	0.893837899219428	0.8977896120534604	0.8935929515320178	0.9865282281002177	0.9884997175669049	0.8984716472636608	0.8935929515320176
std	0.014400404439123639	0.017320014453370943	0.034902781621054674	0.014239599760737359	0.013004840217005717	0.014400404439123635	0.002356214564673534	0.001999623572099876	0.012264075820459316	0.014400404439123639

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 66464.1641 secs

