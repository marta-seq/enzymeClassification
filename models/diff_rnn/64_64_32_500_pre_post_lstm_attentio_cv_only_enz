/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_post_lstm_attentio_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fca8021c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fca8021c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fca8021c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fca8021c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.90      0.81      3813
         1.0       0.85      0.92      0.89     10869
         2.0       0.91      0.77      0.83      6897
         3.0       0.94      0.80      0.87      2585
         4.0       0.91      0.84      0.88      1616
         5.0       0.96      0.93      0.95      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.87     30410
   macro avg       0.90      0.87      0.88     30410
weighted avg       0.88      0.87      0.87     30410


===confusion_matrix===

[[ 3417   217   111    26    20    16     6]
 [  450 10036   237    47    41    33    25]
 [  435  1025  5296    41    40    40    20]
 [  149   243    87  2073    18    15     0]
 [   64   125    44     8  1359    15     1]
 [   46   131    25     8     4  3044     0]
 [   16    23    13     1     5     1  1313]]

===multilabel confusion matrix===

[[[25437  1160]
  [  396  3417]]

 [[17777  1764]
  [  833 10036]]

 [[22996   517]
  [ 1601  5296]]

 [[27694   131]
  [  512  2073]]

 [[28666   128]
  [  257  1359]]

 [[27032   120]
  [  214  3044]]

 [[28986    52]
  [   59  1313]]]

===scores report===
metrics	scores
Accuracy	0.8727
MCC	0.8378
log_loss	0.3757
f1 score weighted	0.8726
f1 score macro	0.8832
f1 score micro	0.8727
roc_auc ovr	0.9822
roc_auc ovo	0.9858
precision	0.8792
recall	0.8727

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fca8021c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fca8021c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fca8021c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fca8021c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.86      0.85      3813
         1.0       0.92      0.86      0.89     10869
         2.0       0.85      0.84      0.84      6897
         3.0       0.82      0.88      0.84      2585
         4.0       0.83      0.87      0.85      1616
         5.0       0.87      0.97      0.92      3258
         6.0       0.95      0.96      0.95      1372

    accuracy                           0.87     30410
   macro avg       0.87      0.89      0.88     30410
weighted avg       0.88      0.87      0.87     30410


===confusion_matrix===

[[3295  140  188   81   36   62   11]
 [ 308 9371  622  198  109  225   36]
 [ 183  472 5794  193  113  120   22]
 [  51  110  105 2262   20   32    5]
 [  52   52   50   31 1412   19    0]
 [  24   31   44    8    4 3146    1]
 [  13   18   18    2    1    4 1316]]

===multilabel confusion matrix===

[[[25966   631]
  [  518  3295]]

 [[18718   823]
  [ 1498  9371]]

 [[22486  1027]
  [ 1103  5794]]

 [[27312   513]
  [  323  2262]]

 [[28511   283]
  [  204  1412]]

 [[26690   462]
  [  112  3146]]

 [[28963    75]
  [   56  1316]]]

===scores report===
metrics	scores
Accuracy	0.8746
MCC	0.8412
log_loss	0.3708
f1 score weighted	0.8746
f1 score macro	0.8789
f1 score micro	0.8746
roc_auc ovr	0.9825
roc_auc ovo	0.9864
precision	0.8761
recall	0.8746

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fca8021c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fca8021c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fca8021c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fca8021c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.83      0.85      3814
         1.0       0.90      0.88      0.89     10869
         2.0       0.83      0.87      0.85      6896
         3.0       0.71      0.87      0.78      2584
         4.0       0.94      0.81      0.87      1617
         5.0       0.98      0.93      0.95      3258
         6.0       0.94      0.95      0.95      1372

    accuracy                           0.87     30410
   macro avg       0.88      0.88      0.88     30410
weighted avg       0.88      0.87      0.88     30410


===confusion_matrix===

[[3181  218  249  125   12    5   24]
 [ 172 9526  643  435   30   31   32]
 [ 123  525 5992  196   25   13   22]
 [  48   97  168 2254   12    4    1]
 [  55   75   88   79 1313    5    2]
 [  44   79   45   66    6 3018    0]
 [  11   32   19    6    0    1 1303]]

===multilabel confusion matrix===

[[[26143   453]
  [  633  3181]]

 [[18515  1026]
  [ 1343  9526]]

 [[22302  1212]
  [  904  5992]]

 [[26919   907]
  [  330  2254]]

 [[28708    85]
  [  304  1313]]

 [[27093    59]
  [  240  3018]]

 [[28957    81]
  [   69  1303]]]

===scores report===
metrics	scores
Accuracy	0.8743
MCC	0.8398
log_loss	0.3757
f1 score weighted	0.8755
f1 score macro	0.8782
f1 score micro	0.8743
roc_auc ovr	0.9819
roc_auc ovo	0.9851
precision	0.8792
recall	0.8743

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fca8021c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fca8021c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fca8021c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fca8021c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.84      0.85      3813
         1.0       0.89      0.89      0.89     10868
         2.0       0.85      0.84      0.84      6897
         3.0       0.86      0.85      0.86      2585
         4.0       0.89      0.84      0.87      1616
         5.0       0.88      0.97      0.92      3258
         6.0       0.96      0.94      0.95      1372

    accuracy                           0.88     30409
   macro avg       0.88      0.88      0.88     30409
weighted avg       0.88      0.88      0.88     30409


===confusion_matrix===

[[3194  232  222   53   21   78   13]
 [ 213 9697  567  118   61  188   24]
 [ 183  641 5780  129   49  103   12]
 [  74  142  132 2193   22   21    1]
 [  34  100   64   37 1353   26    2]
 [  13   44   44    8    5 3144    0]
 [  19   27   22    4    1    6 1293]]

===multilabel confusion matrix===

[[[26060   536]
  [  619  3194]]

 [[18355  1186]
  [ 1171  9697]]

 [[22461  1051]
  [ 1117  5780]]

 [[27475   349]
  [  392  2193]]

 [[28634   159]
  [  263  1353]]

 [[26729   422]
  [  114  3144]]

 [[28985    52]
  [   79  1293]]]

===scores report===
metrics	scores
Accuracy	0.8765
MCC	0.8421
log_loss	0.3658
f1 score weighted	0.8762
f1 score macro	0.8821
f1 score micro	0.8765
roc_auc ovr	0.9819
roc_auc ovo	0.9855
precision	0.8765
recall	0.8765

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fca8021c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fca8021c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fca8021c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fca8021c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.85      0.84      3813
         1.0       0.93      0.85      0.89     10868
         2.0       0.76      0.91      0.83      6897
         3.0       0.93      0.78      0.85      2585
         4.0       0.89      0.86      0.88      1616
         5.0       0.95      0.95      0.95      3258
         6.0       0.98      0.93      0.95      1372

    accuracy                           0.87     30409
   macro avg       0.89      0.88      0.88     30409
weighted avg       0.88      0.87      0.87     30409


===confusion_matrix===

[[3250  101  394   14   13   31   10]
 [ 341 9204 1088   88   72   64   11]
 [ 139  361 6265   27   58   42    5]
 [ 116  113  288 2027   22   19    0]
 [  48   53   97   10 1394   13    1]
 [  28   29   90    3    8 3100    0]
 [  23   30   42    2    3    1 1271]]

===multilabel confusion matrix===

[[[25901   695]
  [  563  3250]]

 [[18854   687]
  [ 1664  9204]]

 [[21513  1999]
  [  632  6265]]

 [[27680   144]
  [  558  2027]]

 [[28617   176]
  [  222  1394]]

 [[26981   170]
  [  158  3100]]

 [[29010    27]
  [  101  1271]]]

===scores report===
metrics	scores
Accuracy	0.8718
MCC	0.8382
log_loss	0.3717
f1 score weighted	0.8731
f1 score macro	0.8829
f1 score micro	0.8718
roc_auc ovr	0.9822
roc_auc ovo	0.9857
precision	0.8801
recall	0.8718

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.872673462676751	0.8378171947709327	0.37572942080705707	0.8725974314561726	0.8832050524715039	0.872673462676751	0.9821572357822855	0.9858091513868481	0.879211264141234	0.872673462676751
1	0.8745807300230187	0.8411563408083063	0.370750288707371	0.874613795216768	0.8788570462302304	0.8745807300230187	0.9824894498899353	0.9863975926671453	0.8761058653334725	0.8745807300230187
2	0.8742847747451497	0.8398379704797926	0.375671713199295	0.87548521726804	0.8782230964562653	0.8742847747451497	0.9818541918833175	0.9850906285425207	0.8791527293605796	0.8742847747451497
3	0.8765168206780887	0.8420527640266756	0.36578078499139133	0.8762066864156864	0.8820555654112197	0.8765168206780887	0.98191566995827	0.9854569381318248	0.8764549206199631	0.8765168206780887
4	0.8718142655134993	0.8381583885662393	0.3717326788233812	0.8730998077978553	0.8829065177025993	0.8718142655134993	0.9822272784491792	0.9856733626934578	0.880118715228724	0.8718142655134993
mean	0.8739740107273015	0.8398045317303893	0.3719329773056991	0.8744005876309044	0.8810494556543637	0.8739740107273015	0.9821287651925974	0.9856855346843594	0.8782086989367945	0.8739740107273015
std	0.0016301220595243268	0.0016457429871316554	0.00367911596490046	0.001373118502486525	0.002092964372922141	0.0016301220595243268	0.00022865212360931634	0.0004309583550121644	0.0016150628602917636	0.0016301220595243268

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 33587.6169 secs

