/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_term_bi_attention_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f971859c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f971859c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f971859c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f971859c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.85      0.88      3813
         1.0       0.91      0.92      0.92     10869
         2.0       0.87      0.88      0.87      6897
         3.0       0.82      0.90      0.86      2585
         4.0       0.92      0.89      0.91      1616
         5.0       0.98      0.95      0.96      3258
         6.0       0.96      0.97      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.91      0.91      0.91     30410
weighted avg       0.91      0.90      0.90     30410


===confusion_matrix===

[[ 3223   213   191   133    20    16    17]
 [  113 10016   481   167    46    25    21]
 [  106   494  6060   156    45    16    20]
 [   32   100   101  2329    13     8     2]
 [   25    55    55    29  1446     5     1]
 [   14    67    56    22     8  3091     0]
 [    5    21    15     2     0     0  1329]]

===multilabel confusion matrix===

[[[26302   295]
  [  590  3223]]

 [[18591   950]
  [  853 10016]]

 [[22614   899]
  [  837  6060]]

 [[27316   509]
  [  256  2329]]

 [[28662   132]
  [  170  1446]]

 [[27082    70]
  [  167  3091]]

 [[28977    61]
  [   43  1329]]]

===scores report===
metrics	scores
Accuracy	0.9041
MCC	0.8773
log_loss	0.3061
f1 score weighted	0.9043
f1 score macro	0.9087
f1 score micro	0.9041
roc_auc ovr	0.9884
roc_auc ovo	0.9907
precision	0.9052
recall	0.9041

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f971859c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f971859c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f971859c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f971859c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.93      0.83      3813
         1.0       0.91      0.92      0.92     10869
         2.0       0.90      0.83      0.87      6897
         3.0       0.97      0.84      0.90      2585
         4.0       0.90      0.90      0.90      1616
         5.0       0.98      0.93      0.96      3258
         6.0       0.94      0.97      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.91      0.90      0.90     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[ 3537   125   112     7    20     3     9]
 [  383 10025   333    24    49    26    29]
 [  490   529  5741    31    49    19    38]
 [  134   156    92  2166    29     4     4]
 [   63    49    39     9  1451     5     0]
 [   81    87    34     6    10  3040     0]
 [   14    12     9     0     0     0  1337]]

===multilabel confusion matrix===

[[[25432  1165]
  [  276  3537]]

 [[18583   958]
  [  844 10025]]

 [[22894   619]
  [ 1156  5741]]

 [[27748    77]
  [  419  2166]]

 [[28637   157]
  [  165  1451]]

 [[27095    57]
  [  218  3040]]

 [[28958    80]
  [   35  1337]]]

===scores report===
metrics	scores
Accuracy	0.8976
MCC	0.8698
log_loss	0.3361
f1 score weighted	0.8984
f1 score macro	0.9039
f1 score micro	0.8976
roc_auc ovr	0.9879
roc_auc ovo	0.9903
precision	0.9031
recall	0.8976

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f971859c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f971859c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f971859c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f971859c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.89      0.88      3814
         1.0       0.85      0.95      0.90     10869
         2.0       0.95      0.72      0.82      6896
         3.0       0.82      0.89      0.86      2584
         4.0       0.77      0.90      0.83      1617
         5.0       0.99      0.92      0.95      3258
         6.0       0.97      0.94      0.95      1372

    accuracy                           0.88     30410
   macro avg       0.89      0.89      0.88     30410
weighted avg       0.89      0.88      0.88     30410


===confusion_matrix===

[[ 3391   233    60    84    38     1     7]
 [  154 10340   140   122    97     6    10]
 [  264  1171  4963   240   222    13    23]
 [   41   157    43  2311    29     1     2]
 [   26    76    14    33  1463     1     4]
 [   41   148    14    25    42  2988     0]
 [   19    46     3     3     7     0  1294]]

===multilabel confusion matrix===

[[[26051   545]
  [  423  3391]]

 [[17710  1831]
  [  529 10340]]

 [[23240   274]
  [ 1933  4963]]

 [[27319   507]
  [  273  2311]]

 [[28358   435]
  [  154  1463]]

 [[27130    22]
  [  270  2988]]

 [[28992    46]
  [   78  1294]]]

===scores report===
metrics	scores
Accuracy	0.8796
MCC	0.8481
log_loss	0.3892
f1 score weighted	0.8782
f1 score macro	0.8838
f1 score micro	0.8796
roc_auc ovr	0.9866
roc_auc ovo	0.9892
precision	0.8872
recall	0.8796

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f971859c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f971859c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f971859c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f971859c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.82      0.87      3813
         1.0       0.92      0.91      0.92     10868
         2.0       0.83      0.91      0.87      6897
         3.0       0.84      0.89      0.87      2585
         4.0       0.98      0.81      0.88      1616
         5.0       0.97      0.95      0.96      3258
         6.0       0.95      0.97      0.96      1372

    accuracy                           0.90     30409
   macro avg       0.92      0.89      0.90     30409
weighted avg       0.90      0.90      0.90     30409


===confusion_matrix===

[[3130  204  308  110    7   27   27]
 [  82 9944  648  133    9   36   16]
 [  71  375 6301  103    7   26   14]
 [  41   86  149 2295    4    7    3]
 [  30   87  134   49 1303   11    2]
 [  10   67   69   22    2 3086    2]
 [   4   14   22    5    0    1 1326]]

===multilabel confusion matrix===

[[[26358   238]
  [  683  3130]]

 [[18708   833]
  [  924  9944]]

 [[22182  1330]
  [  596  6301]]

 [[27402   422]
  [  290  2295]]

 [[28764    29]
  [  313  1303]]

 [[27043   108]
  [  172  3086]]

 [[28973    64]
  [   46  1326]]]

===scores report===
metrics	scores
Accuracy	0.9006
MCC	0.8729
log_loss	0.3332
f1 score weighted	0.9008
f1 score macro	0.9035
f1 score micro	0.9006
roc_auc ovr	0.9879
roc_auc ovo	0.9896
precision	0.9039
recall	0.9006

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f971859c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f971859c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f971859c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f971859c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.89      0.88      3813
         1.0       0.94      0.90      0.92     10868
         2.0       0.82      0.92      0.86      6897
         3.0       0.97      0.84      0.90      2585
         4.0       0.92      0.87      0.90      1616
         5.0       0.96      0.95      0.96      3258
         6.0       0.97      0.95      0.96      1372

    accuracy                           0.90     30409
   macro avg       0.92      0.90      0.91     30409
weighted avg       0.91      0.90      0.91     30409


===confusion_matrix===

[[3407  125  242    4   18    8    9]
 [ 174 9787  763   27   48   46   23]
 [ 166  302 6340   18   27   31   13]
 [  82  107  193 2165   22   16    0]
 [  27   48  109   10 1409   13    0]
 [  25   48   82    3    2 3098    0]
 [  17   12   34    1    3    2 1303]]

===multilabel confusion matrix===

[[[26105   491]
  [  406  3407]]

 [[18899   642]
  [ 1081  9787]]

 [[22089  1423]
  [  557  6340]]

 [[27761    63]
  [  420  2165]]

 [[28673   120]
  [  207  1409]]

 [[27035   116]
  [  160  3098]]

 [[28992    45]
  [   69  1303]]]

===scores report===
metrics	scores
Accuracy	0.9046
MCC	0.8786
log_loss	0.3124
f1 score weighted	0.9054
f1 score macro	0.9113
f1 score micro	0.9046
roc_auc ovr	0.9883
roc_auc ovo	0.9903
precision	0.9087
recall	0.9046

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9041104899704044	0.877300718688833	0.3060852921402307	0.9042643560218163	0.9087462298233765	0.9041104899704044	0.9883565593308103	0.9906838590243779	0.9051797040255337	0.9041104899704044
1	0.897632357777047	0.8698389852557227	0.33610126122407513	0.8984035149130063	0.9038996345434581	0.897632357777047	0.9878873909541169	0.9902942297104489	0.9030581932725603	0.897632357777047
2	0.8796448536665571	0.8480510185733215	0.38920210630353097	0.8782421446554419	0.8837855052044187	0.8796448536665572	0.9866316608094804	0.9892115634406804	0.8871935913958436	0.8796448536665571
3	0.9005557565194515	0.8729107754750239	0.33324282938829414	0.900811695989527	0.9034966291175113	0.9005557565194515	0.9878563483433086	0.9896007752149658	0.9039242333028311	0.9005557565194515
4	0.9046334966621724	0.8785896694376778	0.3123501873337696	0.9053500646711844	0.9112604416617781	0.9046334966621724	0.988263129743464	0.9902927837916344	0.9086820639604948	0.9046334966621724
mean	0.8973153909191265	0.8693382334861157	0.33539633527798013	0.8974143552501952	0.9022376880701085	0.8973153909191265	0.9877990178362361	0.9900166422364215	0.9016075571914527	0.8973153909191265
std	0.009193218879046804	0.01109188500760903	0.02929319951370912	0.009899414271691156	0.009680921952789327	0.00919321887904676	0.00061645298336919	0.0005328385221189647	0.007457112339656522	0.009193218879046804

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 68555.5854 secs

