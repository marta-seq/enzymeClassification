/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_700_pre_middle_bilstm_attent_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f32a409c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f32a409c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f32a409c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f32a409c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.86      0.89      3813
         1.0       0.87      0.96      0.91     10869
         2.0       0.90      0.87      0.89      6897
         3.0       0.97      0.82      0.89      2585
         4.0       0.92      0.89      0.90      1616
         5.0       0.99      0.94      0.96      3258
         6.0       0.92      0.98      0.95      1372

    accuracy                           0.91     30410
   macro avg       0.93      0.90      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3283   297   150    15    23     7    38]
 [   88 10399   270    18    30    18    46]
 [   91   704  6004    30    36     6    26]
 [   47   258   111  2129    29     6     5]
 [   23    94    51     3  1437     4     4]
 [   25   130    42     6     6  3048     1]
 [    6     7    14     0     0     0  1345]]

===multilabel confusion matrix===

[[[26317   280]
  [  530  3283]]

 [[18051  1490]
  [  470 10399]]

 [[22875   638]
  [  893  6004]]

 [[27753    72]
  [  456  2129]]

 [[28670   124]
  [  179  1437]]

 [[27111    41]
  [  210  3048]]

 [[28918   120]
  [   27  1345]]]

===scores report===
metrics	scores
Accuracy	0.9091
MCC	0.8834
log_loss	0.3034
f1 score weighted	0.9088
f1 score macro	0.9134
f1 score micro	0.9091
roc_auc ovr	0.9892
roc_auc ovo	0.9911
precision	0.9114
recall	0.9091

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f32a409c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f32a409c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f32a409c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f32a409c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.91      0.87      3813
         1.0       0.95      0.88      0.91     10869
         2.0       0.86      0.90      0.88      6897
         3.0       0.89      0.87      0.88      2585
         4.0       0.87      0.90      0.88      1616
         5.0       0.93      0.97      0.95      3258
         6.0       0.98      0.95      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.90      0.91      0.90     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[3482  109  130   34   31   22    5]
 [ 306 9523  661  141  101  127   10]
 [ 244  262 6184   75   58   61   13]
 [  69   92  129 2252   30   13    0]
 [  39   31   55   23 1462    5    1]
 [  26   29   25    3    8 3165    2]
 [  41    7   18    5    0    0 1301]]

===multilabel confusion matrix===

[[[25872   725]
  [  331  3482]]

 [[19011   530]
  [ 1346  9523]]

 [[22495  1018]
  [  713  6184]]

 [[27544   281]
  [  333  2252]]

 [[28566   228]
  [  154  1462]]

 [[26924   228]
  [   93  3165]]

 [[29007    31]
  [   71  1301]]]

===scores report===
metrics	scores
Accuracy	0.9000
MCC	0.8735
log_loss	0.3220
f1 score weighted	0.9004
f1 score macro	0.9049
f1 score micro	0.9000
roc_auc ovr	0.9881
roc_auc ovo	0.9906
precision	0.9026
recall	0.9000

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f32a409c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f32a409c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f32a409c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f32a409c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.90      0.89      0.89      3814
         1.0       0.95      0.90      0.92     10869
         2.0       0.84      0.93      0.88      6896
         3.0       0.92      0.87      0.89      2584
         4.0       0.91      0.91      0.91      1617
         5.0       0.98      0.95      0.97      3258
         6.0       0.98      0.97      0.98      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.92      0.92     30410
weighted avg       0.92      0.91      0.91     30410


===confusion_matrix===

[[3395  123  211   40   26    9   10]
 [ 152 9812  723   85   59   35    3]
 [ 123  234 6445   44   33    9    8]
 [  64   82  173 2240   19    6    0]
 [  25   36   69   13 1470    2    2]
 [  18   46   72    5   13 3104    0]
 [  11   17   11    2    1    1 1329]]

===multilabel confusion matrix===

[[[26203   393]
  [  419  3395]]

 [[19003   538]
  [ 1057  9812]]

 [[22255  1259]
  [  451  6445]]

 [[27637   189]
  [  344  2240]]

 [[28642   151]
  [  147  1470]]

 [[27090    62]
  [  154  3104]]

 [[29015    23]
  [   43  1329]]]

===scores report===
metrics	scores
Accuracy	0.9140
MCC	0.8907
log_loss	0.2957
f1 score weighted	0.9146
f1 score macro	0.9207
f1 score micro	0.9140
roc_auc ovr	0.9902
roc_auc ovo	0.9918
precision	0.9169
recall	0.9140

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f32a409c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f32a409c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f32a409c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f32a409c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.89      0.88      3813
         1.0       0.88      0.95      0.92     10868
         2.0       0.94      0.83      0.88      6897
         3.0       0.93      0.86      0.89      2585
         4.0       0.95      0.85      0.90      1616
         5.0       0.90      0.97      0.94      3258
         6.0       0.97      0.95      0.96      1372

    accuracy                           0.90     30409
   macro avg       0.92      0.90      0.91     30409
weighted avg       0.91      0.90      0.90     30409


===confusion_matrix===

[[ 3399   229    82    32    13    38    20]
 [  161 10333   161    40    22   140    11]
 [  241   737  5701    77    30   102     9]
 [   80   181    66  2222     8    23     5]
 [   39   114    45    16  1379    23     0]
 [   13    56    20     2     3  3164     0]
 [   17    27    12     2     1     9  1304]]

===multilabel confusion matrix===

[[[26045   551]
  [  414  3399]]

 [[18197  1344]
  [  535 10333]]

 [[23126   386]
  [ 1196  5701]]

 [[27655   169]
  [  363  2222]]

 [[28716    77]
  [  237  1379]]

 [[26816   335]
  [   94  3164]]

 [[28992    45]
  [   68  1304]]]

===scores report===
metrics	scores
Accuracy	0.9044
MCC	0.8780
log_loss	0.3075
f1 score weighted	0.9038
f1 score macro	0.9081
f1 score micro	0.9044
roc_auc ovr	0.9893
roc_auc ovo	0.9909
precision	0.9064
recall	0.9044

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f32a409c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f32a409c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f32a409c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f32a409c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.92      0.90      3813
         1.0       0.93      0.94      0.93     10868
         2.0       0.91      0.88      0.90      6897
         3.0       0.95      0.88      0.91      2585
         4.0       0.95      0.90      0.92      1616
         5.0       0.94      0.98      0.96      3258
         6.0       0.97      0.98      0.97      1372

    accuracy                           0.92     30409
   macro avg       0.93      0.93      0.93     30409
weighted avg       0.92      0.92      0.92     30409


===confusion_matrix===

[[ 3513   137   100    19    11    22    11]
 [  175 10238   310    36    18    79    12]
 [  167   464  6091    56    26    78    15]
 [   64   106    91  2287    20    15     2]
 [   34    60    41    12  1450    19     0]
 [   14    25    20     4     1  3193     1]
 [   10    13     7     1     0     2  1339]]

===multilabel confusion matrix===

[[[26132   464]
  [  300  3513]]

 [[18736   805]
  [  630 10238]]

 [[22943   569]
  [  806  6091]]

 [[27696   128]
  [  298  2287]]

 [[28717    76]
  [  166  1450]]

 [[26936   215]
  [   65  3193]]

 [[28996    41]
  [   33  1339]]]

===scores report===
metrics	scores
Accuracy	0.9244
MCC	0.9033
log_loss	0.2690
f1 score weighted	0.9242
f1 score macro	0.9291
f1 score micro	0.9244
roc_auc ovr	0.9922
roc_auc ovo	0.9938
precision	0.9247
recall	0.9244

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9090759618546531	0.8834281798115672	0.3033550070261831	0.9087813708361022	0.9134176836708402	0.9090759618546531	0.9891687720005424	0.9910918196776873	0.9114480771455382	0.9090759618546531
1	0.9	0.8734880701890606	0.3219513651558822	0.9003859854771191	0.9049123703675807	0.9	0.9880926333429462	0.9905748967960747	0.9026420863896308	0.9
2	0.9140085498191385	0.8906953391717023	0.29572424817433957	0.9145536995474237	0.9206693674812346	0.9140085498191385	0.9902175562065555	0.9918132835062125	0.9169200732345958	0.9140085498191385
3	0.9044033016541155	0.8779513182433628	0.307531328590614	0.9037951606004507	0.9080514868981256	0.9044033016541155	0.9893018507673541	0.9908713756315805	0.9064090388800309	0.9044033016541155
4	0.9244302673550594	0.9033075634490119	0.26899452084572617	0.9242429512141063	0.9291278524605072	0.9244302673550594	0.992158999134375	0.9937586278111077	0.9246884416850905	0.9244302673550594
mean	0.9103836161365934	0.8857740941729408	0.29951129395854903	0.9103518335350405	0.9152357521756576	0.9103836161365934	0.9897879622903545	0.9916220006845325	0.9124215434669771	0.9103836161365934
std	0.008434952990486856	0.010481285416975593	0.01748294619323877	0.008430815724865402	0.00876362799569692	0.008434952990486856	0.0013638334147726063	0.001143916169939814	0.0077903682939689965	0.008434952990486856

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 88118.5354 secs

