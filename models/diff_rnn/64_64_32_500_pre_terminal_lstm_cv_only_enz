/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_terminal_lstm_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9c3879c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9c3879c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9c3879c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9c3879c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.86      0.83      3813
         1.0       0.92      0.86      0.89     10869
         2.0       0.86      0.82      0.84      6897
         3.0       0.88      0.82      0.85      2585
         4.0       0.72      0.87      0.79      1616
         5.0       0.84      0.96      0.90      3258
         6.0       0.87      0.97      0.91      1372

    accuracy                           0.86     30410
   macro avg       0.84      0.88      0.86     30410
weighted avg       0.87      0.86      0.86     30410


===confusion_matrix===

[[3289  123  169   44   71   78   39]
 [ 405 9314  492  118  180  260  100]
 [ 239  508 5647  114  204  131   54]
 [ 103  110  114 2129   71   55    3]
 [  33   51   65   13 1409   43    2]
 [  30   47   36    6   22 3112    5]
 [   9   14   13    1    3    7 1325]]

===multilabel confusion matrix===

[[[25778   819]
  [  524  3289]]

 [[18688   853]
  [ 1555  9314]]

 [[22624   889]
  [ 1250  5647]]

 [[27529   296]
  [  456  2129]]

 [[28243   551]
  [  207  1409]]

 [[26578   574]
  [  146  3112]]

 [[28835   203]
  [   47  1325]]]

===scores report===
metrics	scores
Accuracy	0.8624
MCC	0.8263
log_loss	0.4127
f1 score weighted	0.8627
f1 score macro	0.8578
f1 score micro	0.8624
roc_auc ovr	0.9805
roc_auc ovo	0.9845
precision	0.8662
recall	0.8624

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9c3879c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9c3879c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9c3879c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9c3879c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.87      0.86      3813
         1.0       0.92      0.87      0.89     10869
         2.0       0.77      0.91      0.83      6897
         3.0       0.90      0.83      0.86      2585
         4.0       0.93      0.83      0.87      1616
         5.0       0.99      0.90      0.94      3258
         6.0       0.97      0.94      0.96      1372

    accuracy                           0.88     30410
   macro avg       0.90      0.88      0.89     30410
weighted avg       0.88      0.88      0.88     30410


===confusion_matrix===

[[3305  152  290   38   15    3   10]
 [ 242 9413 1057  109   24   14   10]
 [ 167  374 6263   49   25    8   11]
 [  80  103  226 2157   17    0    2]
 [  38   52  155   29 1337    5    0]
 [  49   91  150   24   22 2921    1]
 [  11   31   40    1    2    0 1287]]

===multilabel confusion matrix===

[[[26010   587]
  [  508  3305]]

 [[18738   803]
  [ 1456  9413]]

 [[21595  1918]
  [  634  6263]]

 [[27575   250]
  [  428  2157]]

 [[28689   105]
  [  279  1337]]

 [[27122    30]
  [  337  2921]]

 [[29004    34]
  [   85  1287]]]

===scores report===
metrics	scores
Accuracy	0.8774
MCC	0.8444
log_loss	0.3712
f1 score weighted	0.8790
f1 score macro	0.8881
f1 score micro	0.8774
roc_auc ovr	0.9830
roc_auc ovo	0.9857
precision	0.8849
recall	0.8774

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9c3879c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9c3879c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9c3879c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9c3879c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.89      0.81      3814
         1.0       0.90      0.88      0.89     10869
         2.0       0.86      0.83      0.84      6896
         3.0       0.79      0.87      0.83      2584
         4.0       0.90      0.82      0.86      1617
         5.0       0.99      0.86      0.92      3258
         6.0       0.93      0.94      0.93      1372

    accuracy                           0.87     30410
   macro avg       0.87      0.87      0.87     30410
weighted avg       0.87      0.87      0.87     30410


===confusion_matrix===

[[3401  129  170   78   15    1   20]
 [ 451 9618  484  210   46    5   55]
 [ 368  549 5708  215   37    4   15]
 [  85  131  106 2246   13    2    1]
 [  49   86   83   57 1334    2    6]
 [ 179  132   80   36   43 2787    1]
 [  26   14   40    1    2    1 1288]]

===multilabel confusion matrix===

[[[25438  1158]
  [  413  3401]]

 [[18500  1041]
  [ 1251  9618]]

 [[22551   963]
  [ 1188  5708]]

 [[27229   597]
  [  338  2246]]

 [[28637   156]
  [  283  1334]]

 [[27137    15]
  [  471  2787]]

 [[28940    98]
  [   84  1288]]]

===scores report===
metrics	scores
Accuracy	0.8675
MCC	0.8315
log_loss	0.3988
f1 score weighted	0.8687
f1 score macro	0.8697
f1 score micro	0.8675
roc_auc ovr	0.9809
roc_auc ovo	0.9840
precision	0.8733
recall	0.8675

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9c3879c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9c3879c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9c3879c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9c3879c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00      3813
         1.0       0.36      1.00      0.53     10868
         2.0       0.00      0.00      0.00      6897
         3.0       0.00      0.00      0.00      2585
         4.0       0.00      0.00      0.00      1616
         5.0       0.00      0.00      0.00      3258
         6.0       0.00      0.00      0.00      1372

    accuracy                           0.36     30409
   macro avg       0.05      0.14      0.08     30409
weighted avg       0.13      0.36      0.19     30409


===confusion_matrix===

[[    0  3813     0     0     0     0     0]
 [    0 10868     0     0     0     0     0]
 [    0  6897     0     0     0     0     0]
 [    0  2585     0     0     0     0     0]
 [    0  1616     0     0     0     0     0]
 [    0  3258     0     0     0     0     0]
 [    0  1372     0     0     0     0     0]]

===multilabel confusion matrix===

[[[26596     0]
  [ 3813     0]]

 [[    0 19541]
  [    0 10868]]

 [[23512     0]
  [ 6897     0]]

 [[27824     0]
  [ 2585     0]]

 [[28793     0]
  [ 1616     0]]

 [[27151     0]
  [ 3258     0]]

 [[29037     0]
  [ 1372     0]]]

===scores report===
metrics	scores
Accuracy	0.3574
MCC	0.0000
log_loss	1.7092
f1 score weighted	0.1882
f1 score macro	0.0752
f1 score micro	0.3574
roc_auc ovr	0.5000
roc_auc ovo	0.5000
precision	0.1277
recall	0.3574

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9c3879c1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9c3879c820>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9c3879c880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9c3879c1f0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00      3813
         1.0       0.36      1.00      0.53     10868
         2.0       0.00      0.00      0.00      6897
         3.0       0.00      0.00      0.00      2585
         4.0       0.00      0.00      0.00      1616
         5.0       0.00      0.00      0.00      3258
         6.0       0.00      0.00      0.00      1372

    accuracy                           0.36     30409
   macro avg       0.05      0.14      0.08     30409
weighted avg       0.13      0.36      0.19     30409


===confusion_matrix===

[[    0  3813     0     0     0     0     0]
 [    0 10868     0     0     0     0     0]
 [    0  6897     0     0     0     0     0]
 [    0  2585     0     0     0     0     0]
 [    0  1616     0     0     0     0     0]
 [    0  3258     0     0     0     0     0]
 [    0  1372     0     0     0     0     0]]

===multilabel confusion matrix===

[[[26596     0]
  [ 3813     0]]

 [[    0 19541]
  [    0 10868]]

 [[23512     0]
  [ 6897     0]]

 [[27824     0]
  [ 2585     0]]

 [[28793     0]
  [ 1616     0]]

 [[27151     0]
  [ 3258     0]]

 [[29037     0]
  [ 1372     0]]]

===scores report===
metrics	scores
Accuracy	0.3574
MCC	0.0000
log_loss	1.7092
f1 score weighted	0.1882
f1 score macro	0.0752
f1 score micro	0.3574
roc_auc ovr	0.5000
roc_auc ovo	0.5000
precision	0.1277
recall	0.3574

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8623807957908582	0.826294010725654	0.41265079340403643	0.8626915896109216	0.8578262193683531	0.8623807957908584	0.980466934361207	0.9845078263740435	0.8661744791432043	0.8623807957908582
1	0.8774416310424202	0.8444384463538396	0.3712031920851444	0.8789569637196386	0.8881153624482091	0.8774416310424202	0.9829676835527494	0.9857056201253679	0.8848742089195755	0.8774416310424202
2	0.8675435711936863	0.83152688599497	0.398842347263806	0.8687402617916076	0.8696560283587077	0.8675435711936863	0.9809373230489355	0.9839873214668434	0.8733272650245296	0.8675435711936863
3	0.3573941925087967	0.0	1.709201082701418	0.18819972789619416	0.07522695101734277	0.3573941925087967	0.5	0.5	0.12773060883901485	0.3573941925087967
4	0.3573941925087967	0.0	1.7092009879972836	0.18819972789619416	0.07522695101734277	0.3573941925087967	0.5	0.5	0.12773060883901485	0.3573941925087967
mean	0.6644308766089116	0.5004518686148927	0.9202196806903377	0.5973576541829111	0.5532103024419912	0.6644308766089116	0.7888743881925784	0.790840153593251	0.5759674341530678	0.6644308766089116
std	0.250741129245422	0.40865992707222376	0.6443388487296942	0.3341165082483253	0.3903911684431123	0.2507411292454221	0.23586644793359604	0.23747064486752423	0.36603248397094457	0.250741129245422

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 32715.4402 secs

