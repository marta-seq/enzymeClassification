/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_500_pre_pre_bilst_attention_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd35471b430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd35471b6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd35471b640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd35471b400>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.78      0.77      4541
         1.0       0.83      0.89      0.86      3813
         2.0       0.91      0.89      0.90     10869
         3.0       0.85      0.84      0.84      6897
         4.0       0.84      0.88      0.86      2585
         5.0       0.93      0.85      0.89      1617
         6.0       0.95      0.96      0.95      3258
         7.0       0.95      0.95      0.95      1372

    accuracy                           0.87     34952
   macro avg       0.88      0.88      0.88     34952
weighted avg       0.87      0.87      0.87     34952


===confusion_matrix===

[[3522  153  279  412   72   28   39   36]
 [  83 3386  132  138   43    8   16    7]
 [ 492  245 9621  314  130   22   40    5]
 [ 346  162  352 5805  128   25   67   12]
 [  42   49  111   99 2272    5    7    0]
 [  37   36   54   59   38 1381   10    2]
 [  13   31   47   29   14    7 3117    0]
 [  27    8   11   12    3    2    2 1307]]

===multilabel confusion matrix===

[[[29371  1040]
  [ 1019  3522]]

 [[30455   684]
  [  427  3386]]

 [[23097   986]
  [ 1248  9621]]

 [[26992  1063]
  [ 1092  5805]]

 [[31939   428]
  [  313  2272]]

 [[33238    97]
  [  236  1381]]

 [[31513   181]
  [  141  3117]]

 [[33518    62]
  [   65  1307]]]

===scores report===
metrics	scores
Accuracy	0.8701
MCC	0.8415
log_loss	0.4139
f1 score weighted	0.8703
f1 score macro	0.8786
f1 score micro	0.8701
roc_auc ovr	0.9823
roc_auc ovo	0.9855
precision	0.8709
recall	0.8701

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd35471b430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd35471b6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd35471b640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd35471b400>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.81      0.75      0.78      4541
         1.0       0.84      0.90      0.87      3813
         2.0       0.88      0.92      0.90     10869
         3.0       0.86      0.84      0.85      6897
         4.0       0.94      0.86      0.90      2585
         5.0       0.94      0.86      0.90      1616
         6.0       0.95      0.96      0.96      3258
         7.0       0.96      0.96      0.96      1372

    accuracy                           0.88     34951
   macro avg       0.90      0.88      0.89     34951
weighted avg       0.88      0.88      0.88     34951


===confusion_matrix===

[[ 3392   128   483   417    26    24    35    36]
 [   70  3442   153   100    19    12     9     8]
 [  314   191 10003   243    36    16    61     5]
 [  307   191   490  5788    46    25    41     9]
 [   47    66   152    78  2225     7     9     1]
 [   42    43    67    53    13  1389     9     0]
 [   16    30    47    29     4     1  3131     0]
 [   22    10     9    12     0     0     1  1318]]

===multilabel confusion matrix===

[[[29592   818]
  [ 1149  3392]]

 [[30479   659]
  [  371  3442]]

 [[22681  1401]
  [  866 10003]]

 [[27122   932]
  [ 1109  5788]]

 [[32222   144]
  [  360  2225]]

 [[33250    85]
  [  227  1389]]

 [[31528   165]
  [  127  3131]]

 [[33520    59]
  [   54  1318]]]

===scores report===
metrics	scores
Accuracy	0.8780
MCC	0.8506
log_loss	0.3940
f1 score weighted	0.8774
f1 score macro	0.8881
f1 score micro	0.8780
roc_auc ovr	0.9841
roc_auc ovo	0.9868
precision	0.8781
recall	0.8780

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd35471b430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd35471b6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd35471b640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd35471b400>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.79      0.80      4542
         1.0       0.82      0.92      0.87      3814
         2.0       0.90      0.92      0.91     10869
         3.0       0.90      0.81      0.85      6896
         4.0       0.89      0.88      0.89      2584
         5.0       0.89      0.89      0.89      1616
         6.0       0.96      0.96      0.96      3258
         7.0       0.96      0.97      0.96      1372

    accuracy                           0.88     34951
   macro avg       0.89      0.89      0.89     34951
weighted avg       0.88      0.88      0.88     34951


===confusion_matrix===

[[ 3602   159   364   244    80    40    20    33]
 [   64  3506   105    66    33    13    18     9]
 [  320   224 10009   173    61    36    41     5]
 [  440   248   436  5567    88    55    51    11]
 [   33    69   128    51  2277    20     6     0]
 [   30    41    50    30    13  1445     7     0]
 [   16    30    41    23     5     6  3137     0]
 [   13    12     7     8     2     0     1  1329]]

===multilabel confusion matrix===

[[[29493   916]
  [  940  3602]]

 [[30354   783]
  [  308  3506]]

 [[22951  1131]
  [  860 10009]]

 [[27460   595]
  [ 1329  5567]]

 [[32085   282]
  [  307  2277]]

 [[33165   170]
  [  171  1445]]

 [[31549   144]
  [  121  3137]]

 [[33521    58]
  [   43  1329]]]

===scores report===
metrics	scores
Accuracy	0.8833
MCC	0.8577
log_loss	0.3968
f1 score weighted	0.8829
f1 score macro	0.8907
f1 score micro	0.8833
roc_auc ovr	0.9857
roc_auc ovo	0.9883
precision	0.8844
recall	0.8833

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd35471b430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd35471b6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd35471b640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd35471b400>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.81      0.80      4542
         1.0       0.82      0.91      0.86      3813
         2.0       0.93      0.90      0.91     10868
         3.0       0.88      0.85      0.87      6897
         4.0       0.90      0.88      0.89      2585
         5.0       0.92      0.88      0.90      1616
         6.0       0.95      0.96      0.96      3258
         7.0       0.95      0.97      0.96      1372

    accuracy                           0.89     34951
   macro avg       0.89      0.90      0.89     34951
weighted avg       0.89      0.89      0.89     34951


===confusion_matrix===

[[3666  171  242  331   40   27   22   43]
 [  73 3479  101   94   28   11   15   12]
 [ 387  255 9817  229   73   32   69    6]
 [ 375  203  273 5874   77   32   55    8]
 [  52   76   86   70 2284   11    5    1]
 [  40   41   48   36   22 1421    8    0]
 [  32   27   30   16    6    4 3141    2]
 [  12    8    2   11    2    0    0 1337]]

===multilabel confusion matrix===

[[[29438   971]
  [  876  3666]]

 [[30357   781]
  [  334  3479]]

 [[23301   782]
  [ 1051  9817]]

 [[27267   787]
  [ 1023  5874]]

 [[32118   248]
  [  301  2284]]

 [[33218   117]
  [  195  1421]]

 [[31519   174]
  [  117  3141]]

 [[33507    72]
  [   35  1337]]]

===scores report===
metrics	scores
Accuracy	0.8875
MCC	0.8629
log_loss	0.3809
f1 score weighted	0.8877
f1 score macro	0.8941
f1 score micro	0.8875
roc_auc ovr	0.9863
roc_auc ovo	0.9888
precision	0.8889
recall	0.8875

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd35471b430>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd35471b6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd35471b640>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd35471b400>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.74      0.78      4542
         1.0       0.88      0.90      0.89      3813
         2.0       0.91      0.91      0.91     10868
         3.0       0.82      0.88      0.85      6897
         4.0       0.92      0.89      0.90      2585
         5.0       0.88      0.89      0.89      1616
         6.0       0.96      0.96      0.96      3258
         7.0       0.97      0.94      0.95      1372

    accuracy                           0.88     34951
   macro avg       0.90      0.89      0.89     34951
weighted avg       0.88      0.88      0.88     34951


===confusion_matrix===

[[3377  118  329  592   40   40   23   23]
 [  61 3418  137  124   26   27   11    9]
 [ 261  132 9892  418   67   54   43    1]
 [ 277  141  295 6052   49   40   38    5]
 [  44   54   84   95 2290   14    4    0]
 [  36   17   48   48   19 1439    9    0]
 [  14   14   45   49    8    6 3122    0]
 [  32   11   11   24    1    6    1 1286]]

===multilabel confusion matrix===

[[[29684   725]
  [ 1165  3377]]

 [[30651   487]
  [  395  3418]]

 [[23134   949]
  [  976  9892]]

 [[26704  1350]
  [  845  6052]]

 [[32156   210]
  [  295  2290]]

 [[33148   187]
  [  177  1439]]

 [[31564   129]
  [  136  3122]]

 [[33541    38]
  [   86  1286]]]

===scores report===
metrics	scores
Accuracy	0.8834
MCC	0.8574
log_loss	0.3935
f1 score weighted	0.8831
f1 score macro	0.8908
f1 score micro	0.8834
roc_auc ovr	0.9857
roc_auc ovo	0.9882
precision	0.8839
recall	0.8834

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8700789654383154	0.8414760183940666	0.4138737019523667	0.8702530687897907	0.8786306579061909	0.8700789654383154	0.9822542875729078	0.9854939194572866	0.8709459184733337	0.8700789654383154
1	0.8780292409373123	0.8505666487614547	0.3939551093406921	0.8774082586769464	0.8881302925781565	0.8780292409373123	0.9840533565093442	0.9868447895714308	0.8781420312691464	0.8780292409373123
2	0.8832937541129009	0.8576960831405364	0.3968481439912943	0.8829206130381552	0.8906872702029965	0.8832937541129009	0.9857326654331011	0.9883348453965732	0.8843599737475994	0.8832937541129009
3	0.8874996423564419	0.8629142666860183	0.3808850936995582	0.8877417360940008	0.894102363664911	0.8874996423564419	0.9862706235493852	0.988835701981443	0.8888692886258562	0.8874996423564419
4	0.8834082000515007	0.8574455155757276	0.3934792545486953	0.8831167018843644	0.8908247223551442	0.8834082000515007	0.9856896304687081	0.9881526870717444	0.8838602949290592	0.8834082000515007
mean	0.8804619605792942	0.8540197065115607	0.3958082607065213	0.8802880756966515	0.8884750613414798	0.8804619605792942	0.9848001127066892	0.9875323886956956	0.881235501408999	0.8804619605792942
std	0.005999217605572146	0.0073977406412199095	0.010573560212517081	0.005991379506774153	0.0052747028515792976	0.005999217605572146	0.0014739178406572191	0.0012128876076988617	0.006170440019738895	0.005999217605572146

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 73719.0539 secs

