/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_lstm_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd9d071c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd9d071c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd9d071c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd9d071c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.83      0.85      3813
         1.0       0.95      0.83      0.88     10869
         2.0       0.75      0.91      0.82      6897
         3.0       0.90      0.82      0.86      2585
         4.0       0.81      0.84      0.83      1616
         5.0       0.89      0.95      0.92      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.87     30410
   macro avg       0.88      0.88      0.87     30410
weighted avg       0.88      0.87      0.87     30410


===confusion_matrix===

[[3160  106  355   55   54   73   10]
 [ 219 9011 1253   97  112  156   21]
 [ 114  235 6287   62   79  105   15]
 [  66   78  234 2129   48   29    1]
 [  38   38  155   12 1358   15    0]
 [  26   45   85    6   12 3083    1]
 [  12   10   21    0    5    5 1319]]

===multilabel confusion matrix===

[[[26122   475]
  [  653  3160]]

 [[19029   512]
  [ 1858  9011]]

 [[21410  2103]
  [  610  6287]]

 [[27593   232]
  [  456  2129]]

 [[28484   310]
  [  258  1358]]

 [[26769   383]
  [  175  3083]]

 [[28990    48]
  [   53  1319]]]

===scores report===
metrics	scores
Accuracy	0.8664
MCC	0.8326
log_loss	0.4008
f1 score weighted	0.8677
f1 score macro	0.8747
f1 score micro	0.8664
roc_auc ovr	0.9813
roc_auc ovo	0.9848
precision	0.8759
recall	0.8664

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd9d071c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd9d071c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd9d071c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd9d071c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.91      0.80      0.85      3813
         1.0       0.85      0.93      0.89     10869
         2.0       0.84      0.84      0.84      6897
         3.0       0.92      0.80      0.86      2585
         4.0       0.86      0.82      0.84      1616
         5.0       0.96      0.92      0.94      3258
         6.0       0.97      0.94      0.96      1372

    accuracy                           0.88     30410
   macro avg       0.90      0.87      0.88     30410
weighted avg       0.88      0.88      0.88     30410


===confusion_matrix===

[[ 3059   403   250    46    20    27     8]
 [   92 10117   492    51    65    41    11]
 [  103   816  5817    52    59    29    21]
 [   53   229   171  2072    43    17     0]
 [   22   132   101    22  1330     9     0]
 [   13   147    65     5    21  3004     3]
 [   10    34    23     2     3     4  1296]]

===multilabel confusion matrix===

[[[26304   293]
  [  754  3059]]

 [[17780  1761]
  [  752 10117]]

 [[22411  1102]
  [ 1080  5817]]

 [[27647   178]
  [  513  2072]]

 [[28583   211]
  [  286  1330]]

 [[27025   127]
  [  254  3004]]

 [[28995    43]
  [   76  1296]]]

===scores report===
metrics	scores
Accuracy	0.8778
MCC	0.8428
log_loss	0.3712
f1 score weighted	0.8775
f1 score macro	0.8831
f1 score micro	0.8778
roc_auc ovr	0.9821
roc_auc ovo	0.9846
precision	0.8801
recall	0.8778

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd9d071c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd9d071c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd9d071c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd9d071c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.83      0.84      3814
         1.0       0.92      0.87      0.89     10869
         2.0       0.85      0.83      0.84      6896
         3.0       0.79      0.86      0.82      2584
         4.0       0.70      0.88      0.78      1617
         5.0       0.89      0.95      0.92      3258
         6.0       0.95      0.96      0.96      1372

    accuracy                           0.87     30410
   macro avg       0.85      0.88      0.86     30410
weighted avg       0.87      0.87      0.87     30410


===confusion_matrix===

[[3170  148  193   88  118   75   22]
 [ 214 9439  612  205  219  156   24]
 [ 187  463 5693  245  196   91   21]
 [  51  119  105 2224   62   23    0]
 [  35   39   68   33 1422   19    1]
 [  17   43   53   12   25 3108    0]
 [  19   15   13    4    2    3 1316]]

===multilabel confusion matrix===

[[[26073   523]
  [  644  3170]]

 [[18714   827]
  [ 1430  9439]]

 [[22470  1044]
  [ 1203  5693]]

 [[27239   587]
  [  360  2224]]

 [[28171   622]
  [  195  1422]]

 [[26785   367]
  [  150  3108]]

 [[28970    68]
  [   56  1316]]]

===scores report===
metrics	scores
Accuracy	0.8672
MCC	0.8319
log_loss	0.3967
f1 score weighted	0.8679
f1 score macro	0.8646
f1 score micro	0.8672
roc_auc ovr	0.9812
roc_auc ovo	0.9850
precision	0.8708
recall	0.8672

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd9d071c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd9d071c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd9d071c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd9d071c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00      3813
         1.0       0.36      1.00      0.53     10868
         2.0       0.00      0.00      0.00      6897
         3.0       0.00      0.00      0.00      2585
         4.0       0.00      0.00      0.00      1616
         5.0       0.00      0.00      0.00      3258
         6.0       0.00      0.00      0.00      1372

    accuracy                           0.36     30409
   macro avg       0.05      0.14      0.08     30409
weighted avg       0.13      0.36      0.19     30409


===confusion_matrix===

[[    0  3813     0     0     0     0     0]
 [    0 10868     0     0     0     0     0]
 [    0  6897     0     0     0     0     0]
 [    0  2585     0     0     0     0     0]
 [    0  1616     0     0     0     0     0]
 [    0  3258     0     0     0     0     0]
 [    0  1372     0     0     0     0     0]]

===multilabel confusion matrix===

[[[26596     0]
  [ 3813     0]]

 [[    0 19541]
  [    0 10868]]

 [[23512     0]
  [ 6897     0]]

 [[27824     0]
  [ 2585     0]]

 [[28793     0]
  [ 1616     0]]

 [[27151     0]
  [ 3258     0]]

 [[29037     0]
  [ 1372     0]]]

===scores report===
metrics	scores
Accuracy	0.3574
MCC	0.0000
log_loss	1.7092
f1 score weighted	0.1882
f1 score macro	0.0752
f1 score micro	0.3574
roc_auc ovr	0.5000
roc_auc ovo	0.5000
precision	0.1277
recall	0.3574

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd9d071c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fd9d071c1f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd9d071c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fd9d071c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.86      0.85      3813
         1.0       0.85      0.93      0.89     10868
         2.0       0.91      0.75      0.82      6897
         3.0       0.87      0.84      0.86      2585
         4.0       0.95      0.79      0.86      1616
         5.0       0.88      0.96      0.92      3258
         6.0       0.90      0.97      0.94      1372

    accuracy                           0.87     30409
   macro avg       0.89      0.87      0.88     30409
weighted avg       0.87      0.87      0.87     30409


===confusion_matrix===

[[ 3292   273    72    75    11    58    32]
 [  214 10154   232    65    15   131    57]
 [  271  1097  5164   137    25   154    49]
 [   81   200    84  2168     8    43     1]
 [   49   144    80    32  1278    30     3]
 [   27    81    24     6     2  3115     3]
 [    9    16    11     0     0     2  1334]]

===multilabel confusion matrix===

[[[25945   651]
  [  521  3292]]

 [[17730  1811]
  [  714 10154]]

 [[23009   503]
  [ 1733  5164]]

 [[27509   315]
  [  417  2168]]

 [[28732    61]
  [  338  1278]]

 [[26733   418]
  [  143  3115]]

 [[28892   145]
  [   38  1334]]]

===scores report===
metrics	scores
Accuracy	0.8716
MCC	0.8365
log_loss	0.3891
f1 score weighted	0.8700
f1 score macro	0.8763
f1 score micro	0.8716
roc_auc ovr	0.9819
roc_auc ovo	0.9851
precision	0.8748
recall	0.8716

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8663926340019731	0.8325712519050503	0.4007746307048198	0.8676501655899737	0.8747048064435239	0.8663926340019731	0.9812856780854488	0.9848065368605908	0.8758981831774477	0.8663926340019731
1	0.8778362380795791	0.8428222671727081	0.371222192835795	0.8774888901860547	0.88308441352508	0.8778362380795791	0.9821425959910333	0.9845760507378046	0.8801320837930035	0.8778362380795791
2	0.8672147319960539	0.8319392645280409	0.3967441650620263	0.8679205583926228	0.8646371509267111	0.8672147319960539	0.9812316419463599	0.9849928023538889	0.8708483060663471	0.8672147319960539
3	0.3573941925087967	0.0	1.709202714048537	0.18819972789619416	0.07522695101734277	0.3573941925087967	0.5	0.5	0.12773060883901485	0.3573941925087967
4	0.8716169555065935	0.8364743621379732	0.38913213038671396	0.8699645843703446	0.8762969185220666	0.8716169555065935	0.9818517697072842	0.9850823557448254	0.8747672145261695	0.8716169555065935
mean	0.7680909504185992	0.6687614291487545	0.6534151666075785	0.7342447852870378	0.7147900480869449	0.7680909504185992	0.8853023371460251	0.887891549139422	0.7258752792803965	0.7680909504185992
std	0.20538852641782804	0.33440314482165095	0.5279910958391828	0.2730458386284802	0.31983598982570666	0.20538852641782804	0.19265147439281521	0.1939458521611285	0.2990869663112336	0.20538852641782804

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 31670.5683 secs

