/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_3level_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f84d151b760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f84d151b8b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f84d151bc40>]/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_3level_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f12a8350460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f12a8350310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f12a83507f0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f12a8350610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.84      0.80       358
         1.0       0.64      0.58      0.61        12
         2.0       0.69      0.47      0.56        19
         3.0       0.62      0.62      0.62        80
         4.0       0.42      0.41      0.41        54
         5.0       0.30      0.19      0.23        58
         6.0       0.44      0.40      0.42        45
         7.0       0.61      0.56      0.59        48
         8.0       0.40      0.18      0.25        11
         9.0       0.75      0.43      0.55        21
        10.0       0.67      0.27      0.38        15
        11.0       0.73      0.67      0.70        36
        12.0       0.70      0.58      0.64        12
        13.0       0.91      0.80      0.85        25
        14.0       0.56      0.26      0.36        19
        15.0       0.94      0.77      0.85        22
        16.0       0.67      0.78      0.72        23
        17.0       0.91      0.81      0.86       119
        18.0       0.63      0.67      0.65        18
        19.0       0.50      0.08      0.14        12
        20.0       0.57      0.52      0.55        90
        21.0       0.56      0.42      0.48        12
        22.0       0.82      0.92      0.87        25
        23.0       0.50      0.08      0.14        12
        24.0       0.45      0.23      0.30        22
        25.0       0.75      0.63      0.69        38
        26.0       1.00      0.94      0.97        17
        27.0       0.62      0.23      0.33        35
        28.0       0.50      0.18      0.27        11
        29.0       0.64      0.69      0.67        36
        30.0       0.76      0.91      0.83        32
        31.0       0.81      0.76      0.78        38
        32.0       0.80      0.85      0.83       747
        33.0       0.82      0.84      0.83        74
        34.0       0.96      0.93      0.95        59
        35.0       0.80      0.85      0.83        48
        36.0       0.73      0.76      0.75       502
        37.0       0.75      0.77      0.76       241
        38.0       0.86      0.58      0.69        33
        39.0       0.67      0.79      0.73       344
        40.0       0.77      0.69      0.73       191
        41.0       0.88      0.66      0.75        32
        42.0       0.79      0.80      0.80       384
        43.0       0.81      0.81      0.81       118
        44.0       0.77      0.78      0.78       436
        45.0       0.89      0.83      0.86        48
        46.0       0.82      0.86      0.84       402
        47.0       0.80      0.47      0.59        17
        48.0       0.78      0.69      0.73        42
        49.0       0.91      0.95      0.93        78
        50.0       0.92      0.90      0.91       172
        51.0       0.90      0.45      0.60        20
        52.0       0.73      0.76      0.75       499
        53.0       0.85      0.83      0.84       100
        54.0       0.67      0.18      0.29        11
        55.0       0.87      0.77      0.81       103
        56.0       0.50      0.39      0.44        18
        57.0       0.33      0.10      0.15        10
        58.0       0.94      0.97      0.96        34
        59.0       0.60      0.66      0.63       231
        60.0       0.91      0.72      0.81        58
        61.0       0.13      0.07      0.09        30
        62.0       0.74      0.58      0.65        48
        63.0       0.43      0.36      0.39        50
        64.0       0.88      0.62      0.72        34
        65.0       0.73      0.77      0.75       155
        66.0       0.33      0.14      0.20        14
        67.0       0.76      0.68      0.72       314
        68.0       0.34      0.25      0.29        63
        69.0       0.55      0.80      0.65       308
        70.0       0.62      0.54      0.58        68
        71.0       0.62      0.67      0.64        66
        72.0       0.67      0.29      0.40        14
        73.0       0.70      0.56      0.62        25
        74.0       0.20      0.06      0.09        18
        75.0       0.51      0.38      0.44        60
        76.0       0.81      0.77      0.79       205
        77.0       0.54      0.43      0.48        77
        78.0       0.86      0.81      0.83        59
        79.0       0.71      0.58      0.64       139
        80.0       0.85      0.79      0.81        42
        81.0       0.51      0.62      0.56       175
        82.0       0.65      0.51      0.57        43
        83.0       0.67      0.62      0.64        26
        84.0       0.68      0.67      0.67       106
        85.0       0.78      0.50      0.61        14
        86.0       0.76      0.81      0.78       242
        87.0       0.77      0.81      0.79       309
        88.0       0.87      0.78      0.82        58
        89.0       0.33      0.18      0.24        11
        90.0       0.63      0.65      0.64       187
        91.0       0.49      0.39      0.43        46
        92.0       0.49      0.42      0.45        40
        93.0       0.88      0.69      0.77        32
        94.0       0.63      0.79      0.70       289
        95.0       0.11      0.03      0.05        31
        96.0       0.78      0.88      0.83        74
        97.0       0.64      0.59      0.62        27
        98.0       0.87      0.73      0.79        37
        99.0       0.92      0.96      0.94        24
       100.0       0.30      0.24      0.27        25
       101.0       0.67      0.65      0.66        65
       102.0       0.83      0.86      0.84        22
       103.0       0.90      0.81      0.85        64
       104.0       0.63      0.42      0.51        40
       105.0       0.85      0.92      0.88        12
       106.0       0.85      0.75      0.79       114
       107.0       0.80      0.88      0.83       161
       108.0       0.81      0.54      0.65        24
       109.0       0.84      0.69      0.76        52
       110.0       1.00      0.80      0.89        15
       111.0       0.69      0.76      0.73       123
       112.0       0.78      0.50      0.61        42
       113.0       0.81      0.95      0.88       430
       114.0       0.93      0.77      0.84        65
       115.0       0.88      0.68      0.76        31
       116.0       0.80      0.80      0.80       173
       117.0       0.97      0.97      0.97        31
       118.0       0.88      0.85      0.87       117
       119.0       0.87      0.90      0.88       136
       120.0       0.83      0.73      0.78        62
       121.0       0.92      0.87      0.89       224
       122.0       0.87      0.74      0.80        35
       123.0       0.91      0.84      0.87        37
       124.0       0.76      0.84      0.80        31
       125.0       1.00      0.87      0.93        15
       126.0       0.94      0.71      0.81        21
       127.0       0.79      0.84      0.81        73

    accuracy                           0.74     12227
   macro avg       0.71      0.63      0.66     12227
weighted avg       0.74      0.74      0.74     12227


===confusion_matrix===

[[302   0   0 ...   0   0   0]
 [  0   7   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   0  15   5]
 [  0   0   0 ...   0   1  61]]

===multilabel confusion matrix===

[[[11770    99]
  [   56   302]]

 [[12211     4]
  [    5     7]]

 [[12204     4]
  [   10     9]]

 [[12117    30]
  [   30    50]]

 [[12142    31]
  [   32    22]]

 [[12143    26]
  [   47    11]]

 [[12159    23]
  [   27    18]]

 [[12162    17]
  [   21    27]]

 [[12213     3]
  [    9     2]]

 [[12203     3]
  [   12     9]]

 [[12210     2]
  [   11     4]]

 [[12182     9]
  [   12    24]]

 [[12212     3]
  [    5     7]]

 [[12200     2]
  [    5    20]]

 [[12204     4]
  [   14     5]]

 [[12204     1]
  [    5    17]]

 [[12195     9]
  [    5    18]]

 [[12099     9]
  [   23    96]]

 [[12202     7]
  [    6    12]]

 [[12214     1]
  [   11     1]]

 [[12102    35]
  [   43    47]]

 [[12211     4]
  [    7     5]]

 [[12197     5]
  [    2    23]]

 [[12214     1]
  [   11     1]]

 [[12199     6]
  [   17     5]]

 [[12181     8]
  [   14    24]]

 [[12210     0]
  [    1    16]]

 [[12187     5]
  [   27     8]]

 [[12214     2]
  [    9     2]]

 [[12177    14]
  [   11    25]]

 [[12186     9]
  [    3    29]]

 [[12182     7]
  [    9    29]]

 [[11324   156]
  [  109   638]]

 [[12139    14]
  [   12    62]]

 [[12166     2]
  [    4    55]]

 [[12169    10]
  [    7    41]]

 [[11587   138]
  [  121   381]]

 [[11925    61]
  [   55   186]]

 [[12191     3]
  [   14    19]]

 [[11750   133]
  [   72   272]]

 [[11996    40]
  [   59   132]]

 [[12192     3]
  [   11    21]]

 [[11762    81]
  [   77   307]]

 [[12086    23]
  [   22    96]]

 [[11692    99]
  [   96   340]]

 [[12174     5]
  [    8    40]]

 [[11748    77]
  [   56   346]]

 [[12208     2]
  [    9     8]]

 [[12177     8]
  [   13    29]]

 [[12142     7]
  [    4    74]]

 [[12041    14]
  [   17   155]]

 [[12206     1]
  [   11     9]]

 [[11588   140]
  [  119   380]]

 [[12112    15]
  [   17    83]]

 [[12215     1]
  [    9     2]]

 [[12112    12]
  [   24    79]]

 [[12202     7]
  [   11     7]]

 [[12215     2]
  [    9     1]]

 [[12191     2]
  [    1    33]]

 [[11893   103]
  [   79   152]]

 [[12165     4]
  [   16    42]]

 [[12184    13]
  [   28     2]]

 [[12169    10]
  [   20    28]]

 [[12153    24]
  [   32    18]]

 [[12190     3]
  [   13    21]]

 [[12027    45]
  [   35   120]]

 [[12209     4]
  [   12     2]]

 [[11844    69]
  [   99   215]]

 [[12133    31]
  [   47    16]]

 [[11716   203]
  [   62   246]]

 [[12136    23]
  [   31    37]]

 [[12134    27]
  [   22    44]]

 [[12211     2]
  [   10     4]]

 [[12196     6]
  [   11    14]]

 [[12205     4]
  [   17     1]]

 [[12145    22]
  [   37    23]]

 [[11984    38]
  [   47   158]]

 [[12122    28]
  [   44    33]]

 [[12160     8]
  [   11    48]]

 [[12055    33]
  [   58    81]]

 [[12179     6]
  [    9    33]]

 [[11949   103]
  [   67   108]]

 [[12172    12]
  [   21    22]]

 [[12193     8]
  [   10    16]]

 [[12087    34]
  [   35    71]]

 [[12211     2]
  [    7     7]]

 [[11925    60]
  [   47   195]]

 [[11842    76]
  [   58   251]]

 [[12162     7]
  [   13    45]]

 [[12212     4]
  [    9     2]]

 [[11967    73]
  [   65   122]]

 [[12162    19]
  [   28    18]]

 [[12169    18]
  [   23    17]]

 [[12192     3]
  [   10    22]]

 [[11803   135]
  [   61   228]]

 [[12188     8]
  [   30     1]]

 [[12135    18]
  [    9    65]]

 [[12191     9]
  [   11    16]]

 [[12186     4]
  [   10    27]]

 [[12201     2]
  [    1    23]]

 [[12188    14]
  [   19     6]]

 [[12141    21]
  [   23    42]]

 [[12201     4]
  [    3    19]]

 [[12157     6]
  [   12    52]]

 [[12177    10]
  [   23    17]]

 [[12213     2]
  [    1    11]]

 [[12098    15]
  [   29    85]]

 [[12030    36]
  [   20   141]]

 [[12200     3]
  [   11    13]]

 [[12168     7]
  [   16    36]]

 [[12212     0]
  [    3    12]]

 [[12062    42]
  [   29    94]]

 [[12179     6]
  [   21    21]]

 [[11704    93]
  [   23   407]]

 [[12158     4]
  [   15    50]]

 [[12193     3]
  [   10    21]]

 [[12020    34]
  [   35   138]]

 [[12195     1]
  [    1    30]]

 [[12096    14]
  [   17   100]]

 [[12072    19]
  [   14   122]]

 [[12156     9]
  [   17    45]]

 [[11985    18]
  [   29   195]]

 [[12188     4]
  [    9    26]]

 [[12187     3]
  [    6    31]]

 [[12188     8]
  [    5    26]]

 [[12212     0]
  [    2    13]]

 [[12205     1]
  [    6    15]]

 [[12138    16]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.7438
MCC	0.7381
log_loss	1.2674
f1 score weighted	0.7382
f1 score macro	0.6566
f1 score micro	0.7438
roc_auc ovr	0.9814
roc_auc ovo	0.9789
precision	0.7418
recall	0.7438

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f12a8350460>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f12a8350310>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f12a83507f0>]