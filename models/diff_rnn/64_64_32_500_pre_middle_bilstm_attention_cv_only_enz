/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_middle_bilstm_attention_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f72bc0dc1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f72bc0dc7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f72bc0dc850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f72bc0dc610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.90      0.88      3813
         1.0       0.88      0.95      0.91     10869
         2.0       0.91      0.84      0.87      6897
         3.0       0.96      0.85      0.90      2585
         4.0       0.92      0.87      0.90      1616
         5.0       0.98      0.95      0.96      3258
         6.0       0.93      0.97      0.95      1372

    accuracy                           0.91     30410
   macro avg       0.92      0.90      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3429   209   121    12    17     7    18]
 [  165 10303   293    21    29    22    36]
 [  207   742  5814    35    45    22    32]
 [   89   184    94  2188    22     2     6]
 [   40   114    37    11  1408     2     4]
 [   37   103    24     2     5  3087     0]
 [   10    15    10     0     1     4  1332]]

===multilabel confusion matrix===

[[[26049   548]
  [  384  3429]]

 [[18174  1367]
  [  566 10303]]

 [[22934   579]
  [ 1083  5814]]

 [[27744    81]
  [  397  2188]]

 [[28675   119]
  [  208  1408]]

 [[27093    59]
  [  171  3087]]

 [[28942    96]
  [   40  1332]]]

===scores report===
metrics	scores
Accuracy	0.9063
MCC	0.8800
log_loss	0.3097
f1 score weighted	0.9060
f1 score macro	0.9118
f1 score micro	0.9063
roc_auc ovr	0.9886
roc_auc ovo	0.9907
precision	0.9081
recall	0.9063

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f72bc0dc1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f72bc0dc7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f72bc0dc850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f72bc0dc610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.88      0.89      3813
         1.0       0.94      0.89      0.92     10869
         2.0       0.81      0.94      0.87      6897
         3.0       0.94      0.86      0.90      2585
         4.0       0.94      0.87      0.90      1616
         5.0       0.98      0.95      0.97      3258
         6.0       0.99      0.94      0.97      1372

    accuracy                           0.91     30410
   macro avg       0.93      0.90      0.91     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[3358  146  253   25   17    8    6]
 [ 168 9726  870   54   34   17    0]
 [ 104  254 6457   34   28   14    6]
 [  38  137  180 2212   10    8    0]
 [  46   53   99   13 1399    5    1]
 [  21   45   93    3    4 3092    0]
 [  17   18   39    1    1    0 1296]]

===multilabel confusion matrix===

[[[26203   394]
  [  455  3358]]

 [[18888   653]
  [ 1143  9726]]

 [[21979  1534]
  [  440  6457]]

 [[27695   130]
  [  373  2212]]

 [[28700    94]
  [  217  1399]]

 [[27100    52]
  [  166  3092]]

 [[29025    13]
  [   76  1296]]]

===scores report===
metrics	scores
Accuracy	0.9056
MCC	0.8801
log_loss	0.3038
f1 score weighted	0.9065
f1 score macro	0.9145
f1 score micro	0.9056
roc_auc ovr	0.9889
roc_auc ovo	0.9909
precision	0.9105
recall	0.9056

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f72bc0dc1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f72bc0dc7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f72bc0dc850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f72bc0dc610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.94      0.82      0.87      3814
         1.0       0.91      0.91      0.91     10869
         2.0       0.84      0.89      0.87      6896
         3.0       0.87      0.86      0.87      2584
         4.0       0.89      0.87      0.88      1617
         5.0       0.91      0.97      0.94      3258
         6.0       0.98      0.94      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.91      0.89      0.90     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[3122  242  273   76   40   52    9]
 [  85 9939  529  130   60  124    2]
 [  64  484 6116   89   46   87   10]
 [  23  132  174 2220   17   18    0]
 [  17   60   94   17 1411   17    1]
 [   9   43   37    8    7 3154    0]
 [   7   44   22    3    1    9 1286]]

===multilabel confusion matrix===

[[[26391   205]
  [  692  3122]]

 [[18536  1005]
  [  930  9939]]

 [[22385  1129]
  [  780  6116]]

 [[27503   323]
  [  364  2220]]

 [[28622   171]
  [  206  1411]]

 [[26845   307]
  [  104  3154]]

 [[29016    22]
  [   86  1286]]]

===scores report===
metrics	scores
Accuracy	0.8960
MCC	0.8669
log_loss	0.3360
f1 score weighted	0.8959
f1 score macro	0.8996
f1 score micro	0.8960
roc_auc ovr	0.9860
roc_auc ovo	0.9883
precision	0.8973
recall	0.8960

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f72bc0dc1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f72bc0dc7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f72bc0dc850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f72bc0dc610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.93      0.87      3813
         1.0       0.94      0.91      0.93     10868
         2.0       0.88      0.90      0.89      6897
         3.0       0.95      0.87      0.91      2585
         4.0       0.94      0.87      0.90      1616
         5.0       0.96      0.96      0.96      3258
         6.0       0.99      0.95      0.97      1372

    accuracy                           0.91     30409
   macro avg       0.92      0.91      0.92     30409
weighted avg       0.92      0.91      0.91     30409


===confusion_matrix===

[[3533   88  148   18    7   12    7]
 [ 349 9932  429   50   41   63    4]
 [ 235  325 6231   30   25   45    6]
 [  92  115  120 2237   16    5    0]
 [  59   56   66   17 1411    6    1]
 [  31   38   47    3    4 3135    0]
 [  35   14   16    3    0    4 1300]]

===multilabel confusion matrix===

[[[25795   801]
  [  280  3533]]

 [[18905   636]
  [  936  9932]]

 [[22686   826]
  [  666  6231]]

 [[27703   121]
  [  348  2237]]

 [[28700    93]
  [  205  1411]]

 [[27016   135]
  [  123  3135]]

 [[29019    18]
  [   72  1300]]]

===scores report===
metrics	scores
Accuracy	0.9135
MCC	0.8898
log_loss	0.3054
f1 score weighted	0.9140
f1 score macro	0.9177
f1 score micro	0.9135
roc_auc ovr	0.9910
roc_auc ovo	0.9924
precision	0.9161
recall	0.9135

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f72bc0dc1f0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f72bc0dc7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f72bc0dc850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f72bc0dc610>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.88      0.91      0.90      3813
         1.0       0.92      0.94      0.93     10868
         2.0       0.90      0.88      0.89      6897
         3.0       0.95      0.89      0.92      2585
         4.0       0.93      0.88      0.91      1616
         5.0       0.97      0.96      0.97      3258
         6.0       0.98      0.96      0.97      1372

    accuracy                           0.92     30409
   macro avg       0.93      0.92      0.92     30409
weighted avg       0.92      0.92      0.92     30409


===confusion_matrix===

[[ 3487   156   120    12    14    14    10]
 [  160 10268   331    49    27    24     9]
 [  166   533  6076    45    34    36     7]
 [   63   123    83  2289    20     6     1]
 [   42    76    53    12  1422    11     0]
 [   26    54    34     6     7  3131     0]
 [   23     9    25     1     2     0  1312]]

===multilabel confusion matrix===

[[[26116   480]
  [  326  3487]]

 [[18590   951]
  [  600 10268]]

 [[22866   646]
  [  821  6076]]

 [[27699   125]
  [  296  2289]]

 [[28689   104]
  [  194  1422]]

 [[27060    91]
  [  127  3131]]

 [[29010    27]
  [   60  1312]]]

===scores report===
metrics	scores
Accuracy	0.9203
MCC	0.8978
log_loss	0.2904
f1 score weighted	0.9202
f1 score macro	0.9248
f1 score micro	0.9203
roc_auc ovr	0.9910
roc_auc ovo	0.9926
precision	0.9208
recall	0.9203

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9063137125945413	0.880019022696139	0.3097412004693934	0.906044195562372	0.9117911220508651	0.9063137125945413	0.9885778269225508	0.9906636148169287	0.9080969078478195	0.9063137125945413
1	0.9056231502795133	0.8800589482021213	0.30383197765385783	0.9065061624932672	0.914469416546307	0.9056231502795133	0.9889384782543628	0.9909064004897407	0.9105239309517421	0.9056231502795133
2	0.8960210457086485	0.8668800580377075	0.3359946277228783	0.8959028888453399	0.8996238722866343	0.8960210457086485	0.9860488619674894	0.9882537394568992	0.8973102410620291	0.8960210457086485
3	0.9135124469729357	0.8897654829801713	0.3053822197521252	0.9140167242026831	0.9176688598079376	0.9135124469729357	0.9909761483893064	0.9924105259612425	0.9160823112160289	0.9135124469729357
4	0.9202867572100365	0.8977997378211967	0.29036572055622395	0.9202299416690793	0.9248096027860422	0.9202867572100365	0.9909670474311256	0.9925993125224551	0.9207766957393957	0.9202867572100365
mean	0.9083514225531351	0.8829046499474673	0.30906314923089573	0.9085399825545484	0.9136725746955573	0.9083514225531351	0.9891016725929671	0.9909667186494533	0.9105580173634029	0.9083514225531351
std	0.008157478912451156	0.010412944651732061	0.014941703545357054	0.008206233695759863	0.008264920444281182	0.008157478912451156	0.0018228539267583943	0.0015624153494287443	0.007956142396721435	0.008157478912451156

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 67274.1820 secs

