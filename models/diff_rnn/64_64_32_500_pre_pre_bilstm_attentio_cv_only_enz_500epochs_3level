/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_attentio_cv_only_enz_500epochs_3level
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3198396400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f31983962b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3198396790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f31983965b0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([ 56.,  56.,  56., ...,  50.,  46., 153.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.95      0.92       825
         1.0       0.67      0.43      0.52        14
         2.0       0.92      0.71      0.80        31
         3.0       0.00      0.00      0.00        11
         4.0       0.98      0.85      0.91        52
         5.0       0.78      0.80      0.79       176
         6.0       0.63      0.69      0.66       102
         7.0       0.61      0.54      0.57        97
         8.0       1.00      0.36      0.53        14
         9.0       0.76      0.49      0.59        70
        10.0       0.79      0.88      0.83       104
        11.0       0.86      0.33      0.48        18
        12.0       0.80      0.57      0.67        14
        13.0       0.87      0.79      0.83        43
        14.0       0.82      0.68      0.74        34
        15.0       0.96      0.83      0.89        64
        16.0       0.71      0.38      0.50        13
        17.0       0.83      0.53      0.65        19
        18.0       0.91      0.89      0.90        72
        19.0       0.75      0.60      0.67        30
        20.0       0.99      1.00      0.99        94
        21.0       0.87      0.89      0.88        46
        22.0       0.79      0.76      0.78        25
        23.0       0.96      0.96      0.96       345
        24.0       0.96      0.87      0.91        30
        25.0       0.50      0.25      0.33        20
        26.0       0.87      0.83      0.85       167
        27.0       0.91      0.81      0.85        36
        28.0       1.00      0.93      0.97        61
        29.0       0.98      0.87      0.92        63
        30.0       1.00      0.64      0.78        11
        31.0       0.20      0.09      0.13        11
        32.0       0.67      0.60      0.63        40
        33.0       0.86      0.84      0.85        73
        34.0       1.00      1.00      1.00        57
        35.0       1.00      0.87      0.93        15
        36.0       0.64      0.36      0.46        50
        37.0       0.90      0.95      0.92        19
        38.0       0.88      0.72      0.79        29
        39.0       0.94      0.97      0.96       101
        40.0       1.00      0.67      0.80        12
        41.0       0.93      1.00      0.97        14
        42.0       0.94      0.91      0.92        67
        43.0       0.99      0.88      0.93        76
        44.0       1.00      1.00      1.00        11
        45.0       1.00      0.86      0.93        37
        46.0       0.89      0.93      0.91      1613
        47.0       1.00      0.98      0.99       299
        48.0       1.00      0.98      0.99       244
        49.0       0.92      0.98      0.95       168
        50.0       0.86      0.88      0.87      1024
        51.0       0.80      0.80      0.80       353
        52.0       0.91      0.81      0.86        86
        53.0       0.81      0.84      0.82       607
        54.0       0.97      0.93      0.95       543
        55.0       0.95      0.94      0.94        78
        56.0       0.90      0.94      0.92       954
        57.0       0.91      0.92      0.92       247
        58.0       1.00      0.94      0.97        34
        59.0       0.86      0.89      0.88       877
        60.0       0.93      0.87      0.90        77
        61.0       0.85      0.91      0.88       566
        62.0       0.79      0.62      0.70        24
        63.0       0.89      0.76      0.82        55
        64.0       0.98      1.00      0.99       254
        65.0       0.69      0.64      0.67        14
        66.0       0.97      0.96      0.97       456
        67.0       0.93      0.68      0.79        38
        68.0       0.81      0.93      0.86      1189
        69.0       0.94      0.92      0.93       224
        70.0       0.89      0.84      0.86        19
        71.0       0.98      0.97      0.97       358
        72.0       0.86      0.59      0.70        32
        73.0       0.50      0.15      0.24        13
        74.0       0.98      1.00      0.99       127
        75.0       1.00      0.92      0.96        12
        76.0       0.84      0.86      0.85       460
        77.0       0.91      0.88      0.90       103
        78.0       0.60      0.46      0.52        52
        79.0       0.81      0.80      0.80        83
        80.0       0.61      0.55      0.58        80
        81.0       0.97      0.86      0.91        84
        82.0       0.90      0.93      0.92       335
        83.0       0.55      0.48      0.51        23
        84.0       0.84      0.84      0.84       518
        85.0       0.36      0.24      0.29        87
        86.0       0.71      0.38      0.50        13
        87.0       0.64      0.83      0.72       480
        88.0       0.88      0.73      0.80       126
        89.0       0.96      0.96      0.96        25
        90.0       0.88      0.81      0.85       152
        91.0       0.91      0.50      0.65        20
        92.0       0.77      0.61      0.68        28
        93.0       1.00      0.64      0.78        42
        94.0       0.78      0.62      0.69        34
        95.0       0.74      0.59      0.66        99
        96.0       0.88      0.87      0.87       415
        97.0       0.88      0.68      0.77       118
        98.0       0.95      0.77      0.85        99
        99.0       0.86      0.82      0.84       253
       100.0       0.98      0.98      0.98       116
       101.0       0.88      0.86      0.87       423
       102.0       0.94      0.86      0.90        99
       103.0       0.86      0.90      0.88        60
       104.0       0.82      0.90      0.86       266
       105.0       0.89      0.89      0.89        37
       106.0       0.88      0.89      0.89       494
       107.0       0.93      1.00      0.97        14
       108.0       0.90      0.88      0.89       610
       109.0       0.95      0.88      0.92       206
       110.0       0.77      0.45      0.57        22
       111.0       0.89      0.93      0.91       534
       112.0       0.76      0.73      0.75        98
       113.0       0.89      0.78      0.83        86
       114.0       0.99      0.92      0.95       109
       115.0       0.88      0.93      0.91       858
       116.0       0.70      0.62      0.66        61
       117.0       0.98      0.95      0.96       209
       118.0       0.50      0.08      0.13        13
       119.0       0.90      0.80      0.85        65
       120.0       0.96      0.95      0.95       156
       121.0       0.99      0.95      0.97        84
       122.0       0.81      0.62      0.70        55
       123.0       0.91      0.85      0.88       154
       124.0       0.98      0.92      0.95        52
       125.0       1.00      0.90      0.95       147
       126.0       0.77      0.71      0.74        77
       127.0       1.00      0.84      0.91        19
       128.0       0.96      0.89      0.92       198
       129.0       0.97      0.94      0.95       450
       130.0       0.85      1.00      0.92        11
       131.0       0.97      0.70      0.81        43
       132.0       1.00      0.81      0.90        16
       133.0       0.98      0.98      0.98       204
       134.0       1.00      0.96      0.98        76
       135.0       0.88      0.86      0.87       255
       136.0       0.83      0.50      0.62        20
       137.0       0.91      0.77      0.83        13
       138.0       0.85      0.69      0.76        67
       139.0       0.96      0.99      0.97      1464
       140.0       0.95      0.90      0.92       146
       141.0       0.94      0.97      0.96        99
       142.0       0.94      0.92      0.93       455
       143.0       0.99      0.93      0.96        82
       144.0       0.98      0.98      0.98       411
       145.0       0.97      0.97      0.97       406
       146.0       0.50      0.33      0.40        12
       147.0       0.96      0.91      0.93       149
       148.0       0.95      0.97      0.96       703
       149.0       0.99      0.96      0.98       195
       150.0       1.00      0.70      0.82        33
       151.0       0.98      0.81      0.89        68
       152.0       0.98      0.91      0.94        93
       153.0       0.86      0.97      0.91        33
       154.0       0.89      0.96      0.92        49
       155.0       0.94      0.95      0.94       154

    accuracy                           0.89     28656
   macro avg       0.87      0.78      0.82     28656
weighted avg       0.89      0.89      0.89     28656


===confusion_matrix===

[[781   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0  22 ...   0   0   0]
 ...
 [  0   0   0 ...  32   0   0]
 [  0   0   0 ...   0  47   1]
 [  0   0   0 ...   1   5 146]]

===multilabel confusion matrix===

[[[27734    97]
  [   44   781]]

 [[28639     3]
  [    8     6]]

 [[28623     2]
  [    9    22]]

 [[28644     1]
  [   11     0]]

 [[28603     1]
  [    8    44]]

 [[28440    40]
  [   35   141]]

 [[28513    41]
  [   32    70]]

 [[28526    33]
  [   45    52]]

 [[28642     0]
  [    9     5]]

 [[28575    11]
  [   36    34]]

 [[28528    24]
  [   13    91]]

 [[28637     1]
  [   12     6]]

 [[28640     2]
  [    6     8]]

 [[28608     5]
  [    9    34]]

 [[28617     5]
  [   11    23]]

 [[28590     2]
  [   11    53]]

 [[28641     2]
  [    8     5]]

 [[28635     2]
  [    9    10]]

 [[28578     6]
  [    8    64]]

 [[28620     6]
  [   12    18]]

 [[28561     1]
  [    0    94]]

 [[28604     6]
  [    5    41]]

 [[28626     5]
  [    6    19]]

 [[28298    13]
  [   15   330]]

 [[28625     1]
  [    4    26]]

 [[28631     5]
  [   15     5]]

 [[28468    21]
  [   28   139]]

 [[28617     3]
  [    7    29]]

 [[28595     0]
  [    4    57]]

 [[28592     1]
  [    8    55]]

 [[28645     0]
  [    4     7]]

 [[28641     4]
  [   10     1]]

 [[28604    12]
  [   16    24]]

 [[28573    10]
  [   12    61]]

 [[28599     0]
  [    0    57]]

 [[28641     0]
  [    2    13]]

 [[28596    10]
  [   32    18]]

 [[28635     2]
  [    1    18]]

 [[28624     3]
  [    8    21]]

 [[28549     6]
  [    3    98]]

 [[28644     0]
  [    4     8]]

 [[28641     1]
  [    0    14]]

 [[28585     4]
  [    6    61]]

 [[28579     1]
  [    9    67]]

 [[28645     0]
  [    0    11]]

 [[28619     0]
  [    5    32]]

 [[26863   180]
  [  105  1508]]

 [[28356     1]
  [    6   293]]

 [[28412     0]
  [    5   239]]

 [[28473    15]
  [    3   165]]

 [[27487   145]
  [  118   906]]

 [[28232    71]
  [   70   283]]

 [[28563     7]
  [   16    70]]

 [[27926   123]
  [   95   512]]

 [[28097    16]
  [   39   504]]

 [[28574     4]
  [    5    73]]

 [[27604    98]
  [   55   899]]

 [[28387    22]
  [   19   228]]

 [[28622     0]
  [    2    32]]

 [[27649   130]
  [   93   784]]

 [[28574     5]
  [   10    67]]

 [[28002    88]
  [   53   513]]

 [[28628     4]
  [    9    15]]

 [[28596     5]
  [   13    42]]

 [[28396     6]
  [    1   253]]

 [[28638     4]
  [    5     9]]

 [[28187    13]
  [   17   439]]

 [[28616     2]
  [   12    26]]

 [[27209   258]
  [   89  1100]]

 [[28419    13]
  [   19   205]]

 [[28635     2]
  [    3    16]]

 [[28290     8]
  [   10   348]]

 [[28621     3]
  [   13    19]]

 [[28641     2]
  [   11     2]]

 [[28526     3]
  [    0   127]]

 [[28644     0]
  [    1    11]]

 [[28120    76]
  [   64   396]]

 [[28544     9]
  [   12    91]]

 [[28588    16]
  [   28    24]]

 [[28558    15]
  [   17    66]]

 [[28548    28]
  [   36    44]]

 [[28570     2]
  [   12    72]]

 [[28288    33]
  [   23   312]]

 [[28624     9]
  [   12    11]]

 [[28054    84]
  [   84   434]]

 [[28532    37]
  [   66    21]]

 [[28641     2]
  [    8     5]]

 [[27953   223]
  [   82   398]]

 [[28518    12]
  [   34    92]]

 [[28630     1]
  [    1    24]]

 [[28488    16]
  [   29   123]]

 [[28635     1]
  [   10    10]]

 [[28623     5]
  [   11    17]]

 [[28614     0]
  [   15    27]]

 [[28616     6]
  [   13    21]]

 [[28537    20]
  [   41    58]]

 [[28190    51]
  [   55   360]]

 [[28527    11]
  [   38    80]]

 [[28553     4]
  [   23    76]]

 [[28370    33]
  [   46   207]]

 [[28538     2]
  [    2   114]]

 [[28182    51]
  [   59   364]]

 [[28552     5]
  [   14    85]]

 [[28587     9]
  [    6    54]]

 [[28339    51]
  [   26   240]]

 [[28615     4]
  [    4    33]]

 [[28104    58]
  [   55   439]]

 [[28641     1]
  [    0    14]]

 [[27986    60]
  [   71   539]]

 [[28441     9]
  [   24   182]]

 [[28631     3]
  [   12    10]]

 [[28059    63]
  [   38   496]]

 [[28535    23]
  [   26    72]]

 [[28562     8]
  [   19    67]]

 [[28546     1]
  [    9   100]]

 [[27693   105]
  [   58   800]]

 [[28579    16]
  [   23    38]]

 [[28442     5]
  [   11   198]]

 [[28642     1]
  [   12     1]]

 [[28585     6]
  [   13    52]]

 [[28494     6]
  [    8   148]]

 [[28571     1]
  [    4    80]]

 [[28593     8]
  [   21    34]]

 [[28489    13]
  [   23   131]]

 [[28603     1]
  [    4    48]]

 [[28509     0]
  [   14   133]]

 [[28563    16]
  [   22    55]]

 [[28637     0]
  [    3    16]]

 [[28450     8]
  [   21   177]]

 [[28191    15]
  [   27   423]]

 [[28643     2]
  [    0    11]]

 [[28612     1]
  [   13    30]]

 [[28640     0]
  [    3    13]]

 [[28448     4]
  [    4   200]]

 [[28580     0]
  [    3    73]]

 [[28371    30]
  [   35   220]]

 [[28634     2]
  [   10    10]]

 [[28642     1]
  [    3    10]]

 [[28581     8]
  [   21    46]]

 [[27129    63]
  [   20  1444]]

 [[28503     7]
  [   15   131]]

 [[28551     6]
  [    3    96]]

 [[28172    29]
  [   36   419]]

 [[28573     1]
  [    6    76]]

 [[28235    10]
  [   10   401]]

 [[28236    14]
  [   12   394]]

 [[28640     4]
  [    8     4]]

 [[28502     5]
  [   14   135]]

 [[27916    37]
  [   22   681]]

 [[28460     1]
  [    7   188]]

 [[28623     0]
  [   10    23]]

 [[28587     1]
  [   13    55]]

 [[28561     2]
  [    8    85]]

 [[28618     5]
  [    1    32]]

 [[28601     6]
  [    2    47]]

 [[28492    10]
  [    8   146]]]

===scores report===
metrics	scores
Accuracy	0.8914
MCC	0.8891
log_loss	0.5421
f1 score weighted	0.8895
f1 score macro	0.8151
f1 score micro	0.8914
roc_auc ovr	0.9965
roc_auc ovo	0.9947
precision	0.8915
recall	0.8914

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f3198396400>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f31983962b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f3198396790>]