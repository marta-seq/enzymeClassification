/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_middle_lstm_attent_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa11021c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa11021c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa11021c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa11021c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.83      0.85      3813
         1.0       0.87      0.91      0.89     10869
         2.0       0.84      0.84      0.84      6897
         3.0       0.96      0.78      0.86      2585
         4.0       0.94      0.85      0.89      1616
         5.0       0.91      0.96      0.93      3258
         6.0       0.97      0.96      0.96      1372

    accuracy                           0.88     30410
   macro avg       0.91      0.88      0.89     30410
weighted avg       0.88      0.88      0.88     30410


===confusion_matrix===

[[3156  294  248   34   12   58   11]
 [ 186 9926  575   25   35  110   12]
 [ 171  758 5821   25   18   84   20]
 [  71  273  180 2011   16   34    0]
 [  32   98   83    8 1374   21    0]
 [  13   83   42    2    4 3113    1]
 [  14   12   21    0    2    4 1319]]

===multilabel confusion matrix===

[[[26110   487]
  [  657  3156]]

 [[18023  1518]
  [  943  9926]]

 [[22364  1149]
  [ 1076  5821]]

 [[27731    94]
  [  574  2011]]

 [[28707    87]
  [  242  1374]]

 [[26841   311]
  [  145  3113]]

 [[28994    44]
  [   53  1319]]]

===scores report===
metrics	scores
Accuracy	0.8787
MCC	0.8440
log_loss	0.3645
f1 score weighted	0.8782
f1 score macro	0.8890
f1 score micro	0.8787
roc_auc ovr	0.9818
roc_auc ovo	0.9853
precision	0.8803
recall	0.8787

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa11021c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa11021c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa11021c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa11021c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.95      0.76      0.85      3813
         1.0       0.93      0.84      0.89     10869
         2.0       0.75      0.92      0.83      6897
         3.0       0.87      0.85      0.86      2585
         4.0       0.93      0.81      0.87      1616
         5.0       0.84      0.97      0.90      3258
         6.0       0.97      0.94      0.96      1372

    accuracy                           0.87     30410
   macro avg       0.89      0.87      0.88     30410
weighted avg       0.88      0.87      0.87     30410


===confusion_matrix===

[[2914  195  453   83   28  124   16]
 [  62 9173 1161  149   47  267   10]
 [  37  290 6360   62   19  119   10]
 [  20   97  225 2197    8   37    1]
 [  24   51  168   25 1317   31    0]
 [   9   26   55    8    2 3157    1]
 [   4   23   40    9    0    5 1291]]

===multilabel confusion matrix===

[[[26441   156]
  [  899  2914]]

 [[18859   682]
  [ 1696  9173]]

 [[21411  2102]
  [  537  6360]]

 [[27489   336]
  [  388  2197]]

 [[28690   104]
  [  299  1317]]

 [[26569   583]
  [  101  3157]]

 [[29000    38]
  [   81  1291]]]

===scores report===
metrics	scores
Accuracy	0.8684
MCC	0.8346
log_loss	0.3935
f1 score weighted	0.8693
f1 score macro	0.8777
f1 score micro	0.8684
roc_auc ovr	0.9821
roc_auc ovo	0.9853
precision	0.8794
recall	0.8684

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa11021c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa11021c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa11021c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa11021c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.88      0.84      3814
         1.0       0.92      0.87      0.89     10869
         2.0       0.83      0.86      0.85      6896
         3.0       0.87      0.85      0.86      2584
         4.0       0.89      0.84      0.86      1617
         5.0       0.92      0.95      0.94      3258
         6.0       0.89      0.98      0.93      1372

    accuracy                           0.88     30410
   macro avg       0.88      0.89      0.88     30410
weighted avg       0.88      0.88      0.88     30410


===confusion_matrix===

[[3347  134  193   45   19   50   26]
 [ 341 9404  704  141   77  122   80]
 [ 319  413 5922   91   40   69   42]
 [  86  122  138 2184   29   22    3]
 [  62   66   91   29 1351   13    5]
 [  25   58   54    7    6 3106    2]
 [   9    6   13    3    0    2 1339]]

===multilabel confusion matrix===

[[[25754   842]
  [  467  3347]]

 [[18742   799]
  [ 1465  9404]]

 [[22321  1193]
  [  974  5922]]

 [[27510   316]
  [  400  2184]]

 [[28622   171]
  [  266  1351]]

 [[26874   278]
  [  152  3106]]

 [[28880   158]
  [   33  1339]]]

===scores report===
metrics	scores
Accuracy	0.8765
MCC	0.8432
log_loss	0.3660
f1 score weighted	0.8767
f1 score macro	0.8804
f1 score micro	0.8765
roc_auc ovr	0.9823
roc_auc ovo	0.9857
precision	0.8785
recall	0.8765

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa11021c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa11021c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa11021c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa11021c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.83      0.86      3813
         1.0       0.85      0.94      0.89     10868
         2.0       0.92      0.77      0.84      6897
         3.0       0.92      0.82      0.87      2585
         4.0       0.79      0.87      0.83      1616
         5.0       0.88      0.96      0.92      3258
         6.0       0.95      0.96      0.96      1372

    accuracy                           0.88     30409
   macro avg       0.88      0.88      0.88     30409
weighted avg       0.88      0.88      0.87     30409


===confusion_matrix===

[[ 3151   333   133    37    78    59    22]
 [  124 10228   180    56   103   165    12]
 [  169  1073  5283    81   137   131    23]
 [   57   240    96  2122    37    27     6]
 [   24   105    37    11  1406    28     5]
 [   14    93    14     5    14  3118     0]
 [   10    26     7     1     4     4  1320]]

===multilabel confusion matrix===

[[[26198   398]
  [  662  3151]]

 [[17671  1870]
  [  640 10228]]

 [[23045   467]
  [ 1614  5283]]

 [[27633   191]
  [  463  2122]]

 [[28420   373]
  [  210  1406]]

 [[26737   414]
  [  140  3118]]

 [[28969    68]
  [   52  1320]]]

===scores report===
metrics	scores
Accuracy	0.8757
MCC	0.8417
log_loss	0.3707
f1 score weighted	0.8744
f1 score macro	0.8788
f1 score micro	0.8757
roc_auc ovr	0.9833
roc_auc ovo	0.9864
precision	0.8793
recall	0.8757

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa11021c250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa11021c850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa11021c8b0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fa11021c670>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.87      0.85      3813
         1.0       0.90      0.89      0.89     10868
         2.0       0.80      0.88      0.84      6897
         3.0       0.95      0.80      0.87      2585
         4.0       0.94      0.81      0.87      1616
         5.0       0.96      0.94      0.95      3258
         6.0       0.97      0.95      0.96      1372

    accuracy                           0.88     30409
   macro avg       0.91      0.88      0.89     30409
weighted avg       0.88      0.88      0.88     30409


===confusion_matrix===

[[3311  171  276   20   10   11   14]
 [ 258 9651  819   53   26   47   14]
 [ 171  546 6084   19   28   38   11]
 [  92  178  235 2062   13    3    2]
 [  39  124  107   14 1317   14    1]
 [  40   78   83    4    4 3048    1]
 [  22   20   23    1    1    1 1304]]

===multilabel confusion matrix===

[[[25974   622]
  [  502  3311]]

 [[18424  1117]
  [ 1217  9651]]

 [[21969  1543]
  [  813  6084]]

 [[27713   111]
  [  523  2062]]

 [[28711    82]
  [  299  1317]]

 [[27037   114]
  [  210  3048]]

 [[28994    43]
  [   68  1304]]]

===scores report===
metrics	scores
Accuracy	0.8806
MCC	0.8471
log_loss	0.3543
f1 score weighted	0.8812
f1 score macro	0.8906
f1 score micro	0.8806
roc_auc ovr	0.9828
roc_auc ovo	0.9858
precision	0.8845
recall	0.8806

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.87865833607366	0.8440308368530932	0.3644697272115969	0.8782492293111496	0.8889652788516572	0.87865833607366	0.9817515479946193	0.9853479747989059	0.8802927368806189	0.87865833607366
1	0.8684314370272936	0.8345954484988501	0.39348523655559675	0.8692641984759429	0.8777426178774109	0.8684314370272936	0.982107151261772	0.9853453228528894	0.8794002733146632	0.8684314370272936
2	0.8764551134495232	0.8432154977945169	0.3660001730192299	0.8767029811770148	0.8804239192218856	0.8764551134495232	0.9823315394914957	0.9857288687340228	0.8785003280254222	0.8764551134495232
3	0.8756618106481634	0.841651020217105	0.3707444841667936	0.87438601282694	0.8788377990799666	0.8756618106481635	0.9832702727170856	0.9864011591037031	0.879344124367824	0.8756618106481634
4	0.8805616758196586	0.8470834141334161	0.3543186271310712	0.8811676749169566	0.8905563248070772	0.8805616758196586	0.9827918757949999	0.9857928014184276	0.884450829633033	0.8805616758196586
mean	0.8759536746036598	0.8421152434993964	0.36980364961685763	0.8759540193416008	0.8833051879675995	0.8759536746036598	0.9824504774519944	0.9857232253815897	0.8803976584443122	0.8759536746036598
std	0.004134478262463203	0.004155131693832494	0.01299542853026993	0.004005583221910921	0.005363153425872858	0.004134478262463201	0.0005308744866726513	0.00038680489265515317	0.00210446093264837	0.004134478262463203

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 34359.3792 secs

