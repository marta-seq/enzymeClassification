/home/amsequeira/enzymeClassification/models/diff_rnn/64_64_32_500_pre_pre_bilstm_cv_only_enz
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f16d829c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f16d829c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f16d829c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f16d829c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.89      0.87      0.88      3813
         1.0       0.88      0.94      0.91     10869
         2.0       0.88      0.85      0.86      6897
         3.0       0.90      0.87      0.88      2585
         4.0       0.95      0.83      0.88      1616
         5.0       0.95      0.95      0.95      3258
         6.0       0.97      0.96      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.92      0.89      0.90     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[ 3313   245   155    54    13    23    10]
 [  152 10176   379    78    15    55    14]
 [  132   721  5833   100    41    55    15]
 [   57   169   102  2248     3     6     0]
 [   46   103    84    22  1343    17     1]
 [   25    81    33     5     6  3108     0]
 [   16    17    21     3     0     0  1315]]

===multilabel confusion matrix===

[[[26169   428]
  [  500  3313]]

 [[18205  1336]
  [  693 10176]]

 [[22739   774]
  [ 1064  5833]]

 [[27563   262]
  [  337  2248]]

 [[28716    78]
  [  273  1343]]

 [[26996   156]
  [  150  3108]]

 [[28998    40]
  [   57  1315]]]

===scores report===
metrics	scores
Accuracy	0.8989
MCC	0.8702
log_loss	0.3185
f1 score weighted	0.8986
f1 score macro	0.9050
f1 score micro	0.8989
roc_auc ovr	0.9871
roc_auc ovo	0.9891
precision	0.8994
recall	0.8989

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f16d829c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f16d829c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f16d829c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f16d829c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.85      0.90      0.87      3813
         1.0       0.92      0.91      0.92     10869
         2.0       0.87      0.87      0.87      6897
         3.0       0.93      0.86      0.89      2585
         4.0       0.96      0.82      0.89      1616
         5.0       0.90      0.97      0.93      3258
         6.0       0.97      0.96      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.91      0.90      0.91     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[3440  141  139   21    9   51   12]
 [ 210 9917  516   61   21  128   16]
 [ 239  440 6025   64   12  101   16]
 [  83  123  121 2218   11   28    1]
 [  52   79   99   22 1328   34    2]
 [  14   45   43    2    0 3154    0]
 [  18   14   15    0    0    4 1321]]

===multilabel confusion matrix===

[[[25981   616]
  [  373  3440]]

 [[18699   842]
  [  952  9917]]

 [[22580   933]
  [  872  6025]]

 [[27655   170]
  [  367  2218]]

 [[28741    53]
  [  288  1328]]

 [[26806   346]
  [  104  3154]]

 [[28991    47]
  [   51  1321]]]

===scores report===
metrics	scores
Accuracy	0.9011
MCC	0.8736
log_loss	0.3165
f1 score weighted	0.9011
f1 score macro	0.9053
f1 score micro	0.9011
roc_auc ovr	0.9872
roc_auc ovo	0.9894
precision	0.9023
recall	0.9011

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f16d829c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f16d829c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f16d829c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f16d829c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.87      0.83      3814
         1.0       0.96      0.80      0.88     10869
         2.0       0.84      0.85      0.84      6896
         3.0       0.71      0.90      0.79      2584
         4.0       0.68      0.89      0.77      1617
         5.0       0.90      0.95      0.93      3258
         6.0       0.97      0.95      0.96      1372

    accuracy                           0.86     30410
   macro avg       0.84      0.89      0.86     30410
weighted avg       0.87      0.86      0.86     30410


===confusion_matrix===

[[3334   62  160  136   63   40   19]
 [ 452 8734  773  392  318  190   10]
 [ 260  188 5857  326  184   70   11]
 [  60   41   94 2313   63   13    0]
 [  40   18   52   49 1445   10    3]
 [  36   24   35   25   28 3109    1]
 [  12   11   24    3   13    9 1300]]

===multilabel confusion matrix===

[[[25736   860]
  [  480  3334]]

 [[19197   344]
  [ 2135  8734]]

 [[22376  1138]
  [ 1039  5857]]

 [[26895   931]
  [  271  2313]]

 [[28124   669]
  [  172  1445]]

 [[26820   332]
  [  149  3109]]

 [[28994    44]
  [   72  1300]]]

===scores report===
metrics	scores
Accuracy	0.8580
MCC	0.8242
log_loss	0.4408
f1 score weighted	0.8599
f1 score macro	0.8579
f1 score micro	0.8580
roc_auc ovr	0.9827
roc_auc ovo	0.9863
precision	0.8708
recall	0.8580

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f16d829c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f16d829c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f16d829c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f16d829c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.77      0.85      3813
         1.0       0.86      0.93      0.90     10868
         2.0       0.93      0.75      0.83      6897
         3.0       0.81      0.88      0.84      2585
         4.0       0.64      0.91      0.75      1616
         5.0       0.91      0.96      0.93      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.87     30409
   macro avg       0.86      0.88      0.87     30409
weighted avg       0.88      0.87      0.87     30409


===confusion_matrix===

[[ 2953   362    98   120   189    70    21]
 [   61 10138   189   150   212   103    15]
 [   93   937  5193   224   331   104    15]
 [   28   150    56  2278    58    15     0]
 [   13    74    26    27  1465    11     0]
 [    4    73    14    15    35  3117     0]
 [    8    23     8    11     2     3  1317]]

===multilabel confusion matrix===

[[[26389   207]
  [  860  2953]]

 [[17922  1619]
  [  730 10138]]

 [[23121   391]
  [ 1704  5193]]

 [[27277   547]
  [  307  2278]]

 [[27966   827]
  [  151  1465]]

 [[26845   306]
  [  141  3117]]

 [[28986    51]
  [   55  1317]]]

===scores report===
metrics	scores
Accuracy	0.8702
MCC	0.8358
log_loss	0.4043
f1 score weighted	0.8700
f1 score macro	0.8659
f1 score micro	0.8702
roc_auc ovr	0.9838
roc_auc ovo	0.9870
precision	0.8798
recall	0.8702

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f16d829c580>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f16d829c730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f16d829c790>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f16d829c550>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.90      0.87      3813
         1.0       0.85      0.96      0.90     10868
         2.0       0.93      0.79      0.85      6897
         3.0       0.92      0.85      0.88      2585
         4.0       0.93      0.84      0.88      1616
         5.0       0.99      0.93      0.96      3258
         6.0       0.96      0.96      0.96      1372

    accuracy                           0.89     30409
   macro avg       0.92      0.89      0.90     30409
weighted avg       0.90      0.89      0.89     30409


===confusion_matrix===

[[ 3441   238    79    23    13     7    12]
 [  183 10407   163    58    27    15    15]
 [  254  1043  5426    86    49    17    22]
 [   98   197    80  2195     9     5     1]
 [   49   133    50    19  1365     0     0]
 [   49   143    29     6     6  3023     2]
 [   20    25     8     0     0     0  1319]]

===multilabel confusion matrix===

[[[25943   653]
  [  372  3441]]

 [[17762  1779]
  [  461 10407]]

 [[23103   409]
  [ 1471  5426]]

 [[27632   192]
  [  390  2195]]

 [[28689   104]
  [  251  1365]]

 [[27107    44]
  [  235  3023]]

 [[28985    52]
  [   53  1319]]]

===scores report===
metrics	scores
Accuracy	0.8937
MCC	0.8646
log_loss	0.3414
f1 score weighted	0.8930
f1 score macro	0.9016
f1 score micro	0.8937
roc_auc ovr	0.9874
roc_auc ovo	0.9897
precision	0.8981
recall	0.8937

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8989148306478132	0.8702491440836949	0.3184568425494728	0.8985580160313058	0.9049652765432475	0.8989148306478132	0.9871482370017517	0.9891474719835546	0.8993641577043975	0.8989148306478132
1	0.90111805327195	0.873606107299838	0.3164574709486125	0.9010740503553761	0.9052819006319989	0.90111805327195	0.9871768968797825	0.9894252800089602	0.9023419635293538	0.90111805327195
2	0.858007234462348	0.8242282161550266	0.4408362026126837	0.8599245572238999	0.8579288195723018	0.858007234462348	0.9827102395219698	0.9862570375929557	0.8708186350407846	0.858007234462348
3	0.8701700154559505	0.8358146271444243	0.40429373188457984	0.8700043886488106	0.8659426968491386	0.8701700154559505	0.9838450803011651	0.9869692757475393	0.8797952069692808	0.8701700154559505
4	0.8936827912788977	0.8645851594688545	0.3414147052347225	0.8930105758484949	0.9015752904028899	0.8936827912788977	0.9874134237287482	0.9897190337084059	0.8980788448408938	0.8936827912788977
mean	0.884378585023392	0.8536966508303678	0.36429179064601425	0.8845143176215775	0.8871387967999154	0.884378585023392	0.9856587754866835	0.9883036198082831	0.8900797616169422	0.884378585023392
std	0.017177963020738412	0.019885102582089243	0.04974239228468668	0.01648533270702561	0.020774336894403823	0.017177963020738412	0.001979158062592147	0.0014101473288058092	0.012468440160314426	0.017177963020738412

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 63603.9270 secs

