/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_500_pre_pre_lstm_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f601465a1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f601465a370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f601465a3d0>]/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_500_pre_pre_lstm_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f078859b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f078859b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f078859b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f078859b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.77      0.74      4541
         1.0       0.80      0.81      0.81      3813
         2.0       0.83      0.89      0.86     10869
         3.0       0.84      0.73      0.78      6897
         4.0       0.95      0.74      0.83      2585
         5.0       0.74      0.79      0.76      1617
         6.0       0.85      0.96      0.90      3258
         7.0       0.97      0.90      0.93      1372

    accuracy                           0.82     34952
   macro avg       0.84      0.82      0.83     34952
weighted avg       0.83      0.82      0.82     34952


===confusion_matrix===

[[3482  131  429  394   17   32   35   21]
 [ 110 3105  343  119   16   15  100    5]
 [ 543  175 9646  227   28   95  154    1]
 [ 540  243  736 5021   25  163  158   11]
 [  58  126  231  112 1903  135   19    1]
 [  55   39  120   52   12 1281   56    2]
 [  25   28   68   10    1   12 3114    0]
 [  47   20   35   17    0    4    9 1240]]

===multilabel confusion matrix===

[[[29033  1378]
  [ 1059  3482]]

 [[30377   762]
  [  708  3105]]

 [[22121  1962]
  [ 1223  9646]]

 [[27124   931]
  [ 1876  5021]]

 [[32268    99]
  [  682  1903]]

 [[32879   456]
  [  336  1281]]

 [[31163   531]
  [  144  3114]]

 [[33539    41]
  [  132  1240]]]

===scores report===
metrics	scores
Accuracy	0.8238
MCC	0.7846
log_loss	0.5244
f1 score weighted	0.8231
f1 score macro	0.8275
f1 score micro	0.8238
roc_auc ovr	0.9722
roc_auc ovo	0.9760
precision	0.8276
recall	0.8238

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f078859b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f078859b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f078859b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f078859b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.71      0.83      0.76      4541
         1.0       0.80      0.85      0.82      3813
         2.0       0.84      0.90      0.87     10869
         3.0       0.88      0.74      0.80      6897
         4.0       0.85      0.83      0.84      2585
         5.0       0.93      0.75      0.83      1616
         6.0       0.97      0.91      0.94      3258
         7.0       0.98      0.91      0.95      1372

    accuracy                           0.84     34951
   macro avg       0.87      0.84      0.85     34951
weighted avg       0.85      0.84      0.84     34951


===confusion_matrix===

[[3747   96  409  225   30   13   11   10]
 [ 154 3242  244   88   62   11    7    5]
 [ 529  242 9770  204   86   22   15    1]
 [ 627  268  725 5071  147   25   28    6]
 [  75   87  200   69 2135   15    4    0]
 [  70   48  142   68   55 1217   16    0]
 [  36   69  148   42    9    2 2951    1]
 [  65   18   14   23    0    0    1 1251]]

===multilabel confusion matrix===

[[[28854  1556]
  [  794  3747]]

 [[30310   828]
  [  571  3242]]

 [[22200  1882]
  [ 1099  9770]]

 [[27335   719]
  [ 1826  5071]]

 [[31977   389]
  [  450  2135]]

 [[33247    88]
  [  399  1217]]

 [[31611    82]
  [  307  2951]]

 [[33556    23]
  [  121  1251]]]

===scores report===
metrics	scores
Accuracy	0.8407
MCC	0.8056
log_loss	0.4854
f1 score weighted	0.8411
f1 score macro	0.8505
f1 score micro	0.8407
roc_auc ovr	0.9754
roc_auc ovo	0.9788
precision	0.8472
recall	0.8407

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f078859b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f078859b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f078859b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f078859b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.46      0.58      4542
         1.0       0.44      0.18      0.26      3814
         2.0       0.49      0.88      0.63     10869
         3.0       0.51      0.38      0.43      6896
         4.0       0.53      0.19      0.28      2584
         5.0       0.75      0.03      0.06      1616
         6.0       0.71      0.79      0.75      3258
         7.0       0.83      0.87      0.85      1372

    accuracy                           0.55     34951
   macro avg       0.63      0.47      0.48     34951
weighted avg       0.58      0.55      0.51     34951


===confusion_matrix===

[[2086   22 1291  967    3    1   46  126]
 [  20  686 2261  438  141    3  244   21]
 [ 237  177 9546  456   74    1  319   59]
 [ 245  219 3619 2593   76    1  118   25]
 [   7  248 1356  357  483    9  123    1]
 [  38  171  878  180  126   47  169    7]
 [   9   37  593   19    7    1 2584    8]
 [   8    2  117   34    0    0   24 1187]]

===multilabel confusion matrix===

[[[29845   564]
  [ 2456  2086]]

 [[30261   876]
  [ 3128   686]]

 [[13967 10115]
  [ 1323  9546]]

 [[25604  2451]
  [ 4303  2593]]

 [[31940   427]
  [ 2101   483]]

 [[33319    16]
  [ 1569    47]]

 [[30650  1043]
  [  674  2584]]

 [[33332   247]
  [  185  1187]]]

===scores report===
metrics	scores
Accuracy	0.5497
MCC	0.4393
log_loss	1.2267
f1 score weighted	0.5096
f1 score macro	0.4780
f1 score micro	0.5497
roc_auc ovr	0.8510
roc_auc ovo	0.8622
precision	0.5753
recall	0.5497

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f078859b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f078859b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f078859b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f078859b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.78      0.73      4542
         1.0       0.96      0.68      0.79      3813
         2.0       0.80      0.91      0.85     10868
         3.0       0.84      0.76      0.79      6897
         4.0       0.80      0.81      0.81      2585
         5.0       0.89      0.78      0.83      1616
         6.0       0.96      0.90      0.93      3258
         7.0       0.91      0.95      0.93      1372

    accuracy                           0.82     34951
   macro avg       0.85      0.82      0.83     34951
weighted avg       0.83      0.82      0.82     34951


===confusion_matrix===

[[3532   25  572  306   30   12   12   53]
 [ 185 2587  528  249  182   30   28   24]
 [ 514   28 9873  249  119   30   38   17]
 [ 626   35  794 5225  109   57   30   21]
 [  63   11  236  128 2104   27   10    6]
 [ 101    7  129   58   57 1255    6    3]
 [  30    7  224   35   27    5 2923    7]
 [  36    1   19    3    0    2    1 1310]]

===multilabel confusion matrix===

[[[28854  1555]
  [ 1010  3532]]

 [[31024   114]
  [ 1226  2587]]

 [[21581  2502]
  [  995  9873]]

 [[27026  1028]
  [ 1672  5225]]

 [[31842   524]
  [  481  2104]]

 [[33172   163]
  [  361  1255]]

 [[31568   125]
  [  335  2923]]

 [[33448   131]
  [   62  1310]]]

===scores report===
metrics	scores
Accuracy	0.8243
MCC	0.7848
log_loss	0.5323
f1 score weighted	0.8239
f1 score macro	0.8331
f1 score micro	0.8243
roc_auc ovr	0.9730
roc_auc ovo	0.9768
precision	0.8329
recall	0.8243

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f078859b1c0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f078859b370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f078859b3d0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f078859b190>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.76      0.73      0.75      4542
         1.0       0.65      0.92      0.76      3813
         2.0       0.92      0.83      0.87     10868
         3.0       0.82      0.80      0.81      6897
         4.0       0.93      0.81      0.87      2585
         5.0       0.77      0.85      0.81      1616
         6.0       0.94      0.94      0.94      3258
         7.0       0.95      0.95      0.95      1372

    accuracy                           0.83     34951
   macro avg       0.84      0.85      0.84     34951
weighted avg       0.85      0.83      0.84     34951


===confusion_matrix===

[[3312  372  208  500   26   72   22   30]
 [  60 3506   79   94   10   41   12   11]
 [ 493  704 8978  437   59  106   81   10]
 [ 356  467  299 5546   37  121   62    9]
 [  29  203   94  120 2090   38   11    0]
 [  36   83   48   45   15 1377    9    3]
 [  20   75   40   31    5   17 3069    1]
 [  24   19    5   14    0    6    3 1301]]

===multilabel confusion matrix===

[[[29391  1018]
  [ 1230  3312]]

 [[29215  1923]
  [  307  3506]]

 [[23310   773]
  [ 1890  8978]]

 [[26813  1241]
  [ 1351  5546]]

 [[32214   152]
  [  495  2090]]

 [[32934   401]
  [  239  1377]]

 [[31493   200]
  [  189  3069]]

 [[33515    64]
  [   71  1301]]]

===scores report===
metrics	scores
Accuracy	0.8349
MCC	0.8013
log_loss	0.5129
f1 score weighted	0.8371
f1 score macro	0.8444
f1 score micro	0.8349
roc_auc ovr	0.9755
roc_auc ovo	0.9800
precision	0.8471
recall	0.8349

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8237582970931563	0.7846458154073803	0.5244156656887035	0.823075670477907	0.8274765634114989	0.8237582970931563	0.9721909447630187	0.9759820343800744	0.8276012724907466	0.8237582970931563
1	0.8407198649537925	0.8055572407839854	0.485375737221086	0.8411201689310713	0.8504551434673673	0.8407198649537925	0.9753673784351768	0.9787941903277873	0.8472045175629395	0.8407198649537925
2	0.5496838430946182	0.43928696595297373	1.226696453117702	0.5096118434586279	0.4780136160414595	0.5496838430946182	0.8509959678063964	0.8621596798089717	0.5752778846329469	0.5496838430946182
3	0.8242682612800778	0.7848278764232834	0.5323457472042799	0.8239026478992821	0.83313454310405	0.8242682612800778	0.9729768873169661	0.9767909481941691	0.8329075080645116	0.8242682612800778
4	0.834854510600555	0.8013414058017336	0.5128661794348275	0.8370860805312687	0.8444036694278464	0.834854510600555	0.9754701411085307	0.9799628087016146	0.8470866126172267	0.834854510600555
mean	0.77465695540444	0.7231318608738713	0.6563399565333198	0.7669592822596314	0.7666967070904444	0.77465695540444	0.9494002638860177	0.9547379322825232	0.7860155590736743	0.77465695540444
std	0.11267047382380276	0.14217521969796934	0.28562163946660224	0.12886962801389357	0.144568289542478	0.11267047382380276	0.049219116876624	0.0463106427450233	0.10565259683620902	0.11267047382380276

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 36087.1333 secs

