/home/amsequeira/enzymeClassification/models/300_300_lstm
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9f2af5aa90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9f2af5a730>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9f2af5a7f0>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.5500189578533172)
('Validation Accuracy mean: ', 0.4189299500361085)
('Training Loss mean: ', 1.2875476837158204)
('Validation Loss mean: ', 4.243550472259521)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500, 20)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 600)          770400    
_________________________________________________________________
bidirectional_1 (Bidirection (None, 600)               2162400   
_________________________________________________________________
dense (Dense)                (None, 300)               180300    
_________________________________________________________________
batch_normalization (BatchNo (None, 300)               1200      
_________________________________________________________________
dropout (Dropout)            (None, 300)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 2408      
=================================================================
Total params: 3,116,708
Trainable params: 3,116,108
Non-trainable params: 600
_________________________________________________________________Finished run_model in 24485.3739 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f9f2af5a610>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.78      0.52      0.62      4542
           1       0.37      0.87      0.52      3813
           2       0.77      0.77      0.77     10869
           3       0.71      0.56      0.63      6897
           4       0.85      0.59      0.70      2585
           5       0.81      0.47      0.59      1616
           6       0.95      0.81      0.87      3258
           7       0.94      0.91      0.92      1372

    accuracy                           0.69     34952
   macro avg       0.77      0.69      0.70     34952
weighted avg       0.75      0.69      0.70     34952


===confusion_matrix===

[[2341  767  655  683   24    9   20   43]
 [  32 3311  285  132   29    5    9   10]
 [ 328 1672 8336  368   59   34   59   13]
 [ 241 1755  876 3852   78   48   32   15]
 [  11  613  236  153 1537   25    9    1]
 [  18  389  207  173   59  753   16    1]
 [   7  320  209   15    8   55 2644    0]
 [  16   56   31   19    4    0    2 1244]]

===multilabel confusion matrix===

[[[29757   653]
  [ 2201  2341]]

 [[25567  5572]
  [  502  3311]]

 [[21584  2499]
  [ 2533  8336]]

 [[26512  1543]
  [ 3045  3852]]

 [[32106   261]
  [ 1048  1537]]

 [[33160   176]
  [  863   753]]

 [[31547   147]
  [  614  2644]]

 [[33497    83]
  [  128  1244]]]

===scores report===
metrics	scores
Accuracy	0.6872
MCC	0.6286
log_loss	0.8791
f1 score weighted	0.6971
f1 score macro	0.7034
f1 score micro	0.6872
roc_auc ovr	0.9363
roc_auc ovo	0.9441
precision	0.7482
recall	0.6872
