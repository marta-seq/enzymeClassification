/home/amsequeira/enzymeClassification/models/256_256_128_lstm
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f2e6ee9aa30>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f2e6ee9a6d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f2e6ee9a790>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.3110030674934387)
('Validation Accuracy mean: ', 0.30587334647774694)
('Training Loss mean: ', 1.8843227660655975)
('Validation Loss mean: ', 1.8920017623901366)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500, 20)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 512)          567296    
_________________________________________________________________
bidirectional_1 (Bidirection (None, 500, 512)          1574912   
_________________________________________________________________
bidirectional_2 (Bidirection (None, 256)               656384    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
batch_normalization (BatchNo (None, 128)               512       
_________________________________________________________________
dropout (Dropout)            (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dropout_1 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
batch_normalization_2 (Batch (None, 32)                128       
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 264       
=================================================================
Total params: 2,842,984
Trainable params: 2,842,536
Non-trainable params: 448
_________________________________________________________________Finished run_model in 28724.5429 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f2e6ee9a5b0>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.00      0.00      0.00      4542
           1       0.00      0.00      0.00      3813
           2       0.31      1.00      0.47     10869
           3       0.00      0.00      0.00      6897
           4       0.00      0.00      0.00      2585
           5       0.00      0.00      0.00      1616
           6       0.00      0.00      0.00      3258
           7       0.00      0.00      0.00      1372

    accuracy                           0.31     34952
   macro avg       0.04      0.12      0.06     34952
weighted avg       0.10      0.31      0.15     34952


===confusion_matrix===

[[    0     0  4542     0     0     0     0     0]
 [    0     0  3813     0     0     0     0     0]
 [    0     0 10869     0     0     0     0     0]
 [    0     0  6897     0     0     0     0     0]
 [    0     0  2585     0     0     0     0     0]
 [    0     0  1616     0     0     0     0     0]
 [    0     0  3258     0     0     0     0     0]
 [    0     0  1372     0     0     0     0     0]]

===multilabel confusion matrix===

[[[30410     0]
  [ 4542     0]]

 [[31139     0]
  [ 3813     0]]

 [[    0 24083]
  [    0 10869]]

 [[28055     0]
  [ 6897     0]]

 [[32367     0]
  [ 2585     0]]

 [[33336     0]
  [ 1616     0]]

 [[31694     0]
  [ 3258     0]]

 [[33580     0]
  [ 1372     0]]]

===scores report===
metrics	scores
Accuracy	0.3110
MCC	0.0000
log_loss	1.8734
f1 score weighted	0.1475
f1 score macro	0.0593
f1 score micro	0.3110
roc_auc ovr	0.4998
roc_auc ovo	0.4999
precision	0.0967
recall	0.3110
