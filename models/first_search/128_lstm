/home/amsequeira/enzymeClassification/models/128_lstm
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4b591daaf0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4b591daa90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4b591dab50>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.46607973098754885)
('Validation Accuracy mean: ', 0.35062705762684343)
('Training Loss mean: ', 1.4578968751430512)
('Validation Loss mean: ', 4.820001536607743)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500, 20)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 256)               152576    
_________________________________________________________________
dense (Dense)                (None, 128)               32896     
_________________________________________________________________
batch_normalization (BatchNo (None, 128)               512       
_________________________________________________________________
dropout (Dropout)            (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
batch_normalization_1 (Batch (None, 64)                256       
_________________________________________________________________
dropout_1 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                2080      
_________________________________________________________________
batch_normalization_2 (Batch (None, 32)                128       
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 264       
=================================================================
Total params: 196,968
Trainable params: 196,520
Non-trainable params: 448
_________________________________________________________________Finished run_model in 6775.4403 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f4b591dad60>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.62      0.59      0.61      4542
           1       0.43      0.22      0.29      3813
           2       0.46      0.81      0.58     10869
           3       0.54      0.39      0.45      6897
           4       0.58      0.11      0.18      2585
           5       0.78      0.12      0.20      1616
           6       0.70      0.58      0.64      3258
           7       0.82      0.61      0.70      1372

    accuracy                           0.52     34952
   macro avg       0.62      0.43      0.46     34952
weighted avg       0.55      0.52      0.49     34952


===confusion_matrix===

[[2665   62 1082  594   11   10   44   74]
 [ 114  846 2284  375   61   10  110   13]
 [ 695  324 8792  643   70   15  284   46]
 [ 559  341 3048 2698   29    8  179   35]
 [  72  178 1575  389  276    6   84    5]
 [  58  117  945  178   18  189  105    6]
 [  45  108 1096   86   11    5 1904    3]
 [  56   10  383   64    0    0   16  843]]

===multilabel confusion matrix===

[[[28811  1599]
  [ 1877  2665]]

 [[29999  1140]
  [ 2967   846]]

 [[13670 10413]
  [ 2077  8792]]

 [[25726  2329]
  [ 4199  2698]]

 [[32167   200]
  [ 2309   276]]

 [[33282    54]
  [ 1427   189]]

 [[30872   822]
  [ 1354  1904]]

 [[33398   182]
  [  529   843]]]

===scores report===
metrics	scores
Accuracy	0.5211
MCC	0.3972
log_loss	1.3029
f1 score weighted	0.4913
f1 score macro	0.4572
f1 score micro	0.5211
roc_auc ovr	0.8208
roc_auc ovo	0.8395
precision	0.5522
recall	0.5211
