/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_z_lev1_ec90_32_16
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_z_lev1_ec90_32_16
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fc7906ddac0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fc7906ddbe0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fc7906ddc40>]/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_z_lev1_ec90_32_16
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_z_lev1_ec90_32_16
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f725c55f760>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f725c55f880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f725c55f8e0>]/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_z_lev1_ec90_32_16
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_z_lev1_ec90_32_16
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f668049da90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f668049dbb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f668049dc10>]/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_z_lev1_ec90_32_16
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_pre_pre_lstm_attentio_cv_only_enz_z_lev1_ec90_32_16
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64304dda90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64304ddbb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64304ddb50>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64304dda00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-2,  2,  0,  0, -1],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 0, -2, -1, -1,  0],
        [ 3,  0,  1, -2,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [-1,  0,  1,  0,  2],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-4, -1, -1,  0,  0],
        [-4, -1, -1,  0,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 2, -1,  1, -1,  0],
        [ 0, -2,  0,  0,  1]],

       [[-1,  0,  1,  0,  2],
        [ 2, -4,  0,  0,  0],
        [-2,  2,  0,  0, -1],
        ...,
        [ 2, -4,  0,  0,  0],
        [ 2, -4,  0,  0,  0],
        [ 2,  1,  0,  3,  0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 6., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.90      0.87      3813
         1.0       0.90      0.92      0.91     10869
         2.0       0.86      0.88      0.87      6897
         3.0       0.99      0.77      0.86      2585
         4.0       0.92      0.89      0.90      1616
         5.0       0.98      0.94      0.96      3258
         6.0       0.94      0.98      0.96      1372

    accuracy                           0.90     30410
   macro avg       0.92      0.90      0.90     30410
weighted avg       0.90      0.90      0.90     30410


===confusion_matrix===

[[ 3429   181   172     3    10     5    13]
 [  255 10043   473     7    43    19    29]
 [  177   516  6088    13    42    23    38]
 [  137   222   199  1983    31     8     5]
 [   27    71    70     1  1437     6     4]
 [   40    76    69     2     7  3060     4]
 [    3    14    16     0     0     0  1339]]

===multilabel confusion matrix===

[[[25958   639]
  [  384  3429]]

 [[18461  1080]
  [  826 10043]]

 [[22514   999]
  [  809  6088]]

 [[27799    26]
  [  602  1983]]

 [[28661   133]
  [  179  1437]]

 [[27091    61]
  [  198  3060]]

 [[28945    93]
  [   33  1339]]]

===scores report===
metrics	scores
Accuracy	0.9003
MCC	0.8722
log_loss	0.3412
f1 score weighted	0.9002
f1 score macro	0.9049
f1 score micro	0.9003
roc_auc ovr	0.9872
roc_auc ovo	0.9896
precision	0.9030
recall	0.9003

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64304dda90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64304ddbb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64304ddb50>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64304dda00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [-2,  0,  0,  1,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-4, -1, -1,  0,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 2, -1,  1, -1,  0],
        [-2, -2, -1,  0,  0],
        [ 2, -4,  0,  0,  0],
        ...,
        [ 2, -4,  0,  0,  0],
        [ 2, -4,  0,  0,  0],
        [-4,  1,  1,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 2,  1,  0,  3,  0],
        [ 0, -1,  3,  0, -2],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 2, -4,  0,  0,  0],
        [-4, -1, -1,  0,  0],
        [-1,  0,  1,  0,  2]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.87      0.90      3813
         1.0       0.88      0.96      0.92     10869
         2.0       0.90      0.86      0.88      6897
         3.0       0.92      0.89      0.90      2585
         4.0       0.93      0.89      0.91      1616
         5.0       0.99      0.92      0.95      3258
         6.0       0.97      0.98      0.97      1372

    accuracy                           0.91     30410
   macro avg       0.93      0.91      0.92     30410
weighted avg       0.91      0.91      0.91     30410


===confusion_matrix===

[[ 3324   273   145    43    16     4     8]
 [   64 10407   304    51    24    11     8]
 [  112   746  5906    69    38     8    18]
 [   30   144    95  2297    16     1     2]
 [   31    74    54    21  1434     1     1]
 [   15   175    49    12     8  2999     0]
 [    4    11    16     0     1     0  1340]]

===multilabel confusion matrix===

[[[26341   256]
  [  489  3324]]

 [[18118  1423]
  [  462 10407]]

 [[22850   663]
  [  991  5906]]

 [[27629   196]
  [  288  2297]]

 [[28691   103]
  [  182  1434]]

 [[27127    25]
  [  259  2999]]

 [[29001    37]
  [   32  1340]]]

===scores report===
metrics	scores
Accuracy	0.9111
MCC	0.8860
log_loss	0.3382
f1 score weighted	0.9109
f1 score macro	0.9196
f1 score micro	0.9111
roc_auc ovr	0.9898
roc_auc ovo	0.9917
precision	0.9128
recall	0.9111

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64304dda90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64304ddbb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64304ddb50>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64304dda00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 2, -1,  1, -1,  0],
        [ 2,  1,  0,  3,  0],
        [-2, -2, -1,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  0,  0,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 0, -2, -1, -1,  0],
        [ 2,  0, -2,  1,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  1,  1, -1,  1],
        [ 2,  1,  0,  3,  0],
        [-4, -1, -1,  0,  0]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 1., 1., 1.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.95      0.83      0.89      3814
         1.0       0.85      0.97      0.91     10869
         2.0       0.91      0.85      0.88      6896
         3.0       0.95      0.84      0.89      2584
         4.0       0.91      0.88      0.90      1617
         5.0       0.98      0.94      0.96      3258
         6.0       0.98      0.96      0.97      1372

    accuracy                           0.91     30410
   macro avg       0.93      0.90      0.91     30410
weighted avg       0.91      0.91      0.90     30410


===confusion_matrix===

[[ 3177   420   148    22    30     5    12]
 [   48 10494   245    32    30    17     3]
 [   70   812  5887    49    48    16    14]
 [   25   264   109  2164    16     3     3]
 [   17   109    44     9  1431     6     1]
 [   10   150    39     1     9  3049     0]
 [    6    26    16     0     1     3  1320]]

===multilabel confusion matrix===

[[[26420   176]
  [  637  3177]]

 [[17760  1781]
  [  375 10494]]

 [[22913   601]
  [ 1009  5887]]

 [[27713   113]
  [  420  2164]]

 [[28659   134]
  [  186  1431]]

 [[27102    50]
  [  209  3049]]

 [[29005    33]
  [   52  1320]]]

===scores report===
metrics	scores
Accuracy	0.9050
MCC	0.8785
log_loss	0.3683
f1 score weighted	0.9048
f1 score macro	0.9130
f1 score micro	0.9050
roc_auc ovr	0.9887
roc_auc ovo	0.9901
precision	0.9090
recall	0.9050

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64304dda90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64304ddbb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64304ddb50>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64304dda00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [ 2, -1,  1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 3,  0,  0,  0,  0],
        [ 0, -2, -1, -1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 3,  0,  1, -2,  0],
        [ 3,  0,  0,  0,  0],
        [-4, -1, -1,  0,  0]],

       [[-3, -1, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [ 3,  0,  0,  0,  0],
        ...,
        [ 2, -4,  0,  0,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0]],

       [[-4,  1,  1,  0,  0],
        [ 0, -1,  3,  0, -2],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 3,  1,  1, -1,  1],
        [ 3,  0,  0,  0,  0],
        [ 3,  1,  1, -1,  1]]], dtype=int8), 'y_test': array([1., 1., 0., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.93      0.86      0.89      3813
         1.0       0.89      0.95      0.92     10868
         2.0       0.89      0.88      0.88      6897
         3.0       0.91      0.88      0.90      2585
         4.0       0.95      0.84      0.90      1616
         5.0       0.99      0.93      0.96      3258
         6.0       0.96      0.97      0.96      1372

    accuracy                           0.91     30409
   macro avg       0.93      0.90      0.92     30409
weighted avg       0.91      0.91      0.91     30409


===confusion_matrix===

[[ 3284   267   185    48    11     3    15]
 [   88 10354   311    57    14    18    26]
 [  100   592  6070    72    31    14    18]
 [   28   157   106  2285     6     1     2]
 [   15   120    72    38  1365     5     1]
 [   18   140    67    10     3  3020     0]
 [    2    15    21     1     0     0  1333]]

===multilabel confusion matrix===

[[[26345   251]
  [  529  3284]]

 [[18250  1291]
  [  514 10354]]

 [[22750   762]
  [  827  6070]]

 [[27598   226]
  [  300  2285]]

 [[28728    65]
  [  251  1365]]

 [[27110    41]
  [  238  3020]]

 [[28975    62]
  [   39  1333]]]

===scores report===
metrics	scores
Accuracy	0.9113
MCC	0.8861
log_loss	0.3433
f1 score weighted	0.9111
f1 score macro	0.9158
f1 score micro	0.9113
roc_auc ovr	0.9894
roc_auc ovo	0.9909
precision	0.9127
recall	0.9113

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f64304dda90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f64304ddbb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f64304ddb50>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f64304dda00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 3,  2, -3,  1,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 2, -4,  0,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2, -2, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  0,  1, -2,  0],
        [ 3,  2, -3,  1,  0],
        [ 3,  1,  1, -1,  1]],

       [[ 2, -4,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        [-1,  0,  1,  0,  2],
        ...,
        [ 2,  1,  0,  3,  0],
        [ 0, -2, -1, -1,  0],
        [-4, -1, -1,  0,  0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 0., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.95      0.85      0.90      3813
         1.0       0.84      0.97      0.90     10868
         2.0       0.91      0.84      0.87      6897
         3.0       0.96      0.85      0.90      2585
         4.0       0.97      0.85      0.91      1616
         5.0       0.99      0.93      0.96      3258
         6.0       0.96      0.97      0.97      1372

    accuracy                           0.90     30409
   macro avg       0.94      0.89      0.92     30409
weighted avg       0.91      0.90      0.90     30409


===confusion_matrix===

[[ 3226   394   143    24    10     6    10]
 [   52 10543   223    25     3     7    15]
 [   51   984  5792    38    13     4    15]
 [   31   225   107  2203    11     3     5]
 [   16   141    74    12  1370     1     2]
 [   10   172    45     2     1  3026     2]
 [    8    21    10     0     0     0  1333]]

===multilabel confusion matrix===

[[[26428   168]
  [  587  3226]]

 [[17604  1937]
  [  325 10543]]

 [[22910   602]
  [ 1105  5792]]

 [[27723   101]
  [  382  2203]]

 [[28755    38]
  [  246  1370]]

 [[27130    21]
  [  232  3026]]

 [[28988    49]
  [   39  1333]]]

===scores report===
metrics	scores
Accuracy	0.9041
MCC	0.8776
log_loss	0.3462
f1 score weighted	0.9040
f1 score macro	0.9150
f1 score micro	0.9041
roc_auc ovr	0.9891
roc_auc ovo	0.9908
precision	0.9095
recall	0.9041

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.9003288391976324	0.8722403981577835	0.34117079017179053	0.900223102567497	0.9048670541503985	0.9003288391976324	0.9872149176319018	0.9895915349184747	0.9030045469637826	0.9003288391976324
1	0.9111147648799737	0.886041294654795	0.33824237878527563	0.9109449936498872	0.9196208632877709	0.9111147648799737	0.9897901874499115	0.991656781813846	0.912808380656813	0.9111147648799737
2	0.9050312397237751	0.8785247437799448	0.36832262764397405	0.9047622704310887	0.9129950833503117	0.9050312397237751	0.9886862150856357	0.990105775643929	0.9089539689103473	0.9050312397237751
3	0.9112762668946693	0.8860577574319443	0.3433458482177034	0.9111195811489793	0.915759622669993	0.9112762668946693	0.9894224601140122	0.9908535524683918	0.9126712614803683	0.9112762668946693
4	0.9041073366437568	0.8775560938991934	0.34617114522677583	0.9039796669210673	0.9150195779238051	0.9041073366437568	0.9891210546467866	0.9908244086017538	0.9094697764097839	0.9041073366437568
mean	0.9063716894679615	0.8800840575847323	0.3474505580091039	0.906205922943704	0.9136524402764558	0.9063716894679615	0.9888469669856497	0.990606410689279	0.909381586884219	0.9063716894679615
std	0.0042424469994897145	0.005320128128469753	0.010755044203449563	0.004229357308763041	0.004889713360529408	0.0042424469994897145	0.0008927942089204266	0.000706043897636495	0.003561520663404203	0.0042424469994897145

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 70899.8042 secs

