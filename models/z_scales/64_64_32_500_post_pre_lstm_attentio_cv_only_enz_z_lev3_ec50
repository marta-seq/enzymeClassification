/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_z_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_z_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fed44791a60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fed44791b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fed44791be0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fed447919d0>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [-2,  0,  0,  1,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 2, -4,  0,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [-1,  0,  1,  0,  2],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  1, -2,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 0, -2, -1, -1,  0],
        [-2,  2,  0,  0, -1],
        [ 2, -1,  1, -1,  0],
        ...,
        [ 3,  0,  0,  0,  0],
        [-4,  1,  1,  0,  0],
        [ 3,  0,  1, -2,  0]],

       [[-2,  0,  0,  1,  0],
        [-1,  0,  1,  0,  2],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.78      0.73       358
         1.0       0.80      0.33      0.47        12
         2.0       0.73      0.42      0.53        19
         3.0       0.64      0.46      0.54        80
         4.0       0.67      0.19      0.29        54
         5.0       0.25      0.05      0.09        58
         6.0       0.47      0.20      0.28        45
         7.0       0.64      0.44      0.52        48
         8.0       0.00      0.00      0.00        11
         9.0       0.57      0.38      0.46        21
        10.0       0.00      0.00      0.00        15
        11.0       0.84      0.72      0.78        36
        12.0       1.00      0.33      0.50        12
        13.0       0.95      0.76      0.84        25
        14.0       1.00      0.05      0.10        19
        15.0       0.92      0.55      0.69        22
        16.0       0.73      0.48      0.58        23
        17.0       0.72      0.87      0.78       119
        18.0       0.69      0.61      0.65        18
        19.0       0.00      0.00      0.00        12
        20.0       0.62      0.32      0.42        90
        21.0       0.00      0.00      0.00        12
        22.0       1.00      0.80      0.89        25
        23.0       0.00      0.00      0.00        12
        24.0       0.22      0.09      0.13        22
        25.0       0.69      0.29      0.41        38
        26.0       1.00      0.59      0.74        17
        27.0       0.33      0.14      0.20        35
        28.0       0.50      0.09      0.15        11
        29.0       0.67      0.22      0.33        36
        30.0       0.64      0.66      0.65        32
        31.0       0.96      0.66      0.78        38
        32.0       0.75      0.78      0.77       747
        33.0       0.81      0.82      0.82        74
        34.0       0.95      0.93      0.94        59
        35.0       0.46      0.79      0.58        48
        36.0       0.73      0.60      0.66       502
        37.0       0.86      0.66      0.75       241
        38.0       0.86      0.36      0.51        33
        39.0       0.56      0.77      0.65       344
        40.0       0.53      0.69      0.60       191
        41.0       0.86      0.56      0.68        32
        42.0       0.66      0.70      0.68       384
        43.0       0.51      0.74      0.61       118
        44.0       0.85      0.57      0.68       436
        45.0       0.85      0.83      0.84        48
        46.0       0.91      0.83      0.87       402
        47.0       0.75      0.18      0.29        17
        48.0       0.74      0.60      0.66        42
        49.0       0.86      0.87      0.87        78
        50.0       0.85      0.86      0.86       172
        51.0       0.82      0.45      0.58        20
        52.0       0.37      0.80      0.51       499
        53.0       0.75      0.77      0.76       100
        54.0       1.00      0.09      0.17        11
        55.0       0.89      0.63      0.74       103
        56.0       1.00      0.28      0.43        18
        57.0       0.00      0.00      0.00        10
        58.0       0.97      0.88      0.92        34
        59.0       0.54      0.62      0.58       231
        60.0       0.90      0.66      0.76        58
        61.0       0.00      0.00      0.00        30
        62.0       0.65      0.27      0.38        48
        63.0       0.50      0.12      0.19        50
        64.0       0.85      0.50      0.63        34
        65.0       0.82      0.71      0.76       155
        66.0       1.00      0.21      0.35        14
        67.0       0.82      0.58      0.68       314
        68.0       0.42      0.08      0.13        63
        69.0       0.51      0.64      0.57       308
        70.0       0.65      0.32      0.43        68
        71.0       0.62      0.55      0.58        66
        72.0       0.00      0.00      0.00        14
        73.0       0.55      0.44      0.49        25
        74.0       0.00      0.00      0.00        18
        75.0       0.15      0.03      0.05        60
        76.0       0.62      0.68      0.65       205
        77.0       0.94      0.21      0.34        77
        78.0       0.95      0.63      0.76        59
        79.0       0.68      0.53      0.59       139
        80.0       0.91      0.50      0.65        42
        81.0       0.40      0.45      0.42       175
        82.0       0.68      0.35      0.46        43
        83.0       0.50      0.19      0.28        26
        84.0       0.75      0.45      0.56       106
        85.0       0.86      0.43      0.57        14
        86.0       0.87      0.53      0.66       242
        87.0       0.62      0.83      0.71       309
        88.0       0.85      0.50      0.63        58
        89.0       0.25      0.09      0.13        11
        90.0       0.19      0.78      0.31       187
        91.0       0.42      0.28      0.34        46
        92.0       0.22      0.05      0.08        40
        93.0       0.52      0.47      0.49        32
        94.0       0.50      0.75      0.60       289
        95.0       0.18      0.06      0.10        31
        96.0       0.75      0.68      0.71        74
        97.0       0.89      0.30      0.44        27
        98.0       0.85      0.59      0.70        37
        99.0       0.91      0.88      0.89        24
       100.0       0.25      0.04      0.07        25
       101.0       0.45      0.52      0.49        65
       102.0       0.82      0.82      0.82        22
       103.0       0.71      0.69      0.70        64
       104.0       0.35      0.20      0.25        40
       105.0       1.00      0.83      0.91        12
       106.0       0.92      0.62      0.74       114
       107.0       0.78      0.74      0.76       161
       108.0       0.70      0.29      0.41        24
       109.0       0.95      0.67      0.79        52
       110.0       0.85      0.73      0.79        15
       111.0       0.76      0.62      0.68       123
       112.0       0.60      0.36      0.45        42
       113.0       0.81      0.86      0.83       430
       114.0       0.53      0.58      0.55        65
       115.0       0.93      0.45      0.61        31
       116.0       0.80      0.73      0.77       173
       117.0       0.84      0.87      0.86        31
       118.0       0.90      0.74      0.81       117
       119.0       0.82      0.83      0.82       136
       120.0       0.68      0.68      0.68        62
       121.0       0.93      0.84      0.89       224
       122.0       0.86      0.71      0.78        35
       123.0       0.85      0.76      0.80        37
       124.0       0.94      0.55      0.69        31
       125.0       0.93      0.87      0.90        15
       126.0       0.72      0.86      0.78        21
       127.0       0.74      0.82      0.78        73

    accuracy                           0.64     12227
   macro avg       0.66      0.50      0.54     12227
weighted avg       0.69      0.64      0.64     12227


===confusion_matrix===

[[280   0   0 ...   0   0   0]
 [  1   4   0 ...   0   0   0]
 [  0   0   8 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   2]
 [  0   0   0 ...   0  18   1]
 [  0   0   0 ...   0   5  60]]

===multilabel confusion matrix===

[[[11745   124]
  [   78   280]]

 [[12214     1]
  [    8     4]]

 [[12205     3]
  [   11     8]]

 [[12126    21]
  [   43    37]]

 [[12168     5]
  [   44    10]]

 [[12160     9]
  [   55     3]]

 [[12172    10]
  [   36     9]]

 [[12167    12]
  [   27    21]]

 [[12216     0]
  [   11     0]]

 [[12200     6]
  [   13     8]]

 [[12212     0]
  [   15     0]]

 [[12186     5]
  [   10    26]]

 [[12215     0]
  [    8     4]]

 [[12201     1]
  [    6    19]]

 [[12208     0]
  [   18     1]]

 [[12204     1]
  [   10    12]]

 [[12200     4]
  [   12    11]]

 [[12067    41]
  [   16   103]]

 [[12204     5]
  [    7    11]]

 [[12215     0]
  [   12     0]]

 [[12119    18]
  [   61    29]]

 [[12215     0]
  [   12     0]]

 [[12202     0]
  [    5    20]]

 [[12215     0]
  [   12     0]]

 [[12198     7]
  [   20     2]]

 [[12184     5]
  [   27    11]]

 [[12210     0]
  [    7    10]]

 [[12182    10]
  [   30     5]]

 [[12215     1]
  [   10     1]]

 [[12187     4]
  [   28     8]]

 [[12183    12]
  [   11    21]]

 [[12188     1]
  [   13    25]]

 [[11286   194]
  [  163   584]]

 [[12139    14]
  [   13    61]]

 [[12165     3]
  [    4    55]]

 [[12135    44]
  [   10    38]]

 [[11612   113]
  [  202   300]]

 [[11961    25]
  [   81   160]]

 [[12192     2]
  [   21    12]]

 [[11673   210]
  [   80   264]]

 [[11920   116]
  [   59   132]]

 [[12192     3]
  [   14    18]]

 [[11705   138]
  [  117   267]]

 [[12027    82]
  [   31    87]]

 [[11747    44]
  [  186   250]]

 [[12172     7]
  [    8    40]]

 [[11792    33]
  [   70   332]]

 [[12209     1]
  [   14     3]]

 [[12176     9]
  [   17    25]]

 [[12138    11]
  [   10    68]]

 [[12029    26]
  [   24   148]]

 [[12205     2]
  [   11     9]]

 [[11058   670]
  [   98   401]]

 [[12102    25]
  [   23    77]]

 [[12216     0]
  [   10     1]]

 [[12116     8]
  [   38    65]]

 [[12209     0]
  [   13     5]]

 [[12216     1]
  [   10     0]]

 [[12192     1]
  [    4    30]]

 [[11873   123]
  [   88   143]]

 [[12165     4]
  [   20    38]]

 [[12197     0]
  [   30     0]]

 [[12172     7]
  [   35    13]]

 [[12171     6]
  [   44     6]]

 [[12190     3]
  [   17    17]]

 [[12048    24]
  [   45   110]]

 [[12213     0]
  [   11     3]]

 [[11872    41]
  [  133   181]]

 [[12157     7]
  [   58     5]]

 [[11727   192]
  [  111   197]]

 [[12147    12]
  [   46    22]]

 [[12139    22]
  [   30    36]]

 [[12212     1]
  [   14     0]]

 [[12193     9]
  [   14    11]]

 [[12209     0]
  [   18     0]]

 [[12156    11]
  [   58     2]]

 [[11937    85]
  [   66   139]]

 [[12149     1]
  [   61    16]]

 [[12166     2]
  [   22    37]]

 [[12054    34]
  [   66    73]]

 [[12183     2]
  [   21    21]]

 [[11931   121]
  [   96    79]]

 [[12177     7]
  [   28    15]]

 [[12196     5]
  [   21     5]]

 [[12105    16]
  [   58    48]]

 [[12212     1]
  [    8     6]]

 [[11965    20]
  [  113   129]]

 [[11761   157]
  [   54   255]]

 [[12164     5]
  [   29    29]]

 [[12213     3]
  [   10     1]]

 [[11424   616]
  [   41   146]]

 [[12163    18]
  [   33    13]]

 [[12180     7]
  [   38     2]]

 [[12181    14]
  [   17    15]]

 [[11719   219]
  [   72   217]]

 [[12187     9]
  [   29     2]]

 [[12136    17]
  [   24    50]]

 [[12199     1]
  [   19     8]]

 [[12186     4]
  [   15    22]]

 [[12201     2]
  [    3    21]]

 [[12199     3]
  [   24     1]]

 [[12121    41]
  [   31    34]]

 [[12201     4]
  [    4    18]]

 [[12145    18]
  [   20    44]]

 [[12172    15]
  [   32     8]]

 [[12215     0]
  [    2    10]]

 [[12107     6]
  [   43    71]]

 [[12032    34]
  [   42   119]]

 [[12200     3]
  [   17     7]]

 [[12173     2]
  [   17    35]]

 [[12210     2]
  [    4    11]]

 [[12080    24]
  [   47    76]]

 [[12175    10]
  [   27    15]]

 [[11708    89]
  [   59   371]]

 [[12128    34]
  [   27    38]]

 [[12195     1]
  [   17    14]]

 [[12023    31]
  [   46   127]]

 [[12191     5]
  [    4    27]]

 [[12100    10]
  [   31    86]]

 [[12066    25]
  [   23   113]]

 [[12145    20]
  [   20    42]]

 [[11989    14]
  [   35   189]]

 [[12188     4]
  [   10    25]]

 [[12185     5]
  [    9    28]]

 [[12195     1]
  [   14    17]]

 [[12211     1]
  [    2    13]]

 [[12199     7]
  [    3    18]]

 [[12133    21]
  [   13    60]]]

===scores report===
metrics	scores
Accuracy	0.6446
MCC	0.6378
log_loss	1.7186
f1 score weighted	0.6419
f1 score macro	0.5390
f1 score micro	0.6446
roc_auc ovr	0.9694
roc_auc ovo	0.9656
precision	0.6878
recall	0.6446

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fed44791a60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fed44791b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fed44791be0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fed447919d0>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [ 2, -4,  0,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 2, -1,  1, -1,  0],
        [ 2,  1,  0,  3,  0],
        [-2, -2, -1,  0,  0]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.71      0.74       357
         1.0       1.00      0.08      0.15        12
         2.0       0.87      0.68      0.76        19
         3.0       0.78      0.35      0.48        80
         4.0       0.32      0.15      0.20        54
         5.0       0.17      0.09      0.11        58
         6.0       0.29      0.39      0.33        44
         7.0       0.43      0.58      0.50        48
         8.0       0.00      0.00      0.00        11
         9.0       0.77      0.81      0.79        21
        10.0       0.29      0.13      0.18        15
        11.0       0.96      0.69      0.81        36
        12.0       0.50      0.17      0.25        12
        13.0       0.71      0.60      0.65        25
        14.0       0.38      0.45      0.41        20
        15.0       0.89      0.74      0.81        23
        16.0       0.68      0.57      0.62        23
        17.0       0.75      0.85      0.80       119
        18.0       0.78      0.41      0.54        17
        19.0       0.00      0.00      0.00        13
        20.0       0.35      0.48      0.40        90
        21.0       0.67      0.17      0.27        12
        22.0       0.77      0.80      0.78        25
        23.0       0.33      0.08      0.13        12
        24.0       0.80      0.18      0.30        22
        25.0       0.66      0.51      0.58        37
        26.0       1.00      1.00      1.00        18
        27.0       0.20      0.03      0.05        35
        28.0       0.33      0.08      0.13        12
        29.0       0.90      0.49      0.63        37
        30.0       0.57      0.84      0.68        32
        31.0       0.86      0.64      0.74        39
        32.0       0.54      0.89      0.67       746
        33.0       0.95      0.77      0.85        74
        34.0       0.76      0.81      0.78        58
        35.0       1.00      0.27      0.43        48
        36.0       0.41      0.77      0.53       502
        37.0       0.55      0.78      0.65       241
        38.0       0.64      0.64      0.64        33
        39.0       0.61      0.62      0.61       344
        40.0       0.54      0.69      0.60       191
        41.0       0.90      0.29      0.44        31
        42.0       0.64      0.74      0.68       384
        43.0       0.74      0.81      0.77       118
        44.0       0.69      0.68      0.68       436
        45.0       0.76      0.77      0.76        48
        46.0       0.63      0.93      0.75       402
        47.0       0.80      0.24      0.36        17
        48.0       0.65      0.40      0.50        42
        49.0       0.97      0.81      0.88        77
        50.0       0.87      0.81      0.84       172
        51.0       0.88      0.75      0.81        20
        52.0       0.64      0.66      0.65       499
        53.0       0.69      0.53      0.60        99
        54.0       0.50      0.09      0.15        11
        55.0       0.70      0.79      0.74       103
        56.0       0.47      0.50      0.49        18
        57.0       0.00      0.00      0.00        11
        58.0       0.89      0.91      0.90        34
        59.0       0.60      0.59      0.60       231
        60.0       0.82      0.64      0.72        58
        61.0       0.00      0.00      0.00        30
        62.0       0.54      0.29      0.38        48
        63.0       0.33      0.08      0.13        49
        64.0       0.88      0.68      0.77        34
        65.0       0.46      0.79      0.58       154
        66.0       0.00      0.00      0.00        14
        67.0       0.82      0.53      0.64       314
        68.0       0.25      0.05      0.08        63
        69.0       0.52      0.57      0.55       308
        70.0       0.28      0.46      0.35        69
        71.0       0.53      0.24      0.33        66
        72.0       1.00      0.07      0.13        14
        73.0       0.61      0.56      0.58        25
        74.0       0.00      0.00      0.00        18
        75.0       0.36      0.27      0.31        59
        76.0       0.70      0.70      0.70       205
        77.0       0.34      0.32      0.33        77
        78.0       0.78      0.47      0.59        59
        79.0       0.86      0.57      0.68       139
        80.0       0.57      0.73      0.64        41
        81.0       0.66      0.36      0.46       175
        82.0       0.75      0.07      0.13        43
        83.0       1.00      0.15      0.27        26
        84.0       0.48      0.51      0.50       105
        85.0       0.88      0.50      0.64        14
        86.0       0.77      0.60      0.67       242
        87.0       0.74      0.70      0.72       309
        88.0       0.80      0.41      0.55        58
        89.0       0.75      0.27      0.40        11
        90.0       0.71      0.36      0.48       187
        91.0       0.75      0.20      0.31        46
        92.0       0.33      0.10      0.15        40
        93.0       0.79      0.58      0.67        33
        94.0       0.58      0.62      0.60       289
        95.0       0.00      0.00      0.00        32
        96.0       0.75      0.66      0.71        74
        97.0       0.30      0.22      0.26        27
        98.0       0.83      0.41      0.55        37
        99.0       0.86      0.79      0.83        24
       100.0       0.00      0.00      0.00        26
       101.0       0.57      0.37      0.45        65
       102.0       1.00      0.41      0.58        22
       103.0       0.75      0.73      0.74        64
       104.0       0.64      0.17      0.27        40
       105.0       0.82      0.69      0.75        13
       106.0       0.86      0.68      0.76       113
       107.0       0.82      0.71      0.76       162
       108.0       0.47      0.29      0.36        24
       109.0       1.00      0.63      0.78        52
       110.0       0.81      0.87      0.84        15
       111.0       0.65      0.65      0.65       123
       112.0       0.82      0.56      0.67        41
       113.0       0.93      0.83      0.87       430
       114.0       0.58      0.78      0.67        65
       115.0       0.80      0.26      0.39        31
       116.0       0.95      0.61      0.75       173
       117.0       0.82      0.77      0.79        30
       118.0       0.83      0.81      0.82       118
       119.0       0.91      0.55      0.69       136
       120.0       0.62      0.67      0.65        61
       121.0       0.75      0.85      0.80       225
       122.0       1.00      0.86      0.92        35
       123.0       0.65      0.74      0.69        38
       124.0       0.69      0.77      0.73        31
       125.0       0.93      0.88      0.90        16
       126.0       0.82      0.67      0.74        21
       127.0       0.75      0.73      0.74        73

    accuracy                           0.64     12227
   macro avg       0.64      0.50      0.53     12227
weighted avg       0.66      0.64      0.63     12227


===confusion_matrix===

[[252   0   0 ...   0   0   0]
 [  0   1   0 ...   0   0   0]
 [  0   0  13 ...   0   0   0]
 ...
 [  0   0   0 ...  14   0   0]
 [  0   0   0 ...   0  14   4]
 [  0   0   0 ...   0   1  53]]

===multilabel confusion matrix===

[[[11794    76]
  [  105   252]]

 [[12215     0]
  [   11     1]]

 [[12206     2]
  [    6    13]]

 [[12139     8]
  [   52    28]]

 [[12156    17]
  [   46     8]]

 [[12144    25]
  [   53     5]]

 [[12141    42]
  [   27    17]]

 [[12142    37]
  [   20    28]]

 [[12213     3]
  [   11     0]]

 [[12201     5]
  [    4    17]]

 [[12207     5]
  [   13     2]]

 [[12190     1]
  [   11    25]]

 [[12213     2]
  [   10     2]]

 [[12196     6]
  [   10    15]]

 [[12192    15]
  [   11     9]]

 [[12202     2]
  [    6    17]]

 [[12198     6]
  [   10    13]]

 [[12074    34]
  [   18   101]]

 [[12208     2]
  [   10     7]]

 [[12212     2]
  [   13     0]]

 [[12056    81]
  [   47    43]]

 [[12214     1]
  [   10     2]]

 [[12196     6]
  [    5    20]]

 [[12213     2]
  [   11     1]]

 [[12204     1]
  [   18     4]]

 [[12180    10]
  [   18    19]]

 [[12209     0]
  [    0    18]]

 [[12188     4]
  [   34     1]]

 [[12213     2]
  [   11     1]]

 [[12188     2]
  [   19    18]]

 [[12175    20]
  [    5    27]]

 [[12184     4]
  [   14    25]]

 [[10908   573]
  [   85   661]]

 [[12150     3]
  [   17    57]]

 [[12154    15]
  [   11    47]]

 [[12179     0]
  [   35    13]]

 [[11167   558]
  [  117   385]]

 [[11831   155]
  [   52   189]]

 [[12182    12]
  [   12    21]]

 [[11745   138]
  [  131   213]]

 [[11924   112]
  [   60   131]]

 [[12195     1]
  [   22     9]]

 [[11681   162]
  [  100   284]]

 [[12075    34]
  [   23    95]]

 [[11657   134]
  [  140   296]]

 [[12167    12]
  [   11    37]]

 [[11601   224]
  [   28   374]]

 [[12209     1]
  [   13     4]]

 [[12176     9]
  [   25    17]]

 [[12148     2]
  [   15    62]]

 [[12035    20]
  [   33   139]]

 [[12205     2]
  [    5    15]]

 [[11543   185]
  [  169   330]]

 [[12105    23]
  [   47    52]]

 [[12215     1]
  [   10     1]]

 [[12089    35]
  [   22    81]]

 [[12199    10]
  [    9     9]]

 [[12216     0]
  [   11     0]]

 [[12189     4]
  [    3    31]]

 [[11906    90]
  [   95   136]]

 [[12161     8]
  [   21    37]]

 [[12197     0]
  [   30     0]]

 [[12167    12]
  [   34    14]]

 [[12170     8]
  [   45     4]]

 [[12190     3]
  [   11    23]]

 [[11927   146]
  [   32   122]]

 [[12213     0]
  [   14     0]]

 [[11876    37]
  [  147   167]]

 [[12155     9]
  [   60     3]]

 [[11757   162]
  [  131   177]]

 [[12077    81]
  [   37    32]]

 [[12147    14]
  [   50    16]]

 [[12213     0]
  [   13     1]]

 [[12193     9]
  [   11    14]]

 [[12209     0]
  [   18     0]]

 [[12139    29]
  [   43    16]]

 [[11961    61]
  [   62   143]]

 [[12102    48]
  [   52    25]]

 [[12160     8]
  [   31    28]]

 [[12075    13]
  [   60    79]]

 [[12163    23]
  [   11    30]]

 [[12019    33]
  [  112    63]]

 [[12183     1]
  [   40     3]]

 [[12201     0]
  [   22     4]]

 [[12064    58]
  [   51    54]]

 [[12212     1]
  [    7     7]]

 [[11941    44]
  [   97   145]]

 [[11840    78]
  [   92   217]]

 [[12163     6]
  [   34    24]]

 [[12215     1]
  [    8     3]]

 [[12012    28]
  [  120    67]]

 [[12178     3]
  [   37     9]]

 [[12179     8]
  [   36     4]]

 [[12189     5]
  [   14    19]]

 [[11809   129]
  [  109   180]]

 [[12192     3]
  [   32     0]]

 [[12137    16]
  [   25    49]]

 [[12186    14]
  [   21     6]]

 [[12187     3]
  [   22    15]]

 [[12200     3]
  [    5    19]]

 [[12198     3]
  [   26     0]]

 [[12144    18]
  [   41    24]]

 [[12205     0]
  [   13     9]]

 [[12147    16]
  [   17    47]]

 [[12183     4]
  [   33     7]]

 [[12212     2]
  [    4     9]]

 [[12101    13]
  [   36    77]]

 [[12040    25]
  [   47   115]]

 [[12195     8]
  [   17     7]]

 [[12175     0]
  [   19    33]]

 [[12209     3]
  [    2    13]]

 [[12060    44]
  [   43    80]]

 [[12181     5]
  [   18    23]]

 [[11769    28]
  [   74   356]]

 [[12125    37]
  [   14    51]]

 [[12194     2]
  [   23     8]]

 [[12049     5]
  [   67   106]]

 [[12192     5]
  [    7    23]]

 [[12089    20]
  [   23    95]]

 [[12084     7]
  [   61    75]]

 [[12141    25]
  [   20    41]]

 [[11937    65]
  [   33   192]]

 [[12192     0]
  [    5    30]]

 [[12174    15]
  [   10    28]]

 [[12185    11]
  [    7    24]]

 [[12210     1]
  [    2    14]]

 [[12203     3]
  [    7    14]]

 [[12136    18]
  [   20    53]]]

===scores report===
metrics	scores
Accuracy	0.6380
MCC	0.6300
log_loss	1.7370
f1 score weighted	0.6259
f1 score macro	0.5335
f1 score micro	0.6380
roc_auc ovr	0.9672
roc_auc ovo	0.9619
precision	0.6595
recall	0.6380

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fed44791a60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fed44791b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fed44791be0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fed447919d0>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 1,  0, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 2, -1,  1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 2, -1,  1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 3,  0,  0,  0,  0],
        [ 0, -2, -1, -1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 3,  0,  1, -2,  0],
        [ 3,  0,  0,  0,  0],
        [-4, -1, -1,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  0,  0,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.68      0.71      0.69       357
         1.0       0.42      0.62      0.50        13
         2.0       0.78      0.37      0.50        19
         3.0       0.26      0.65      0.37        79
         4.0       0.36      0.16      0.22        55
         5.0       0.22      0.10      0.14        59
         6.0       0.36      0.11      0.17        44
         7.0       0.63      0.60      0.62        48
         8.0       0.00      0.00      0.00        10
         9.0       0.89      0.38      0.53        21
        10.0       1.00      0.07      0.12        15
        11.0       0.96      0.72      0.83        36
        12.0       0.83      0.42      0.56        12
        13.0       0.82      0.72      0.77        25
        14.0       0.00      0.00      0.00        20
        15.0       0.94      0.68      0.79        22
        16.0       0.53      0.83      0.64        23
        17.0       0.56      0.92      0.69       118
        18.0       0.42      0.44      0.43        18
        19.0       0.00      0.00      0.00        13
        20.0       0.82      0.30      0.44        89
        21.0       0.00      0.00      0.00        12
        22.0       1.00      0.62      0.77        24
        23.0       0.67      0.17      0.27        12
        24.0       0.40      0.09      0.14        23
        25.0       0.86      0.51      0.64        37
        26.0       0.80      0.94      0.86        17
        27.0       0.45      0.14      0.21        36
        28.0       0.00      0.00      0.00        12
        29.0       0.66      0.62      0.64        37
        30.0       0.53      0.50      0.52        32
        31.0       0.89      0.79      0.84        39
        32.0       0.72      0.82      0.76       746
        33.0       0.80      0.86      0.83        74
        34.0       0.95      0.66      0.78        58
        35.0       0.42      0.75      0.54        48
        36.0       0.71      0.55      0.62       502
        37.0       0.78      0.65      0.71       240
        38.0       0.91      0.61      0.73        33
        39.0       0.62      0.62      0.62       344
        40.0       0.93      0.63      0.75       191
        41.0       0.76      0.42      0.54        31
        42.0       0.88      0.52      0.66       384
        43.0       0.62      0.88      0.73       117
        44.0       0.87      0.58      0.70       436
        45.0       0.92      0.69      0.79        49
        46.0       0.85      0.85      0.85       402
        47.0       1.00      0.24      0.38        17
        48.0       0.64      0.69      0.67        42
        49.0       0.94      0.75      0.83        77
        50.0       0.88      0.93      0.90       172
        51.0       0.86      0.32      0.46        19
        52.0       0.33      0.83      0.47       499
        53.0       0.91      0.48      0.63        99
        54.0       0.50      0.18      0.27        11
        55.0       0.77      0.70      0.73       103
        56.0       0.46      0.33      0.39        18
        57.0       0.00      0.00      0.00        11
        58.0       0.71      0.91      0.80        35
        59.0       0.70      0.48      0.57       231
        60.0       0.48      0.75      0.59        57
        61.0       0.00      0.00      0.00        29
        62.0       0.94      0.31      0.47        48
        63.0       0.33      0.20      0.25        49
        64.0       0.86      0.35      0.50        34
        65.0       0.81      0.71      0.76       155
        66.0       0.33      0.07      0.12        14
        67.0       0.67      0.55      0.60       315
        68.0       0.24      0.08      0.12        63
        69.0       0.52      0.62      0.57       307
        70.0       0.60      0.30      0.40        69
        71.0       0.39      0.39      0.39        66
        72.0       0.17      0.07      0.10        15
        73.0       0.48      0.40      0.43        25
        74.0       0.00      0.00      0.00        18
        75.0       0.34      0.27      0.30        59
        76.0       0.77      0.58      0.66       206
        77.0       0.88      0.38      0.53        76
        78.0       0.79      0.51      0.62        59
        79.0       0.47      0.48      0.47       140
        80.0       1.00      0.50      0.67        42
        81.0       0.44      0.34      0.39       175
        82.0       1.00      0.05      0.09        43
        83.0       0.88      0.28      0.42        25
        84.0       0.37      0.56      0.44       105
        85.0       0.80      0.57      0.67        14
        86.0       0.68      0.65      0.67       242
        87.0       0.45      0.82      0.58       310
        88.0       0.91      0.49      0.64        59
        89.0       0.00      0.00      0.00        11
        90.0       0.64      0.48      0.55       187
        91.0       0.60      0.26      0.36        46
        92.0       0.00      0.00      0.00        40
        93.0       0.30      0.30      0.30        33
        94.0       0.76      0.51      0.61       289
        95.0       0.18      0.06      0.09        32
        96.0       0.93      0.55      0.69        75
        97.0       0.33      0.07      0.12        28
        98.0       0.91      0.54      0.68        37
        99.0       0.86      0.78      0.82        23
       100.0       0.00      0.00      0.00        25
       101.0       0.78      0.48      0.60        66
       102.0       0.53      0.81      0.64        21
       103.0       0.74      0.78      0.76        65
       104.0       0.44      0.30      0.36        40
       105.0       1.00      0.75      0.86        12
       106.0       0.76      0.77      0.76       113
       107.0       0.93      0.65      0.76       162
       108.0       0.78      0.29      0.42        24
       109.0       0.68      0.92      0.78        53
       110.0       0.75      0.43      0.55        14
       111.0       0.63      0.70      0.66       123
       112.0       0.40      0.54      0.46        41
       113.0       0.62      0.94      0.75       429
       114.0       0.85      0.68      0.75        65
       115.0       0.89      0.26      0.40        31
       116.0       0.60      0.82      0.70       173
       117.0       1.00      0.87      0.93        30
       118.0       0.61      0.85      0.71       117
       119.0       0.43      0.88      0.58       136
       120.0       0.57      0.64      0.60        61
       121.0       0.76      0.87      0.81       225
       122.0       0.69      0.71      0.70        35
       123.0       0.80      0.63      0.71        38
       124.0       0.65      0.73      0.69        30
       125.0       0.81      0.81      0.81        16
       126.0       0.89      0.73      0.80        22
       127.0       0.81      0.77      0.79        73

    accuracy                           0.63     12226
   macro avg       0.62      0.50      0.52     12226
weighted avg       0.67      0.63      0.62     12226


===confusion_matrix===

[[255   0   0 ...   0   0   0]
 [  0   8   0 ...   0   0   0]
 [  0   0   7 ...   0   0   0]
 ...
 [  0   0   0 ...  13   0   0]
 [  0   0   0 ...   1  16   2]
 [  0   0   0 ...   0   2  56]]

===multilabel confusion matrix===

[[[11747   122]
  [  102   255]]

 [[12202    11]
  [    5     8]]

 [[12205     2]
  [   12     7]]

 [[12003   144]
  [   28    51]]

 [[12155    16]
  [   46     9]]

 [[12146    21]
  [   53     6]]

 [[12173     9]
  [   39     5]]

 [[12161    17]
  [   19    29]]

 [[12216     0]
  [   10     0]]

 [[12204     1]
  [   13     8]]

 [[12211     0]
  [   14     1]]

 [[12189     1]
  [   10    26]]

 [[12213     1]
  [    7     5]]

 [[12197     4]
  [    7    18]]

 [[12206     0]
  [   20     0]]

 [[12203     1]
  [    7    15]]

 [[12186    17]
  [    4    19]]

 [[12022    86]
  [   10   108]]

 [[12197    11]
  [   10     8]]

 [[12211     2]
  [   13     0]]

 [[12131     6]
  [   62    27]]

 [[12212     2]
  [   12     0]]

 [[12202     0]
  [    9    15]]

 [[12213     1]
  [   10     2]]

 [[12200     3]
  [   21     2]]

 [[12186     3]
  [   18    19]]

 [[12205     4]
  [    1    16]]

 [[12184     6]
  [   31     5]]

 [[12213     1]
  [   12     0]]

 [[12177    12]
  [   14    23]]

 [[12180    14]
  [   16    16]]

 [[12183     4]
  [    8    31]]

 [[11237   243]
  [  134   612]]

 [[12136    16]
  [   10    64]]

 [[12166     2]
  [   20    38]]

 [[12129    49]
  [   12    36]]

 [[11611   113]
  [  227   275]]

 [[11942    44]
  [   83   157]]

 [[12191     2]
  [   13    20]]

 [[11753   129]
  [  132   212]]

 [[12026     9]
  [   71   120]]

 [[12191     4]
  [   18    13]]

 [[11815    27]
  [  183   201]]

 [[12046    63]
  [   14   103]]

 [[11752    38]
  [  183   253]]

 [[12174     3]
  [   15    34]]

 [[11765    59]
  [   61   341]]

 [[12209     0]
  [   13     4]]

 [[12168    16]
  [   13    29]]

 [[12145     4]
  [   19    58]]

 [[12032    22]
  [   12   160]]

 [[12206     1]
  [   13     6]]

 [[10890   837]
  [   86   413]]

 [[12122     5]
  [   51    48]]

 [[12213     2]
  [    9     2]]

 [[12102    21]
  [   31    72]]

 [[12201     7]
  [   12     6]]

 [[12215     0]
  [   11     0]]

 [[12178    13]
  [    3    32]]

 [[11948    47]
  [  120   111]]

 [[12123    46]
  [   14    43]]

 [[12191     6]
  [   29     0]]

 [[12177     1]
  [   33    15]]

 [[12157    20]
  [   39    10]]

 [[12190     2]
  [   22    12]]

 [[12045    26]
  [   45   110]]

 [[12210     2]
  [   13     1]]

 [[11825    86]
  [  142   173]]

 [[12147    16]
  [   58     5]]

 [[11745   174]
  [  116   191]]

 [[12143    14]
  [   48    21]]

 [[12120    40]
  [   40    26]]

 [[12206     5]
  [   14     1]]

 [[12190    11]
  [   15    10]]

 [[12207     1]
  [   18     0]]

 [[12136    31]
  [   43    16]]

 [[11984    36]
  [   86   120]]

 [[12146     4]
  [   47    29]]

 [[12159     8]
  [   29    30]]

 [[12010    76]
  [   73    67]]

 [[12184     0]
  [   21    21]]

 [[11975    76]
  [  115    60]]

 [[12183     0]
  [   41     2]]

 [[12200     1]
  [   18     7]]

 [[12019   102]
  [   46    59]]

 [[12210     2]
  [    6     8]]

 [[11911    73]
  [   84   158]]

 [[11598   318]
  [   55   255]]

 [[12164     3]
  [   30    29]]

 [[12215     0]
  [   11     0]]

 [[11990    49]
  [   98    89]]

 [[12172     8]
  [   34    12]]

 [[12184     2]
  [   40     0]]

 [[12170    23]
  [   23    10]]

 [[11890    47]
  [  141   148]]

 [[12185     9]
  [   30     2]]

 [[12148     3]
  [   34    41]]

 [[12194     4]
  [   26     2]]

 [[12187     2]
  [   17    20]]

 [[12200     3]
  [    5    18]]

 [[12199     2]
  [   25     0]]

 [[12151     9]
  [   34    32]]

 [[12190    15]
  [    4    17]]

 [[12143    18]
  [   14    51]]

 [[12171    15]
  [   28    12]]

 [[12214     0]
  [    3     9]]

 [[12085    28]
  [   26    87]]

 [[12056     8]
  [   57   105]]

 [[12200     2]
  [   17     7]]

 [[12150    23]
  [    4    49]]

 [[12210     2]
  [    8     6]]

 [[12053    50]
  [   37    86]]

 [[12152    33]
  [   19    22]]

 [[11555   242]
  [   26   403]]

 [[12153     8]
  [   21    44]]

 [[12194     1]
  [   23     8]]

 [[11960    93]
  [   31   142]]

 [[12196     0]
  [    4    26]]

 [[12047    62]
  [   18    99]]

 [[11932   158]
  [   17   119]]

 [[12135    30]
  [   22    39]]

 [[11939    62]
  [   29   196]]

 [[12180    11]
  [   10    25]]

 [[12182     6]
  [   14    24]]

 [[12184    12]
  [    8    22]]

 [[12207     3]
  [    3    13]]

 [[12202     2]
  [    6    16]]

 [[12140    13]
  [   17    56]]]

===scores report===
metrics	scores
Accuracy	0.6290
MCC	0.6219
log_loss	1.8306
f1 score weighted	0.6212
f1 score macro	0.5207
f1 score micro	0.6290
roc_auc ovr	0.9665
roc_auc ovo	0.9618
precision	0.6686
recall	0.6290

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fed44791a60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fed44791b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fed44791be0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fed447919d0>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [-3, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 0, -2, -1, -1,  0],
        [ 2,  0, -2,  1,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  1,  1, -1,  1],
        [ 2,  1,  0,  3,  0],
        [-4, -1, -1,  0,  0]],

       [[-2, -2, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  0,  1, -2,  0],
        [ 3,  2, -3,  1,  0],
        [ 3,  1,  1, -1,  1]],

       [[ 2, -4,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        [-1,  0,  1,  0,  2],
        ...,
        [ 2,  1,  0,  3,  0],
        [ 0, -2, -1, -1,  0],
        [-4, -1, -1,  0,  0]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.64      0.81      0.72       358
         1.0       0.67      0.17      0.27        12
         2.0       1.00      0.06      0.11        18
         3.0       0.54      0.56      0.55        79
         4.0       0.23      0.29      0.26        55
         5.0       0.33      0.22      0.27        58
         6.0       0.26      0.24      0.25        45
         7.0       0.21      0.64      0.32        47
         8.0       0.17      0.30      0.21        10
         9.0       0.32      0.57      0.41        21
        10.0       0.15      0.20      0.17        15
        11.0       0.71      0.69      0.70        36
        12.0       1.00      0.08      0.15        12
        13.0       0.83      0.40      0.54        25
        14.0       0.38      0.15      0.21        20
        15.0       1.00      0.55      0.71        22
        16.0       0.35      0.87      0.50        23
        17.0       0.87      0.81      0.84       118
        18.0       0.75      0.33      0.46        18
        19.0       0.00      0.00      0.00        13
        20.0       0.55      0.42      0.47        89
        21.0       1.00      0.08      0.14        13
        22.0       0.59      0.80      0.68        25
        23.0       0.00      0.00      0.00        12
        24.0       0.00      0.00      0.00        23
        25.0       0.50      0.54      0.52        37
        26.0       0.76      0.94      0.84        17
        27.0       0.36      0.14      0.20        36
        28.0       0.33      0.17      0.22        12
        29.0       0.42      0.83      0.56        36
        30.0       0.78      0.56      0.65        32
        31.0       0.91      0.77      0.83        39
        32.0       0.73      0.83      0.78       747
        33.0       0.73      0.74      0.74        74
        34.0       0.75      0.72      0.74        58
        35.0       0.96      0.47      0.63        47
        36.0       0.47      0.72      0.57       502
        37.0       0.76      0.65      0.70       240
        38.0       0.67      0.47      0.55        34
        39.0       0.51      0.74      0.60       344
        40.0       0.58      0.74      0.65       191
        41.0       0.52      0.50      0.51        32
        42.0       0.48      0.75      0.58       384
        43.0       0.50      0.79      0.62       117
        44.0       0.88      0.56      0.69       437
        45.0       0.95      0.71      0.81        49
        46.0       0.83      0.84      0.84       401
        47.0       0.83      0.29      0.43        17
        48.0       0.66      0.45      0.54        42
        49.0       0.91      0.81      0.86        77
        50.0       0.94      0.78      0.86       171
        51.0       1.00      0.45      0.62        20
        52.0       0.77      0.52      0.62       499
        53.0       0.49      0.59      0.54       100
        54.0       0.00      0.00      0.00        11
        55.0       0.89      0.72      0.80       104
        56.0       0.26      0.42      0.32        19
        57.0       0.20      0.09      0.13        11
        58.0       1.00      0.91      0.96        35
        59.0       0.53      0.59      0.56       230
        60.0       0.91      0.72      0.81        58
        61.0       0.00      0.00      0.00        29
        62.0       0.55      0.43      0.48        49
        63.0       0.10      0.10      0.10        50
        64.0       0.91      0.62      0.74        34
        65.0       0.45      0.83      0.58       155
        66.0       0.00      0.00      0.00        14
        67.0       0.69      0.61      0.65       314
        68.0       0.14      0.10      0.11        62
        69.0       0.63      0.53      0.57       307
        70.0       0.38      0.35      0.36        68
        71.0       0.79      0.23      0.35        66
        72.0       0.00      0.00      0.00        15
        73.0       0.86      0.24      0.38        25
        74.0       1.00      0.05      0.10        19
        75.0       0.50      0.19      0.27        59
        76.0       0.76      0.67      0.71       206
        77.0       0.46      0.42      0.44        77
        78.0       0.75      0.51      0.61        59
        79.0       0.71      0.50      0.58       139
        80.0       0.77      0.57      0.66        42
        81.0       0.36      0.44      0.40       174
        82.0       0.70      0.33      0.44        43
        83.0       0.00      0.00      0.00        25
        84.0       0.86      0.51      0.64       105
        85.0       0.47      0.60      0.53        15
        86.0       0.67      0.55      0.60       242
        87.0       0.88      0.70      0.78       309
        88.0       0.92      0.41      0.56        59
        89.0       0.33      0.18      0.24        11
        90.0       0.43      0.56      0.48       188
        91.0       0.54      0.15      0.23        47
        92.0       0.29      0.05      0.09        40
        93.0       0.56      0.42      0.48        33
        94.0       0.58      0.63      0.60       288
        95.0       0.23      0.09      0.13        32
        96.0       0.31      0.88      0.46        75
        97.0       0.28      0.19      0.22        27
        98.0       1.00      0.45      0.62        38
        99.0       0.88      0.96      0.92        23
       100.0       0.17      0.08      0.11        25
       101.0       0.29      0.47      0.36        66
       102.0       0.74      0.64      0.68        22
       103.0       0.85      0.55      0.67        64
       104.0       0.24      0.31      0.27        39
       105.0       0.67      0.67      0.67        12
       106.0       0.86      0.61      0.72       113
       107.0       0.74      0.78      0.76       161
       108.0       0.75      0.13      0.22        23
       109.0       0.95      0.66      0.78        53
       110.0       0.83      0.71      0.77        14
       111.0       0.70      0.62      0.66       123
       112.0       0.67      0.29      0.41        41
       113.0       0.82      0.83      0.82       429
       114.0       0.89      0.52      0.66        65
       115.0       0.79      0.35      0.49        31
       116.0       0.98      0.50      0.66       173
       117.0       0.70      0.84      0.76        31
       118.0       0.92      0.73      0.81       117
       119.0       0.95      0.51      0.66       135
       120.0       0.94      0.53      0.68        62
       121.0       0.51      0.91      0.65       224
       122.0       0.96      0.69      0.80        35
       123.0       0.71      0.65      0.68        37
       124.0       0.70      0.53      0.60        30
       125.0       1.00      0.69      0.81        16
       126.0       0.86      0.55      0.67        22
       127.0       0.58      0.89      0.70        73

    accuracy                           0.62     12226
   macro avg       0.61      0.48      0.50     12226
weighted avg       0.66      0.62      0.62     12226


===confusion_matrix===

[[291   1   0 ...   0   0   0]
 [  0   2   0 ...   0   0   0]
 [  0   0   1 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   0]
 [  0   0   0 ...   0  12  10]
 [  0   0   0 ...   0   1  65]]

===multilabel confusion matrix===

[[[11706   162]
  [   67   291]]

 [[12213     1]
  [   10     2]]

 [[12208     0]
  [   17     1]]

 [[12109    38]
  [   35    44]]

 [[12117    54]
  [   39    16]]

 [[12142    26]
  [   45    13]]

 [[12149    32]
  [   34    11]]

 [[12068   111]
  [   17    30]]

 [[12201    15]
  [    7     3]]

 [[12179    26]
  [    9    12]]

 [[12194    17]
  [   12     3]]

 [[12180    10]
  [   11    25]]

 [[12214     0]
  [   11     1]]

 [[12199     2]
  [   15    10]]

 [[12201     5]
  [   17     3]]

 [[12204     0]
  [   10    12]]

 [[12166    37]
  [    3    20]]

 [[12094    14]
  [   23    95]]

 [[12206     2]
  [   12     6]]

 [[12213     0]
  [   13     0]]

 [[12107    30]
  [   52    37]]

 [[12213     0]
  [   12     1]]

 [[12187    14]
  [    5    20]]

 [[12213     1]
  [   12     0]]

 [[12203     0]
  [   23     0]]

 [[12169    20]
  [   17    20]]

 [[12204     5]
  [    1    16]]

 [[12181     9]
  [   31     5]]

 [[12210     4]
  [   10     2]]

 [[12149    41]
  [    6    30]]

 [[12189     5]
  [   14    18]]

 [[12184     3]
  [    9    30]]

 [[11247   232]
  [  126   621]]

 [[12132    20]
  [   19    55]]

 [[12154    14]
  [   16    42]]

 [[12178     1]
  [   25    22]]

 [[11317   407]
  [  140   362]]

 [[11937    49]
  [   83   157]]

 [[12184     8]
  [   18    16]]

 [[11632   250]
  [   88   256]]

 [[11932   103]
  [   49   142]]

 [[12179    15]
  [   16    16]]

 [[11525   317]
  [   95   289]]

 [[12017    92]
  [   24    93]]

 [[11756    33]
  [  192   245]]

 [[12175     2]
  [   14    35]]

 [[11756    69]
  [   63   338]]

 [[12208     1]
  [   12     5]]

 [[12174    10]
  [   23    19]]

 [[12143     6]
  [   15    62]]

 [[12047     8]
  [   37   134]]

 [[12206     0]
  [   11     9]]

 [[11651    76]
  [  238   261]]

 [[12065    61]
  [   41    59]]

 [[12214     1]
  [   11     0]]

 [[12113     9]
  [   29    75]]

 [[12184    23]
  [   11     8]]

 [[12211     4]
  [   10     1]]

 [[12191     0]
  [    3    32]]

 [[11878   118]
  [   95   135]]

 [[12164     4]
  [   16    42]]

 [[12195     2]
  [   29     0]]

 [[12160    17]
  [   28    21]]

 [[12129    47]
  [   45     5]]

 [[12190     2]
  [   13    21]]

 [[11911   160]
  [   26   129]]

 [[12212     0]
  [   14     0]]

 [[11825    87]
  [  122   192]]

 [[12126    38]
  [   56     6]]

 [[11823    96]
  [  145   162]]

 [[12118    40]
  [   44    24]]

 [[12156     4]
  [   51    15]]

 [[12211     0]
  [   15     0]]

 [[12200     1]
  [   19     6]]

 [[12207     0]
  [   18     1]]

 [[12156    11]
  [   48    11]]

 [[11975    45]
  [   67   139]]

 [[12112    37]
  [   45    32]]

 [[12157    10]
  [   29    30]]

 [[12059    28]
  [   70    69]]

 [[12177     7]
  [   18    24]]

 [[11918   134]
  [   97    77]]

 [[12177     6]
  [   29    14]]

 [[12199     2]
  [   25     0]]

 [[12112     9]
  [   51    54]]

 [[12201    10]
  [    6     9]]

 [[11919    65]
  [  109   133]]

 [[11887    30]
  [   92   217]]

 [[12165     2]
  [   35    24]]

 [[12211     4]
  [    9     2]]

 [[11898   140]
  [   83   105]]

 [[12173     6]
  [   40     7]]

 [[12181     5]
  [   38     2]]

 [[12182    11]
  [   19    14]]

 [[11806   132]
  [  106   182]]

 [[12184    10]
  [   29     3]]

 [[12004   147]
  [    9    66]]

 [[12186    13]
  [   22     5]]

 [[12188     0]
  [   21    17]]

 [[12200     3]
  [    1    22]]

 [[12191    10]
  [   23     2]]

 [[12083    77]
  [   35    31]]

 [[12199     5]
  [    8    14]]

 [[12156     6]
  [   29    35]]

 [[12150    37]
  [   27    12]]

 [[12210     4]
  [    4     8]]

 [[12102    11]
  [   44    69]]

 [[12020    45]
  [   35   126]]

 [[12202     1]
  [   20     3]]

 [[12171     2]
  [   18    35]]

 [[12210     2]
  [    4    10]]

 [[12070    33]
  [   47    76]]

 [[12179     6]
  [   29    12]]

 [[11720    77]
  [   74   355]]

 [[12157     4]
  [   31    34]]

 [[12192     3]
  [   20    11]]

 [[12051     2]
  [   87    86]]

 [[12184    11]
  [    5    26]]

 [[12102     7]
  [   32    85]]

 [[12087     4]
  [   66    69]]

 [[12162     2]
  [   29    33]]

 [[11807   195]
  [   20   204]]

 [[12190     1]
  [   11    24]]

 [[12179    10]
  [   13    24]]

 [[12189     7]
  [   14    16]]

 [[12210     0]
  [    5    11]]

 [[12202     2]
  [   10    12]]

 [[12105    48]
  [    8    65]]]

===scores report===
metrics	scores
Accuracy	0.6246
MCC	0.6167
log_loss	1.8405
f1 score weighted	0.6205
f1 score macro	0.5036
f1 score micro	0.6246
roc_auc ovr	0.9647
roc_auc ovo	0.9610
precision	0.6633
recall	0.6246

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fed44791a60>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fed44791b80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fed44791be0>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fed447919d0>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 0, -2, -1, -1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  1, -2,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2, -2, -1,  0,  0],
        [-2,  2,  0,  0, -1],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [-2,  2,  0,  0, -1],
        [ 0, -1,  3,  0, -2]],

       [[-2, -2, -1,  0,  0],
        [-2, -2, -1,  0,  0],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1]],

       [[-4, -1, -1,  0,  0],
        [-4, -1, -1,  0,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 2, -1,  1, -1,  0],
        [ 0, -2,  0,  0,  1]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.60      0.75      0.67       358
         1.0       0.62      0.42      0.50        12
         2.0       0.45      0.47      0.46        19
         3.0       0.76      0.56      0.64        79
         4.0       0.72      0.24      0.36        55
         5.0       0.33      0.07      0.11        58
         6.0       0.40      0.18      0.25        45
         7.0       0.59      0.21      0.31        47
         8.0       0.20      0.20      0.20        10
         9.0       0.67      0.29      0.40        21
        10.0       0.07      0.07      0.07        15
        11.0       0.92      0.61      0.73        36
        12.0       0.67      0.33      0.44        12
        13.0       0.94      0.68      0.79        25
        14.0       0.13      0.16      0.14        19
        15.0       0.89      0.36      0.52        22
        16.0       0.70      0.30      0.42        23
        17.0       0.47      0.92      0.62       118
        18.0       1.00      0.39      0.56        18
        19.0       0.33      0.08      0.13        12
        20.0       0.46      0.29      0.36        90
        21.0       0.50      0.23      0.32        13
        22.0       0.94      0.64      0.76        25
        23.0       0.50      0.08      0.13        13
        24.0       0.44      0.18      0.26        22
        25.0       0.67      0.47      0.55        38
        26.0       0.76      0.94      0.84        17
        27.0       0.43      0.09      0.14        35
        28.0       1.00      0.08      0.15        12
        29.0       0.88      0.39      0.54        36
        30.0       0.66      0.78      0.71        32
        31.0       0.97      0.82      0.89        38
        32.0       0.89      0.75      0.81       747
        33.0       0.94      0.77      0.85        75
        34.0       0.95      0.63      0.76        59
        35.0       0.81      0.55      0.66        47
        36.0       0.46      0.71      0.56       501
        37.0       0.68      0.67      0.67       241
        38.0       0.68      0.52      0.59        33
        39.0       0.54      0.66      0.59       344
        40.0       0.89      0.70      0.78       192
        41.0       0.83      0.47      0.60        32
        42.0       0.63      0.78      0.69       384
        43.0       0.83      0.74      0.78       117
        44.0       0.73      0.67      0.70       436
        45.0       0.94      0.90      0.92        49
        46.0       0.75      0.87      0.80       401
        47.0       0.78      0.41      0.54        17
        48.0       0.30      0.81      0.44        42
        49.0       1.00      0.70      0.82        77
        50.0       0.95      0.81      0.87       172
        51.0       1.00      0.40      0.57        20
        52.0       0.49      0.69      0.58       499
        53.0       0.60      0.61      0.60       100
        54.0       0.25      0.09      0.13        11
        55.0       0.78      0.76      0.77       104
        56.0       0.60      0.17      0.26        18
        57.0       0.00      0.00      0.00        10
        58.0       1.00      0.66      0.79        35
        59.0       0.77      0.48      0.59       230
        60.0       0.98      0.72      0.83        58
        61.0       0.00      0.00      0.00        29
        62.0       0.88      0.31      0.45        49
        63.0       0.26      0.10      0.14        50
        64.0       0.84      0.62      0.71        34
        65.0       0.80      0.69      0.74       155
        66.0       0.00      0.00      0.00        14
        67.0       0.71      0.58      0.64       314
        68.0       0.18      0.08      0.11        62
        69.0       0.38      0.79      0.51       307
        70.0       0.74      0.29      0.42        68
        71.0       0.58      0.32      0.41        66
        72.0       0.33      0.14      0.20        14
        73.0       0.60      0.50      0.55        24
        74.0       0.00      0.00      0.00        19
        75.0       0.33      0.22      0.26        60
        76.0       0.60      0.65      0.62       206
        77.0       0.41      0.48      0.44        77
        78.0       0.48      0.64      0.55        59
        79.0       0.48      0.50      0.49       139
        80.0       0.61      0.79      0.69        42
        81.0       0.45      0.37      0.41       174
        82.0       0.24      0.44      0.31        43
        83.0       0.40      0.08      0.13        26
        84.0       0.30      0.65      0.41       106
        85.0       0.83      0.33      0.48        15
        86.0       0.65      0.68      0.67       241
        87.0       0.80      0.69      0.74       309
        88.0       0.74      0.49      0.59        59
        89.0       0.67      0.20      0.31        10
        90.0       0.52      0.54      0.53       188
        91.0       0.54      0.30      0.39        46
        92.0       0.40      0.05      0.09        41
        93.0       0.70      0.44      0.54        32
        94.0       0.75      0.55      0.63       288
        95.0       0.33      0.06      0.11        31
        96.0       0.92      0.72      0.81        75
        97.0       0.38      0.19      0.25        27
        98.0       0.69      0.47      0.56        38
        99.0       1.00      0.92      0.96        24
       100.0       0.33      0.04      0.07        25
       101.0       0.21      0.74      0.32        65
       102.0       1.00      0.64      0.78        22
       103.0       0.60      0.78      0.68        64
       104.0       0.47      0.20      0.28        40
       105.0       1.00      0.83      0.91        12
       106.0       0.79      0.56      0.65       113
       107.0       0.84      0.66      0.74       161
       108.0       0.43      0.25      0.32        24
       109.0       0.92      0.42      0.58        52
       110.0       1.00      0.80      0.89        15
       111.0       0.94      0.40      0.56       124
       112.0       0.80      0.39      0.52        41
       113.0       0.87      0.87      0.87       430
       114.0       0.70      0.71      0.70        65
       115.0       0.88      0.45      0.60        31
       116.0       0.83      0.75      0.78       173
       117.0       0.89      0.81      0.85        31
       118.0       0.93      0.74      0.82       117
       119.0       0.62      0.85      0.72       136
       120.0       0.97      0.63      0.76        62
       121.0       0.61      0.91      0.73       224
       122.0       0.88      0.66      0.75        35
       123.0       0.90      0.73      0.81        37
       124.0       0.67      0.84      0.74        31
       125.0       0.65      0.73      0.69        15
       126.0       0.66      0.90      0.76        21
       127.0       0.74      0.70      0.72        73

    accuracy                           0.64     12226
   macro avg       0.64      0.50      0.53     12226
weighted avg       0.67      0.64      0.63     12226


===confusion_matrix===

[[270   0   1 ...   0   0   0]
 [  1   5   0 ...   0   0   0]
 [  0   0   9 ...   0   0   0]
 ...
 [  0   0   0 ...  11   1   0]
 [  0   0   0 ...   0  19   1]
 [  0   0   0 ...   2   5  51]]

===multilabel confusion matrix===

[[[11691   177]
  [   88   270]]

 [[12211     3]
  [    7     5]]

 [[12196    11]
  [   10     9]]

 [[12133    14]
  [   35    44]]

 [[12166     5]
  [   42    13]]

 [[12160     8]
  [   54     4]]

 [[12169    12]
  [   37     8]]

 [[12172     7]
  [   37    10]]

 [[12208     8]
  [    8     2]]

 [[12202     3]
  [   15     6]]

 [[12197    14]
  [   14     1]]

 [[12188     2]
  [   14    22]]

 [[12212     2]
  [    8     4]]

 [[12200     1]
  [    8    17]]

 [[12187    20]
  [   16     3]]

 [[12203     1]
  [   14     8]]

 [[12200     3]
  [   16     7]]

 [[11988   120]
  [   10   108]]

 [[12208     0]
  [   11     7]]

 [[12212     2]
  [   11     1]]

 [[12106    30]
  [   64    26]]

 [[12210     3]
  [   10     3]]

 [[12200     1]
  [    9    16]]

 [[12212     1]
  [   12     1]]

 [[12199     5]
  [   18     4]]

 [[12179     9]
  [   20    18]]

 [[12204     5]
  [    1    16]]

 [[12187     4]
  [   32     3]]

 [[12214     0]
  [   11     1]]

 [[12188     2]
  [   22    14]]

 [[12181    13]
  [    7    25]]

 [[12187     1]
  [    7    31]]

 [[11409    70]
  [  186   561]]

 [[12147     4]
  [   17    58]]

 [[12165     2]
  [   22    37]]

 [[12173     6]
  [   21    26]]

 [[11313   412]
  [  146   355]]

 [[11909    76]
  [   80   161]]

 [[12185     8]
  [   16    17]]

 [[11684   198]
  [  116   228]]

 [[12018    16]
  [   58   134]]

 [[12191     3]
  [   17    15]]

 [[11664   178]
  [   86   298]]

 [[12091    18]
  [   30    87]]

 [[11683   107]
  [  143   293]]

 [[12174     3]
  [    5    44]]

 [[11706   119]
  [   52   349]]

 [[12207     2]
  [   10     7]]

 [[12105    79]
  [    8    34]]

 [[12149     0]
  [   23    54]]

 [[12047     7]
  [   33   139]]

 [[12206     0]
  [   12     8]]

 [[11374   353]
  [  153   346]]

 [[12085    41]
  [   39    61]]

 [[12212     3]
  [   10     1]]

 [[12100    22]
  [   25    79]]

 [[12206     2]
  [   15     3]]

 [[12216     0]
  [   10     0]]

 [[12191     0]
  [   12    23]]

 [[11963    33]
  [  120   110]]

 [[12167     1]
  [   16    42]]

 [[12196     1]
  [   29     0]]

 [[12175     2]
  [   34    15]]

 [[12162    14]
  [   45     5]]

 [[12188     4]
  [   13    21]]

 [[12045    26]
  [   48   107]]

 [[12210     2]
  [   14     0]]

 [[11838    74]
  [  132   182]]

 [[12141    23]
  [   57     5]]

 [[11517   402]
  [   65   242]]

 [[12151     7]
  [   48    20]]

 [[12145    15]
  [   45    21]]

 [[12208     4]
  [   12     2]]

 [[12194     8]
  [   12    12]]

 [[12207     0]
  [   19     0]]

 [[12140    26]
  [   47    13]]

 [[11929    91]
  [   72   134]]

 [[12096    53]
  [   40    37]]

 [[12126    41]
  [   21    38]]

 [[12012    75]
  [   70    69]]

 [[12163    21]
  [    9    33]]

 [[11974    78]
  [  109    65]]

 [[12123    60]
  [   24    19]]

 [[12197     3]
  [   24     2]]

 [[11959   161]
  [   37    69]]

 [[12210     1]
  [   10     5]]

 [[11895    90]
  [   76   165]]

 [[11863    54]
  [   96   213]]

 [[12157    10]
  [   30    29]]

 [[12215     1]
  [    8     2]]

 [[11944    94]
  [   86   102]]

 [[12168    12]
  [   32    14]]

 [[12182     3]
  [   39     2]]

 [[12188     6]
  [   18    14]]

 [[11887    51]
  [  131   157]]

 [[12191     4]
  [   29     2]]

 [[12146     5]
  [   21    54]]

 [[12191     8]
  [   22     5]]

 [[12180     8]
  [   20    18]]

 [[12202     0]
  [    2    22]]

 [[12199     2]
  [   24     1]]

 [[11976   185]
  [   17    48]]

 [[12204     0]
  [    8    14]]

 [[12128    34]
  [   14    50]]

 [[12177     9]
  [   32     8]]

 [[12214     0]
  [    2    10]]

 [[12096    17]
  [   50    63]]

 [[12045    20]
  [   55   106]]

 [[12194     8]
  [   18     6]]

 [[12172     2]
  [   30    22]]

 [[12211     0]
  [    3    12]]

 [[12099     3]
  [   75    49]]

 [[12181     4]
  [   25    16]]

 [[11740    56]
  [   57   373]]

 [[12141    20]
  [   19    46]]

 [[12193     2]
  [   17    14]]

 [[12026    27]
  [   44   129]]

 [[12192     3]
  [    6    25]]

 [[12103     6]
  [   31    86]]

 [[12021    69]
  [   21   115]]

 [[12163     1]
  [   23    39]]

 [[11870   132]
  [   20   204]]

 [[12188     3]
  [   12    23]]

 [[12186     3]
  [   10    27]]

 [[12182    13]
  [    5    26]]

 [[12205     6]
  [    4    11]]

 [[12195    10]
  [    2    19]]

 [[12135    18]
  [   22    51]]]

===scores report===
metrics	scores
Accuracy	0.6368
MCC	0.6292
log_loss	1.7425
f1 score weighted	0.6329
f1 score macro	0.5314
f1 score micro	0.6368
roc_auc ovr	0.9682
roc_auc ovo	0.9638
precision	0.6733
recall	0.6368

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6445571276682751	0.6378286586240152	1.7185546130995442	0.6419126901527857	0.5389987474032722	0.6445571276682751	0.9694405371157796	0.9656370093566035	0.6878199636226743	0.6445571276682751
1	0.638014230800687	0.6300311840767031	1.7369790976750623	0.6258814736033869	0.5335384775207793	0.638014230800687	0.9671596362508795	0.961902637960236	0.6594529325269132	0.638014230800687
2	0.6289874038933421	0.6219320735048985	1.8305596073907968	0.6212387939360771	0.5207131741587071	0.6289874038933421	0.9664625427511221	0.9618136300677274	0.668628361771229	0.6289874038933421
3	0.6245705872730247	0.6167345326183675	1.8405425861171318	0.6204754228097761	0.5036136679227301	0.6245705872730247	0.9646998480690183	0.9609835778868537	0.6632566802619877	0.6245705872730247
4	0.6367577294290856	0.6291735792172031	1.7424508477320244	0.6328742462802853	0.5313724540033417	0.6367577294290856	0.9682004898766768	0.9638328762296177	0.673345404958736	0.6367577294290856
mean	0.6345774158128827	0.6271400056082375	1.7738173504029118	0.6284765253564621	0.5256473042017661	0.6345774158128827	0.9671926108126951	0.9628339463002076	0.6705006686283081	0.6345774158128827
std	0.0070362627030090075	0.007240691441943864	0.05112108233850714	0.008037501669488504	0.01251507698036972	0.0070362627030090075	0.001601058753714601	0.001684474232839643	0.009859856766465213	0.0070362627030090075

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 29057.4816 secs

