/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_z_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/z_scales/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_z_lev2_ec90
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f830c71aa90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f830c71abb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f830c71ac10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f830c71aa00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 3,  2, -3,  1,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-2,  0,  0,  1,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  1, -2,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  0,  0,  0,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 32., 22., 22.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.88      0.83       911
         1.0       0.88      0.57      0.69        53
         2.0       0.90      0.83      0.86       179
         3.0       0.30      0.28      0.29        25
         4.0       0.74      0.31      0.44       112
         5.0       0.89      0.63      0.74       491
         6.0       0.96      0.78      0.86        64
         7.0       0.56      0.14      0.22        37
         8.0       0.83      0.86      0.84       206
         9.0       0.76      0.83      0.79        71
        10.0       0.59      0.94      0.72       404
        11.0       1.00      0.44      0.61        16
        12.0       0.75      0.73      0.74       378
        13.0       0.89      0.74      0.81       191
        14.0       0.00      0.00      0.00        76
        15.0       0.78      0.74      0.76        66
        16.0       0.91      0.77      0.83       141
        17.0       0.80      0.76      0.78       182
        18.0       1.00      0.67      0.80        12
        19.0       1.00      0.92      0.96        38
        20.0       0.90      0.92      0.91      2162
        21.0       0.88      0.95      0.91       168
        22.0       0.65      0.86      0.74      1470
        23.0       0.93      0.73      0.82      1259
        24.0       0.90      0.88      0.89       956
        25.0       0.90      0.88      0.89       283
        26.0       0.80      0.92      0.85      3919
        27.0       0.94      0.90      0.92       531
        28.0       1.00      0.83      0.91        12
        29.0       0.77      0.74      0.76      2345
        30.0       0.86      0.43      0.58       615
        31.0       1.00      0.66      0.79        32
        32.0       0.81      0.72      0.76      1449
        33.0       0.72      0.84      0.78       893
        34.0       0.80      0.89      0.84      1377
        35.0       1.00      0.23      0.37        22
        36.0       0.91      0.78      0.84       844
        37.0       0.92      0.82      0.87      1142
        38.0       0.89      0.83      0.86       314
        39.0       0.82      0.41      0.55        56
        40.0       0.90      0.74      0.81       154
        41.0       0.96      0.94      0.95        52
        42.0       0.86      0.72      0.78       247
        43.0       0.80      0.74      0.77       198
        44.0       0.98      0.83      0.90       529
        45.0       0.95      0.85      0.90       540
        46.0       0.00      0.00      0.00        20
        47.0       0.66      0.66      0.66        80
        48.0       0.99      0.94      0.96      1466
        49.0       0.90      0.82      0.86       148
        50.0       0.90      0.95      0.92      1453
        51.0       0.50      0.08      0.14        12
        52.0       0.95      0.95      0.95       151
        53.0       0.86      0.97      0.91       903
        54.0       0.85      0.68      0.75       108
        55.0       0.92      0.94      0.93        93
        56.0       1.00      0.88      0.94        33
        57.0       0.75      0.86      0.80        49
        58.0       0.86      0.90      0.88       154

    accuracy                           0.83     29892
   macro avg       0.82      0.72      0.75     29892
weighted avg       0.84      0.83      0.83     29892


===confusion_matrix===

[[805   0   0 ...   0   0   0]
 [  0  30   0 ...   0   0   0]
 [  1   0 148 ...   0   0   0]
 ...
 [  0   0   0 ...  29   2   1]
 [  0   0   0 ...   0  42   4]
 [  0   0   0 ...   0  10 139]]

===multilabel confusion matrix===

[[[28753   228]
  [  106   805]]

 [[29835     4]
  [   23    30]]

 [[29696    17]
  [   31   148]]

 [[29851    16]
  [   18     7]]

 [[29768    12]
  [   77    35]]

 [[29361    40]
  [  181   310]]

 [[29826     2]
  [   14    50]]

 [[29851     4]
  [   32     5]]

 [[29650    36]
  [   29   177]]

 [[29802    19]
  [   12    59]]

 [[29224   264]
  [   25   379]]

 [[29876     0]
  [    9     7]]

 [[29424    90]
  [  103   275]]

 [[29683    18]
  [   49   142]]

 [[29812     4]
  [   76     0]]

 [[29812    14]
  [   17    49]]

 [[29740    11]
  [   33   108]]

 [[29676    34]
  [   43   139]]

 [[29880     0]
  [    4     8]]

 [[29854     0]
  [    3    35]]

 [[27517   213]
  [  183  1979]]

 [[29702    22]
  [    9   159]]

 [[27750   672]
  [  200  1270]]

 [[28568    65]
  [  335   924]]

 [[28839    97]
  [  114   842]]

 [[29581    28]
  [   34   249]]

 [[25068   905]
  [  319  3600]]

 [[29332    29]
  [   53   478]]

 [[29880     0]
  [    2    10]]

 [[27021   526]
  [  601  1744]]

 [[29235    42]
  [  348   267]]

 [[29860     0]
  [   11    21]]

 [[28200   243]
  [  403  1046]]

 [[28712   287]
  [  146   747]]

 [[28202   313]
  [  147  1230]]

 [[29870     0]
  [   17     5]]

 [[28984    64]
  [  188   656]]

 [[28671    79]
  [  202   940]]

 [[29546    32]
  [   52   262]]

 [[29831     5]
  [   33    23]]

 [[29726    12]
  [   40   114]]

 [[29838     2]
  [    3    49]]

 [[29616    29]
  [   70   177]]

 [[29657    37]
  [   51   147]]

 [[29355     8]
  [   90   439]]

 [[29328    24]
  [   83   457]]

 [[29872     0]
  [   20     0]]

 [[29785    27]
  [   27    53]]

 [[28407    19]
  [   83  1383]]

 [[29730    14]
  [   27   121]]

 [[28286   153]
  [   77  1376]]

 [[29879     1]
  [   11     1]]

 [[29733     8]
  [    7   144]]

 [[28848   141]
  [   30   873]]

 [[29771    13]
  [   35    73]]

 [[29791     8]
  [    6    87]]

 [[29859     0]
  [    4    29]]

 [[29829    14]
  [    7    42]]

 [[29715    23]
  [   15   139]]]

===scores report===
metrics	scores
Accuracy	0.8338
MCC	0.8249
log_loss	0.6717
f1 score weighted	0.8305
f1 score macro	0.7498
f1 score micro	0.8338
roc_auc ovr	0.9896
roc_auc ovo	0.9863
precision	0.8403
recall	0.8338

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f830c71aa90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f830c71abb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f830c71ac10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f830c71aa00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 3,  0,  1, -2,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2, -2, -1,  0,  0],
        [-2, -2, -1,  0,  0],
        [-2, -2, -1,  0,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 1,  0, -1, -1,  0],
        [ 0, -2,  0,  0,  1]],

       [[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-4, -1, -1,  0,  0],
        [-4, -1, -1,  0,  0],
        [ 3,  2, -3,  1,  0],
        ...,
        [ 0, -2,  0,  0,  1],
        [ 2, -1,  1, -1,  0],
        [ 0, -2,  0,  0,  1]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 56.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.87      0.83       912
         1.0       0.97      0.70      0.81        53
         2.0       0.99      0.59      0.74       179
         3.0       0.67      0.08      0.14        25
         4.0       0.81      0.35      0.49       112
         5.0       0.95      0.59      0.73       492
         6.0       0.94      0.75      0.84        65
         7.0       0.50      0.13      0.21        38
         8.0       0.99      0.79      0.88       206
         9.0       0.94      0.63      0.76        71
        10.0       0.84      0.86      0.85       405
        11.0       1.00      0.53      0.69        17
        12.0       0.89      0.67      0.76       377
        13.0       0.93      0.70      0.80       191
        14.0       0.65      0.14      0.24        76
        15.0       0.76      0.67      0.71        66
        16.0       0.93      0.74      0.82       140
        17.0       0.94      0.70      0.80       182
        18.0       1.00      1.00      1.00        11
        19.0       0.97      0.76      0.85        37
        20.0       0.79      0.94      0.86      2163
        21.0       0.86      0.95      0.90       169
        22.0       0.61      0.85      0.71      1469
        23.0       0.81      0.90      0.85      1259
        24.0       0.93      0.86      0.89       956
        25.0       0.82      0.88      0.85       282
        26.0       0.91      0.87      0.89      3919
        27.0       0.99      0.85      0.91       531
        28.0       1.00      0.75      0.86        12
        29.0       0.73      0.79      0.76      2346
        30.0       0.70      0.63      0.66       615
        31.0       0.96      0.81      0.88        32
        32.0       0.85      0.69      0.76      1450
        33.0       0.90      0.72      0.80       893
        34.0       0.79      0.90      0.84      1376
        35.0       0.87      0.59      0.70        22
        36.0       0.58      0.88      0.70       843
        37.0       0.88      0.84      0.86      1142
        38.0       0.86      0.89      0.87       314
        39.0       0.64      0.57      0.60        56
        40.0       0.84      0.69      0.76       154
        41.0       0.94      0.92      0.93        52
        42.0       0.81      0.80      0.81       247
        43.0       0.99      0.76      0.86       198
        44.0       0.90      0.88      0.89       529
        45.0       0.91      0.88      0.90       539
        46.0       1.00      0.05      0.10        19
        47.0       0.94      0.40      0.56        80
        48.0       0.99      0.95      0.97      1466
        49.0       0.67      0.91      0.77       148
        50.0       0.98      0.91      0.94      1453
        51.0       0.00      0.00      0.00        12
        52.0       1.00      0.83      0.91       151
        53.0       0.96      0.94      0.95       903
        54.0       0.86      0.83      0.85       108
        55.0       0.84      0.98      0.91        93
        56.0       0.91      0.91      0.91        33
        57.0       0.93      0.80      0.86        49
        58.0       0.89      0.82      0.85       154

    accuracy                           0.83     29892
   macro avg       0.85      0.72      0.76     29892
weighted avg       0.85      0.83      0.83     29892


===confusion_matrix===

[[790   0   0 ...   0   0   0]
 [  0  37   0 ...   0   0   0]
 [  1   0 105 ...   0   0   0]
 ...
 [  0   0   0 ...  30   1   1]
 [  0   0   0 ...   0  39   3]
 [  0   0   0 ...   0   1 126]]

===multilabel confusion matrix===

[[[28786   194]
  [  122   790]]

 [[29838     1]
  [   16    37]]

 [[29712     1]
  [   74   105]]

 [[29866     1]
  [   23     2]]

 [[29771     9]
  [   73    39]]

 [[29385    15]
  [  203   289]]

 [[29824     3]
  [   16    49]]

 [[29849     5]
  [   33     5]]

 [[29684     2]
  [   43   163]]

 [[29818     3]
  [   26    45]]

 [[29422    65]
  [   57   348]]

 [[29875     0]
  [    8     9]]

 [[29483    32]
  [  125   252]]

 [[29691    10]
  [   58   133]]

 [[29810     6]
  [   65    11]]

 [[29812    14]
  [   22    44]]

 [[29744     8]
  [   37   103]]

 [[29702     8]
  [   55   127]]

 [[29881     0]
  [    0    11]]

 [[29854     1]
  [    9    28]]

 [[27179   550]
  [  123  2040]]

 [[29696    27]
  [    8   161]]

 [[27630   793]
  [  221  1248]]

 [[28371   262]
  [  132  1127]]

 [[28871    65]
  [  134   822]]

 [[29557    53]
  [   35   247]]

 [[25651   322]
  [  529  3390]]

 [[29355     6]
  [   80   451]]

 [[29880     0]
  [    3     9]]

 [[26868   678]
  [  493  1853]]

 [[29107   170]
  [  225   390]]

 [[29859     1]
  [    6    26]]

 [[28262   180]
  [  452   998]]

 [[28927    72]
  [  253   640]]

 [[28198   318]
  [  144  1232]]

 [[29868     2]
  [    9    13]]

 [[28525   524]
  [  105   738]]

 [[28614   136]
  [  182   960]]

 [[29532    46]
  [   35   279]]

 [[29818    18]
  [   24    32]]

 [[29718    20]
  [   48   106]]

 [[29837     3]
  [    4    48]]

 [[29600    45]
  [   49   198]]

 [[29692     2]
  [   47   151]]

 [[29314    49]
  [   65   464]]

 [[29305    48]
  [   63   476]]

 [[29873     0]
  [   18     1]]

 [[29810     2]
  [   48    32]]

 [[28407    19]
  [   78  1388]]

 [[29678    66]
  [   14   134]]

 [[28407    32]
  [  128  1325]]

 [[29880     0]
  [   12     0]]

 [[29741     0]
  [   26   125]]

 [[28957    32]
  [   53   850]]

 [[29769    15]
  [   18    90]]

 [[29782    17]
  [    2    91]]

 [[29856     3]
  [    3    30]]

 [[29840     3]
  [   10    39]]

 [[29723    15]
  [   28   126]]]

===scores report===
metrics	scores
Accuracy	0.8337
MCC	0.8251
log_loss	0.7062
f1 score weighted	0.8331
f1 score macro	0.7596
f1 score micro	0.8337
roc_auc ovr	0.9891
roc_auc ovo	0.9861
precision	0.8474
recall	0.8337

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f830c71aa90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f830c71abb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f830c71ac10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f830c71aa00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 2, -1,  1, -1,  0],
        [ 2, -4,  0,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 1,  0, -1, -1,  0],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-2,  2,  0,  0, -1],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [ 0, -2, -1, -1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[ 2,  1,  0,  3,  0],
        [ 0, -1,  3,  0, -2],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 2, -4,  0,  0,  0],
        [-4, -1, -1,  0,  0],
        [-1,  0,  1,  0,  2]],

       [[-2, -2, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  0,  1, -2,  0],
        [ 3,  2, -3,  1,  0],
        [ 3,  1,  1, -1,  1]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 17., 30., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.91      0.79       912
         1.0       0.98      0.83      0.90        52
         2.0       0.98      0.73      0.84       179
         3.0       0.83      0.20      0.32        25
         4.0       1.00      0.38      0.55       112
         5.0       0.92      0.67      0.77       492
         6.0       0.93      0.82      0.87        65
         7.0       0.75      0.16      0.26        38
         8.0       0.96      0.79      0.87       205
         9.0       0.96      0.73      0.83        71
        10.0       0.87      0.89      0.88       405
        11.0       1.00      0.53      0.69        17
        12.0       0.74      0.76      0.75       377
        13.0       0.82      0.77      0.80       190
        14.0       0.46      0.08      0.13        76
        15.0       0.92      0.67      0.78        67
        16.0       0.97      0.83      0.89       140
        17.0       0.93      0.78      0.85       183
        18.0       1.00      0.92      0.96        12
        19.0       0.97      0.84      0.90        37
        20.0       0.87      0.93      0.90      2162
        21.0       0.98      0.89      0.93       169
        22.0       0.67      0.87      0.76      1470
        23.0       0.91      0.83      0.87      1259
        24.0       0.90      0.90      0.90       956
        25.0       0.91      0.91      0.91       282
        26.0       0.78      0.93      0.85      3918
        27.0       0.91      0.92      0.91       531
        28.0       0.83      0.77      0.80        13
        29.0       0.84      0.70      0.76      2346
        30.0       0.74      0.66      0.70       615
        31.0       1.00      0.75      0.86        32
        32.0       0.82      0.78      0.80      1450
        33.0       0.89      0.78      0.84       893
        34.0       0.89      0.88      0.89      1376
        35.0       1.00      0.55      0.71        22
        36.0       0.73      0.86      0.79       843
        37.0       0.85      0.89      0.87      1142
        38.0       0.90      0.92      0.91       314
        39.0       1.00      0.38      0.55        55
        40.0       0.96      0.71      0.82       154
        41.0       0.93      0.77      0.84        52
        42.0       0.87      0.77      0.81       247
        43.0       0.98      0.75      0.85       197
        44.0       0.99      0.85      0.91       530
        45.0       0.97      0.85      0.91       540
        46.0       1.00      0.05      0.10        19
        47.0       0.97      0.49      0.66        79
        48.0       0.99      0.95      0.97      1465
        49.0       0.98      0.80      0.88       149
        50.0       0.95      0.92      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.95      0.89      0.92       152
        53.0       0.96      0.95      0.95       903
        54.0       0.94      0.69      0.79       108
        55.0       0.95      0.83      0.89        93
        56.0       1.00      0.81      0.90        32
        57.0       0.97      0.70      0.81        50
        58.0       0.77      1.00      0.87       154

    accuracy                           0.85     29892
   macro avg       0.89      0.73      0.78     29892
weighted avg       0.86      0.85      0.85     29892


===confusion_matrix===

[[834   0   0 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  2   1 131 ...   0   0   0]
 ...
 [  0   0   0 ...  26   1   2]
 [  0   0   0 ...   0  35  14]
 [  0   0   0 ...   0   0 154]]

===multilabel confusion matrix===

[[[28616   364]
  [   78   834]]

 [[29839     1]
  [    9    43]]

 [[29711     2]
  [   48   131]]

 [[29866     1]
  [   20     5]]

 [[29780     0]
  [   69    43]]

 [[29371    29]
  [  163   329]]

 [[29823     4]
  [   12    53]]

 [[29852     2]
  [   32     6]]

 [[29680     7]
  [   43   162]]

 [[29819     2]
  [   19    52]]

 [[29432    55]
  [   45   360]]

 [[29875     0]
  [    8     9]]

 [[29413   102]
  [   89   288]]

 [[29671    31]
  [   44   146]]

 [[29809     7]
  [   70     6]]

 [[29821     4]
  [   22    45]]

 [[29748     4]
  [   24   116]]

 [[29698    11]
  [   41   142]]

 [[29880     0]
  [    1    11]]

 [[29854     1]
  [    6    31]]

 [[27439   291]
  [  153  2009]]

 [[29720     3]
  [   18   151]]

 [[27780   642]
  [  185  1285]]

 [[28526   107]
  [  213  1046]]

 [[28841    95]
  [   91   865]]

 [[29586    24]
  [   24   258]]

 [[24962  1012]
  [  288  3630]]

 [[29312    49]
  [   42   489]]

 [[29877     2]
  [    3    10]]

 [[27223   323]
  [  709  1637]]

 [[29134   143]
  [  209   406]]

 [[29860     0]
  [    8    24]]

 [[28195   247]
  [  320  1130]]

 [[28916    83]
  [  193   700]]

 [[28369   147]
  [  165  1211]]

 [[29870     0]
  [   10    12]]

 [[28782   267]
  [  116   727]]

 [[28568   182]
  [  131  1011]]

 [[29546    32]
  [   24   290]]

 [[29837     0]
  [   34    21]]

 [[29734     4]
  [   45   109]]

 [[29837     3]
  [   12    40]]

 [[29617    28]
  [   58   189]]

 [[29692     3]
  [   49   148]]

 [[29356     6]
  [   80   450]]

 [[29339    13]
  [   82   458]]

 [[29873     0]
  [   18     1]]

 [[29812     1]
  [   40    39]]

 [[28408    19]
  [   67  1398]]

 [[29741     2]
  [   30   119]]

 [[28364    75]
  [  122  1331]]

 [[29880     0]
  [   12     0]]

 [[29733     7]
  [   17   135]]

 [[28951    38]
  [   48   855]]

 [[29779     5]
  [   34    74]]

 [[29795     4]
  [   16    77]]

 [[29860     0]
  [    6    26]]

 [[29841     1]
  [   15    35]]

 [[29693    45]
  [    0   154]]]

===scores report===
metrics	scores
Accuracy	0.8485
MCC	0.8404
log_loss	0.6323
f1 score weighted	0.8465
f1 score macro	0.7787
f1 score micro	0.8485
roc_auc ovr	0.9906
roc_auc ovo	0.9879
precision	0.8574
recall	0.8485

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f830c71aa90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f830c71abb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f830c71ac10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f830c71aa00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 3,  1,  1, -1,  1],
        [-3, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 2,  0, -2,  1,  0],
        [ 2,  0, -2,  1,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[ 0, -2, -1, -1,  0],
        [ 2,  0, -2,  1,  0],
        [-1,  0,  1,  0,  2],
        ...,
        [ 3,  1,  1, -1,  1],
        [ 2,  1,  0,  3,  0],
        [-4, -1, -1,  0,  0]],

       [[-2, -2, -1,  0,  0],
        [ 3,  2, -3,  1,  0],
        [ 0, -2,  0,  0,  1],
        ...,
        [ 1,  0, -1, -1,  0],
        [ 3,  0,  0,  0,  0],
        [ 3,  0,  0,  0,  0]],

       [[ 2, -4,  0,  0,  0],
        [-1,  0,  1,  0,  2],
        [-1,  0,  1,  0,  2],
        ...,
        [ 2,  1,  0,  3,  0],
        [ 0, -2, -1, -1,  0],
        [-4, -1, -1,  0,  0]]], dtype=int8), 'y_test': array([24., 24., 24., ..., 20., 22., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.86      0.86      0.86       912
         1.0       0.96      0.83      0.89        52
         2.0       0.98      0.64      0.78       179
         3.0       0.50      0.17      0.25        24
         4.0       0.98      0.37      0.53       112
         5.0       0.92      0.59      0.72       492
         6.0       1.00      0.67      0.80        64
         7.0       0.56      0.26      0.36        38
         8.0       0.93      0.82      0.88       205
         9.0       0.61      0.84      0.71        70
        10.0       0.84      0.91      0.87       405
        11.0       0.80      0.24      0.36        17
        12.0       0.83      0.74      0.78       378
        13.0       0.88      0.76      0.82       191
        14.0       0.50      0.04      0.07        76
        15.0       0.90      0.55      0.69        67
        16.0       0.94      0.74      0.83       140
        17.0       0.81      0.79      0.80       183
        18.0       0.92      0.92      0.92        12
        19.0       1.00      0.92      0.96        37
        20.0       0.95      0.93      0.94      2162
        21.0       0.98      0.90      0.94       168
        22.0       0.81      0.81      0.81      1470
        23.0       0.91      0.80      0.85      1259
        24.0       0.94      0.86      0.90       955
        25.0       0.88      0.94      0.91       282
        26.0       0.79      0.94      0.85      3918
        27.0       0.95      0.89      0.92       532
        28.0       1.00      0.85      0.92        13
        29.0       0.68      0.82      0.74      2346
        30.0       0.82      0.63      0.71       616
        31.0       0.91      0.66      0.76        32
        32.0       0.69      0.83      0.76      1449
        33.0       0.90      0.76      0.82       893
        34.0       0.89      0.86      0.87      1377
        35.0       1.00      0.36      0.53        22
        36.0       0.91      0.79      0.84       844
        37.0       0.91      0.88      0.90      1142
        38.0       0.88      0.89      0.88       314
        39.0       0.88      0.52      0.65        56
        40.0       0.98      0.71      0.82       153
        41.0       0.98      0.80      0.88        51
        42.0       0.87      0.72      0.79       246
        43.0       0.96      0.82      0.88       197
        44.0       0.94      0.89      0.91       530
        45.0       0.86      0.89      0.88       540
        46.0       1.00      0.10      0.18        20
        47.0       0.50      0.69      0.58        80
        48.0       0.97      0.96      0.96      1465
        49.0       0.82      0.86      0.84       148
        50.0       0.93      0.92      0.92      1453
        51.0       0.00      0.00      0.00        13
        52.0       0.87      0.87      0.87       151
        53.0       0.94      0.95      0.95       904
        54.0       0.72      0.70      0.71       108
        55.0       0.96      0.94      0.95        93
        56.0       1.00      0.91      0.95        33
        57.0       0.90      0.92      0.91        50
        58.0       0.94      0.76      0.84       153

    accuracy                           0.85     29892
   macro avg       0.86      0.73      0.77     29892
weighted avg       0.86      0.85      0.85     29892


===confusion_matrix===

[[788   0   0 ...   0   0   0]
 [  0  43   0 ...   0   0   0]
 [  2   0 115 ...   0   0   0]
 ...
 [  0   0   0 ...  30   1   0]
 [  0   0   0 ...   0  46   2]
 [  0   0   0 ...   0   4 116]]

===multilabel confusion matrix===

[[[28853   127]
  [  124   788]]

 [[29838     2]
  [    9    43]]

 [[29711     2]
  [   64   115]]

 [[29864     4]
  [   20     4]]

 [[29779     1]
  [   71    41]]

 [[29373    27]
  [  201   291]]

 [[29828     0]
  [   21    43]]

 [[29846     8]
  [   28    10]]

 [[29675    12]
  [   36   169]]

 [[29785    37]
  [   11    59]]

 [[29415    72]
  [   38   367]]

 [[29874     1]
  [   13     4]]

 [[29458    56]
  [   99   279]]

 [[29681    20]
  [   45   146]]

 [[29813     3]
  [   73     3]]

 [[29821     4]
  [   30    37]]

 [[29746     6]
  [   37   103]]

 [[29675    34]
  [   39   144]]

 [[29879     1]
  [    1    11]]

 [[29855     0]
  [    3    34]]

 [[27617   113]
  [  154  2008]]

 [[29721     3]
  [   17   151]]

 [[28141   281]
  [  273  1197]]

 [[28531   102]
  [  249  1010]]

 [[28888    49]
  [  134   821]]

 [[29574    36]
  [   16   266]]

 [[24976   998]
  [  248  3670]]

 [[29335    25]
  [   59   473]]

 [[29879     0]
  [    2    11]]

 [[26633   913]
  [  416  1930]]

 [[29191    85]
  [  228   388]]

 [[29858     2]
  [   11    21]]

 [[27907   536]
  [  244  1205]]

 [[28921    78]
  [  218   675]]

 [[28368   147]
  [  197  1180]]

 [[29870     0]
  [   14     8]]

 [[28979    69]
  [  178   666]]

 [[28649   101]
  [  134  1008]]

 [[29538    40]
  [   34   280]]

 [[29832     4]
  [   27    29]]

 [[29737     2]
  [   45   108]]

 [[29840     1]
  [   10    41]]

 [[29619    27]
  [   69   177]]

 [[29688     7]
  [   36   161]]

 [[29330    32]
  [   60   470]]

 [[29276    76]
  [   57   483]]

 [[29872     0]
  [   18     2]]

 [[29757    55]
  [   25    55]]

 [[28379    48]
  [   65  1400]]

 [[29716    28]
  [   21   127]]

 [[28332   107]
  [  121  1332]]

 [[29879     0]
  [   13     0]]

 [[29722    19]
  [   19   132]]

 [[28937    51]
  [   41   863]]

 [[29755    29]
  [   32    76]]

 [[29795     4]
  [    6    87]]

 [[29859     0]
  [    3    30]]

 [[29837     5]
  [    4    46]]

 [[29731     8]
  [   37   116]]]

===scores report===
metrics	scores
Accuracy	0.8495
MCC	0.8413
log_loss	0.6104
f1 score weighted	0.8479
f1 score macro	0.7663
f1 score micro	0.8495
roc_auc ovr	0.9911
roc_auc ovo	0.9887
precision	0.8579
recall	0.8495

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f830c71aa90>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f830c71abb0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f830c71ac10>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f830c71aa00>, 'x_test': array([[[-2,  0,  0,  1,  0],
        [-4, -1, -1,  0,  0],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 0, -2, -1, -1,  0],
        [ 3,  0,  1, -2,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [ 0, -2,  0,  0,  1],
        [-4, -1, -1,  0,  0],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       ...,

       [[-3, -1, -1,  0,  0],
        [ 3,  0,  0,  0,  0],
        [ 3,  0,  0,  0,  0],
        ...,
        [ 2, -4,  0,  0,  0],
        [ 2, -1,  1, -1,  0],
        [-4, -1, -1,  0,  0]],

       [[-2,  0,  0,  1,  0],
        [-1,  0,  1,  0,  2],
        [ 3,  1,  1, -1,  1],
        ...,
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0]],

       [[-1,  0,  1,  0,  2],
        [ 2, -4,  0,  0,  0],
        [-2,  2,  0,  0, -1],
        ...,
        [ 2, -4,  0,  0,  0],
        [ 2, -4,  0,  0,  0],
        [ 2,  1,  0,  3,  0]]], dtype=int8), 'y_test': array([24., 12., 12., ..., 32., 34., 34.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.92      0.83      0.87       911
         1.0       0.95      0.68      0.79        53
         2.0       0.89      0.75      0.81       180
         3.0       0.60      0.12      0.20        25
         4.0       0.93      0.36      0.52       111
         5.0       0.60      0.75      0.67       491
         6.0       0.98      0.86      0.92        64
         7.0       0.38      0.16      0.23        37
         8.0       0.88      0.86      0.87       205
         9.0       0.66      0.77      0.71        71
        10.0       0.91      0.87      0.89       404
        11.0       1.00      0.29      0.45        17
        12.0       0.93      0.68      0.79       378
        13.0       0.89      0.71      0.79       191
        14.0       0.50      0.05      0.10        76
        15.0       0.81      0.58      0.67        66
        16.0       0.95      0.75      0.84       140
        17.0       0.83      0.75      0.79       182
        18.0       1.00      1.00      1.00        12
        19.0       1.00      0.68      0.81        37
        20.0       0.98      0.87      0.92      2162
        21.0       0.95      0.92      0.94       168
        22.0       0.73      0.83      0.78      1470
        23.0       0.94      0.76      0.84      1259
        24.0       0.96      0.85      0.90       955
        25.0       0.93      0.91      0.92       283
        26.0       0.91      0.85      0.88      3919
        27.0       0.95      0.91      0.93       532
        28.0       1.00      0.77      0.87        13
        29.0       0.60      0.85      0.70      2345
        30.0       0.82      0.50      0.62       616
        31.0       0.96      0.84      0.90        32
        32.0       0.52      0.87      0.65      1449
        33.0       0.81      0.78      0.79       893
        34.0       0.89      0.87      0.88      1377
        35.0       0.86      0.55      0.67        22
        36.0       0.88      0.85      0.86       844
        37.0       0.93      0.85      0.89      1142
        38.0       0.89      0.91      0.90       314
        39.0       0.96      0.46      0.63        56
        40.0       0.85      0.77      0.81       153
        41.0       1.00      0.75      0.86        52
        42.0       0.96      0.70      0.81       247
        43.0       0.90      0.82      0.86       197
        44.0       0.97      0.83      0.89       529
        45.0       0.95      0.91      0.93       540
        46.0       0.00      0.00      0.00        20
        47.0       0.76      0.68      0.72        80
        48.0       0.98      0.97      0.97      1466
        49.0       0.96      0.88      0.92       148
        50.0       0.98      0.88      0.93      1453
        51.0       0.00      0.00      0.00        12
        52.0       0.99      0.87      0.93       151
        53.0       0.90      0.96      0.93       904
        54.0       0.92      0.72      0.81       108
        55.0       0.98      0.98      0.98        93
        56.0       0.94      0.91      0.92        33
        57.0       0.90      0.88      0.89        50
        58.0       0.90      0.92      0.91       154

    accuracy                           0.84     29892
   macro avg       0.85      0.73      0.77     29892
weighted avg       0.86      0.84      0.84     29892


===confusion_matrix===

[[760   0   0 ...   0   0   0]
 [  0  36   1 ...   0   0   0]
 [  0   0 135 ...   0   0   0]
 ...
 [  0   0   0 ...  30   0   1]
 [  0   0   0 ...   0  44   5]
 [  0   0   0 ...   0   2 142]]

===multilabel confusion matrix===

[[[28914    67]
  [  151   760]]

 [[29837     2]
  [   17    36]]

 [[29695    17]
  [   45   135]]

 [[29865     2]
  [   22     3]]

 [[29778     3]
  [   71    40]]

 [[29160   241]
  [  123   368]]

 [[29827     1]
  [    9    55]]

 [[29845    10]
  [   31     6]]

 [[29663    24]
  [   29   176]]

 [[29793    28]
  [   16    55]]

 [[29454    34]
  [   53   351]]

 [[29875     0]
  [   12     5]]

 [[29496    18]
  [  120   258]]

 [[29685    16]
  [   56   135]]

 [[29812     4]
  [   72     4]]

 [[29817     9]
  [   28    38]]

 [[29747     5]
  [   35   105]]

 [[29681    29]
  [   45   137]]

 [[29880     0]
  [    0    12]]

 [[29855     0]
  [   12    25]]

 [[27697    33]
  [  278  1884]]

 [[29716     8]
  [   13   155]]

 [[27959   463]
  [  244  1226]]

 [[28569    64]
  [  296   963]]

 [[28900    37]
  [  144   811]]

 [[29590    19]
  [   26   257]]

 [[25643   330]
  [  584  3335]]

 [[29334    26]
  [   49   483]]

 [[29879     0]
  [    3    10]]

 [[26214  1333]
  [  348  1997]]

 [[29207    69]
  [  307   309]]

 [[29859     1]
  [    5    27]]

 [[27266  1177]
  [  183  1266]]

 [[28834   165]
  [  195   698]]

 [[28366   149]
  [  183  1194]]

 [[29868     2]
  [   10    12]]

 [[28949    99]
  [  129   715]]

 [[28679    71]
  [  166   976]]

 [[29541    37]
  [   27   287]]

 [[29835     1]
  [   30    26]]

 [[29718    21]
  [   35   118]]

 [[29840     0]
  [   13    39]]

 [[29638     7]
  [   75   172]]

 [[29677    18]
  [   36   161]]

 [[29349    14]
  [   91   438]]

 [[29327    25]
  [   50   490]]

 [[29872     0]
  [   20     0]]

 [[29795    17]
  [   26    54]]

 [[28401    25]
  [   50  1416]]

 [[29739     5]
  [   18   130]]

 [[28415    24]
  [  180  1273]]

 [[29880     0]
  [   12     0]]

 [[29740     1]
  [   19   132]]

 [[28892    96]
  [   33   871]]

 [[29777     7]
  [   30    78]]

 [[29797     2]
  [    2    91]]

 [[29857     2]
  [    3    30]]

 [[29837     5]
  [    6    44]]

 [[29723    15]
  [   12   142]]]

===scores report===
metrics	scores
Accuracy	0.8368
MCC	0.8290
log_loss	0.6622
f1 score weighted	0.8405
f1 score macro	0.7669
f1 score micro	0.8368
roc_auc ovr	0.9898
roc_auc ovo	0.9874
precision	0.8614
recall	0.8368

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8338016860698515	0.824926061962358	0.6717184230703045	0.8305283943282173	0.7498030059159004	0.8338016860698515	0.9895866052914044	0.9863144694872402	0.8402917728866027	0.8338016860698515
1	0.8336678710022749	0.8250708449683261	0.7062248160921317	0.8331294619662739	0.759636956267394	0.8336678710022749	0.9890936703430611	0.9860829980033541	0.847446952906041	0.8336678710022749
2	0.8484544359694902	0.8404213084426987	0.6323420290361078	0.8465039338388852	0.7786542754497303	0.8484544359694902	0.9906205330746073	0.9878732790817832	0.8573507225562244	0.8484544359694902
3	0.8495249565101031	0.8413450782847115	0.6104280366092275	0.8479487297841357	0.7662601882260246	0.8495249565101031	0.991096564186579	0.9886542317046451	0.8578553435574932	0.8495249565101031
4	0.8368125250903252	0.828966249461865	0.6622158276373119	0.8405282031384367	0.7669045012820491	0.8368125250903252	0.9897625748489842	0.9874144926239076	0.861437634981404	0.8368125250903252
mean	0.840452294928409	0.832145908623992	0.6565858264890166	0.8397277446111898	0.7642517854282196	0.840452294928409	0.9900319895489271	0.987267894180186	0.8528764853775531	0.840452294928409
std	0.0070690081353829625	0.007285600984718888	0.032994014495251744	0.006961428747149509	0.009471707128055907	0.0070690081353829625	0.0007254098138629147	0.0009615520068614496	0.007822479414936974	0.0070690081353829625

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 68734.0842 secs

