/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_900_pre_pre_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fa268212fd0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fa268212dc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fa268212f40>]/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_900_pre_pre_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4e107d7fd0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f4e107d7dc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4e107d7f40>]/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_900_pre_pre_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab640d3df0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab640d3ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab640d3f70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab640d3cd0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.87      0.66      0.75      4541
         1.0       0.93      0.82      0.87      3813
         2.0       0.90      0.91      0.90     10869
         3.0       0.76      0.91      0.83      6897
         4.0       0.91      0.84      0.88      2585
         5.0       0.82      0.88      0.85      1617
         6.0       0.91      0.97      0.94      3258
         7.0       0.95      0.96      0.95      1372

    accuracy                           0.87     34952
   macro avg       0.88      0.87      0.87     34952
weighted avg       0.87      0.87      0.87     34952


===confusion_matrix===

[[3016   55  368  944   35   45   41   37]
 [  45 3136  196  256   56   48   65   11]
 [ 184   56 9860  496   61   71  127   14]
 [ 144   58  269 6254   43   70   52    7]
 [  24   35  128  147 2176   61   13    1]
 [  18   23   53   77   13 1420   11    2]
 [   3    6   39   26    0    8 3176    0]
 [  16    8   14   11    1    0    5 1317]]

===multilabel confusion matrix===

[[[29977   434]
  [ 1525  3016]]

 [[30898   241]
  [  677  3136]]

 [[23016  1067]
  [ 1009  9860]]

 [[26098  1957]
  [  643  6254]]

 [[32158   209]
  [  409  2176]]

 [[33032   303]
  [  197  1420]]

 [[31380   314]
  [   82  3176]]

 [[33508    72]
  [   55  1317]]]

===scores report===
metrics	scores
Accuracy	0.8685
MCC	0.8400
log_loss	0.4215
f1 score weighted	0.8672
f1 score macro	0.8726
f1 score micro	0.8685
roc_auc ovr	0.9836
roc_auc ovo	0.9859
precision	0.8734
recall	0.8685

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab640d3df0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab640d3ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab640d3f70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab640d3cd0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.69      0.71      4541
         1.0       0.70      0.67      0.68      3813
         2.0       0.79      0.74      0.77     10869
         3.0       0.64      0.73      0.68      6897
         4.0       0.47      0.68      0.55      2585
         5.0       0.70      0.36      0.48      1616
         6.0       0.89      0.83      0.86      3258
         7.0       0.93      0.89      0.91      1372

    accuracy                           0.72     34951
   macro avg       0.73      0.70      0.71     34951
weighted avg       0.73      0.72      0.72     34951


===confusion_matrix===

[[3155  109  400  717   55   28   30   47]
 [  87 2541  367  386  345   54   28    5]
 [ 454  461 8070  988  669   61  144   22]
 [ 439  185  680 5029  458   20   66   20]
 [  57  105  262  340 1758   30   32    1]
 [  77  135  160  210  398  588   47    1]
 [  17   65  248   80   85   53 2710    0]
 [  34   26   35   52    4    1    4 1216]]

===multilabel confusion matrix===

[[[29245  1165]
  [ 1386  3155]]

 [[30052  1086]
  [ 1272  2541]]

 [[21930  2152]
  [ 2799  8070]]

 [[25281  2773]
  [ 1868  5029]]

 [[30352  2014]
  [  827  1758]]

 [[33088   247]
  [ 1028   588]]

 [[31342   351]
  [  548  2710]]

 [[33483    96]
  [  156  1216]]]

===scores report===
metrics	scores
Accuracy	0.7172
MCC	0.6558
log_loss	0.8332
f1 score weighted	0.7187
f1 score macro	0.7052
f1 score micro	0.7172
roc_auc ovr	0.9324
roc_auc ovo	0.9373
precision	0.7300
recall	0.7172

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab640d3df0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab640d3ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab640d3f70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab640d3cd0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.82      0.79      4542
         1.0       0.90      0.84      0.87      3814
         2.0       0.87      0.92      0.90     10869
         3.0       0.84      0.83      0.84      6896
         4.0       0.88      0.84      0.86      2584
         5.0       0.93      0.81      0.87      1616
         6.0       0.99      0.93      0.96      3258
         7.0       0.96      0.96      0.96      1372

    accuracy                           0.87     34951
   macro avg       0.89      0.87      0.88     34951
weighted avg       0.87      0.87      0.87     34951


===confusion_matrix===

[[ 3732    74   312   367    16     9     5    27]
 [  124  3200   226   160    68    16     6    14]
 [  391    86 10026   272    67    14     8     5]
 [  471    75   490  5718    92    27    10    13]
 [   48    41   176   135  2161    18     5     0]
 [   59    35    96    68    39  1314     5     0]
 [   27    21   122    43    10    13  3022     0]
 [   20    12    15     7     1     1     3  1313]]

===multilabel confusion matrix===

[[[29269  1140]
  [  810  3732]]

 [[30793   344]
  [  614  3200]]

 [[22645  1437]
  [  843 10026]]

 [[27003  1052]
  [ 1178  5718]]

 [[32074   293]
  [  423  2161]]

 [[33237    98]
  [  302  1314]]

 [[31651    42]
  [  236  3022]]

 [[33520    59]
  [   59  1313]]]

===scores report===
metrics	scores
Accuracy	0.8722
MCC	0.8433
log_loss	0.4013
f1 score weighted	0.8725
f1 score macro	0.8795
f1 score micro	0.8722
roc_auc ovr	0.9825
roc_auc ovo	0.9844
precision	0.8744
recall	0.8722

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab640d3df0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab640d3ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab640d3f70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab640d3cd0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.59      0.64      0.62      4542
         1.0       0.24      0.12      0.16      3813
         2.0       0.46      0.55      0.50     10868
         3.0       0.35      0.47      0.40      6897
         4.0       0.53      0.01      0.01      2585
         5.0       0.00      0.00      0.00      1616
         6.0       0.42      0.60      0.50      3258
         7.0       0.64      0.43      0.52      1372

    accuracy                           0.43     34951
   macro avg       0.40      0.35      0.34     34951
weighted avg       0.42      0.43      0.40     34951


===confusion_matrix===

[[2921    9  409 1059    0    0   54   90]
 [ 124  472 1613 1171    2    0  411   20]
 [ 825  639 5999 2276    5    0  979  145]
 [ 832  225 1986 3244    1    0  533   76]
 [  54  365 1080  795   16    0  272    3]
 [  68  151  730  371    6    0  290    0]
 [  21  121  873  291    0    0 1952    0]
 [  98    2  438  126    0    0  115  593]]

===multilabel confusion matrix===

[[[28387  2022]
  [ 1621  2921]]

 [[29626  1512]
  [ 3341   472]]

 [[16954  7129]
  [ 4869  5999]]

 [[21965  6089]
  [ 3653  3244]]

 [[32352    14]
  [ 2569    16]]

 [[33335     0]
  [ 1616     0]]

 [[29039  2654]
  [ 1306  1952]]

 [[33245   334]
  [  779   593]]]

===scores report===
metrics	scores
Accuracy	0.4348
MCC	0.2910
log_loss	1.5017
f1 score weighted	0.3996
f1 score macro	0.3379
f1 score micro	0.4348
roc_auc ovr	0.7534
roc_auc ovo	0.7706
precision	0.4175
recall	0.4348

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fab640d3df0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fab640d3ca0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fab640d3f70>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fab640d3cd0>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.79      0.71      0.75      4542
         1.0       0.93      0.75      0.83      3813
         2.0       0.91      0.85      0.88     10868
         3.0       0.69      0.89      0.78      6897
         4.0       0.86      0.80      0.83      2585
         5.0       0.77      0.83      0.80      1616
         6.0       0.96      0.94      0.95      3258
         7.0       0.95      0.93      0.94      1372

    accuracy                           0.84     34951
   macro avg       0.86      0.84      0.84     34951
weighted avg       0.85      0.84      0.84     34951


===confusion_matrix===

[[3234   49  230  895   42   53    5   34]
 [  91 2869  204  439   72  101   27   10]
 [ 345   75 9239  936  103  107   55    8]
 [ 287   42  260 6151   57   63   26   11]
 [  31   27  112  283 2066   57    6    3]
 [  38   18   54  110   37 1348    9    2]
 [  11   15   46   96    4   30 3056    0]
 [  31    1   17   34    8    1    4 1276]]

===multilabel confusion matrix===

[[[29575   834]
  [ 1308  3234]]

 [[30911   227]
  [  944  2869]]

 [[23160   923]
  [ 1629  9239]]

 [[25261  2793]
  [  746  6151]]

 [[32043   323]
  [  519  2066]]

 [[32923   412]
  [  268  1348]]

 [[31561   132]
  [  202  3056]]

 [[33511    68]
  [   96  1276]]]

===scores report===
metrics	scores
Accuracy	0.8366
MCC	0.8022
log_loss	0.5007
f1 score weighted	0.8383
f1 score macro	0.8443
f1 score micro	0.8366
roc_auc ovr	0.9758
roc_auc ovo	0.9791
precision	0.8488
recall	0.8366

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8684767681391623	0.8399630984466341	0.4214760332179804	0.8672454372608268	0.8726377787600481	0.8684767681391623	0.9835657078946253	0.9859069712457212	0.8734364287488036	0.8684767681391623
1	0.717204085720008	0.655770225819023	0.8331671246978226	0.7186609066401659	0.705178686965603	0.717204085720008	0.9324275559392462	0.9373267241025927	0.7299627793959077	0.717204085720008
2	0.8722497210380247	0.8433126517298679	0.4013226374350016	0.8725262718462786	0.8795240382486299	0.8722497210380247	0.9825220630167237	0.984440828562428	0.8743542101710755	0.8722497210380247
3	0.4348087322251152	0.29103154259111746	1.501735894374142	0.39959781506030106	0.33788366234790024	0.4348087322251152	0.7533966885326006	0.7706359452579835	0.417492119438842	0.4348087322251152
4	0.8365711996795514	0.8021554981805434	0.5007144920691315	0.8383265769349988	0.8442590402026573	0.8365711996795514	0.9758025631560665	0.9791126537997868	0.8488241058807529	0.8365711996795514
mean	0.7458621013603722	0.6864466033534372	0.7316832363588157	0.7392714015485142	0.7278966413049678	0.7458621013603722	0.9255429157078524	0.9314846245937023	0.7488139287270764	0.7458621013603722
std	0.16541572340365532	0.2092161227808935	0.41520916915438827	0.17874511456459455	0.20499136638271273	0.16541572340365532	0.08811472249811993	0.08239054349943578	0.1740245226697369	0.16541572340365532

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 116492.4500 secs

