/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_300_pre_middle_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7a983d82b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7a983d8040>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7a983d8490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7a983d8280>, 'x_test': array([[[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.78      0.75      4541
         1.0       0.88      0.84      0.86      3813
         2.0       0.89      0.89      0.89     10869
         3.0       0.83      0.85      0.84      6897
         4.0       0.91      0.86      0.88      2585
         5.0       0.84      0.88      0.86      1617
         6.0       0.96      0.95      0.95      3258
         7.0       0.95      0.95      0.95      1372

    accuracy                           0.87     34952
   macro avg       0.88      0.87      0.87     34952
weighted avg       0.87      0.87      0.87     34952


===confusion_matrix===

[[3541  107  370  391   36   48   14   34]
 [ 121 3213  180  186   33   45   29    6]
 [ 607  114 9623  365   57   70   26    7]
 [ 441   97  332 5847   74   56   32   18]
 [  49   56  114  111 2211   22   20    2]
 [  35   26   54   54   18 1420    7    3]
 [  28   21   58   42    3   18 3088    0]
 [  25   12   21    7    1    2    1 1303]]

===multilabel confusion matrix===

[[[29105  1306]
  [ 1000  3541]]

 [[30706   433]
  [  600  3213]]

 [[22954  1129]
  [ 1246  9623]]

 [[26899  1156]
  [ 1050  5847]]

 [[32145   222]
  [  374  2211]]

 [[33074   261]
  [  197  1420]]

 [[31565   129]
  [  170  3088]]

 [[33510    70]
  [   69  1303]]]

===scores report===
metrics	scores
Accuracy	0.8654
MCC	0.8355
log_loss	0.4323
f1 score weighted	0.8660
f1 score macro	0.8741
f1 score micro	0.8654
roc_auc ovr	0.9810
roc_auc ovo	0.9843
precision	0.8671
recall	0.8654

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7a983d82b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7a983d8040>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7a983d8490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7a983d8280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.70      0.74      4541
         1.0       0.85      0.87      0.86      3813
         2.0       0.86      0.91      0.89     10869
         3.0       0.84      0.83      0.84      6897
         4.0       0.90      0.86      0.88      2585
         5.0       0.93      0.84      0.88      1616
         6.0       0.94      0.95      0.95      3258
         7.0       0.96      0.95      0.96      1372

    accuracy                           0.86     34951
   macro avg       0.88      0.87      0.87     34951
weighted avg       0.86      0.86      0.86     34951


===confusion_matrix===

[[3195  157  589  469   43   25   37   26]
 [  60 3335  195  131   40   10   34    8]
 [ 370  142 9920  279   70   21   55   12]
 [ 323  170  515 5731   63   40   50    5]
 [  48   54  155   80 2223   11   14    0]
 [  47   30   91   56   24 1359    9    0]
 [  15   29   67   31    7    2 3107    0]
 [  30   11   14    7    3    1    3 1303]]

===multilabel confusion matrix===

[[[29517   893]
  [ 1346  3195]]

 [[30545   593]
  [  478  3335]]

 [[22456  1626]
  [  949  9920]]

 [[27001  1053]
  [ 1166  5731]]

 [[32116   250]
  [  362  2223]]

 [[33225   110]
  [  257  1359]]

 [[31491   202]
  [  151  3107]]

 [[33528    51]
  [   69  1303]]]

===scores report===
metrics	scores
Accuracy	0.8633
MCC	0.8324
log_loss	0.4504
f1 score weighted	0.8623
f1 score macro	0.8734
f1 score micro	0.8633
roc_auc ovr	0.9809
roc_auc ovo	0.9840
precision	0.8626
recall	0.8633

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7a983d82b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7a983d8040>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7a983d8490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7a983d8280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.70      0.71      4542
         1.0       0.83      0.79      0.81      3814
         2.0       0.85      0.86      0.85     10869
         3.0       0.76      0.81      0.79      6896
         4.0       0.80      0.79      0.80      2584
         5.0       0.88      0.72      0.79      1616
         6.0       0.90      0.94      0.92      3258
         7.0       0.92      0.94      0.93      1372

    accuracy                           0.82     34951
   macro avg       0.84      0.82      0.83     34951
weighted avg       0.82      0.82      0.82     34951


===confusion_matrix===

[[3189  117  462  606   46   31   38   53]
 [ 109 3022  254  246   94   13   50   26]
 [ 546  203 9306  489  163   44  107   11]
 [ 383  152  486 5618  123   38   79   17]
 [  53   64  192  181 2052   14   26    2]
 [  62   57  117  141   49 1165   24    1]
 [  19   28   77   59   16   11 3048    0]
 [  24    9   25   14    7    1    4 1288]]

===multilabel confusion matrix===

[[[29213  1196]
  [ 1353  3189]]

 [[30507   630]
  [  792  3022]]

 [[22469  1613]
  [ 1563  9306]]

 [[26319  1736]
  [ 1278  5618]]

 [[31869   498]
  [  532  2052]]

 [[33183   152]
  [  451  1165]]

 [[31365   328]
  [  210  3048]]

 [[33469   110]
  [   84  1288]]]

===scores report===
metrics	scores
Accuracy	0.8208
MCC	0.7805
log_loss	0.5356
f1 score weighted	0.8204
f1 score macro	0.8262
f1 score micro	0.8208
roc_auc ovr	0.9691
roc_auc ovo	0.9735
precision	0.8213
recall	0.8208

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7a983d82b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7a983d8040>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7a983d8490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7a983d8280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.77      0.68      0.72      4542
         1.0       0.92      0.76      0.83      3813
         2.0       0.84      0.91      0.87     10868
         3.0       0.78      0.86      0.82      6897
         4.0       0.85      0.86      0.85      2585
         5.0       0.88      0.83      0.85      1616
         6.0       0.97      0.92      0.95      3258
         7.0       0.98      0.92      0.95      1372

    accuracy                           0.85     34951
   macro avg       0.87      0.84      0.86     34951
weighted avg       0.85      0.85      0.85     34951


===confusion_matrix===

[[3093   71  633  595   61   48   25   16]
 [  82 2901  362  306  118   30   12    2]
 [ 387   65 9844  427   84   38   23    0]
 [ 318   62  458 5923   73   46    9    8]
 [  34   26  151  142 2213   12    7    0]
 [  31   14  103   88   33 1337   10    0]
 [  22    5  131   64   21   15 2999    1]
 [  59   13   19   15    4    1    1 1260]]

===multilabel confusion matrix===

[[[29476   933]
  [ 1449  3093]]

 [[30882   256]
  [  912  2901]]

 [[22226  1857]
  [ 1024  9844]]

 [[26417  1637]
  [  974  5923]]

 [[31972   394]
  [  372  2213]]

 [[33145   190]
  [  279  1337]]

 [[31606    87]
  [  259  2999]]

 [[33552    27]
  [  112  1260]]]

===scores report===
metrics	scores
Accuracy	0.8460
MCC	0.8110
log_loss	0.4832
f1 score weighted	0.8453
f1 score macro	0.8553
f1 score micro	0.8460
roc_auc ovr	0.9778
roc_auc ovo	0.9808
precision	0.8486
recall	0.8460

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7a983d82b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f7a983d8040>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f7a983d8490>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f7a983d8280>, 'x_test': array([[[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 1, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.73      0.76      0.74      4542
         1.0       0.91      0.80      0.85      3813
         2.0       0.90      0.86      0.88     10868
         3.0       0.75      0.87      0.80      6897
         4.0       0.89      0.85      0.87      2585
         5.0       0.92      0.85      0.88      1616
         6.0       0.94      0.94      0.94      3258
         7.0       0.95      0.92      0.94      1372

    accuracy                           0.85     34951
   macro avg       0.87      0.86      0.86     34951
weighted avg       0.86      0.85      0.85     34951


===confusion_matrix===

[[3442   64  306  586   47   30   30   37]
 [ 121 3056  172  350   59   17   28   10]
 [ 556  102 9363  677   77   25   59    9]
 [ 433   73  286 5972   65   31   34    3]
 [  68   33  101  148 2210    9   16    0]
 [  38    9   54  117   19 1366   12    1]
 [  29    9   69   70    9    9 3063    0]
 [  33    7   23   37    4    0    1 1267]]

===multilabel confusion matrix===

[[[29131  1278]
  [ 1100  3442]]

 [[30841   297]
  [  757  3056]]

 [[23072  1011]
  [ 1505  9363]]

 [[26069  1985]
  [  925  5972]]

 [[32086   280]
  [  375  2210]]

 [[33214   121]
  [  250  1366]]

 [[31513   180]
  [  195  3063]]

 [[33519    60]
  [  105  1267]]]

===scores report===
metrics	scores
Accuracy	0.8509
MCC	0.8182
log_loss	0.4674
f1 score weighted	0.8522
f1 score macro	0.8643
f1 score micro	0.8509
roc_auc ovr	0.9773
roc_auc ovo	0.9810
precision	0.8566
recall	0.8509

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.865358205539025	0.8354565916745353	0.4323040254930906	0.866001918606061	0.8741081658926548	0.865358205539025	0.980964977273211	0.9842882727469048	0.8671407635149996	0.865358205539025
1	0.863294326342594	0.8323685430486228	0.45037596704492394	0.862274664441132	0.8734205519796578	0.8632943263425941	0.9809297753680051	0.9840367321212369	0.8626165913382603	0.863294326342594
2	0.8208062716374352	0.7805237652912733	0.5355558526017148	0.8203995910863977	0.8261716134835944	0.8208062716374352	0.969087072830889	0.9734931119491951	0.8212954233632205	0.8208062716374352
3	0.846041601098681	0.8110047641354873	0.48321024654550065	0.8453096257590397	0.8553232216529186	0.8460416010986809	0.9777574060846662	0.9808365879622605	0.8485767845749681	0.846041601098681
4	0.8508769420045206	0.8182336980708378	0.4674144379778266	0.8522487418164312	0.8642967737497566	0.8508769420045206	0.9772641432069599	0.9809706600350246	0.8565904896759783	0.8508769420045206
mean	0.8492754693244512	0.8155174724441512	0.4737721059326113	0.8492469083418122	0.8586640653517164	0.8492754693244511	0.9772006749527462	0.9807250729629244	0.8512440104934853	0.8492754693244512
std	0.015991876635540577	0.019666362217939	0.03525254828438489	0.016168696355111187	0.01763475096528786	0.015991876635540598	0.004340983276431449	0.0038996791609196076	0.016215172873246038	0.015991876635540577

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 50376.2407 secs

