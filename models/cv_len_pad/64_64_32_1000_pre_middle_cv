/home/amsequeira/enzymeClassification/models/cv_len_pad/64_64_32_1000_pre_middle_cv
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5550058250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5550058430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5550058460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5550058220>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 1, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.75      0.82      0.78      4541
         1.0       0.79      0.89      0.84      3813
         2.0       0.90      0.89      0.89     10869
         3.0       0.88      0.80      0.84      6897
         4.0       0.84      0.84      0.84      2585
         5.0       0.88      0.84      0.86      1617
         6.0       0.96      0.95      0.96      3258
         7.0       0.96      0.95      0.95      1372

    accuracy                           0.86     34952
   macro avg       0.87      0.87      0.87     34952
weighted avg       0.87      0.86      0.86     34952


===confusion_matrix===

[[3701  157  277  303   26   24   16   37]
 [  95 3387  146   85   69   14   11    6]
 [ 479  286 9640  230  131   45   55    3]
 [ 502  225  381 5532  145   69   34    9]
 [  49  129  113   84 2176   29    5    0]
 [  37   49   66   53   42 1360   10    0]
 [  10   42   68   17    3    8 3110    0]
 [  36   14    9    6    4    0    3 1300]]

===multilabel confusion matrix===

[[[29203  1208]
  [  840  3701]]

 [[30237   902]
  [  426  3387]]

 [[23023  1060]
  [ 1229  9640]]

 [[27277   778]
  [ 1365  5532]]

 [[31947   420]
  [  409  2176]]

 [[33146   189]
  [  257  1360]]

 [[31560   134]
  [  148  3110]]

 [[33525    55]
  [   72  1300]]]

===scores report===
metrics	scores
Accuracy	0.8642
MCC	0.8347
log_loss	0.4256
f1 score weighted	0.8647
f1 score macro	0.8700
f1 score micro	0.8642
roc_auc ovr	0.9813
roc_auc ovo	0.9840
precision	0.8669
recall	0.8642

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5550058250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5550058430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5550058460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5550058220>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.72      0.77      4541
         1.0       0.91      0.84      0.87      3813
         2.0       0.89      0.89      0.89     10869
         3.0       0.79      0.88      0.83      6897
         4.0       0.86      0.85      0.86      2585
         5.0       0.84      0.87      0.85      1616
         6.0       0.93      0.96      0.94      3258
         7.0       0.97      0.94      0.95      1372

    accuracy                           0.87     34951
   macro avg       0.88      0.87      0.87     34951
weighted avg       0.87      0.87      0.87     34951


===confusion_matrix===

[[3263   68  397  659   30   64   34   26]
 [  64 3211  164  226   75   32   36    5]
 [ 266  110 9725  490  102   72  102    2]
 [ 230   64  334 6077  100   42   41    9]
 [  43   49  108  132 2206   31   15    1]
 [  35   17   67   55   22 1398   22    0]
 [   9   11   61   36   12   17 3112    0]
 [  34    8   18   19    5    3    2 1283]]

===multilabel confusion matrix===

[[[29729   681]
  [ 1278  3263]]

 [[30811   327]
  [  602  3211]]

 [[22933  1149]
  [ 1144  9725]]

 [[26437  1617]
  [  820  6077]]

 [[32020   346]
  [  379  2206]]

 [[33074   261]
  [  218  1398]]

 [[31441   252]
  [  146  3112]]

 [[33536    43]
  [   89  1283]]]

===scores report===
metrics	scores
Accuracy	0.8662
MCC	0.8365
log_loss	0.4214
f1 score weighted	0.8657
f1 score macro	0.8717
f1 score micro	0.8662
roc_auc ovr	0.9817
roc_auc ovo	0.9844
precision	0.8676
recall	0.8662

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5550058250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5550058430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5550058460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5550058220>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.82      0.78      4542
         1.0       0.93      0.81      0.86      3814
         2.0       0.91      0.88      0.90     10869
         3.0       0.82      0.86      0.84      6896
         4.0       0.94      0.80      0.87      2584
         5.0       0.91      0.81      0.86      1616
         6.0       0.83      0.98      0.90      3258
         7.0       0.96      0.95      0.96      1372

    accuracy                           0.86     34951
   macro avg       0.88      0.86      0.87     34951
weighted avg       0.87      0.86      0.86     34951


===confusion_matrix===

[[3734   38  201  441   21   21   64   22]
 [ 184 3074  180  215   14   15  120   12]
 [ 530   63 9603  391   33   17  230    2]
 [ 414   39  329 5913   31   31  125   14]
 [  74   62  163  150 2074   38   23    0]
 [  55   20   69   74   21 1316   61    0]
 [  17    6   27   19    1    2 3186    0]
 [  25    7    9   13    0    0   12 1306]]

===multilabel confusion matrix===

[[[29110  1299]
  [  808  3734]]

 [[30902   235]
  [  740  3074]]

 [[23104   978]
  [ 1266  9603]]

 [[26752  1303]
  [  983  5913]]

 [[32246   121]
  [  510  2074]]

 [[33211   124]
  [  300  1316]]

 [[31058   635]
  [   72  3186]]

 [[33529    50]
  [   66  1306]]]

===scores report===
metrics	scores
Accuracy	0.8642
MCC	0.8345
log_loss	0.4344
f1 score weighted	0.8648
f1 score macro	0.8704
f1 score micro	0.8642
roc_auc ovr	0.9817
roc_auc ovo	0.9840
precision	0.8693
recall	0.8642

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5550058250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5550058430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5550058460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5550058220>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 1, 0, 0],
        [0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[0, 0, 1, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 1, 0]]], dtype=int8), 'y_test': array([2., 2., 1., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.84      0.67      0.75      4542
         1.0       0.81      0.85      0.83      3813
         2.0       0.91      0.86      0.88     10868
         3.0       0.80      0.85      0.82      6897
         4.0       0.59      0.92      0.71      2585
         5.0       0.92      0.76      0.83      1616
         6.0       0.99      0.90      0.94      3258
         7.0       0.94      0.94      0.94      1372

    accuracy                           0.84     34951
   macro avg       0.85      0.84      0.84     34951
weighted avg       0.85      0.84      0.84     34951


===confusion_matrix===

[[3060  187  307  696  228    9    3   52]
 [  52 3223  135  138  248    5    1   11]
 [ 262  211 9316  436  607   16   10   10]
 [ 170  162  279 5885  357   34    4    6]
 [  27   51   50   81 2366    9    0    1]
 [  36   29   39  106  174 1223    9    0]
 [  18  104  105   21   43   28 2939    0]
 [  27   16   14   15   15    0    0 1285]]

===multilabel confusion matrix===

[[[29817   592]
  [ 1482  3060]]

 [[30378   760]
  [  590  3223]]

 [[23154   929]
  [ 1552  9316]]

 [[26561  1493]
  [ 1012  5885]]

 [[30694  1672]
  [  219  2366]]

 [[33234   101]
  [  393  1223]]

 [[31666    27]
  [  319  2939]]

 [[33499    80]
  [   87  1285]]]

===scores report===
metrics	scores
Accuracy	0.8382
MCC	0.8046
log_loss	0.5072
f1 score weighted	0.8406
f1 score macro	0.8388
f1 score micro	0.8382
roc_auc ovr	0.9781
roc_auc ovo	0.9812
precision	0.8527
recall	0.8382

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5550058250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5550058430>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5550058460>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5550058220>, 'x_test': array([[[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 1, 0, ..., 0, 0, 0]],

       ...,

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 1]],

       [[1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        [1, 0, 0, ..., 0, 0, 0],
        ...,
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0],
        [0, 0, 0, ..., 0, 0, 0]]], dtype=int8), 'y_test': array([2., 2., 2., ..., 0., 0., 0.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.82      0.59      0.69      4542
         1.0       0.88      0.53      0.66      3813
         2.0       0.70      0.88      0.78     10868
         3.0       0.74      0.65      0.69      6897
         4.0       0.59      0.77      0.67      2585
         5.0       0.73      0.71      0.72      1616
         6.0       0.90      0.88      0.89      3258
         7.0       0.87      0.87      0.87      1372

    accuracy                           0.74     34951
   macro avg       0.78      0.74      0.75     34951
weighted avg       0.76      0.74      0.74     34951


===confusion_matrix===

[[2695   50  928  586  104   81   10   88]
 [  52 2028  870  311  355   76   93   28]
 [ 197   62 9565  383  453   72  106   30]
 [ 269   70 1566 4454  308  112   87   31]
 [  21   31  352  130 1984   55   11    1]
 [  21   26  174   88  131 1155   19    2]
 [  12   18  225   55   33   41 2874    0]
 [  33   12   81   36    6    0    8 1196]]

===multilabel confusion matrix===

[[[29804   605]
  [ 1847  2695]]

 [[30869   269]
  [ 1785  2028]]

 [[19887  4196]
  [ 1303  9565]]

 [[26465  1589]
  [ 2443  4454]]

 [[30976  1390]
  [  601  1984]]

 [[32898   437]
  [  461  1155]]

 [[31359   334]
  [  384  2874]]

 [[33399   180]
  [  176  1196]]]

===scores report===
metrics	scores
Accuracy	0.7425
MCC	0.6849
log_loss	0.7525
f1 score weighted	0.7387
f1 score macro	0.7452
f1 score micro	0.7425
roc_auc ovr	0.9474
roc_auc ovo	0.9551
precision	0.7587
recall	0.7425

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.8642137788967728	0.8346825009043476	0.42562871611449427	0.8647197990444403	0.8700201541629309	0.8642137788967728	0.9812612761814509	0.9840276860371787	0.8668963053785318	0.8642137788967728
1	0.8662126977768877	0.8365118511769817	0.42142010170672956	0.8657378472082657	0.8717305381448274	0.8662126977768877	0.9817007289624731	0.9844499895615185	0.867593750157706	0.8662126977768877
2	0.8642385053360419	0.8344877268246454	0.4344295822031318	0.8648163957918168	0.8704109710566887	0.8642385053360419	0.9817467295083606	0.9839649736690823	0.8693427358089755	0.8642385053360419
3	0.8382306657892478	0.8045625895211392	0.5072101672110912	0.8405840052954161	0.8388219691084247	0.8382306657892478	0.9781205471912715	0.9812297511885733	0.8526881376612775	0.8382306657892478
4	0.7424966381505537	0.6848981695778389	0.7525137048410526	0.7386872949490535	0.7452070402157049	0.7424966381505537	0.9473974722681715	0.9551189617055506	0.7586939917595742	0.7424966381505537
mean	0.8350784571899007	0.7990285676009906	0.5082404544153	0.8349090684577984	0.8392381345377155	0.8350784571899007	0.9740453508223454	0.9777582724323807	0.8430429841532131	0.8350784571899007
std	0.047433840138586265	0.05829223727396748	0.12608013338470736	0.04903952709987708	0.04861492498003595	0.047433840138586265	0.01339180558255865	0.011377146569037063	0.04259384811462017	0.047433840138586265

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 190057.4556 secs

