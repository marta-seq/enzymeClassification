/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff664402fa0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe3028a3850>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe3028a38e0>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff47e98bac0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff47e98b970>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff47e98b520>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff47e7736d0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff47e7737c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff47e773820>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff47e76be80>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7ff47e76bf70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff47e76bfd0>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fe22a0fe790>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fe22a0fe940>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fe22a0fe250>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9a6e559c40>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9a6e559c10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9a6e559e80>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9a6e559b20>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9a6d6919d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9a6d691af0>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9affaf9ee0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9aff57d4c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9aff57d1f0>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9a6c71a190>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9a6c701880>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f99dd40a970>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9aff57e3a0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9aff9a3a90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f9ab51ded00>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fae5fe2c850>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f9a6d071700>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f99dd8aa430>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9a242fcbb0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f99dd430760>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f99dd4301c0>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9a6d031f70>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f99de528af0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f99de5283d0>]/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f9a6cfc03d0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f99dd413c10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f99dd413610>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.4798087179660797)
('Validation Accuracy mean: ', 0.4842705249786377)
('Training Loss mean: ', 1.44292471408844)
('Validation Loss mean: ', 1.4471107959747314)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_7 (Masking)          (None, 500, 21)           0         
_________________________________________________________________
bidirectional_21 (Bidirectio (None, 500, 128)          44032     
_________________________________________________________________
bidirectional_22 (Bidirectio (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_23 (Bidirectio (None, 500, 64)           41216     
_________________________________________________________________
attention_5 (attention)      (None, 64)                564       
_________________________________________________________________
dense_6 (Dense)              (None, 32)                2080      
_________________________________________________________________
batch_normalization_4 (Batch (None, 32)                128       
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_7 (Dense)              (None, 16)                528       
_________________________________________________________________
batch_normalization_5 (Batch (None, 16)                64        
_________________________________________________________________
dropout_5 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 7)                 119       
=================================================================
Total params: 187,547
Trainable params: 187,451
Non-trainable params: 96
_________________________________________________________________Finished run_model in 609.1497 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f99dd4258e0>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.65      0.36      0.47      3813
           1       0.60      0.81      0.69     10869
           2       0.72      0.41      0.52      6897
           3       0.39      0.68      0.49      2585
           4       0.66      0.25      0.37      1616
           5       0.68      0.69      0.68      3258
           6       0.87      0.86      0.87      1372

    accuracy                           0.61     30410
   macro avg       0.65      0.58      0.58     30410
weighted avg       0.64      0.61      0.60     30410


===confusion_matrix===

[[1383 1475  181  555   33  157   29]
 [ 251 8757  492  915   42  346   66]
 [ 308 2514 2808  754   92  353   68]
 [  40  580  114 1752   23   71    5]
 [  52  533  154  353  410  114    0]
 [  74  646   91  177   24 2243    3]
 [  20   96   40   25    1    9 1181]]

===multilabel confusion matrix===

[[[25852   745]
  [ 2430  1383]]

 [[13697  5844]
  [ 2112  8757]]

 [[22441  1072]
  [ 4089  2808]]

 [[25046  2779]
  [  833  1752]]

 [[28579   215]
  [ 1206   410]]

 [[26102  1050]
  [ 1015  2243]]

 [[28867   171]
  [  191  1181]]]

===scores report===
metrics	scores
Accuracy	0.6095
MCC	0.4998
log_loss	1.0639
f1 score weighted	0.5961
f1 score macro	0.5835
f1 score micro	0.6095
roc_auc ovr	0.8670
roc_auc ovo	0.8865
precision	0.6401
recall	0.6095
/home/amsequeira/enzymeClassification/models/try_attenttry_attentions_context
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f5f60c74250>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f5f60c74280>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f5f60c74490>]
===TRAIN MODELS===

run_model
('Training Accuracy mean: ', 0.46945000290870664)
('Validation Accuracy mean: ', 0.4880412042140961)
('Training Loss mean: ', 1.4702526330947876)
('Validation Loss mean: ', 1.4138143062591553)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking (Masking)            (None, 500, 21)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 500, 128)          44032     
_________________________________________________________________
bidirectional_1 (Bidirection (None, 500, 128)          98816     
_________________________________________________________________
bidirectional_2 (Bidirection (None, 500, 64)           41216     
_________________________________________________________________
attention (attention)        (None, 64)                564       
_________________________________________________________________
dense (Dense)                (None, 32)                2080      
_________________________________________________________________
batch_normalization (BatchNo (None, 32)                128       
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                528       
_________________________________________________________________
batch_normalization_1 (Batch (None, 16)                64        
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 7)                 119       
=================================================================
Total params: 187,547
Trainable params: 187,451
Non-trainable params: 96
_________________________________________________________________Finished run_model in 608.5633 secs


===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f5f61bab6d0>, 'x_test': None, 'y_test': None, 'model': None}
report

              precision    recall  f1-score   support

           0       0.71      0.25      0.36      3813
           1       0.50      0.90      0.64     10869
           2       0.67      0.37      0.47      6897
           3       0.79      0.17      0.28      2585
           4       0.77      0.02      0.04      1616
           5       0.59      0.75      0.66      3258
           6       0.94      0.60      0.73      1372

    accuracy                           0.56     30410
   macro avg       0.71      0.44      0.46     30410
weighted avg       0.63      0.56      0.51     30410


===confusion_matrix===

[[ 938 2332  213   19    1  289   21]
 [ 105 9826  499   24    1  409    5]
 [ 129 3891 2540   28    4  284   21]
 [  82 1463  185  446    4  405    0]
 [  62  963  191   44   34  321    1]
 [   5  706  100    1    0 2446    0]
 [   9  436   77    5    0   22  823]]

===multilabel confusion matrix===

[[[26205   392]
  [ 2875   938]]

 [[ 9750  9791]
  [ 1043  9826]]

 [[22248  1265]
  [ 4357  2540]]

 [[27704   121]
  [ 2139   446]]

 [[28784    10]
  [ 1582    34]]

 [[25422  1730]
  [  812  2446]]

 [[28990    48]
  [  549   823]]]

===scores report===
metrics	scores
Accuracy	0.5608
MCC	0.4265
log_loss	1.2113
f1 score weighted	0.5136
f1 score macro	0.4571
f1 score micro	0.5608
roc_auc ovr	0.8431
roc_auc ovo	0.8555
precision	0.6322
recall	0.5608
