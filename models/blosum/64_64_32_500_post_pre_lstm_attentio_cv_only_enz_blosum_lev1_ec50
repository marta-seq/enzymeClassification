/home/amsequeira/enzymeClassification/models/blosum/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_blosum_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/blosum/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_blosum_lev1_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd1803e2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd1803e7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd1803e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd1803e670>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 1, -1,  1, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 1, -1,  1, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[ 0, -1,  0, ..., -2, -2,  0],
        [-2, -2, -2, ...,  2,  7, -1],
        [ 1, -1,  1, ..., -3, -2, -2],
        ...,
        [-1,  0,  0, ..., -3, -2, -2],
        [-2, -3, -3, ...,  1,  3, -1],
        [-2, -2,  1, ..., -4, -3, -3]],

       [[ 0, -3, -3, ..., -3, -1,  4],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  5,  0, ..., -3, -2, -3],
        [-2,  0,  6, ..., -4, -2, -3]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.83      0.71      0.77      1793
         1.0       0.77      0.88      0.82      4921
         2.0       0.77      0.77      0.77      3576
         3.0       0.74      0.59      0.66       943
         4.0       0.82      0.67      0.74       695
         5.0       0.87      0.80      0.84      1073
         6.0       0.93      0.88      0.91       471

    accuracy                           0.79     13472
   macro avg       0.82      0.76      0.78     13472
weighted avg       0.79      0.79      0.79     13472


===confusion_matrix===

[[1280  257  174   31   22   20    9]
 [  87 4327  378   59   26   39    5]
 [  90  587 2739   71   34   41   14]
 [  44  191  129  553   11   15    0]
 [  24   96   82   15  467   10    1]
 [  21  118   49   15    7  862    1]
 [   5   25   23    1    1    1  415]]

===multilabel confusion matrix===

[[[11408   271]
  [  513  1280]]

 [[ 7277  1274]
  [  594  4327]]

 [[ 9061   835]
  [  837  2739]]

 [[12337   192]
  [  390   553]]

 [[12676   101]
  [  228   467]]

 [[12273   126]
  [  211   862]]

 [[12971    30]
  [   56   415]]]

===scores report===
metrics	scores
Accuracy	0.7900
MCC	0.7215
log_loss	0.9549
f1 score weighted	0.7880
f1 score macro	0.7845
f1 score micro	0.7900
roc_auc ovr	0.9455
roc_auc ovo	0.9509
precision	0.7919
recall	0.7900

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd1803e2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd1803e7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd1803e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd1803e670>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [ 0, -1,  0, ..., -2, -2,  0],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  2,  0, ..., -3, -2, -2],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 0, -3, -3, ..., -3, -1,  4],
        [ 1, -1,  1, ..., -3, -2, -2],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1,  5,  0, ..., -3, -2, -3]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 0, -2,  0, ..., -2, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-2,  0,  6, ..., -4, -2, -3],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-1, -2, -3, ..., -2, -1,  1],
        [-2, -2, -2, ...,  2,  7, -1],
        [ 4, -1, -2, ..., -3, -2,  0]]], dtype=int8), 'y_test': array([1., 3., 0., ..., 6., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.71      0.74      1792
         1.0       0.77      0.87      0.82      4921
         2.0       0.78      0.75      0.76      3576
         3.0       0.74      0.62      0.68       943
         4.0       0.77      0.68      0.73       696
         5.0       0.91      0.80      0.85      1072
         6.0       0.93      0.88      0.90       471

    accuracy                           0.78     13471
   macro avg       0.81      0.76      0.78     13471
weighted avg       0.79      0.78      0.78     13471


===confusion_matrix===

[[1281  264  159   35   29   14   10]
 [ 133 4288  367   66   30   28    9]
 [ 114  622 2671   76   51   31   11]
 [  57  165  107  587   20    6    1]
 [  29   99   67   19  475    7    0]
 [  24  122   53   10    6  857    0]
 [  14   22   17    0    3    2  413]]

===multilabel confusion matrix===

[[[11308   371]
  [  511  1281]]

 [[ 7256  1294]
  [  633  4288]]

 [[ 9125   770]
  [  905  2671]]

 [[12322   206]
  [  356   587]]

 [[12636   139]
  [  221   475]]

 [[12311    88]
  [  215   857]]

 [[12969    31]
  [   58   413]]]

===scores report===
metrics	scores
Accuracy	0.7848
MCC	0.7150
log_loss	1.0284
f1 score weighted	0.7833
f1 score macro	0.7822
f1 score micro	0.7848
roc_auc ovr	0.9424
roc_auc ovo	0.9498
precision	0.7863
recall	0.7848

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd1803e2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd1803e7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd1803e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd1803e670>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -1,  0, ..., -2, -2,  0],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2,  0,  6, ..., -4, -2, -3],
        [-2,  0,  1, ..., -2,  2, -3],
        [-1, -2, -3, ..., -2, -1,  1]],

       [[ 0, -2,  0, ..., -2, -3, -3],
        [-1, -2, -2, ..., -4, -3, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2,  0,  1, ..., -2,  2, -3],
        [ 0, -1,  0, ..., -2, -2,  0],
        [-1, -2, -3, ..., -2, -1,  1]],

       [[-2, -3, -3, ...,  1,  3, -1],
        [ 0, -3, -3, ..., -2, -2, -1],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [-2,  0,  6, ..., -4, -2, -3],
        [-1,  0,  0, ..., -3, -2, -2],
        [-2,  0,  6, ..., -4, -2, -3]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.80      0.71      0.75      1792
         1.0       0.79      0.86      0.83      4921
         2.0       0.80      0.76      0.78      3576
         3.0       0.76      0.60      0.67       943
         4.0       0.62      0.74      0.68       695
         5.0       0.86      0.86      0.86      1072
         6.0       0.92      0.90      0.91       472

    accuracy                           0.79     13471
   macro avg       0.79      0.78      0.78     13471
weighted avg       0.79      0.79      0.79     13471


===confusion_matrix===

[[1272  247  147   40   57   23    6]
 [ 105 4252  368   63   61   62   10]
 [ 114  494 2729   58  115   48   18]
 [  36  175  100  566   59    6    1]
 [  30   80   46   14  515   10    0]
 [  21   85   26    4   17  919    0]
 [   6   25   11    3    0    2  425]]

===multilabel confusion matrix===

[[[11367   312]
  [  520  1272]]

 [[ 7444  1106]
  [  669  4252]]

 [[ 9197   698]
  [  847  2729]]

 [[12346   182]
  [  377   566]]

 [[12467   309]
  [  180   515]]

 [[12248   151]
  [  153   919]]

 [[12964    35]
  [   47   425]]]

===scores report===
metrics	scores
Accuracy	0.7927
MCC	0.7270
log_loss	0.9013
f1 score weighted	0.7914
f1 score macro	0.7826
f1 score micro	0.7927
roc_auc ovr	0.9464
roc_auc ovo	0.9528
precision	0.7940
recall	0.7927

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd1803e2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd1803e7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd1803e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd1803e670>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1, -1, -2, ..., -1, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 0, -2,  0, ..., -2, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1,  1,  0, ..., -2, -1, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -1,  0, ..., -2, -2,  0],
        [ 0, -3, -3, ..., -2, -2, -1],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [-2,  0,  6, ..., -4, -2, -3],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 0, -3, -3, ..., -3, -1,  4]],

       [[ 0, -3, -3, ..., -3, -1,  4],
        [-2, -2, -2, ...,  2,  7, -1],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [-2, -2, -2, ...,  2,  7, -1],
        [ 0, -3, -3, ..., -2, -2, -1]],

       [[-1,  0,  0, ..., -3, -2, -2],
        [ 0, -1,  0, ..., -2, -2,  0],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 1., 1., 2.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.74      0.74      0.74      1792
         1.0       0.78      0.87      0.82      4920
         2.0       0.78      0.73      0.76      3576
         3.0       0.78      0.60      0.68       944
         4.0       0.72      0.69      0.71       695
         5.0       0.86      0.83      0.85      1072
         6.0       0.91      0.86      0.89       472

    accuracy                           0.78     13471
   macro avg       0.80      0.76      0.78     13471
weighted avg       0.78      0.78      0.78     13471


===confusion_matrix===

[[1322  229  161   24   24   17   15]
 [ 163 4268  322   55   51   53    8]
 [ 154  638 2613   53   64   42   12]
 [  56  176   96  570   27   18    1]
 [  41   78   63   19  480   11    3]
 [  29   87   43    7   15  890    1]
 [  10   17   33    1    2    1  408]]

===multilabel confusion matrix===

[[[11226   453]
  [  470  1322]]

 [[ 7326  1225]
  [  652  4268]]

 [[ 9177   718]
  [  963  2613]]

 [[12368   159]
  [  374   570]]

 [[12593   183]
  [  215   480]]

 [[12257   142]
  [  182   890]]

 [[12959    40]
  [   64   408]]]

===scores report===
metrics	scores
Accuracy	0.7832
MCC	0.7138
log_loss	0.9143
f1 score weighted	0.7815
f1 score macro	0.7770
f1 score micro	0.7832
roc_auc ovr	0.9447
roc_auc ovo	0.9512
precision	0.7838
recall	0.7832

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fbd1803e2b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fbd1803e7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fbd1803e730>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fbd1803e670>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  2,  0, ..., -3, -2, -2],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [-1, -3, -3, ..., -3, -1,  3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -3, -3, ..., -3, -1,  4],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 4, -1, -2, ..., -3, -2,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1, -2, -2, ..., -4, -3, -2],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -2, -3, ..., -2, -1,  1],
        [-1, -2, -3, ..., -2, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 4, -1, -2, ..., -3, -2,  0]]], dtype=int8), 'y_test': array([1., 1., 1., ..., 2., 2., 6.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.78      0.73      0.75      1792
         1.0       0.80      0.84      0.82      4920
         2.0       0.76      0.77      0.77      3576
         3.0       0.64      0.66      0.65       944
         4.0       0.86      0.63      0.73       695
         5.0       0.91      0.83      0.87      1073
         6.0       0.90      0.89      0.89       471

    accuracy                           0.79     13471
   macro avg       0.81      0.76      0.78     13471
weighted avg       0.79      0.79      0.79     13471


===confusion_matrix===

[[1315  204  162   71   15   11   14]
 [ 150 4146  440  126   16   28   14]
 [ 108  527 2771  107   25   23   15]
 [  45  135  114  626   11   11    2]
 [  37   89   96   29  436    7    1]
 [  28   80   62   13    3  887    0]
 [   9   21   19    2    0    3  417]]

===multilabel confusion matrix===

[[[11302   377]
  [  477  1315]]

 [[ 7495  1056]
  [  774  4146]]

 [[ 9002   893]
  [  805  2771]]

 [[12179   348]
  [  318   626]]

 [[12706    70]
  [  259   436]]

 [[12315    83]
  [  186   887]]

 [[12954    46]
  [   54   417]]]

===scores report===
metrics	scores
Accuracy	0.7867
MCC	0.7183
log_loss	0.9361
f1 score weighted	0.7864
f1 score macro	0.7828
f1 score micro	0.7867
roc_auc ovr	0.9436
roc_auc ovo	0.9514
precision	0.7891
recall	0.7867

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.7900089073634204	0.7214750383818718	0.9548870949323158	0.7879983671555573	0.784499193096278	0.7900089073634204	0.9454641422008145	0.9509051150809831	0.7919178744106222	0.7900089073634204
1	0.7847969712716205	0.7150374950742799	1.0283582576999688	0.7833270283226118	0.782241758257295	0.7847969712716205	0.9424096381303948	0.949784487466936	0.7863068637848996	0.7847969712716205
2	0.7926657263751763	0.7269553035567266	0.9013030636647755	0.791442936101879	0.7825500556281499	0.7926657263751763	0.9463867706110072	0.952829485969421	0.7940480543515053	0.7926657263751763
3	0.783238066958652	0.7138433982629427	0.9142527970875061	0.7814754769036314	0.7769863016556345	0.783238066958652	0.9447109694157997	0.9511975891553494	0.7837773356284417	0.783238066958652
4	0.786727043278153	0.7183482371150088	0.9360876094096122	0.7864054231619165	0.7828063097084709	0.7867270432781529	0.9435544514918919	0.9514137544878539	0.7890562075133607	0.786727043278153
mean	0.7874873430494044	0.719131894478166	0.9469777645588356	0.7861298463291192	0.7818167236691657	0.7874873430494044	0.9445051943699816	0.9512260864321087	0.7890212671377659	0.7874873430494044
std	0.003436464572744872	0.004733761095023298	0.0446341560865364	0.003501861765676363	0.0025387528335212312	0.003436464572744877	0.0013998229485218535	0.0009785858832839845	0.003702079076728649	0.003436464572744872

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 15943.3654 secs

