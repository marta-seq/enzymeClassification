/home/amsequeira/enzymeClassification/models/blosum/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_blosum_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/blosum/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_blosum_lev3_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ac84905b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ac8490370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ac8490850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ac84903a0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1, -1, -2, ..., -1, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 0, -2,  0, ..., -2, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2, -2,  1, ..., -4, -3, -3],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[ 0, -1,  0, ..., -2, -2,  0],
        [-2, -2, -2, ...,  2,  7, -1],
        [ 1, -1,  1, ..., -3, -2, -2],
        ...,
        [-1,  0,  0, ..., -3, -2, -2],
        [-2, -3, -3, ...,  1,  3, -1],
        [-2, -2,  1, ..., -4, -3, -3]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1, -2, -2, ..., -4, -3, -2],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 78., 76., 88.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.73      0.71       358
         1.0       0.86      0.50      0.63        12
         2.0       0.64      0.37      0.47        19
         3.0       0.61      0.55      0.58        80
         4.0       0.29      0.28      0.28        54
         5.0       0.36      0.21      0.26        58
         6.0       0.29      0.27      0.28        45
         7.0       0.49      0.50      0.49        48
         8.0       0.00      0.00      0.00        11
         9.0       0.30      0.14      0.19        21
        10.0       0.33      0.13      0.19        15
        11.0       0.74      0.69      0.71        36
        12.0       0.70      0.58      0.64        12
        13.0       0.62      0.64      0.63        25
        14.0       0.54      0.37      0.44        19
        15.0       0.85      0.50      0.63        22
        16.0       0.72      0.57      0.63        23
        17.0       0.86      0.75      0.80       119
        18.0       0.44      0.44      0.44        18
        19.0       0.29      0.17      0.21        12
        20.0       0.38      0.46      0.41        90
        21.0       0.43      0.25      0.32        12
        22.0       0.82      0.72      0.77        25
        23.0       0.00      0.00      0.00        12
        24.0       0.38      0.23      0.29        22
        25.0       0.61      0.45      0.52        38
        26.0       0.83      0.59      0.69        17
        27.0       0.36      0.26      0.30        35
        28.0       0.00      0.00      0.00        11
        29.0       0.71      0.56      0.63        36
        30.0       0.64      0.84      0.73        32
        31.0       0.79      0.68      0.73        38
        32.0       0.79      0.82      0.80       747
        33.0       0.87      0.84      0.86        74
        34.0       0.81      0.93      0.87        59
        35.0       0.66      0.73      0.69        48
        36.0       0.69      0.66      0.67       502
        37.0       0.71      0.71      0.71       241
        38.0       0.67      0.61      0.63        33
        39.0       0.61      0.73      0.66       344
        40.0       0.64      0.60      0.62       191
        41.0       0.76      0.59      0.67        32
        42.0       0.65      0.72      0.68       384
        43.0       0.70      0.69      0.70       118
        44.0       0.74      0.73      0.74       436
        45.0       0.97      0.79      0.87        48
        46.0       0.82      0.85      0.84       402
        47.0       0.55      0.35      0.43        17
        48.0       0.81      0.62      0.70        42
        49.0       0.78      0.87      0.82        78
        50.0       0.85      0.85      0.85       172
        51.0       0.62      0.25      0.36        20
        52.0       0.62      0.72      0.66       499
        53.0       0.60      0.74      0.66       100
        54.0       0.50      0.18      0.27        11
        55.0       0.79      0.71      0.75       103
        56.0       0.64      0.39      0.48        18
        57.0       0.29      0.20      0.24        10
        58.0       0.82      0.82      0.82        34
        59.0       0.64      0.64      0.64       231
        60.0       0.78      0.66      0.71        58
        61.0       0.35      0.30      0.32        30
        62.0       0.63      0.46      0.53        48
        63.0       0.21      0.20      0.21        50
        64.0       0.77      0.68      0.72        34
        65.0       0.72      0.77      0.74       155
        66.0       0.00      0.00      0.00        14
        67.0       0.64      0.67      0.65       314
        68.0       0.17      0.17      0.17        63
        69.0       0.58      0.68      0.62       308
        70.0       0.38      0.51      0.44        68
        71.0       0.56      0.44      0.49        66
        72.0       0.14      0.07      0.10        14
        73.0       0.50      0.40      0.44        25
        74.0       0.00      0.00      0.00        18
        75.0       0.28      0.33      0.31        60
        76.0       0.72      0.62      0.67       205
        77.0       0.50      0.35      0.41        77
        78.0       0.79      0.76      0.78        59
        79.0       0.65      0.51      0.57       139
        80.0       0.86      0.57      0.69        42
        81.0       0.50      0.47      0.49       175
        82.0       0.48      0.26      0.33        43
        83.0       0.32      0.35      0.33        26
        84.0       0.40      0.43      0.42       106
        85.0       0.50      0.43      0.46        14
        86.0       0.61      0.73      0.66       242
        87.0       0.71      0.76      0.73       309
        88.0       0.56      0.67      0.61        58
        89.0       0.67      0.18      0.29        11
        90.0       0.47      0.56      0.51       187
        91.0       0.38      0.33      0.35        46
        92.0       0.18      0.15      0.16        40
        93.0       0.40      0.38      0.39        32
        94.0       0.61      0.69      0.65       289
        95.0       0.31      0.13      0.18        31
        96.0       0.76      0.68      0.71        74
        97.0       0.37      0.56      0.44        27
        98.0       0.69      0.65      0.67        37
        99.0       0.84      0.88      0.86        24
       100.0       0.13      0.08      0.10        25
       101.0       0.77      0.52      0.62        65
       102.0       0.80      0.73      0.76        22
       103.0       0.65      0.69      0.67        64
       104.0       0.44      0.30      0.36        40
       105.0       0.71      0.83      0.77        12
       106.0       0.86      0.78      0.82       114
       107.0       0.65      0.75      0.70       161
       108.0       0.36      0.17      0.23        24
       109.0       0.84      0.60      0.70        52
       110.0       0.69      0.73      0.71        15
       111.0       0.79      0.70      0.74       123
       112.0       0.53      0.43      0.47        42
       113.0       0.80      0.87      0.83       430
       114.0       0.74      0.71      0.72        65
       115.0       0.64      0.68      0.66        31
       116.0       0.72      0.75      0.73       173
       117.0       0.90      0.87      0.89        31
       118.0       0.80      0.80      0.80       117
       119.0       0.79      0.75      0.77       136
       120.0       0.78      0.65      0.71        62
       121.0       0.89      0.81      0.85       224
       122.0       0.73      0.69      0.71        35
       123.0       0.79      0.70      0.74        37
       124.0       0.75      0.77      0.76        31
       125.0       0.92      0.80      0.86        15
       126.0       0.88      0.67      0.76        21
       127.0       0.72      0.97      0.83        73

    accuracy                           0.67     12227
   macro avg       0.60      0.54      0.56     12227
weighted avg       0.67      0.67      0.66     12227


===confusion_matrix===

[[262   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0   7 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   1]
 [  0   0   0 ...   0  14   7]
 [  0   0   0 ...   0   0  71]]

===multilabel confusion matrix===

[[[11750   119]
  [   96   262]]

 [[12214     1]
  [    6     6]]

 [[12204     4]
  [   12     7]]

 [[12119    28]
  [   36    44]]

 [[12136    37]
  [   39    15]]

 [[12148    21]
  [   46    12]]

 [[12152    30]
  [   33    12]]

 [[12154    25]
  [   24    24]]

 [[12216     0]
  [   11     0]]

 [[12199     7]
  [   18     3]]

 [[12208     4]
  [   13     2]]

 [[12182     9]
  [   11    25]]

 [[12212     3]
  [    5     7]]

 [[12192    10]
  [    9    16]]

 [[12202     6]
  [   12     7]]

 [[12203     2]
  [   11    11]]

 [[12199     5]
  [   10    13]]

 [[12094    14]
  [   30    89]]

 [[12199    10]
  [   10     8]]

 [[12210     5]
  [   10     2]]

 [[12070    67]
  [   49    41]]

 [[12211     4]
  [    9     3]]

 [[12198     4]
  [    7    18]]

 [[12213     2]
  [   12     0]]

 [[12197     8]
  [   17     5]]

 [[12178    11]
  [   21    17]]

 [[12208     2]
  [    7    10]]

 [[12176    16]
  [   26     9]]

 [[12214     2]
  [   11     0]]

 [[12183     8]
  [   16    20]]

 [[12180    15]
  [    5    27]]

 [[12182     7]
  [   12    26]]

 [[11314   166]
  [  132   615]]

 [[12144     9]
  [   12    62]]

 [[12155    13]
  [    4    55]]

 [[12161    18]
  [   13    35]]

 [[11574   151]
  [  173   329]]

 [[11916    70]
  [   71   170]]

 [[12184    10]
  [   13    20]]

 [[11720   163]
  [   94   250]]

 [[11970    66]
  [   76   115]]

 [[12189     6]
  [   13    19]]

 [[11691   152]
  [  106   278]]

 [[12075    34]
  [   37    81]]

 [[11682   109]
  [  119   317]]

 [[12178     1]
  [   10    38]]

 [[11750    75]
  [   59   343]]

 [[12205     5]
  [   11     6]]

 [[12179     6]
  [   16    26]]

 [[12130    19]
  [   10    68]]

 [[12029    26]
  [   25   147]]

 [[12204     3]
  [   15     5]]

 [[11506   222]
  [  142   357]]

 [[12077    50]
  [   26    74]]

 [[12214     2]
  [    9     2]]

 [[12105    19]
  [   30    73]]

 [[12205     4]
  [   11     7]]

 [[12212     5]
  [    8     2]]

 [[12187     6]
  [    6    28]]

 [[11913    83]
  [   84   147]]

 [[12158    11]
  [   20    38]]

 [[12180    17]
  [   21     9]]

 [[12166    13]
  [   26    22]]

 [[12140    37]
  [   40    10]]

 [[12186     7]
  [   11    23]]

 [[12025    47]
  [   36   119]]

 [[12212     1]
  [   14     0]]

 [[11796   117]
  [  105   209]]

 [[12110    54]
  [   52    11]]

 [[11767   152]
  [  100   208]]

 [[12102    57]
  [   33    35]]

 [[12138    23]
  [   37    29]]

 [[12207     6]
  [   13     1]]

 [[12192    10]
  [   15    10]]

 [[12203     6]
  [   18     0]]

 [[12116    51]
  [   40    20]]

 [[11973    49]
  [   78   127]]

 [[12123    27]
  [   50    27]]

 [[12156    12]
  [   14    45]]

 [[12050    38]
  [   68    71]]

 [[12181     4]
  [   18    24]]

 [[11969    83]
  [   92    83]]

 [[12172    12]
  [   32    11]]

 [[12182    19]
  [   17     9]]

 [[12052    69]
  [   60    46]]

 [[12207     6]
  [    8     6]]

 [[11870   115]
  [   65   177]]

 [[11820    98]
  [   73   236]]

 [[12138    31]
  [   19    39]]

 [[12215     1]
  [    9     2]]

 [[11922   118]
  [   82   105]]

 [[12157    24]
  [   31    15]]

 [[12159    28]
  [   34     6]]

 [[12177    18]
  [   20    12]]

 [[11811   127]
  [   89   200]]

 [[12187     9]
  [   27     4]]

 [[12137    16]
  [   24    50]]

 [[12174    26]
  [   12    15]]

 [[12179    11]
  [   13    24]]

 [[12199     4]
  [    3    21]]

 [[12189    13]
  [   23     2]]

 [[12152    10]
  [   31    34]]

 [[12201     4]
  [    6    16]]

 [[12139    24]
  [   20    44]]

 [[12172    15]
  [   28    12]]

 [[12211     4]
  [    2    10]]

 [[12098    15]
  [   25    89]]

 [[12000    66]
  [   40   121]]

 [[12196     7]
  [   20     4]]

 [[12169     6]
  [   21    31]]

 [[12207     5]
  [    4    11]]

 [[12081    23]
  [   37    86]]

 [[12169    16]
  [   24    18]]

 [[11705    92]
  [   56   374]]

 [[12146    16]
  [   19    46]]

 [[12184    12]
  [   10    21]]

 [[12003    51]
  [   43   130]]

 [[12193     3]
  [    4    27]]

 [[12086    24]
  [   23    94]]

 [[12064    27]
  [   34   102]]

 [[12154    11]
  [   22    40]]

 [[11980    23]
  [   43   181]]

 [[12183     9]
  [   11    24]]

 [[12183     7]
  [   11    26]]

 [[12188     8]
  [    7    24]]

 [[12211     1]
  [    3    12]]

 [[12204     2]
  [    7    14]]

 [[12127    27]
  [    2    71]]]

===scores report===
metrics	scores
Accuracy	0.6684
MCC	0.6611
log_loss	1.8239
f1 score weighted	0.6632
f1 score macro	0.5574
f1 score micro	0.6684
roc_auc ovr	0.9694
roc_auc ovo	0.9647
precision	0.6656
recall	0.6684

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ac84905b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ac8490370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ac8490850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ac84903a0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 0, -2,  0, ..., -2, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 0, -3, -3, ..., -3, -1,  4],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1,  2,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 1, -1,  1, ..., -3, -2, -2],
        [-2,  0,  1, ..., -2,  2, -3],
        [ 0, -3, -3, ..., -3, -1,  4]]], dtype=int8), 'y_test': array([42., 21., 21., ..., 36., 37., 32.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.66      0.81      0.73       357
         1.0       0.50      0.25      0.33        12
         2.0       0.80      0.63      0.71        19
         3.0       0.63      0.42      0.51        80
         4.0       0.43      0.28      0.34        54
         5.0       0.17      0.12      0.14        58
         6.0       0.27      0.27      0.27        44
         7.0       0.52      0.54      0.53        48
         8.0       0.00      0.00      0.00        11
         9.0       0.50      0.43      0.46        21
        10.0       0.25      0.07      0.11        15
        11.0       0.79      0.72      0.75        36
        12.0       0.00      0.00      0.00        12
        13.0       0.67      0.64      0.65        25
        14.0       0.44      0.20      0.28        20
        15.0       0.79      0.65      0.71        23
        16.0       0.50      0.65      0.57        23
        17.0       0.88      0.77      0.83       119
        18.0       0.71      0.59      0.65        17
        19.0       0.20      0.08      0.11        13
        20.0       0.64      0.43      0.52        90
        21.0       0.33      0.17      0.22        12
        22.0       0.70      0.64      0.67        25
        23.0       0.50      0.08      0.14        12
        24.0       0.67      0.36      0.47        22
        25.0       0.53      0.51      0.52        37
        26.0       0.94      0.94      0.94        18
        27.0       0.25      0.14      0.18        35
        28.0       0.38      0.25      0.30        12
        29.0       0.68      0.57      0.62        37
        30.0       0.59      0.53      0.56        32
        31.0       0.66      0.64      0.65        39
        32.0       0.70      0.81      0.75       746
        33.0       0.88      0.89      0.89        74
        34.0       0.74      0.78      0.76        58
        35.0       0.67      0.67      0.67        48
        36.0       0.63      0.67      0.65       502
        37.0       0.62      0.75      0.68       241
        38.0       0.58      0.45      0.51        33
        39.0       0.61      0.68      0.64       344
        40.0       0.76      0.69      0.73       191
        41.0       0.73      0.52      0.60        31
        42.0       0.69      0.71      0.70       384
        43.0       0.81      0.75      0.78       118
        44.0       0.70      0.74      0.72       436
        45.0       0.81      0.79      0.80        48
        46.0       0.82      0.84      0.83       402
        47.0       0.82      0.53      0.64        17
        48.0       0.76      0.45      0.57        42
        49.0       0.83      0.94      0.88        77
        50.0       0.83      0.81      0.82       172
        51.0       0.76      0.80      0.78        20
        52.0       0.63      0.70      0.66       499
        53.0       0.64      0.66      0.65        99
        54.0       0.75      0.27      0.40        11
        55.0       0.71      0.74      0.72       103
        56.0       0.44      0.39      0.41        18
        57.0       0.50      0.09      0.15        11
        58.0       0.82      0.91      0.86        34
        59.0       0.53      0.61      0.57       231
        60.0       0.77      0.71      0.74        58
        61.0       0.23      0.10      0.14        30
        62.0       0.35      0.29      0.32        48
        63.0       0.16      0.12      0.14        49
        64.0       0.75      0.62      0.68        34
        65.0       0.67      0.75      0.71       154
        66.0       0.00      0.00      0.00        14
        67.0       0.65      0.63      0.64       314
        68.0       0.14      0.13      0.13        63
        69.0       0.52      0.61      0.56       308
        70.0       0.55      0.48      0.51        69
        71.0       0.40      0.35      0.37        66
        72.0       0.12      0.07      0.09        14
        73.0       0.59      0.52      0.55        25
        74.0       0.17      0.06      0.08        18
        75.0       0.39      0.31      0.34        59
        76.0       0.69      0.63      0.66       205
        77.0       0.44      0.32      0.37        77
        78.0       0.70      0.63      0.66        59
        79.0       0.51      0.55      0.53       139
        80.0       0.65      0.63      0.64        41
        81.0       0.48      0.46      0.47       175
        82.0       0.74      0.47      0.57        43
        83.0       0.76      0.50      0.60        26
        84.0       0.54      0.52      0.53       105
        85.0       0.89      0.57      0.70        14
        86.0       0.67      0.65      0.66       242
        87.0       0.69      0.75      0.72       309
        88.0       0.77      0.62      0.69        58
        89.0       1.00      0.27      0.43        11
        90.0       0.58      0.57      0.57       187
        91.0       0.48      0.33      0.39        46
        92.0       0.44      0.17      0.25        40
        93.0       0.46      0.36      0.41        33
        94.0       0.57      0.62      0.59       289
        95.0       0.48      0.34      0.40        32
        96.0       0.65      0.61      0.63        74
        97.0       0.43      0.44      0.44        27
        98.0       0.65      0.54      0.59        37
        99.0       0.94      0.67      0.78        24
       100.0       0.22      0.08      0.11        26
       101.0       0.56      0.45      0.50        65
       102.0       0.81      0.59      0.68        22
       103.0       0.67      0.64      0.66        64
       104.0       0.17      0.12      0.14        40
       105.0       0.69      0.85      0.76        13
       106.0       0.69      0.72      0.70       113
       107.0       0.75      0.78      0.77       162
       108.0       0.38      0.12      0.19        24
       109.0       0.67      0.77      0.71        52
       110.0       0.92      0.80      0.86        15
       111.0       0.62      0.69      0.66       123
       112.0       0.50      0.54      0.52        41
       113.0       0.80      0.92      0.86       430
       114.0       0.76      0.80      0.78        65
       115.0       0.69      0.58      0.63        31
       116.0       0.79      0.75      0.77       173
       117.0       0.89      0.57      0.69        30
       118.0       0.79      0.85      0.82       118
       119.0       0.77      0.76      0.77       136
       120.0       0.83      0.79      0.81        61
       121.0       0.82      0.84      0.83       225
       122.0       1.00      0.94      0.97        35
       123.0       0.84      0.71      0.77        38
       124.0       0.64      0.74      0.69        31
       125.0       0.92      0.75      0.83        16
       126.0       0.75      0.71      0.73        21
       127.0       0.75      0.82      0.78        73

    accuracy                           0.66     12227
   macro avg       0.61      0.54      0.56     12227
weighted avg       0.65      0.66      0.65     12227


===confusion_matrix===

[[289   0   0 ...   0   0   0]
 [  1   3   0 ...   0   0   0]
 [  1   0  12 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   1]
 [  0   0   0 ...   0  15   3]
 [  0   0   0 ...   0   4  60]]

===multilabel confusion matrix===

[[[11722   148]
  [   68   289]]

 [[12212     3]
  [    9     3]]

 [[12205     3]
  [    7    12]]

 [[12127    20]
  [   46    34]]

 [[12153    20]
  [   39    15]]

 [[12134    35]
  [   51     7]]

 [[12150    33]
  [   32    12]]

 [[12155    24]
  [   22    26]]

 [[12215     1]
  [   11     0]]

 [[12197     9]
  [   12     9]]

 [[12209     3]
  [   14     1]]

 [[12184     7]
  [   10    26]]

 [[12213     2]
  [   12     0]]

 [[12194     8]
  [    9    16]]

 [[12202     5]
  [   16     4]]

 [[12200     4]
  [    8    15]]

 [[12189    15]
  [    8    15]]

 [[12096    12]
  [   27    92]]

 [[12206     4]
  [    7    10]]

 [[12210     4]
  [   12     1]]

 [[12115    22]
  [   51    39]]

 [[12211     4]
  [   10     2]]

 [[12195     7]
  [    9    16]]

 [[12214     1]
  [   11     1]]

 [[12201     4]
  [   14     8]]

 [[12173    17]
  [   18    19]]

 [[12208     1]
  [    1    17]]

 [[12177    15]
  [   30     5]]

 [[12210     5]
  [    9     3]]

 [[12180    10]
  [   16    21]]

 [[12183    12]
  [   15    17]]

 [[12175    13]
  [   14    25]]

 [[11225   256]
  [  142   604]]

 [[12144     9]
  [    8    66]]

 [[12153    16]
  [   13    45]]

 [[12163    16]
  [   16    32]]

 [[11532   193]
  [  167   335]]

 [[11875   111]
  [   61   180]]

 [[12183    11]
  [   18    15]]

 [[11731   152]
  [  111   233]]

 [[11995    41]
  [   59   132]]

 [[12190     6]
  [   15    16]]

 [[11722   121]
  [  110   274]]

 [[12089    20]
  [   30    88]]

 [[11651   140]
  [  112   324]]

 [[12170     9]
  [   10    38]]

 [[11749    76]
  [   64   338]]

 [[12208     2]
  [    8     9]]

 [[12179     6]
  [   23    19]]

 [[12135    15]
  [    5    72]]

 [[12027    28]
  [   32   140]]

 [[12202     5]
  [    4    16]]

 [[11521   207]
  [  149   350]]

 [[12091    37]
  [   34    65]]

 [[12215     1]
  [    8     3]]

 [[12093    31]
  [   27    76]]

 [[12200     9]
  [   11     7]]

 [[12215     1]
  [   10     1]]

 [[12186     7]
  [    3    31]]

 [[11871   125]
  [   89   142]]

 [[12157    12]
  [   17    41]]

 [[12187    10]
  [   27     3]]

 [[12153    26]
  [   34    14]]

 [[12146    32]
  [   43     6]]

 [[12186     7]
  [   13    21]]

 [[12017    56]
  [   39   115]]

 [[12212     1]
  [   14     0]]

 [[11806   107]
  [  116   198]]

 [[12115    49]
  [   55     8]]

 [[11743   176]
  [  120   188]]

 [[12131    27]
  [   36    33]]

 [[12127    34]
  [   43    23]]

 [[12206     7]
  [   13     1]]

 [[12193     9]
  [   12    13]]

 [[12204     5]
  [   17     1]]

 [[12140    28]
  [   41    18]]

 [[11964    58]
  [   76   129]]

 [[12118    32]
  [   52    25]]

 [[12152    16]
  [   22    37]]

 [[12016    72]
  [   63    76]]

 [[12172    14]
  [   15    26]]

 [[11967    85]
  [   95    80]]

 [[12177     7]
  [   23    20]]

 [[12197     4]
  [   13    13]]

 [[12075    47]
  [   50    55]]

 [[12212     1]
  [    6     8]]

 [[11907    78]
  [   85   157]]

 [[11814   104]
  [   77   232]]

 [[12158    11]
  [   22    36]]

 [[12216     0]
  [    8     3]]

 [[11964    76]
  [   81   106]]

 [[12165    16]
  [   31    15]]

 [[12178     9]
  [   33     7]]

 [[12180    14]
  [   21    12]]

 [[11801   137]
  [  111   178]]

 [[12183    12]
  [   21    11]]

 [[12129    24]
  [   29    45]]

 [[12184    16]
  [   15    12]]

 [[12179    11]
  [   17    20]]

 [[12202     1]
  [    8    16]]

 [[12194     7]
  [   24     2]]

 [[12139    23]
  [   36    29]]

 [[12202     3]
  [    9    13]]

 [[12143    20]
  [   23    41]]

 [[12163    24]
  [   35     5]]

 [[12209     5]
  [    2    11]]

 [[12077    37]
  [   32    81]]

 [[12023    42]
  [   35   127]]

 [[12198     5]
  [   21     3]]

 [[12155    20]
  [   12    40]]

 [[12211     1]
  [    3    12]]

 [[12053    51]
  [   38    85]]

 [[12164    22]
  [   19    22]]

 [[11700    97]
  [   35   395]]

 [[12146    16]
  [   13    52]]

 [[12188     8]
  [   13    18]]

 [[12020    34]
  [   43   130]]

 [[12195     2]
  [   13    17]]

 [[12083    26]
  [   18   100]]

 [[12061    30]
  [   33   103]]

 [[12156    10]
  [   13    48]]

 [[11960    42]
  [   37   188]]

 [[12192     0]
  [    2    33]]

 [[12184     5]
  [   11    27]]

 [[12183    13]
  [    8    23]]

 [[12210     1]
  [    4    12]]

 [[12201     5]
  [    6    15]]

 [[12134    20]
  [   13    60]]]

===scores report===
metrics	scores
Accuracy	0.6629
MCC	0.6552
log_loss	1.7761
f1 score weighted	0.6546
f1 score macro	0.5589
f1 score micro	0.6629
roc_auc ovr	0.9698
roc_auc ovo	0.9648
precision	0.6549
recall	0.6629

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ac84905b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ac8490370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ac8490850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ac84903a0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1,  1,  0, ..., -2, -1, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 1, -1,  1, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 1, -1,  1, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1,  0,  0, ..., -3, -2, -2],
        [ 0, -1,  0, ..., -2, -2,  0],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]]], dtype=int8), 'y_test': array([42., 42., 42., ..., 88., 87., 37.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.72      0.77      0.74       357
         1.0       0.45      0.38      0.42        13
         2.0       0.38      0.26      0.31        19
         3.0       0.55      0.46      0.50        79
         4.0       0.31      0.29      0.30        55
         5.0       0.21      0.19      0.20        59
         6.0       0.18      0.11      0.14        44
         7.0       0.52      0.52      0.52        48
         8.0       0.00      0.00      0.00        10
         9.0       0.57      0.38      0.46        21
        10.0       0.50      0.27      0.35        15
        11.0       0.74      0.64      0.69        36
        12.0       1.00      0.58      0.74        12
        13.0       0.79      0.60      0.68        25
        14.0       0.27      0.15      0.19        20
        15.0       0.69      0.50      0.58        22
        16.0       0.70      0.70      0.70        23
        17.0       0.73      0.76      0.74       118
        18.0       0.40      0.44      0.42        18
        19.0       0.22      0.15      0.18        13
        20.0       0.44      0.40      0.42        89
        21.0       0.67      0.17      0.27        12
        22.0       0.71      0.71      0.71        24
        23.0       0.20      0.17      0.18        12
        24.0       0.14      0.09      0.11        23
        25.0       0.43      0.32      0.37        37
        26.0       0.88      0.88      0.88        17
        27.0       0.33      0.17      0.22        36
        28.0       0.50      0.17      0.25        12
        29.0       0.62      0.68      0.65        37
        30.0       0.67      0.56      0.61        32
        31.0       0.88      0.77      0.82        39
        32.0       0.74      0.84      0.78       746
        33.0       0.83      0.81      0.82        74
        34.0       0.81      0.72      0.76        58
        35.0       0.62      0.54      0.58        48
        36.0       0.59      0.63      0.61       502
        37.0       0.66      0.67      0.67       240
        38.0       0.57      0.52      0.54        33
        39.0       0.56      0.72      0.63       344
        40.0       0.76      0.73      0.74       191
        41.0       0.54      0.45      0.49        31
        42.0       0.76      0.70      0.73       384
        43.0       0.69      0.79      0.74       117
        44.0       0.72      0.71      0.71       436
        45.0       0.79      0.69      0.74        49
        46.0       0.82      0.83      0.83       402
        47.0       0.64      0.53      0.58        17
        48.0       0.82      0.55      0.66        42
        49.0       0.91      0.87      0.89        77
        50.0       0.90      0.90      0.90       172
        51.0       0.38      0.26      0.31        19
        52.0       0.63      0.65      0.64       499
        53.0       0.69      0.75      0.71        99
        54.0       0.50      0.09      0.15        11
        55.0       0.71      0.70      0.70       103
        56.0       0.50      0.39      0.44        18
        57.0       0.40      0.18      0.25        11
        58.0       0.83      0.86      0.85        35
        59.0       0.53      0.56      0.54       231
        60.0       0.81      0.81      0.81        57
        61.0       0.23      0.21      0.22        29
        62.0       0.55      0.44      0.49        48
        63.0       0.29      0.24      0.26        49
        64.0       0.64      0.53      0.58        34
        65.0       0.65      0.68      0.66       155
        66.0       0.60      0.21      0.32        14
        67.0       0.62      0.65      0.63       315
        68.0       0.30      0.22      0.26        63
        69.0       0.52      0.66      0.58       307
        70.0       0.48      0.36      0.41        69
        71.0       0.62      0.45      0.53        66
        72.0       0.14      0.13      0.14        15
        73.0       0.42      0.32      0.36        25
        74.0       0.00      0.00      0.00        18
        75.0       0.45      0.41      0.43        59
        76.0       0.60      0.61      0.61       206
        77.0       0.44      0.41      0.42        76
        78.0       0.62      0.59      0.61        59
        79.0       0.54      0.43      0.48       140
        80.0       0.76      0.60      0.67        42
        81.0       0.40      0.38      0.39       175
        82.0       0.45      0.40      0.42        43
        83.0       0.67      0.24      0.35        25
        84.0       0.47      0.44      0.46       105
        85.0       0.70      0.50      0.58        14
        86.0       0.67      0.71      0.69       242
        87.0       0.67      0.74      0.70       310
        88.0       0.78      0.54      0.64        59
        89.0       0.33      0.18      0.24        11
        90.0       0.50      0.57      0.53       187
        91.0       0.37      0.33      0.34        46
        92.0       0.21      0.17      0.19        40
        93.0       0.46      0.33      0.39        33
        94.0       0.59      0.66      0.62       289
        95.0       0.27      0.12      0.17        32
        96.0       0.62      0.69      0.65        75
        97.0       0.40      0.36      0.38        28
        98.0       0.74      0.54      0.62        37
        99.0       0.82      0.78      0.80        23
       100.0       0.08      0.04      0.05        25
       101.0       0.65      0.53      0.58        66
       102.0       0.71      0.71      0.71        21
       103.0       0.62      0.71      0.66        65
       104.0       0.44      0.28      0.34        40
       105.0       0.73      0.67      0.70        12
       106.0       0.74      0.73      0.74       113
       107.0       0.76      0.75      0.75       162
       108.0       0.39      0.29      0.33        24
       109.0       0.72      0.77      0.75        53
       110.0       0.45      0.36      0.40        14
       111.0       0.63      0.59      0.61       123
       112.0       0.59      0.46      0.52        41
       113.0       0.84      0.87      0.86       429
       114.0       0.71      0.71      0.71        65
       115.0       0.85      0.55      0.67        31
       116.0       0.72      0.78      0.75       173
       117.0       0.88      0.77      0.82        30
       118.0       0.83      0.85      0.84       117
       119.0       0.78      0.82      0.80       136
       120.0       0.62      0.70      0.66        61
       121.0       0.79      0.90      0.84       225
       122.0       0.85      0.66      0.74        35
       123.0       0.84      0.71      0.77        38
       124.0       0.88      0.77      0.82        30
       125.0       0.92      0.75      0.83        16
       126.0       0.64      0.73      0.68        22
       127.0       0.72      0.85      0.78        73

    accuracy                           0.65     12226
   macro avg       0.59      0.52      0.54     12226
weighted avg       0.65      0.65      0.65     12226


===confusion_matrix===

[[274   0   0 ...   0   0   0]
 [  1   5   1 ...   0   0   0]
 [  0   0   5 ...   0   0   0]
 ...
 [  0   0   0 ...  12   2   2]
 [  0   0   0 ...   0  16   5]
 [  0   0   0 ...   0   4  62]]

===multilabel confusion matrix===

[[[11761   108]
  [   83   274]]

 [[12207     6]
  [    8     5]]

 [[12199     8]
  [   14     5]]

 [[12118    29]
  [   43    36]]

 [[12136    35]
  [   39    16]]

 [[12125    42]
  [   48    11]]

 [[12159    23]
  [   39     5]]

 [[12155    23]
  [   23    25]]

 [[12214     2]
  [   10     0]]

 [[12199     6]
  [   13     8]]

 [[12207     4]
  [   11     4]]

 [[12182     8]
  [   13    23]]

 [[12214     0]
  [    5     7]]

 [[12197     4]
  [   10    15]]

 [[12198     8]
  [   17     3]]

 [[12199     5]
  [   11    11]]

 [[12196     7]
  [    7    16]]

 [[12074    34]
  [   28    90]]

 [[12196    12]
  [   10     8]]

 [[12206     7]
  [   11     2]]

 [[12091    46]
  [   53    36]]

 [[12213     1]
  [   10     2]]

 [[12195     7]
  [    7    17]]

 [[12206     8]
  [   10     2]]

 [[12191    12]
  [   21     2]]

 [[12173    16]
  [   25    12]]

 [[12207     2]
  [    2    15]]

 [[12178    12]
  [   30     6]]

 [[12212     2]
  [   10     2]]

 [[12174    15]
  [   12    25]]

 [[12185     9]
  [   14    18]]

 [[12183     4]
  [    9    30]]

 [[11256   224]
  [  120   626]]

 [[12140    12]
  [   14    60]]

 [[12158    10]
  [   16    42]]

 [[12162    16]
  [   22    26]]

 [[11504   220]
  [  184   318]]

 [[11903    83]
  [   79   161]]

 [[12180    13]
  [   16    17]]

 [[11687   195]
  [   98   246]]

 [[11990    45]
  [   52   139]]

 [[12183    12]
  [   17    14]]

 [[11757    85]
  [  116   268]]

 [[12068    41]
  [   24    93]]

 [[11669   121]
  [  128   308]]

 [[12168     9]
  [   15    34]]

 [[11753    71]
  [   68   334]]

 [[12204     5]
  [    8     9]]

 [[12179     5]
  [   19    23]]

 [[12142     7]
  [   10    67]]

 [[12037    17]
  [   17   155]]

 [[12199     8]
  [   14     5]]

 [[11536   191]
  [  173   326]]

 [[12093    34]
  [   25    74]]

 [[12214     1]
  [   10     1]]

 [[12093    30]
  [   31    72]]

 [[12201     7]
  [   11     7]]

 [[12212     3]
  [    9     2]]

 [[12185     6]
  [    5    30]]

 [[11880   115]
  [  102   129]]

 [[12158    11]
  [   11    46]]

 [[12177    20]
  [   23     6]]

 [[12161    17]
  [   27    21]]

 [[12147    30]
  [   37    12]]

 [[12182    10]
  [   16    18]]

 [[12014    57]
  [   50   105]]

 [[12210     2]
  [   11     3]]

 [[11786   125]
  [  111   204]]

 [[12131    32]
  [   49    14]]

 [[11728   191]
  [  104   203]]

 [[12130    27]
  [   44    25]]

 [[12142    18]
  [   36    30]]

 [[12199    12]
  [   13     2]]

 [[12190    11]
  [   17     8]]

 [[12197    11]
  [   18     0]]

 [[12138    29]
  [   35    24]]

 [[11936    84]
  [   80   126]]

 [[12111    39]
  [   45    31]]

 [[12146    21]
  [   24    35]]

 [[12034    52]
  [   80    60]]

 [[12176     8]
  [   17    25]]

 [[11954    97]
  [  109    66]]

 [[12162    21]
  [   26    17]]

 [[12198     3]
  [   19     6]]

 [[12070    51]
  [   59    46]]

 [[12209     3]
  [    7     7]]

 [[11898    86]
  [   69   173]]

 [[11806   110]
  [   82   228]]

 [[12158     9]
  [   27    32]]

 [[12211     4]
  [    9     2]]

 [[11931   108]
  [   81   106]]

 [[12154    26]
  [   31    15]]

 [[12159    27]
  [   33     7]]

 [[12180    13]
  [   22    11]]

 [[11805   132]
  [   98   191]]

 [[12183    11]
  [   28     4]]

 [[12119    32]
  [   23    52]]

 [[12183    15]
  [   18    10]]

 [[12182     7]
  [   17    20]]

 [[12199     4]
  [    5    18]]

 [[12190    11]
  [   24     1]]

 [[12141    19]
  [   31    35]]

 [[12199     6]
  [    6    15]]

 [[12133    28]
  [   19    46]]

 [[12172    14]
  [   29    11]]

 [[12211     3]
  [    4     8]]

 [[12084    29]
  [   30    83]]

 [[12026    38]
  [   41   121]]

 [[12191    11]
  [   17     7]]

 [[12157    16]
  [   12    41]]

 [[12206     6]
  [    9     5]]

 [[12061    42]
  [   51    72]]

 [[12172    13]
  [   22    19]]

 [[11726    71]
  [   54   375]]

 [[12142    19]
  [   19    46]]

 [[12192     3]
  [   14    17]]

 [[12001    52]
  [   38   135]]

 [[12193     3]
  [    7    23]]

 [[12088    21]
  [   17   100]]

 [[12059    31]
  [   24   112]]

 [[12139    26]
  [   18    43]]

 [[11946    55]
  [   23   202]]

 [[12187     4]
  [   12    23]]

 [[12183     5]
  [   11    27]]

 [[12193     3]
  [    7    23]]

 [[12209     1]
  [    4    12]]

 [[12195     9]
  [    6    16]]

 [[12129    24]
  [   11    62]]]

===scores report===
metrics	scores
Accuracy	0.6548
MCC	0.6471
log_loss	1.9266
f1 score weighted	0.6483
f1 score macro	0.5444
f1 score micro	0.6548
roc_auc ovr	0.9672
roc_auc ovo	0.9625
precision	0.6488
recall	0.6548

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ac84905b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ac8490370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ac8490850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ac84903a0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [-1, -3, -3, ..., -3, -1,  3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -1,  0, ..., -2, -2,  0],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2,  0,  6, ..., -4, -2, -3],
        [-2,  0,  1, ..., -2,  2, -3],
        [-1, -2, -3, ..., -2, -1,  1]],

       [[ 0, -3, -3, ..., -3, -1,  4],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  5,  0, ..., -3, -2, -3],
        [-2,  0,  6, ..., -4, -2, -3]],

       [[ 0, -2,  0, ..., -2, -3, -3],
        [-1, -2, -2, ..., -4, -3, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2,  0,  1, ..., -2,  2, -3],
        [ 0, -1,  0, ..., -2, -2,  0],
        [-1, -2, -3, ..., -2, -1,  1]]], dtype=int8), 'y_test': array([42., 42., 21., ..., 32., 70., 87.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.70      0.76      0.73       358
         1.0       0.25      0.17      0.20        12
         2.0       0.55      0.33      0.41        18
         3.0       0.55      0.61      0.57        79
         4.0       0.38      0.31      0.34        55
         5.0       0.24      0.19      0.21        58
         6.0       0.46      0.38      0.41        45
         7.0       0.64      0.49      0.55        47
         8.0       0.00      0.00      0.00        10
         9.0       0.54      0.33      0.41        21
        10.0       0.17      0.07      0.10        15
        11.0       0.67      0.67      0.67        36
        12.0       0.60      0.25      0.35        12
        13.0       0.71      0.40      0.51        25
        14.0       0.23      0.15      0.18        20
        15.0       0.83      0.91      0.87        22
        16.0       0.70      0.61      0.65        23
        17.0       0.78      0.76      0.77       118
        18.0       0.67      0.44      0.53        18
        19.0       0.38      0.23      0.29        13
        20.0       0.42      0.40      0.41        89
        21.0       1.00      0.23      0.38        13
        22.0       0.86      0.72      0.78        25
        23.0       0.25      0.08      0.12        12
        24.0       0.36      0.22      0.27        23
        25.0       0.53      0.57      0.55        37
        26.0       1.00      0.71      0.83        17
        27.0       0.21      0.11      0.15        36
        28.0       0.67      0.33      0.44        12
        29.0       0.55      0.58      0.57        36
        30.0       0.83      0.75      0.79        32
        31.0       0.71      0.82      0.76        39
        32.0       0.79      0.82      0.80       747
        33.0       0.78      0.77      0.78        74
        34.0       0.76      0.72      0.74        58
        35.0       0.66      0.57      0.61        47
        36.0       0.63      0.69      0.66       502
        37.0       0.66      0.70      0.68       240
        38.0       0.44      0.44      0.44        34
        39.0       0.57      0.72      0.63       344
        40.0       0.69      0.72      0.71       191
        41.0       0.58      0.47      0.52        32
        42.0       0.66      0.74      0.70       384
        43.0       0.70      0.71      0.70       117
        44.0       0.67      0.74      0.71       437
        45.0       0.92      0.73      0.82        49
        46.0       0.83      0.84      0.83       401
        47.0       0.73      0.47      0.57        17
        48.0       0.55      0.43      0.48        42
        49.0       0.88      0.87      0.88        77
        50.0       0.88      0.83      0.85       171
        51.0       0.65      0.55      0.59        20
        52.0       0.60      0.69      0.64       499
        53.0       0.67      0.59      0.63       100
        54.0       0.75      0.27      0.40        11
        55.0       0.83      0.75      0.79       104
        56.0       0.41      0.58      0.48        19
        57.0       0.33      0.09      0.14        11
        58.0       0.97      0.86      0.91        35
        59.0       0.55      0.61      0.58       230
        60.0       0.77      0.79      0.78        58
        61.0       0.18      0.14      0.16        29
        62.0       0.62      0.43      0.51        49
        63.0       0.28      0.24      0.26        50
        64.0       0.80      0.71      0.75        34
        65.0       0.72      0.84      0.77       155
        66.0       0.00      0.00      0.00        14
        67.0       0.65      0.65      0.65       314
        68.0       0.29      0.21      0.24        62
        69.0       0.54      0.63      0.58       307
        70.0       0.46      0.34      0.39        68
        71.0       0.55      0.41      0.47        66
        72.0       0.50      0.27      0.35        15
        73.0       0.77      0.40      0.53        25
        74.0       0.33      0.16      0.21        19
        75.0       0.33      0.27      0.30        59
        76.0       0.69      0.70      0.70       206
        77.0       0.58      0.48      0.52        77
        78.0       0.69      0.58      0.63        59
        79.0       0.58      0.56      0.57       139
        80.0       0.74      0.62      0.68        42
        81.0       0.53      0.41      0.46       174
        82.0       0.48      0.35      0.41        43
        83.0       0.17      0.08      0.11        25
        84.0       0.60      0.56      0.58       105
        85.0       0.89      0.53      0.67        15
        86.0       0.64      0.62      0.63       242
        87.0       0.65      0.77      0.70       309
        88.0       0.67      0.63      0.65        59
        89.0       0.29      0.18      0.22        11
        90.0       0.53      0.57      0.55       188
        91.0       0.45      0.19      0.27        47
        92.0       0.32      0.23      0.26        40
        93.0       0.59      0.52      0.55        33
        94.0       0.56      0.62      0.59       288
        95.0       0.26      0.16      0.20        32
        96.0       0.63      0.73      0.68        75
        97.0       0.52      0.41      0.46        27
        98.0       0.78      0.55      0.65        38
        99.0       0.95      0.91      0.93        23
       100.0       0.18      0.08      0.11        25
       101.0       0.51      0.47      0.49        66
       102.0       0.84      0.73      0.78        22
       103.0       0.81      0.67      0.74        64
       104.0       0.47      0.38      0.42        39
       105.0       0.88      0.58      0.70        12
       106.0       0.83      0.75      0.79       113
       107.0       0.73      0.74      0.74       161
       108.0       0.36      0.22      0.27        23
       109.0       0.78      0.75      0.77        53
       110.0       0.78      0.50      0.61        14
       111.0       0.62      0.68      0.65       123
       112.0       0.41      0.51      0.46        41
       113.0       0.79      0.88      0.83       429
       114.0       0.72      0.80      0.76        65
       115.0       0.52      0.39      0.44        31
       116.0       0.81      0.72      0.76       173
       117.0       0.81      0.84      0.83        31
       118.0       0.74      0.78      0.76       117
       119.0       0.82      0.73      0.77       135
       120.0       0.77      0.77      0.77        62
       121.0       0.85      0.79      0.82       224
       122.0       0.85      0.80      0.82        35
       123.0       0.83      0.65      0.73        37
       124.0       0.58      0.63      0.60        30
       125.0       0.79      0.69      0.73        16
       126.0       0.85      0.77      0.81        22
       127.0       0.74      0.84      0.79        73

    accuracy                           0.66     12226
   macro avg       0.61      0.53      0.56     12226
weighted avg       0.66      0.66      0.66     12226


===confusion_matrix===

[[272   0   0 ...   0   0   0]
 [  1   2   0 ...   0   0   0]
 [  0   0   6 ...   0   0   0]
 ...
 [  0   0   0 ...  11   0   0]
 [  0   0   0 ...   0  17   4]
 [  0   0   0 ...   1   2  61]]

===multilabel confusion matrix===

[[[11750   118]
  [   86   272]]

 [[12208     6]
  [   10     2]]

 [[12203     5]
  [   12     6]]

 [[12107    40]
  [   31    48]]

 [[12143    28]
  [   38    17]]

 [[12134    34]
  [   47    11]]

 [[12161    20]
  [   28    17]]

 [[12166    13]
  [   24    23]]

 [[12212     4]
  [   10     0]]

 [[12199     6]
  [   14     7]]

 [[12206     5]
  [   14     1]]

 [[12178    12]
  [   12    24]]

 [[12212     2]
  [    9     3]]

 [[12197     4]
  [   15    10]]

 [[12196    10]
  [   17     3]]

 [[12200     4]
  [    2    20]]

 [[12197     6]
  [    9    14]]

 [[12082    26]
  [   28    90]]

 [[12204     4]
  [   10     8]]

 [[12208     5]
  [   10     3]]

 [[12087    50]
  [   53    36]]

 [[12213     0]
  [   10     3]]

 [[12198     3]
  [    7    18]]

 [[12211     3]
  [   11     1]]

 [[12194     9]
  [   18     5]]

 [[12170    19]
  [   16    21]]

 [[12209     0]
  [    5    12]]

 [[12175    15]
  [   32     4]]

 [[12212     2]
  [    8     4]]

 [[12173    17]
  [   15    21]]

 [[12189     5]
  [    8    24]]

 [[12174    13]
  [    7    32]]

 [[11311   168]
  [  132   615]]

 [[12136    16]
  [   17    57]]

 [[12155    13]
  [   16    42]]

 [[12165    14]
  [   20    27]]

 [[11518   206]
  [  156   346]]

 [[11901    85]
  [   73   167]]

 [[12173    19]
  [   19    15]]

 [[11695   187]
  [   98   246]]

 [[11974    61]
  [   53   138]]

 [[12183    11]
  [   17    15]]

 [[11695   147]
  [   99   285]]

 [[12073    36]
  [   34    83]]

 [[11633   156]
  [  114   323]]

 [[12174     3]
  [   13    36]]

 [[11755    70]
  [   64   337]]

 [[12206     3]
  [    9     8]]

 [[12169    15]
  [   24    18]]

 [[12140     9]
  [   10    67]]

 [[12035    20]
  [   29   142]]

 [[12200     6]
  [    9    11]]

 [[11499   228]
  [  156   343]]

 [[12097    29]
  [   41    59]]

 [[12214     1]
  [    8     3]]

 [[12106    16]
  [   26    78]]

 [[12191    16]
  [    8    11]]

 [[12213     2]
  [   10     1]]

 [[12190     1]
  [    5    30]]

 [[11881   115]
  [   90   140]]

 [[12154    14]
  [   12    46]]

 [[12179    18]
  [   25     4]]

 [[12164    13]
  [   28    21]]

 [[12145    31]
  [   38    12]]

 [[12186     6]
  [   10    24]]

 [[12020    51]
  [   25   130]]

 [[12203     9]
  [   14     0]]

 [[11803   109]
  [  109   205]]

 [[12132    32]
  [   49    13]]

 [[11754   165]
  [  114   193]]

 [[12131    27]
  [   45    23]]

 [[12138    22]
  [   39    27]]

 [[12207     4]
  [   11     4]]

 [[12198     3]
  [   15    10]]

 [[12201     6]
  [   16     3]]

 [[12134    33]
  [   43    16]]

 [[11956    64]
  [   62   144]]

 [[12122    27]
  [   40    37]]

 [[12152    15]
  [   25    34]]

 [[12031    56]
  [   61    78]]

 [[12175     9]
  [   16    26]]

 [[11988    64]
  [  103    71]]

 [[12167    16]
  [   28    15]]

 [[12191    10]
  [   23     2]]

 [[12082    39]
  [   46    59]]

 [[12210     1]
  [    7     8]]

 [[11898    86]
  [   92   150]]

 [[11790   127]
  [   72   237]]

 [[12149    18]
  [   22    37]]

 [[12210     5]
  [    9     2]]

 [[11943    95]
  [   80   108]]

 [[12168    11]
  [   38     9]]

 [[12167    19]
  [   31     9]]

 [[12181    12]
  [   16    17]]

 [[11798   140]
  [  109   179]]

 [[12180    14]
  [   27     5]]

 [[12119    32]
  [   20    55]]

 [[12189    10]
  [   16    11]]

 [[12182     6]
  [   17    21]]

 [[12202     1]
  [    2    21]]

 [[12192     9]
  [   23     2]]

 [[12130    30]
  [   35    31]]

 [[12201     3]
  [    6    16]]

 [[12152    10]
  [   21    43]]

 [[12170    17]
  [   24    15]]

 [[12213     1]
  [    5     7]]

 [[12095    18]
  [   28    85]]

 [[12022    43]
  [   42   119]]

 [[12194     9]
  [   18     5]]

 [[12162    11]
  [   13    40]]

 [[12210     2]
  [    7     7]]

 [[12051    52]
  [   39    84]]

 [[12155    30]
  [   20    21]]

 [[11695   102]
  [   52   377]]

 [[12141    20]
  [   13    52]]

 [[12184    11]
  [   19    12]]

 [[12023    30]
  [   49   124]]

 [[12189     6]
  [    5    26]]

 [[12077    32]
  [   26    91]]

 [[12069    22]
  [   36    99]]

 [[12150    14]
  [   14    48]]

 [[11971    31]
  [   46   178]]

 [[12186     5]
  [    7    28]]

 [[12184     5]
  [   13    24]]

 [[12182    14]
  [   11    19]]

 [[12207     3]
  [    5    11]]

 [[12201     3]
  [    5    17]]

 [[12132    21]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.6634
MCC	0.6558
log_loss	1.8320
f1 score weighted	0.6568
f1 score macro	0.5580
f1 score micro	0.6634
roc_auc ovr	0.9688
roc_auc ovo	0.9640
precision	0.6581
recall	0.6634

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f8ac84905b0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f8ac8490370>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f8ac8490850>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7f8ac84903a0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [ 0, -1,  0, ..., -2, -2,  0],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -3, -3, ..., -3, -1,  4],
        [-2, -2, -2, ...,  2,  7, -1],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [-2, -2, -2, ...,  2,  7, -1],
        [ 0, -3, -3, ..., -2, -2, -1]],

       [[ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -3, -3, ..., -3, -1,  4],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 4, -1, -2, ..., -3, -2,  0]],

       [[-1, -2, -3, ..., -2, -1,  1],
        [-1, -2, -3, ..., -2, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 4, -1, -2, ..., -3, -2,  0]]], dtype=int8), 'y_test': array([ 42.,  42.,  42., ...,  58.,  76., 125.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.80      0.74       358
         1.0       0.43      0.50      0.46        12
         2.0       0.67      0.32      0.43        19
         3.0       0.56      0.63      0.59        79
         4.0       0.42      0.40      0.41        55
         5.0       0.40      0.29      0.34        58
         6.0       0.25      0.22      0.24        45
         7.0       0.45      0.47      0.46        47
         8.0       0.00      0.00      0.00        10
         9.0       0.60      0.43      0.50        21
        10.0       0.43      0.20      0.27        15
        11.0       0.88      0.81      0.84        36
        12.0       0.50      0.17      0.25        12
        13.0       0.88      0.56      0.68        25
        14.0       0.75      0.47      0.58        19
        15.0       0.88      0.68      0.77        22
        16.0       0.70      0.61      0.65        23
        17.0       0.83      0.78      0.80       118
        18.0       0.50      0.44      0.47        18
        19.0       0.25      0.08      0.12        12
        20.0       0.43      0.41      0.42        90
        21.0       0.62      0.38      0.48        13
        22.0       0.70      0.56      0.62        25
        23.0       0.50      0.15      0.24        13
        24.0       0.32      0.27      0.29        22
        25.0       0.57      0.53      0.55        38
        26.0       0.93      0.82      0.87        17
        27.0       0.41      0.31      0.35        35
        28.0       0.00      0.00      0.00        12
        29.0       0.58      0.53      0.55        36
        30.0       0.64      0.66      0.65        32
        31.0       0.80      0.84      0.82        38
        32.0       0.78      0.80      0.79       747
        33.0       0.74      0.87      0.80        75
        34.0       0.85      0.66      0.74        59
        35.0       0.58      0.38      0.46        47
        36.0       0.62      0.68      0.65       501
        37.0       0.64      0.67      0.66       241
        38.0       0.71      0.76      0.74        33
        39.0       0.59      0.65      0.62       344
        40.0       0.73      0.76      0.74       192
        41.0       0.62      0.50      0.55        32
        42.0       0.65      0.74      0.70       384
        43.0       0.81      0.71      0.76       117
        44.0       0.67      0.71      0.69       436
        45.0       0.93      0.86      0.89        49
        46.0       0.82      0.85      0.83       401
        47.0       1.00      0.18      0.30        17
        48.0       0.66      0.55      0.60        42
        49.0       0.79      0.83      0.81        77
        50.0       0.86      0.84      0.85       172
        51.0       0.58      0.35      0.44        20
        52.0       0.58      0.69      0.63       499
        53.0       0.63      0.63      0.63       100
        54.0       0.75      0.27      0.40        11
        55.0       0.66      0.74      0.70       104
        56.0       0.33      0.22      0.27        18
        57.0       0.25      0.10      0.14        10
        58.0       0.87      0.74      0.80        35
        59.0       0.64      0.55      0.59       230
        60.0       0.81      0.74      0.77        58
        61.0       0.24      0.21      0.22        29
        62.0       0.60      0.31      0.41        49
        63.0       0.24      0.22      0.23        50
        64.0       0.67      0.59      0.62        34
        65.0       0.76      0.76      0.76       155
        66.0       0.50      0.14      0.22        14
        67.0       0.57      0.63      0.60       314
        68.0       0.23      0.23      0.23        62
        69.0       0.61      0.65      0.63       307
        70.0       0.36      0.34      0.35        68
        71.0       0.55      0.44      0.49        66
        72.0       0.40      0.14      0.21        14
        73.0       0.80      0.50      0.62        24
        74.0       0.44      0.21      0.29        19
        75.0       0.45      0.35      0.39        60
        76.0       0.62      0.64      0.63       206
        77.0       0.46      0.51      0.48        77
        78.0       0.61      0.59      0.60        59
        79.0       0.57      0.48      0.52       139
        80.0       0.71      0.60      0.65        42
        81.0       0.37      0.49      0.42       174
        82.0       0.59      0.44      0.51        43
        83.0       0.35      0.23      0.28        26
        84.0       0.53      0.52      0.53       106
        85.0       0.75      0.80      0.77        15
        86.0       0.57      0.68      0.62       241
        87.0       0.71      0.74      0.72       309
        88.0       0.70      0.54      0.61        59
        89.0       1.00      0.20      0.33        10
        90.0       0.54      0.62      0.58       188
        91.0       0.53      0.39      0.45        46
        92.0       0.10      0.05      0.07        41
        93.0       0.35      0.19      0.24        32
        94.0       0.62      0.64      0.63       288
        95.0       0.32      0.23      0.26        31
        96.0       0.72      0.64      0.68        75
        97.0       0.25      0.22      0.24        27
        98.0       0.75      0.55      0.64        38
        99.0       0.92      0.92      0.92        24
       100.0       0.10      0.04      0.06        25
       101.0       0.54      0.52      0.53        65
       102.0       0.89      0.73      0.80        22
       103.0       0.67      0.67      0.67        64
       104.0       0.41      0.33      0.36        40
       105.0       0.85      0.92      0.88        12
       106.0       0.67      0.74      0.71       113
       107.0       0.68      0.73      0.71       161
       108.0       0.39      0.29      0.33        24
       109.0       0.76      0.62      0.68        52
       110.0       0.77      0.67      0.71        15
       111.0       0.74      0.63      0.68       124
       112.0       0.64      0.56      0.60        41
       113.0       0.82      0.88      0.85       430
       114.0       0.73      0.66      0.69        65
       115.0       0.62      0.42      0.50        31
       116.0       0.77      0.68      0.72       173
       117.0       0.87      0.65      0.74        31
       118.0       0.84      0.76      0.80       117
       119.0       0.82      0.72      0.77       136
       120.0       0.80      0.69      0.74        62
       121.0       0.77      0.85      0.81       224
       122.0       0.89      0.69      0.77        35
       123.0       0.85      0.59      0.70        37
       124.0       0.72      0.74      0.73        31
       125.0       0.67      0.67      0.67        15
       126.0       0.73      0.76      0.74        21
       127.0       0.77      0.86      0.81        73

    accuracy                           0.66     12226
   macro avg       0.61      0.53      0.56     12226
weighted avg       0.66      0.66      0.65     12226


===confusion_matrix===

[[288   0   0 ...   0   0   0]
 [  0   6   0 ...   0   0   0]
 [  0   0   6 ...   0   0   0]
 ...
 [  0   0   0 ...  10   1   0]
 [  0   0   0 ...   0  16   3]
 [  0   0   0 ...   1   1  63]]

===multilabel confusion matrix===

[[[11740   128]
  [   70   288]]

 [[12206     8]
  [    6     6]]

 [[12204     3]
  [   13     6]]

 [[12107    40]
  [   29    50]]

 [[12141    30]
  [   33    22]]

 [[12142    26]
  [   41    17]]

 [[12151    30]
  [   35    10]]

 [[12152    27]
  [   25    22]]

 [[12214     2]
  [   10     0]]

 [[12199     6]
  [   12     9]]

 [[12207     4]
  [   12     3]]

 [[12186     4]
  [    7    29]]

 [[12212     2]
  [   10     2]]

 [[12199     2]
  [   11    14]]

 [[12204     3]
  [   10     9]]

 [[12202     2]
  [    7    15]]

 [[12197     6]
  [    9    14]]

 [[12089    19]
  [   26    92]]

 [[12200     8]
  [   10     8]]

 [[12211     3]
  [   11     1]]

 [[12086    50]
  [   53    37]]

 [[12210     3]
  [    8     5]]

 [[12195     6]
  [   11    14]]

 [[12211     2]
  [   11     2]]

 [[12191    13]
  [   16     6]]

 [[12173    15]
  [   18    20]]

 [[12208     1]
  [    3    14]]

 [[12175    16]
  [   24    11]]

 [[12214     0]
  [   12     0]]

 [[12176    14]
  [   17    19]]

 [[12182    12]
  [   11    21]]

 [[12180     8]
  [    6    32]]

 [[11308   171]
  [  146   601]]

 [[12128    23]
  [   10    65]]

 [[12160     7]
  [   20    39]]

 [[12166    13]
  [   29    18]]

 [[11515   210]
  [  158   343]]

 [[11894    91]
  [   79   162]]

 [[12183    10]
  [    8    25]]

 [[11725   157]
  [  120   224]]

 [[11980    54]
  [   47   145]]

 [[12184    10]
  [   16    16]]

 [[11691   151]
  [   98   286]]

 [[12090    19]
  [   34    83]]

 [[11638   152]
  [  126   310]]

 [[12174     3]
  [    7    42]]

 [[11748    77]
  [   61   340]]

 [[12209     0]
  [   14     3]]

 [[12172    12]
  [   19    23]]

 [[12132    17]
  [   13    64]]

 [[12030    24]
  [   28   144]]

 [[12201     5]
  [   13     7]]

 [[11477   250]
  [  157   342]]

 [[12089    37]
  [   37    63]]

 [[12214     1]
  [    8     3]]

 [[12083    39]
  [   27    77]]

 [[12200     8]
  [   14     4]]

 [[12213     3]
  [    9     1]]

 [[12187     4]
  [    9    26]]

 [[11924    72]
  [  104   126]]

 [[12158    10]
  [   15    43]]

 [[12178    19]
  [   23     6]]

 [[12167    10]
  [   34    15]]

 [[12142    34]
  [   39    11]]

 [[12182    10]
  [   14    20]]

 [[12034    37]
  [   37   118]]

 [[12210     2]
  [   12     2]]

 [[11765   147]
  [  116   198]]

 [[12118    46]
  [   48    14]]

 [[11788   131]
  [  106   201]]

 [[12117    41]
  [   45    23]]

 [[12136    24]
  [   37    29]]

 [[12209     3]
  [   12     2]]

 [[12199     3]
  [   12    12]]

 [[12202     5]
  [   15     4]]

 [[12140    26]
  [   39    21]]

 [[11941    79]
  [   75   131]]

 [[12104    45]
  [   38    39]]

 [[12145    22]
  [   24    35]]

 [[12037    50]
  [   72    67]]

 [[12174    10]
  [   17    25]]

 [[11908   144]
  [   89    85]]

 [[12170    13]
  [   24    19]]

 [[12189    11]
  [   20     6]]

 [[12072    48]
  [   51    55]]

 [[12207     4]
  [    3    12]]

 [[11860   125]
  [   77   164]]

 [[11822    95]
  [   81   228]]

 [[12153    14]
  [   27    32]]

 [[12216     0]
  [    8     2]]

 [[11940    98]
  [   72   116]]

 [[12164    16]
  [   28    18]]

 [[12167    18]
  [   39     2]]

 [[12183    11]
  [   26     6]]

 [[11827   111]
  [  103   185]]

 [[12180    15]
  [   24     7]]

 [[12132    19]
  [   27    48]]

 [[12181    18]
  [   21     6]]

 [[12181     7]
  [   17    21]]

 [[12200     2]
  [    2    22]]

 [[12192     9]
  [   24     1]]

 [[12132    29]
  [   31    34]]

 [[12202     2]
  [    6    16]]

 [[12141    21]
  [   21    43]]

 [[12167    19]
  [   27    13]]

 [[12212     2]
  [    1    11]]

 [[12072    41]
  [   29    84]]

 [[12010    55]
  [   43   118]]

 [[12191    11]
  [   17     7]]

 [[12164    10]
  [   20    32]]

 [[12208     3]
  [    5    10]]

 [[12075    27]
  [   46    78]]

 [[12172    13]
  [   18    23]]

 [[11714    82]
  [   53   377]]

 [[12145    16]
  [   22    43]]

 [[12187     8]
  [   18    13]]

 [[12017    36]
  [   55   118]]

 [[12192     3]
  [   11    20]]

 [[12092    17]
  [   28    89]]

 [[12069    21]
  [   38    98]]

 [[12153    11]
  [   19    43]]

 [[11944    58]
  [   33   191]]

 [[12188     3]
  [   11    24]]

 [[12185     4]
  [   15    22]]

 [[12186     9]
  [    8    23]]

 [[12206     5]
  [    5    10]]

 [[12199     6]
  [    5    16]]

 [[12134    19]
  [   10    63]]]

===scores report===
metrics	scores
Accuracy	0.6584
MCC	0.6507
log_loss	1.8307
f1 score weighted	0.6529
f1 score macro	0.5579
f1 score micro	0.6584
roc_auc ovr	0.9685
roc_auc ovo	0.9625
precision	0.6559
recall	0.6584

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.6684387012349717	0.6610721015463747	1.823883650335314	0.6631595118145135	0.5573927212608204	0.6684387012349717	0.9693538850975528	0.9647129123091425	0.6656252204812099	0.6684387012349717
1	0.6628772388975219	0.6552121245800486	1.776052199362233	0.6545783289229682	0.558869264894249	0.6628772388975219	0.9697620432517129	0.9647820486065016	0.6548942743194551	0.6628772388975219
2	0.6548339604122362	0.6470822902223761	1.926622692753837	0.648299716529587	0.5444321608333803	0.6548339604122362	0.9672361077434151	0.962541032582972	0.6488231492719917	0.6548339604122362
3	0.6634222149517421	0.6558210883786253	1.8319781834671123	0.656804069877715	0.5580395739928989	0.6634222149517421	0.9687599996023283	0.9640286012583579	0.6581162031883264	0.6634222149517421
4	0.6584328480287911	0.650734351149502	1.8307270344613866	0.6528662848090613	0.5578788062899449	0.6584328480287911	0.9685288995216902	0.9624683268346015	0.6559449062130248	0.6584328480287911
mean	0.6616009927050526	0.6539843911753853	1.8378527520759764	0.6551415823907689	0.5553225054542587	0.6616009927050526	0.9687281870433399	0.963706584318315	0.6566807506948016	0.6616009927050526
std	0.004637451444435888	0.004760634032725514	0.04894861161458859	0.004885824780016628	0.005465931528634293	0.004637451444435888	0.0008634100887870239	0.0010163470680526296	0.005432106933445137	0.004637451444435888

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 23827.4987 secs

