/home/amsequeira/enzymeClassification/models/blosum/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_blosum_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights/home/amsequeira/enzymeClassification/models/blosum/64_64_32_500_post_pre_lstm_attentio_cv_only_enz_blosum_lev2_ec50
self
x_train
y_train
x_test
y_test
number_classes
problem_type
x_dval
y_dval
model
epochs
batch_size
callbacks
reduce_lr
early_stopping
checkpoint
tensorboard
early_stopping_patience
reduce_lr_patience
reduce_lr_factor
reduce_lr_min
path
report_name
verbose
validation_split
shuffle
class_weights
===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb0fc5746d0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb0fc5743a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb0fc574880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb0fc5745e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1, -1, -2, ..., -1, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 0, -2,  0, ..., -2, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 0, -3, -3, ..., -3, -1,  4],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -3, -3, ..., -3, -1,  3],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1,  0,  0, ..., -3, -2, -2],
        ...,
        [ 0, -2,  0, ..., -2, -3, -3],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1, -2, -2, ..., -4, -3, -2],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 19., 28., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.67      0.75      0.71       402
         1.0       0.64      0.37      0.47        19
         2.0       0.68      0.49      0.57        82
         3.0       0.00      0.00      0.00        16
         4.0       0.40      0.19      0.26        62
         5.0       0.58      0.52      0.54       277
         6.0       0.88      0.64      0.74        36
         7.0       0.40      0.23      0.29        26
         8.0       0.54      0.44      0.49        72
         9.0       0.70      0.63      0.67        30
        10.0       0.77      0.67      0.72       156
        11.0       0.54      0.49      0.51       168
        12.0       0.56      0.48      0.52        83
        13.0       0.20      0.11      0.14        53
        14.0       0.62      0.52      0.56        31
        15.0       0.51      0.40      0.45        52
        16.0       0.64      0.63      0.63        94
        17.0       0.79      0.80      0.80       885
        18.0       0.62      0.58      0.60        48
        19.0       0.63      0.69      0.66       781
        20.0       0.70      0.68      0.69       591
        21.0       0.70      0.72      0.71       385
        22.0       0.77      0.67      0.72       128
        23.0       0.77      0.81      0.79      1888
        24.0       0.69      0.64      0.67       169
        25.0       0.63      0.70      0.66      1296
        26.0       0.60      0.55      0.57       381
        27.0       0.50      0.14      0.22        14
        28.0       0.62      0.63      0.62       769
        29.0       0.45      0.46      0.46       372
        30.0       0.70      0.75      0.73       631
        31.0       0.67      0.55      0.60        11
        32.0       0.47      0.56      0.51       316
        33.0       0.59      0.59      0.59       405
        34.0       0.53      0.56      0.55        96
        35.0       0.00      0.00      0.00        26
        36.0       0.51      0.37      0.43        65
        37.0       0.87      0.62      0.72        21
        38.0       0.67      0.55      0.60       121
        39.0       0.79      0.66      0.72       114
        40.0       0.72      0.71      0.71       207
        41.0       0.73      0.61      0.67       194
        42.0       0.59      0.55      0.57        47
        43.0       0.90      0.84      0.87       431
        44.0       0.66      0.61      0.64        67
        45.0       0.81      0.76      0.78       488
        46.0       0.85      0.53      0.65        62
        47.0       0.86      0.86      0.86       264
        48.0       0.71      0.61      0.66        49
        49.0       0.85      0.57      0.68        30
        50.0       0.79      0.73      0.76        15
        51.0       0.85      0.52      0.65        21
        52.0       0.71      0.89      0.79        73

    accuracy                           0.68     13120
   macro avg       0.63      0.56      0.59     13120
weighted avg       0.68      0.68      0.68     13120


===confusion_matrix===

[[303   0   1 ...   0   0   1]
 [  0   7   2 ...   0   0   0]
 [  1   0  40 ...   0   0   0]
 ...
 [  0   0   0 ...  11   1   1]
 [  0   0   0 ...   0  11   6]
 [  0   0   0 ...   0   1  65]]

===multilabel confusion matrix===

[[[12568   150]
  [   99   303]]

 [[13097     4]
  [   12     7]]

 [[13019    19]
  [   42    40]]

 [[13097     7]
  [   16     0]]

 [[13040    18]
  [   50    12]]

 [[12738   105]
  [  134   143]]

 [[13081     3]
  [   13    23]]

 [[13085     9]
  [   20     6]]

 [[13021    27]
  [   40    32]]

 [[13082     8]
  [   11    19]]

 [[12933    31]
  [   51   105]]

 [[12883    69]
  [   86    82]]

 [[13005    32]
  [   43    40]]

 [[13043    24]
  [   47     6]]

 [[13079    10]
  [   15    16]]

 [[13048    20]
  [   31    21]]

 [[12993    33]
  [   35    59]]

 [[12050   185]
  [  178   707]]

 [[13055    17]
  [   20    28]]

 [[12019   320]
  [  240   541]]

 [[12355   174]
  [  187   404]]

 [[12618   117]
  [  109   276]]

 [[12967    25]
  [   42    86]]

 [[10767   465]
  [  350  1538]]

 [[12903    48]
  [   60   109]]

 [[11280   544]
  [  388   908]]

 [[12603   136]
  [  173   208]]

 [[13104     2]
  [   12     2]]

 [[12057   294]
  [  287   482]]

 [[12541   207]
  [  201   171]]

 [[12285   204]
  [  155   476]]

 [[13106     3]
  [    5     6]]

 [[12605   199]
  [  139   177]]

 [[12552   163]
  [  168   237]]

 [[12977    47]
  [   42    54]]

 [[13091     3]
  [   26     0]]

 [[13032    23]
  [   41    24]]

 [[13097     2]
  [    8    13]]

 [[12966    33]
  [   55    66]]

 [[12986    20]
  [   39    75]]

 [[12856    57]
  [   61   146]]

 [[12882    44]
  [   75   119]]

 [[13055    18]
  [   21    26]]

 [[12649    40]
  [   67   364]]

 [[13032    21]
  [   26    41]]

 [[12545    87]
  [  118   370]]

 [[13052     6]
  [   29    33]]

 [[12818    38]
  [   37   227]]

 [[13059    12]
  [   19    30]]

 [[13087     3]
  [   13    17]]

 [[13102     3]
  [    4    11]]

 [[13097     2]
  [   10    11]]

 [[13020    27]
  [    8    65]]]

===scores report===
metrics	scores
Accuracy	0.6831
MCC	0.6633
log_loss	1.6692
f1 score weighted	0.6801
f1 score macro	0.5883
f1 score micro	0.6831
roc_auc ovr	0.9566
roc_auc ovo	0.9531
precision	0.6815
recall	0.6831

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb0fc5746d0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb0fc5743a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb0fc574880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb0fc5745e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1,  1,  0, ..., -2, -1, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-2, -2,  1, ..., -4, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1,  2,  0, ..., -3, -2, -2],
        [ 0, -3, -3, ..., -3, -1,  4],
        [-2, -3, -3, ...,  1,  3, -1],
        ...,
        [-2,  0,  1, ..., -2,  2, -3],
        [-1, -2, -2, ..., -4, -3, -2],
        [-1, -2, -3, ..., -2, -1,  1]],

       [[-2,  0,  6, ..., -4, -2, -3],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-1, -2, -3, ..., -2, -1,  1],
        [-2, -2, -2, ...,  2,  7, -1],
        [ 4, -1, -2, ..., -3, -2,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2, -2,  1, ..., -4, -3, -3],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 25., 30., 28.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.67      0.71      0.69       402
         1.0       0.58      0.37      0.45        19
         2.0       0.54      0.53      0.53        81
         3.0       0.00      0.00      0.00        16
         4.0       0.38      0.39      0.38        62
         5.0       0.73      0.55      0.63       277
         6.0       0.73      0.75      0.74        36
         7.0       0.67      0.31      0.42        26
         8.0       0.58      0.36      0.44        73
         9.0       0.65      0.45      0.53        29
        10.0       0.71      0.63      0.67       156
        11.0       0.67      0.43      0.52       168
        12.0       0.68      0.49      0.57        83
        13.0       0.12      0.06      0.08        53
        14.0       0.48      0.41      0.44        32
        15.0       0.37      0.42      0.40        52
        16.0       0.59      0.58      0.58        95
        17.0       0.80      0.81      0.80       884
        18.0       0.63      0.50      0.56        48
        19.0       0.79      0.60      0.68       782
        20.0       0.83      0.62      0.71       591
        21.0       0.73      0.68      0.71       385
        22.0       0.67      0.69      0.68       128
        23.0       0.81      0.78      0.80      1888
        24.0       0.60      0.72      0.65       169
        25.0       0.60      0.68      0.64      1295
        26.0       0.45      0.67      0.53       381
        27.0       0.83      0.71      0.77        14
        28.0       0.58      0.65      0.61       769
        29.0       0.50      0.53      0.52       371
        30.0       0.66      0.75      0.70       631
        31.0       0.50      0.36      0.42        11
        32.0       0.51      0.54      0.52       316
        33.0       0.64      0.60      0.62       405
        34.0       0.64      0.49      0.56        96
        35.0       0.25      0.19      0.22        26
        36.0       0.48      0.48      0.48        65
        37.0       0.64      0.64      0.64        22
        38.0       0.51      0.50      0.51       121
        39.0       0.73      0.72      0.72       113
        40.0       0.54      0.74      0.62       208
        41.0       0.67      0.65      0.66       193
        42.0       0.50      0.41      0.45        46
        43.0       0.91      0.89      0.90       431
        44.0       0.75      0.68      0.71        66
        45.0       0.72      0.80      0.76       489
        46.0       0.78      0.61      0.68        62
        47.0       0.81      0.84      0.82       264
        48.0       0.75      0.49      0.59        49
        49.0       0.79      0.84      0.81        31
        50.0       0.92      0.75      0.83        16
        51.0       0.86      0.86      0.86        21
        52.0       0.78      0.84      0.81        73

    accuracy                           0.68     13120
   macro avg       0.63      0.58      0.60     13120
weighted avg       0.69      0.68      0.68     13120


===confusion_matrix===

[[285   0   2 ...   0   0   0]
 [  0   7   1 ...   0   0   0]
 [  1   0  43 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   1]
 [  0   0   0 ...   0  18   2]
 [  0   0   0 ...   0   0  61]]

===multilabel confusion matrix===

[[[12579   139]
  [  117   285]]

 [[13096     5]
  [   12     7]]

 [[13002    37]
  [   38    43]]

 [[13100     4]
  [   16     0]]

 [[13019    39]
  [   38    24]]

 [[12787    56]
  [  125   152]]

 [[13074    10]
  [    9    27]]

 [[13090     4]
  [   18     8]]

 [[13028    19]
  [   47    26]]

 [[13084     7]
  [   16    13]]

 [[12923    41]
  [   57    99]]

 [[12916    36]
  [   96    72]]

 [[13018    19]
  [   42    41]]

 [[13046    21]
  [   50     3]]

 [[13074    14]
  [   19    13]]

 [[13031    37]
  [   30    22]]

 [[12986    39]
  [   40    55]]

 [[12051   185]
  [  166   718]]

 [[13058    14]
  [   24    24]]

 [[12209   129]
  [  311   471]]

 [[12455    74]
  [  226   365]]

 [[12639    96]
  [  122   263]]

 [[12949    43]
  [   40    88]]

 [[10880   352]
  [  409  1479]]

 [[12870    81]
  [   48   121]]

 [[11230   595]
  [  411   884]]

 [[12421   318]
  [  126   255]]

 [[13104     2]
  [    4    10]]

 [[11987   364]
  [  272   497]]

 [[12552   197]
  [  174   197]]

 [[12248   241]
  [  160   471]]

 [[13105     4]
  [    7     4]]

 [[12636   168]
  [  144   172]]

 [[12578   137]
  [  160   245]]

 [[12998    26]
  [   49    47]]

 [[13079    15]
  [   21     5]]

 [[13022    33]
  [   34    31]]

 [[13090     8]
  [    8    14]]

 [[12941    58]
  [   60    61]]

 [[12977    30]
  [   32    81]]

 [[12780   132]
  [   55   153]]

 [[12865    62]
  [   68   125]]

 [[13055    19]
  [   27    19]]

 [[12649    40]
  [   49   382]]

 [[13039    15]
  [   21    45]]

 [[12481   150]
  [  100   389]]

 [[13047    11]
  [   24    38]]

 [[12804    52]
  [   43   221]]

 [[13063     8]
  [   25    24]]

 [[13082     7]
  [    5    26]]

 [[13103     1]
  [    4    12]]

 [[13096     3]
  [    3    18]]

 [[13030    17]
  [   12    61]]]

===scores report===
metrics	scores
Accuracy	0.6788
MCC	0.6598
log_loss	1.5918
f1 score weighted	0.6785
f1 score macro	0.5967
f1 score micro	0.6788
roc_auc ovr	0.9571
roc_auc ovo	0.9570
precision	0.6874
recall	0.6788

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb0fc5746d0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb0fc5743a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb0fc574880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb0fc5745e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 4, -1, -2, ..., -3, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 0, -1,  0, ..., -2, -2,  0],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -1,  0, ..., -2, -2,  0],
        [-2, -2, -2, ...,  2,  7, -1],
        [ 1, -1,  1, ..., -3, -2, -2],
        ...,
        [-1,  0,  0, ..., -3, -2, -2],
        [-2, -3, -3, ...,  1,  3, -1],
        [-2, -2,  1, ..., -4, -3, -3]],

       [[ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -3, -3, ..., -3, -1,  4],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [-1,  1,  0, ..., -2, -1, -2],
        [ 4, -1, -2, ..., -3, -2,  0]],

       [[ 0, -1,  0, ..., -2, -2,  0],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2,  0,  6, ..., -4, -2, -3],
        [-2,  0,  1, ..., -2,  2, -3],
        [-1, -2, -3, ..., -2, -1,  1]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 28., 28., 17.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.71      0.73      0.72       401
         1.0       0.58      0.55      0.56        20
         2.0       0.51      0.45      0.48        82
         3.0       0.10      0.06      0.08        16
         4.0       0.36      0.29      0.32        62
         5.0       0.67      0.46      0.55       277
         6.0       0.71      0.69      0.70        36
         7.0       0.40      0.16      0.23        25
         8.0       0.51      0.51      0.51        73
         9.0       0.47      0.55      0.51        29
        10.0       0.64      0.59      0.61       156
        11.0       0.59      0.45      0.51       168
        12.0       0.51      0.52      0.51        83
        13.0       0.21      0.13      0.16        54
        14.0       0.64      0.23      0.33        31
        15.0       0.52      0.43      0.47        53
        16.0       0.56      0.54      0.55        95
        17.0       0.85      0.76      0.81       884
        18.0       0.63      0.55      0.59        47
        19.0       0.71      0.62      0.66       782
        20.0       0.70      0.72      0.71       592
        21.0       0.74      0.68      0.70       385
        22.0       0.68      0.74      0.71       128
        23.0       0.79      0.79      0.79      1887
        24.0       0.68      0.68      0.68       168
        25.0       0.61      0.66      0.64      1295
        26.0       0.54      0.58      0.56       381
        27.0       0.64      0.50      0.56        14
        28.0       0.57      0.61      0.59       768
        29.0       0.51      0.49      0.50       372
        30.0       0.66      0.75      0.70       631
        31.0       0.00      0.00      0.00        10
        32.0       0.56      0.53      0.54       316
        33.0       0.52      0.61      0.57       405
        34.0       0.60      0.52      0.56        96
        35.0       0.11      0.04      0.06        26
        36.0       0.60      0.45      0.52        66
        37.0       0.83      0.45      0.59        22
        38.0       0.56      0.53      0.54       121
        39.0       0.76      0.81      0.78       113
        40.0       0.71      0.74      0.72       208
        41.0       0.64      0.74      0.68       194
        42.0       0.57      0.46      0.51        46
        43.0       0.83      0.90      0.87       431
        44.0       0.75      0.58      0.65        66
        45.0       0.70      0.80      0.75       489
        46.0       0.74      0.60      0.66        62
        47.0       0.78      0.87      0.83       263
        48.0       0.59      0.70      0.64        50
        49.0       0.64      0.68      0.66        31
        50.0       0.90      0.56      0.69        16
        51.0       0.82      0.67      0.74        21
        52.0       0.70      0.78      0.74        73

    accuracy                           0.67     13120
   macro avg       0.60      0.56      0.57     13120
weighted avg       0.67      0.67      0.67     13120


===confusion_matrix===

[[294   1   0 ...   0   0   0]
 [  1  11   0 ...   0   0   0]
 [  1   0  37 ...   0   0   0]
 ...
 [  0   0   0 ...   9   0   1]
 [  0   0   0 ...   0  14   4]
 [  0   0   0 ...   0   1  57]]

===multilabel confusion matrix===

[[[12599   120]
  [  107   294]]

 [[13092     8]
  [    9    11]]

 [[13003    35]
  [   45    37]]

 [[13095     9]
  [   15     1]]

 [[13026    32]
  [   44    18]]

 [[12781    62]
  [  149   128]]

 [[13074    10]
  [   11    25]]

 [[13089     6]
  [   21     4]]

 [[13011    36]
  [   36    37]]

 [[13073    18]
  [   13    16]]

 [[12912    52]
  [   64    92]]

 [[12899    53]
  [   92    76]]

 [[12995    42]
  [   40    43]]

 [[13040    26]
  [   47     7]]

 [[13085     4]
  [   24     7]]

 [[13046    21]
  [   30    23]]

 [[12985    40]
  [   44    51]]

 [[12120   116]
  [  208   676]]

 [[13058    15]
  [   21    26]]

 [[12139   199]
  [  301   481]]

 [[12346   182]
  [  165   427]]

 [[12642    93]
  [  125   260]]

 [[12948    44]
  [   33    95]]

 [[10831   402]
  [  396  1491]]

 [[12899    53]
  [   53   115]]

 [[11272   553]
  [  435   860]]

 [[12547   192]
  [  159   222]]

 [[13102     4]
  [    7     7]]

 [[11994   358]
  [  299   469]]

 [[12570   178]
  [  188   184]]

 [[12249   240]
  [  160   471]]

 [[13107     3]
  [   10     0]]

 [[12670   134]
  [  148   168]]

 [[12489   226]
  [  156   249]]

 [[12991    33]
  [   46    50]]

 [[13086     8]
  [   25     1]]

 [[13034    20]
  [   36    30]]

 [[13096     2]
  [   12    10]]

 [[12949    50]
  [   57    64]]

 [[12978    29]
  [   22    91]]

 [[12848    64]
  [   54   154]]

 [[12844    82]
  [   51   143]]

 [[13058    16]
  [   25    21]]

 [[12612    77]
  [   42   389]]

 [[13041    13]
  [   28    38]]

 [[12467   164]
  [   99   390]]

 [[13045    13]
  [   25    37]]

 [[12793    64]
  [   33   230]]

 [[13046    24]
  [   15    35]]

 [[13077    12]
  [   10    21]]

 [[13103     1]
  [    7     9]]

 [[13096     3]
  [    7    14]]

 [[13023    24]
  [   16    57]]]

===scores report===
metrics	scores
Accuracy	0.6749
MCC	0.6554
log_loss	1.6692
f1 score weighted	0.6722
f1 score macro	0.5718
f1 score micro	0.6749
roc_auc ovr	0.9559
roc_auc ovo	0.9546
precision	0.6746
recall	0.6749

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb0fc5746d0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb0fc5743a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb0fc574880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb0fc5745e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 1, -1,  1, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [ 0, -3, -3, ..., -3, -1,  4],
        [ 0, -2,  0, ..., -2, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[-1,  2,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        [-1, -2, -3, ..., -2, -1,  1],
        ...,
        [ 1, -1,  1, ..., -3, -2, -2],
        [-2,  0,  1, ..., -2,  2, -3],
        [ 0, -3, -3, ..., -3, -1,  4]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -2, -3, ..., -2, -1,  1],
        [-1, -2, -3, ..., -2, -1,  1],
        [-1,  5,  0, ..., -3, -2, -3],
        ...,
        [ 4, -1, -2, ..., -3, -2,  0],
        [ 1, -1,  1, ..., -3, -2, -2],
        [ 4, -1, -2, ..., -3, -2,  0]]], dtype=int8), 'y_test': array([21., 11., 11., ..., 17., 19., 50.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.67      0.73      0.70       401
         1.0       0.67      0.20      0.31        20
         2.0       0.68      0.51      0.58        82
         3.0       0.00      0.00      0.00        15
         4.0       0.30      0.23      0.26        62
         5.0       0.62      0.59      0.60       278
         6.0       0.81      0.61      0.70        36
         7.0       0.33      0.24      0.28        25
         8.0       0.62      0.51      0.56        73
         9.0       0.58      0.52      0.55        29
        10.0       0.78      0.69      0.73       156
        11.0       0.52      0.50      0.51       168
        12.0       0.62      0.43      0.51        83
        13.0       0.09      0.04      0.05        54
        14.0       0.52      0.52      0.52        31
        15.0       0.51      0.40      0.45        53
        16.0       0.62      0.49      0.55        95
        17.0       0.80      0.79      0.80       884
        18.0       0.65      0.66      0.65        47
        19.0       0.71      0.67      0.69       781
        20.0       0.67      0.71      0.69       592
        21.0       0.60      0.71      0.65       385
        22.0       0.80      0.68      0.74       129
        23.0       0.75      0.82      0.79      1887
        24.0       0.73      0.68      0.71       168
        25.0       0.64      0.70      0.66      1295
        26.0       0.56      0.56      0.56       381
        27.0       0.80      0.31      0.44        13
        28.0       0.62      0.61      0.62       769
        29.0       0.54      0.48      0.51       372
        30.0       0.67      0.77      0.72       631
        31.0       0.40      0.36      0.38        11
        32.0       0.58      0.52      0.55       316
        33.0       0.65      0.63      0.64       405
        34.0       0.46      0.52      0.49        95
        35.0       0.33      0.04      0.07        25
        36.0       0.48      0.41      0.44        66
        37.0       0.54      0.64      0.58        22
        38.0       0.54      0.42      0.47       121
        39.0       0.80      0.81      0.80       113
        40.0       0.75      0.69      0.72       208
        41.0       0.66      0.61      0.63       194
        42.0       0.51      0.41      0.46        46
        43.0       0.82      0.83      0.83       431
        44.0       0.81      0.67      0.73        66
        45.0       0.78      0.74      0.76       489
        46.0       0.77      0.65      0.70        62
        47.0       0.82      0.88      0.85       263
        48.0       0.67      0.48      0.56        50
        49.0       0.85      0.74      0.79        31
        50.0       0.82      0.88      0.85        16
        51.0       0.75      0.68      0.71        22
        52.0       0.71      0.82      0.76        73

    accuracy                           0.68     13120
   macro avg       0.62      0.56      0.58     13120
weighted avg       0.68      0.68      0.68     13120


===confusion_matrix===

[[293   0   0 ...   0   0   0]
 [  0   4   0 ...   0   0   1]
 [  0   0  42 ...   0   0   0]
 ...
 [  0   0   0 ...  14   0   0]
 [  0   0   0 ...   0  15   5]
 [  0   0   0 ...   2   3  60]]

===multilabel confusion matrix===

[[[12576   143]
  [  108   293]]

 [[13098     2]
  [   16     4]]

 [[13018    20]
  [   40    42]]

 [[13098     7]
  [   15     0]]

 [[13025    33]
  [   48    14]]

 [[12743    99]
  [  115   163]]

 [[13079     5]
  [   14    22]]

 [[13083    12]
  [   19     6]]

 [[13024    23]
  [   36    37]]

 [[13080    11]
  [   14    15]]

 [[12933    31]
  [   48   108]]

 [[12875    77]
  [   84    84]]

 [[13015    22]
  [   47    36]]

 [[13046    20]
  [   52     2]]

 [[13074    15]
  [   15    16]]

 [[13047    20]
  [   32    21]]

 [[12996    29]
  [   48    47]]

 [[12056   180]
  [  182   702]]

 [[13056    17]
  [   16    31]]

 [[12128   211]
  [  260   521]]

 [[12323   205]
  [  174   418]]

 [[12555   180]
  [  112   273]]

 [[12969    22]
  [   41    88]]

 [[10726   507]
  [  332  1555]]

 [[12909    43]
  [   53   115]]

 [[11310   515]
  [  394   901]]

 [[12571   168]
  [  166   215]]

 [[13106     1]
  [    9     4]]

 [[12067   284]
  [  297   472]]

 [[12594   154]
  [  193   179]]

 [[12253   236]
  [  148   483]]

 [[13103     6]
  [    7     4]]

 [[12683   121]
  [  151   165]]

 [[12577   138]
  [  150   255]]

 [[12968    57]
  [   46    49]]

 [[13093     2]
  [   24     1]]

 [[13025    29]
  [   39    27]]

 [[13086    12]
  [    8    14]]

 [[12956    43]
  [   70    51]]

 [[12984    23]
  [   22    91]]

 [[12864    48]
  [   64   144]]

 [[12864    62]
  [   76   118]]

 [[13056    18]
  [   27    19]]

 [[12613    76]
  [   73   358]]

 [[13044    10]
  [   22    44]]

 [[12532    99]
  [  129   360]]

 [[13046    12]
  [   22    40]]

 [[12807    50]
  [   32   231]]

 [[13058    12]
  [   26    24]]

 [[13085     4]
  [    8    23]]

 [[13101     3]
  [    2    14]]

 [[13093     5]
  [    7    15]]

 [[13023    24]
  [   13    60]]]

===scores report===
metrics	scores
Accuracy	0.6840
MCC	0.6643
log_loss	1.6426
f1 score weighted	0.6798
f1 score macro	0.5822
f1 score micro	0.6840
roc_auc ovr	0.9582
roc_auc ovo	0.9554
precision	0.6801
recall	0.6840

===Callbacks===

generate_callbacks
[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fb0fc5746d0>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7fb0fc5743a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fb0fc574880>]
===SCORING TEST SET ===

model_complete_evaluate
{'self': <deep_ml.DeepML object at 0x7fb0fc5745e0>, 'x_test': array([[[-1, -1, -2, ..., -1, -1,  1],
        [ 0, -1,  0, ..., -2, -2,  0],
        [-1,  2,  0, ..., -3, -2, -2],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-1,  2,  0, ..., -3, -2, -2],
        [-2,  0,  6, ..., -4, -2, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[-1, -1, -2, ..., -1, -1,  1],
        [-2,  0,  6, ..., -4, -2, -3],
        [-1, -3, -3, ..., -3, -1,  3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       ...,

       [[ 0, -2,  0, ..., -2, -3, -3],
        [ 0, -3, -3, ..., -3, -1,  4],
        [-2, -2,  1, ..., -4, -3, -3],
        ...,
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0],
        [ 0,  0,  0, ...,  0,  0,  0]],

       [[ 0, -3, -3, ..., -3, -1,  4],
        [-1,  0,  0, ..., -3, -2, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2, -2,  1, ..., -4, -3, -3],
        [-1,  5,  0, ..., -3, -2, -3],
        [-2,  0,  6, ..., -4, -2, -3]],

       [[ 0, -2,  0, ..., -2, -3, -3],
        [-1, -2, -2, ..., -4, -3, -2],
        [-1, -2, -2, ..., -4, -3, -2],
        ...,
        [-2,  0,  1, ..., -2,  2, -3],
        [ 0, -1,  0, ..., -2, -2,  0],
        [-1, -2, -3, ..., -2, -1,  1]]], dtype=int8), 'y_test': array([21., 21., 21., ..., 47., 26., 30.], dtype=float32), 'model': None}
report

              precision    recall  f1-score   support

         0.0       0.69      0.70      0.69       402
         1.0       0.90      0.47      0.62        19
         2.0       0.64      0.51      0.57        82
         3.0       0.00      0.00      0.00        16
         4.0       0.34      0.24      0.28        62
         5.0       0.61      0.50      0.55       278
         6.0       0.96      0.64      0.77        36
         7.0       0.36      0.15      0.22        26
         8.0       0.59      0.51      0.54        73
         9.0       0.57      0.43      0.49        30
        10.0       0.64      0.62      0.63       156
        11.0       0.48      0.45      0.47       169
        12.0       0.49      0.49      0.49        83
        13.0       0.36      0.09      0.15        53
        14.0       0.50      0.42      0.46        31
        15.0       0.40      0.40      0.40        52
        16.0       0.52      0.48      0.50        95
        17.0       0.79      0.81      0.80       885
        18.0       0.72      0.54      0.62        48
        19.0       0.67      0.67      0.67       781
        20.0       0.70      0.68      0.69       592
        21.0       0.69      0.70      0.70       384
        22.0       0.74      0.68      0.71       128
        23.0       0.79      0.79      0.79      1887
        24.0       0.70      0.65      0.67       168
        25.0       0.61      0.69      0.64      1295
        26.0       0.57      0.58      0.57       381
        27.0       0.78      0.50      0.61        14
        28.0       0.64      0.64      0.64       769
        29.0       0.54      0.54      0.54       372
        30.0       0.77      0.73      0.75       630
        31.0       0.60      0.27      0.37        11
        32.0       0.48      0.56      0.52       316
        33.0       0.58      0.62      0.60       405
        34.0       0.66      0.68      0.67        95
        35.0       0.08      0.04      0.05        25
        36.0       0.54      0.38      0.45        65
        37.0       0.85      0.77      0.81        22
        38.0       0.62      0.58      0.60       121
        39.0       0.71      0.75      0.73       113
        40.0       0.64      0.71      0.68       208
        41.0       0.61      0.65      0.63       194
        42.0       0.38      0.47      0.42        47
        43.0       0.85      0.85      0.85       431
        44.0       0.82      0.71      0.76        66
        45.0       0.76      0.79      0.77       488
        46.0       0.75      0.62      0.68        63
        47.0       0.80      0.82      0.81       263
        48.0       0.85      0.57      0.68        49
        49.0       0.80      0.80      0.80        30
        50.0       1.00      0.80      0.89        15
        51.0       0.79      0.86      0.83        22
        52.0       0.84      0.89      0.87        73

    accuracy                           0.68     13119
   macro avg       0.64      0.58      0.60     13119
weighted avg       0.68      0.68      0.68     13119


===confusion_matrix===

[[281   0   1 ...   0   0   0]
 [  0   9   0 ...   0   0   0]
 [  0   0  42 ...   0   0   0]
 ...
 [  0   0   0 ...  12   0   0]
 [  0   0   0 ...   0  19   3]
 [  0   0   0 ...   0   1  65]]

===multilabel confusion matrix===

[[[12588   129]
  [  121   281]]

 [[13099     1]
  [   10     9]]

 [[13013    24]
  [   40    42]]

 [[13096     7]
  [   16     0]]

 [[13028    29]
  [   47    15]]

 [[12752    89]
  [  139   139]]

 [[13082     1]
  [   13    23]]

 [[13086     7]
  [   22     4]]

 [[13020    26]
  [   36    37]]

 [[13079    10]
  [   17    13]]

 [[12910    53]
  [   60    96]]

 [[12869    81]
  [   93    76]]

 [[12993    43]
  [   42    41]]

 [[13057     9]
  [   48     5]]

 [[13075    13]
  [   18    13]]

 [[13035    32]
  [   31    21]]

 [[12981    43]
  [   49    46]]

 [[12046   188]
  [  171   714]]

 [[13061    10]
  [   22    26]]

 [[12079   259]
  [  259   522]]

 [[12356   171]
  [  188   404]]

 [[12616   119]
  [  114   270]]

 [[12961    30]
  [   41    87]]

 [[10836   396]
  [  402  1485]]

 [[12903    48]
  [   58   110]]

 [[11248   576]
  [  405   890]]

 [[12569   169]
  [  160   221]]

 [[13103     2]
  [    7     7]]

 [[12065   285]
  [  273   496]]

 [[12573   174]
  [  171   201]]

 [[12351   138]
  [  169   461]]

 [[13106     2]
  [    8     3]]

 [[12609   194]
  [  139   177]]

 [[12532   182]
  [  155   250]]

 [[12991    33]
  [   30    65]]

 [[13082    12]
  [   24     1]]

 [[13033    21]
  [   40    25]]

 [[13094     3]
  [    5    17]]

 [[12956    42]
  [   51    70]]

 [[12972    34]
  [   28    85]]

 [[12829    82]
  [   60   148]]

 [[12845    80]
  [   67   127]]

 [[13036    36]
  [   25    22]]

 [[12625    63]
  [   64   367]]

 [[13043    10]
  [   19    47]]

 [[12509   122]
  [  104   384]]

 [[13043    13]
  [   24    39]]

 [[12801    55]
  [   48   215]]

 [[13065     5]
  [   21    28]]

 [[13083     6]
  [    6    24]]

 [[13104     0]
  [    3    12]]

 [[13092     5]
  [    3    19]]

 [[13034    12]
  [    8    65]]]

===scores report===
metrics	scores
Accuracy	0.6818
MCC	0.6625
log_loss	1.6532
f1 score weighted	0.6799
f1 score macro	0.5982
f1 score micro	0.6818
roc_auc ovr	0.9572
roc_auc ovo	0.9553
precision	0.6815
recall	0.6818

===TRAIN MODELS with CV===

train_model_cv	Accuracy	MCC	log_loss	f1 score weighted	f1 score macro	f1 score micro	roc_auc ovr	roc_auc ovo	precision	recall
0	0.683079268292683	0.6633263726309233	1.669199797335486	0.6800747464628465	0.5883335344476402	0.683079268292683	0.9565866598153122	0.9531165299547096	0.6814588279680028	0.683079268292683
1	0.6788109756097561	0.6597655292965965	1.5917916154391534	0.6785415715215073	0.5967354549299884	0.6788109756097561	0.9571472860873937	0.9569652212479324	0.687409775053242	0.6788109756097561
2	0.6749237804878049	0.655360257189555	1.669227582429789	0.6722456186275403	0.5717526337085651	0.6749237804878049	0.955852663177791	0.9546471264102495	0.6746218533824281	0.6749237804878049
3	0.6839939024390244	0.6643229400382352	1.6425548452178762	0.6798322587128118	0.5822211540113472	0.6839939024390244	0.9581686159986237	0.9553534933986249	0.6800707337145029	0.6839939024390244
4	0.6818355057550118	0.6624848497538717	1.6532085383350774	0.6799382523011037	0.5981694057311234	0.6818355057550118	0.9571827618866228	0.9552700641769964	0.6814519689483518	0.6818355057550118
mean	0.6805286865168559	0.6610519897818363	1.6451964757514763	0.6781264895251619	0.5874424365657329	0.6805286865168559	0.9569875973931488	0.9550704870377025	0.6810026318133054	0.6805286865168559
std	0.0033041327957122842	0.0032241532564578484	0.02855487348579274	0.0029914803543143443	0.009753500073699607	0.0033041327957122842	0.0007625249136351713	0.0012415412893111582	0.004075396195219754	0.0033041327957122842

Accuracy
MCC
log_loss
f1 score weighted
f1 score macro
f1 score micro
roc_auc ovr
roc_auc ovo
precision
recallFinished train_model_cv in 21427.0968 secs

